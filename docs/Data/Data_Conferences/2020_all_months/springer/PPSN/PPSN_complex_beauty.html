<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>PPSN_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ppsn---99">PPSN - 99</h2>
<ul>
<li><details>
<summary>
(2020). Benchmarking a <span
class="math display">(<em>Œº</em>‚ÄÖ+‚ÄÖ<em>Œª</em>)</span> genetic algorithm
with configurable crossover probability. <em>PPSN</em>, 699‚Äì713. (<a
href="https://doi.org/10.1007/978-3-030-58115-2_49">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We investigate a family of $$(\mu +\lambda )$$ Genetic Algorithms (GAs) which creates offspring either from mutation or by recombining two randomly chosen parents. By scaling the crossover probability, we can thus interpolate from a fully mutation-only algorithm towards a fully crossover-based GA. We analyze, by empirical means, how the performance depends on the interplay of population size and the crossover probability. Our comparison on 25 pseudo-Boolean optimization problems reveals an advantage of crossover-based configurations on several easy optimization tasks, whereas the picture for more complex optimization problems is rather mixed. Moreover, we observe that the ‚Äúfast‚Äù mutation scheme with its are power-law distributed mutation strengths outperforms standard bit mutation on complex optimization tasks when it is combined with crossover, but performs worse in the absence of crossover. We then take a closer look at the surprisingly good performance of the crossover-based $$(\mu +\lambda )$$ GAs on the well-known LeadingOnes benchmark problem. We observe that the optimal crossover probability increases with increasing population size $$\mu $$ . At the same time, it decreases with increasing problem dimension, indicating that the advantages of the crossover are not visible in the asymptotic view classically applied in runtime analysis. We therefore argue that a mathematical investigation for fixed dimensions might help us observe effects which are not visible when focusing exclusively on asymptotic performance bounds.},
  archive   = {C_PPSN},
  author    = {Ye, Furong and Wang, Hao and Doerr, Carola and B√§ck, Thomas},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58115-2_49},
  pages     = {699-713},
  title     = {Benchmarking a $$(\mu +\lambda )$$ genetic algorithm with configurable crossover probability},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Approximation speed-up by quadratization on LeadingOnes.
<em>PPSN</em>, 686‚Äì698. (<a
href="https://doi.org/10.1007/978-3-030-58115-2_48">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We investigate the quadratization of LeadingOnes in the context of the landscape for local search. We prove that a standard quadratization (i.e., its expression as a degree-2 multilinear polynomial) of LeadingOnes transforms the search space for local search in such a way that faster progress can be made. In particular, we prove there is a $$\varOmega (n/\log n)$$ speed-up for constant-factor approximations by RLS when using the quadratized version of the function. This suggests that well-known transformations for classical pseudo-Boolean optimization might have an interesting impact on search heuristics. We derive and present numerical results that investigate the difference in correlation structure between the untransformed landscape and its quadratization. Finally, we report experiments that provide a detailed glimpse into the convergence properties on the quadratized function.},
  archive   = {C_PPSN},
  author    = {Sutton, Andrew M. and Whitley, Darrell},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58115-2_48},
  pages     = {686-698},
  title     = {Approximation speed-up by quadratization on LeadingOnes},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Filter sort is <span
class="math display"><em>ùõ∫</em>(<em>N</em><sup>3</sup>)</span> in the
worst case. <em>PPSN</em>, 675‚Äì685. (<a
href="https://doi.org/10.1007/978-3-030-58115-2_47">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Non-dominated sorting is a crucial operation used in many popular evolutionary multiobjective algorithms. The problem of non-dominated sorting, although solvable in polynomial time, is surprisingly difficult, and no algorithm is yet known which solves any instance on N points and M objectives in time asymptotically smaller than $$MN^2$$ . For this reason, many algorithm designers concentrate on reducing the leading constant and on (implicitly) tailoring their algorithms to inputs typical to evolutionary computation. While doing that, they sometimes forget to ensure that the worst-case running time of their algorithm is still $$O(MN^2)$$ . This is undesirable, especially if the inputs which make the algorithm work too slow can occur spontaneously. However, even if a counterexample is hard to find, the fact that it exists is still a weak point, as this can be exploited and lead to denial of service and other kinds of misbehaving. In this paper we prove that a recent algorithm for non-dominated sorting, called Filter Sort, has the worst-case complexity of $$\varOmega (N^3)$$ . In particular, we present a scenario which requires Filter Sort to perform $$\varTheta (N^3)$$ dominance comparisons, where each comparison, however, needs only O(1) elementary operations. Our scenario contains $$\varTheta (N)$$ non-domination layers, which is a necessary, but by no means a sufficient condition for being difficult for Filter Sort.},
  archive   = {C_PPSN},
  author    = {Mishra, Sumit and Buzdalov, Maxim},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58115-2_47},
  pages     = {675-685},
  title     = {Filter sort is $$\varOmega (N^3)$$ in the worst case},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On averaging the best samples in evolutionary computation.
<em>PPSN</em>, 661‚Äì674. (<a
href="https://doi.org/10.1007/978-3-030-58115-2_46">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Choosing the right selection rate is a long standing issue in evolutionary computation. In the continuous unconstrained case, we prove mathematically that a single parent $$\mu =1$$ leads to a sub-optimal simple regret in the case of the sphere function. We provide a theoretically-based selection rate $$\mu /\lambda $$ that leads to better progress rates. With our choice of selection rate, we get a provable regret of order $$O(\lambda ^{-1})$$ which has to be compared with $$O(\lambda ^{-2/d})$$ in the case where $$\mu =1$$ . We complete our study with experiments to confirm our theoretical claims.},
  archive   = {C_PPSN},
  author    = {Meunier, Laurent and Chevaleyre, Yann and Rapin, Jeremy and Royer, Cl√©ment W. and Teytaud, Olivier},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58115-2_46},
  pages     = {661-674},
  title     = {On averaging the best samples in evolutionary computation},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improved fixed-budget results via drift analysis.
<em>PPSN</em>, 648‚Äì660. (<a
href="https://doi.org/10.1007/978-3-030-58115-2_45">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Fixed-budget theory is concerned with computing or bounding the fitness value achievable by randomized search heuristics within a given budget of fitness function evaluations. Despite recent progress in fixed-budget theory, there is a lack of general tools to derive such results. We transfer drift theory, the key tool to derive expected optimization times, to the fixed-budged perspective. A first and easy-to-use statement concerned with iterating drift in so-called greed-admitting scenarios immediately translates into bounds on the expected function value. Afterwards, we consider a more general tool based on the well-known variable drift theorem. Applications of this technique to the LeadingOnes benchmark function yield statements that are more precise than the previous state of the art.},
  archive   = {C_PPSN},
  author    = {K√∂tzing, Timo and Witt, Carsten},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58115-2_45},
  pages     = {648-660},
  title     = {Improved fixed-budget results via drift analysis},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Analysis on the efficiency of multifactorial evolutionary
algorithms. <em>PPSN</em>, 634‚Äì647. (<a
href="https://doi.org/10.1007/978-3-030-58115-2_44">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Many experimental studies have demonstrated the superiority of multifactorial evolutionary algorithms (MFEAs) over traditional methods of solving each task independently. In this paper, we investigate this topic from theoretical analysis aspect. We present a runtime analysis of a (4+2) MFEA on several benchmark pseudo-Boolean functions, which include problems with similar tasks and problems with dissimilar tasks. Our analysis results show that, by properly setting the parameter rmp (i.e., the random mating probability), for the group of problems with similar tasks, the upper bound of expected runtime of the (4+2) MFEA on the harder task can be improved to be the same as on the easier one. As for the group of problems with dissimilar tasks, the expected upper bound of (4+2) MFEA on each task are the same as that of solving them independently. This study theoretically explains why some existing MFEAs perform better than traditional methods in experimental studies and provides insights into the parameter setting of MFEAs.},
  archive   = {C_PPSN},
  author    = {Huang, Zhengxin and Chen, Zefeng and Zhou, Yuren},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58115-2_44},
  pages     = {634-647},
  title     = {Analysis on the efficiency of multifactorial evolutionary algorithms},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Exponential upper bounds for the runtime of randomized
search heuristics. <em>PPSN</em>, 619‚Äì633. (<a
href="https://doi.org/10.1007/978-3-030-58115-2_43">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We argue that proven exponential upper bounds on runtimes, an established area in classic algorithms, are interesting also in evolutionary computation and we prove several such results. We show that any of the algorithms randomized local search, Metropolis algorithm, simulated annealing, and $$(1+1)$$ evolutionary algorithm can optimize any pseudo-Boolean weakly monotonic function under a large set of noise assumptions in a runtime that is at most exponential in the problem dimension¬†n. This drastically extends a previous such result, limited to the $$(1+1)$$ EA, the LeadingOnes function, and one-bit or bit-wise prior noise with noise probability at most 1/2, and at the same time simplifies its proof. With the same general argument, among others, we also derive a sub-exponential upper bound for the runtime of the $$(1,\lambda )$$ evolutionary algorithm on the OneMax problem when the offspring population size $$\lambda $$ is logarithmic, but below the efficiency threshold.},
  archive   = {C_PPSN},
  author    = {Doerr, Benjamin},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58115-2_43},
  pages     = {619-633},
  title     = {Exponential upper bounds for the runtime of randomized search heuristics},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Lower bounds for non-elitist evolutionary algorithms via
negative multiplicative drift. <em>PPSN</em>, 604‚Äì618. (<a
href="https://doi.org/10.1007/978-3-030-58115-2_42">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A decent number of lower bounds for non-elitist population-based evolutionary algorithms has been shown by now. Most of them are technically demanding due to the (hard to avoid) use of negative drift theorems ‚Äì general results which translate an expected progress away from the target into a high hitting time. We propose a simple negative drift theorem for multiplicative drift scenarios and show that it can simplify existing analyses. We discuss in more detail Lehre‚Äôs (PPSN 2010) negative drift in populations method, one of the most general tools to prove lower bounds on the runtime of non-elitist mutation-based evolutionary algorithms for discrete search spaces. Together with other arguments, we obtain an alternative and simpler proof, which also strengthens and simplifies this method. In particular, now only three of the five technical conditions of the previous result have to be verified. The lower bounds we obtain are explicit instead of only asymptotic. This allows to compute concrete lower bounds for concrete algorithms, but also enables us to show that super-polynomial runtimes appear already when the reproduction rate is only a $$(1 - \omega (n^{-1/2}))$$ factor below the threshold. As one particular result, we apply this method and a novel domination argument to show an exponential lower bound for the runtime of the mutation-only simple GA on OneMax for arbitrary population size.},
  archive   = {C_PPSN},
  author    = {Doerr, Benjamin},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58115-2_42},
  pages     = {604-618},
  title     = {Lower bounds for non-elitist evolutionary algorithms via negative multiplicative drift},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Maximizing submodular or monotone functions under partition
matroid constraints by multi-objective evolutionary algorithms.
<em>PPSN</em>, 588‚Äì603. (<a
href="https://doi.org/10.1007/978-3-030-58115-2_41">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Many important problems can be regarded as maximizing submodular functions under some constraints. A simple multi-objective evolutionary algorithm called GSEMO has been shown to achieve good approximation for submodular functions efficiently. While there have been many studies on the subject, most of existing run-time analyses for GSEMO assume a single cardinality constraint. In this work, we extend the theoretical results to partition matroid constraints which generalize cardinality constraints, and show that GSEMO can generally guarantee good approximation performance within polynomial expected run time. Furthermore, we conducted experimental comparison against a baseline GREEDY algorithm in maximizing undirected graph cuts on random graphs, under various partition matroid constraints. The results show GSEMO tends to outperform GREEDY in quadratic run time.},
  archive   = {C_PPSN},
  author    = {Do, Anh Viet and Neumann, Frank},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58115-2_41},
  pages     = {588-603},
  title     = {Maximizing submodular or monotone functions under partition matroid constraints by multi-objective evolutionary algorithms},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal mutation rates for the <span
class="math display">(1‚ÄÖ+‚ÄÖ<em>Œª</em>)</span> EA on OneMax.
<em>PPSN</em>, 574‚Äì587. (<a
href="https://doi.org/10.1007/978-3-030-58115-2_40">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The OneMax problem, alternatively known as the Hamming distance problem, is often referred to as the ‚Äúdrosophila of evolutionary computation (EC)‚Äù, because of its high relevance in theoretical and empirical analyses of EC approaches. It is therefore surprising that even for the simplest of all mutation-based algorithms, Randomized Local Search and the (1¬†+¬†1) EA, the optimal mutation rates were determined only very recently, in a GECCO 2019 poster. In this work, we extend the analysis of optimal mutation rates to two variants of the $$(1+\lambda )$$ EA and to the $$(1+\lambda )$$ RLS. To do this, we use dynamic programming and, for the $$(1+\lambda )$$ EA, numeric optimization, both requiring $$\varTheta (n^3)$$ time for problem dimension n. With this in hand, we compute for all population sizes $$\lambda \in {2^i \mid 0 \le i \le 18}$$ and for problem dimension $$n \in {1000, 2000, 5000}$$ which mutation rates minimize the expected running time and which ones maximize the expected progress. Our results do not only provide a lower bound against which we can measure common evolutionary approaches, but we also obtain insight into the structure of these optimal parameter choices. For example, we show that, for large population sizes, the best number of bits to flip is not monotone in the distance to the optimum. We also observe that the expected remaining running times are not necessarily unimodal for the $$(1+\lambda )$$ EA $$_{0 \rightarrow 1}$$ with shifted mutation.},
  archive   = {C_PPSN},
  author    = {Buzdalov, Maxim and Doerr, Carola},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58115-2_40},
  pages     = {574-587},
  title     = {Optimal mutation rates for the $$(1+\lambda )$$ EA on OneMax},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). First steps towards a runtime analysis when starting with a
good solution. <em>PPSN</em>, 560‚Äì573. (<a
href="https://doi.org/10.1007/978-3-030-58115-2_39">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The mathematical runtime analysis of evolutionary algorithms traditionally regards the time an algorithm needs to find a solution of a certain quality when initialized with a random population. In practical applications it may be possible to guess solutions that are better than random ones. We start a mathematical runtime analysis for such situations. We observe that different algorithms profit to a very different degree from a better initialization. We also show that the optimal parameterization of the algorithm can depend strongly on the quality of the initial solutions. To overcome this difficulty, self-adjusting and randomized heavy-tailed parameter choices can be profitable. Finally, we observe a larger gap between the performance of the best evolutionary algorithm we found and the corresponding black-box complexity. This could suggest that evolutionary algorithms better exploiting good initial solutions are still to be found. These first findings stem from analyzing the performance of the $$(1+1)$$ evolutionary algorithm and the static, self-adjusting, and heavy-tailed $$(1 + (\lambda ,\lambda ))$$ GA on the OneMax benchmark, but we are optimistic that the question how to profit from good initial solutions is interesting beyond these first examples.},
  archive   = {C_PPSN},
  author    = {Antipov, Denis and Buzdalov, Maxim and Doerr, Benjamin},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58115-2_39},
  pages     = {560-573},
  title     = {First steps towards a runtime analysis when starting with a good solution},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Runtime analysis of a heavy-tailed <span
class="math display">(1‚ÄÖ+‚ÄÖ(<em>Œª</em>,‚ÄÜ<em>Œª</em>))</span> genetic
algorithm on jump functions. <em>PPSN</em>, 545‚Äì559. (<a
href="https://doi.org/10.1007/978-3-030-58115-2_38">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {It was recently observed that the $$(1+(\lambda ,\lambda ))$$ genetic algorithm can comparably easily escape the local optimum of the jump functions benchmark. Consequently, this algorithm can optimize the jump function with jump size k in an expected runtime of only $$n^{(k + 1)/2}k^{-k/2}e^{O(k)}$$ fitness evaluations (Antipov, Doerr, Karavaev (GECCO 2020)). This performance, however, was obtained with non-standard parameter setting depending on the jump size¬†k. To overcome this difficulty, we propose to choose two parameters of the $$(1+(\lambda ,\lambda ))$$ genetic algorithm randomly from a power-law distribution. Via a mathematical runtime analysis, we show that this algorithm with natural instance-independent choices of the power-law parameters on all jump functions with jump size at most n/4 has a performance close to what the best instance-specific parameters in the previous work obtained. This price for instance-independence can be made as small as an $$O(n\log (n))$$ factor. Given the difficulty of the jump problem and the runtime losses from using mildly suboptimal fixed parameters (also discussed in this work), this appears to be a fair price.},
  archive   = {C_PPSN},
  author    = {Antipov, Denis and Doerr, Benjamin},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58115-2_38},
  pages     = {545-559},
  title     = {Runtime analysis of a heavy-tailed $$(1+(\lambda ,\lambda ))$$ genetic algorithm on jump functions},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Warm-start AlphaZero self-play search enhancements.
<em>PPSN</em>, 528‚Äì542. (<a
href="https://doi.org/10.1007/978-3-030-58115-2_37">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, AlphaZero has achieved landmark results in deep reinforcement learning, by providing a single self-play architecture that learned three different games at super human level. AlphaZero is a large and complicated system with many parameters, and success requires much compute power and fine-tuning. Reproducing results in other games is a challenge, and many researchers are looking for ways to improve results while reducing computational demands. AlphaZero‚Äôs design is purely based on self-play and makes no use of labeled expert data or domain specific enhancements; it is designed to learn from scratch. We propose a novel approach to deal with this cold-start problem by employing simple search enhancements at the beginning phase of self-play training, namely Rollout, Rapid Action Value Estimate¬†(RAVE) and dynamically weighted combinations of these with the neural network, and Rolling Horizon Evolutionary Algorithms (RHEA). Our experiments indicate that most of these enhancements improve the performance of their baseline player in three different (small) board games, with especially RAVE based variants playing strongly.},
  archive   = {C_PPSN},
  author    = {Wang, Hui and Preuss, Mike and Plaat, Aske},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58115-2_37},
  pages     = {528-542},
  title     = {Warm-start AlphaZero self-play search enhancements},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). ClipUp: A simple and powerful optimizer for
distribution-based policy evolution. <em>PPSN</em>, 515‚Äì527. (<a
href="https://doi.org/10.1007/978-3-030-58115-2_36">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Distribution-based search algorithms are a powerful approach for evolutionary reinforcement learning of neural network controllers. In these algorithms, gradients of the reward function with respect to the policy parameters are estimated using a population of solutions drawn from a search distribution, and then used for policy optimization with stochastic gradient ascent. A common choice is to use the Adam optimization algorithm for obtaining an adaptive behavior during gradient ascent, due to its success in a variety of supervised learning settings. As an alternative to Adam, we propose to enhance classical momentum-based gradient ascent with two simple-yet-effective techniques: gradient normalization and update clipping. We argue that the resulting optimizer called ClipUp (short for clipped updates) is a better choice for distribution-based policy evolution because its working principles are simple and easy to understand and its hyperparameters can be tuned more intuitively in practice. Moreover, it avoids the need to re-tune hyperparameters if the reward scale changes. Experiments show that ClipUp is competitive with Adam despite its simplicity and is effective at some of the most challenging continuous control benchmarks, including the Humanoid control task based on the Bullet physics simulator.},
  archive   = {C_PPSN},
  author    = {Toklu, Nihat Engin and Liskowski, Pawe≈Ç and Srivastava, Rupesh Kumar},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58115-2_36},
  pages     = {515-527},
  title     = {ClipUp: A simple and powerful optimizer for distribution-based policy evolution},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fitness landscape features and reward shaping in
reinforcement learning policy spaces. <em>PPSN</em>, 500‚Äì514. (<a
href="https://doi.org/10.1007/978-3-030-58115-2_35">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Reinforcement learning (RL) algorithms have received a lot of attention in recent years. However, relatively little work has been dedicated to analysing RL problems; which are thought to contain unique challenges, such as sparsity of the reward signal. Reward shaping is one approach that may help alleviate the sparse reward problem. In this paper we use fitness landscape features to study how reward shaping affects the underlying optimisation landscape of RL problems. Our results indicate that features such as deception, ruggedness, searchability, and symmetry can all be greatly affected by reward shaping; while neutrality, dispersion, and the number of local optima remain relatively invariant. This may provide some guidance as to the potential effectiveness of reward shaping for different algorithms, depending on what features they are sensitive to. Additionally, all of the reward functions we studied produced policy landscapes that contain a single local optimum and very high neutrality. This suggests that algorithms that explore spaces globally, rather than locally, may perform well on RL problems; and may help explain the success of evolutionary methods on RL problems. Furthermore, we suspect that the high neutrality of these landscapes is connected to the issue of reward sparsity in RL.},
  archive   = {C_PPSN},
  author    = {du Preez-Wilkinson, Nathaniel and Gallagher, Marcus},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58115-2_35},
  pages     = {500-514},
  title     = {Fitness landscape features and reward shaping in reinforcement learning policy spaces},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hybridizing the 1/5-th success rule with q-learning for
controlling the mutation rate of an evolutionary algorithm.
<em>PPSN</em>, 485‚Äì499. (<a
href="https://doi.org/10.1007/978-3-030-58115-2_34">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {It is well known that evolutionary algorithms (EAs) achieve peak performance only when their parameters are suitably tuned to the given problem. Even more, it is known that the best parameter values can change during the optimization process. Parameter control mechanisms are techniques developed to identify and to track these values. Recently, a series of rigorous theoretical works confirmed the superiority of several parameter control techniques over EAs with best possible static parameters. Among these results are examples for controlling the mutation rate of the $$(1+\lambda )$$ EA when optimizing the OneMax problem. However, it was shown in [Rodionova et¬†al., GECCO‚Äô19] that the quality of these techniques strongly depends on the offspring population size $$\lambda $$ . We introduce in this work a new hybrid parameter control technique, which combines the well-known one-fifth success rule with Q-learning. We demonstrate that our HQL mechanism achieves equal or superior performance to all techniques tested in [Rodionova et¬†al., GECCO‚Äô19] and this ‚Äì in contrast to previous parameter control methods ‚Äì simultaneously for all offspring population sizes $$\lambda $$ . We also show that the promising performance of HQL is not restricted to OneMax, but extends to several other benchmark problems.},
  archive   = {C_PPSN},
  author    = {Buzdalova, Arina and Doerr, Carola and Rodionova, Anna},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58115-2_34},
  pages     = {485-499},
  title     = {Hybridizing the 1/5-th success rule with Q-learning for controlling the mutation rate of an evolutionary algorithm},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimality-based analysis of XCSF compaction in discrete
reinforcement learning. <em>PPSN</em>, 471‚Äì484. (<a
href="https://doi.org/10.1007/978-3-030-58115-2_33">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Learning classifier systems (LCSs) are population-based predictive systems that were originally envisioned as agents to act in reinforcement learning (RL) environments. These systems can suffer from population bloat and so are amenable to compaction techniques that try to strike a balance between population size and performance. A well-studied LCS architecture is XCSF, which in the RL setting acts as a Q-function approximator. We apply XCSF to a deterministic and stochastic variant of the FrozenLake8x8 environment from OpenAI Gym, with its performance compared in terms of function approximation error and policy accuracy to the optimal Q-functions and policies produced by solving the environments via dynamic programming. We then introduce a novel compaction algorithm (Greedy Niche Mass Compaction‚ÄîGNMC) and study its operation on XCSF‚Äôs trained populations. Results show that given a suitable parametrisation, GNMC preserves or even slightly improves function approximation error while yielding a significant reduction in population size. Reasonable preservation of policy accuracy also occurs, and we link this metric to the commonly used steps-to-goal metric in maze-like environments, illustrating how the metrics are complementary rather than competitive.},
  archive   = {C_PPSN},
  author    = {Bishop, Jordan T. and Gallagher, Marcus},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58115-2_33},
  pages     = {471-484},
  title     = {Optimality-based analysis of XCSF compaction in discrete reinforcement learning},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A hybrid evolutionary algorithm for reliable facility
location problem. <em>PPSN</em>, 454‚Äì467. (<a
href="https://doi.org/10.1007/978-3-030-58115-2_32">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The reliable facility location problem (RFLP) is an important research topic of operational research and plays a vital role in the decision-making and management of modern supply chain and logistics. Through solving RFLP, the decision-maker can obtain reliable location decisions under the risk of facilities‚Äô disruptions or failures. In this paper, we propose a novel model for the RFLP. Instead of assuming allocating a fixed number of facilities to each customer as in the existing works, we set the number of allocated facilities as an independent variable in our proposed model, which makes our model more close to the scenarios in real life but more difficult to be solved by traditional methods. To handle it, we propose EAMLS, a hybrid evolutionary algorithm, which combines a memorable local search (MLS) method and an evolutionary algorithm (EA). Additionally, a novel metric called l3-value is proposed to assist the analysis of the algorithm‚Äôs convergence speed and exam the process of evolution. The experimental results show the effectiveness and superior performance of our EAMLS, compared to a CPLEX solver and a Genetic Algorithm (GA), on large-scale problems.},
  archive   = {C_PPSN},
  author    = {Zhang, Han and Liu, Jialin and Yao, Xin},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58115-2_32},
  pages     = {454-467},
  title     = {A hybrid evolutionary algorithm for reliable facility location problem},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust evolutionary bi-objective optimization for prostate
cancer treatment with high-dose-rate brachytherapy. <em>PPSN</em>,
441‚Äì453. (<a
href="https://doi.org/10.1007/978-3-030-58115-2_31">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We address the real-world problem of automating the design of high-quality prostate cancer treatment plans in case of high-dose-rate brachytherapy, a form of internal radiotherapy. For this, recently a bi-objective real-valued problem formulation was introduced. With a GPU parallelization of the Multi-Objective Real-Valued Gene-pool Optimal Mixing Evolutionary Algorithm (MO-RV-GOMEA), good treatment plans were found in clinically acceptable running times. However, optimizing a treatment plan and delivering it to the patient in practice is a two-stage decision process and involves a number of uncertainties. Firstly, there is uncertainty in the identified organ boundaries due to the limited resolution of the medical images. Secondly, the treatment involves placing catheters inside the patient, which always end up (slightly) different from what was optimized. An important factor is therefore the robustness of the final treatment plan to these uncertainties. In this work, we show how we can extend the evolutionary optimization approach to find robust plans using multiple scenarios without linearly increasing the amount of required computation effort, as well as how to deal with these uncertainties efficiently when taking into account the sequential decision-making moments. The performance is tested on three real-world patient cases. We find that MO-RV-GOMEA is equally well capable of solving the more complex robust problem formulation, resulting in a more realistic reflection of the treatment plan qualities.},
  archive   = {C_PPSN},
  author    = {van der Meer, Marjolein C. and Bel, Arjan and Niatsetski, Yury and Alderliesten, Tanja and Pieters, Bradley R. and Bosman, Peter A. N.},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58115-2_31},
  pages     = {441-453},
  title     = {Robust evolutionary bi-objective optimization for prostate cancer treatment with high-dose-rate brachytherapy},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Towards novel meta-heuristic algorithms for dynamic
capacitated arc routing problems. <em>PPSN</em>, 428‚Äì440. (<a
href="https://doi.org/10.1007/978-3-030-58115-2_30">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Capacitated Arc Routing Problem (CARP) is an abstraction for typical real world applications, like waste collection, winter gritting and mail delivery, to allow the development of efficient optimization algorithms. Most research work focuses on the static CARP, where all information in the problem remains unchanged over time. However, in the real world, dynamic changes may happen when the vehicles are in service, requiring routes to be rescheduled. In this paper, we mainly focus on this kind of Dynamic CARP (DCARP). Some meta-heuristics solve (D)CARP by generating individuals that are sequences of tasks to be served as the individual representation. The split of this sequence into sub-sequences to be served by different vehicles needs to be decided to generate an executable solution, which is necessary for calculating individual‚Äôs fitness. However, the existing split schemes for static CARP and DCARP are not capable of getting high quality feasible solutions for DCARP. Therefore, we propose two different split schemes in this paper ‚Äì an optimal and a greedy split scheme. The optimal split scheme, assisted by A-star algorithm, can obtain the best vehicle routes from an ordered list. The greedy split scheme is not guaranteed to obtain optimal splits, but it is much more efficient. More importantly, it can keep the rank information between different individuals. Our experiments show that the greedy split scheme has good relative accuracy with respect to the optimal split scheme and that the two proposed split schemes are better than the existing DCARP split scheme in terms of the obtained solutions‚Äô quality.},
  archive   = {C_PPSN},
  author    = {Tong, Hao and Minku, Leandro L. and Menzel, Stefan and Sendhoff, Bernhard and Yao, Xin},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58115-2_30},
  pages     = {428-440},
  title     = {Towards novel meta-heuristic algorithms for dynamic capacitated arc routing problems},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Human-derived heuristic enhancement of an evolutionary
algorithm for the 2D bin-packing problem. <em>PPSN</em>, 413‚Äì427. (<a
href="https://doi.org/10.1007/978-3-030-58115-2_29">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The 2D Bin-Packing Problem (2DBPP) is an NP-Hard combinatorial optimisation problem with many real-world analogues. Fully deterministic methods such as the well-known Best Fit and First Fit heuristics, stochastic methods such as Evolutionary Algorithms (EAs), and hybrid EAs that combine the deterministic and stochastic approaches have all been applied to the problem. Combining derived human expertise with a hybrid EA offers another potential approach. In this work, the moves of humans playing a gamified version of the 2DBPP were recorded and four different Human-Derived Heuristics (HDHs) were created by learning the underlying heuristics employed by those players. Each HDH used a decision tree in place of the mutation operator in the EA. To test their effectiveness, these were compared against hybrid EAs utilising Best Fit or First Fit heuristics as well as a standard EA using a random swap mutation modified with a Next Fit heuristic if the mutation was infeasible. The HDHs were shown to outperform the standard EA and were faster to converge than ‚Äì but ultimately outperformed by ‚Äì the First Fit and Best Fit heuristics. This shows that humans can create competitive heuristics through gameplay and helps to understand the role that heuristics can play in stochastic search.},
  archive   = {C_PPSN},
  author    = {Ross, Nicholas and Keedwell, Ed and Savic, Dragan},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58115-2_29},
  pages     = {413-427},
  title     = {Human-derived heuristic enhancement of an evolutionary algorithm for the 2D bin-packing problem},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Evolutionary graph-based v+e optimization for protection
against epidemics. <em>PPSN</em>, 399‚Äì412. (<a
href="https://doi.org/10.1007/978-3-030-58115-2_28">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Protection against spreading threats in networks gives rise to a¬†variety of interesting optimization problems. Among others, vertex protection problems such as the Firefighter Problem and vaccination optimization problem can be tackled. Interestingly, in some cases a¬†networked system can be made more resilient to threats, by changing its connectivity, which motivates the study of another type of optimization problems focused on adapting graph connectivity. In this paper the above-mentioned approaches are combined, that is both vertex and edge protection is applied in order to stop the threat from spreading. Solutions to the proposed problem are evaluated using different cost functions for protected vertices and edges, motivated by real-life observations regarding the costs of epidemics control. Instead of making decisions for each of the vertices and edges a¬†decision model is used (based on rules or a¬†neural network) with parameters optimized using an evolutionary algorithm. In the experiments the model using rules was found to perform better than the one based on a¬†neural network.},
  archive   = {C_PPSN},
  author    = {Michalak, Krzysztof},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58115-2_28},
  pages     = {399-412},
  title     = {Evolutionary graph-based V+E optimization for protection against epidemics},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A variable neighborhood search for the job sequencing with
one common and multiple secondary resources problem. <em>PPSN</em>,
385‚Äì398. (<a
href="https://doi.org/10.1007/978-3-030-58115-2_27">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this work we consider a scheduling problem where a set of non-preemptive jobs needs to be scheduled such that the makespan is minimized. Each job requires two resources: (1) a common resource, shared by all jobs and (2) a secondary resource, shared with only a subset of the other jobs. The secondary resource is required during the job‚Äôs entire processing time whereas the common resource is only required during a part of a job‚Äôs execution. The problem models, for instance, the scheduling of patients during one day in a particle therapy facility for cancer treatment. We heuristically tackle the problem by a general variable neighborhood search (GVNS) based on move and exchange neighborhoods and an efficient evaluation scheme to scan the neighborhoods of the current incumbent solution. An experimental evaluation on two benchmark instance sets, including instances with up¬†to 2000 jobs, shows the effectiveness of the GVNS. In particular for larger instances our GVNS outperforms an anytime A $$^*$$ algorithm that was the so far leading method in heuristic terms as well as a constrained programming model solved by ILOG CP optimizer.},
  archive   = {C_PPSN},
  author    = {Kaufmann, Thomas and Horn, Matthias and Raidl, G√ºnther R.},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58115-2_27},
  pages     = {385-398},
  title     = {A variable neighborhood search for the job sequencing with one common and multiple secondary resources problem},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Generic relative relations in hierarchical gene expression
data classification. <em>PPSN</em>, 372‚Äì384. (<a
href="https://doi.org/10.1007/978-3-030-58115-2_26">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Relative Expression Analysis (RXA) plays an important role in biomarker discovery and disease prediction from gene expression profiles. It deliberately ignores raw data values and investigates only the relative ordering relationships between a small group of genes. The classifiers constituted on that concept are therefore robust to small data perturbations and normalization procedures, but above all, they are easy to interpret and analyze. In this paper, we propose a novel globally induced decision tree in which node splits are based on the RXA methodology. We have extended a simple ordering with a more generic concept that also explores fractional relative relations between the genes. To face up¬†to the newly arisen computational complexity, we have replaced the typical brute force approach with an evolutionary algorithm. As this was not enough, we boosted our solution with the OpenMP parallelization, local search components calculated on the GPU and embedded ranking of genes to improve the evolutionary convergence. This way we managed to explore in a reasonable time a much larger solution space and search for more complex but still comprehensible gene-gene interactions. An empirical investigation carried out on 8 cancer-related datasets shows the potential of the proposed algorithm not only in the context of accuracy improvement but also in finding biologically meaningful patterns.},
  archive   = {C_PPSN},
  author    = {Czajkowski, Marcin and Jurczuk, Krzysztof and Kretowski, Marek},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58115-2_26},
  pages     = {372-384},
  title     = {Generic relative relations in hierarchical gene expression data classification},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Evolutionary multi-objective design of SARS-CoV-2 protease
inhibitor candidates. <em>PPSN</em>, 357‚Äì371. (<a
href="https://doi.org/10.1007/978-3-030-58115-2_25">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Computational drug design based on artificial intelligence is an emerging research area. At the time of writing this paper, the world suffers from an outbreak of the coronavirus SARS-CoV-2. A promising way to stop the virus replication is via protease inhibition. We propose an evolutionary multi-objective algorithm (EMOA) to design potential protease inhibitors for SARS-CoV-2 ‚Äôs main protease. Based on the SELFIES representation the EMOA maximizes the binding of candidate ligands to the protein using the docking tool QuickVina 2, while at the same time taking into account further objectives like drug-likeness or the fulfillment of filter constraints. The experimental part analyzes the evolutionary process and discusses the inhibitor candidates.},
  archive   = {C_PPSN},
  author    = {Cofala, Tim and Elend, Lars and Mirbach, Philip and Prellberg, Jonas and Teusch, Thomas and Kramer, Oliver},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58115-2_25},
  pages     = {357-371},
  title     = {Evolutionary multi-objective design of SARS-CoV-2 protease inhibitor candidates},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A search for additional structure: The case of cryptographic
s-boxes. <em>PPSN</em>, 343‚Äì356. (<a
href="https://doi.org/10.1007/978-3-030-58115-2_24">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We investigate whether it is possible to evolve cryptographically strong S-boxes that have additional constraints on their structure. We investigate two scenarios: where S-boxes additionally have a specific sum of values in rows, columns, or diagonals and the scenario where we check that the difference between the Hamming weights of inputs and outputs is minimal. The first case represents an interesting benchmark problem, while the second one has practical ramifications as such S-boxes could offer better resilience against side-channel attacks. We explore three solution representations by using the permutation, integer, and cellular automata-based encoding. Our results show that it is possible to find S-boxes with excellent cryptographic properties (even optimal ones) and reach the required sums when representing S-box as a square matrix. On the other hand, for the most promising S-box representation based on trees and cellular automata rules, we did not succeed in finding S-boxes with small differences in the Hamming weights between the inputs and outputs, which opens an interesting future research direction. Our results for this scenario and different encodings inspired a mathematical proof that the values reached by evolutionary algorithms are the best possible ones.},
  archive   = {C_PPSN},
  author    = {Carlet, Claude and Djurasevic, Marko and Jakobovic, Domagoj and Picek, Stjepan},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58115-2_24},
  pages     = {343-356},
  title     = {A search for additional structure: The case of cryptographic S-boxes},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Human-like summaries from heterogeneous and time-windowed
software development artefacts. <em>PPSN</em>, 329‚Äì342. (<a
href="https://doi.org/10.1007/978-3-030-58115-2_23">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Automatic text summarisation has drawn considerable interest in the area of software engineering. It is challenging to summarise the activities related to a software project, (1) because of the volume and heterogeneity of involved software artefacts, and (2) because it is unclear what information a developer seeks in such a multi-document summary. We present the first framework for summarising multi-document software artefacts containing heterogeneous data within a given time frame. To produce human-like summaries, we employ a range of iterative heuristics to minimise the cosine-similarity between texts and high-dimensional feature vectors. A first study shows that users find the automatically generated summaries the most useful when they are generated using word similarity and based on the eight most relevant software artefacts.},
  archive   = {C_PPSN},
  author    = {Alghamdi, Mahfouth and Treude, Christoph and Wagner, Markus},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58115-2_23},
  pages     = {329-342},
  title     = {Human-like summaries from heterogeneous and time-windowed software development artefacts},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improving many-objective evolutionary algorithms by means of
edge-rotated cones. <em>PPSN</em>, 313‚Äì326. (<a
href="https://doi.org/10.1007/978-3-030-58115-2_22">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Given a point in m-dimensional objective space, any $$\varepsilon $$ -ball of a point can be partitioned into the incomparable, the dominated and dominating region. The ratio between the size of the incomparable region, and the dominated (and dominating) region decreases proportionally to $$1/2^{m-1}$$ , i.e., the volume of the Pareto dominating orthant as compared to all other volumes. Due to this reason, it gets increasingly unlikely that dominating points can be found by random, isotropic mutations. As a remedy to stagnation of search in many objective optimization, in this paper, we suggest to enhance the Pareto dominance order by involving an obtuse convex dominance cone in the convergence phase of an evolutionary optimization algorithm. We propose edge-rotated cones as generalizations of Pareto dominance cones for which the opening angle can be controlled by a single parameter only. The approach is integrated in several state-of-the-art multi-objective evolutionary algorithms (MOEAs) and tested on benchmark problems with four, five, six and eight objectives. Computational experiments demonstrate the ability of these edge-rotated cones to improve the performance of MOEAs on many-objective optimization problems.},
  archive   = {C_PPSN},
  author    = {Wang, Yali and Deutz, Andr√© and B√§ck, Thomas and Emmerich, Michael},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58115-2_22},
  pages     = {313-326},
  title     = {Improving many-objective evolutionary algorithms by means of edge-rotated cones},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Visualising evolution history in multi- and many-objective
optimisation. <em>PPSN</em>, 299‚Äì312. (<a
href="https://doi.org/10.1007/978-3-030-58115-2_21">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Evolutionary algorithms are widely used to solve optimisation problems. However, challenges of transparency arise in both visualising the processes of an optimiser operating through a problem and understanding the problem features produced from many-objective problems, where comprehending four or more spatial dimensions is difficult. This work considers the visualisation of a population as an optimisation process executes. We have adapted an existing visualisation technique to multi- and many-objective problem data, enabling a user to visualise the EA processes and identify specific problem characteristics and thus providing a greater understanding of the problem landscape. This is particularly valuable if the problem landscape is unknown, contains unknown features or is a many-objective problem. We have shown how using this framework is effective on a suite of multi- and many-objective benchmark test problems, optimising them with NSGA-II and NSGA-III.},
  archive   = {C_PPSN},
  author    = {Walter, Mathew J. and Walker, David J. and Craven, Matthew J.},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58115-2_21},
  pages     = {299-312},
  title     = {Visualising evolution history in multi- and many-objective optimisation},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A study of swarm topologies and their influence on the
performance of multi-objective particle swarm optimizers. <em>PPSN</em>,
285‚Äì298. (<a
href="https://doi.org/10.1007/978-3-030-58115-2_20">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {It has been shown that swarm topologies influence the behavior of Particle Swarm Optimization (PSO). A large number of connections stimulates exploitation, while a low number of connections stimulates exploration. Furthermore, a topology with four links per particle is known to improve PSO‚Äôs performance. In spite of this, there are few studies about the influence of swarm topologies in Multi-Objective Particle Swarm Optimizers (MOPSOs). We analyze the influence of star, tree, lattice, ring and wheel topologies in the performance of the Speed-constrained Multi-objective Particle Swarm Optimizer (SMPSO) when adopting a variety of multi-objective problems, including the well-known ZDT, DTLZ and WFG test suites. Our results indicate that the selection of the proper topology does indeed improve the performance in SMPSO.},
  archive   = {C_PPSN},
  author    = {Valencia-Rodr√≠guez, Diana Cristina and Coello Coello, Carlos A.},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58115-2_20},
  pages     = {285-298},
  title     = {A study of swarm topologies and their influence on the performance of multi-objective particle swarm optimizers},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adaptive operator selection based on dynamic thompson
sampling for MOEA/d.¬†<em>PPSN</em>, 271‚Äì284. (<a
href="https://doi.org/10.1007/978-3-030-58115-2_19">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In evolutionary computation, different reproduction operators have various search dynamics. To strike a well balance between exploration and exploitation, it is attractive to have an adaptive operator selection (AOS) mechanism that automatically chooses the most appropriate operator on the fly according to the current status. This paper proposes a new AOS mechanism for multi-objective evolutionary algorithm based on decomposition (MOEA/D). More specifically, the AOS is formulated as a multi-armed bandit problem where the dynamic Thompson sampling (DYTS) is applied to adapt the bandit learning model, originally proposed with an assumption of a fixed award distribution, to a non-stationary setup. In particular, each arm of our bandit learning model represents a reproduction operator and is assigned with a prior reward distribution. The parameters of these reward distributions will be progressively updated according to the performance of its performance collected from the evolutionary process. When generating an offspring, an operator is chosen by sampling from those reward distribution according to the DYTS. Experimental results fully demonstrate the effectiveness and competitiveness of our proposed AOS mechanism compared with other four state-of-the-art MOEA/D variants.},
  archive   = {C_PPSN},
  author    = {Sun, Lei and Li, Ke},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58115-2_19},
  pages     = {271-284},
  title     = {Adaptive operator selection based on dynamic thompson sampling for MOEA/D},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hypervolume optimal <span
class="math display"><em>Œº</em></span> -distributions on line-based
pareto fronts in three dimensions. <em>PPSN</em>, 257‚Äì270. (<a
href="https://doi.org/10.1007/978-3-030-58115-2_18">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Hypervolume optimal $$\mu $$ -distribution is a fundamental research topic which investigates the distribution of $$\mu $$ solutions on the Pareto front for hypervolume maximization. It has been theoretically shown that the optimal distribution of $$\mu $$ solutions on a linear Pareto front in two dimensions is the one with $$\mu $$ equispaced solutions. However, the equispaced property of an optimal distribution does not always hold for a single-line Pareto front in three dimensions. It only holds for the single-line Pareto front where one objective of the Pareto front is constant. In this paper, we further theoretically investigate the hypervolume optimal $$\mu $$ -distribution on line-based Pareto fronts in three dimensions. In addition to a single-line Pareto front, we consider Pareto fronts constructed with two lines and three lines, where each line is a Pareto front with one constant objective. We show that even the equispaced property holds for each single-line Pareto front, it does not always hold for the Pareto fronts combined with them. Specifically, whether this property holds or not depends on how the lines are combined.},
  archive   = {C_PPSN},
  author    = {Shang, Ke and Ishibuchi, Hisao and Chen, Weiyu and Adam, Luk√°≈°},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58115-2_18},
  pages     = {257-270},
  title     = {Hypervolume optimal $$\mu $$ -distributions on line-based pareto fronts in three dimensions},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new paradigm in interactive evolutionary multiobjective
optimization. <em>PPSN</em>, 243‚Äì256. (<a
href="https://doi.org/10.1007/978-3-030-58115-2_17">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Over the years, scalarization functions have been used to solve multiobjective optimization problems by converting them to one or more single objective optimization problem(s). This study proposes a novel idea of solving multiobjective optimization problems in an interactive manner by using multiple scalarization functions to map vectors in the objective space to a new, so-called preference incorporated space (PIS). In this way, the original problem is converted into a new multiobjective optimization problem with typically fewer objectives in the PIS. This mapping enables a modular incorporation of decision maker‚Äôs preferences to convert any evolutionary algorithm to an interactive one, where preference information is directing the solution process. Advantages of optimizing in this new space are discussed and the idea is demonstrated with two interactive evolutionary algorithms: IOPIS/RVEA and IOPIS/NSGA-III. According to the experiments conducted, the new algorithms provide solutions that are better in quality as compared to those of state-of-the-art evolutionary algorithms and their variants where preference information is incorporated in the original objective space. Furthermore, the promising results require fewer function evaluations.},
  archive   = {C_PPSN},
  author    = {Saini, Bhupinder Singh and Hakanen, Jussi and Miettinen, Kaisa},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58115-2_17},
  pages     = {243-256},
  title     = {A new paradigm in interactive evolutionary multiobjective optimization},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Many-objective test database generation for SQL.
<em>PPSN</em>, 229‚Äì242. (<a
href="https://doi.org/10.1007/978-3-030-58115-2_16">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Generating test database for SQL queries is an important but challenging task in software engineering. Existing approaches have modeled the task as a single-objective optimization problem. However, due to the improper handling of the relationship between different targets, the existing approaches face strong limitations, which we summarize as the inter-objective barrier and the test database bloating barrier. In this study, we propose a two-stage approach MoeSQL, which features the combination of many-objective evolutionary algorithm and decomposition based test database reduction. The effectiveness of MoeSQL lie in the ability to handle multiple targets simultaneously, and a local search to avoid the test database from bloating. Experiments over 1888 SQL queries demonstrate that, MoeSQL is able to achieve high coverage comparable to the state-of-the-art algorithm EvoSQL, and obtain more compact solutions, only 59.47\% of those obtained by EvoSQL, measured by the overall number of data rows.},
  archive   = {C_PPSN},
  author    = {Ren, Zhilei and Dong, Shaozheng and Li, Xiaochen and Chi, Zongzheng and Jiang, He},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58115-2_16},
  pages     = {229-242},
  title     = {Many-objective test database generation for SQL},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Ensuring smoothly navigable approximation sets by b√©zier
curve parameterizations in evolutionary bi-objective optimization.
<em>PPSN</em>, 215‚Äì228. (<a
href="https://doi.org/10.1007/978-3-030-58115-2_15">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The aim of bi-objective optimization is to obtain an approximation set of (near) Pareto optimal solutions. A decision maker then navigates this set to select a final desired solution, often using a visualization of the approximation front. The front provides a navigational ordering of solutions to traverse, but this ordering does not necessarily map to a smooth trajectory through decision space. This forces the decision maker to inspect the decision variables of each solution individually, potentially making navigation of the approximation set unintuitive. In this work, we aim to improve approximation set navigability by enforcing a form of smoothness or continuity between solutions in terms of their decision variables. Imposing smoothness as a restriction upon common domination-based multi-objective evolutionary algorithms is not straightforward. Therefore, we use the recently introduced uncrowded hypervolume (UHV) to reformulate the multi-objective optimization problem as a single-objective problem in which parameterized approximation sets are directly optimized. We study here the case of parameterizing approximation sets as smooth B√©zier curves in decision space. We approach the resulting single-objective problem with the gene-pool optimal mixing evolutionary algorithm (GOMEA), and we call the resulting algorithm BezEA. We analyze the behavior of BezEA and compare it to optimization of the UHV with GOMEA as well as the domination-based multi-objective GOMEA. We show that high-quality approximation sets can be obtained with BezEA, sometimes even outperforming the domination- and UHV-based algorithms, while smoothness of the navigation trajectory through decision space is guaranteed.},
  archive   = {C_PPSN},
  author    = {Maree, Stefanus C. and Alderliesten, Tanja and Bosman, Peter A. N.},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58115-2_15},
  pages     = {215-228},
  title     = {Ensuring smoothly navigable approximation sets by b√©zier curve parameterizations in evolutionary bi-objective optimization},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An ensemble indicator-based density estimator for
evolutionary multi-objective optimization. <em>PPSN</em>, 201‚Äì214. (<a
href="https://doi.org/10.1007/978-3-030-58115-2_14">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Ensemble learning is one of the most employed methods in machine learning. Its main ground is the construction of stronger mechanisms based on the combination of elementary ones. In this paper, we employ AdaBoost, which is one of the most well-known ensemble methods, to generate an ensemble indicator-based density estimator for multi-objective optimization. It combines the search properties of five density estimators, based on the hypervolume, R2, IGD $$^+$$ , $$\epsilon ^+$$ , and $$\varDelta _p$$ quality indicators. Through the multi-objective evolutionary search process, the proposed ensemble mechanism adapts itself using a learning process that takes the preferences of the underlying quality indicators into account. The proposed method gives rise to the ensemble indicator-based multi-objective evolutionary algorithm (EIB-MOEA) that shows a robust performance on different multi-objective optimization problems when compared with respect to several existing indicator-based multi-objective evolutionary algorithms.},
  archive   = {C_PPSN},
  author    = {Falc√≥n-Cardona, Jes√∫s Guillermo and Liefooghe, Arnaud and Coello Coello, Carlos A.},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58115-2_14},
  pages     = {201-214},
  title     = {An ensemble indicator-based density estimator for evolutionary multi-objective optimization},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-objective optimization by uncrowded hypervolume
gradient ascent. <em>PPSN</em>, 186‚Äì200. (<a
href="https://doi.org/10.1007/978-3-030-58115-2_13">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Evolutionary algorithms (EAs) are the preferred method for solving black-box multi-objective optimization problems, but when gradients of the objective functions are available, it is not straightforward to exploit these efficiently. By contrast, gradient-based optimization is well-established for single-objective optimization. A single-objective reformulation of the multi-objective problem could therefore offer a solution. Of particular interest to this end is the recently introduced uncrowded hypervolume (UHV) indicator, which is Pareto compliant and also takes into account dominated solutions. In this work, we show that the gradient of the UHV can often be computed, which allows for a direct application of gradient ascent algorithms. We compare this new approach with two EAs for UHV optimization as well as with one gradient-based algorithm for optimizing the well-established hypervolume. On several bi-objective benchmarks, we find that gradient-based algorithms outperform the tested EAs by obtaining a better hypervolume with fewer evaluations whenever exact gradients of the multiple objective functions are available and in case of small evaluation budgets. For larger budgets, however, EAs perform similarly or better. We further find that, when finite differences are used to approximate the gradients of the multiple objectives, our new gradient-based algorithm is still competitive with EAs in most considered benchmarks. Implementations are available at https://github.com/scmaree/uncrowded-hypervolume .},
  archive   = {C_PPSN},
  author    = {Deist, Timo M. and Maree, Stefanus C. and Alderliesten, Tanja and Bosman, Peter A. N.},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58115-2_13},
  pages     = {186-200},
  title     = {Multi-objective optimization by uncrowded hypervolume gradient ascent},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On sharing information between sub-populations in MOEA/s.
<em>PPSN</em>, 171‚Äì185. (<a
href="https://doi.org/10.1007/978-3-030-58115-2_12">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This work investigates the effect of information exchange in decomposition methods that work with multi-membered populations as sub-problems. As an algorithm framework, we use the Multi-objective Evolutionary Algorithm based on Sub-populations¬†(MOEA/S). This algorithm uses parallel sub-populations that can exchange information via migration and/or recombination. For this work, each sub-population is constructed by a few weighted utility functions, grouped by distance between their weighting vectors. The question investigated in this paper is: How is the distance between sub-populations and the mechanism of information exchange influencing the performance of MOEA/S? The study considers two ways of transferring information: (1) migration of individuals, (2) recombination using parents from two different sub-populations. A matrix describing the linkage patterns between sub-populations governs migration and recombination mechanisms. This work conducts a systematic study using the multi-objective knapsack problem¬†(MOKP) and multi-objective traveling salesperson¬†(MOTSP) for two and three objectives test problems. The results motivated a restriction policy for sharing information. We compare an algorithm using this policy with other state-of-the-art MOEAs, including NSGA III, MOEA/D, and the previous version of MOEA/S.},
  archive   = {C_PPSN},
  author    = {de Almeida Ribeiro, Lucas and Emmerich, Michael and da Silva Soares, Anderson and de Lima, Telma Woerle},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58115-2_12},
  pages     = {171-185},
  title     = {On sharing information between sub-populations in MOEA/S},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). One PLOT to show them all: Visualization of efficient sets
in multi-objective landscapes. <em>PPSN</em>, 154‚Äì167. (<a
href="https://doi.org/10.1007/978-3-030-58115-2_11">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Visualization techniques for the decision space of continuous multi-objective optimization problems (MOPs) are rather scarce in research. For long, all techniques focused on global optimality and even for the few available landscape visualizations, e.g., cost landscapes, globality is the main criterion. In contrast, the recently proposed gradient field heatmaps (GFHs) emphasize the location and attraction basins of local efficient sets, but ignore the relation of sets in terms of solution quality. In this paper, we propose a new and hybrid visualization technique, which combines the advantages of both approaches in order to represent local and global optimality together within a single visualization. Therefore, we build on the GFH approach but apply a new technique for approximating the location of locally efficient points and using the divergence of the multi-objective gradient vector field as a robust second-order condition. Then, the relative dominance relationship of the determined locally efficient points is used to visualize the complete landscape of the MOP. Augmented by information on the basins of attraction, this Plot of Landscapes with Optimal Trade-offs (PLOT) becomes one of the most informative multi-objective landscape visualization techniques available.},
  archive   = {C_PPSN},
  author    = {Sch√§permeier, Lennart and Grimme, Christian and Kerschke, Pascal},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58115-2_11},
  pages     = {154-167},
  title     = {One PLOT to show them all: Visualization of efficient sets in multi-objective landscapes},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Exploratory landscape analysis is strongly sensitive to the
sampling strategy. <em>PPSN</em>, 139‚Äì153. (<a
href="https://doi.org/10.1007/978-3-030-58115-2_10">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Exploratory landscape analysis (ELA) supports supervised learning approaches for automated algorithm selection and configuration by providing sets of features that quantify the most relevant characteristics of the optimization problem at hand. In black-box optimization, where an explicit problem representation is not available, the feature values need to be approximated from a small number of sample points. In practice, uniformly sampled random point sets and Latin hypercube constructions are commonly used sampling strategies. In this work, we analyze how the sampling method and the sample size influence the quality of the feature value approximations and how this quality impacts the accuracy of a standard classification task. While, not unexpectedly, increasing the number of sample points gives more robust estimates for the feature values, to our surprise we find that the feature value approximations for different sampling strategies do not converge to the same value. This implies that approximated feature values cannot be interpreted independently of the underlying sampling strategy. As our classification experiments show, this also implies that the feature approximations used for training a classifier must stem from the same sampling strategy as those used for the actual classification tasks. As a side result we show that classifiers trained with feature values approximated by Sobol‚Äô sequences achieve higher accuracy than any of the standard sampling techniques. This may indicate improvement potential for ELA-trained machine learning models.},
  archive   = {C_PPSN},
  author    = {Renau, Quentin and Doerr, Carola and Dreo, Johann and Doerr, Benjamin},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58115-2_10},
  pages     = {139-153},
  title     = {Exploratory landscape analysis is strongly sensitive to the sampling strategy},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Global landscape structure and the random MAX-SAT phase
transition. <em>PPSN</em>, 125‚Äì138. (<a
href="https://doi.org/10.1007/978-3-030-58115-2_9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We revisit the fitness landscape structure of random MAX-SAT instances, and address the question: what structural features change when we go from easy underconstrained instances to hard overconstrained ones? Some standard techniques such as autocorrelation analysis fail to explain what makes instances hard to solve for stochastic local search algorithms, indicating that deeper landscape features are required to explain the observed performance differences. We address this question by means of local optima network (LON) analysis and visualisation. Our results reveal that the number, size, and, most importantly, the connectivity pattern of local and global optima change significantly over the easy-hard transition. Our empirical results suggests that the landscape of hard MAX-SAT instances may feature sub-optimal funnels, that is, clusters of sub-optimal solutions where stochastic local search methods can get trapped.},
  archive   = {C_PPSN},
  author    = {Ochoa, Gabriela and Chicano, Francisco and Tomassini, Marco},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58115-2_9},
  pages     = {125-138},
  title     = {Global landscape structure and the random MAX-SAT phase transition},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fitness landscape analysis of dimensionally-aware genetic
programming featuring feynman equations. <em>PPSN</em>, 111‚Äì124. (<a
href="https://doi.org/10.1007/978-3-030-58115-2_8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Genetic programming is an often-used technique for symbolic regression: finding symbolic expressions that match data from an unknown function. To make the symbolic regression more efficient, one can also use dimensionally-aware genetic programming that constrains the physical units of the equation. Nevertheless, there is no formal analysis of how much dimensionality awareness helps in the regression process. In this paper, we conduct a fitness landscape analysis of dimensionally-aware genetic programming search spaces on a subset of equations from Richard Feynman‚Äôs well-known lectures. We define an initialisation procedure and an accompanying set of neighbourhood operators for conducting the local search within the physical unit constraints. Our experiments show that the added information about the variable dimensionality can efficiently guide the search algorithm. Still, further analysis of the differences between the dimensionally-aware and standard genetic programming landscapes is needed to help in the design of efficient evolutionary operators to be used in a dimensionally-aware regression.},
  archive   = {C_PPSN},
  author    = {Durasevic, Marko and Jakobovic, Domagoj and Scoczynski Ribeiro Martins, Marcella and Picek, Stjepan and Wagner, Markus},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58115-2_8},
  pages     = {111-124},
  title     = {Fitness landscape analysis of dimensionally-aware genetic programming featuring feynman equations},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On stochastic fitness landscapes: Local optimality and
fitness landscape analysis for stochastic search operators.
<em>PPSN</em>, 97‚Äì110. (<a
href="https://doi.org/10.1007/978-3-030-58115-2_7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Fitness landscape analysis is a well-established tool for gaining insights about optimization problems and informing about the behavior of local and evolutionary search algorithms. In the conventional definition of a fitness landscape, the neighborhood of a given solution is a set containing nearby solutions whose distance is below a threshold, or that are reachable using a deterministic local search operator. In this paper, we generalize this definition in order to analyze the induced fitness landscape for stochastic search operators, that is when neighboring solutions are reachable under different probabilities. More particularly, we give the definition of a stochastic local optimum under this setting, in terms of a probability to reach strictly improving solutions. We illustrate the relevance of stochastic fitness landscapes for enumerable combinatorial benchmark problems, and we empirically analyze their properties for different stochastic operators, neighborhood sample sizes, and local optimality thresholds. We also portray their differences through stochastic local optima networks, intending to gather a better understanding of fitness landscapes under stochastic search operators.},
  archive   = {C_PPSN},
  author    = {Aboutaib, Brahim and Verel, S√©bastien and Fonlupt, Cyril and Derbel, Bilel and Liefooghe, Arnaud and Ahiod, Bela√Ød},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58115-2_7},
  pages     = {97-110},
  title     = {On stochastic fitness landscapes: Local optimality and fitness landscape analysis for stochastic search operators},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Learning a formula of interpretability to learn
interpretable formulas. <em>PPSN</em>, 79‚Äì93. (<a
href="https://doi.org/10.1007/978-3-030-58115-2_6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Many risk-sensitive applications require Machine Learning (ML) models to be interpretable. Attempts to obtain interpretable models typically rely on tuning, by trial-and-error, hyper-parameters of model complexity that are only loosely related to interpretability. We show that it is instead possible to take a meta-learning approach: an ML model of non-trivial Proxies of Human Interpretability (PHIs) can be learned from human feedback, then this model can be incorporated within an ML training process to directly optimize for interpretability. We show this for evolutionary symbolic regression. We first design and distribute a survey finalized at finding a link between features of mathematical formulas and two established PHIs, simulatability and decomposability. Next, we use the resulting dataset to learn an ML model of interpretability. Lastly, we query this model to estimate the interpretability of evolving solutions within bi-objective genetic programming. We perform experiments on five synthetic and eight real-world symbolic regression problems, comparing to the traditional use of solution size minimization. The results show that the use of our model leads to formulas that are, for a same level of accuracy-interpretability trade-off, either significantly more or equally accurate. Moreover, the formulas are also arguably more interpretable. Given the very positive results, we believe that our approach represents an important stepping stone for the design of next-generation interpretable (evolutionary) ML algorithms.},
  archive   = {C_PPSN},
  author    = {Virgolin, Marco and De Lorenzo, Andrea and Medvet, Eric and Randone, Francesca},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58115-2_6},
  pages     = {79-93},
  title     = {Learning a formula of interpretability to learn interpretable formulas},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Image feature learning with genetic programming.
<em>PPSN</em>, 63‚Äì78. (<a
href="https://doi.org/10.1007/978-3-030-58115-2_5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Learning features from raw data is an important topic in machine learning. This paper presents Genetic Program Feature Learner (GPFL), a novel generative GP feature learner for 2D images. GPFL executes multiple GP runs, each run generates a model that focuses on a particular high-level feature of the training images. Then, it combines the models generated by each run into a function that reconstructs the observed images. As a sanity check, we evaluated GPFL on the popular MNIST dataset of handwritten digits, and compared it with the convolutional neural network LeNet5. Our evaluation results show that when considering smaller training sets, GPFL achieves comparable/slightly-better classification accuracy than LeNet5. However, GPFL drastically outperforms LeNet5 when considering noisy images as test sets.},
  archive   = {C_PPSN},
  author    = {Ruberto, Stefano and Terragni, Valerio and Moore, Jason H.},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58115-2_5},
  pages     = {63-78},
  title     = {Image feature learning with genetic programming},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cooperative co-evolutionary genetic programming for high
dimensional problems. <em>PPSN</em>, 48‚Äì62. (<a
href="https://doi.org/10.1007/978-3-030-58115-2_4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose a framework for Cooperative Co-Evolutionary Genetic Programming (CCGP) that considers co-evolution at three different abstraction levels: genotype, feature and output level. A thorough empirical evaluation is carried out on a real-world high dimensional ML problem (image denoising). Results indicate that GP‚Äôs performance is enhanced only when cooperation happens at an output level (ensemble-alike). The proposed co-evolutionary ensemble approach is compared against a canonical GP implementation and a GP customized for image processing tasks. Preliminary results show that the proposed framework obtains superior average performance in comparison to the other GP models. Our most relevant finding is the empirical evidence showing that the proposed CCGP model is a promising alternative to specialized GP implementations that require knowledge of the problem‚Äôs domain.},
  archive   = {C_PPSN},
  author    = {Rodriguez-Coayahuitl, Lino and Morales-Reyes, Alicia and Escalante, Hugo Jair and Coello Coello, Carlos A.},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58115-2_4},
  pages     = {48-62},
  title     = {Cooperative co-evolutionary genetic programming for high dimensional problems},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Program synthesis in a continuous space using grammars and
variational autoencoders. <em>PPSN</em>, 33‚Äì47. (<a
href="https://doi.org/10.1007/978-3-030-58115-2_3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {An important but elusive goal of computer scientists is the automatic creation of computer programs given only input and output examples. We present a novel approach to program synthesis based on the combination of grammars, generative neural models, and evolutionary algorithms. Programs are described by sequences of productions sampled from a Backus-Naur form grammar. A sequence-to-sequence Variational Autoencoder (VAE) is trained to embed randomly sampled programs in a continuous space ‚Äì the VAE‚Äôs encoder maps a sequence of productions (a program) to a point z in the latent space, and the VAE‚Äôs decoder reconstructs the program given z. After the VAE has converged, we can engage the decoder as a generative model that maps locations in the latent space to executable programs. Hence, an Evolutionary Algorithm can be employed to search for a vector z (and its corresponding program) that solves the synthesis task. Experiments on the program synthesis benchmark suite suggest that the proposed approach is competitive with tree-based GP and PushGP. Crucially, code can be synthesised in any programming language.},
  archive   = {C_PPSN},
  author    = {Lynch, David and McDermott, James and O‚ÄôNeill, Michael},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58115-2_3},
  pages     = {33-47},
  title     = {Program synthesis in a continuous space using grammars and variational autoencoders},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The usability argument for refinement typed genetic
programming. <em>PPSN</em>, 18‚Äì32. (<a
href="https://doi.org/10.1007/978-3-030-58115-2_2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The performance of Evolutionary Algorithms is frequently hindered by arbitrarily large search spaces. In order to overcome this challenge, domain-specific knowledge is often used to restrict the representation or evaluation of candidate solutions to the problem at hand. Due to the diversity of problems and the unpredictable performance impact, the encoding of domain-specific knowledge is a frequent problem in the implementation of evolutionary algorithms. We propose the use of Refinement Typed Genetic Programming, an enhanced hybrid of Strongly Typed Genetic Programming (STGP) and Grammar-Guided Genetic Programming (GGGP) that features an advanced type system with polymorphism and dependent and refined types. We argue that this approach is more usable for describing common problems in machine learning, optimisation and program synthesis, due to the familiarity of the language (when compared to GGGP) and the use of a unifying language to express the representation, the phenotype translation, the evaluation function and the context in which programs are executed.},
  archive   = {C_PPSN},
  author    = {Fonseca, Alcides and Santos, Paulo and Silva, Sara},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58115-2_2},
  pages     = {18-32},
  title     = {The usability argument for refinement typed genetic programming},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Generation of new scalarizing functions using genetic
programming. <em>PPSN</em>, 3‚Äì17. (<a
href="https://doi.org/10.1007/978-3-030-58115-2_1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In recent years, there has been a growing interest in multiobjective evolutionary algorithms (MOEAs) with a selection mechanism different from Pareto dominance. This interest has been mainly motivated by the poor performance of Pareto-based selection mechanisms when dealing with problems having more than three objectives (the so-called many-objective optimization problems). Two viable alternatives for solving many-objective optimization problems are decomposition-based and indicator-based MOEAs. However, it is well-known that the performance of decomposition-based MOEAs (and also of indicator-based MOEAs designed around R2) heavily relies on the scalarizing function adopted. In this paper, we propose an approach for generating novel scalarizing functions using genetic programming. Using our proposed approach, we were able to generate two new scalarizing functions (called AGSF1 and AGSF2), which were validated using an indicator-based MOEA designed around R2 (MOMBI-II). This validation was conducted using a set of standard test problems and two performance indicators (hypervolume and s-energy). Our results indicate that AGSF1 has a similar performance to that obtained when using the well-known Achievement Scalarizing Function (ASF). However, AGSF2 provided a better performance than ASF in most of the test problems adopted. Nevertheless, our most remarkable finding is that genetic programming can indeed generate novel (and possible more competitive) scalarizing functions.},
  archive   = {C_PPSN},
  author    = {Bernab√© Rodr√≠guez, Am√≠n V. and Coello Coello, Carlos A.},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58115-2_1},
  pages     = {3-17},
  title     = {Generation of new scalarizing functions using genetic programming},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adaptive stochastic natural gradient method for optimizing
functions with low effective dimensionality. <em>PPSN</em>, 719‚Äì731. (<a
href="https://doi.org/10.1007/978-3-030-58112-1_50">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Black-box optimization algorithms, such as evolutionary algorithms, have been recognized as useful tools for real-world applications. Several efficient probabilistic model-based evolutionary algorithms, such as the compact genetic algorithm (cGA) and the covariance matrix adaptation evolution strategy (CMA-ES), can be regarded as a stochastic natural gradient ascent on statistical manifolds. Our baseline algorithm is the adaptive stochastic natural gradient (ASNG) method which automatically adapts the learning rate based on the signal-to-noise ratio (SNR) of the approximated natural gradient. ASNG has shown effectiveness in a practical application, but the convergence speed of ASNG deteriorates on objective functions with low effective dimensionality (LED), where LED means that part of the design variables is ineffective or does not affect the objective value significantly. In this paper, we propose an element-wise adjustment method for the approximated natural gradient based on the element-wise SNR and introduce the proposed adjustment method into ASNG. The proposed method suppresses the natural gradient elements with the low SNRs, helping to accelerate the learning rate adaptation in ASNG. We incorporate the proposed method into the cGA and demonstrate the effectiveness of the proposed method on the benchmark functions of binary optimization.},
  archive   = {C_PPSN},
  author    = {Yamaguchi, Teppei and Uchida, Kento and Shirakawa, Shinichi},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58112-1_50},
  pages     = {719-731},
  title     = {Adaptive stochastic natural gradient method for optimizing functions with low effective dimensionality},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Sparse inverse covariance learning for CMA-ES with graphical
lasso. <em>PPSN</em>, 707‚Äì718. (<a
href="https://doi.org/10.1007/978-3-030-58112-1_49">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper introduces a variant of the Covariance Matrix Adaptation Evolution Strategy (CMA-ES), denoted as gl-CMA-ES, that utilizes the Graphical Lasso regularization. Our goal is to efficiently solve partially separable optimization problems of a certain class by performing stochastic search with a search model parameterized by a sparse precision, i.e. inverse covariance matrix. We illustrate the effect of the global weight of the $$l_1$$ regularizer and investigate how Graphical Lasso with non equal weights can be combined with CMA-ES, allowing to learn the conditional dependency structure of problems with sparse Hessian matrices. For non-separable sparse problems, the proposed method with appropriately selected weights, outperforms CMA-ES and improves its scaling, while for dense problems it maintains the same performance.},
  archive   = {C_PPSN},
  author    = {Varelas, Konstantinos and Auger, Anne and Hansen, Nikolaus},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58112-1_49},
  pages     = {707-718},
  title     = {Sparse inverse covariance learning for CMA-ES with graphical lasso},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Learning step-size adaptation in CMA-ES. <em>PPSN</em>,
691‚Äì706. (<a
href="https://doi.org/10.1007/978-3-030-58112-1_48">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {An algorithm‚Äôs parameter setting often affects its ability to solve a given problem, e.g., population-size, mutation-rate or crossover-rate of an evolutionary algorithm. Furthermore, some parameters have to be adjusted dynamically, such as lowering the mutation-strength over time. While hand-crafted heuristics offer a way to fine-tune and dynamically configure these parameters, their design is tedious, time-consuming and typically involves analyzing the algorithm‚Äôs behavior on simple problems that may not be representative for those that arise in practice. In this paper, we show that formulating dynamic algorithm configuration as a reinforcement learning problem allows us to automatically learn policies that can dynamically configure the mutation step-size parameter of Covariance Matrix Adaptation Evolution Strategy (CMA-ES). We evaluate our approach on a wide range of black-box optimization problems, and show that (i) learning step-size policies has the potential to improve the performance of CMA-ES; (ii) learned step-size policies can outperform the default Cumulative Step-Size Adaptation of CMA-ES; and transferring the policies to (iii) different function classes and to (iv) higher dimensions is also possible.},
  archive   = {C_PPSN},
  author    = {Shala, Gresa and Biedenkapp, Andr√© and Awad, Noor and Adriaensen, Steven and Lindauer, Marius and Hutter, Frank},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58112-1_48},
  pages     = {691-706},
  title     = {Learning step-size adaptation in CMA-ES},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Behavior optimization in large distributed systems modeled
by cellular automata. <em>PPSN</em>, 678‚Äì690. (<a
href="https://doi.org/10.1007/978-3-030-58112-1_47">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider a distributed system modeled by the second-order Cellular Automata (CA) and interpreted as a multi-agent system, where interactions between agents are defined by a spatial Prisoner‚Äôs Dilemma game. The idea of the second-order CA is based on the concept ‚Äúadapt to the best neighbor. Each agent uses some strategy for the selection of actions used against opponents and can change it during the iterated game. An agent acts in such a way to maximize its income. We intend to study conditions of emerging collective behavior in such systems measured by the average total payoff of agents in the game or by an equivalent measure‚Äìthe total number of cooperating players. These measures are the external criterion of the game, and players acting selfishly are not aware of them. We show experimentally that collective behavior in such systems can emerge if some conditions related to the game are fulfilled. We propose to introduce an income sharing mechanism to the game, giving a possibility to share incomes locally by agents. We present the results of an experimental study showing that the sharing mechanism is a distributed optimization algorithm that significantly improves the capabilities of emerging collective behavior on a wide range of the game parameters.},
  archive   = {C_PPSN},
  author    = {Seredy≈Ñski, Franciszek and GƒÖsior, Jakub},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58112-1_47},
  pages     = {678-690},
  title     = {Behavior optimization in large distributed systems modeled by cellular automata},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Evolutionary algorithms with self-adjusting asymmetric
mutation. <em>PPSN</em>, 664‚Äì677. (<a
href="https://doi.org/10.1007/978-3-030-58112-1_46">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Evolutionary Algorithms (EAs) and other randomized search heuristics are often considered as unbiased algorithms that are invariant with respect to different transformations of the underlying search space. However, if a certain amount of domain knowledge is available the use of biased search operators in EAs becomes viable. We consider a simple (1+1) EA for binary search spaces and analyze an asymmetric mutation operator that can treat zero- and one-bits differently. This operator extends previous work by Jansen and Sudholt (ECJ 18(1), 2010) by allowing the operator asymmetry to vary according to the success rate of the algorithm. Using a self-adjusting scheme that learns an appropriate degree of asymmetry, we show improved runtime results on the class of functions OneMax $$_a$$ describing the number of matching bits with a fixed target $$a\in {0,1}^n$$ .},
  archive   = {C_PPSN},
  author    = {Rajabi, Amirhossein and Witt, Carsten},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58112-1_46},
  pages     = {664-677},
  title     = {Evolutionary algorithms with self-adjusting asymmetric mutation},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A SHADE-based algorithm for large scale global optimization.
<em>PPSN</em>, 650‚Äì663. (<a
href="https://doi.org/10.1007/978-3-030-58112-1_45">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {During the last decade, large-scale global optimization has been a very active research area not only because of its many challenges but also because of its high applicability. It is indeed crucial to develop more effective search strategies to explore large search spaces considering limited computational resources. In this paper, we propose a new hybrid algorithm called Global and Local search using Success-History Based Parameter Adaptation for Differential Evolution (GL-SHADE) which was specifically designed for large-scale global optimization. Our proposed approach uses two populations that evolve differently allowing them to complement each other during the search process. One is in charge of exploring the search space while the other is in charge of exploiting it. Our proposed method is evaluated using the CEC‚Äô2013 large-scale global optimization (LSGO) test suite with 1000 decision variables. Our experimental results show that the new proposal outperforms one of the best hybrid algorithms available in the state of the art (SHADEILS) in the majority of the test problems adopted while being competitive with respect to several other state-of-the-art algorithms when using the LSGO competition criteria adopted at CEC‚Äô2019.},
  archive   = {C_PPSN},
  author    = {Pacheco-Del-Moral, Oscar and Coello Coello, Carlos A.},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58112-1_45},
  pages     = {650-663},
  title     = {A SHADE-based algorithm for large scale global optimization},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Evolved gossip contracts - a framework for designing
multi-agent systems. <em>PPSN</em>, 637‚Äì649. (<a
href="https://doi.org/10.1007/978-3-030-58112-1_44">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-agent systems are systems of autonomous interacting agents acting in an environment to achieve a common goal. One of the most interesting aspects of multi-agent systems is when they exhibit emergence; where the whole is considered greater than the sum of the parts. Designing multi-agents systems is challenging, and doing this in an automated way has been described as ‚Äúone of the holy grails of artificial intelligence and agent-based modelling‚Äù. In previous research, we presented a novel decentralised cooperation protocol called Gossip Contracts (GC), which is inspired by Contract Net and Gossip Protocol. Here we present Evolved Gossip Contracts (EGC), a new framework which builds on GC and uses evolutionary computing to tailor GC to address a specific problem. We evaluate the EGC framework and the experimental results indicate that it is a promising approach for the automated design of decentralised strategies.},
  archive   = {C_PPSN},
  author    = {Mc Donnell, Nicola and Howley, Enda and Duggan, Jim},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58112-1_44},
  pages     = {637-649},
  title     = {Evolved gossip contracts - a framework for designing multi-agent systems},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Neuromemetic evolutionary optimization. <em>PPSN</em>,
623‚Äì636. (<a
href="https://doi.org/10.1007/978-3-030-58112-1_43">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Discrete and combinatorial optimization can be notoriously difficult due to complex and rugged characteristics of the objective function. We address this challenge by mapping the search process to a continuous space using recurrent neural networks. Alongside with an evolutionary run, we learn three mappings: from the original search space to a continuous Cartesian latent space, from that latent space back to the search space, and from the latent space to the search objective. We elicit gradient from that last network and use it to perform moves in the latent space, and apply this Neuromemetic Evolutionary Optimization (NEO) to evolutionary synthesis of programs. Evaluation on a range of benchmarks suggests that NEO significantly outperforms conventional genetic programming.},
  archive   = {C_PPSN},
  author    = {Liskowski, Pawe≈Ç and Krawiec, Krzysztof and Toklu, Nihat Engin},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58112-1_43},
  pages     = {623-636},
  title     = {Neuromemetic evolutionary optimization},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Large population sizes and crossover help in dynamic
environments. <em>PPSN</em>, 610‚Äì622. (<a
href="https://doi.org/10.1007/978-3-030-58112-1_42">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Dynamic linear functions on the boolean hypercube are functions which assign to each bit a positive weight, but the weights change over time. Throughout optimization, these functions maintain the same global optimum, and never have defecting local optima. Nevertheless, it was recently shown [Lengler, Schaller, FOCI 2019] that the $$(1+1)$$ -Evolutionary Algorithm needs exponential time to find or approximate the optimum for some algorithm configurations. In this experimental paper, we study the effect of larger population sizes for Dynamic BinVal, the extremal form of dynamic linear functions. We find that moderately increased population sizes extend the range of efficient algorithm configurations, and that crossover boosts this positive effect substantially. Remarkably, similar to the static setting of monotone functions in [Lengler, Zou, FOGA 2019], the hardest region of optimization for $$(\mu +1)$$ -EA is not close the optimum, but far away from it. In contrast, for the $$(\mu +1)$$ -GA, the region around the optimum is the hardest region in all studied cases (Extended Abstract. A full version is available on arxiv at [11]).},
  archive   = {C_PPSN},
  author    = {Lengler, Johannes and Meier, Jonas},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58112-1_42},
  pages     = {610-622},
  title     = {Large population sizes and crossover help in dynamic environments},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The hessian estimation evolution strategy. <em>PPSN</em>,
597‚Äì609. (<a
href="https://doi.org/10.1007/978-3-030-58112-1_41">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present a novel black box optimization algorithm called Hessian Estimation Evolution Strategy. The algorithm updates the covariance matrix of its sampling distribution by directly estimating the curvature of the objective function. This algorithm design is targeted at twice continuously differentiable problems. For this, we extend the cumulative step-size adaptation algorithm of the CMA-ES to mirrored sampling. We demonstrate that our approach to covariance matrix adaptation is efficient by evaluating it on the BBOB/COCO testbed. We also show that the algorithm is surprisingly robust when its core assumption of a twice continuously differentiable objective function is violated. The approach yields a new evolution strategy with competitive performance, and at the same time it also offers an interesting alternative to the usual covariance matrix update mechanism.},
  archive   = {C_PPSN},
  author    = {Glasmachers, Tobias and Krause, Oswin},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58112-1_41},
  pages     = {597-609},
  title     = {The hessian estimation evolution strategy},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improving sampling in evolution strategies through
mixture-based distributions built from past problem instances.
<em>PPSN</em>, 583‚Äì596. (<a
href="https://doi.org/10.1007/978-3-030-58112-1_40">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The notion of learning from different problem instances, although an old and known one, has in recent years regained popularity within the optimization community. Notable endeavors have been drawing inspiration from machine learning methods as a means for algorithm selection and solution transfer. However, surprisingly approaches which are centered around internal sampling models have not been revisited. Even though notable algorithms have been established in the last decades. In this work, we progress along this direction by investigating a method that allows us to learn an evolutionary search strategy reflecting rough characteristics of a fitness landscape. This latter model of a search strategy is represented through a flexible mixture-based distribution, which can subsequently be transferred and adapted for similar problems of interest. We validate this approach in two series of experiments in which we first demonstrate the efficacy of the recovered distributions and subsequently investigate the transfer with a systematic from the literature to generate benchmarking scenarios.},
  archive   = {C_PPSN},
  author    = {Friess, Stephen and Ti≈ào, Peter and Menzel, Stefan and Sendhoff, Bernhard and Yao, Xin},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58112-1_40},
  pages     = {583-596},
  title     = {Improving sampling in evolution strategies through mixture-based distributions built from past problem instances},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Canonical correlation discriminative learning for domain
adaptation. <em>PPSN</em>, 567‚Äì580. (<a
href="https://doi.org/10.1007/978-3-030-58112-1_39">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Domain adaptation aims to diminish the discrepancy between the source and target domains and enhance the classification ability for the target samples by using well-labeled source domain data. However, most existing methods concentrate on learning domain invariant features for cross-domain tasks, but ignore the correlation and discriminative information between different domains. If the learned features from the source and target domains are not correlated, the adaptability of domain adaptation methods will be greatly degraded. To make up for this deficiency, we propose a novel domain adaptation approach, referred to as Canonical Correlation Discriminative Learning (CCDL) for domain adaptation. By introducing a novel correlation representation, CCDL maximizes the correlations of the learned features from the two domains as much as possible. Specifically, CCDL learns a latent feature representation to reduce the difference by jointly adapting the marginal and conditional distributions between the source and target domains, and simultaneously maximizes the inter-class distance and minimizes the intra-class scatter. The experiments certify that CCDL is superior to several state-of-the-art methods on four visual benchmark databases.},
  archive   = {C_PPSN},
  author    = {Wang, Wenjing and Lu, Yuwu and Lai, Zhihui},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58112-1_39},
  pages     = {567-580},
  title     = {Canonical correlation discriminative learning for domain adaptation},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Analyzing the components of distributed coevolutionary GAN
training. <em>PPSN</em>, 552‚Äì566. (<a
href="https://doi.org/10.1007/978-3-030-58112-1_38">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Distributed coevolutionary Generative Adversarial Network (GAN) training has empirically shown success in overcoming GAN training pathologies. This is mainly due to diversity maintenance in the populations of generators and discriminators during the training process. The method studied here coevolves sub-populations on each cell of a spatial grid organized into overlapping Moore neighborhoods. We investigate the impact on performance of two algorithm components that influence the diversity during coevolution: the performance-based selection/replacement inside each sub-population and the communication through migration of solutions (networks) among overlapping neighborhoods. In experiments on MNIST dataset, we find that the combination of these two components provides the best generative models. In addition, migrating solutions without applying selection in the sub-populations achieves competitive results, while selection without communication between cells reduces performance.},
  archive   = {C_PPSN},
  author    = {Toutouh, Jamal and Hemberg, Erik and O‚ÄôReilly, Una-May},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58112-1_38},
  pages     = {552-566},
  title     = {Analyzing the components of distributed coevolutionary GAN training},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Nash equilibrium as a solution in supervised classification.
<em>PPSN</em>, 539‚Äì551. (<a
href="https://doi.org/10.1007/978-3-030-58112-1_37">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The supervised classification problem offers numerous challenges to algorithm designers, most of them stemming from the size and type of the data. While dealing with large data-sets has been the focus of many studies, the task of uncovering subtle relationships within data remains an important challenge, for which new solutions concepts have to be explored. In this paper, we propose a general framework for the supervised classification problem based on game theory and the Nash equilibrium concept. The framework is used to estimate parameters of probabilistic classification models to approximate the equilibrium of a game as the optimum of a function. CMA-ES is adapted to compute such model parameters; a noise mechanism is used to enhance the diversity of the search. To illustrate the approach we use Probit regression; numerical experiments indicate that the game-theoretic approach may provide a better insight into data than other models.},
  archive   = {C_PPSN},
  author    = {Suciu, Mihai-Alexandru and Lung, Rodica Ioana},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58112-1_37},
  pages     = {539-551},
  title     = {Nash equilibrium as a solution in supervised classification},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). BACS: A thorough study of using behavioral sequences in
ACS2. <em>PPSN</em>, 524‚Äì538. (<a
href="https://doi.org/10.1007/978-3-030-58112-1_36">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This papers introduces BACS, a learning classifier system that integrates Behavioral Sequences to ACS2 (Anticipatory Classifier System 2), in order to address the Perceptual Aliasing Issue: this issue occurs when systems can not differentiate situations that are truly distinct in partially observable environments. In order to permit this integration, BACS implements (1) an aliased-state detection algorithm allowing the system to build behavioral classifiers and (2) an evolved Anticipatory Learning Process. A study of the capabilities of BACS is presented through a thorough benchmarking on 23 mazes. The obtained results show that Behavioral Sequences are a suitable approach to address the perceptual aliasing issue.},
  archive   = {C_PPSN},
  author    = {Orhand, Romain and Jeannin-Girardon, Anne and Parrend, Pierre and Collet, Pierre},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58112-1_36},
  pages     = {524-538},
  title     = {BACS: A thorough study of using behavioral sequences in ACS2},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improving imbalanced classification by anomaly detection.
<em>PPSN</em>, 512‚Äì523. (<a
href="https://doi.org/10.1007/978-3-030-58112-1_35">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Although the anomaly detection problem can be considered as an extreme case of class imbalance problem, very few studies consider improving class imbalance classification with anomaly detection ideas. Most data-level approaches in the imbalanced learning domain aim to introduce more information to the original dataset by generating synthetic samples. However, in this paper, we gain additional information in another way, by introducing additional attributes. We propose to introduce the outlier score and four types of samples (safe, borderline, rare, outlier) as additional attributes in order to gain more information on the data characteristics and improve the classification performance. According to our experimental results, introducing additional attributes can improve the imbalanced classification performance in most cases (6 out of 7 datasets). Further study shows that this performance improvement is mainly contributed by a more accurate classification in the overlapping region of the two classes (majority and minority classes). The proposed idea of introducing additional attributes is simple to implement and can be combined with resampling techniques and other algorithmic-level approaches in the imbalanced learning domain.},
  archive   = {C_PPSN},
  author    = {Kong, Jiawen and Kowalczyk, Wojtek and Menzel, Stefan and B√§ck, Thomas},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58112-1_35},
  pages     = {512-523},
  title     = {Improving imbalanced classification by anomaly detection},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A committee of convolutional neural networks for image
classification in the concurrent presence of feature and label noise.
<em>PPSN</em>, 498‚Äì511. (<a
href="https://doi.org/10.1007/978-3-030-58112-1_34">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Image classification has become a ubiquitous task. Models trained on good quality data achieve accuracy which in some application domains is already above human-level performance. Unfortunately, real-world data are quite often degenerated by noise existing in features and/or labels. There are numerous papers that handle the problem of either feature or label noise separately. However, to the best of our knowledge, this piece of research is the first attempt to address the problem of concurrent occurrence of both types of noise. Basing on the MNIST, CIFAR-10 and CIFAR-100 datasets, we experimentally prove that the difference by which committees beat single models increases along with noise level, no matter whether it is an attribute or label disruption. Thus, it makes ensembles legitimate to be applied to noisy images with noisy labels. The aforementioned committees‚Äô advantage over single models is positively correlated with dataset difficulty level as well. We propose three committee selection algorithms that outperform a strong baseline algorithm which relies on an ensemble of individual (nonassociated) best models.},
  archive   = {C_PPSN},
  author    = {Ka≈∫mierczak, Stanis≈Çaw and Ma≈Ñdziuk, Jacek},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58112-1_34},
  pages     = {498-511},
  title     = {A committee of convolutional neural networks for image classification in the concurrent presence of feature and label noise},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Network representation learning based on topological
structure and vertex attributes. <em>PPSN</em>, 484‚Äì497. (<a
href="https://doi.org/10.1007/978-3-030-58112-1_33">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Network Representation Learning (NRL) is an essential task in the field of network data analysis, which tries to learn the distributed representation of each vertex in the network for downstream vector-based data mining tasks. NRL is helpful in solving the computationally expensive or intractable problems of large-scale network analysis. Most related NRL methods only focus on encoding the network topology information into vertex representation. However, vertices may contain rich attributes that directly impact the network formation and measure the attribute-level similarity between vertices. Additionally, encoding the vertex attributes information into the representation vector may improve the performance of the representation. This paper proposes a general NRL framework TAFNE that can effectively retain both network topology and vertex attributes information. For complex types of vertex attributes, we design two different information fusion methods that take both training efficiency and generality into account. The proposed TAFNE framework is extensively evaluated through various data analysis tasks, including clustering, visualization and node classification, and achieves superior performance compared with baseline methods.},
  archive   = {C_PPSN},
  author    = {Hu, Shengxiang and Zhang, Bofeng and Lv, Ying and Chang, Furong and Zhou, Zhuocheng},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58112-1_33},
  pages     = {484-497},
  title     = {Network representation learning based on topological structure and vertex attributes},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-objective magnitude-based pruning for latency-aware
deep neural network compression. <em>PPSN</em>, 470‚Äì483. (<a
href="https://doi.org/10.1007/978-3-030-58112-1_32">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Layer-wise magnitude-based pruning is a popular method for Deep Neural Network (DNN) compression. It has the potential to reduce the latency for an inference made by a DNN by pruning connects in the network, which prompts the application of DNNs to tasks with real-time operation requirements, such as self-driving vehicles, video detection and tracking. However, previous methods mainly use the compression rate as a proxy for the latency, without explicitly accounting for latency in the training of the compressed network. This paper presents a new layer-wise magnitude-based pruning method, namely Multi-objective Magnitude-based Latency-Aware Pruning (MMLAP). MMLAP captures latency directly and incorporates a novel multi-objective evolutionary algorithm to optimize both accuracy of a DNN and its latency efficiency when designing compressed networks, i.e., when tuning hyper-parameters of LMP. Empirical studies show the competitiveness of MMLAP compared to well-established LMP methods and show the value of multi-objective optimization in yielding Pareto-optimal compressed networks in terms of accuracy and latency.},
  archive   = {C_PPSN},
  author    = {Hong, Wenjing and Yang, Peng and Wang, Yiwen and Tang, Ke},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58112-1_32},
  pages     = {470-483},
  title     = {Multi-objective magnitude-based pruning for latency-aware deep neural network compression},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-objective counterfactual explanations. <em>PPSN</em>,
448‚Äì469. (<a
href="https://doi.org/10.1007/978-3-030-58112-1_31">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Counterfactual explanations are one of the most popular methods to make predictions of black box machine learning models interpretable by providing explanations in the form of ‚Äòwhat-if scenarios‚Äô. Most current approaches optimize a collapsed, weighted sum of multiple objectives, which are naturally difficult to balance a-priori. We propose the Multi-Objective Counterfactuals (MOC) method, which translates the counterfactual search into a multi-objective optimization problem. Our approach not only returns a diverse set of counterfactuals with different trade-offs between the proposed objectives, but also maintains diversity in feature space. This enables a more detailed post-hoc analysis to facilitate better understanding and also more options for actionable user responses to change the predicted outcome. Our approach is also model-agnostic and works for numerical and categorical input features. We show the usefulness of MOC in concrete cases and compare our approach with state-of-the-art methods for counterfactual explanations.},
  archive   = {C_PPSN},
  author    = {Dandl, Susanne and Molnar, Christoph and Binder, Martin and Bischl, Bernd},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58112-1_31},
  pages     = {448-469},
  title     = {Multi-objective counterfactual explanations},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Biologically plausible learning of text representation with
spiking neural networks. <em>PPSN</em>, 433‚Äì447. (<a
href="https://doi.org/10.1007/978-3-030-58112-1_30">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This study proposes a novel biologically plausible mechanism for generating low-dimensional spike-based text representation. First, we demonstrate how to transform documents into series of spikes (spike trains) which are subsequently used as input in the training process of a spiking neural network (SNN). The network is composed of biologically plausible elements, and trained according to the unsupervised Hebbian learning rule, Spike-Timing-Dependent Plasticity (STDP). After training, the SNN can be used to generate low-dimensional spike-based text representation suitable for text/document classification. Empirical results demonstrate that the generated text representation may be effectively used in text classification leading to an accuracy of $$80.19\%$$ on the bydate version of the 20 newsgroups data set, which is a leading result amongst approaches that rely on low-dimensional text representations.},
  archive   = {C_PPSN},
  author    = {Bia≈Ças, Marcin and Miro≈Ñczuk, Marcin Micha≈Ç and Ma≈Ñdziuk, Jacek},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58112-1_30},
  pages     = {433-447},
  title     = {Biologically plausible learning of text representation with spiking neural networks},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Parameter-less population pyramid for permutation-based
problems. <em>PPSN</em>, 418‚Äì430. (<a
href="https://doi.org/10.1007/978-3-030-58112-1_29">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Linkage learning is frequently employed in state-of-the-art methods dedicated to discrete optimization domains. Information about linkage identifies a subgroup of genes that are found dependent on each other. If such information is precise and properly used, it may significantly improve a method‚Äôs effectiveness. The recent research shows that to solve problems with so-called overlapping blocks, it is not enough to use linkage of high quality ‚Äì it is also necessary to use many different linkages that are diverse. Taking into account that the overlapping nature of problem structure is typical for practical problems, it is important to propose methods that are capable of gathering many different linkages (preferably of high quality) to keep them diverse. One of such methods is a Parameter-less Population Pyramid (P3) that was shown highly effective for overlapping problems in binary domains. Since P3 does not apply to permutation optimization problems, we propose a new P3-based method to fill this gap. Our proposition, namely the Parameter-less Population Pyramid for Permutations (P4), is compared with the state-of-the-art methods dedicated to solving permutation optimization problems: Generalized Mallows Estimation of Distribution Algorithm (GM-EDA) and Linkage Tree Gene-pool Optimal Mixing Evolutionary Algorithm (LT-GOMEA) for Permutation Spaces. As a test problem, we use the Permutation Flowshop Scheduling problem (Taillard benchmark). Statistical tests show that P4 significantly outperforms GM-EDA for almost all considered problem instances and is superior compared to LT-GOMEA for large instances of this problem.},
  archive   = {C_PPSN},
  author    = {Wozniak, Szymon and Przewozniczek, Michal W. and Komarnicki, Marcin M.},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58112-1_29},
  pages     = {418-430},
  title     = {Parameter-less population pyramid for permutation-based problems},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimising monotone chance-constrained submodular functions
using evolutionary multi-objective algorithms. <em>PPSN</em>, 404‚Äì417.
(<a href="https://doi.org/10.1007/978-3-030-58112-1_28">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Many real-world optimisation problems can be stated in terms of submodular functions. A lot of evolutionary multi-objective algorithms have recently been analyzed and applied to submodular problems with different types of constraints. We present a first runtime analysis of evolutionary multi-objective algorithms for chance-constrained submodular functions. Here, the constraint involves stochastic components and the constraint can only be violated with a small probability of $$\alpha $$ . We show that the GSEMO algorithm obtains the same worst case performance guarantees as recently analyzed greedy algorithms. Furthermore, we investigate the behavior of evolutionary multi-objective algorithms such as GSEMO and NSGA-II on different submodular chance constrained network problems. Our experimental results show that this leads to significant performance improvements compared to the greedy algorithm.},
  archive   = {C_PPSN},
  author    = {Neumann, Aneta and Neumann, Frank},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58112-1_28},
  pages     = {404-417},
  title     = {Optimising monotone chance-constrained submodular functions using evolutionary multi-objective algorithms},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Evaluation of a permutation-based evolutionary framework for
lyndon factorizations. <em>PPSN</em>, 390‚Äì403. (<a
href="https://doi.org/10.1007/978-3-030-58112-1_27">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {String factorization is an important tool for partitioning data for parallel processing and other algorithmic techniques often found in the context of big data applications such as bioinformatics or compression. Duval‚Äôs well-known algorithm uniquely factors a string over an ordered alphabet into Lyndon words, i.e., patterned strings which are strictly smaller than all of their cyclic rotations. While Duval‚Äôs algorithm produces a pre-determined factorization, modern applications motivate the demand for factorizations with specific properties, e.g., those that minimize the number of factors or consist of factors with similar lengths. In this paper, we consider the problem of finding an alphabet ordering that yields a Lyndon factorization with such properties. We introduce a flexible evolutionary framework and evaluate it on biological sequence data. For the minimization case, we also propose a new problem-specific heuristic, Flexi-Duval, and a problem-specific mutation operator for Lyndon factorization. Our results show that our framework is competitive with Flexi-Duval for minimization and yields high quality and robust solutions for balancing where no problem-specific algorithm is available.},
  archive   = {C_PPSN},
  author    = {Major, Lily and Clare, Amanda and Daykin, Jacqueline W. and Mora, Benjamin and Pe√±a Gamboa, Leonel Jose and Zarges, Christine},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58112-1_27},
  pages     = {390-403},
  title     = {Evaluation of a permutation-based evolutionary framework for lyndon factorizations},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). PbO-CCSAT: Boosting local search for satisfiability using
programming by optimisation. <em>PPSN</em>, 373‚Äì389. (<a
href="https://doi.org/10.1007/978-3-030-58112-1_26">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Propositional satisfiability (SAT) is a prominent problem in artificial intelligence with many important applications. Stochastic local search (SLS) is a well-known approach for solving SAT and known to achieve excellent performance on randomly generated, satisfiable instances. However, SLS solvers for SAT are usually ineffective in solving application instances. Here, we propose a highly configurable SLS solver dubbed PbO-CCSAT, which leverages a powerful technique known as configuration checking (CC) in combination with the automatic algorithm design paradigm of programming by optimisation (PbO). Our PbO-CCSAT solver exposes a large number of design choices, which are automatically configured to optimise the performance for specific classes of SAT instances. We present extensive empirical results showing that our PbO-CCSAT solver significantly outperforms state-of-the-art SLS solvers on SAT instances from many applications, and further show that PbO-CCSAT is complementary to state-of-the-art complete solvers.},
  archive   = {C_PPSN},
  author    = {Luo, Chuan and Hoos, Holger and Cai, Shaowei},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58112-1_26},
  pages     = {373-389},
  title     = {PbO-CCSAT: Boosting local search for satisfiability using programming by optimisation},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Decentralized combinatorial optimization. <em>PPSN</em>,
360‚Äì372. (<a
href="https://doi.org/10.1007/978-3-030-58112-1_25">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Combinatorial optimization is a widely-studied class of computational problems with many theoretical and real-world applications. Optimization problems are typically tackled using hardware and software controlled by the user. Optimization can be competitive where problems are solved by competing agents in isolation, or by groups sharing hardware and software in a distributed manner. Blockchain technology enables decentralized applications (DApps). Optimization as a DApp would be run in a trustless manner where participation in the system is voluntary and problem-solving is incentivized with bitcoin, ether, or other fungible tokens. Using a purpose-built blockchain introduces the problem of bootstrapping robust immutability and token value. This is solved by building a DApp as a smart-contract on top of an existing Turing-complete blockchain platform such as Ethereum. We propose a means of using Ethereum Virtual Machine smart contracts to automate the payout of cryptocurrency rewards for market-based voluntary participation in the solution of combinatorial optimization problems without trusted intermediaries. We suggest use of this method for optimization-as-a-service, automation of contests, and long-term recording of best-known solutions.},
  archive   = {C_PPSN},
  author    = {Christie, Lee A.},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58112-1_25},
  pages     = {360-372},
  title     = {Decentralized combinatorial optimization},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimising tours for the weighted traveling salesperson
problem and the traveling thief problem: A structural comparison of
solutions. <em>PPSN</em>, 346‚Äì359. (<a
href="https://doi.org/10.1007/978-3-030-58112-1_24">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Traveling Salesperson Problem (TSP) is one of the best-known combinatorial optimisation problems. However, many real-world problems are composed of several interacting components. The Traveling Thief Problem (TTP) addresses such interactions by combining two combinatorial optimisation problems, namely the TSP and the Knapsack Problem (KP). Recently, a new problem called the node weight dependent Traveling Salesperson Problem (W-TSP) has been introduced where nodes have weights that influence the cost of the tour. In this paper, we compare W-TSP and TTP. We investigate the structure of the optimised tours for W-TSP and TTP and the impact of using each others fitness function. Our experimental results suggest (1) that the W-TSP often can be solved better using the TTP fitness function and (2) final W-TSP and TTP solutions show different distributions when compared with optimal TSP or weighted greedy solutions.},
  archive   = {C_PPSN},
  author    = {Bossek, Jakob and Neumann, Aneta and Neumann, Frank},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58112-1_24},
  pages     = {346-359},
  title     = {Optimising tours for the weighted traveling salesperson problem and the traveling thief problem: A structural comparison of solutions},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Solution repair by inequality network propagation in
LocalSolver. <em>PPSN</em>, 332‚Äì345. (<a
href="https://doi.org/10.1007/978-3-030-58112-1_23">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper focuses on optimization problems whose constraints comprise a network of binary and ternary linear inequalities. These constraints are often encountered in the fields of scheduling, packing, layout, and mining. Alone, small-neighborhood local search algorithms encounter difficulties on these problems. Indeed, moving from a good solution to another requires small changes on many variables, due to the tight satisfaction of the constraints. The solution we implemented in LocalSolver is a kind of constraint propagation: when the solution obtained after a local transformation is infeasible, we gradually repair it, one constraint at a time. In order to extend the local transformation rather than cancel it, we impose never to go back on the decision to increase or decrease the value of a variable. We show that the success of this repair procedure is guaranteed for a large class of constraints. We apply this method to several scheduling problems, characterized by precedences and disjunctive resource constraints. We give numerical results on the Job Shop, Open Shop and Unit Commitment Problems, and show that our repair algorithm dramatically improves the performance of our local search algorithms.},
  archive   = {C_PPSN},
  author    = {Blaise, L√©a and Artigues, Christian and Benoist, Thierry},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58112-1_23},
  pages     = {332-345},
  title     = {Solution repair by inequality network propagation in LocalSolver},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A permutational boltzmann machine with parallel tempering
for solving combinatorial optimization problems. <em>PPSN</em>, 317‚Äì331.
(<a href="https://doi.org/10.1007/978-3-030-58112-1_22">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Boltzmann Machines are recurrent neural networks that have been used extensively in combinatorial optimization due to their simplicity and ease of parallelization. This paper introduces the Permutational Boltzmann Machine, a neural network capable of solving permutation optimization problems. We implement this network in combination with a Parallel Tempering algorithm with varying degrees of parallelism ranging from a single-thread variant to a multi-threaded system using a 64-core CPU with SIMD instructions. We benchmark the performance of this new system on Quadratic Assignment Problems, using some of the most difficult known instances, and show that our parallel system performs in excess of 100 $$\times $$ faster than any known dedicated solver, including those implemented on CPU clusters, GPUs, and FPGAs.},
  archive   = {C_PPSN},
  author    = {Bagherbeik, Mohammad and Ashtari, Parastoo and Mousavi, Seyed Farzad and Kanda, Kouichi and Tamura, Hirotaka and Sheikholeslami, Ali},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58112-1_22},
  pages     = {317-331},
  title     = {A permutational boltzmann machine with parallel tempering for solving combinatorial optimization problems},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the design of a partition crossover for the quadratic
assignment problem. <em>PPSN</em>, 303‚Äì316. (<a
href="https://doi.org/10.1007/978-3-030-58112-1_21">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We conduct a study on the design of a partition crossover for the QAP. On the basis of a bipartite graph representation, we propose to recombine the unshared components from parents, while enabling their fast evaluation using a preprocessing step for objective function decomposition. Besides a formal description and complexity analysis of the proposed crossover, we conduct an empirical analysis on its relative behavior using a number of large-size QAP instances, and a number of baseline crossovers. The proposed operator is shown to have a relatively high intensification ability, while keeping execution time relatively low.},
  archive   = {C_PPSN},
  author    = {Abdelkafi, Omar and Derbel, Bilel and Liefooghe, Arnaud and Whitley, Darrell},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58112-1_21},
  pages     = {303-316},
  title     = {On the design of a partition crossover for the quadratic assignment problem},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Comparative run-time performance of evolutionary algorithms
on multi-objective interpolated continuous optimisation problems.
<em>PPSN</em>, 287‚Äì300. (<a
href="https://doi.org/10.1007/978-3-030-58112-1_20">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose a new class of multi-objective benchmark problems on which we analyse the performance of four well established multi-objective evolutionary algorithms (MOEAs) ‚Äì each implementing a different search paradigm ‚Äì by comparing run-time convergence behaviour over a set of 1200 problem instances. The new benchmarks are created by fusing previously proposed single-objective interpolated continuous optimisation problems (ICOPs) via a common set of Pareto non-dominated seeds. They thus inherit the ICOP property of having tunable fitness landscape features. The benchmarks are of intrinsic interest as they derive from interpolation methods and so can approximate general problem instances. This property is revealed to be of particular importance as our extensive set of numerical experiments indicates that choices pertaining to (i) the weighting of the inverse distance interpolation function and (ii) the problem dimension can be used to construct problems that are challenging to all tested multi-objective search paradigms. This in turn means that the new multi-objective ICOPs problems (MO-ICOPs) can be used to construct well-balanced benchmark sets that discriminate well between the run-time convergence behaviour of different solvers.},
  archive   = {C_PPSN},
  author    = {ZƒÉvoianu, Alexandru-Ciprian and Lacroix, Benjamin and McCall, John},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58112-1_20},
  pages     = {287-300},
  title     = {Comparative run-time performance of evolutionary algorithms on multi-objective interpolated continuous optimisation problems},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Continuous optimization benchmarks by simulation.
<em>PPSN</em>, 273‚Äì286. (<a
href="https://doi.org/10.1007/978-3-030-58112-1_19">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Benchmark experiments are required to test, compare, tune, and understand optimization algorithms. Ideally, benchmark problems closely reflect real-world problem behavior. Yet, real-world problems are not always readily available for benchmarking. For example, evaluation costs may be too high, or resources are unavailable (e.g., software or equipment). As a solution, data from previous evaluations can be used to train surrogate models which are then used for benchmarking. The goal is to generate test functions on which the performance of an algorithm is similar to that on the real-world objective function. However, predictions from data-driven models tend to be smoother than the ground-truth from which the training data is derived. This is especially problematic when the training data becomes sparse. The resulting benchmarks may not reflect the landscape features of the ground-truth, are too easy, and may lead to biased conclusions. To resolve this, we use simulation of Gaussian processes instead of estimation (or prediction). This retains the covariance properties estimated during model training. While previous research suggested a decomposition-based approach for a small-scale, discrete problem, we show that the spectral simulation method enables simulation for continuous optimization problems. In a set of experiments with an artificial ground-truth, we demonstrate that this yields more accurate benchmarks than simply predicting with the Gaussian process model.},
  archive   = {C_PPSN},
  author    = {Zaefferer, Martin and Rehbach, Frederik},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58112-1_19},
  pages     = {273-286},
  title     = {Continuous optimization benchmarks by simulation},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Revisiting population models in differential evolution on a
limited budget of evaluations. <em>PPSN</em>, 257‚Äì272. (<a
href="https://doi.org/10.1007/978-3-030-58112-1_18">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {No previous study has reported that differential evolution (DE) is competitive with state-of-the-art black-box optimizers on a limited budget of evaluations (i.e., the expensive optimization scenario). This is true even for surrogate-assisted DEs. The basic framework of DE should be reconsidered to improve its performance substantially. In this context, this paper revisits population models in DE on a limited budget of evaluations. This paper analyzes the performance of DE with five population models on the BBOB function set. Results demonstrate that the traditional synchronous model is unsuitable for DE in most cases. In contrast, the performance of DE can be significantly improved by using the plus-selection model and the worst improvement model. Results also demonstrate that DE with a suitable population model is competitive with covariance matrix adaptation evolution strategy depending on the number of evaluations and the dimensionality of a problem.},
  archive   = {C_PPSN},
  author    = {Tanabe, Ryoji},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58112-1_18},
  pages     = {257-272},
  title     = {Revisiting population models in differential evolution on a limited budget of evaluations},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Parallelized bayesian optimization for expensive robot
controller evolution. <em>PPSN</em>, 243‚Äì256. (<a
href="https://doi.org/10.1007/978-3-030-58112-1_17">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {An important class of black-box optimization problems relies on using simulations to assess the quality of a given candidate solution. Solving such problems can be computationally expensive because each simulation is very time-consuming. We present an approach to mitigate this problem by distinguishing two factors of computational cost: the number of trials and the time needed to execute the trials. Our approach tries to keep down the number of trials by using Bayesian optimization (BO) ‚Äìknown to be sample efficient‚Äì and reducing wall-clock times by parallel execution of trials. We compare the performance of four parallelization methods and two model-free alternatives. Each method is evaluated on all 24 objective functions of the Black-Box-Optimization-Benchmarking (BBOB) test suite in their five, ten, and 20-dimensional versions. Additionally, their performance is investigated on six test cases in robot learning. The results show that parallelized BO outperforms the state-of-the-art CMA-ES on the BBOB test functions, especially for higher dimensions. On the robot learning tasks, the differences are less clear, but the data do support parallelized BO as the ‚Äòbest guess‚Äô, winning on some cases and never losing.},
  archive   = {C_PPSN},
  author    = {Rebolledo, Margarita and Rehbach, Frederik and Eiben, A. E. and Bartz-Beielstein, Thomas},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58112-1_17},
  pages     = {243-256},
  title     = {Parallelized bayesian optimization for expensive robot controller evolution},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Can compact optimisation algorithms be structurally biased?
<em>PPSN</em>, 229‚Äì242. (<a
href="https://doi.org/10.1007/978-3-030-58112-1_16">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the field of stochastic optimisation, the so-called structural bias constitutes an undesired behaviour of an algorithm that is unable to explore the search space to a uniform extent. In this paper, we investigate whether algorithms from a subclass of estimation of distribution algorithms, the compact algorithms, exhibit structural bias. Our approach, justified in our earlier publications, is based on conducting experiments on a test function whose values are uniformly distributed in its domain. For the experiment, 81 combinations of compact algorithms and strategies of dealing with infeasible solutions have been selected as test cases. We have applied two approaches for determining the presence and severity of structural bias, namely an (existing) visual and an (updated) statistical (Anderson-Darling) test. Our results suggest that compact algorithms are more immune to structural bias than their counterparts maintaining explicit populations. Both tests indicate that strong structural bias is found only in the cBFO algorithm, regardless of the choice of strategy of dealing with infeasible solutions, and cPSO with mirror strategy. For other test cases, statistical and visual tests disagree on some cases classified as having mild or strong structural bias: the former one tends to make harsher decisions, thus needing further investigation.},
  archive   = {C_PPSN},
  author    = {Kononova, Anna V. and Caraffini, Fabio and Wang, Hao and B√§ck, Thomas},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58112-1_16},
  pages     = {229-242},
  title     = {Can compact optimisation algorithms be structurally biased?},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Approximate hypervolume calculation with guaranteed or
confidence bounds. <em>PPSN</em>, 215‚Äì228. (<a
href="https://doi.org/10.1007/978-3-030-58112-1_15">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present a new version of the Quick Hypervolume algorithm allowing calculation of guaranteed lower and upper bounds for the value of hypervolume, which is one of the most often used and recommended quality indicators in multiobjective optimization. To ensure fast convergence of these bounds, we use a priority queue of subproblems instead of the depth-first search applied in the original recursive Quick Hypervolume algorithm. We also combine this new algorithm with the Monte Carlo sampling approach, which allows obtaining better confidence intervals than the standard Monte Carlo sampling. The performance of the two proposed methods is compared with that of a straightforward adaptation of recursive Quick Hypervolume algorithm and the standard Monte Carlo sampling in a comprehensive computational experiment.},
  archive   = {C_PPSN},
  author    = {Jaszkiewicz, A. and Susmaga, R. and Zielniewicz, P.},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58112-1_15},
  pages     = {215-228},
  title     = {Approximate hypervolume calculation with guaranteed or confidence bounds},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Proposal of a realistic many-objective test suite.
<em>PPSN</em>, 201‚Äì214. (<a
href="https://doi.org/10.1007/978-3-030-58112-1_14">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Real-world many-objective optimization problems are not always available as easy-to-use test problems. For example, their true Pareto fronts are usually unknown, and they are not scalable with respect to the number of objectives or decision variables. Thus, the performance of existing multi-objective evolutionary algorithms is always evaluated using artificial test problems. However, there exist some differences between frequently-used many-objective test problems and real-world problems. In this paper, first we clearly point out one difference with respect to the effect of changing the value of each decision variable on the location of the objective vector in the objective space. Next, to make artificial test problems more realistic, we introduce a coefficient matrix to their problem structure. Then, we demonstrate that a different coefficient matrix leads to a different difficulty of a test problem. Finally, based on these observations, we propose a realistic many-objective test suite using various coefficient matrices.},
  archive   = {C_PPSN},
  author    = {Chen, Weiyu and Ishibuchi, Hisao and Shang, Ke},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58112-1_14},
  pages     = {201-214},
  title     = {Proposal of a realistic many-objective test suite},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Simple surrogate model assisted optimization with covariance
matrix adaptation. <em>PPSN</em>, 184‚Äì197. (<a
href="https://doi.org/10.1007/978-3-030-58112-1_13">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We aim to observe differences between surrogate model assisted covariance matrix adaptation evolution strategies applied to simple test problems. We propose a simple Gaussian process assisted strategy as a baseline. The performance of the algorithm is compared with those of several related strategies using families of parameterized, unimodal test problems. The impact of algorithm design choices on the observed differences is discussed.},
  archive   = {C_PPSN},
  author    = {Toal, Lauchlan and Arnold, Dirk V.},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58112-1_13},
  pages     = {184-197},
  title     = {Simple surrogate model assisted optimization with covariance matrix adaptation},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). High dimensional bayesian optimization assisted by principal
component analysis. <em>PPSN</em>, 169‚Äì183. (<a
href="https://doi.org/10.1007/978-3-030-58112-1_12">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Bayesian Optimization (BO) is a surrogate-assisted global optimization technique that has been successfully applied in various fields, e.g., automated machine learning and design optimization. Built upon a so-called infill-criterion and Gaussian Process regression (GPR), the BO technique suffers from a substantial computational complexity and hampered convergence rate as the dimension of the search spaces increases. Scaling up BO for high-dimensional optimization problems remains a challenging task. In this paper, we propose to tackle the scalability of BO by hybridizing it with a Principal Component Analysis (PCA), resulting in a novel PCA-assisted BO (PCA-BO) algorithm. Specifically, the PCA procedure learns a linear transformation from all the evaluated points during the run and selects dimensions in the transformed space according to the variability of evaluated points. We then construct the GPR model, and the infill-criterion in the space spanned by the selected dimensions. We assess the performance of our PCA-BO in terms of the empirical convergence rate and CPU time on multi-modal problems from the COCO benchmark framework. The experimental results show that PCA-BO can effectively reduce the CPU time incurred on high-dimensional problems, and maintains the convergence rate on problems with an adequate global structure. PCA-BO therefore provides a satisfactory trade-off between the convergence rate and computational efficiency opening new ways to benefit from the strength of BO approaches in high dimensional numerical optimization.},
  archive   = {C_PPSN},
  author    = {Raponi, Elena and Wang, Hao and Bujny, Mariusz and Boria, Simonetta and Doerr, Carola},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58112-1_12},
  pages     = {169-183},
  title     = {High dimensional bayesian optimization assisted by principal component analysis},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Variance reduction for better sampling in continuous
domains. <em>PPSN</em>, 154‚Äì168. (<a
href="https://doi.org/10.1007/978-3-030-58112-1_11">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Design of experiments, random search, initialization of population-based methods, or sampling inside an epoch of an evolutionary algorithm uses a sample drawn according to some probability distribution for approximating the location of an optimum. Recent papers have shown that the optimal search distribution, used for the sampling, might be more peaked around the center of the distribution than the prior distribution modelling our uncertainty about the location of the optimum.We confirm this statement, provide explicit values for this reshaping of the search distribution depending on the population size $$\lambda $$ and the dimension d, and validate our results experimentally.},
  archive   = {C_PPSN},
  author    = {Meunier, Laurent and Doerr, Carola and Rapin, Jeremy and Teytaud, Olivier},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58112-1_11},
  pages     = {154-168},
  title     = {Variance reduction for better sampling in continuous domains},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Designing air flow with surrogate-assisted phenotypic
niching. <em>PPSN</em>, 140‚Äì153. (<a
href="https://doi.org/10.1007/978-3-030-58112-1_10">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In complex, expensive optimization domains we often narrowly focus on finding high performing solutions, instead of expanding our understanding of the domain itself. But what if we could quickly understand the complex behaviors that can emerge in said domains instead? We introduce surrogate-assisted phenotypic niching, a quality diversity algorithm which allows to discover a large, diverse set of behaviors by using computationally expensive phenotypic features. In this work we discover the types of air flow in a 2D fluid dynamics optimization problem. A fast GPU-based fluid dynamics solver is used in conjunction with surrogate models to accurately predict fluid characteristics from the shapes that produce the air flow. We show that these features can be modeled in a data-driven way while sampling to improve performance, rather than explicitly sampling to improve feature models. Our method can reduce the need to run an infeasibly large set of simulations while still being able to design a large diversity of air flows and the shapes that cause them. Discovering diversity of behaviors helps engineers to better understand expensive domains and their solutions.},
  archive   = {C_PPSN},
  author    = {Hagg, Alexander and Wilde, Dominik and Asteroth, Alexander and B√§ck, Thomas},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58112-1_10},
  pages     = {140-153},
  title     = {Designing air flow with surrogate-assisted phenotypic niching},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A surrogate-assisted evolutionary algorithm with random
feature selection for large-scale expensive problems. <em>PPSN</em>,
125‚Äì139. (<a href="https://doi.org/10.1007/978-3-030-58112-1_9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {When optimizing large-scale problems an evolutionary algorithm typically requires a substantial number of fitness evaluations to discover a good approximation to the global optimum. This is an issue when the problem is also computationally expensive. Surrogate-assisted evolutionary algorithms have shown better performance on high-dimensional problems which are no larger than 200 dimensions. However, it is very difficult to train sufficiently accurate surrogate models for a large-scale optimization problem due to the lack of training data. In this paper, a random feature selection technique is utilized to select decision variables from the original large-scale optimization problem to form a number of sub-problems, whose dimension may differ to each other, at each generation. The population employed to optimize the original large-scale optimization problem is updated by sequentially optimizing each sub-problem assisted by a surrogate constructed for this sub-problem. A new candidate solution of the original problem is generated by replacing the decision variables of the best solution found so far with those of the sub-problem that has achieved the best approximated fitness among all sub-problems. This new solution is then evaluated using the original expensive problem and used to update the best solution. In order to evaluate the performance of the proposed method, we conduct the experiments on 15 CEC‚Äô2013 benchmark problems and compare to some state-of-the-art algorithms. The experimental results show that the proposed method is more effective than the state-of-the-art algorithms, especially on problems that are partially separable or non-separable.},
  archive   = {C_PPSN},
  author    = {Fu, Guoxia and Sun, Chaoli and Tan, Ying and Zhang, Guochen and Jin, Yaochu},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58112-1_9},
  pages     = {125-139},
  title     = {A surrogate-assisted evolutionary algorithm with random feature selection for large-scale expensive problems},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Evolving sampling strategies for one-shot optimization
tasks. <em>PPSN</em>, 111‚Äì124. (<a
href="https://doi.org/10.1007/978-3-030-58112-1_8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {One-shot optimization tasks require to determine the set of solution candidates prior to their evaluation, i.e., without possibility for adaptive sampling. We consider two variants, classic one-shot optimization (where our aim is to find at least one solution of high quality) and one-shot regression (where the goal is to fit a model that resembles the true problem as well as possible). For both tasks it seems intuitive that well-distributed samples should perform better than uniform or grid-based samples, since they show a better coverage of the decision space. In practice, quasi-random designs such as Latin Hypercube Samples and low-discrepancy point sets are indeed very commonly used designs for one-shot optimization tasks. We study in this work how well low star discrepancy correlates with performance in one-shot optimization. Our results confirm an advantage of low-discrepancy designs, but also indicate the correlation between discrepancy values and overall performance is rather weak. We then demonstrate that commonly used designs may be far from optimal. More precisely, we evolve 24 very specific designs that each achieve good performance on one of our benchmark problems. Interestingly, we find that these specifically designed samples yield surprisingly good performance across the whole benchmark set. Our results therefore give strong indication that significant performance gains over state-of-the-art one-shot sampling techniques are possible, and that evolutionary algorithms can be an efficient means to evolve these.},
  archive   = {C_PPSN},
  author    = {Bossek, Jakob and Doerr, Carola and Kerschke, Pascal and Neumann, Aneta and Neumann, Frank},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58112-1_8},
  pages     = {111-124},
  title     = {Evolving sampling strategies for one-shot optimization tasks},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Model-based algorithm configuration with default-guided
probabilistic sampling. <em>PPSN</em>, 95‚Äì110. (<a
href="https://doi.org/10.1007/978-3-030-58112-1_7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In recent years, general-purpose automated algorithm configuration procedures have enabled impressive improvements in the state of the art in solving a wide range of challenging problems from AI, operations research and other areas. To search vast combinatorial spaces of parameter settings for a given algorithm as efficiently as possible, the most successful configurators combine techniques such as racing, estimation of distribution algorithms, Bayesian optimisation and model-free stochastic search. Two of the most widely used general-purpose algorithm configurators, SMAC and irace, can be seen as combinations of Bayesian optimisation and racing, and of racing and an estimation of distribution algorithm, respectively. Here, we propose a first approach that combines all three of these techniques into one single configurator, while exploiting prior knowledge contained in expert-chosen default parameter values. We demonstrate significant performance improvements over irace and SMAC on a broad range of running time optimisation scenarios from AClib.},
  archive   = {C_PPSN},
  author    = {Anastacio, Marie and Hoos, Holger},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58112-1_7},
  pages     = {95-110},
  title     = {Model-based algorithm configuration with default-guided probabilistic sampling},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-fidelity optimization approach under prior and
posterior constraints and its application to compliance minimization.
<em>PPSN</em>, 81‚Äì94. (<a
href="https://doi.org/10.1007/978-3-030-58112-1_6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we consider a multi-fidelity optimization under two types of constraints: prior constraints and posterior constraints. The prior constraints are prerequisite to execution of the simulation that computes the objective function value and the posterior constraint violation values, and are evaluated independently from the simulation with significantly lower computational time than the simulation. We have several simulators that approximately simulate the objective and constraint violation values with different trade-offs between accuracy and computational time. We propose an approach to solve the described constrained optimization problem with as little computational time as possible by utilizing multiple simulators. Based on a covariance matrix adaptation evolution strategy, we combines three algorithmic components: prior constraint handling technique, posterior constraint handling technique, and adaptive simulator selection technique for multi-fidelity optimization. We apply the proposed approach to a compliance minimization problem and show a promising convergence behavior.},
  archive   = {C_PPSN},
  author    = {Akimoto, Youhei and Sakamoto, Naoki and Ohtani, Makoto},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58112-1_6},
  pages     = {81-94},
  title     = {Multi-fidelity optimization approach under prior and posterior constraints and its application to compliance minimization},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Automatic configuration of a multi-objective local search
for imbalanced classification. <em>PPSN</em>, 65‚Äì77. (<a
href="https://doi.org/10.1007/978-3-030-58112-1_5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {MOCA-I is a multi-objective local search algorithm, based on the Pittsburgh representation, that has been formerly designed to solve partial classification problems with imbalanced data. Recently, multi-objective automatic algorithm configuration (MO-AAC) has proven effective in boosting the performance of multi-objective local search algorithms for combinatorial optimization problems. Here, for the first time, we apply MO-ACC to multi-objective local search for rule-based classification problems. Specifically, we present the Automatic Configuration of MOCA-I (AC-MOCA-I). AC-MOCA-I uses a methodology based on k-fold cross-validation to automatically configure an extended and improved version of MOCA-I. In a series of experiments on well-known datasets from the literature, we consider 183¬†456 unique configurations for MOCA-I and demonstrate that AC-MOCA-I leads to substantial improvements in performance. Moreover, we investigate the impact of the running time allotted to AC-MOCA-I on performance and the role of specific parameters and components.},
  archive   = {C_PPSN},
  author    = {Tari, Sara and Hoos, Holger and Jacques, Julie and Kessaci, Marie-El√©onore and Jourdan, Laetitia},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58112-1_5},
  pages     = {65-77},
  title     = {Automatic configuration of a multi-objective local search for imbalanced classification},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep learning as a competitive feature-free approach for
automated algorithm selection on the traveling salesperson problem.
<em>PPSN</em>, 48‚Äì64. (<a
href="https://doi.org/10.1007/978-3-030-58112-1_4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this work we focus on the well-known Euclidean Traveling Salesperson Problem (TSP) and two highly competitive inexact heuristic TSP solvers, EAX and LKH, in the context of per-instance algorithm selection (AS). We evolve instances with $$1\,000$$ nodes where the solvers show strongly different performance profiles. These instances serve as a basis for an exploratory study on the identification of well-discriminating problem characteristics (features). Our results in a nutshell: we show that even though (1) promising features exist, (2) these are in line with previous results from the literature, and (3) models trained with these features are more accurate than models adopting sophisticated feature selection methods, the advantage is not close to the virtual best solver in terms of penalized average runtime and so is the performance gain over the single best solver. However, we show that a feature-free deep neural network based approach solely based on visual representation of the instances already matches classical AS model results and thus shows huge potential for future studies.},
  archive   = {C_PPSN},
  author    = {Seiler, Moritz and Pohl, Janina and Bossek, Jakob and Kerschke, Pascal and Trautmann, Heike},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58112-1_4},
  pages     = {48-64},
  title     = {Deep learning as a competitive feature-free approach for automated algorithm selection on the traveling salesperson problem},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dominance, indicator and decomposition based search for
multi-objective QAP: Landscape analysis and automated algorithm
selection. <em>PPSN</em>, 33‚Äì47. (<a
href="https://doi.org/10.1007/978-3-030-58112-1_3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We investigate the properties of large-scale multi-objective quadratic assignment problems (mQAP) and how they impact the performance of multi-objective evolutionary algorithms. The landscape of a diversified dataset of bi-, multi-, and many-objective mQAP instances is characterized by means of previously-identified features. These features measure complementary facets of problem difficulty based on a sample of solutions collected along random and adaptive walks over the landscape. The strengths and weaknesses of a dominance-based, an indicator-based, and a decomposition-based search algorithm are then highlighted by relating their expected approximation quality in view of landscape features. We also discriminate between algorithms by revealing the most suitable one for subsets of instances. At last, we investigate the performance of a feature-based automated algorithm selection approach. By relying on low-cost features, we show that our recommendation system performs best in more than $$90\%$$ of the considered mQAP instances.},
  archive   = {C_PPSN},
  author    = {Liefooghe, Arnaud and Verel, S√©bastien and Derbel, Bilel and Aguirre, Hernan and Tanaka, Kiyoshi},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58112-1_3},
  pages     = {33-47},
  title     = {Dominance, indicator and decomposition based search for multi-objective QAP: Landscape analysis and automated algorithm selection},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fast perturbative algorithm configurators. <em>PPSN</em>,
19‚Äì32. (<a href="https://doi.org/10.1007/978-3-030-58112-1_2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent work has shown that the ParamRLS and ParamILS algorithm configurators can tune some simple randomised search heuristics for standard benchmark functions in linear expected time in the size of the parameter space. In this paper we prove a linear lower bound on the expected time to optimise any parameter tuning problem for ParamRLS, ParamILS as well as for larger classes of algorithm configurators. We propose a harmonic mutation operator for perturbative algorithm configurators that provably tunes single-parameter algorithms in polylogarithmic time for unimodal and approximately unimodal (i.e., non-smooth, rugged with an underlying gradient towards the optimum) parameter spaces. It is suitable as a general-purpose operator since even on worst-case (e.g., deceptive) landscapes it is only by at most a logarithmic factor slower than the default ones used by ParamRLS and ParamILS. An experimental analysis confirms the superiority of the approach in practice for a number of configuration scenarios, including ones involving more than one parameter.},
  archive   = {C_PPSN},
  author    = {Hall, George T. and Oliveto, Pietro S. and Sudholt, Dirk},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58112-1_2},
  pages     = {19-32},
  title     = {Fast perturbative algorithm configurators},
  year      = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Evolving deep forest with automatic feature extraction for
image classification using genetic programming. <em>PPSN</em>, 3‚Äì18. (<a
href="https://doi.org/10.1007/978-3-030-58112-1_1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep forest is an alternative to deep neural networks to use multiple layers of random forests without back-propagation for solving various problems. In this study, we propose a genetic programming-based approach to automatically and simultaneously evolving effective structures of deep forest connections and extracting informative features for image classification. First, in the new approach we define two types of modules: forest modules and feature extraction modules. Second, an encoding strategy is developed to integrate forest modules and feature extraction modules into a tree and the search strategy is introduced to search for the best solution. With these designs, the proposed approach can automatically extract image features and find forests with effective structures simultaneously for image classification. The parameters in the forest can be dynamically determined during the learning process of the new approach. The results show that the new approach can achieve better performance on the datasets having a small number of training instances and competitive performance on the datasets having a large number of training instances. The analysis of evolved solutions shows that the proposed approach uses a smaller number of random forests over the deep forest method.},
  archive   = {C_PPSN},
  author    = {Bi, Ying and Xue, Bing and Zhang, Mengjie},
  booktitle = {International Conference on Parallel Problem Solving from Nature},
  doi       = {10.1007/978-3-030-58112-1_1},
  pages     = {3-18},
  title     = {Evolving deep forest with automatic feature extraction for image classification using genetic programming},
  year      = {2020},
}
</textarea>
</details></li>
</ul>

</body>
</html>
