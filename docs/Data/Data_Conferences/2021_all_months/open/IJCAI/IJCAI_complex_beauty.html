<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>IJCAI_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ijcai---722">IJCAI - 722</h2>
<ul>
<li><details>
<summary>
(2021). Self-adaptive swarm system (SASS). <em>IJCAI</em>,
5040–5041. (<a href="https://doi.org/10.24963/ijcai.2021/722">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Distributed artificial intelligence (DAI) studies artificial intelligence entities working together to reason, plan, solve problems, organize behaviors and strategies, make collective decisions and learn. This Ph.D. research proposes a principled Multi-Agent Systems (MAS) cooperation framework -- Self-Adaptive Swarm System (SASS) -- to bridge the fourth level automation gap between perception, communication, planning, execution, decision-making, and learning. Keywords: Agent-based and Multi-agent Systems: Agent Theories and Models Uncertainty in AI: Bayesian Networks Robotics: Multi-Robot Systems Machine Learning: Bayesian Learning},
  archive   = {C_IJCAI},
  author    = {Qin Yang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/722},
  pages     = {5040-5041},
  title     = {Self-adaptive swarm system (SASS)},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). IIAS: An intelligent insurance assessment system through
online real-time conversation analysis. <em>IJCAI</em>, 5036–5039. (<a
href="https://doi.org/10.24963/ijcai.2021/721">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With the development of Chinese medical insurance industry, the amount of claim cases is growing rapidly. Ultimately, more claims necessarily indicate that the insurance company has to spend much time assessing claims and decides how much compensation the claimant should receive, which is a highly professional process that involves many complex operations. Therefore, the insurance assessor&#39;s role is essential. However, for the junior assessor often lacking in practical experience, it is not easy to quickly handle such an online procedure. In order to alleviate assessors&#39; cognitive workload, we propose an Intelligent Insurance Assessment System (IIAS) that helps effectively collect claimant information through online real-time conversation analysis. With the assistance of IIAS, the average time cost of the insurance assessment procedure is reduced from 55 minutes to 35 minutes. Keywords: Human-Computer Interaction: General Natural Language Processing: General},
  archive   = {C_IJCAI},
  author    = {Mengdi Zhou and Shuang Peng and Minghui Yang and Nan Li and Hongbin Wang and Li Qiao and Haitao Mi and Zujie Wen and Teng Xu and Lei Liu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/721},
  pages     = {5036-5039},
  title     = {IIAS: An intelligent insurance assessment system through online real-time conversation analysis},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Communication-efficient and scalable decentralized federated
edge learning. <em>IJCAI</em>, 5032–5035. (<a
href="https://doi.org/10.24963/ijcai.2021/720">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Federated Edge Learning (FEL) is a distributed Machine Learning (ML) framework for collaborative training on edge devices. FEL improves data privacy over traditional centralized ML model training by keeping data on the devices and only sending local model updates to a central coordinator for aggregation. However, challenges still remain in existing FEL architectures where there is high communication overhead between edge devices and the coordinator. In this paper, we present a working prototype of blockchain-empowered and communication-efficient FEL framework, which enhances the security and scalability towards large-scale implementation of FEL. Keywords: Machine Learning: General},
  archive   = {C_IJCAI},
  author    = {Austine Zong Han Yapp and Hong Soo Nicholas Koh and Yan Ting Lai and Jiawen Kang and Xuandi Li and Jer Shyuan Ng and Hongchao Jiang and Wei Yang Bryan Lim and Zehui Xiong and Dusit Niyato},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/720},
  pages     = {5032-5035},
  title     = {Communication-efficient and scalable decentralized federated edge learning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). AutoBandit: A meta bandit online learning system.
<em>IJCAI</em>, 5028–5031. (<a
href="https://doi.org/10.24963/ijcai.2021/719">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently online multi-armed bandit (MAB) is growing rapidly, as novel problem settings and algorithms motivated by various practical applications are being studied, building on the top of the classic bandit problem. However, identifying the best bandit algorithm from lots of potential candidates for a given application is not only time-consuming but also relying on human expertise, which hinders the practicality of MAB. To alleviate this problem, this paper outlines an intelligent system called AutoBandit, equipped with many out-of-the-box MAB algorithms, for automatically and adaptively choosing the best with suitable hyper-parameters online. It is effective to help a growing application for continuously maximizing cumulative rewards of its whole life-cycle. With a flexible architecture and user-friendly web-based interfaces, it is very convenient for the user to integrate and monitor online bandits in a business system. At the time of publication, AutoBandit has been deployed for various industrial applications. Keywords: Machine Learning: General Recommender Systems: General},
  archive   = {C_IJCAI},
  author    = {Miao Xie and Wotao Yin and Huan Xu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/719},
  pages     = {5028-5031},
  title     = {AutoBandit: A meta bandit online learning system},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Interactive video acquisition and learning system for motor
assessment of parkinson’s disease. <em>IJCAI</em>, 5024–5027. (<a
href="https://doi.org/10.24963/ijcai.2021/718">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Diagnosis and treatment for Parkinson&#39;s disease rely on the evaluation of motor functions, which is expensive and time consuming when performing at clinics. It is also difficult for patients to record correct movements at home without the guidance from experienced physicians. To help patients with Parkinson’s disease get better evaluation from in-home recorded movement videos, we developed an interactive video acquisition and learning system for clinical motor assessments. The system provides real-time guidance with multi-level body keypoint tracking and analysis to patients, which guarantees correct understanding and performing of clinical tasks. We tested its effectiveness on healthy subjects, and the efficiency and usability on patient groups. Experiments showed that our system enabled high quality video recordings following clinical standards, benefiting both patients and physicians. Our system provides a novel learning-based telemedicine approach for the care of patients with Parkinson’s disease. Keywords: Human-Computer Interaction: General Computer Vision: General Machine Learning: General},
  archive   = {C_IJCAI},
  author    = {Yunyue Wei and Bingquan Zhu and Chen Hou and Chen Zhang and Yanan Sui},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/718},
  pages     = {5024-5027},
  title     = {Interactive video acquisition and learning system for motor assessment of parkinson&#39;s disease},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Graph-augmented code summarization in computational
notebooks. <em>IJCAI</em>, 5020–5023. (<a
href="https://doi.org/10.24963/ijcai.2021/717">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Computational notebooks allow data scientists to express their ideas through a combination of code and documentation. However, data scientists often pay attention only to the code and neglect the creation of the documentation in a notebook. In this work, we present a human-centered automation system, Themisto, that can support users to easily create documentation via three approaches: 1) We have developed and reported a GNN-augmented code documentation generation algorithm in a previous paper, which can generate documentation for a given source code; 2) Themisto also implements a query-based approach to retrieve the online API documentation as the summary for certain types of source code; 3) Lastly, Themistoalso enables a user prompt approach to motivate users to write documentation for some use cases that automation does not work well. Keywords: Natural Language Processing: General Human-Computer Interaction: General},
  archive   = {C_IJCAI},
  author    = {April Wang and Dakuo Wang and Xuye Liu and Lingfei Wu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/717},
  pages     = {5020-5023},
  title     = {Graph-augmented code summarization in computational notebooks},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Predictive analytics for COVID-19 social distancing.
<em>IJCAI</em>, 5016–5019. (<a
href="https://doi.org/10.24963/ijcai.2021/716">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The COVID-19 pandemic has disrupted the lives of millions across the globe. In Singapore, promoting safe distancing by managing crowds in public areas have been the cornerstone of containing the community spread of the virus. One of the most important solutions to maintain social distancing is to monitor the crowdedness of indoor and outdoor points of interest. Using Nanyang Technological University (NTU) as a testbed, we develop and deploy a platform that provides live and predicted crowd counts for key locations on campus to help users plan their trips in an informed manner, so as to mitigate the risk of community transmission. Keywords: Computer Vision: General Human-Computer Interaction: General Machine Learning: General},
  archive   = {C_IJCAI},
  author    = {Harold Ze Chie Teng and Hongchao Jiang and Xuan Rong Zane Ho and Wei Yang Bryan Lim and Jer Shyuan Ng and Han Yu and Zehui Xiong and Dusit Niyato and Chunyan Miao},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/716},
  pages     = {5016-5019},
  title     = {Predictive analytics for COVID-19 social distancing},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards fast and accurate multi-person pose estimation on
mobile devices. <em>IJCAI</em>, 5012–5015. (<a
href="https://doi.org/10.24963/ijcai.2021/715">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The rapid development of autonomous driving, abnormal behavior detection, and behavior recognition makes an increasing demand for multi-person pose estimation-based applications, especially on mobile platforms. However, to achieve high accuracy, state-of-the-art methods tend to have a large model size and complex post-processing algorithm, which costs intense computation and long end-to-end latency. To solve this problem, we propose an architecture optimization and weight pruning framework to accelerate inference of multi-person pose estimation on mobile devices. With our optimization framework, we achieve up to 2.51X faster model inference speed with higher accuracy compared to representative lightweight multi-person pose estimator. Keywords: Computer Vision: General Human-Computer Interaction: General Machine Learning: General},
  archive   = {C_IJCAI},
  author    = {Xuan Shen and Geng Yuan and Wei Niu and Xiaolong Ma and Jiexiong Guan and Zhengang Li and Bin Ren and Yanzhi Wang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/715},
  pages     = {5012-5015},
  title     = {Towards fast and accurate multi-person pose estimation on mobile devices},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Connect multi-agent path finding: Generation and
visualization. <em>IJCAI</em>, 5008–5011. (<a
href="https://doi.org/10.24963/ijcai.2021/714">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present a generic tool to visualize missions of the Connected Multi-Agent Path Finding (CMAPF) problem. This problem is a variant of MAPF which requires a group of agents to navigate from an initial configuration to a goal configuration while maintaining connection. The user can create an instance of CMAPF and can play the generated plan. Any algorithm for CMAPF can be plugged into the tool. Keywords: Multi-agent Systems: General Planning and Scheduling: General},
  archive   = {C_IJCAI},
  author    = {Arthur Queffelec and Ocan Sankur and Francois Schwarzentruber},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/714},
  pages     = {5008-5011},
  title     = {Connect multi-agent path finding: Generation and visualization},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). VisioRed: A visualisation tool for interpretable predictive
maintenance. <em>IJCAI</em>, 5004–5007. (<a
href="https://doi.org/10.24963/ijcai.2021/713">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The use of machine learning rapidly increases in high-risk scenarios where decisions are required, for example in healthcare or industrial monitoring equipment. In crucial situations, a model that can offer meaningful explanations of its decision-making is essential. In industrial facilities, the equipment&#39;s well-timed maintenance is vital to ensure continuous operation to prevent money loss. Using machine learning, predictive and prescriptive maintenance attempt to anticipate and prevent eventual system failures. This paper introduces a visualisation tool incorporating interpretations to display information derived from predictive maintenance models, trained on time-series data. Keywords: Machine Learning: General Human-Computer Interaction: General},
  archive   = {C_IJCAI},
  author    = {Spyridon Paraschos and Ioannis Mollas and Nick Bassiliades and Grigorios Tsoumakas},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/713},
  pages     = {5004-5007},
  title     = {VisioRed: A visualisation tool for interpretable predictive maintenance},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A compression-compilation framework for on-mobile real-time
BERT applications. <em>IJCAI</em>, 5000–5003. (<a
href="https://doi.org/10.24963/ijcai.2021/712">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Transformer-based deep learning models have increasingly demonstrated high accuracy on many natural language processing (NLP) tasks. In this paper, we propose a compression-compilation co-design framework that can guarantee the identified model meets both resource and real-time specifications of mobile devices. Our framework applies a compiler-aware neural architecture optimization method (CANAO), which can generate the optimal compressed model that balances both accuracy and latency. We are able to achieve up to 7.8x speedup compared with TensorFlow-Lite with only minor accuracy loss. We present two types of BERT applications on mobile devices: Question Answering (QA) and Text Generation. Both can be executed in real-time with latency as low as 45ms. Videos for demonstrating the framework can be found on https://www.youtube.com/watch?v=_WIRvK_2PZI Keywords: Knowledge Representation and Reasoning: General Natural Language Processing: General},
  archive   = {C_IJCAI},
  author    = {Wei Niu and Zhenglun Kong and Geng Yuan and Weiwen Jiang and Jiexiong Guan and Caiwen Ding and Pu Zhao and Sijia Liu and Bin Ren and Yanzhi Wang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/712},
  pages     = {5000-5003},
  title     = {A compression-compilation framework for on-mobile real-time BERT applications},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). InfOCF-web: An online tool for nonmonotonic reasoning with
conditionals and ranking functions. <em>IJCAI</em>, 4996–4999. (<a
href="https://doi.org/10.24963/ijcai.2021/711">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {InfOCF-Web provides implementations of system P and system Z inference, and of inference relations based on c-representation with respect to various inference modes and different classes of minimal models. It has an easy-to-use online interface for computing ranking models of a conditional knowledge R, and for answering queries and comparing inference results of nonmonotonic inference relations induced by R. Keywords: Constraint Programming: General Knowledge Representation and Reasoning: General Uncertainty in AI: General},
  archive   = {C_IJCAI},
  author    = {Steven Kutsch and Christoph Beierle},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/711},
  pages     = {4996-4999},
  title     = {InfOCF-web: An online tool for nonmonotonic reasoning with conditionals and ranking functions},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). ConvLogMiner: A real-time conversational lifelog miner.
<em>IJCAI</em>, 4992–4995. (<a
href="https://doi.org/10.24963/ijcai.2021/710">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper presents a conversational lifelog mining system, ConvLogMiner, which detects personal life events from the human online conversation in real-time. Given a daily conversation of two speakers, ConvLogMiner identifies the new life events specific to each speaker that occur in the latest utterances. The lifelogs mined by our system are useful to provide complementary information to support lifestyle analysis and memory assistance service. Keywords: Natural Language Processing: General},
  archive   = {C_IJCAI},
  author    = {Pei-Wei Kao and An-Zi Yen and Hen-Hsen Huang and Hsin-Hsi Chen},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/710},
  pages     = {4992-4995},
  title     = {ConvLogMiner: A real-time conversational lifelog miner},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). HIVE: Hierarchical information visualization for
explainability. <em>IJCAI</em>, 4988–4991. (<a
href="https://doi.org/10.24963/ijcai.2021/709">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this demonstration, we develop an interactive tool, HIVE, to demonstrate the ability and versatility of an explainable risk ranking model with a special focus on financial use cases. HIVE is a web-based tool that provides users with automated highlighted financial statements, and HIVE is designed for making comparing statements rather more efficient. Moreover, with the proposed tool, users can find related reports at ease, and we believe that HIVE can benefit both academics and practitioners in finance as they can work around deep learning models with their newly gained insights. Keywords: Natural Language Processing: General},
  archive   = {C_IJCAI},
  author    = {Yi-Ning Juan and Yi-Shyuan Chiang and Shang-Chuan Liu and Ming-Feng Tsai and Chuan-Ju Wang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/709},
  pages     = {4988-4991},
  title     = {HIVE: Hierarchical information visualization for explainability},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Skills2Graph: Processing million job ads to face the job
skill mismatch problem. <em>IJCAI</em>, 4984–4987. (<a
href="https://doi.org/10.24963/ijcai.2021/708">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we present Skills2Graph, a tool that, starting from a set of users’ professional skills, identifies the most suitable jobs as they emerge from a large corpus of 2.5M+ Online Job Vacancies (OJVs) posted in three different countries (the United Kingdom, France, and Germany). To this aim, we rely both on co-occurrence statistics - computing a count-based measure of skill-relevance named Revealed Comparative Advantage (rca) - and distributional semantics - generating several embeddings on the OJVs corpus and performing an intrinsic evaluation of their quality. Results, evaluated through a user study of 10 labor market experts, show a high P@3 for the recommendations provided by Skills2Graph, and a high nDCG (0.985 and 0.984 in a [0, 1] range), that indicates a strong correlation between the experts’ scores and the rankings generated by Skills2Graph. Keywords: Human-Computer Interaction: General Natural Language Processing: General Recommender Systems: General Machine Learning: General},
  archive   = {C_IJCAI},
  author    = {Anna Giabelli and Lorenzo Malandri and Fabio Mercorio and Mario Mezzanzanica and Andrea Seveso},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/708},
  pages     = {4984-4987},
  title     = {Skills2Graph: Processing million job ads to face the job skill mismatch problem},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Web interoperability for ontology development and support
with crowd 2.0. <em>IJCAI</em>, 4980–4983. (<a
href="https://doi.org/10.24963/ijcai.2021/707">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this work, we treat web interoperability in terms of interchanging ontologies (as knowledge models) within user-centred ontology engineering environments, involving visual and serialised representations of ontologies. To do this, we deal with the tool interoperability problem by re-using an enough expressive ontology-driven metamodel, named KF, proposed as a bridge for interchanging both knowledge models. We provide an extensible web framework, named crowd 2.0, unifying the standard conceptual data modelling languages for generating OWL 2 ontologies from semantic visualisations. Visual models are designed as UML, ER or ORM 2 diagrams, represented as KF instances, and finally, formalised as DL-based models. Reasoning results may be newly incorporated into the shared KF instance to be visualised in any of the provided languages. Keywords: Knowledge Representation and Reasoning: General},
  archive   = {C_IJCAI},
  author    = {German Braun and Giuliano Marinelli and Emiliano Rios Gavagnin and Laura Cecchi and Pablo Fillottrani},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/707},
  pages     = {4980-4983},
  title     = {Web interoperability for ontology development and support with crowd 2.0},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A neural network auction for group decision making over a
continuous space. <em>IJCAI</em>, 4976–4979. (<a
href="https://doi.org/10.24963/ijcai.2021/706">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose a system for conducting an auction over locations in a continuous space. It enables participants to express their preferences over possible choices of location in the space, selecting the location that maximizes the total utility of all agents. We prevent agents from tricking the system into selecting a location that improves their individual utility at the expense of others by using a pricing rule that gives agents no incentive to misreport their true preferences. The system queries participants for their utility in many random locations, then trains a neural network to approximate the preference function of each participant. The parameters of these neural network models are transmitted and processed by the auction mechanism, which composes these into differentiable models that are optimized through gradient ascent to compute the final chosen location and charged prices. Keywords: Machine Learning: General Multi-agent Systems: General},
  archive   = {C_IJCAI},
  author    = {Yoram Bachrach and Ian Gemp and Marta Garnelo and Janos Kramar and Tom Eccles and Dan Rosenbaum and Thore Graepel},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/706},
  pages     = {4976-4979},
  title     = {A neural network auction for group decision making over a continuous space},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards fair and transparent algorithmic systems.
<em>IJCAI</em>, 4970–4974. (<a
href="https://doi.org/10.24963/ijcai.2021/705">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {My research in the past few years has focused on fostering trust in algorithmic systems. I often analyze scenarios where a variety of desirable trust-oriented goals must be simultaneously satisfied; for example, ensuring that an allocation mechanism is both fair and efficient, or that a model explanation framework is both effective and differentially private. This interdisciplinary approach requires tools from a variety of computer science disciplines, such as game theory, economics, ML and differential privacy. Keywords: Agent-based and Multi-agent Systems: Resource Allocation Agent-based and Multi-agent Systems: Cooperative Games AI Ethics, Trust, Fairness: Explainability Agent-based and Multi-agent Systems: Computational Social Choice},
  archive   = {C_IJCAI},
  author    = {Yair Zick},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/705},
  pages     = {4970-4974},
  title     = {Towards fair and transparent algorithmic systems},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Alleviating road traffic congestion with artificial
intelligence. <em>IJCAI</em>, 4965–4969. (<a
href="https://doi.org/10.24963/ijcai.2021/704">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper reviews current AI solutions towards road traffic congestion alleviation. Three specific AI technologies are discussed, (1) intersection management protocols for coordinating vehicles through a roads intersection in a safe and efficient manner, (2) road pricing protocol that induce optimized traffic flow, and (3) partial or full autonomous driving that can stabilize traffic flow and mitigate adverse traffic shock waves. The paper briefly presents the challenges affiliated with each of these applications along with an overview of state-of-the-art solutions. Finally, real-world implementation gaps and challenges are discussed. Keywords: Multidisciplinary Topics and Applications: Transportation Multidisciplinary Topics and Applications: Computational Sustainability Machine Learning Applications: Applications of Reinforcement Learning Agent-based and Multi-agent Systems: Coordination and Cooperation},
  archive   = {C_IJCAI},
  author    = {Guni Sharon},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/704},
  pages     = {4965-4969},
  title     = {Alleviating road traffic congestion with artificial intelligence},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards a new generation of cognitive diagnosis.
<em>IJCAI</em>, 4961–4964. (<a
href="https://doi.org/10.24963/ijcai.2021/703">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Cognitive diagnosis is a type of assessment for automatically measuring individuals&#39; proficiency profiles from their observed behaviors, e.g. quantifying the mastery level of examinees on specific knowledge concepts/skills. As one of the fundamental research tasks in domains like intelligent education, a number of Cognitive Diagnosis Models (CDMs) have been developed in the past decades. Though these solutions are usually well designed based on psychometric theories, they still suffer from the limited ability of the handcrafted diagnosis functions, especially when dealing with heterogeneous data. In this paper, I will share my personal understanding of cognitive diagnosis and review our recent developments of CDMs mostly from a machine learning perspective. Meanwhile, I will show the wide applications of cognitive diagnosis. Keywords: Data Mining: Big Data, Large-Scale Systems Humans and AI: Computer-Aided Education Multidisciplinary Topics and Applications: Social Sciences Machine Learning Applications: Humanities},
  archive   = {C_IJCAI},
  author    = {Qi Liu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/703},
  pages     = {4961-4964},
  title     = {Towards a new generation of cognitive diagnosis},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Width-based algorithms for common problems in control,
planning and reinforcement learning. <em>IJCAI</em>, 4956–4960. (<a
href="https://doi.org/10.24963/ijcai.2021/702">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Width-based algorithms search for solutions through a general definition of state novelty. These algorithms have been shown to result in state-of-the-art performance in classical planning, and have been successfully applied to model-based and model-free settings where the dynamics of the problem are given through simulation engines. Width-based algorithms performance is understood theoretically through the notion of planning width, providing polynomial guarantees on their runtime and memory consumption. To facilitate synergies across research communities, this paper summarizes the area of width-based planning, and surveys current and future research directions. Keywords: Planning and Scheduling: General Planning and Scheduling: Planning Algorithms Planning and Scheduling: Theoretical Foundations of Planning Planning and Scheduling: Applications of Planning},
  archive   = {C_IJCAI},
  author    = {Nir Lipovetzky},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/702},
  pages     = {4956-4960},
  title     = {Width-based algorithms for common problems in control, planning and reinforcement learning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Safe weakly supervised learning. <em>IJCAI</em>, 4951–4955.
(<a href="https://doi.org/10.24963/ijcai.2021/701">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Weakly supervised learning (WSL) refers to learning from a large amount of weak supervision data. This includes i) incomplete supervision (e.g., semi-supervised learning); ii) inexact supervision (e.g., multi-instance learning) and iii) inaccurate supervision (e.g., label noise learning). Unlike supervised learning which typically achieves performance improvement with more labeled data, WSL may sometimes even degenerate performance with more weak supervision data. It is thus desired to study safe WSL, which could robustly improve performance with weak supervision data. In this article, we share our understanding of the problem from in-distribution data to out-of-distribution data, and discuss possible ways to alleviate it, from the aspects of worst-case analysis, ensemble-learning, and bi-level optimization. We also share some open problems, to inspire future researches. Keywords: Machine Learning: Semi-Supervised Learning Machine Learning: Weakly Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Yu-Feng Li},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/701},
  pages     = {4951-4955},
  title     = {Safe weakly supervised learning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Intelligent and learning agents: Four investigations.
<em>IJCAI</em>, 4946–4950. (<a
href="https://doi.org/10.24963/ijcai.2021/700">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {My research is driven by my curiosity about the nature of intelligence. Of the several aspects that characterise the behaviour of intelligent agents, I primarily study sequential decision making, learning, and exploration. My interests also extend to broader questions on the effects of AI on life and society. In this paper, I present four distinct investigations drawn from my recent work, which range from theoretical to applied, and which involve both analysis and design. I also share my outlook as an early-career researcher. Keywords: Planning and Scheduling: Markov Decisions Processes Machine Learning: Online Learning Planning and Scheduling: Applications of Planning AI Ethics, Trust, Fairness: Societal Impact of AI},
  archive   = {C_IJCAI},
  author    = {Shivaram Kalyanakrishnan},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/700},
  pages     = {4946-4950},
  title     = {Intelligent and learning agents: Four investigations},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive experimental design for optimizing combinatorial
structures. <em>IJCAI</em>, 4940–4945. (<a
href="https://doi.org/10.24963/ijcai.2021/699">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Scientists and engineers in diverse domains need to perform expensive experiments to optimize combinatorial spaces, where each candidate input is a discrete structure (e.g., sequence, tree, graph) or a hybrid structure (mixture of discrete and continuous design variables). For example, in hardware design optimization over locations of processing cores and communication links for data transfer, design evaluation involves performing a computationally-expensive simulation. These experiments are often performed in a heuristic manner by humans and without any formal reasoning. In this paper, we first describe the key challenges in solving these problems in the framework of Bayesian optimization (BO) and our progress over the last five years in addressing these challenges. We also discuss exciting sustainability applications in domains such as electronic design automation, nanoporous materials science, biological sequence design, and electric transportation systems. Keywords: Uncertainty in AI: Sequential Decision Making Machine Learning: Bayesian Learning Multidisciplinary Topics and Applications: AI Hardware Multidisciplinary Topics and Applications: Natural Sciences},
  archive   = {C_IJCAI},
  author    = {Janardhan Rao Doppa},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/699},
  pages     = {4940-4945},
  title     = {Adaptive experimental design for optimizing combinatorial structures},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). From computational social choice to digital democracy.
<em>IJCAI</em>, 4937–4939. (<a
href="https://doi.org/10.24963/ijcai.2021/698">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Digital Democracy (aka e-democracy or interactive democracy) aims to enhance democratic decision-making processes by utilizing digital technology. A common goal of these approaches is to make collective decision-making more engaging, inclusive, and responsive to participants&#39; opinions. For example, online decision-making platforms often provide much more flexibility and interaction possibilities than traditional democratic systems. It is without doubt that the successful design of digital democracy systems presents a multidisciplinary research challenge. I argue that tools and techniques from computational social choice should be employed to aid the design of online decision-making platforms and other digital democracy systems. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice Agent-based and Multi-agent Systems: Voting AI Ethics, Trust, Fairness: Fairness AI Ethics, Trust, Fairness: Societal Impact of AI},
  archive   = {C_IJCAI},
  author    = {Markus Brill},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/698},
  pages     = {4937-4939},
  title     = {From computational social choice to digital democracy},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Anomaly mining - past, present and future. <em>IJCAI</em>,
4932–4936. (<a href="https://doi.org/10.24963/ijcai.2021/697">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Anomaly mining is an important problem that finds numerous applications in various real world do- mains such as environmental monitoring, cybersecurity, finance, healthcare and medicine, to name a few. In this article, I focus on two areas, (1) point-cloud and (2) graph-based anomaly mining. I aim to present a broad view of each area, and discuss classes of main research problems, recent trends and future directions. I conclude with key take-aways and overarching open problems. Disclaimer. I try to provide an overview of past and recent trends in both areas within 4 pages. Undoubtedly, these are my personal view of the trends, which can be organized differently. For brevity, I omit all technical details and refer to corresponding papers. Again, due to space limit, it is not possible to include all (even most relevant) references, but a few representative examples. Keywords: Data Mining: Anomaly/Outlier Detection Data Mining: Mining Graphs, Semi Structured Data, Complex Data Machine Learning: Deep Learning Machine Learning: Unsupervised Learning},
  archive   = {C_IJCAI},
  author    = {Leman Akoglu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/697},
  pages     = {4932-4936},
  title     = {Anomaly mining - past, present and future},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An automated framework for supporting data-governance rule
compliance in decentralized MIMO contexts. <em>IJCAI</em>, 4929–4930.
(<a href="https://doi.org/10.24963/ijcai.2021/696">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose Dr.Aid, a logic-based AI framework for automated compliance checking of data governance rules over data-flow graphs. The rules are modelled using a formal language based on situation calculus and are suitable for decentralized contexts with multi-input-multi-output (MIMO) processes. Dr.Aid models data rules and flow rules and checks compliance by reasoning about the propagation, combination, modification and application of data rules over the data flow graphs. Our approach is driven and evaluated by real-world datasets using provenance graphs from data-intensive research. Keywords: Multidisciplinary Topics and Applications: Security and Privacy Planning and Scheduling: Model-Based Reasoning Agent-based and Multi-agent Systems: Normative systems},
  archive   = {C_IJCAI},
  author    = {Rui Zhao},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/696},
  pages     = {4929-4930},
  title     = {An automated framework for supporting data-governance rule compliance in decentralized MIMO contexts},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning and planning under uncertainty for green security.
<em>IJCAI</em>, 4927–4928. (<a
href="https://doi.org/10.24963/ijcai.2021/695">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Green security concerns the protection of the world&#39;s wildlife, forests, and fisheries from poaching, illegal logging, and illegal fishing. Unfortunately, conservation efforts in green security domains are constrained by the limited availability of defenders, who must patrol vast areas to protect from attackers. Artificial intelligence (AI) techniques have been developed for green security and other security settings, such as US Coast Guard patrols and airport screenings, but effective deployment of AI in these settings requires learning adversarial behavior and planning in complex environments where the true dynamics may be unknown. My research develops novel techniques in machine learning and game theory to enable the effective development and deployment of AI in these resource-constrained settings. Notably, my work has spanned the pipeline from learning in a supervised setting, planning in stochastic environments, sequential planning in uncertain environments, and deployment in the real world. The overarching goal is to optimally allocate scarce resources under uncertainty for environmental conservation. Keywords: Agent-based and Multi-agent Systems: Multi-agent Planning Humans and AI: Computational Sustainability and Human Well-Being Machine Learning: Reinforcement Learning},
  archive   = {C_IJCAI},
  author    = {Lily Xu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/695},
  pages     = {4927-4928},
  title     = {Learning and planning under uncertainty for green security},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adversarial examples in physical world. <em>IJCAI</em>,
4925–4926. (<a href="https://doi.org/10.24963/ijcai.2021/694">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Although deep neural networks (DNNs) have already made fairly high achievements and a very wide range of impact, their vulnerability attracts lots of interest of researchers towards related studies about artificial intelligence (AI) safety and robustness this year. A series of works reveals that the current DNNs are always misled by elaborately designed adversarial examples. And unfortunately, this peculiarity also affects real-world AI applications and places them at potential risk. we are more interested in physical attacks due to their implementability in the real world. The study of physical attacks can effectively promote the application of AI techniques, which is of great significance to the security development of AI. Keywords: AI Ethics, Trust, Fairness: Explainability Machine Learning: Adversarial Machine Learning AI Ethics, Trust, Fairness: Trustable Learning},
  archive   = {C_IJCAI},
  author    = {Jiakai Wang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/694},
  pages     = {4925-4926},
  title     = {Adversarial examples in physical world},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Data efficient algorithms and interpretability requirements
for personalized assessment of taskable AI systems. <em>IJCAI</em>,
4923–4924. (<a href="https://doi.org/10.24963/ijcai.2021/693">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The vast diversity of internal designs of black-box AI systems and their nuanced zones of safe functionality make it difficult for a layperson to use them without unintended side effects. The focus of my dissertation is to develop algorithms and requirements of interpretability that would enable a user to assess and understand the limits of an AI system&#39;s safe operability. We develop an assessment module that lets an AI system execute high-level instruction sequences in simulators and answer the user queries about its execution of sequences of actions. Our results show that such a primitive query-response capability is sufficient to efficiently derive a user-interpretable model of the system in stationary, fully observable, and deterministic settings. Keywords: Planning and Scheduling: Model-Based Reasoning Knowledge Representation and Reasoning: Action, Change and Causality},
  archive   = {C_IJCAI},
  author    = {Pulkit Verma},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/693},
  pages     = {4923-4924},
  title     = {Data efficient algorithms and interpretability requirements for personalized assessment of taskable AI systems},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning from multimedia data with incomplete information.
<em>IJCAI</em>, 4921–4922. (<a
href="https://doi.org/10.24963/ijcai.2021/692">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Traditional deep learning methods are based on the condition that the data is of high-quality, which means the data information is highly available. However, data in these scenes often have the characteristics of large background noise, lack of sample content, small target, serious occlusion and a small number of samples. The application of related tasks in real open scenarios is very important, so it is urgent to make full use of these incomplete information data accurately. Keywords: Computer Vision: Recognition: Detection, Categorization, Indexing, Matching, Retrieval, Semantic Interpretation Machine Learning: Deep Learning Data Mining: Feature Extraction, Selection and Dimensionality Reduction Computer Vision: Language and Vision},
  archive   = {C_IJCAI},
  author    = {Renshuai Tao},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/692},
  pages     = {4921-4922},
  title     = {Learning from multimedia data with incomplete information},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Continual lifelong learning for intelligent agents.
<em>IJCAI</em>, 4919–4920. (<a
href="https://doi.org/10.24963/ijcai.2021/691">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep neural networks have achieved outstanding performance in many machine learning tasks. However, this remarkable success is achieved in a closed and static environment where the model is trained using large training data of a single task and deployed for testing on data with a similar distribution. Once the model is deployed, it becomes fixed and inflexible to new knowledge. This contradicts real-world applications, in which agents interact with open and dynamic environments and deal with non-stationary data. This Ph.D. research aims to propose efficient approaches that can develop intelligent agents capable of accumulating new knowledge and adapting to new environments without forgetting the previously learned ones. Keywords: Machine Learning: Incremental Learning Machine Learning: Learning Sparse Models Machine Learning: Classification Machine Learning: Deep Learning},
  archive   = {C_IJCAI},
  author    = {Ghada Sokar},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/691},
  pages     = {4919-4920},
  title     = {Continual lifelong learning for intelligent agents},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A human-AI teaming approach for incremental taxonomy
learning from text. <em>IJCAI</em>, 4917–4918. (<a
href="https://doi.org/10.24963/ijcai.2021/690">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Taxonomies provide a structured representation of semantic relations between lexical terms, acting as the backbone of many applications. The research proposed herein addresses the topic of taxonomy enrichment using an ”human-in-the-loop” semi-supervised approach. I will be investigating possible ways to extend and enrich a taxonomy using corpora of unstructured text data. The objective is to develop a methodological framework potentially applicable to any domain. Keywords: Natural Language Processing: Knowledge Extraction Data Mining: Recommender Systems Humans and AI: Human-AI Collaboration Knowledge Representation and Reasoning: Semantic Web},
  archive   = {C_IJCAI},
  author    = {Andrea Seveso and Fabio Mercorio and Mario Mezzanzanica},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/690},
  pages     = {4917-4918},
  title     = {A human-AI teaming approach for incremental taxonomy learning from text},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Inter-task similarity for lifelong reinforcement learning in
heterogeneous tasks. <em>IJCAI</em>, 4915–4916. (<a
href="https://doi.org/10.24963/ijcai.2021/689">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Reinforcement learning (RL) is a learning paradigm in which an agent interacts with the environment it inhabits to learn in a trial-and-error way. By letting the agent acquire knowledge from its own experience, RL has been successfully applied to complex domains such as robotics. However, for non-trivial problems, training an RL agent can take very long periods of time. Lifelong machine learning (LML) is a learning setting in which the agent learns to solve tasks sequentially, by leveraging knowledge accumulated from previously solved tasks to learn better/faster in a new one. Most LML works heavily rely on the assumption that tasks are similar to each other. However, this may not be true for some domains with a high degree of task-diversity that could benefit from adopting a lifelong learning approach, e.g., service robotics. Therefore, in this research we will address the problem of learning to solve a sequence of RL heterogeneous tasks (i.e., tasks that differ in their state-action space). Keywords: Machine Learning: Transfer, Adaptation, Multi-task Learning Machine Learning: Reinforcement Learning Machine Learning: Incremental Learning Robotics: Learning in Robotics},
  archive   = {C_IJCAI},
  author    = {Sergio A. Serrano},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/689},
  pages     = {4915-4916},
  title     = {Inter-task similarity for lifelong reinforcement learning in heterogeneous tasks},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modeling institutions in socio-ecosystems. <em>IJCAI</em>,
4913–4914. (<a href="https://doi.org/10.24963/ijcai.2021/688">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In socio-ecosystems, human activities are structured in time and space by interactions between different regulatory systems with different collective goals. These regulatory systems are modeled by institutions and organizations, and the regulatory mechanisms by norms applied to agents in Multi-Agent Systems (MAS). However, little is said about sharing resources, space and time. In particular, temporal and spatial expressivity is often limited in MAS for institutions and norms. This research proposes an institutional MAS model capable of representing multiple institutions and norms in the socio-ecosystem, in order to account for the multiplicity of interactions through agents, resources, space and time. We propose an extension of Descriptive Logic for the description of institutions and norms, and use Allen&#39;s algebra and the RCC8 to represent time and space. The resulting model allows us to know the norms applicable to an agent located socially, spatially and temporally. Keywords: Agent-based and Multi-agent Systems: Normative systems Agent-based and Multi-agent Systems: Coordination and Cooperation Knowledge Representation and Reasoning: Description Logics and Ontologies Agent-based and Multi-agent Systems: Agent Societies},
  archive   = {C_IJCAI},
  author    = {Sitraka Oliva Raharivelo and Jean-Pierre Müller},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/688},
  pages     = {4913-4914},
  title     = {Modeling institutions in socio-ecosystems},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hardware-friendly deep learning by network quantization and
binarization. <em>IJCAI</em>, 4911–4912. (<a
href="https://doi.org/10.24963/ijcai.2021/687">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Quantization is emerging as an efficient approach to promote hardware-friendly deep learning and run deep neural networks on resource-limited hardware. However, it still causes a significant decrease to the network in accuracy. We summarize challenges of quantization into two categories: Quantization for Diverse Architectures and Quantization on Complex Scenes. Our studies focus mainly on applying quantization on various architectures and scenes and pushing the limit of quantization to extremely compress and accelerate networks. The comprehensive research on quantization will achieve more powerful, more efficient, and more flexible hardware-friendly deep learning, and make it better suited to more real-world applications. Keywords: Machine Learning: Deep Learning},
  archive   = {C_IJCAI},
  author    = {Haotong Qin},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/687},
  pages     = {4911-4912},
  title     = {Hardware-friendly deep learning by network quantization and binarization},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards an explainer-agnostic conversational XAI.
<em>IJCAI</em>, 4909–4910. (<a
href="https://doi.org/10.24963/ijcai.2021/686">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Explainable Artificial Intelligence (XAI) is gaining interests in both academia and industry, mainly thanks to the proliferation of darker more complex black-box solutions which are replacing their more transparent ancestors. Believing that the overall performance of an XAI system can be augmented by considering the end-user as a human being, we are studying the ways we can improve the explanations by making them more informative and easier to use from one hand, and interactive and customisable from the other hand. Keywords: Natural Language Processing: Dialogue Humans and AI: Intelligent User Interfaces AI Ethics, Trust, Fairness: Explainability Humans and AI: Human-Computer Interaction},
  archive   = {C_IJCAI},
  author    = {Navid Nobani and Fabio Mercorio and Mario Mezzanzanica},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/686},
  pages     = {4909-4910},
  title     = {Towards an explainer-agnostic conversational XAI},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the learnability of knowledge in multi-agent logics.
<em>IJCAI</em>, 4907–4908. (<a
href="https://doi.org/10.24963/ijcai.2021/685">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Since knowledge engineering is an inherently challenging and somewhat unbounded task, machine learning has been widely proposed as an alternative. In real world scenarios, we often need to explicitly model multiple agents, where intelligent agents act towards achieving goals either by coordinating with the other agents or by overseeing the opponents moves, if in a competitive context. We consider the knowledge acquisition problem where agents have knowledge about the world and other agents and then acquire new knowledge (both about the world as well as other agents) in service of answering queries. We propose a model of implicit learning, or more generally, learning to reason, which bypasses the intractable step of producing an explicit representation of the learned knowledge. We show that polynomial-time learnability results can be obtained when limited to knowledge bases and observations consisting of conjunctions of modal literals. Keywords: Agent-based and Multi-agent Systems: Multi-agent Learning Knowledge Representation and Reasoning: Knowledge Representation Languages Knowledge Representation and Reasoning: Logics for Knowledge Representation Knowledge Representation and Reasoning: Reasoning about Knowledge and Belief},
  archive   = {C_IJCAI},
  author    = {Ionela G Mocanu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/685},
  pages     = {4907-4908},
  title     = {On the learnability of knowledge in multi-agent logics},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Combining reinforcement learning and causal models for
robotics applications. <em>IJCAI</em>, 4905–4906. (<a
href="https://doi.org/10.24963/ijcai.2021/684">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The relation between Reinforcement learning (RL) and Causal Modeling(CM) is an underexplored area with untapped potential for any learning task. In this extended abstract of our Ph.D. research proposal, we present a way to combine both areas to improve their respective learning processes, especially in the context of our application area (service robotics). The preliminary results obtained so far are a good starting point for thinking about the success of our research project. Keywords: Machine Learning: Reinforcement Learning Uncertainty in AI: Graphical Models Robotics: Learning in Robotics},
  archive   = {C_IJCAI},
  author    = {Arquímides Méndez-Molina},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/684},
  pages     = {4905-4906},
  title     = {Combining reinforcement learning and causal models for robotics applications},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Uncertain time series classification. <em>IJCAI</em>,
4903–4904. (<a href="https://doi.org/10.24963/ijcai.2021/683">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Time series analysis has gained a lot of interest during the last decade with diverse applications in a large range of domains such as medicine, physic, and industry. The field of time series classification has been particularly active recently with the development of more and more efficient methods. However, the existing methods assume that the input time series is free of uncertainty. However, there are applications in which uncertainty is so important that it can not be neglected. This project aims to build efficient, robust, and interpretable classification methods for uncertain time series. Keywords: Machine Learning: Time-series; Data Streams Machine Learning: Classification Machine Learning: Explainable/Interpretable Machine Learning},
  archive   = {C_IJCAI},
  author    = {Michael Franklin Mbouopda},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/683},
  pages     = {4903-4904},
  title     = {Uncertain time series classification},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). AI for planning public health interventions. <em>IJCAI</em>,
4901–4902. (<a href="https://doi.org/10.24963/ijcai.2021/682">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Several scenarios involving public health interventions have a unifying underlying theme, that deals with the challenge of optimizing the limited intervention resources available. My dissertation casts this as a Restless Multi-Armed Bandit (RMAB) planning problem, identifying and addressing several new, fundamental questions in RMABs. Keywords: Planning and Scheduling: Planning and Scheduling Agent-based and Multi-agent Systems: Resource Allocation Agent-based and Multi-agent Systems: Multi-agent Planning Planning and Scheduling: Markov Decisions Processes},
  archive   = {C_IJCAI},
  author    = {Aditya Mate},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/682},
  pages     = {4901-4902},
  title     = {AI for planning public health interventions},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep reinforcement learning with hierarchical structures.
<em>IJCAI</em>, 4899–4900. (<a
href="https://doi.org/10.24963/ijcai.2021/681">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Hierarchical reinforcement learning (HRL), which enables control at multiple time scales, is a promising paradigm to solve challenging and long-horizon tasks. In this paper, we briefly introduce our work in bottom-up and top-down HRL and outline the directions for future work. Keywords: Machine Learning: Reinforcement Learning},
  archive   = {C_IJCAI},
  author    = {Siyuan Li},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/681},
  pages     = {4899-4900},
  title     = {Deep reinforcement learning with hierarchical structures},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Nash welfare in the facility location problem.
<em>IJCAI</em>, 4897–4898. (<a
href="https://doi.org/10.24963/ijcai.2021/680">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In most facility location research, either an efficient facility placement which minimizes the total cost or a fairer placement which minimizes the maximum cost are typically proposed. To find a solution that is both fair and efficient, we propose converting the agent costs to utilities and placing the facility/ies such that the product of utilities, also known as the Nash welfare, is maximized. We ask whether the Nash welfare&#39;s well-studied balance between fairness and efficiency also applies to the facility location setting, and what agent strategic behaviour may occur under this facility placement. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice Agent-based and Multi-agent Systems: Algorithmic Game Theory Agent-based and Multi-agent Systems: Economic Paradigms, Auctions and Market-Based Systems Agent-based and Multi-agent Systems: Voting},
  archive   = {C_IJCAI},
  author    = {Alexander Lam},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/680},
  pages     = {4897-4898},
  title     = {Nash welfare in the facility location problem},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Planning and reinforcement learning for general-purpose
service robots. <em>IJCAI</em>, 4895–4896. (<a
href="https://doi.org/10.24963/ijcai.2021/679">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Despite recent progress in AI and robotics research, especially learned robot skills, there remain significant challenges in building robust, scalable, and general-purpose systems for service robots. This Ph.D. research aims to combine symbolic planning and reinforcement learning to reason about high-level robot tasks and adapt to the real world. We will introduce task planning algorithms that adapt to the environment and other agents, as well as reinforcement learning methods that are practical for service robot systems. Taken together, this work will make a significant step towards creating general-purpose service robots. Keywords: Robotics: Cognitive Robotics Planning and Scheduling: Robot Planning Machine Learning: Reinforcement Learning Robotics: Learning in Robotics},
  archive   = {C_IJCAI},
  author    = {Yuqian Jiang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/679},
  pages     = {4895-4896},
  title     = {Planning and reinforcement learning for general-purpose service robots},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robot manipulation learning using generative adversarial
imitation learning. <em>IJCAI</em>, 4893–4894. (<a
href="https://doi.org/10.24963/ijcai.2021/678">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Imitation learning allows learning complex behaviors given demonstrations. Early approaches belonging to either Behavior Cloning or Inverse Reinforcement Learning were however of limited scalability to complex environments. A more promising approach termed as Generative Adversarial Imitation Learning tackles the imitation learning problem by drawing a connection with Generative Adversarial Networks. In this work, we advocate the use of this class of methods and investigate possible extensions by endowing them with global temporal consistency, in particular through a contrastive learning based approach. Keywords: Machine Learning: Reinforcement Learning Machine Learning: Adversarial Machine Learning Machine Learning: Unsupervised Learning Robotics: Learning in Robotics},
  archive   = {C_IJCAI},
  author    = {Mohamed Khalil Jabri},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/678},
  pages     = {4893-4894},
  title     = {Robot manipulation learning using generative adversarial imitation learning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An information-theoretic approach on causal structure
learning for heterogeneous data characteristics of real-world scenarios.
<em>IJCAI</em>, 4891–4892. (<a
href="https://doi.org/10.24963/ijcai.2021/677">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {While the knowledge about the structures of a system’s underlying causal relationships is crucial within many real-world scenarios, the omnipresence of heterogeneous data characteristics impedes applying methods for causal structure learning (CSL). In this dissertation project, we reduce the barriers for the transfer of CSL into practice with threefold contributions: (1) We derive an information-theoretic conditional independence test that, incorporated into methods for CSL, improves the accuracy for non-linear and mixed discrete-continuous causal relationships; (2) We develop a modular pipeline that covers the essential components required for a comprehensive benchmarking to support the transferability into practice; (3) We evaluate opportunities and challenges of CSL within different real-world scenarios from genetics and discrete manufacturing to demonstrate the accuracy of our approach in practice. Keywords: Machine Learning: Learning Graphical Models Machine Learning: Probabilistic Machine Learning Computer Vision: Statistical Methods and Machine Learning Knowledge Representation and Reasoning: Action, Change and Causality},
  archive   = {C_IJCAI},
  author    = {Johannes Huegle},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/677},
  pages     = {4891-4892},
  title     = {An information-theoretic approach on causal structure learning for heterogeneous data characteristics of real-world scenarios},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards robust dynamic network embedding. <em>IJCAI</em>,
4889–4890. (<a href="https://doi.org/10.24963/ijcai.2021/676">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Dynamic Network Embedding (DNE) has recently drawn much attention due to the dynamic nature of many real-world networks. Comparing to a static network, a dynamic network has a unique character called the degree of changes, which can be defined as the average number of the changed edges between consecutive snapshots spanning a dynamic network. The degree of changes could be quite different even for the dynamic networks generated from the same dataset. It is natural to ask whether existing DNE methods are effective and robust w.r.t. the degree of changes. Towards robust DNE, we suggest two important scenarios. One is to investigate the robustness w.r.t. different slicing settings that are used to generate different dynamic networks with different degree of changes, while another focuses more on the robustness w.r.t. different number of changed edges over timesteps. Keywords: Data Mining: Mining Graphs, Semi Structured Data, Complex Data Machine Learning: Time-series; Data Streams Machine Learning: Ensemble Methods Natural Language Processing: Embeddings},
  archive   = {C_IJCAI},
  author    = {Chengbin Hou and Ke Tang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/676},
  pages     = {4889-4890},
  title     = {Towards robust dynamic network embedding},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Safety analysis of deep neural networks. <em>IJCAI</em>,
4887–4888. (<a href="https://doi.org/10.24963/ijcai.2021/675">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep Neural Networks (DNNs) are popular machine learning models which have found successful application in many different domains across computer science. Nevertheless, providing formal guarantees on the behaviour of neural networks is hard and therefore their reliability in safety-critical domains is still a concern. Verification and repair emerged as promising solutions to address this issue. In the following, I will present some of my recent efforts in this area. Keywords: AI Ethics, Trust, Fairness: Trustable Learning Multidisciplinary Topics and Applications: Validation and Verification Machine Learning: Deep Learning Machine Learning: Adversarial Machine Learning},
  archive   = {C_IJCAI},
  author    = {Dario Guidotti},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/675},
  pages     = {4887-4888},
  title     = {Safety analysis of deep neural networks},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automated facilitation support in online forum.
<em>IJCAI</em>, 4885–4886. (<a
href="https://doi.org/10.24963/ijcai.2021/674">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Online forum that gathers participants together to solve the common issues that they are facing is considered as a promising application of utilizing collective intelligence to solve complicated real-world problems. To facilitate the discussions in online forum to proceed smoothly and to build consensus efficiently, human facilitators are introduced into the system. With the increasing sophistication of online forum, human facilitators related problems such as human bias and restricted scale become critical. Therefore, it is critical to explore approaches to support human facilitators in conducting facilitation. However, most of the existing facilitation support techniques only support predefined facilitation tasks that could be defined by static rules. In this research, we aim to explore potential solutions for supporting the human facilitators to conduct facilitation in online forum. As the first step, we have proposed a case-based reasoning (CBR)-based framework that targets support facilitation by utilizing past successful facilitation experience. Currently, our work is focusing on the specific facilitation task of detecting influential user in the online forum. In the future work, we are planning to propose approaches of solving other specific facilitation tasks such as measuring the level of agreement and encouraging participants to reach a consensus. Keywords: Multidisciplinary Topics and Applications: Social Sciences Multidisciplinary Topics and Applications: Knowledge-based Software Engineering Knowledge Representation and Reasoning: Reasoning about Knowledge and Belief},
  archive   = {C_IJCAI},
  author    = {Wen Gu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/674},
  pages     = {4885-4886},
  title     = {Automated facilitation support in online forum},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Distributional metareasoning for heuristic search.
<em>IJCAI</em>, 4883–4884. (<a
href="https://doi.org/10.24963/ijcai.2021/673">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Heuristic search methods are widely used in many real-world autonomous systems. Yet, people always want to solve search problems that are larger than time allows. To address these challenging problems, even suboptimally, a planning agent should be smart enough to intelligently allocate its computational resources, to think carefully about where in the state space it should spend time searching. For finding optimal solutions, we must examine every node that is not provably too expensive. In contrast, to find suboptimal solutions when under time pressure, we need to be very selective about which nodes to examine. In this work, we will demonstrate that estimates of uncertainty, represented as belief distributions, can be used to drive search effectively. This type of algorithmic approach is known as metareasoning, which refers to reasoning about which reasoning to do. We will provide examples of improved algorithms for real-time search, bounded-cost search, and situated planning. Keywords: Heuristic Search and Game Playing: Heuristic Search Heuristic Search and Game Playing: Heuristic Search and Machine Learning Heuristic Search and Game Playing: Meta-Reasoning and Meta-Heuristics},
  archive   = {C_IJCAI},
  author    = {Tianyi Gu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/673},
  pages     = {4883-4884},
  title     = {Distributional metareasoning for heuristic search},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automatic design of heuristic algorithms for binary
optimization problems. <em>IJCAI</em>, 4881–4882. (<a
href="https://doi.org/10.24963/ijcai.2021/672">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this work we present AutoBQP, a heuristic solver for binary optimization problems. It applies automatic algorithm design techniques to search for the best heuristics for a given optimization problem. Experiments show that the solver can find algorithms which perform better than or comparable to state-of-the-art methods, and can even find new best solutions for some instances of standard benchmark sets. Keywords: Heuristic Search and Game Playing: Combinatorial Search and Optimisation Heuristic Search and Game Playing: Meta-Reasoning and Meta-Heuristics Heuristic Search and Game Playing: Heuristic Search Multidisciplinary Topics and Applications: Autonomic Computing},
  archive   = {C_IJCAI},
  author    = {Marcelo de Souza},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/672},
  pages     = {4881-4882},
  title     = {Automatic design of heuristic algorithms for binary optimization problems},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-agent approach to resource allocation in autonomous
vehicle fleets. <em>IJCAI</em>, 4879–4880. (<a
href="https://doi.org/10.24963/ijcai.2021/671">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The development of autonomous vehicles, capable of peer-to-peer communication, as well as the interest in on-demand solutions, are the primary motivations for this study. In the absence of central control, we are interested in forming a fleet of autonomous vehicles capable of responding to city-scale travel demands. Typically, this problem is solved centrally; this implies that the vehicles have continuous access to a dispatching portal. However, such access to such a global switching infrastructure (for data collection and order delivery) is costly and represents a critical bottleneck. The idea is to use low-cost vehicle-to-vehicle (V2V) communication technologies to coordinate vehicles without a global communication infrastructure. We propose to model the different aspects of decision and optimization problems related to this more general problem. After modeling these problems, the question arises as to the choice of centralized and decentralized solution methods. Methodologically, we explore the directions and compare the performance of distributed constraint optimization techniques (DCOP), self-organized multi-agent techniques, market-based approaches, and centralized operations research solutions. Keywords: Agent-based and Multi-agent Systems: Resource Allocation Multidisciplinary Topics and Applications: Transportation Agent-based and Multi-agent Systems: Coordination and Cooperation Planning and Scheduling: Planning and Scheduling},
  archive   = {C_IJCAI},
  author    = {Alaa Daoud},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/671},
  pages     = {4879-4880},
  title     = {Multi-agent approach to resource allocation in autonomous vehicle fleets},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bottleneck identification to semantic segmentation of
industrial 3D point cloud scene via deep learning. <em>IJCAI</em>,
4877–4878. (<a href="https://doi.org/10.24963/ijcai.2021/670">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Point cloud acquisition techniques are an essential tool for the digitization of industrial plants, yet the bulk of a designer&#39;s work remains manual. A first step to automatize drawing generation is to extract the semantics of the point cloud. Towards this goal, we investigate the use of deep learning to semantically segment oil and gas industrial scenes. We focus on domain characteristics such as high variation of object size, increased concavity and lack of annotated data, which hampers the use of conventional approaches. To address these issues, we advocate the use of synthetic data, adaptive downsampling and context sharing. Keywords: Computer Vision: 2D and 3D Computer Vision Machine Learning: Deep Learning Machine Learning Applications: Applications of Supervised Learning Computer Vision: Recognition: Detection, Categorization, Indexing, Matching, Retrieval, Semantic Interpretation},
  archive   = {C_IJCAI},
  author    = {Romain Cazorla and Line Poinel and Panagiotis Papadakis and Cédric Buche},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/670},
  pages     = {4877-4878},
  title     = {Bottleneck identification to semantic segmentation of industrial 3D point cloud scene via deep learning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Greybox algorithm configuration. <em>IJCAI</em>, 4875–4876.
(<a href="https://doi.org/10.24963/ijcai.2021/669">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The performance of state-of-the-art algorithms is highly dependent on their parameter values, and choosing the right configuration can make the difference between solving a problem in a few minutes or hours. Automated algorithm configurators have shown their efficiency on a wide range of applications. However, they still encounter limitations when confronted to a large number of parameters to tune or long algorithm running time. We believe that there is untapped knowledge that can be gathered from the elements of the configuration problem, such as the default value in the configuration space, the source code of the algorithm, and the distribution of the problem instances at hand. We aim at utilising this knowledge to improve algorithm configurators. Keywords: Heuristic Search and Game Playing: Combinatorial Search and Optimisation Heuristic Search and Game Playing: Heuristic Search and Machine Learning},
  archive   = {C_IJCAI},
  author    = {Marie Anastacio},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/669},
  pages     = {4875-4876},
  title     = {Greybox algorithm configuration},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep residual reinforcement learning (extended abstract).
<em>IJCAI</em>, 4869–4873. (<a
href="https://doi.org/10.24963/ijcai.2021/668">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We revisit residual algorithms in both model-free and model-based reinforcement learning settings. We propose the bidirectional target network technique to stabilize residual algorithms, yielding a residual version of DDPG that significantly outperforms vanilla DDPG in commonly used benchmarks. Moreover, we find the residual algorithm an effective approach to the distribution mismatch problem in model-based planning. Compared with the existing TD(k) method, our residual-based method makes weaker assumptions about the model and yields a greater performance boost. Keywords: Machine Learning: Reinforcement Learning},
  archive   = {C_IJCAI},
  author    = {Shangtong Zhang and Wendelin Boehmer and Shimon Whiteson},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/668},
  pages     = {4869-4873},
  title     = {Deep residual reinforcement learning (Extended abstract)},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Semantic linking maps for active visual object search
(extended abstract). <em>IJCAI</em>, 4864–4868. (<a
href="https://doi.org/10.24963/ijcai.2021/667">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We aim for mobile robots to function in a variety of common human environments, which requires them to efficiently search previously unseen target objects. We can exploit background knowledge about common spatial relations between landmark objects and target objects to narrow down search space. In this paper, we propose an active visual object search strategy method through our introduction of the Semantic Linking Maps (SLiM) model. SLiM simultaneously maintains the belief over a target object&#39;s location as well as landmark objects&#39; locations, while accounting for probabilistic inter-object spatial relations. Based on SLiM, we describe a hybrid search strategy that selects the next best view pose for searching for the target object based on the maintained belief. We demonstrate the efficiency of our SLiM-based search strategy through comparative experiments in simulated environments. We further demonstrate the real-world applicability of SLiM-based search in scenarios with a Fetch mobile manipulation robot. Keywords: Robotics: Cognitive Robotics Robotics: Robotics and Vision Robotics: Vision and Perception Uncertainty in AI: Graphical Models},
  archive   = {C_IJCAI},
  author    = {Zhen Zeng and Adrian Röfer and Odest Chadwicke Jenkins},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/667},
  pages     = {4864-4868},
  title     = {Semantic linking maps for active visual object search (Extended abstract)},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). TAXOGAN: Hierarchical network representation learning via
taxonomy guided generative adversarial networks (extended abstract).
<em>IJCAI</em>, 4859–4863. (<a
href="https://doi.org/10.24963/ijcai.2021/666">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Network representation learning aims at transferring node proximity in networks into distributed vectors, which can be leveraged in various downstream applications. Recent research has shown that nodes in a network can often be organized in latent hierarchical structures, but without a particular underlying taxonomy, the learned node embedding is less useful nor interpretable. In this work, we aim to improve network embedding by modeling the conditional node proximity in networks indicated by node labels residing in real taxonomies. In the meantime, we also aim to model the hierarchical label proximity in the given taxonomies, which is too coarse by solely looking at the hierarchical topologies. Comprehensive experiments and case studies demonstrate the utility of TAXOGAN. Keywords: Data Mining: Mining Graphs, Semi Structured Data, Complex Data Knowledge Representation and Reasoning: Leveraging Knowledge and Learning Machine Learning: Knowledge Aided Learning Machine Learning Applications: Networks},
  archive   = {C_IJCAI},
  author    = {Carl Yang and Jieyu Zhang and Jiawei Han},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/666},
  pages     = {4859-4863},
  title     = {TAXOGAN: Hierarchical network representation learning via taxonomy guided generative adversarial networks (Extended abstract)},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Unsupervised learning of probably symmetric deformable 3D
objects from images in the wild (extended abstract). <em>IJCAI</em>,
4854–4858. (<a href="https://doi.org/10.24963/ijcai.2021/665">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose a method to learn 3D deformable object categories from raw single-view images, without external supervision. The method is based on an autoencoder that factors each input image into depth, albedo, viewpoint and illumination. In order to disentangle these components without supervision, we use the fact that many object categories have, at least approximately, a symmetric structure. We show that reasoning about illumination allows us to exploit the underlying object symmetry even if the appearance is not symmetric due to shading. Furthermore, we model objects that are probably, but not certainly, symmetric by predicting a symmetry probability map, learned end-to-end with the other components of the model. Our experiments show that this method can recover very accurately the 3D shape of human faces, cat faces and cars from single-view images, without any supervision or a prior shape model. Code and demo available at https://github.com/elliottwu/unsup3d. Keywords: Computer Vision: 2D and 3D Computer Vision Computer Vision: Computational Photography, Photometry, Shape from X},
  archive   = {C_IJCAI},
  author    = {Shangzhe Wu and Christian Rupprecht and Andrea Vedaldi},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/665},
  pages     = {4854-4858},
  title     = {Unsupervised learning of probably symmetric deformable 3D objects from images in the wild (Extended abstract)},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Speech recognition using RFID tattoos (extended abstract).
<em>IJCAI</em>, 4849–4853. (<a
href="https://doi.org/10.24963/ijcai.2021/664">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper presents a radio-frequency (RF) based assistive technology for voice impairments (i.e., dysphonia), which occurs in an estimated 1\% of the global population. We specifically focus on acquired voice disorders where users continue to be able to make facial and lip gestures associated with speech. Despite the rich literature on assistive technologies in this space, there remains a gap for a solution that neither requires external infrastructure in the environment, battery-powered sensors on skin or body-worn manual input devices. We present RFTattoo, which to our knowledge is the first wireless speech recognition system for voice impairments using batteryless and flexible RFID tattoos. We design specialized wafer-thin tattoos attached around the user&#39;s face and easily hidden by makeup. We build models that process signal variations from these tattoos to a portable RFID reader to recognize various facial gestures corresponding to distinct classes of sounds. We then develop natural language processing models that infer meaningful words and sentences based on the observed series of gestures. A detailed user study with 10 users reveals 86\% accuracy in reconstructing the top-100 words in the English language, even without the users making any sounds. Keywords: Multidisciplinary Topics and Applications: Ubiquitous Computing Systems Humans and AI: Human-Computer Interaction},
  archive   = {C_IJCAI},
  author    = {Jingxian Wang and Chengfeng Pan and Haojian Jin and Vaibhav Singh and Yash Jain and Jason I. Hong and Carmel Majidi and Swarun Kumar},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/664},
  pages     = {4849-4853},
  title     = {Speech recognition using RFID tattoos (Extended abstract)},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Open intent extraction from natural language interactions
(extended abstract). <em>IJCAI</em>, 4844–4848. (<a
href="https://doi.org/10.24963/ijcai.2021/663">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Accurately discovering user intents from their written or spoken language plays a critical role in natural language understanding and automated dialog response. Most existing research models this as a classification task with a single intent label per utterance. Going beyond this formulation, we define and investigate a new problem of open intent discovery. It involves discovering one or more generic intent types from text utterances, that may not have been encountered during training. We propose a novel, domain-agnostic approach, OPINE, which formulates the problem as a sequence tagging task in an open-world setting. It employs a CRF on top of a bidirectional LSTM to extract intents in a consistent format, subject to constraints among intent tag labels. We apply multi-headed self-attention and adversarial training to effectively learn dependencies between distant words, and robustly adapt our model across varying domains. We also curate and release an intent-annotated dataset of 25K real-life utterances spanning diverse domains. Extensive experiments show that OPINE outperforms state-of-art baselines by 5-15\% F1 score. Keywords: Natural Language Processing: Natural Language Processing Natural Language Processing: NLP Applications and Tools Machine Learning: Deep Learning Natural Language Processing: Natural Language Semantics},
  archive   = {C_IJCAI},
  author    = {Nikhita Vedula and Nedim Lipka and Pranav Maneriker and Srinivasan Parthasarathy},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/663},
  pages     = {4844-4848},
  title     = {Open intent extraction from natural language interactions (Extended abstract)},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). RAFT: Recurrent all-pairs field transforms for optical flow
(extended abstract). <em>IJCAI</em>, 4839–4843. (<a
href="https://doi.org/10.24963/ijcai.2021/662">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We introduce Recurrent All-Pairs Field Transforms (RAFT), a new deep network architecture for optical flow. RAFT extracts per-pixel features, builds multi-scale 4D correlation volumes for all pairs of pixels, and iteratively updates a flow field through a recurrent unit that performs lookups on the correlation volumes. RAFT achieves state-of-the-art performance on the KITTI and Sintel datasets. In addition, RAFT has strong cross-dataset generalization as well as high efficiency in inference time, training speed, and parameter count. Keywords: Computer Vision: Motion and Tracking Computer Vision: 2D and 3D Computer Vision},
  archive   = {C_IJCAI},
  author    = {Zachary Teed and Jia Deng},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/662},
  pages     = {4839-4843},
  title     = {RAFT: Recurrent all-pairs field transforms for optical flow (Extended abstract)},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Imprecise oracles impose limits to predictability in
supervised learning (extended abstract). <em>IJCAI</em>, 4834–4838. (<a
href="https://doi.org/10.24963/ijcai.2021/661">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Supervised learning operates on the premise that labels unambiguously represent ground truth. This premise is reasonable in domains wherein a high degree of consensus is easily possible for any given data record, e.g. in agreeing on whether an image contains an elephant or not. However, there are several domains wherein people disagree with each other on the appropriate label to assign to a record, e.g. whether a tweet is toxic. We argue that data labeling must be understood as a process with some degree of domain-dependent noise and that any claims of predictive prowess must be sensitive to the degree of this noise. We present a method for quantifying labeling noise in a particular domain wherein people are seen to disagree with their own past selves on the appropriate label to assign to a record: choices under prospect uncertainty. Our results indicate that `state-of-the-art&#39; choice models of decisions from description, by failing to consider the intrinsic variability of human choice behavior, find themselves in the odd position of predicting humans&#39; choices better than the same humans&#39; own previous choices for the same problem. We conclude with observations on how the predicament we empirically demonstrate in our work could be handled in the practice of supervised learning. Keywords: Uncertainty in AI: Uncertainty Representations Humans and AI: Cognitive Systems Machine Learning: Classification Machine Learning Applications: Applications of Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Anjali Sifar and Nisheeth Srivastava},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/661},
  pages     = {4834-4838},
  title     = {Imprecise oracles impose limits to predictability in supervised learning (Extended abstract)},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Politeness for the theory of algebraic datatypes (extended
abstract). <em>IJCAI</em>, 4829–4833. (<a
href="https://doi.org/10.24963/ijcai.2021/660">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Algebraic datatypes, and among them lists and trees, have attracted a lot of interest in automated reasoning and Satisfiability Modulo Theories (SMT). Since its latest stable version, the SMT-LIB standard defines a theory of algebraic datatypes, which is currently supported by several mainstream SMT solvers. In this paper, we study this particular theory of datatypes and prove that it is strongly polite, showing also how it can be combined with other arbitrary disjoint theories using polite combination. Our results cover both inductive and finite datatypes, as well as their union. The combination method uses a new, simple, and natural notion of additivity, that enables deducing strong politeness from (weak) politeness. Keywords: Constraints and SAT: Satisfiability Modulo Theories Constraints and SAT: SAT: Algorithms and Techniques Constraints and SAT: Constraints: Modeling, Solvers, Applications Constraints and SAT: Constraint Satisfaction},
  archive   = {C_IJCAI},
  author    = {Ying Sheng and Yoni Zohar and Christophe Ringeissen and Jane Lange and Pascal Fontaine and Clark Barrett},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/660},
  pages     = {4829-4833},
  title     = {Politeness for the theory of algebraic datatypes (Extended abstract)},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Beyond accuracy: Behavioral testing of NLP models with
checklist (extended abstract). <em>IJCAI</em>, 4824–4828. (<a
href="https://doi.org/10.24963/ijcai.2021/659">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Although measuring held-out accuracy has been the primary approach to evaluate generalization, it often overestimates the performance of NLP models, while alternative approaches for evaluating models either focus on individual tasks or on specific behaviors. Inspired by principles of behavioral testing in software engineering, we introduce CheckList, a task-agnostic methodology for testing NLP models. CheckList includes a matrix of general linguistic capabilities and test types that facilitate comprehensive test ideation, as well as a software tool to generate a large and diverse number of test cases quickly. We illustrate the utility of CheckList with tests for three tasks, identifying critical failures in both commercial and state-of-art models. In a user study, a team responsible for a commercial sentiment analysis model found new and actionable bugs in an extensively tested model. In another user study, NLP practitioners with CheckList created twice as many tests, and found almost three times as many bugs as users without it. Keywords: Natural Language Processing: Resources and Evaluation Natural Language Processing: NLP Applications and Tools Natural Language Processing: Text Classification Natural Language Processing: Question Answering},
  archive   = {C_IJCAI},
  author    = {Marco Tulio Ribeiro and Tongshuang Wu and Carlos Guestrin and Sameer Singh},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/659},
  pages     = {4824-4828},
  title     = {Beyond accuracy: Behavioral testing of NLP models with checklist (Extended abstract)},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploring the effects of goal setting when training for
complex crowdsourcing tasks (extended abstract). <em>IJCAI</em>,
4819–4823. (<a href="https://doi.org/10.24963/ijcai.2021/658">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Training is one way of enabling novice workers to work on complex crowdsourcing tasks. Based on goal setting theory in psychology, we conduct a randomized experiment to study whether and how setting different goals---including performance goal, learning goal, and behavioral goal---when training workers for a complex crowdsourcing task affects workers&#39; learning perception, learning gain, and post-training performance. We find that setting different goals during training significantly affects workers&#39; learning perception, but does not have an effect on learning gain or post-training performance. Further, exploratory analysis helps shed light on when and why various goals may or may not work in the crowdsourcing context. Keywords: Humans and AI: Human Computation and Crowdsourcing},
  archive   = {C_IJCAI},
  author    = {Amy Rechkemmer and Ming Yin},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/658},
  pages     = {4819-4823},
  title     = {Exploring the effects of goal setting when training for complex crowdsourcing tasks (Extended abstract)},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Finding the hardest formulas for resolution (extended
abstract). <em>IJCAI</em>, 4814–4818. (<a
href="https://doi.org/10.24963/ijcai.2021/657">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A CNF formula is harder than another CNF formula with the same number of clauses if it requires a longer resolution proof. We introduce resolution hardness numbers; they give for m=1, 2, ... the length of a shortest proof of a hardest formula on m clauses. We compute the first ten resolution hardness numbers, along with the corresponding hardest formulas. To achieve this, we devise a candidate filtering and symmetry breaking search scheme for limiting the number of potential candidates for hardest formulas, and an efficient SAT encoding for computing a shortest resolution proof of a given candidate formula. Keywords: Constraints and SAT: SAT: Solvers and Applications Constraints and SAT: Constraints: Modeling, Solvers, Applications Constraints and SAT: SAT: Algorithms and Techniques Constraints and SAT: Constraint Satisfaction},
  archive   = {C_IJCAI},
  author    = {Tomáš Peitl and Stefan Szeider},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/657},
  pages     = {4814-4818},
  title     = {Finding the hardest formulas for resolution (Extended abstract)},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Unifying online and counterfactual learning to rank: A novel
counterfactual estimator that effectively utilizes online interventions
(extended abstract). <em>IJCAI</em>, 4809–4813. (<a
href="https://doi.org/10.24963/ijcai.2021/656">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {State-of-the-art Learning to Rank (LTR) methods for optimizing ranking systems based on user interactions are divided into online approaches – that learn by direct interaction – and counterfactual approaches – that learn from historical interactions. We propose a novel intervention-aware estimator to bridge this online/counterfactual division. The estimator corrects for the effect of position bias, trust bias, and item-selection bias by using corrections based on the behavior of the logging policy and on online interventions: changes to the logging policy made during the gathering of click data. Our experimental results show that, unlike existing counterfactual LTR methods, the intervention-aware estimator can greatly benefit from online interventions. To the best of our knowledge, this is the first method that is shown to be highly effective in both online and counterfactual scenarios. Keywords: Machine Learning: Recommender Systems Machine Learning: Online Learning Data Mining: Information Retrieval},
  archive   = {C_IJCAI},
  author    = {Harrie Oosterhuis and Maarten de Rijke},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/656},
  pages     = {4809-4813},
  title     = {Unifying online and counterfactual learning to rank: A novel counterfactual estimator that effectively utilizes online interventions (Extended abstract)},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Controlling fairness and bias in dynamic learning-to-rank
(extended abstract). <em>IJCAI</em>, 4804–4808. (<a
href="https://doi.org/10.24963/ijcai.2021/655">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Rankings are the primary interface through which many online platforms match users to items (e.g. news, products, music, video). In these two-sided markets, not only do the users draw utility from the rankings, but the rankings also determine the utility (e.g. exposure, revenue) for the item providers (e.g. publishers, sellers, artists, studios). It has already been noted that myopically optimizing utility to the users -- as done by virtually all learning-to-rank algorithms -- can be unfair to the item providers. We, therefore, present a learning-to-rank approach for explicitly enforcing merit-based fairness guarantees to groups of items (e.g. articles by the same publisher, tracks by the same artist). In particular, we propose a learning algorithm that ensures notions of amortized group fairness, while simultaneously learning the ranking function from implicit feedback data. The algorithm takes the form of a controller that integrates unbiased estimators for both fairness and utility, dynamically adapting both as more data becomes available. In addition to its rigorous theoretical foundation and convergence guarantees, we find empirically that the algorithm is highly practical and robust. Keywords: Machine Learning: Learning Preferences or Rankings AI Ethics, Trust, Fairness: Fairness Data Mining: Information Retrieval Machine Learning: Online Learning},
  archive   = {C_IJCAI},
  author    = {Marco Morik and Ashudeep Singh and Jessica Hong and Thorsten Joachims},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/655},
  pages     = {4804-4808},
  title     = {Controlling fairness and bias in dynamic learning-to-rank (Extended abstract)},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The moodoo library: Quantitative metrics to model how
teachers make use of the classroom space by analysing indoor positioning
traces (extended abstract). <em>IJCAI</em>, 4799–4803. (<a
href="https://doi.org/10.24963/ijcai.2021/654">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Teachers’ spatial behaviours in the classroom can strongly influence students’ engagement, motivation and other behaviours that shape their learning. However, classroom teaching behav-iour is ephemeral, and has largely remained opaque to computational analysis. This paper presents a library called ‘Moodoo’ that can serve to automatically model how teachers make use of the classroom space by analysing indoor positioning traces. The system automatically ex-tracts spatial metrics (e.g. teacher-student ratios, frequency of visits to students’ personal spaces, presence in classroom spaces of interest, index of dispersion and entropy), mapping from the teachers’ low-level positioning data to higher-order spatial constructs. Keywords: Humans and AI: Human-Computer Interaction Humans and AI: Computer-Aided Education Machine Learning Applications: Humanities Multidisciplinary Topics and Applications: Ubiquitous Computing Systems},
  archive   = {C_IJCAI},
  author    = {Roberto Martinez-Maldonado and Vanessa Echeverria and Katerina Mangaroska and Antonette Shibani and Gloria Fernandez-Nieto and Jurgen Schulte and Simon Buckingham Shum},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/654},
  pages     = {4799-4803},
  title     = {The moodoo library: Quantitative metrics to model how teachers make use of the classroom space by analysing indoor positioning traces (Extended abstract)},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On learning sets of symmetric elements (extended abstract).
<em>IJCAI</em>, 4794–4798. (<a
href="https://doi.org/10.24963/ijcai.2021/653">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Learning from unordered sets is a fundamental learning setup, recently attracting increasing attention. Research in this area has focused on the case where elements of the set are represented by feature vectors, and far less emphasis has been given to the common case where set elements themselves adhere to their own symmetries. That case is relevant to numerous applications, from deblurring image bursts to multi-view 3D shape recognition and reconstruction. In this paper, we present a principled approach to learning sets of general symmetric elements. We first characterize the space of linear layers that are equivariant both to element reordering and to the inherent symmetries of elements, like translation in the case of images. We further show that networks that are composed of these layers, called Deep Sets for Symmetric Elements layers (DSS), are universal approximators of both invariant and equivariant functions, and that these networks are strictly more expressive than Siamese networks. DSS layers are also straightforward to implement. Finally, we show that they improve over existing set-learning architectures in a series of experiments with images, graphs, and point clouds. Keywords: Machine Learning: Deep Learning},
  archive   = {C_IJCAI},
  author    = {Haggai Maron and Or Litany and Gal Chechik and Ethan Fetaya},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/653},
  pages     = {4794-4798},
  title     = {On learning sets of symmetric elements (Extended abstract)},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Revisiting wedge sampling for budgeted maximum inner product
search (extended abstract). <em>IJCAI</em>, 4789–4793. (<a
href="https://doi.org/10.24963/ijcai.2021/652">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Top-k maximum inner product search (MIPS) is a central task in many machine learning applications. This work extends top-k MIPS with a budgeted setting, that asks for the best approximate top-k MIPS given a limited budget of computational operations. We study recent advanced sampling methods, including wedge and diamond sampling, to solve budgeted top-k MIPS. First, we theoretically show that diamond sampling is essentially a combination of wedge sampling and basic sampling for top-k MIPS. Second, we propose dWedge, a simple deterministic variant of wedge sampling for budgeted top-k MIPS. Empirically, dWedge provides significantly higher accuracy than other budgeted top-k MIPS solvers while maintaining a similar speedup. Keywords: Data Mining: Information Retrieval Data Mining: Recommender Systems},
  archive   = {C_IJCAI},
  author    = {Stephan S. Lorenzen and Ninh Pham},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/652},
  pages     = {4789-4793},
  title     = {Revisiting wedge sampling for budgeted maximum inner product search (Extended abstract)},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On sampled metrics for item recommendation (extended
abstract). <em>IJCAI</em>, 4784–4788. (<a
href="https://doi.org/10.24963/ijcai.2021/651">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recommender systems personalize content by recommending items to users. Item recommendation algorithms are evaluated by metrics that compare the positions of truly relevant items among the recommended items. To speed up the computation of metrics, recent work often uses sampled metrics where only a smaller set of random items and the relevant items are ranked. This paper investigates such sampled metrics and shows that they are inconsistent with their exact counterpart, in the sense that they do not persist relative statements, e.g., recommender A is better than B, not even in expectation. We show that it is possible to improve the quality of the sampled metrics by applying a correction. We conclude with an empirical evaluation of the naive sampled metrics and their corrected variants. Our work suggests that sampling should be avoided for metric calculation, however if an experimental study needs to sample, the proposed corrections can improve the estimates. Keywords: Machine Learning: Recommender Systems},
  archive   = {C_IJCAI},
  author    = {Walid Krichene and Steffen Rendle},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/651},
  pages     = {4784-4788},
  title     = {On sampled metrics for item recommendation (Extended abstract)},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep drone acrobatics (extended abstract). <em>IJCAI</em>,
4780–4783. (<a href="https://doi.org/10.24963/ijcai.2021/650">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Acrobatic flight with quadrotors is extremely challenging. Maneuvers such as the loop, matty flip, or barrel roll require high thrust and extreme angular accelerations that push the platform to its limits. Human drone pilots require years of practice to safely master such maneuvers. Yet, a tiny mistake could make the platform lose control, and brutally crash. This short paper describes an approach to safely train acrobatic controllers in simulation and deploy them with no fine-tuning zero-shot transfer on physical quadrotors. The approach uses only onboard sensing and computation. Keywords: Robotics: Learning in Robotics Robotics: Behavior and Control Machine Learning Applications: Applications of Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Elia Kaufmann and Antonio Loquercio and Rene Ranftl and Matthias Müller and Vladlen Koltun and Davide Scaramuzza},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/650},
  pages     = {4780-4783},
  title     = {Deep drone acrobatics (Extended abstract)},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Successor-invariant first-order logic on classes of bounded
degree (extended abstract). <em>IJCAI</em>, 4775–4779. (<a
href="https://doi.org/10.24963/ijcai.2021/649">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the expressive power of successor-invariant first-order logic, which is an extension of first-order logic where the usage of a successor relation on the vertices of the graph is allowed, as long as the validity of formulas is independent on the choice of a particular successor. We show that when the degree is bounded, successor-invariant first-order logic is no more expressive than first-order logic. Keywords: Knowledge Representation and Reasoning: Logics for Knowledge Representation},
  archive   = {C_IJCAI},
  author    = {Julien Grange},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/649},
  pages     = {4775-4779},
  title     = {Successor-invariant first-order logic on classes of bounded degree (Extended abstract)},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mental models of AI agents in a cooperative game setting
(extended abstract). <em>IJCAI</em>, 4770–4774. (<a
href="https://doi.org/10.24963/ijcai.2021/648">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As more and more forms of AI become prevalent, it becomes increasingly important to understand how people develop mental models of these systems. In this work we study people&#39;s mental models of an AI agent in a cooperative word guessing game. We run a study in which people play the game with an AI agent while ``thinking out loud&#39;&#39;; through thematic analysis we identify features of the mental models developed by participants. In a large-scale study we have participants play the game with the AI agent online and use a post-game survey to probe their mental model. We find that those who win more often have better estimates of the AI agent&#39;s abilities. We present three components---global knowledge, local knowledge, and knowledge distribution---for modeling AI systems and propose that understanding the underlying technology is insufficient for developing appropriate conceptual models---analysis of behavior is also necessary. Keywords: Humans and AI: Human-AI Collaboration Humans and AI: Human-Computer Interaction Heuristic Search and Game Playing: Game Playing Humans and AI: Cognitive Modeling},
  archive   = {C_IJCAI},
  author    = {Katy Ilonka Gero and Zahra Ashktorab and Casey Dugan and Qian Pan and James Johnson and Werner Geyer and Maria Ruiz and Sarah Miller and David R. Millen and Murray Campbell and Sadhana Kumaravel and Wei Zhang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/648},
  pages     = {4770-4774},
  title     = {Mental models of AI agents in a cooperative game setting (Extended abstract)},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improved guarantees and a multiple-descent curve for column
subset selection and the nystrom method (extended abstract).
<em>IJCAI</em>, 4765–4769. (<a
href="https://doi.org/10.24963/ijcai.2021/647">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Column Subset Selection Problem (CSSP) and the Nystrom method are among the leading tools for constructing interpretable low-rank approximations of large datasets by selecting a small but representative set of features or instances. A fundamental question in this area is: what is the cost of this interpretability, i.e., how well can a data subset of size k compete with the best rank k approximation? We develop techniques which exploit spectral properties of the data matrix to obtain improved approximation guarantees which go beyond the standard worst-case analysis. Our approach leads to significantly better bounds for datasets with known rates of singular value decay, e.g., polynomial or exponential decay. Our analysis also reveals an intriguing phenomenon: the cost of interpretability as a function of k may exhibit multiple peaks and valleys, which we call a multiple-descent curve. A lower bound we establish shows that this behavior is not an artifact of our analysis, but rather it is an inherent property of the CSSP and Nystrom tasks. Finally, using the example of a radial basis function (RBF) kernel, we show that both our improved bounds and the multiple-descent curve can be observed on real datasets simply by varying the RBF parameter. Keywords: Machine Learning: Dimensionality Reduction Machine Learning: Explainable/Interpretable Machine Learning Machine Learning: Kernel Methods Machine Learning: Unsupervised Learning},
  archive   = {C_IJCAI},
  author    = {Michał Dereziński and Rajiv Khanna and Michael W. Mahoney},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/647},
  pages     = {4765-4769},
  title     = {Improved guarantees and a multiple-descent curve for column subset selection and the nystrom method (Extended abstract)},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Weaving a semantic web of credibility reviews for
explainable misinformation detection (extended abstract).
<em>IJCAI</em>, 4760–4764. (<a
href="https://doi.org/10.24963/ijcai.2021/646">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper summarises work where we combined semantic web technologies with deep learning systems to obtain state-of-the art explainable misinformation detection. We proposed a conceptual and computational model to describe a wide range of misinformation detection systems based around the concepts of credibility and reviews. We described how Credibility Reviews (CRs) can be used to build networks of distributed bots that collaborate for misinformation detection which we evaluated by building a prototype based on publicly available datasets and deep learning models. Keywords: Knowledge Representation and Reasoning: Semantic Web AI Ethics, Trust, Fairness: Societal Impact of AI AI Ethics, Trust, Fairness: Explainability Natural Language Processing: NLP Applications and Tools},
  archive   = {C_IJCAI},
  author    = {Ronald Denaux and Martino Mensio and Jose Manuel Gomez-Perez and Harith Alani},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/646},
  pages     = {4760-4764},
  title     = {Weaving a semantic web of credibility reviews for explainable misinformation detection (Extended abstract)},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Decentralized no-regret learning algorithms for
extensive-form correlated equilibria (extended abstract).
<em>IJCAI</em>, 4755–4759. (<a
href="https://doi.org/10.24963/ijcai.2021/645">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The existence of uncoupled no-regret learning dynamics converging to correlated equilibria in normal-form games is a celebrated result in the theory of multi-agent systems. Specifically, it has been known for more than 20 years that when all players seek to minimize their internal regret in a repeated normal-form game, the empirical frequency of play converges to a normal-form correlated equilibrium. Extensive-form games generalize normal-form games by modeling both sequential and simultaneous moves, as well as imperfect information. Because of the sequential nature and the presence of private information, correlation in extensive-form games possesses significantly different properties than in normal-form games. The extensive-form correlated equilibrium (EFCE) is the natural extensive-form counterpart to the classical notion of correlated equilibrium in normal-form games. Compared to the latter, the constraints that define the set of EFCEs are significantly more complex, as the correlation device ({\em a.k.a.} mediator) must take into account the evolution of beliefs of each player as they make observations throughout the game. Due to this additional complexity, the existence of uncoupled learning dynamics leading to an EFCE has remained a challenging open research question for a long time. In this article, we settle that question by giving the first uncoupled no-regret dynamics which provably converge to the set of EFCEs in n-player general-sum extensive-form games with perfect recall. We show that each iterate can be computed in time polynomial in the size of the game tree, and that, when all players play repeatedly according to our learning dynamics, the empirical frequency of play after T game repetitions is guaranteed to be a O(T^-1/2)-approximate EFCE with high probability, and an EFCE almost surely in the limit. Keywords: Agent-based and Multi-agent Systems: Multi-agent Learning Agent-based and Multi-agent Systems: Algorithmic Game Theory Agent-based and Multi-agent Systems: Noncooperative Games Machine Learning: Reinforcement Learning},
  archive   = {C_IJCAI},
  author    = {Andrea Celli and Alberto Marchesi and Gabriele Farina and Nicola Gatti},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/645},
  pages     = {4755-4759},
  title     = {Decentralized no-regret learning algorithms for extensive-form correlated equilibria (Extended abstract)},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust domain adaptation: Representations, weights and
inductive bias (extended abstract). <em>IJCAI</em>, 4750–4754. (<a
href="https://doi.org/10.24963/ijcai.2021/644">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Domain Invariant Representations (IR) has improved drastically the transferability of representations from a labelled source domain to a new and unlabelled target domain. Unsupervised Domain Adaptation (UDA) in presence of label shift remains an open problem. To this purpose, we present a bound of the target risk which incorporates both weights and invariant representations. Our theoretical analysis highlights the role of inductive bias in aligning distributions across domains. We illustrate it on standard benchmarks by proposing a new learning procedure for UDA. We observed empirically that weak inductive bias makes adaptation robust to label shift. The elaboration of stronger inductive bias is a promising direction for new UDA algorithms. Keywords: Machine Learning: Transfer, Adaptation, Multi-task Learning Machine Learning: Learning Theory},
  archive   = {C_IJCAI},
  author    = {Victor Bouvier and Philippe Very and Clément Chastagnol and Myriam Tami and Céline Hudelot},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/644},
  pages     = {4750-4754},
  title     = {Robust domain adaptation: Representations, weights and inductive bias (Extended abstract)},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Abstract cores in implicit hitting set MaxSat solving
(extended abstract). <em>IJCAI</em>, 4745–4749. (<a
href="https://doi.org/10.24963/ijcai.2021/643">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Maximum satisfiability (MaxSat) solving is an active area of research motivated by numerous successful applications to solving NP-hard combinatorial optimization problems. One of the most successful approaches for solving MaxSat instances from real world domains are the so called implicit hitting set (IHS) solvers. IHS solvers decouple MaxSat solving into separate core-extraction (i.e. reasoning) and optimization steps which are tackled by a Boolean satisfiability (SAT) and an integer linear programming (IP) solver, respectively. While the approach shows state-of-the-art performance on many industrial instances, it is known that there exists instances on which IHS solvers need to extract an exponential number of cores before terminating. Motivated by the simplest of these problematic instances, we propose abstract cores, a compact representation for a potentially exponential number of regular cores. We demonstrate how to incorporate abstract core reasoning into the IHS algorithm and report on an empirical evaluation demonstrating, that including abstract cores into a state-of-the-art IHS solver improves its performance enough to surpass the best performing solvers of the 2019 MaxSat Evaluation. Keywords: Constraints and SAT: MaxSAT, MinSAT Constraints and SAT: Constraint Optimization Constraints and SAT: SAT: Algorithms and Techniques Constraints and SAT: Constraints: Modeling, Solvers, Applications},
  archive   = {C_IJCAI},
  author    = {Jeremias Berg and Fahiem Bacchus and Alex Poole},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/643},
  pages     = {4745-4749},
  title     = {Abstract cores in implicit hitting set MaxSat solving (Extended abstract)},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Comparing weak admissibility semantics to their dung-style
counterparts (extended abstract). <em>IJCAI</em>, 4740–4744. (<a
href="https://doi.org/10.24963/ijcai.2021/642">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Semantics based on weak admissibility were recently introduced to overcome a problem with self-defeating arguments that has not been solved for more than 25 years. The recursive definition of weak admissibility mainly relies on the notion of a reduct regarding a set E which only contains arguments which are neither in E, nor attacked by E. At first glance the reduct seems to be tailored for the weaker versions of Dung-style semantics only. In this paper we show that standard Dung semantics can be naturally reformulated using the reduct revealing that this concept is already implicit. We further identify a new abstract principle for semantics, so-called modularization describing how to obtain further extensions given an initial one. Its importance for the study of abstract argumentation semantics is shown by its ability to alternatively characterize classical and non-classical semantics. Keywords: Knowledge Representation and Reasoning: Computational Models of Argument Knowledge Representation and Reasoning: Non-monotonic Reasoning},
  archive   = {C_IJCAI},
  author    = {Ringo Baumann and Gerhard Brewka and Markus Ulbricht},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/642},
  pages     = {4740-4744},
  title     = {Comparing weak admissibility semantics to their dung-style counterparts (Extended abstract)},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Defining the semantics of abstract argumentation frameworks
through logic programs and partial stable models (extended abstract).
<em>IJCAI</em>, 4735–4739. (<a
href="https://doi.org/10.24963/ijcai.2021/641">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Extensions of Dung’s Argumentation Framework (AF) include the class of Recursive Bipolar AFs (Rec-BAFs), i.e. AFs with recursive attacks and supports. We show that a Rec-BAF \Delta can be translated into a logic program P_\Delta so that the extensions of \Delta under different semantics coincide with subsets of the partial stable models of P_\Delta. Keywords: Knowledge Representation and Reasoning: Computational Models of Argument Knowledge Representation and Reasoning: Logics for Knowledge Representation Knowledge Representation and Reasoning: Knowledge Representation Languages},
  archive   = {C_IJCAI},
  author    = {Gianvincenzo Alfano and Sergio Greco and Francesco Parisi and Irina Trubitsyna},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/641},
  pages     = {4735-4739},
  title     = {Defining the semantics of abstract argumentation frameworks through logic programs and partial stable models (Extended abstract)},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hierarchical graph traversal for aggregate k nearest
neighbors search in road networks (extended abstract). <em>IJCAI</em>,
4730–4734. (<a href="https://doi.org/10.24963/ijcai.2021/640">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A k nearest neighbors (kNN) query finds k closest points-of-interest (POIs) from an agent&#39;s location. In this paper, we study a natural extension of the kNN query for multiple agents, namely, the Aggregate k Nearest Neighbors (AkNN) query. An AkNN query retrieves k POIs with the smallest aggregate distances where the aggregate distance of a POI is obtained by aggregating its distances from the multiple agents (e.g., sum of its distances from each agent). We propose a novel data structure COLT (Compacted Object-Landmark Tree) which enables efficient hierarchical graph traversal and utilize it to efficiently answer AkNN queries. Our experiments on real-world and synthetic data sets show that our techniques outperform existing approaches by more than an order of magnitude in almost all settings. Keywords: Heuristic Search and Game Playing: Heuristic Search Multidisciplinary Topics and Applications: Transportation Data Mining: Big Data, Large-Scale Systems},
  archive   = {C_IJCAI},
  author    = {Tenindra Abeywickrama and Muhammad Aamir Cheema and Sabine Storandt},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/640},
  pages     = {4730-4734},
  title     = {Hierarchical graph traversal for aggregate k nearest neighbors search in road networks (Extended abstract)},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cross-domain recommendation: Challenges, progress, and
prospects. <em>IJCAI</em>, 4721–4728. (<a
href="https://doi.org/10.24963/ijcai.2021/639">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {To address the long-standing data sparsity problem in recommender systems (RSs), cross-domain recommendation (CDR) has been proposed to leverage the relatively richer information from a richer domain to improve the recommendation performance in a sparser domain. Although CDR has been extensively studied in recent years, there is a lack of a systematic review of the existing CDR approaches. To fill this gap, in this paper, we provide a comprehensive review of existing CDR approaches, including challenges, research progress, and prospects. Specifically, we first summarize existing CDR approaches into four types, including single-target CDR, single-target multi-domain recommendation (MDR), dual-target CDR, and multi-target CDR. We then present the definitions and challenges of these CDR approaches. Next, we propose a full-view categorization and new taxonomies on these approaches and report their research progress in detail. In the end, we share several promising prospects in CDR. Keywords: Knowledge representation and reasoning: General Multidisciplinary topics and applications: General},
  archive   = {C_IJCAI},
  author    = {Feng Zhu and Yan Wang and Chaochao Chen and Jun Zhou and Longfei Li and Guanfeng Liu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/639},
  pages     = {4721-4728},
  title     = {Cross-domain recommendation: Challenges, progress, and prospects},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Topic modelling meets deep neural networks: A survey.
<em>IJCAI</em>, 4713–4720. (<a
href="https://doi.org/10.24963/ijcai.2021/638">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Topic modelling has been a successful technique for text analysis for almost twenty years. When topic modelling met deep neural networks, there emerged a new and increasingly popular research area, neural topic models, with nearly a hundred models developed and a wide range of applications in neural language understanding such as text generation, summarisation and language models. There is a need to summarise research developments and discuss open problems and future directions. In this paper, we provide a focused yet comprehensive overview of neural topic models for interested researchers in the AI community, so as to facilitate them to navigate and innovate in this fast-growing research area. To the best of our knowledge, ours is the first review on this specific topic. Keywords: Knowledge representation and reasoning: General Machine learning: General Natural language processing: General},
  archive   = {C_IJCAI},
  author    = {He Zhao and Dinh Phung and Viet Huynh and Yuan Jin and Lan Du and Wray Buntine},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/638},
  pages     = {4713-4720},
  title     = {Topic modelling meets deep neural networks: A survey},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021c). Automated machine learning on graphs: A survey.
<em>IJCAI</em>, 4704–4712. (<a
href="https://doi.org/10.24963/ijcai.2021/637">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Machine learning on graphs has been extensively studied    in both academic and industry. However, as the literature on graph learning booms with a vast number of emerging methods and techniques, it becomes increasingly difficult to manually design the optimal machine learning algorithm for different graph-related tasks. To solve this critical challenge, automated machine learning (AutoML) on graphs which combines the strength of graph machine learning and AutoML together, is gaining attention from the research community. Therefore, we comprehensively survey AutoML on graphs in this paper, primarily focusing on hyper-parameter optimization (HPO) and neural architecture search (NAS) for graph machine learning. We further overview libraries related to automated graph machine learning and in-depth discuss AutoGL, the first dedicated open-source library for AutoML on graphs. In the end, we share our insights on future research directions for automated graph machine learning. This paper is the first systematic and comprehensive review of automated machine learning on graphs to the best of our knowledge. Keywords: Machine learning: General},
  archive   = {C_IJCAI},
  author    = {Ziwei Zhang and Xin Wang and Wenwu Zhu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/637},
  pages     = {4704-4712},
  title     = {Automated machine learning on graphs: A survey},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep learning for click-through rate estimation.
<em>IJCAI</em>, 4695–4703. (<a
href="https://doi.org/10.24963/ijcai.2021/636">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Click-through rate (CTR) estimation plays as a core function module in various personalized online services, including online advertising, recommender systems, and web search etc. From 2015, the success of deep learning started to benefit CTR estimation performance and now deep CTR models have been widely applied in many industrial platforms. In this survey, we provide a comprehensive review of deep learning models for CTR estimation tasks. First, we take a review of the transfer from shallow to deep CTR models and explain why going deep is a necessary trend of development. Second, we concentrate on explicit feature interaction learning modules of deep CTR models. Then, as an important perspective on large platforms with abundant user histories, deep behavior models are discussed. Moreover, the recently emerged automated methods for deep CTR architecture design are presented. Finally, we summarize the survey and discuss the future prospects of this field. Keywords: Machine learning: General Multidisciplinary topics and applications: General},
  archive   = {C_IJCAI},
  author    = {Weinan Zhang and Jiarui Qin and Wei Guo and Ruiming Tang and Xiuqiang He},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/636},
  pages     = {4695-4703},
  title     = {Deep learning for click-through rate estimation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey on universal adversarial attack. <em>IJCAI</em>,
4687–4694. (<a href="https://doi.org/10.24963/ijcai.2021/635">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The intriguing phenomenon of adversarial examples has attracted significant attention in machine learning and what might be more surprising to the community is the existence of universal adversarial perturbations (UAPs), i.e. a single perturbation to fool the target DNN for most images. With the focus on UAP against deep classifiers, this survey summarizes the recent progress on universal adversarial attacks, discussing the challenges from both the attack and defense sides, as well as the reason for the existence of UAP. We aim to extend this work as a dynamic survey that will regularly update its content to follow new works regarding UAP or universal attack in a wide range of domains, such as image, audio, video, text, etc. Relevant updates will be discussed at: https://bit.ly/2SbQlLG. We welcome authors of future works in this field to contact us for including your new findings. Keywords: Machine learning: General Computer vision: General},
  archive   = {C_IJCAI},
  author    = {Chaoning Zhang and Philipp Benz and Chenguo Lin and Adil Karjauv and Jing Wu and In So Kweon},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/635},
  pages     = {4687-4694},
  title     = {A survey on universal adversarial attack},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A comparative survey: Benchmarking for pool-based active
learning. <em>IJCAI</em>, 4679–4686. (<a
href="https://doi.org/10.24963/ijcai.2021/634">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Active learning (AL) is a subfield of machine learning (ML) in which a learning algorithm aims to achieve good accuracy with fewer training samples by interactively querying the oracles to label new data points. Pool-based AL is well-motivated in many ML tasks, where unlabeled data is abundant, but their labels are hard or costly to obtain. Although many pool-based AL methods have been developed, some important questions remain unanswered such as how to: 1) determine the current state-of-the-art technique; 2) evaluate the relative benefit of new methods for various properties of the dataset; 3) understand what specific problems merit greater attention; and 4) measure the progress of the field over time. In this paper, we survey and compare various AL strategies used in both recently proposed and classic highly-cited methods. We propose to benchmark pool-based AL methods with a variety of datasets and quantitative metric, and draw insights from the comparative empirical results. Keywords: Machine learning: General},
  archive   = {C_IJCAI},
  author    = {Xueying Zhan and Huan Liu and Qing Li and Antoni B. Chan},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/634},
  pages     = {4679-4686},
  title     = {A comparative survey: Benchmarking for pool-based active learning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Information-theoretic methods in deep neural networks:
Recent advances and emerging opportunities. <em>IJCAI</em>, 4669–4678.
(<a href="https://doi.org/10.24963/ijcai.2021/633">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present a review on the recent advances and emerging opportunities around the theme of analyzing deep neural networks (DNNs) with information-theoretic methods. We first discuss popular information-theoretic quantities and their estimators. We then introduce recent developments on information-theoretic learning principles (e.g., loss functions, regularizers and objectives) and their parameterization with DNNs. We finally briefly review current usages of information-theoretic concepts in a few modern machine learning problems and list a few emerging opportunities. Keywords: Machine learning: General},
  archive   = {C_IJCAI},
  author    = {Shujian Yu and Luis Sanchez Giraldo and Jose Principe},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/633},
  pages     = {4669-4678},
  title     = {Information-theoretic methods in deep neural networks: Recent advances and emerging opportunities},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Challenges and opportunities of building fast GBDT systems.
<em>IJCAI</em>, 4661–4668. (<a
href="https://doi.org/10.24963/ijcai.2021/632">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the last few years, Gradient Boosting Decision Trees (GBDTs) have been widely used in various applications such as online advertising and spam filtering. However, GBDT training is often a key performance bottleneck for such data science pipelines, especially for training a large number of deep trees on large data sets. Thus, many parallel and distributed GBDT systems have been researched and developed to accelerate the training process. In this survey paper, we review the recent GBDT systems with respect to accelerations with emerging hardware as well as cluster computing, and compare the advantages and disadvantages of the existing implementations. Finally, we present the research opportunities and challenges in designing fast next generation GBDT systems. Keywords: Machine learning: General},
  archive   = {C_IJCAI},
  author    = {Zeyi Wen and Qinbin Li and Bingsheng He and Bin Cui},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/632},
  pages     = {4661-4668},
  title     = {Challenges and opportunities of building fast GBDT systems},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Time series data augmentation for deep learning: A survey.
<em>IJCAI</em>, 4653–4660. (<a
href="https://doi.org/10.24963/ijcai.2021/631">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep learning performs remarkably well on many time series analysis tasks recently. The superior performance of deep neural networks relies heavily on a large number of training data to avoid overfitting. However, the labeled data of many real-world time series applications may be limited such as classification in medical time series and anomaly detection in AIOps. As an effective way to enhance the size and quality of the training data, data augmentation is crucial to the successful application of deep learning models on time series data. In this paper, we systematically review different data augmentation methods for time series. We propose a taxonomy for the reviewed methods, and then provide a structured review for these methods by highlighting their strengths and limitations. We also empirically compare different data augmentation methods for different tasks including time series classification, anomaly detection, and forecasting. Finally, we discuss and highlight five future directions to provide useful research guidance. Keywords: Machine learning: General Multidisciplinary topics and applications: General Knowledge representation and reasoning: General},
  archive   = {C_IJCAI},
  author    = {Qingsong Wen and Liang Sun and Fan Yang and Xiaomin Song and Jingkun Gao and Xue Wang and Huan Xu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/631},
  pages     = {4653-4660},
  title     = {Time series data augmentation for deep learning: A survey},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Graph learning based recommender systems: A review.
<em>IJCAI</em>, 4644–4652. (<a
href="https://doi.org/10.24963/ijcai.2021/630">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent years have witnessed the fast development of the emerging topic of Graph Learning based Recommender Systems (GLRS). GLRS mainly employ advanced graph learning approaches to model users’ preferences and intentions as well as items’ characteristics and popularity for Recommender Systems (RS). Differently from other approaches, including content based filtering and collaborative filtering, GLRS are built on graphs where the important objects, e.g., users, items, and attributes, are either explicitly or implicitly connected. With the rapid development of graph learning techniques, exploring and exploiting homogeneous or heterogeneous relations in graphs is a promising direction for building more effective RS. In this paper, we provide a systematic review of GLRS, by discussing how they extract knowledge from graphs to improve the accuracy, reliability and explainability of the recommendations. First, we characterize and formalize GLRS, and then summarize and categorize the key challenges and main progress in this novel research area. Keywords: Machine learning: General Multidisciplinary topics and applications: General Knowledge representation and reasoning: General Planning and scheduling: General},
  archive   = {C_IJCAI},
  author    = {Shoujin Wang and Liang Hu and Yan Wang and Xiangnan He and Quan Z. Sheng and Mehmet A. Orgun and Longbing Cao and Francesco Ricci and Philip S. Yu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/630},
  pages     = {4644-4652},
  title     = {Graph learning based recommender systems: A review},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey on low-resource neural machine translation.
<em>IJCAI</em>, 4636–4643. (<a
href="https://doi.org/10.24963/ijcai.2021/629">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Neural approaches have achieved state-of-the-art accuracy on machine translation but suffer from the high cost of collecting large scale parallel data. Thus, a lot of research has been conducted for neural machine translation (NMT) with very limited parallel data, i.e., the low-resource setting. In this paper, we provide a survey for low-resource NMT and classify related works into three categories according to the auxiliary data they used: (1) exploiting monolingual data of source and/or target languages, (2) exploiting data from auxiliary languages, and (3) exploiting multi-modal data. We hope that our survey can help researchers to better understand this field and inspire them to design better algorithms, and help industry practitioners to choose appropriate algorithms for their applications. Keywords: Natural language processing: General Machine learning: General},
  archive   = {C_IJCAI},
  author    = {Rui Wang and Xu Tan and Renqian Luo and Tao Qin and Tie-Yan Liu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/629},
  pages     = {4636-4643},
  title     = {A survey on low-resource neural machine translation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Generalizing to unseen domains: A survey on domain
generalization. <em>IJCAI</em>, 4627–4635. (<a
href="https://doi.org/10.24963/ijcai.2021/628">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Domain generalization (DG), i.e., out-of-distribution generalization, has attracted increased interests in recent years. Domain generalization deals with a challenging setting where one or several different but related domain(s) are given, and the goal is to learn a model that can generalize to an unseen test domain. For years, great progress has been achieved. This paper presents the first review for recent advances in domain generalization. First, we provide a formal definition of domain generalization and discuss several related fields. Then, we categorize recent algorithms into three classes and present them in detail: data manipulation, representation learning, and learning strategy, each of which contains several popular algorithms. Third, we introduce the commonly used datasets and applications. Finally, we summarize existing literature and present some potential research topics for the future. Keywords: Computer vision: General Machine learning: General},
  archive   = {C_IJCAI},
  author    = {Jindong Wang and Cuiling Lan and Chang Liu and Yidong Ouyang and Tao Qin},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/628},
  pages     = {4627-4635},
  title     = {Generalizing to unseen domains: A survey on domain generalization},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey on response selection for retrieval-based
dialogues. <em>IJCAI</em>, 4619–4626. (<a
href="https://doi.org/10.24963/ijcai.2021/627">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Building an intelligent dialogue system capable of naturally and coherently conversing with humans has been a long-standing goal of artificial intelligence. In the past decade, with the development of machine/deep learning technology and the explosive growth of available conversation data in social media, numerous neural models have been developed for context-response matching tasks in retrieval-based dialogue systems, with more fluent and informative responses compared with generative models. This paper presents a comprehensive survey of recent advances in response selection for retrieval-based dialogues. In particular, we first formulate the problem of response selection and review state-of-the-art context-response matching models categorized by their architecture. Then we summarize some recent advances on the research of response selection, including incorporation with extra knowledge and exploration on more effective model learning. Finally, we highlight the challenges which are not yet well addressed in this task and present future research directions. Keywords: Natural language processing: General},
  archive   = {C_IJCAI},
  author    = {Chongyang Tao and Jiazhan Feng and Rui Yan and Wei Wu and Daxin Jiang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/627},
  pages     = {4619-4626},
  title     = {A survey on response selection for retrieval-based dialogues},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Tournaments in computational social choice: Recent
developments. <em>IJCAI</em>, 4611–4618. (<a
href="https://doi.org/10.24963/ijcai.2021/626">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Tournaments are commonly used to select winning alternatives in scenarios involving pairwise comparisons such as sports competitions and political elections. This survey discusses recent developments in two major lines of work—tournament solutions and single-elimination tournaments—with a focus on how computational social choice has brought new frameworks and perspectives into these decades-old studies. Keywords: Agent-based and multi-agent based systems: General},
  archive   = {C_IJCAI},
  author    = {Warut Suksompong},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/626},
  pages     = {4611-4618},
  title     = {Tournaments in computational social choice: Recent developments},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A unifying bayesian formulation of measures of
interpretability in human-AI interaction. <em>IJCAI</em>, 4602–4610. (<a
href="https://doi.org/10.24963/ijcai.2021/625">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Existing approaches for generating human-aware agent behaviors have considered different measures of interpretability in isolation. Further, these measures have been studied under differing assumptions, thus precluding the possibility of designing a single framework that captures these measures under the same assumptions. In this paper, we present a unifying Bayesian framework that models a human observer&#39;s evolving beliefs about an agent and thereby define the problem of Generalized Human-Aware Planning. We will show that the definitions of interpretability measures like explicability, legibility and predictability from the prior literature fall out as special cases of our general framework. Through this framework, we also bring a previously ignored fact to light that the human-robot interactions are in effect open-world problems, particularly as a result of modeling the human&#39;s beliefs over the agent. Since the human may not only hold beliefs unknown to the agent but may also form new hypotheses about the agent when presented with novel or unexpected behaviors. Keywords: Humans and AI: General Planning and scheduling: General},
  archive   = {C_IJCAI},
  author    = {Sarath Sreedharan and Anagha Kulkarni and David Smith and Subbarao Kambhampati},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/625},
  pages     = {4602-4610},
  title     = {A unifying bayesian formulation of measures of interpretability in human-AI interaction},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Qualitative spatial and temporal reasoning: Current status
and future challenges. <em>IJCAI</em>, 4594–4601. (<a
href="https://doi.org/10.24963/ijcai.2021/624">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Qualitative Spatial &amp; Temporal Reasoning (QSTR) is a major field of study in Symbolic AI that deals with the representation and reasoning of spatio- temporal information in an abstract, human-like manner. We survey the current status of QSTR from a viewpoint of reasoning approaches, and identify certain future challenges that we think that, once overcome, will allow the field to meet the demands of and adapt to real-world, dynamic, and time-critical applications of highly active areas such as machine learning and data mining. Keywords: Knowledge representation and reasoning: General},
  archive   = {C_IJCAI},
  author    = {Michael Sioutis and Diedrich Wolter},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/624},
  pages     = {4594-4601},
  title     = {Qualitative spatial and temporal reasoning: Current status and future challenges},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Neural temporal point processes: A review. <em>IJCAI</em>,
4585–4593. (<a href="https://doi.org/10.24963/ijcai.2021/623">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Temporal point processes (TPP) are probabilistic generative models for continuous-time event sequences. Neural TPPs combine the fundamental ideas from point process literature with deep learning approaches, thus enabling construction of flexible and efficient models. The topic of neural TPPs has attracted significant attention in the recent years, leading to the development of numerous new architectures and applications for this class of models. In this review paper we aim to consolidate the existing body of knowledge on neural TPPs. Specifically, we focus on important design choices and general principles for defining neural TPP models. Next, we provide an overview of application areas commonly considered in the literature. We conclude this survey with the list of open challenges and important directions for future work in the field of neural TPPs. Keywords: Machine learning: General},
  archive   = {C_IJCAI},
  author    = {Oleksandr Shchur and Ali Caner Türkmen and Tim Januschowski and Stephan Günnemann},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/623},
  pages     = {4585-4593},
  title     = {Neural temporal point processes: A review},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey on spoken language understanding: Recent advances
and new frontiers. <em>IJCAI</em>, 4577–4584. (<a
href="https://doi.org/10.24963/ijcai.2021/622">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Spoken Language Understanding (SLU) aims to extract the semantics frame of user queries, which is a core component in a task-oriented dialog system. With the burst of deep neural networks and the evolution of pre-trained language models, the research of SLU has obtained signiﬁcant breakthroughs. However, there remains a lack of a comprehensive survey summarizing existing approaches and recent trends, which motivated the work presented in this article. In this paper, we survey recent advances and new frontiers in SLU. Specifically, we give a thorough review of this research ﬁeld, covering different aspects including (1) new taxonomy: we provide a new perspective for SLU ﬁled, including single model vs. joint model, implicit joint modeling vs. explicit joint modeling in joint model, non pre-trained paradigm vs. pretrained paradigm; (2) new frontiers: some emerging areas in complex SLU as well as the corresponding challenges; (3) abundant open-source resources: to help the community, we have collected, organized the related papers, baseline projects and leaderboard on a public website where SLU researchers could directly access to the recent progress. We hope that this survey can shed a light on future research in SLU ﬁeld. Keywords: Natural language processing: General},
  archive   = {C_IJCAI},
  author    = {Libo Qin and Tianbao Xie and Wanxiang Che and Ting Liu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/622},
  pages     = {4577-4584},
  title     = {A survey on spoken language understanding: Recent advances and new frontiers},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Analogical proportions: Why they are useful in AI.
<em>IJCAI</em>, 4568–4576. (<a
href="https://doi.org/10.24963/ijcai.2021/621">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper presents a survey of researches in analogical reasoning whose building block are analogical proportions which are statements of the form “a is to b as c is to d”. They have been developed in the last twenty years within an Artificial Intelligence perspective. After discussing their formal modeling with the associated inference mechanism, the paper reports the main results obtained in various AI domains ranging from computational linguistics to classification, including image processing, I.Q. tests, case based reasoning, preference learning, and formal concepts analysis. The last section discusses some new theoretical concerns, and the potential of analogical proportions in other areas such as argumentation, transfer learning, and XAI. Keywords: Knowledge representation and reasoning: General Multidisciplinary topics and applications: General},
  archive   = {C_IJCAI},
  author    = {Henri Prade and Gilles Richard},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/621},
  pages     = {4568-4576},
  title     = {Analogical proportions: Why they are useful in AI},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ten years of BabelNet: A survey. <em>IJCAI</em>, 4559–4567.
(<a href="https://doi.org/10.24963/ijcai.2021/620">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The intelligent manipulation of symbolic knowledge has been a long-sought goal of AI. However, when it comes to Natural Language Processing (NLP), symbols have to be mapped to words and phrases, which are not only ambiguous but also language-specific: multilinguality is indeed a desirable property for NLP systems, and one which enables the generalization of tasks where multiple languages need to be dealt with, without translating text. In this paper we survey BabelNet, a popular wide-coverage lexical-semantic knowledge resource obtained by merging heterogeneous sources into a unified semantic network that helps to scale tasks and applications to hundreds of languages. Over its ten years of existence, thanks to its promise to interconnect languages and resources in structured form, BabelNet has been employed in countless ways and directions. We first introduce the BabelNet model, its components and statistics, and then overview its successful use in a wide range of tasks in NLP as well as in other fields of AI. Keywords: Natural language processing: General},
  archive   = {C_IJCAI},
  author    = {Roberto Navigli and Michele Bevilacqua and Simone Conia and Dario Montagnini and Francesco Cecconi},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/620},
  pages     = {4559-4567},
  title     = {Ten years of BabelNet: A survey},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automated fact-checking for assisting human fact-checkers.
<em>IJCAI</em>, 4551–4558. (<a
href="https://doi.org/10.24963/ijcai.2021/619">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The reporting and the analysis of current events around the globe has expanded from professional, editor-lead journalism all the way to citizen journalism. Nowadays, politicians and other key players enjoy direct access to their audiences through social media, bypassing the filters of official cables or traditional media. However, the multiple advantages of free speech and direct communication are dimmed by the misuse of media to spread inaccurate or misleading claims. These phenomena have led to the modern incarnation of the fact-checker --- a professional whose main aim is to examine claims using available evidence and to assess their veracity. Here, we survey the available intelligent technologies that can support the human expert in the different steps of her fact-checking endeavor. These include identifying claims worth fact-checking, detecting relevant previously fact-checked claims, retrieving relevant evidence to fact-check a claim, and actually verifying a claim. In each case, we pay attention to the challenges and the potential impact on real-world fact-checking. Keywords: Machine learning: General Natural language processing: General},
  archive   = {C_IJCAI},
  author    = {Preslav Nakov and David Corney and Maram Hasanain and Firoj Alam and Tamer Elsayed and Alberto Barrón-Cedeño and Paolo Papotti and Shaden Shaar and Giovanni Da San Martino},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/619},
  pages     = {4551-4558},
  title     = {Automated fact-checking for assisting human fact-checkers},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The power of the weisfeiler-leman algorithm for machine
learning with graphs. <em>IJCAI</em>, 4543–4550. (<a
href="https://doi.org/10.24963/ijcai.2021/618">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In recent years, algorithms and neural architectures based on the Weisfeiler-Leman algorithm, a well-known heuristic for the graph isomorphism problem, emerged as a powerful tool for (supervised) machine learning with graphs and relational data. Here, we give a comprehensive overview of the algorithm&#39;s use in a machine learning setting. We discuss the theoretical background, show how to use it for supervised graph- and node classification, discuss recent extensions, and its connection to neural architectures. Moreover, we give an overview of current applications and future directions to stimulate research. Keywords: Machine learning: General},
  archive   = {C_IJCAI},
  author    = {Christopher Morris and Matthias Fey and Nils Kriege},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/618},
  pages     = {4543-4550},
  title     = {The power of the weisfeiler-leman algorithm for machine learning with graphs},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hybrid probabilistic inference with logical and algebraic
constraints: A survey. <em>IJCAI</em>, 4533–4542. (<a
href="https://doi.org/10.24963/ijcai.2021/617">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Real world decision making problems often involve both discrete and continuous variables and require a combination of probabilistic and deterministic knowledge. Stimulated by recent advances in automated reasoning technology, hybrid (discrete+continuous) probabilistic reasoning with constraints has emerged as a lively and fast growing research field. In this paper we provide a survey of existing techniques for hybrid probabilistic inference with logic and algebraic constraints. We leverage weighted model integration as a unifying formalism and discuss the different paradigms that have been used as well as the expressivity-efficiency trade-offs that have been investigated. We conclude the survey with a comparative overview of existing implementations and a critical discussion of open challenges and promising research directions. Keywords: Uncertainty in AI: General Knowledge representation and reasoning: General Constraints and SAT: General},
  archive   = {C_IJCAI},
  author    = {Paolo Morettin and Pedro Zuidberg Dos Martires and Samuel Kolb and Andrea Passerini},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/617},
  pages     = {4533-4542},
  title     = {Hybrid probabilistic inference with logical and algebraic constraints: A survey},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey on goal recognition as planning. <em>IJCAI</em>,
4524–4532. (<a href="https://doi.org/10.24963/ijcai.2021/616">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Goal Recognition is the task of inferring an agent&#39;s goal, from a set of hypotheses, given a model of the environment dynamic, and a sequence of observations of such agent&#39;s behavior. While research on this problem gathered momentum as an offshoot of plan recognition, recent research has established it as a major subject of research on its own, leading to numerous new approaches that both expand the expressivity of domains in which to perform goal recognition and substantial advances to the state-of-the-art on established domain types. In this survey, we focus on the advances to goal recognition achieved in the last decade, categorizing the resulting techniques and identifying a number of opportunities for further breakthrough research. Keywords: Planning and scheduling: General Agent-based and multi-agent based systems: General},
  archive   = {C_IJCAI},
  author    = {Felipe Meneguzzi and Ramon Fraga Pereira},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/616},
  pages     = {4524-4532},
  title     = {A survey on goal recognition as planning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). What’s the context? Implicit and explicit assumptions in
model-based goal recognition. <em>IJCAI</em>, 4516–4523. (<a
href="https://doi.org/10.24963/ijcai.2021/615">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Every model involves assumptions. While some are standard to all models that simulate intelligent decision-making (e.g., discrete/continuous, static/dynamic), goal recognition is well known also to involve choices about the observed agent: is it aware of being observed? cooperative or adversarial? In this paper, we examine not only these but the many other assumptions made in the context of model-based goal recognition. By exploring their meaning, the relationships between them and the confusions that can arise, we demonstrate their importance, shed light on the way trends emerge in AI, and suggest a novel means for researchers to uncover suitable avenues for future work. Keywords: Agent-based and multi-agent based systems: General Humans and AI: General Planning and scheduling: General},
  archive   = {C_IJCAI},
  author    = {Peta Masters and Mor Vered},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/615},
  pages     = {4516-4523},
  title     = {What’s the context? implicit and explicit assumptions in model-based goal recognition},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Policy learning with constraints in model-free reinforcement
learning: A survey. <em>IJCAI</em>, 4508–4515. (<a
href="https://doi.org/10.24963/ijcai.2021/614">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Reinforcement Learning (RL) algorithms have had tremendous success in simulated domains. These algorithms, however, often cannot be directly applied to physical systems, especially in cases where there are constraints to satisfy (e.g. to ensure safety or limit resource consumption). In standard RL, the agent is incentivized to explore any policy with the sole goal of maximizing reward; in the real world, however, ensuring satisfaction of certain constraints in the process is also necessary and essential. In this article, we overview existing approaches addressing constraints in model-free reinforcement learning. We model the problem of learning with constraints as a Constrained Markov Decision Process and consider two main types of constraints: cumulative and instantaneous. We summarize existing approaches and discuss their pros and cons. To evaluate policy performance under constraints, we introduce a set of standard benchmarks and metrics. We also summarize limitations of current methods and present open questions for future research. Keywords: Machine learning: General Constraints and SAT: General Planning and scheduling: General},
  archive   = {C_IJCAI},
  author    = {Yongshuai Liu and Avishai Halev and Xin Liu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/614},
  pages     = {4508-4515},
  title     = {Policy learning with constraints in model-free reinforcement learning: A survey},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Person search challenges and solutions: A survey.
<em>IJCAI</em>, 4500–4507. (<a
href="https://doi.org/10.24963/ijcai.2021/613">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Person search has drawn increasing attention due to its real-world applications and research significance. Person search aims to find a probe person in a gallery of scene images with a wide range of applications, such as criminals search, multicamera tracking, missing person search, etc. Early person search works focused on image-based person search, which uses person image as the search query. Text-based person search is another major person search category that uses free-form natural language as the search query. Person search is challenging, and corresponding solutions are diverse and complex. Therefore, systematic surveys on this topic are essential. This paper surveyed the recent works on image-based and text-based person search from the perspective of challenges and solutions. Specifically, we provide a brief analysis of highly influential person search methods considering the three significant challenges: the discriminative person features, the query-person gap, and the detection-identification inconsistency. We summarise and compare evaluation results. Finally, we discuss open issues and some promising future research directions. Keywords: Computer vision: General Machine learning: General Natural language processing: General},
  archive   = {C_IJCAI},
  author    = {Xiangtan Lin and Pengzhen Ren and Yun Xiao and Xiaojun Chang and Alex Hauptmann},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/613},
  pages     = {4500-4507},
  title     = {Person search challenges and solutions: A survey},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Pretrained language model for text generation: A survey.
<em>IJCAI</em>, 4492–4499. (<a
href="https://doi.org/10.24963/ijcai.2021/612">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Text generation has become one of the most important yet challenging tasks in natural language processing (NLP). The resurgence of deep learning has greatly advanced this field by neural generation models, especially the paradigm of pretrained language models (PLMs). In this paper, we present an overview of the major advances achieved in the topic of PLMs for text generation. As the preliminaries, we present the general task definition and briefly describe the mainstream architectures of PLMs for text generation. As the core content, we discuss how to adapt existing PLMs to model different input data and satisfy special properties in the generated text. We further summarize several important fine-tuning strategies for text generation. Finally, we present several future directions and conclude this paper. Our survey aims to provide text generation researchers a synthesis and pointer to related research. Keywords: Natural language processing: General},
  archive   = {C_IJCAI},
  author    = {Junyi Li and Tianyi Tang and Wayne Xin Zhao and Ji-Rong Wen},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/612},
  pages     = {4492-4499},
  title     = {Pretrained language model for text generation: A survey},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey on complex knowledge base question answering:
Methods, challenges and solutions. <em>IJCAI</em>, 4483–4491. (<a
href="https://doi.org/10.24963/ijcai.2021/611">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Knowledge base question answering (KBQA) aims to answer a question over a knowledge base (KB). Recently, a large number of studies focus on semantically or syntactically complicated questions. In this paper, we elaborately summarize the typical challenges and solutions for complex KBQA. We begin with introducing the background about the KBQA task. Next, we present the two mainstream categories of methods for complex KBQA, namely semantic parsing-based (SP-based) methods and information retrieval-based (IR-based) methods. We then review the advanced methods comprehensively from the perspective of the two categories. Specifically, we explicate their solutions to the typical challenges. Finally, we conclude and discuss some promising directions for future research. Keywords: Knowledge representation and reasoning: General Natural language processing: General},
  archive   = {C_IJCAI},
  author    = {Yunshi Lan and Gaole He and Jinhao Jiang and Jing Jiang and Wayne Xin Zhao and Ji-Rong Wen},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/611},
  pages     = {4483-4491},
  title     = {A survey on complex knowledge base question answering: Methods, challenges and solutions},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). End-to-end constrained optimization learning: A survey.
<em>IJCAI</em>, 4475–4482. (<a
href="https://doi.org/10.24963/ijcai.2021/610">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper surveys the recent attempts at leveraging machine learning to solve constrained optimization problems. It focuses on surveying the work on integrating combinatorial solvers and optimization methods with machine learning architectures. These approaches hold the promise to develop new hybrid machine learning and optimization methods to predict fast, approximate, solutions to combinatorial problems and to enable structural logical inference. This paper presents a conceptual review of the recent advancements in this emerging area. Keywords: Constraints and SAT: General Machine learning: General},
  archive   = {C_IJCAI},
  author    = {James Kotary and Ferdinando Fioretto and Pascal Van Hentenryck and Bryan Wilder},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/610},
  pages     = {4475-4482},
  title     = {End-to-end constrained optimization learning: A survey},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). If only we had better counterfactual explanations: Five key
deficits to rectify in the evaluation of counterfactual XAI techniques.
<em>IJCAI</em>, 4466–4474. (<a
href="https://doi.org/10.24963/ijcai.2021/609">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In recent years, there has been an explosion of AI research on counterfactual explanations as a solution to the problem of eXplainable AI (XAI). These explanations seem to offer technical, psychological and legal benefits over other explanation techniques. We survey 100 distinct counterfactual explanation methods reported in the literature. This survey addresses the extent to which these methods have been adequately evaluated, both psychologically and computationally, and quantifies the shortfalls occurring. For instance, only 21\% of these methods have been user tested. Five key deficits in the evaluation of these methods are detailed and a roadmap, with standardised benchmark evaluations, is proposed to resolve the issues arising; issues, that currently effectively block scientific progress in this field. Keywords: Humans and AI: General Machine learning: General},
  archive   = {C_IJCAI},
  author    = {Mark T. Keane and Eoin M. Kenny and Eoin Delaney and Barry Smyth},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/609},
  pages     = {4466-4474},
  title     = {If only we had better counterfactual explanations: Five key deficits to rectify in the evaluation of counterfactual XAI techniques},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reasoning-based learning of interpretable ML models.
<em>IJCAI</em>, 4458–4465. (<a
href="https://doi.org/10.24963/ijcai.2021/608">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Artificial Intelligence (AI) is widely used in decision making procedures in myriads of real-world applications across important practical areas such as finance, healthcare, education, and safety critical systems. Due to its ubiquitous use in safety and privacy critical domains, it is often vital to understand the reasoning behind the AI decisions, which motivates the need for explainable AI (XAI). One of the major approaches to XAI is represented by computing so-called interpretable machine learning (ML) models, such as decision trees (DT), decision lists (DL) and decision sets (DS). These models build on the use of if-then rules and are thus deemed to be easily understandable by humans. A number of approaches have been proposed in the recent past to devising all kinds of interpretable ML models, the most prominent of which involve encoding the problem into a logic formalism, which is then tackled by invoking a reasoning or discrete optimization procedure. This paper overviews the recent advances of the reasoning and constraints based approaches to learning interpretable ML models and discusses their advantages and limitations. Keywords: Constraints and SAT: General Knowledge representation and reasoning: General Machine learning: General},
  archive   = {C_IJCAI},
  author    = {Alexey Ignatiev and Joao Marques-Silva and Nina Narodytska and Peter J. Stuckey},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/608},
  pages     = {4458-4465},
  title     = {Reasoning-based learning of interpretable ML models},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal transport for deep generative models: State of the
art and research challenges. <em>IJCAI</em>, 4450–4457. (<a
href="https://doi.org/10.24963/ijcai.2021/607">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Optimal transport has a long history in mathematics which was proposed by Gaspard Monge in the eighteenth century (Monge, 1781). However, until recently, advances in optimal transport theory pave the way for its use in the AI community, particularly for formulating deep generative models. In this paper, we provide a comprehensive overview of the literature in the field of deep generative models using optimal transport theory with an aim of providing a systematic review as well as outstanding problems and more importantly, open research opportunities to use the tools from the established optimal transport theory in the deep generative model domain. Keywords: Machine learning: General},
  archive   = {C_IJCAI},
  author    = {Viet Huynh and Dinh Phung and He Zhao},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/607},
  pages     = {4450-4457},
  title     = {Optimal transport for deep generative models: State of the art and research challenges},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Recent advances in heterogeneous relation learning for
recommendation. <em>IJCAI</em>, 4442–4449. (<a
href="https://doi.org/10.24963/ijcai.2021/606">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recommender systems have played a critical role in many web applications to meet user&#39;s personalized interests and alleviate the information overload. In this survey, we review the development of recommendation frameworks with the focus on heterogeneous relational learning, which consists of different types of dependencies among users and items. The objective of this task is to map heterogeneous relational data into latent representation space, such that the structural and relational properties from both user and item domain can be well preserved. To address this problem, recent research developments can fall into three major categories: social recommendation, knowledge graph-enhanced recommender system, and multi-behavior recommendation. We discuss the learning approaches in each category, such as matrix factorization, attention mechanism and graph neural networks, for effectively distilling heterogeneous contextual information. Finally, we present exploratory outlook to highlight several promising directions and opportunities in heterogeneous relational learning frameworks for recommendation. Keywords: Knowledge representation and reasoning: General},
  archive   = {C_IJCAI},
  author    = {Chao Huang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/606},
  pages     = {4442-4449},
  title     = {Recent advances in heterogeneous relation learning for recommendation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Emerging methods of auction design in social networks.
<em>IJCAI</em>, 4434–4441. (<a
href="https://doi.org/10.24963/ijcai.2021/605">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In recent years, a new branch of auction models called diffusion auction has extended the traditional auction into social network scenarios. The diffusion auction models the auction as a networked market whose nodes are potential customers and whose edges are the relations between these customers. The diffusion auction mechanism can incentivize buyers to not only submit a truthful bid, but also further invite their surrounding neighbors to participate into the auction. It can convene more participants than traditional auction mechanisms, which leads to better optimizations of different key aspects, such as social welfare, seller’s revenue, amount of redistributed money and so on. The diffusion auctions have recently attracted a discrete interest in the algorithmic game theory and market design communities. This survey summarizes the current progress of diffusion auctions. Keywords: Agent-based and multi-agent based systems: General},
  archive   = {C_IJCAI},
  author    = {Yuhang Guo and Dong Hao},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/605},
  pages     = {4434-4441},
  title     = {Emerging methods of auction design in social networks},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A comprehensive survey on image dehazing based on deep
learning. <em>IJCAI</em>, 4426–4433. (<a
href="https://doi.org/10.24963/ijcai.2021/604">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The presence of haze significantly reduces the quality of images. Researchers have designed a variety of algorithms for image dehazing (ID) to restore the quality of hazy images. However, there are few studies that summarize the deep learning (DL) based dehazing technologies. In this paper, we conduct a comprehensive survey on the recent proposed dehazing methods. Firstly, we conclude the commonly used datasets, loss functions and evaluation metrics. Secondly, we group the existing researches of ID into two major categories: supervised ID and unsupervised ID. The core ideas of various influential dehazing models are introduced. Finally, the open issues for future research on ID are pointed out. Keywords: Computer vision: General Machine learning: General},
  archive   = {C_IJCAI},
  author    = {Jie Gui and Xiaofeng Cong and Yuan Cao and Wenqi Ren and Jun Zhang and Jing Zhang and Dacheng Tao},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/604},
  pages     = {4426-4433},
  title     = {A comprehensive survey on image dehazing based on deep learning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Where is your place, visual place recognition?
<em>IJCAI</em>, 4416–4425. (<a
href="https://doi.org/10.24963/ijcai.2021/603">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Visual Place Recognition (VPR) is often characterized as being able to recognize the same place despite significant changes in appearance and viewpoint. VPR is a key component of Spatial Artificial Intelligence, enabling robotic platforms and intelligent augmentation platforms such as augmented reality devices to perceive and understand the physical world. In this paper, we observe that there are three &quot;drivers&quot; that impose requirements on spatially intelligent agents and thus VPR systems: 1) the particular agent including its sensors and computational resources, 2) the operating environment of this agent, and 3) the specific task that the artificial agent carries out. In this paper, we characterize and survey key works in the VPR area considering those drivers, including their place representation and place matching choices. We also provide a new definition of VPR based on the visual overlap - akin to spatial view cells in the brain - that enables us to find similarities and differences to other research areas in the robotics and computer vision fields. We identify several open challenges and suggest areas that require more in-depth attention in future works. Keywords: Computer vision: General Robotics: General},
  archive   = {C_IJCAI},
  author    = {Sourav Garg and Tobias Fischer and Michael Milford},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/603},
  pages     = {4416-4425},
  title     = {Where is your place, visual place recognition?},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bayesian nonparametric space partitions: A survey.
<em>IJCAI</em>, 4408–4415. (<a
href="https://doi.org/10.24963/ijcai.2021/602">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Bayesian nonparametric space partition (BNSP) models provide a variety of strategies for partitioning a D-dimensional space into a set of blocks, such that the data within the same block share certain kinds of homogeneity. BNSP models are applicable to many areas, including regression/classification trees, random feature construction, and relational modelling. This survey provides the first comprehensive review of this subject. We explore the current progress of BNSP research through three perspectives: (1) Partition strategies, where we review the various techniques for generating partitions and discuss their theoretical foundation, `self-consistency&#39;; (2) Applications, where we detail the current mainstream usages of BNSP models and identify some potential future applications; and (3) Challenges, where we discuss current unsolved problems and possible avenues for future research. Keywords: Machine learning: General},
  archive   = {C_IJCAI},
  author    = {Xuhui Fan and Bin Li and Ling Luo and Scott A. Sisson},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/602},
  pages     = {4408-4415},
  title     = {Bayesian nonparametric space partitions: A survey},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Explanation in constraint satisfaction: A survey.
<em>IJCAI</em>, 4400–4407. (<a
href="https://doi.org/10.24963/ijcai.2021/601">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Much of the focus on explanation in the field of artificial intelligence has focused on machine learning methods and, in particular, concepts produced by advanced methods such as neural networks and deep learning. However, there has been a long history of explanation generation in the general field of constraint satisfaction, one of the AI&#39;s most ubiquitous subfields. In this paper we survey the major seminal papers on the explanation and constraints, as well as some more recent works. The survey sets out to unify many disparate lines of work in areas such as model-based diagnosis, constraint programming, Boolean satisfiability, truth maintenance systems, quantified logics, and related areas. Keywords: Constraints and SAT: General},
  archive   = {C_IJCAI},
  author    = {Sharmi Dev Gupta and Begum Genc and Barry O&#39;Sullivan},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/601},
  pages     = {4400-4407},
  title     = {Explanation in constraint satisfaction: A survey},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Argumentative XAI: A survey. <em>IJCAI</em>, 4392–4399. (<a
href="https://doi.org/10.24963/ijcai.2021/600">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Explainable AI (XAI) has been investigated for decades and, together with AI itself, has witnessed unprecedented growth in recent years. Among various approaches to XAI, argumentative models have been advocated in both the AI and social science literature, as their dialectical nature appears to match some basic desirable features of the explanation activity. In this survey we overview XAI approaches built using methods from the field of computational argumentation, leveraging its wide array of reasoning abstractions and explanation delivery methods. We overview the literature focusing on different types of explanation (intrinsic and post-hoc), different models with which argumentation-based explanations are deployed, different forms of delivery, and different argumentation frameworks they use. We also lay out a roadmap for future work. Keywords: Agent-based and multi-agent based systems: General Knowledge representation and reasoning: General Multidisciplinary topics and applications: General},
  archive   = {C_IJCAI},
  author    = {Kristijonas Čyras and Antonio Rago and Emanuele Albini and Pietro Baroni and Francesca Toni},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/600},
  pages     = {4392-4399},
  title     = {Argumentative XAI: A survey},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Understanding the relationship between interactions and
outcomes in human-in-the-loop machine learning. <em>IJCAI</em>,
4382–4391. (<a href="https://doi.org/10.24963/ijcai.2021/599">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Human-in-the-loop Machine Learning (HIL-ML) is a widely adopted paradigm for instilling human knowledge in autonomous agents. Many design choices influence the efficiency and effectiveness of such interactive learning processes, particularly the interaction type through which the human teacher may provide feedback. While different interaction types (demonstrations, preferences, etc.) have been proposed and evaluated in the HIL-ML literature, there has been little discussion of how these compare or how they should be selected to best address a particular learning problem. In this survey, we propose an organizing principle for HIL-ML that provides a way to analyze the effects of interaction types on human performance and training data. We also identify open problems in understanding the effects of interaction types. Keywords: Humans and AI: General},
  archive   = {C_IJCAI},
  author    = {Yuchen Cui and Pallavi Koppol and Henny Admoni and Scott Niekum and Reid Simmons and Aaron Steinfeld and Tesca Fitzgerald},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/599},
  pages     = {4382-4391},
  title     = {Understanding the relationship between interactions and outcomes in human-in-the-loop machine learning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Causal learning for socially responsible AI. <em>IJCAI</em>,
4374–4381. (<a href="https://doi.org/10.24963/ijcai.2021/598">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {There have been increasing concerns about Artificial Intelligence (AI) due to its unfathomable potential power. To make AI address ethical challenges and shun undesirable outcomes, researchers proposed to develop socially responsible AI (SRAI). One of these approaches is causal learning (CL). We survey state-of-the-art methods of CL for SRAI. We begin by examining the seven CL tools to enhance the social responsibility of AI, then review how existing works have succeeded using these tools to tackle issues in developing SRAI such as fairness. The goal of this survey is to bring forefront the potentials and promises of CL for SRAI. Keywords: Humans and AI: General Machine learning: General Multidisciplinary topics and applications: General Uncertainty in AI: General},
  archive   = {C_IJCAI},
  author    = {Lu Cheng and Ahmadreza Mosallanezhad and Paras Sheth and Huan Liu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/598},
  pages     = {4374-4381},
  title     = {Causal learning for socially responsible AI},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Knowledge-aware zero-shot learning: Survey and perspective.
<em>IJCAI</em>, 4366–4373. (<a
href="https://doi.org/10.24963/ijcai.2021/597">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Zero-shot learning (ZSL) which aims at predicting classes that have never appeared during the training using external knowledge (a.k.a. side information) has been widely investigated. In this paper we present a literature review towards ZSL in the perspective of external knowledge, where we categorize the external knowledge, review their methods and compare different external knowledge. With the literature review, we further discuss and outlook the role of symbolic knowledge in addressing ZSL and other machine learning sample shortage issues. Keywords: Knowledge representation and reasoning: General Machine learning: General Multidisciplinary topics and applications: General},
  archive   = {C_IJCAI},
  author    = {Jiaoyan Chen and Yuxia Geng and Zhuo Chen and Ian Horrocks and Jeff Z. Pan and Huajun Chen},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/597},
  pages     = {4366-4373},
  title     = {Knowledge-aware zero-shot learning: Survey and perspective},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mechanism design for facility location problems: A survey.
<em>IJCAI</em>, 4356–4365. (<a
href="https://doi.org/10.24963/ijcai.2021/596">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The study of approximate mechanism design for facility location has been in the center of research at the intersection of artificial intelligence and economics for the last decade, largely due to its practical importance in various domains, such as social planning and clustering. At a high level, the goal is to select a number of locations on which to build a set of facilities, aiming to optimize some social objective based on the preferences of strategic agents, who might have incentives to misreport their private information. This paper presents a comprehensive survey of the significant progress that has been made since the introduction of the problem, highlighting all the different variants and methodologies, as well as the most interesting directions for future research. Keywords: Agent-based and multi-agent based systems: General},
  archive   = {C_IJCAI},
  author    = {Hau Chan and Aris Filos-Ratsikas and Bo Li and Minming Li and Chenhao Wang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/596},
  pages     = {4356-4365},
  title     = {Mechanism design for facility location problems: A survey},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Combinatorial optimization and reasoning with graph neural
networks. <em>IJCAI</em>, 4348–4355. (<a
href="https://doi.org/10.24963/ijcai.2021/595">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Combinatorial optimization is a well-established area in operations research and computer science. Until recently, its methods have mostly focused on solving problem instances in isolation, ignoring the fact that they often stem from related data distributions in practice. However, recent years have seen a surge of interest in using machine learning, especially graph neural networks, as a key building block for combinatorial tasks, either directly as solvers or by enhancing the former. This paper presents a conceptual review of recent key advancements in this emerging field, aiming at researchers in both optimization and machine learning. Keywords: Constraints and SAT: General Machine learning: General},
  archive   = {C_IJCAI},
  author    = {Quentin Cappart and Didier Chételat and Elias B. Khalil and Andrea Lodi and Christopher Morris and Petar Veličković},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/595},
  pages     = {4348-4355},
  title     = {Combinatorial optimization and reasoning with graph neural networks},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). When computational representation meets neuroscience: A
survey on brain encoding and decoding. <em>IJCAI</em>, 4339–4347. (<a
href="https://doi.org/10.24963/ijcai.2021/594">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Real human language mechanisms and the artificial intelligent language processing methods are two independent systems. Exploring the relationship between the two can help develop human-like language models and is also beneficial to reveal the neuroscience of the reading brain. The flourishing research in this interdisciplinal research field calls for surveys to systemically study and analyze the recent successes. However, such a comprehensive review still cannot be found, which motivates our work. This article first briefly introduces the interdisciplinal research progress, then systematically discusses the task of brain decoding from the perspective of simple concepts and complete sentences, and also describes main limitations in this field and put forward with possible solutions. Finally, we conclude this survey with certain open research questions that will stimulate further studies. Keywords: Humans and AI: General Natural language processing: General},
  archive   = {C_IJCAI},
  author    = {Lu Cao and Dandan Huang and Yue Zhang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/594},
  pages     = {4339-4347},
  title     = {When computational representation meets neuroscience: A survey on brain encoding and decoding},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Recent trends in word sense disambiguation: A survey.
<em>IJCAI</em>, 4330–4338. (<a
href="https://doi.org/10.24963/ijcai.2021/593">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Word Sense Disambiguation (WSD) aims at making explicit the semantics of a word in context by identifying the most suitable meaning from a predefined sense inventory. Recent breakthroughs in representation learning have fueled intensive WSD research, resulting in considerable performance improvements, breaching the 80\% glass ceiling set by the inter-annotator agreement. In this survey, we provide an extensive overview of current advances in WSD, describing the state of the art in terms of i) resources for the task, i.e., sense inventories and reference datasets for training and testing, as well as ii) automatic disambiguation approaches, detailing their peculiarities, strengths and weaknesses. Finally, we highlight the current limitations of the task itself, but also point out recent trends that could help expand the scope and applicability of WSD, setting up new promising directions for the future. Keywords: Natural language processing: General},
  archive   = {C_IJCAI},
  author    = {Michele Bevilacqua and Tommaso Pasini and Alessandro Raganato and Roberto Navigli},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/593},
  pages     = {4330-4338},
  title     = {Recent trends in word sense disambiguation: A survey},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hardware-aware neural architecture search: Survey and
taxonomy. <em>IJCAI</em>, 4322–4329. (<a
href="https://doi.org/10.24963/ijcai.2021/592">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {There is no doubt that making AI mainstream by bringing powerful, yet power hungry deep neural networks (DNNs) to resource-constrained devices would required an efficient co-design of algorithms, hardware and software. The increased popularity of DNN applications deployed on a wide variety of platforms, from tiny microcontrollers to data-centers, have resulted in multiple questions and challenges related to constraints introduced by the hardware. In this survey on hardware-aware neural architecture search (HW-NAS), we present some of the existing answers proposed in the literature for the following questions: &quot;Is it possible to build an efficient DL model that meets the latency and energy constraints of tiny edge devices?&quot;, &quot;How can we reduce the trade-off between the accuracy of a DL model and its ability to be deployed in a variety of platforms?&quot;. The survey provides a new taxonomy of HW-NAS and assesses the hardware cost estimation strategies. We also highlight the challenges and limitations of existing approaches and potential future directions. We hope that this survey will help to fuel the research towards efficient deep learning. Keywords: Machine learning: General Computer vision: General Multidisciplinary topics and applications: General},
  archive   = {C_IJCAI},
  author    = {Hadjer Benmeziane and Kaoutar El Maghraoui and Hamza Ouarnoughi and Smail Niar and Martin Wistuba and Naigang Wang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/592},
  pages     = {4322-4329},
  title     = {Hardware-aware neural architecture search: Survey and taxonomy},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Recent advances in adversarial training for adversarial
robustness. <em>IJCAI</em>, 4312–4321. (<a
href="https://doi.org/10.24963/ijcai.2021/591">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Adversarial training is one of the most effective approaches for deep learning models to defend against adversarial examples. Unlike other defense strategies, adversarial training aims to enhance the robustness of models intrinsically. During the past few years, adversarial training has been studied and discussed from various aspects, which deserves a comprehensive review. For the first time in this survey, we systematically review the recent progress on adversarial training for adversarial robustness with a novel taxonomy. Then we discuss the generalization problems in adversarial training from three perspectives and highlight the challenges which are not fully tackled. Finally, we present potential future directions. Keywords: Machine learning: General Computer vision: General},
  archive   = {C_IJCAI},
  author    = {Tao Bai and Jinqi Luo and Jun Zhao and Bihan Wen and Qian Wang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/591},
  pages     = {4312-4321},
  title     = {Recent advances in adversarial training for adversarial robustness},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Building affordance relations for robotic agents - a review.
<em>IJCAI</em>, 4302–4311. (<a
href="https://doi.org/10.24963/ijcai.2021/590">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Affordances describe the possibilities for an agent to perform actions with an object. While the significance of the affordance concept has been previously studied from varied perspectives, such as psychology and cognitive science, these approaches are not always sufficient to enable direct transfer, in the sense of implementations, to artificial intelligence (AI)-based systems and robotics. However, many efforts have been made to pragmatically employ the concept of affordances, as it represents great potential for AI agents to effectively bridge perception to action. In this survey, we review and find common ground amongst different strategies that use the concept of affordances within robotic tasks, and build on these methods to provide guidance for including affordances as a mechanism to improve autonomy. To this end, we outline common design choices for building representations of affordance relations, and their implications on the generalisation capabilities of an agent when facing previously unseen scenarios. Finally, we identify and discuss a range of interesting research directions involving affordances that have the potential to improve the capabilities of an AI agent. Keywords: Multidisciplinary topics and applications: General Robotics: General},
  archive   = {C_IJCAI},
  author    = {Paola Ardón and Èric Pairet and Katrin S. Lohan and Subramanian Ramamoorthy and Ron P. A. Petrick},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/590},
  pages     = {4302-4311},
  title     = {Building affordance relations for robotic agents - a review},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Distortion in social choice problems: The first 15 years and
beyond. <em>IJCAI</em>, 4294–4301. (<a
href="https://doi.org/10.24963/ijcai.2021/589">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The notion of distortion in social choice problems has been defined to measure the loss in efficiency---typically measured by the utilitarian social welfare, the sum of utilities of the participating agents---due to having access only to limited information about the preferences of the agents. We survey the most significant results of the literature on distortion from the past 15 years, and highlight important open problems and the most promising avenues of ongoing and future work. Keywords: Agent-based and multi-agent based systems: General},
  archive   = {C_IJCAI},
  author    = {Elliot Anshelevich and Aris Filos-Ratsikas and Nisarg Shah and Alexandros A. Voudouris},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/589},
  pages     = {4294-4301},
  title     = {Distortion in social choice problems: The first 15 years and beyond},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey of machine learning-based physics event generation.
<em>IJCAI</em>, 4286–4293. (<a
href="https://doi.org/10.24963/ijcai.2021/588">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Event generators in high-energy nuclear and particle physics play an important role in facilitating studies of particle reactions. We survey the state of the art of machine learning (ML) efforts at building physics event generators. We review ML generative models used in ML-based event generators and their specific challenges, and discuss various approaches of incorporating physics into the ML model designs to overcome these challenges. Finally, we explore some open questions related to super-resolution, fidelity, and extrapolation for physics event generation based on ML technology. Keywords: Machine learning: General Multidisciplinary topics and applications: General},
  archive   = {C_IJCAI},
  author    = {Yasir Alanazi and Nobuo Sato and Pawel Ambrozewicz and Astrid Hiller-Blin and Wally Melnitchouk and Marco Battaglieri and Tianbo Liu and Yaohang Li},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/588},
  pages     = {4286-4293},
  title     = {A survey of machine learning-based physics event generation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Partition function estimation: A quantitative study.
<em>IJCAI</em>, 4276–4285. (<a
href="https://doi.org/10.24963/ijcai.2021/587">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Probabilistic graphical models have emerged as a powerful modeling tool for several real-world scenarios where one needs to reason under uncertainty. A graphical model&#39;s partition function is a central quantity of interest, and its computation is key to several probabilistic reasoning tasks. Given the #P-hardness of computing the partition function, several techniques have been proposed over the years with varying guarantees on the quality of estimates and their runtime behavior. This paper seeks to present a survey of 18 techniques and a rigorous empirical study of their behavior across an extensive set of benchmarks. Our empirical study draws up a surprising observation: exact techniques are as efficient as the approximate ones, and therefore, we conclude with an optimistic view of opportunities for the design of approximate techniques with enhanced scalability. Motivated by the observation of an order of magnitude difference between the Virtual Best Solver and the best performing tool, we envision an exciting line of research focused on the development of portfolio solvers. Keywords: Uncertainty in AI: General Knowledge representation and reasoning: General Constraints and SAT: General},
  archive   = {C_IJCAI},
  author    = {Durgesh Agrawal and Yash Pote and Kuldeep S. Meel},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/587},
  pages     = {4276-4285},
  title     = {Partition function estimation: A quantitative study},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fast algorithms for relational marginal polytopes.
<em>IJCAI</em>, 4266–4274. (<a
href="https://doi.org/10.24963/ijcai.2021/586">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the problem of constructing the relational marginal polytope (RMP) of a given set of first-order formulas. Past work has shown that the RMP construction problem can be reduced to weighted first-order model counting (WFOMC). However, existing reductions in the literature are intractable in practice, since they typically require an infeasibly large number of calls to a WFOMC oracle. In this paper, we propose an algorithm to construct RMPs using fewer oracle calls. As an application, we also show how to apply this new algorithm to improve an existing approximation scheme for WFOMC. We demonstrate the efficiency of the proposed approaches experimentally, and find that our method provides speed-ups over the baseline for RMP construction of a full order of magnitude. Keywords: Uncertainty in AI: Statistical Relational AI Machine Learning: Relational Learning},
  archive   = {C_IJCAI},
  author    = {Yuanhong Wang and Timothy van Bremen and Juhua Pu and Yuyi Wang and Ondrej Kuzelka},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/586},
  pages     = {4266-4274},
  title     = {Fast algorithms for relational marginal polytopes},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Provable guarantees on the robustness of decision rules to
causal interventions. <em>IJCAI</em>, 4258–4265. (<a
href="https://doi.org/10.24963/ijcai.2021/585">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Robustness of decision rules to shifts in the data-generating process is crucial to the successful deployment of decision-making systems. Such shifts can be viewed as interventions on a causal graph, which capture (possibly hypothetical) changes in the data-generating process, whether due to natural reasons or by the action of an adversary. We consider causal Bayesian networks and formally define the interventional robustness problem, a novel model-based notion of robustness for decision functions that measures worst-case performance with respect to a set of interventions that denote changes to parameters and/or causal influences. By relying on a tractable representation of Bayesian networks as arithmetic circuits, we provide efficient algorithms for computing guaranteed upper and lower bounds on the interventional robustness probabilities. Experimental results demonstrate that the methods yield useful and interpretable bounds for a range of practical networks, paving the way towards provably causally robust decision-making systems. Keywords: Uncertainty in AI: Bayesian Networks Knowledge Representation and Reasoning: Knowledge Compilation and Tractable Languages Machine Learning: Transfer, Adaptation, Multi-task Learning},
  archive   = {C_IJCAI},
  author    = {Benjie Wang and Clare Lyle and Marta Kwiatkowska},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/585},
  pages     = {4258-4265},
  title     = {Provable guarantees on the robustness of decision rules to causal interventions},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improved acyclicity reasoning for bayesian network structure
learning with constraint programming. <em>IJCAI</em>, 4250–4257. (<a
href="https://doi.org/10.24963/ijcai.2021/584">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Bayesian networks are probabilistic graphical models with a wide range of application areas including gene regulatory networks inference, risk analysis and image processing. Learning the structure of a Bayesian network (BNSL) from discrete data is known to be an NP-hard task with a superexponential search space of directed acyclic graphs. In this work, we propose a new polynomial time algorithm for discovering a subset of all possible cluster cuts, a greedy algorithm for approximately solving the resulting linear program, and a generalized arc consistency algorithm for the acyclicity constraint. We embed these in the constraint programming-based branch-and-bound solver CPBayes and show that, despite being suboptimal, they improve performance by orders of magnitude. The resulting solver also compares favorably with GOBNILP, a state-of-the-art solver for the BNSL problem which solves an NP-hard problem to discover each cut and solves the linear program exactly. Keywords: Uncertainty in AI: Bayesian Networks Constraints and SAT: Constraint Optimization},
  archive   = {C_IJCAI},
  author    = {Fulya Trösser and Simon de Givry and George Katsirelos},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/584},
  pages     = {4250-4257},
  title     = {Improved acyclicity reasoning for bayesian network structure learning with constraint programming},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). BKT-POMDP: Fast action selection for user skill modelling
over tasks with multiple skills. <em>IJCAI</em>, 4243–4249. (<a
href="https://doi.org/10.24963/ijcai.2021/583">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Creating an accurate model of a user&#39;s skills is necessary for intelligent tutoring systems. Without an accurate model, sample problems or tasks must be selected haphazardly by the tutor. Once an accurate model has been trained, the tutor can selectively focus on training essential or deficient skills. Prior work offers mechanisms for optimizing the training of a single skill or for multiple skills when individual tasks involve testing only a single skill at a time, but not for multiple skills when individual tasks can contain evidence for multiple skills. In this paper, we present a system that estimates user skill models for multiple skills by selecting tasks which maximize the information gain across the entire skill model. We compare our system&#39;s policy against several baselines and an optimal policy in both simulated and real tasks. Our system outperforms baselines and performs almost on par with the optimal policy. Keywords: Uncertainty in AI: Markov Decision Processes Humans and AI: Human-Computer Interaction Humans and AI: Personalization and User Modeling},
  archive   = {C_IJCAI},
  author    = {Nicole Salomons and Emir Akdere and Brian Scassellati},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/583},
  pages     = {4243-4249},
  title     = {BKT-POMDP: Fast action selection for user skill modelling over tasks with multiple skills},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep bucket elimination. <em>IJCAI</em>, 4235–4242. (<a
href="https://doi.org/10.24963/ijcai.2021/582">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Bucket Elimination (BE) is a universal inference scheme that can solve most tasks over probabilistic and deterministic graphical models exactly. However, it often requires exponentially high levels of memory (in the induced-width) preventing its execution. In the spirit of exploiting Deep Learning for inference tasks, in this paper, we will use neural networks to approximate BE. The resulting Deep Bucket Elimination (DBE) algorithm is developed for computing the partition function. We provide a proof-of-concept empirically using instances from several different benchmarks, showing that DBE can be a more accurate approximation than current state-of-the-art approaches for approximating BE (e.g. the mini-bucket schemes), especially when problems are sufficiently hard. Keywords: Uncertainty in AI: Approximate Probabilistic Inference Uncertainty in AI: Exact Probabilistic Inference},
  archive   = {C_IJCAI},
  author    = {Yasaman Razeghi and Kalev Kask and Yadong Lu and Pierre Baldi and Sakshi Agarwal and Rina Dechter},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/582},
  pages     = {4235-4242},
  title     = {Deep bucket elimination},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Handling overlaps when lifting gaussian bayesian networks.
<em>IJCAI</em>, 4228–4234. (<a
href="https://doi.org/10.24963/ijcai.2021/581">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Gaussian Bayesian networks are widely used for modeling the behavior of continuous random variables. Lifting exploits symmetries when dealing with large numbers of isomorphic random variables. It provides a more compact representation for more efficient query answering by encoding the symmetries using logical variables. This paper improves on an existing lifted representation of the joint distribution represented by a Gaussian Bayesian network (lifted joint), allowing overlaps between the logical variables. Handling overlaps without grounding a model is critical for modelling real-world scenarios. Specifically, this paper contributes (i) a lifted joint that allows overlaps in logical variables and (ii) a lifted query answering algorithm using the lifted joint. Complexity analyses and experimental results show that - despite overlaps - constructing a lifted joint and answering queries on the lifted joint outperform their grounded counterparts significantly. Keywords: Uncertainty in AI: Bayesian Networks Uncertainty in AI: Exact Probabilistic Inference Uncertainty in AI: Graphical Models Uncertainty in AI: Statistical Relational AI},
  archive   = {C_IJCAI},
  author    = {Mattis Hartwig and Tanya Braun and Ralf Möller},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/581},
  pages     = {4228-4234},
  title     = {Handling overlaps when lifting gaussian bayesian networks},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the parameterized complexity of polytree learning.
<em>IJCAI</em>, 4221–4227. (<a
href="https://doi.org/10.24963/ijcai.2021/580">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A Bayesian network is a directed acyclic graph that represents statistical dependencies between variables of a joint probability distribution. A fundamental task in data science is to learn a Bayesian network from observed data. Polytree Learning is the problem of learning an optimal Bayesian network that fulfills the additional property that its underlying undirected graph is a forest. In this work, we revisit the complexity of Polytree Learning. We show that Polytree Learning can be solved in single-exponential FPT time for the number of variables. Moreover, we consider the influence of d, the number of variables that might receive a nonempty parent set in the final DAG on the complexity of Polytree Learning. We show that Polytree Learning is presumably not fixed-parameter tractable for d, unlike Bayesian network learning which is fixed-parameter tractable for d. Finally, we show that if d and the maximum parent set size are bounded, then we can obtain efficient algorithms. Keywords: Uncertainty in AI: Bayesian Networks Heuristic Search and Game Playing: Combinatorial Search and Optimisation},
  archive   = {C_IJCAI},
  author    = {Niels Grüttemeier and Christian Komusiewicz and Nils Morawietz},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/580},
  pages     = {4221-4227},
  title     = {On the parameterized complexity of polytree learning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Non-parametric stochastic sequential assignment with random
arrival times. <em>IJCAI</em>, 4214–4220. (<a
href="https://doi.org/10.24963/ijcai.2021/579">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider a problem wherein jobs arrive at random times and assume random values. Upon each job arrival, the decision-maker must decide immediately whether or not to accept the job and gain the value on offer as a reward, with the constraint that they may only accept at most n jobs over some reference time period. The decision-maker only has access to M independent realisations of the job arrival process. We propose an algorithm, Non-Parametric Sequential Allocation (NPSA), for solving this problem. Moreover, we prove that the expected reward returned by the NPSA algorithm converges in probability to optimality as M grows large. We demonstrate the effectiveness of the algorithm empirically on synthetic data and on public fraud-detection datasets, from where the motivation for this work is derived. Keywords: Uncertainty in AI: Sequential Decision Making Planning and Scheduling: Planning and Scheduling Machine Learning: Cost-Sensitive Learning},
  archive   = {C_IJCAI},
  author    = {Danial Dervovic and Parisa Hassanzadeh and Samuel Assefa and Prashant Reddy},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/579},
  pages     = {4214-4220},
  title     = {Non-parametric stochastic sequential assignment with random arrival times},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The traveling tournament problem with maximum tour length
two: A practical algorithm with an improved approximation bound.
<em>IJCAI</em>, 4206–4212. (<a
href="https://doi.org/10.24963/ijcai.2021/578">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Traveling Tournament Problem is a well-known benchmark problem in tournament timetabling, which asks us to design a schedule of home/away games of n teams (n is even) under some feasibility requirements such that the total traveling distance of all the n teams is minimized. In this paper, we study TTP-2, the traveling tournament problem where at most two consecutive home games or away games are allowed, and give an effective algorithm for n/2 being odd. Experiments on the well-known benchmark sets show that we can beat previously known solutions for all instances with n/2 being odd by an average improvement of 2.66\%. Furthermore, we improve the theoretical approximation ratio from 3/2+O(1/n) to 1+O(1/n) for n/2 being odd, answering a challenging open problem in this area. Keywords: Planning and Scheduling: Planning Algorithms Planning and Scheduling: Scheduling Planning and Scheduling: Theoretical Foundations of Planning},
  archive   = {C_IJCAI},
  author    = {Jingyang Zhao and Mingyu Xiao},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/578},
  pages     = {4206-4212},
  title     = {The traveling tournament problem with maximum tour length two: A practical algorithm with an improved approximation bound},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). TANGO: Commonsense generalization in predicting tool
interactions for mobile manipulators. <em>IJCAI</em>, 4197–4205. (<a
href="https://doi.org/10.24963/ijcai.2021/577">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Robots assisting us in factories or homes must learn to make use of objects as tools to perform tasks, e.g., a tray for carrying objects. We consider the problem of learning commonsense knowledge of when a tool may be useful and how its use may be composed with other tools to accomplish a high-level task instructed by a human. We introduce TANGO, a novel neural model for predicting task-specific tool interactions. TANGO is trained using demonstrations obtained from human teachers instructing a virtual robot in a physics simulator. TANGO encodes the world state consisting of objects and symbolic relationships between them using a graph neural network. The model learns to attend over the scene using knowledge of the goal and the action history, finally decoding the symbolic action to execute. Crucially, we address generalization to unseen environments where some known tools are missing, but alternative unseen tools are present. We show that by augmenting the representation of the environment with pre-trained embeddings derived from a knowledge-base, the model can generalize effectively to novel environments. Experimental results show a 60.5-78.9\% improvement over the baseline in predicting successful symbolic plans in unseen settings for a simulated mobile manipulator. Keywords: Planning and Scheduling: Robot Planning Uncertainty in AI: Sequential Decision Making Robotics: Learning in Robotics},
  archive   = {C_IJCAI},
  author    = {Shreshth Tuli and Rajas Bansal and Rohan Paul and Mausam},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/577},
  pages     = {4197-4205},
  title     = {TANGO: Commonsense generalization in predicting tool interactions for mobile manipulators},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The fewer the merrier: Pruning preferred operators with
novelty. <em>IJCAI</em>, 4190–4196. (<a
href="https://doi.org/10.24963/ijcai.2021/576">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Heuristic search is among the best performing approaches to classical satisficing planning, with its performance heavily relying on informative and fast heuristics, as well as search-boosting and pruning techniques. While both heuristics and pruning techniques have gained much attention recently, search-boosting techniques in general, and preferred operators in particular have received less attention in the last decade. Our work aims at bringing the light back to preferred operators research, with the introduction of preferred operators pruning technique, based on the concept of novelty. Continuing the research on novelty with respect to an underlying heuristic, we present the definition of preferred operators for such novelty heuristics. For that, we extend the previously defined concepts to operators, allowing us to reason about the novelty of the preferred operators. Our experimental evaluation shows the practical benefit of our suggested approach, compared to the currently used methods. Keywords: Planning and Scheduling: Planning and Scheduling Planning and Scheduling: Search in Planning and Scheduling},
  archive   = {C_IJCAI},
  author    = {Alexander Tuisov and Michael Katz},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/576},
  pages     = {4190-4196},
  title     = {The fewer the merrier: Pruning preferred operators with novelty},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Solving partially observable stochastic shortest-path games.
<em>IJCAI</em>, 4182–4189. (<a
href="https://doi.org/10.24963/ijcai.2021/575">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the two-player zero-sum extension of the partially observable stochastic shortest-path problem where one agent has only partial information about the environment. We formulate this problem as a partially observable stochastic game (POSG): given a set of target states and negative rewards for each transition, the player with imperfect information maximizes the expected undiscounted total reward until a target state is reached. The second player with the perfect information aims for the opposite. We base our formalism on POSGs with one-sided observability (OS-POSGs) and give the following contributions: (1) we introduce a novel heuristic search value iteration algorithm that iteratively solves depth-limited variants of the game, (2) we derive the bound on the depth guaranteeing an arbitrary precision, (3) we propose a novel upper-bound estimation that allows early terminations, and (4) we experimentally evaluate the algorithm on a pursuit-evasion game. Keywords: Planning and Scheduling: Planning with Incomplete Information Agent-based and Multi-agent Systems: Noncooperative Games Uncertainty in AI: Sequential Decision Making},
  archive   = {C_IJCAI},
  author    = {Petr Tomášek and Karel Horák and Aditya Aradhye and Branislav Bošanský and Krishnendu Chatterjee},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/575},
  pages     = {4182-4189},
  title     = {Solving partially observable stochastic shortest-path games},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning generalized unsolvability heuristics for classical
planning. <em>IJCAI</em>, 4175–4181. (<a
href="https://doi.org/10.24963/ijcai.2021/574">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent work in classical planning has introduced dedicated techniques for detecting unsolvable states, i.e., states from which no goal state can be reached. We approach the problem from a generalized planning perspective and learn first-order-like formulas that characterize unsolvability for entire planning domains. We show how to cast the problem as a self-supervised classification task. Our training data is automatically generated and labeled by exhaustive exploration of small instances of each domain, and candidate features are automatically computed from the predicates used to define the domain. We investigate three learning algorithms with different properties and compare them to heuristics from the literature. Our empirical results show that our approach often captures important classes of unsolvable states with high classification accuracy. Additionally, the logical form of our heuristics makes them easy to interpret and reason about, and can be used to show that the characterizations learned in some domains capture exactly all unsolvable states of the domain. Keywords: Planning and Scheduling: Planning and Scheduling},
  archive   = {C_IJCAI},
  author    = {Simon Ståhlberg and Guillem Francès and Jendrik Seipp},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/574},
  pages     = {4175-4181},
  title     = {Learning generalized unsolvability heuristics for classical planning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On weak stubborn sets in classical planning. <em>IJCAI</em>,
4167–4174. (<a href="https://doi.org/10.24963/ijcai.2021/573">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Stubborn sets are a pruning technique for state-space search which is well established in optimal classical planning. In this paper, we show that weak stubborn sets introduced in recent work in planning are actually not weak stubborn sets in Valmari&#39;s original sense. Based on this finding, we introduce weak stubborn sets in the original sense for planning by providing a generalized definition analogously to generalized strong stubborn sets in previous work. We discuss the relationship of strong, weak and the previously called weak stubborn sets, thus providing a further step in getting an overall picture of the stubborn set approach in planning. Keywords: Planning and Scheduling: Planning Algorithms Planning and Scheduling: Search in Planning and Scheduling Planning and Scheduling: Theoretical Foundations of Planning},
  archive   = {C_IJCAI},
  author    = {Silvan Sievers and Martin Wehrle},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/573},
  pages     = {4167-4174},
  title     = {On weak stubborn sets in classical planning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning temporal plan preferences from examples: An
empirical study. <em>IJCAI</em>, 4160–4166. (<a
href="https://doi.org/10.24963/ijcai.2021/572">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Temporal plan preferences are natural and important in a variety of applications. Yet users often find it difficult to formalize their preferences. Here we explore the possibility to learn preferences from example plans. Focusing on one preference at a time, the user is asked to annotate examples as good/bad. We leverage prior work on LTL formula learning to extract a preference from these examples. We conduct an empirical study of this approach in an oversubscription planning context, using hidden target formulas to emulate the user preferences. We explore four different methods for generating example plans, and evaluate performance as a function of domain and formula size. Overall, we find that reasonable-size target formulas can often be learned effectively. Keywords: Planning and Scheduling: Planning and Scheduling},
  archive   = {C_IJCAI},
  author    = {Valentin Seimetz and Rebecca Eifler and Jörg Hoffmann},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/572},
  pages     = {4160-4166},
  title     = {Learning temporal plan preferences from examples: An empirical study},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Change the world - how hard can that be? On the
computational complexity of fixing planning models. <em>IJCAI</em>,
4152–4159. (<a href="https://doi.org/10.24963/ijcai.2021/571">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Incorporating humans into AI planning is an important feature of flexible planning technology. Such human integration allows to incorporate previously unknown constraints, and is also an integral part of automated modeling assistance. As a foundation for integrating user requests, we study the computational complexity of determining the existence of changes to an existing model, such that the resulting model allows for specific user-provided solutions. We are provided with a planning problem modeled either in the classical (non-hierarchical) or hierarchical task network (HTN) planning formalism, as well as with a supposed-to-be solution plan, which is actually not a solution for the current model. Considering changing decomposition methods as well as preconditions and effects of actions, we show that most change requests are NP-complete though some turn out to be tractable. Keywords: Planning and Scheduling: Hierarchical Planning Planning and Scheduling: Model-Based Reasoning Planning and Scheduling: Theoretical Foundations of Planning},
  archive   = {C_IJCAI},
  author    = {Songtuan Lin and Pascal Bercher},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/571},
  pages     = {4152-4159},
  title     = {Change the world - how hard can that be? on the computational complexity of fixing planning models},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Synthesizing good-enough strategies for LTLf specifications.
<em>IJCAI</em>, 4144–4151. (<a
href="https://doi.org/10.24963/ijcai.2021/570">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider the problem of synthesizing good-enough (GE)-strategies for linear temporal logic (LTL) over finite traces or LTLf for short. The problem of synthesizing GE-strategies for an LTL formula φ over infinite traces reduces to the problem of synthesizing winning strategies for the formula (∃Oφ)⇒φ where O is the set of propositions controlled by the system. We first prove that this reduction does not work for LTLf formulas. Then we show how to synthesize GE-strategies for LTLf formulas via the Good-Enough (GE)-synthesis of LTL formulas. Unfortunately, this requires to construct deterministic parity automata on infinite words, which is computationally expensive. We then show how to synthesize GE-strategies for LTLf formulas by a reduction to solving games played on deterministic Büchi automata, based on an easier construction of deterministic automata on finite words. We show empirically that our specialized synthesis algorithm for GE-strategies outperforms the algorithms going through GE-synthesis of LTL formulas by orders of magnitude. Keywords: Planning and Scheduling: Applications of Planning Planning and Scheduling: Planning and Scheduling Planning and Scheduling: Temporal and Hybrid Planning},
  archive   = {C_IJCAI},
  author    = {Yong Li and Andrea Turrini and Moshe Y. Vardi and Lijun Zhang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/570},
  pages     = {4144-4151},
  title     = {Synthesizing good-enough strategies for LTLf specifications},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Dynamic rebalancing dockless bike-sharing system based on
station community discovery. <em>IJCAI</em>, 4136–4143. (<a
href="https://doi.org/10.24963/ijcai.2021/569">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Influenced by the era of the sharing economy and mobile payment, Dockless Bike-Sharing System (Dockless BSS) is expanding in many major cities. The mobility of users constantly leads to supply and demand imbalance, which seriously affects the total profit and customer satisfaction. In this paper, we propose the Spatio-Temporal Mixed Integer Program (STMIP) with Flow-graphed Community Discovery (FCD) approach to rebalancing the system. Different from existing studies that ignore the route of trucks and adopt a centralized rebalancing, our approach considers the spatio-temporal information of trucks and discovers station communities for truck-based rebalancing. First, we propose the FCD algorithm to detect station communities. Significantly, rebalancing communities decomposes the centralized system into a distributed multi-communities system. Then, by considering the routing and velocity of trucks, we design the STMIP model with the objective of maximizing total profit, to find a repositioning policy for each station community. We design a simulator built on real-world data from DiDi Chuxing to test the algorithm performance. The extensive experimental results demonstrate that our approach outperforms in terms of service level, profit, and complexity compared with the state-of-the-art approach. Keywords: Planning and Scheduling: Applications of Planning Planning and Scheduling: Planning and Scheduling},
  archive   = {C_IJCAI},
  author    = {Jingjing Li and Qiang Wang and Wenqi Zhang and Donghai Shi and Zhiwei Qin},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/569},
  pages     = {4136-4143},
  title     = {Dynamic rebalancing dockless bike-sharing system based on station community discovery},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Anytime multi-agent path finding via large neighborhood
search. <em>IJCAI</em>, 4127–4135. (<a
href="https://doi.org/10.24963/ijcai.2021/568">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-Agent Path Finding (MAPF) is the challenging problem of computing collision-free paths for multiple agents. Algorithms for solving MAPF can be categorized on a spectrum. At one end are (bounded-sub)optimal algorithms that can find high-quality solutions for small problems. At the other end are unbounded-suboptimal algorithms that can solve large problems but usually find low-quality solutions. In this paper, we consider a third approach that combines the best of both worlds: anytime algorithms that quickly find an initial solution using efficient MAPF algorithms from the literature, even for large problems, and that subsequently improve the solution quality to near-optimal as time progresses by replanning subgroups of agents using Large Neighborhood Search. We compare our algorithm MAPF-LNS against a range of existing work and report significant gains in scalability, runtime to the initial solution, and speed of improving the solution. Keywords: Planning and Scheduling: Search in Planning and Scheduling Agent-based and Multi-agent Systems: Multi-agent Planning Robotics: Motion and Path Planning},
  archive   = {C_IJCAI},
  author    = {Jiaoyang Li and Zhe Chen and Daniel Harabor and Peter J. Stuckey and Sven Koenig},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/568},
  pages     = {4127-4135},
  title     = {Anytime multi-agent path finding via large neighborhood search},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Polynomial-time in PDDL input size: Making the delete
relaxation feasible for lifted planning. <em>IJCAI</em>, 4119–4126. (<a
href="https://doi.org/10.24963/ijcai.2021/567">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Polynomial-time heuristic functions for planning are commonplace since 20 years. But polynomial-time in which input? Almost all existing approaches are based on a grounded task representation, not on the actual PDDL input which is exponentially smaller. This limits practical applicability to cases where the grounded representation is &quot;small enough&quot;. Previous attempts to tackle this problem for the delete relaxation leveraged symmetries to reduce the blow-up. Here we take a more radical approach, applying an additional relaxation to obtain a heuristic function that runs in time polynomial in the size of the PDDL input. Our relaxation splits the predicates into smaller predicates of fixed arity K. We show that computing a relaxed plan is still NP-hard (in PDDL input size) for K&gt;=2, but is polynomial-time for K=1. We implement a heuristic function for K=1 and show that it can improve the state of the art on benchmarks whose grounded representation is large. Keywords: Planning and Scheduling: Planning Algorithms Planning and Scheduling: Search in Planning and Scheduling},
  archive   = {C_IJCAI},
  author    = {Pascal Lauer and Alvaro Torralba and Daniel Fišer and Daniel Höller and Julia Wichlacz and Jörg Hoffmann},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/567},
  pages     = {4119-4126},
  title     = {Polynomial-time in PDDL input size: Making the delete relaxation feasible for lifted planning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Online learning of action models for PDDL planning.
<em>IJCAI</em>, 4112–4118. (<a
href="https://doi.org/10.24963/ijcai.2021/566">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The automated learning of action models is widely recognised as a key and compelling challenge to address the difficulties of the manual specification of planning domains. Most state-of-the-art methods perform this learning offline from an input set of plan traces generated by the execution of (successful) plans. However, how to generate informative plan traces for learning action models is still an open issue. Moreover, plan traces might not be available for a new environment. In this paper, we propose an algorithm for learning action models online, incrementally during the execution of plans. Such plans are generated to achieve goals that the algorithm decides online in order to obtain informative plan traces and reach states from which useful information can be learned. We show some fundamental theoretical properties of the algorithm, and we experimentally evaluate the online learning of the action models over a large set of IPC domains. Keywords: Planning and Scheduling: Model-Based Reasoning Planning and Scheduling: Planning Algorithms Planning and Scheduling: Planning and Scheduling Knowledge Representation and Reasoning: Action, Change and Causality},
  archive   = {C_IJCAI},
  author    = {Leonardo Lamanna and Alessandro Saetti and Luciano Serafini and Alfonso Gerevini and Paolo Traverso},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/566},
  pages     = {4112-4118},
  title     = {Online learning of action models for PDDL planning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). LTL-constrained steady-state policy synthesis.
<em>IJCAI</em>, 4104–4111. (<a
href="https://doi.org/10.24963/ijcai.2021/565">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Decision-making policies for agents are often synthesized with the constraint that a formal specification of behaviour is satisfied. Here we focus on infinite-horizon properties. On the one hand, Linear Temporal Logic (LTL) is a popular example of a formalism for qualitative specifications. On the other hand, Steady-State Policy Synthesis (SSPS) has recently received considerable attention as it provides a more quantitative and more behavioural perspective on specifications, in terms of the frequency with which states are visited. Finally, rewards provide a classic framework for quantitative properties. In this paper, we study Markov decision processes (MDP) with the specification combining all these three types. The derived policy maximizes the reward among all policies ensuring the LTL specification with the given probability and adhering to the steady-state constraints. To this end, we provide a unified solution reducing the multi-type specification to a multi-dimensional long-run average reward. This is enabled by Limit-Deterministic Büchi Automata (LDBA), recently studied in the context of LTL model checking on MDP, and allows for an elegant solution through a simple linear programme. The algorithm also extends to the general omega-regular properties and runs in time polynomial in the sizes of the MDP as well as the LDBA. Keywords: Planning and Scheduling: Markov Decisions Processes Agent-based and Multi-agent Systems: Formal Verification, Validation and Synthesis Uncertainty in AI: Markov Decision Processes},
  archive   = {C_IJCAI},
  author    = {Jan Křetínský},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/565},
  pages     = {4104-4111},
  title     = {LTL-constrained steady-state policy synthesis},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Counterfactual explanations for optimization-based decisions
in the context of the GDPR. <em>IJCAI</em>, 4097–4103. (<a
href="https://doi.org/10.24963/ijcai.2021/564">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The General Data Protection Regulations (GDPR) entitle individuals to explanations for automated decisions. The form, comprehensibility, and even existence of such explanations remain open problems, investigated as part of explainable AI. We adopt the approach of counterfactual explanations and apply it to decisions made by declarative optimization models. We argue that inverse combinatorial optimization is particularly suited for counterfactual explanations but that the computational difficulties and relatively nascent literature make its application a challenge. To make progress, we address the case of counterfactual explanations that isolate the minimal differences for an individual. We show that under two common optimization functions, full inverse optimization is unnecessary. In particular, we show that for functions of the form of the sum of weighted binary variables, which includes frameworks such as weighted MaxSAT, a solution can be found by solving a slightly modified version of the original optimization model. In contrast, the sum of weighted integer variables can be solved with a binary search over a series of modifications to the original model. Keywords: Planning and Scheduling: Scheduling AI Ethics, Trust, Fairness: Explainability Constraints and SAT: Constraint Optimization},
  archive   = {C_IJCAI},
  author    = {Anton Korikov and Alexander Shleyfman and J. Christopher Beck},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/564},
  pages     = {4097-4103},
  title     = {Counterfactual explanations for optimization-based decisions in the context of the GDPR},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Interference-free walks in time: Temporally disjoint paths.
<em>IJCAI</em>, 4090–4096. (<a
href="https://doi.org/10.24963/ijcai.2021/563">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We investigate the computational complexity of finding temporally disjoint paths or walks in temporal graphs. There, the edge set changes over discrete time steps and a temporal path (resp. walk) uses edges that appear at monotonically increasing time steps. Two paths (or walks) are temporally disjoint if they never use the same vertex at the same time; otherwise, they interfere. This reflects applications in robotics, traffic routing, or finding safe pathways in dynamically changing networks. On the one extreme, we show that on general graphs the problem is computationally hard. The &quot;walk version&quot; is W[1]-hard when parameterized by the number of routes. However, it is polynomial-time solvable for any constant number of walks. The &quot;path version&quot; remains NP-hard even if we want to find only two temporally disjoint paths. On the other extreme, restricting the input temporal graph to have a path as underlying graph, quite counterintuitively, we find NP-hardness in general but also identify natural tractable cases. Keywords: Planning and Scheduling: Planning and Scheduling Planning and Scheduling: Scheduling Agent-based and Multi-agent Systems: Multi-agent Planning},
  archive   = {C_IJCAI},
  author    = {Nina Klobas and George B. Mertzios and Hendrik Molter and Rolf Niedermeier and Philipp Zschoche},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/563},
  pages     = {4090-4096},
  title     = {Interference-free walks in time: Temporally disjoint paths},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Symbolic dynamic programming for continuous state MDPs with
linear program transitions. <em>IJCAI</em>, 4083–4089. (<a
href="https://doi.org/10.24963/ijcai.2021/562">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent advances in symbolic dynamic programming (SDP) have significantly broadened the class of MDPs for which exact closed-form value functions can be derived. However, no existing solution methods can solve complex discrete and continuous state MDPs where a linear program determines state transitions --- transitions that are often required in problems with underlying constrained flow dynamics arising in problems ranging from traffic signal control to telecommunications bandwidth planning. In this paper, we present a novel SDP solution method for MDPs with LP transitions and continuous piecewise linear dynamics by introducing a novel, fully symbolic argmax operator. On three diverse domains, we show the first automated exact closed-form SDP solution to these challenging problems and the significant advantages of our SDP approach over discretized approximations. Keywords: Planning and Scheduling: Markov Decisions Processes Planning and Scheduling: Planning under Uncertainty Uncertainty in AI: Markov Decision Processes},
  archive   = {C_IJCAI},
  author    = {Jihwan Jeong and Parth Jaggi and Scott Sanner},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/562},
  pages     = {4083-4089},
  title     = {Symbolic dynamic programming for continuous state MDPs with linear program transitions},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Incorporating queueing dynamics into schedule-driven traffic
control. <em>IJCAI</em>, 4076–4082. (<a
href="https://doi.org/10.24963/ijcai.2021/561">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Key to the effectiveness of schedule-driven approaches to real-time traffic control is an ability to accurately predict when sensed vehicles will arrive at and pass through the intersection. Prior work in schedule-driven traffic control has assumed a static vehicle arrival model. However, this static predictive model ignores the fact that the queue count and the incurred delay should vary as different partial signal timing schedules (i.e., different possible futures) are explored during the online planning process. In this paper, we propose an alternative arrival time model that incorporates queueing dynamics into this forward search process for a signal timing schedule, to more accurately capture how the intersection’s queues vary over time. As each search state is generated, an incremental queueing delay is dynamically projected for each vehicle. The resulting total queueing delay is then considered in addition to the cumulative delay caused by signal operations. We demonstrate the potential of this approach through microscopic traffic simulation of a real-world road network, showing a 10-15\% reduction in average wait times over the schedule-driven traffic signal control system in heavy traffic scenarios. Keywords: Planning and Scheduling: Applications of Planning Planning and Scheduling: Planning and Scheduling Planning and Scheduling: Real-time Planning},
  archive   = {C_IJCAI},
  author    = {Hsu-Chieh Hu and Allen M. Hawkes and Stephen F. Smith},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/561},
  pages     = {4076-4082},
  title     = {Incorporating queueing dynamics into schedule-driven traffic control},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Stochastic probing with increasing precision.
<em>IJCAI</em>, 4069–4075. (<a
href="https://doi.org/10.24963/ijcai.2021/560">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider a selection problem with stochastic probing. There is a set of items whose values are drawn from independent distributions. The distributions are known in advance. Each item can be \emph{tested} repeatedly. Each test reduces the uncertainty about the realization of its value. We study a testing model, where the first test reveals if the realized value is smaller or larger than the median of the underlying distribution. Subsequent tests allow to further narrow down the interval in which the realization is located. There is a limited number of possible tests, and our goal is to design near-optimal testing strategies that allow to maximize the expected value of the chosen item. We study both identical and non-identical distributions and develop polynomial-time algorithms with constant approximation factors in both scenarios. Keywords: Planning and Scheduling: Planning under Uncertainty Agent-based and Multi-agent Systems: Resource Allocation Agent-based and Multi-agent Systems: Algorithmic Game Theory},
  archive   = {C_IJCAI},
  author    = {Martin Hoefer and Kevin Schewior and Daniel Schmand},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/560},
  pages     = {4069-4075},
  title     = {Stochastic probing with increasing precision},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Active goal recognition design. <em>IJCAI</em>, 4062–4068.
(<a href="https://doi.org/10.24963/ijcai.2021/559">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In Goal Recognition Design (GRD), the objective is to modify a domain to facilitate early detection of the goal of a subject agent. Most previous work studies this problem in the offline setting, in which the observing agent performs its interventions before the subject begins acting. In this paper, we generalize GRD to the online setting in which time passes and the observer&#39;s actions are interleaved with those of the subject. We illustrate weaknesses of existing metrics for GRD and propose an alternative better suited to online settings. We provide a formal definition of this Active GRD (AGRD) problem and study an algorithm for solving it. AGRD occupies an interesting middle ground between passive goal recognition and strategic two-player game settings. Keywords: Planning and Scheduling: Activity and Plan Recognition},
  archive   = {C_IJCAI},
  author    = {Kevin C. Gall and Wheeler Ruml and Sarah Keren},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/559},
  pages     = {4062-4068},
  title     = {Active goal recognition design},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Custom-design of FDR encodings: The case of red-black
planning. <em>IJCAI</em>, 4054–4061. (<a
href="https://doi.org/10.24963/ijcai.2021/558">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Classical planning tasks are commonly described in PDDL, while most planning systems operate on a grounded finite-domain representation (FDR). The translation of PDDL into FDR is complex and has a lot of choice points---it involves identifying so called mutex groups---but most systems rely on the translator that comes with Fast Downward. Yet the translation choice points can strongly impact performance. Prior work has considered optimizing FDR encodings in terms of the number of variables produced. Here we go one step further by proposing to custom-design FDR encodings, optimizing the encoding to suit particular planning techniques. We develop such a custom design here for red-black planning, a partial delete relaxation technique. The FDR encoding affects the causal graph and the domain transition graph structures, which govern the tractable fragment of red-black planning and hence affects the respective heuristic function. We develop integer linear programming techniques optimizing the scope of that fragment in the resulting FDR encoding. We empirically show that the performance of red-black planning can be improved through such FDR custom design. Keywords: Planning and Scheduling: Planning Algorithms Planning and Scheduling: Theoretical Foundations of Planning},
  archive   = {C_IJCAI},
  author    = {Daniel Fišer and Daniel Gnad and Michael Katz and Jörg Hoffmann},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/558},
  pages     = {4054-4061},
  title     = {Custom-design of FDR encodings: The case of red-black planning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Type-WA*: Using exploration in bounded suboptimal planning.
<em>IJCAI</em>, 4047–4053. (<a
href="https://doi.org/10.24963/ijcai.2021/557">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Previous work on satisficing planning using greedy best-first search (GBFS) has shown that non-greedy, randomized exploration can help escape uninformative heuristic regions and solve hard problems faster. Despite their success when used with GBFS, such exploration techniques cannot be directly applied to bounded suboptimal algorithms like Weighted A* (WA*) without losing the solution-quality guarantees. In this work, we present Type-WA*, a novel bounded suboptimal planning algorithm that augments WA* with type-based exploration while still satisfying WA*&#39;s theoretical solution-quality guarantee. Our empirical analysis shows that Type-WA* significantly increases the number of solved problems, when used in conjunction with each of three popular heuristics. Our analysis also provides insight into the runtime vs. solution cost trade-off. Keywords: Planning and Scheduling: Planning Algorithms Planning and Scheduling: Search in Planning and Scheduling Heuristic Search and Game Playing: Heuristic Search},
  archive   = {C_IJCAI},
  author    = {Eldan Cohen and Richard Valenzano and Sheila McIlraith},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/557},
  pages     = {4047-4053},
  title     = {Type-WA*: Using exploration in bounded suboptimal planning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learn to intervene: An adaptive learning policy for restless
bandits in application to preventive healthcare. <em>IJCAI</em>,
4039–4046. (<a href="https://doi.org/10.24963/ijcai.2021/556">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In many public health settings, it is important for patients to adhere to health programs, such as taking medications and periodic health checks. Unfortunately, beneficiaries may gradually disengage from such programs, which is detrimental to their health. A concrete example of gradual disengagement has been observed by an organization that carries out a free automated call-based program for spreading preventive care information among pregnant women. Many women stop picking up calls after being enrolled for a few months. To avoid such disengagements, it is important to provide timely interventions. Such interventions are often expensive and can be provided to only a small fraction of the beneficiaries. We model this scenario as a restless multi-armed bandit (RMAB) problem, where each beneficiary is assumed to transition from one state to another depending on the intervention. Moreover, since the transition probabilities are unknown a priori, we propose a Whittle index based Q-Learning mechanism and show that it converges to the optimal solution. Our method improves over existing learning-based methods for RMABs on multiple benchmarks from literature and also on the maternal healthcare dataset. Keywords: Planning and Scheduling: Applications of Planning Planning and Scheduling: Planning under Uncertainty Uncertainty in AI: Sequential Decision Making},
  archive   = {C_IJCAI},
  author    = {Arpita Biswas and Gaurav Aggarwal and Pradeep Varakantham and Milind Tambe},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/556},
  pages     = {4039-4046},
  title     = {Learn to intervene: An adaptive learning policy for restless bandits in application to preventive healthcare},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). ME-MCTS: Online generalization by combining multiple value
estimators. <em>IJCAI</em>, 4032–4038. (<a
href="https://doi.org/10.24963/ijcai.2021/555">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper addresses the challenge of online generalization in tree search. We propose Multiple Estimator Monte Carlo Tree Search (ME-MCTS), with a two-fold contribution: first, we introduce a formalization of online generalization that can represent existing techniques such as &quot;history heuristics&quot;, &quot;RAVE&quot;, or &quot;OMA&quot; -- contextual action value estimators or abstractors that generalize across specific contexts. Second, we incorporate recent advances in estimator averaging that enable guiding search by combining the online action value estimates of any number of such abstractors or similar types of action value estimators. Unlike previous work, which usually proposed a single abstractor for either the selection or the rollout phase of MCTS simulations, our approach focuses on the combination of multiple estimators and applies them to all move choices in MCTS simulations. As the MCTS tree itself is just another value estimator -- unbiased, but without abstraction -- this blurs the traditional distinction between action choices inside and outside of the MCTS tree. Experiments with three abstractors in four board games show significant improvements of ME-MCTS over MCTS using only a single abstractor, both for MCTS with random rollouts as well as for MCTS with static evaluation functions. While we used deterministic, fully observable games, ME-MCTS naturally extends to more challenging settings. Keywords: Planning and Scheduling: Markov Decisions Processes Heuristic Search and Game Playing: Game Playing},
  archive   = {C_IJCAI},
  author    = {Hendrik Baier and Michael Kaisers},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/555},
  pages     = {4032-4038},
  title     = {ME-MCTS: Online generalization by combining multiple value estimators},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient black-box planning using macro-actions with
focused effects. <em>IJCAI</em>, 4024–4031. (<a
href="https://doi.org/10.24963/ijcai.2021/554">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The difficulty of deterministic planning increases exponentially with search-tree depth. Black-box planning presents an even greater challenge, since planners must operate without an explicit model of the domain. Heuristics can make search more efficient, but goal-aware heuristics for black-box planning usually rely on goal counting, which is often quite uninformative. In this work, we show how to overcome this limitation by discovering macro-actions that make the goal-count heuristic more accurate. Our approach searches for macro-actions with focused effects (i.e. macros that modify only a small number of state variables), which align well with the assumptions made by the goal-count heuristic. Focused macros dramatically improve black-box planning efficiency across a wide range of planning domains, sometimes beating even state-of-the-art planners with access to a full domain model. Keywords: Planning and Scheduling: Planning and Scheduling Planning and Scheduling: Search in Planning and Scheduling Heuristic Search and Game Playing: Heuristic Search},
  archive   = {C_IJCAI},
  author    = {Cameron Allen and Michael Katz and Tim Klinger and George Konidaris and Matthew Riemer and Gerald Tesauro},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/554},
  pages     = {4024-4031},
  title     = {Efficient black-box planning using macro-actions with focused effects},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Relational gating for ”what if” reasoning. <em>IJCAI</em>,
4015–4022. (<a href="https://doi.org/10.24963/ijcai.2021/553">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper addresses the challenge of learning to do procedural reasoning over text to answer &quot;What if...&quot; questions. We propose a novel relational gating network that learns to filter the key entities and relationships and learns contextual and cross representations of both procedure and question for finding the answer. Our relational gating network contains an entity gating module, relation gating module, and contextual interaction module. These modules help in solving the &quot;What if...&quot; reasoning problem. We show that modeling pairwise relationships helps to capture higher-order relations and find the line of reasoning for causes and effects in the procedural descriptions. Our proposed approach achieves the state-of-the-art results on the WIQA dataset. Keywords: Natural Language Processing: Question Answering},
  archive   = {C_IJCAI},
  author    = {Chen Zheng and Parisa Kordjamshidi},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/553},
  pages     = {4015-4022},
  title     = {Relational gating for &#39;&#39;What if&#39;&#39; reasoning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Drop redundant, shrink irrelevant: Selective knowledge
injection for language pretraining. <em>IJCAI</em>, 4007–4014. (<a
href="https://doi.org/10.24963/ijcai.2021/552">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Previous research has demonstrated the power of leveraging prior knowledge to improve the performance of deep models in natural language processing. However, traditional methods neglect the fact that redundant and irrelevant knowledge exists in external knowledge bases. In this study, we launched an in-depth empirical investigation into downstream tasks and found that knowledge-enhanced approaches do not always exhibit satisfactory improvements. To this end, we investigate the fundamental reasons for ineffective knowledge infusion and present selective injection for language pretraining, which constitutes a model-agnostic method and is readily pluggable into previous approaches. Experimental results on benchmark datasets demonstrate that our approach can enhance state-of-the-art knowledge injection methods. Keywords: Natural Language Processing: Information Extraction Natural Language Processing: Natural Language Processing Natural Language Processing: Question Answering},
  archive   = {C_IJCAI},
  author    = {Ningyu Zhang and Shumin Deng and Xu Cheng and Xi Chen and Yichi Zhang and Wei Zhang and Huajun Chen},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/552},
  pages     = {4007-4014},
  title     = {Drop redundant, shrink irrelevant: Selective knowledge injection for language pretraining},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Document-level relation extraction as semantic segmentation.
<em>IJCAI</em>, 3999–4006. (<a
href="https://doi.org/10.24963/ijcai.2021/551">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Document-level relation extraction aims to extract relations among multiple entity pairs from a document. Previously proposed graph-based or transformer-based models utilize the entities independently, regardless of global information among relational triples. This paper approaches the problem by predicting an entity-level relation matrix to capture local and global information, parallel to the semantic segmentation task in computer vision. Herein, we propose a Document U-shaped Network for document-level relation extraction. Specifically, we leverage an encoder module to capture the context information of entities and a U-shaped segmentation module over the image-style feature map to capture global interdependency among triples. Experimental results show that our approach can obtain state-of-the-art performance on three benchmark datasets DocRED, CDR, and GDA. Keywords: Natural Language Processing: Information Extraction Natural Language Processing: Knowledge Extraction},
  archive   = {C_IJCAI},
  author    = {Ningyu Zhang and Xiang Chen and Xin Xie and Shumin Deng and Chuanqi Tan and Mosha Chen and Fei Huang and Luo Si and Huajun Chen},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/551},
  pages     = {3999-4006},
  title     = {Document-level relation extraction as semantic segmentation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cross-domain slot filling as machine reading comprehension.
<em>IJCAI</em>, 3992–3998. (<a
href="https://doi.org/10.24963/ijcai.2021/550">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With task-oriented dialogue systems being widely applied in everyday life, slot filling, the essential component of task-oriented dialogue systems, is required to be quickly adapted to new domains that contain domain-specific slots with few or no training data. Previous methods for slot filling usually adopt sequence labeling framework, which, however, often has limited ability when dealing with the domain-specific slots. In this paper, we take a new perspective on cross-domain slot filling by framing it as a machine reading comprehension (MRC) problem. Our approach firstly transforms slot names into well-designed queries, which contain rich informative prior knowledge and are very helpful for the detection of domain-specific slots. In addition, we utilize the large-scale MRC dataset for pre-training, which further alleviates the data scarcity problem. Experimental results on SNIPS and ATIS datasets show that our approach consistently outperforms the existing state-of-the-art methods by a large margin. Keywords: Natural Language Processing: Dialogue Natural Language Processing: Information Extraction},
  archive   = {C_IJCAI},
  author    = {Mengshi Yu and Jian Liu and Yufeng Chen and Jinan Xu and Yujie Zhang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/550},
  pages     = {3992-3998},
  title     = {Cross-domain slot filling as machine reading comprehension},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MRD-net: Multi-modal residual knowledge distillation for
spoken question answering. <em>IJCAI</em>, 3985–3991. (<a
href="https://doi.org/10.24963/ijcai.2021/549">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Spoken question answering (SQA) has recently drawn considerable attention in the speech community. It requires systems to find correct answers from the given spoken passages simultaneously. The common SQA systems consist of the automatic speech recognition (ASR) module and text-based question answering module. However, previous methods suffer from severe performance degradation due to ASR errors. To alleviate this problem, this work proposes a novel multi-modal residual knowledge distillation method (MRD-Net), which further distills knowledge at the acoustic level from the audio-assistant (Audio-A). Specifically, we utilize the teacher (T) trained on manual transcriptions to guide the training of the student (S) on ASR transcriptions. We also show that introducing an Audio-A helps this procedure by learning residual errors between T and S. Moreover, we propose a simple yet effective attention mechanism to adaptively leverage audio-text features as the new deep attention knowledge to boost the network performance. Extensive experiments demonstrate that the proposed MRD-Net achieves superior results compared with state-of-the-art methods on three spoken question answering benchmark datasets. Keywords: Natural Language Processing: Question Answering Natural Language Processing: Sentiment Analysis and Text Mining Natural Language Processing: Speech},
  archive   = {C_IJCAI},
  author    = {Chenyu You and Nuo Chen and Yuexian Zou},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/549},
  pages     = {3985-3991},
  title     = {MRD-net: Multi-modal residual knowledge distillation for spoken question answering},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). UniMF: A unified framework to incorporate multimodal
knowledge bases intoEnd-to-end task-oriented dialogue systems.
<em>IJCAI</em>, 3978–3984. (<a
href="https://doi.org/10.24963/ijcai.2021/548">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Knowledge bases (KBs) are usually essential for building practical dialogue systems. Recently we have seen rapidly growing interest in integrating knowledge bases into dialogue systems. However, existing approaches mostly deal with knowledge bases of a single modality, typically textual information. As today&#39;s knowledge bases become abundant with multimodal information such as images, audios and videos, the limitation of existing approaches greatly hinders the development of dialogue systems. In this paper, we focus on task-oriented dialogue systems and address this limitation by proposing a novel model that integrates external multimodal KB reasoning with pre-trained language models. We further enhance the model via a novel multi-granularity fusion mechanism to capture multi-grained semantics in the dialogue history. To validate the effectiveness of the proposed model, we collect a new large-scale (14K) dialogue dataset MMDialKB, built upon multimodal KB. Both automatic and human evaluation results on MMDialKB demonstrate the superiority of our proposed framework over strong baselines. Keywords: Natural Language Processing: Dialogue Natural Language Processing: Information Retrieval Natural Language Processing: Knowledge Extraction},
  archive   = {C_IJCAI},
  author    = {Shiquan Yang and Rui Zhang and Sarah M. Erfani and Jey Han Lau},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/548},
  pages     = {3978-3984},
  title     = {UniMF: A unified framework to incorporate multimodal knowledge bases intoEnd-to-end task-oriented dialogue systems},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving stylized neural machine translation with iterative
dual knowledge transfer. <em>IJCAI</em>, 3971–3977. (<a
href="https://doi.org/10.24963/ijcai.2021/547">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Stylized neural machine translation (NMT) aims to translate sentences of one style into sentences of another style, which is essential for the application of machine translation in a real-world scenario. However, a major challenge in this task is the scarcity of high-quality parallel data which is stylized paired. To address this problem, we propose an iterative dual knowledge transfer framework that utilizes informal training data of machine translation and formality style transfer data to create large-scale stylized paired data, for the training of stylized machine translation model. Specifically, we perform bidirectional knowledge transfer between translation model and text style transfer model iteratively through knowledge distillation. Then, we further propose a data-refinement module to process the noisy synthetic parallel data generated during knowledge transfer. Experiment results demonstrate the effectiveness of our method, achieving an improvement over the existing best model by 5 BLEU points on MTFC dataset. Meanwhile, extensive analyses illustrate our method can also improve the accuracy of formality style transfer. Keywords: Natural Language Processing: Machine Translation Natural Language Processing: Natural Language Generation},
  archive   = {C_IJCAI},
  author    = {Xuanxuan Wu and Jian Liu and Xinjie Li and Jinan Xu and Yufeng Chen and Yujie Zhang and Hui Huang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/547},
  pages     = {3971-3977},
  title     = {Improving stylized neural machine translation with iterative dual knowledge transfer},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Knowledge-aware dialogue generation via hierarchical infobox
accessing and infobox-dialogue interaction graph network.
<em>IJCAI</em>, 3964–3970. (<a
href="https://doi.org/10.24963/ijcai.2021/546">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Due to limited knowledge carried by queries, traditional dialogue systems often face the dilemma of generating boring responses, leading to poor user experience. To alleviate this issue, this paper proposes a novel infobox knowledge-aware dialogue generation approach, HITA-Graph, with three unique features. First, open-domain infobox tables that describe entities with relevant attributes are adopted as the knowledge source. An order-irrelevance Hierarchical Infobox Table Encoder is proposed to represent an infobox table at three levels of granularity. In addition, an Infobox-Dialogue Interaction Graph Network is built to effectively integrate the infobox context and the dialogue context into a unified infobox representation. Second, a Hierarchical Infobox Attribute Attention mechanism is developed to access the encoded infobox knowledge at different levels of granularity. Last but not least, a Dynamic Mode Fusion strategy is designed to allow the Decoder to select a vocabulary word or copy a word from the given infobox/query. We extract infobox tables from Chinese Wikipedia and construct an infobox knowledge base. Extensive evaluation on an open-released Chinese corpus demonstrates the superior performance of our approach against several representative methods. Keywords: Natural Language Processing: Dialogue Natural Language Processing: Natural Language Generation},
  archive   = {C_IJCAI},
  author    = {Sixing Wu and Minghui Wang and Dawei Zhang and Yang Zhou and Ying Li and Zhonghai Wu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/546},
  pages     = {3964-3970},
  title     = {Knowledge-aware dialogue generation via hierarchical infobox accessing and infobox-dialogue interaction graph network},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learn from syntax: Improving pair-wise aspect and opinion
terms extraction with rich syntactic knowledge. <em>IJCAI</em>,
3957–3963. (<a href="https://doi.org/10.24963/ijcai.2021/545">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we propose to enhance the pair-wise aspect and opinion terms extraction (PAOTE) task by incorporating rich syntactic knowledge. We first build a syntax fusion encoder for encoding syntactic features, including a label-aware graph convolutional network (LAGCN) for modeling the dependency edges and labels, as well as the POS tags unifiedly, and a local-attention module encoding POS tags for better term boundary detection. During pairing, we then adopt Biaffine and Triaffine scoring for high-order aspect-opinion term pairing, in the meantime re-harnessing the syntax-enriched representations in LAGCN for syntactic-aware scoring. Experimental results on four benchmark datasets demonstrate that our model outperforms current state-of-the-art baselines, meanwhile yielding explainable predictions with syntactic knowledge. Keywords: Natural Language Processing: Information Extraction Natural Language Processing: Natural Language Semantics Natural Language Processing: Sentiment Analysis and Text Mining},
  archive   = {C_IJCAI},
  author    = {Shengqiong Wu and Hao Fei and Yafeng Ren and Donghong Ji and Jingye Li},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/545},
  pages     = {3957-3963},
  title     = {Learn from syntax: Improving pair-wise aspect and opinion terms extraction with rich syntactic knowledge},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hierarchical modeling of label dependency and label noise in
fine-grained entity typing. <em>IJCAI</em>, 3950–3956. (<a
href="https://doi.org/10.24963/ijcai.2021/544">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Fine-grained entity typing (FET) aims to annotate the entity mentions in a sentence with fine-grained type labels. It brings plentiful semantic information for many natural language processing tasks. Existing FET approaches apply hard attention to learn on the noisy labels, and ignore that those noises have structured hierarchical dependency. Despite their successes, these FET models are insufficient in modeling type hierarchy dependencies and handling label noises. In this paper, we directly tackle the structured noisy labels by combining a forward tree module and a backward tree module. Specifically, the forward tree formulates the informative walk that hierarchically represents the type distributions. The backward tree models the erroneous walk that learns the noise confusion matrix. Empirical studies on several benchmark data sets confirm the effectiveness of the proposed framework. Keywords: Natural Language Processing: Information Extraction Natural Language Processing: Named Entities Natural Language Processing: NLP Applications and Tools},
  archive   = {C_IJCAI},
  author    = {Junshuang Wu and Richong Zhang and Yongyi Mao and Masoumeh Soflaei Shahrbabak and Jinpeng Huai},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/544},
  pages     = {3950-3956},
  title     = {Hierarchical modeling of label dependency and label noise in fine-grained entity typing},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A structure self-aware model for discourse parsing on
multi-party dialogues. <em>IJCAI</em>, 3943–3949. (<a
href="https://doi.org/10.24963/ijcai.2021/543">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Conversational discourse structures aim to describe how a dialogue is organized, thus they are helpful for dialogue understanding and response generation. This paper focuses on predicting discourse dependency structures for multi-party dialogues. Previous work adopts incremental methods that take the features from the already predicted discourse relations to help generate the next one. Although the inter-correlations among predictions considered, we find that the error propagation is also very serious and hurts the overall performance. To alleviate error propagation, we propose a Structure Self-Aware (SSA) model, which adopts a novel edge-centric Graph Neural Network (GNN) to update the information between each Elementary Discourse Unit (EDU) pair layer by layer, so that expressive representations can be learned without historical predictions. In addition, we take auxiliary training signals (e.g. structure distillation) for better representation learning. Our model achieves the new state-of-the-art performances on two conversational discourse parsing benchmarks, largely outperforming the previous methods. Keywords: Natural Language Processing: Dialogue Natural Language Processing: Discourse Natural Language Processing: Tagging, Chunking, and Parsing},
  archive   = {C_IJCAI},
  author    = {Ante Wang and Linfeng Song and Hui Jiang and Shaopeng Lai and Junfeng Yao and Min Zhang and Jinsong Su},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/543},
  pages     = {3943-3949},
  title     = {A structure self-aware model for discourse parsing on multi-party dialogues},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A sequence-to-set network for nested named entity
recognition. <em>IJCAI</em>, 3936–3942. (<a
href="https://doi.org/10.24963/ijcai.2021/542">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Named entity recognition (NER) is a widely studied task in natural language processing. Recently, a growing number of studies have focused on the nested NER. The span-based methods, considering the entity recognition as a span classification task, can deal with nested entities naturally. But they suffer from the huge search space and the lack of interactions between entities. To address these issues, we propose a novel sequence-to-set neural network for nested NER. Instead of specifying candidate spans in advance, we provide a fixed set of learnable vectors to learn the patterns of the valuable spans. We utilize a non-autoregressive decoder to predict the final set of entities in one pass, in which we are able to capture dependencies between entities. Compared with the sequence-to-sequence method, our model is more suitable for such unordered recognition task as it is insensitive to the label order. In addition, we utilize the loss function based on bipartite matching to compute the overall training loss. Experimental results show that our proposed model achieves state-of-the-art on three nested NER corpora: ACE 2004, ACE 2005 and KBP 2017. The code is available at https://github.com/zqtan1024/sequence-to-set. Keywords: Natural Language Processing: Information Extraction Natural Language Processing: Named Entities},
  archive   = {C_IJCAI},
  author    = {Zeqi Tan and Yongliang Shen and Shuai Zhang and Weiming Lu and Yueting Zhuang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/542},
  pages     = {3936-3942},
  title     = {A sequence-to-set network for nested named entity recognition},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MEDA: Meta-learning with data augmentation for few-shot text
classification. <em>IJCAI</em>, 3929–3935. (<a
href="https://doi.org/10.24963/ijcai.2021/541">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Meta-learning has recently emerged as a promising technique to address the challenge of few-shot learning. However, standard meta-learning methods mainly focus on visual tasks, which makes it hard for them to deal with diverse text data directly. In this paper, we introduce a novel framework for few-shot text classification, which is named as MEta-learning with Data Augmentation (MEDA). MEDA is composed of two modules, a ball generator and a meta-learner, which are learned jointly. The ball generator is to increase the number of shots per class by generating more samples, so that meta-learner can be trained with both original and augmented samples. It is worth noting that ball generator is agnostic to the choice of the meta-learning methods. Experiment results show that on both datasets, MEDA outperforms existing state-of-the-art methods and significantly improves the performance of meta-learning on few-shot text classification. Keywords: Natural Language Processing: Natural Language Processing Natural Language Processing: Text Classification},
  archive   = {C_IJCAI},
  author    = {Pengfei Sun and Yawen Ouyang and Wenming Zhang and Xin-yu Dai},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/541},
  pages     = {3929-3935},
  title     = {MEDA: Meta-learning with data augmentation for few-shot text classification},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning class-transductive intent representations for
zero-shot intent detection. <em>IJCAI</em>, 3922–3928. (<a
href="https://doi.org/10.24963/ijcai.2021/540">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Zero-shot intent detection (ZSID) aims to deal with the continuously emerging intents without annotated training data. However, existing ZSID systems suffer from two limitations: 1) They are not good at modeling the relationship between seen and unseen intents. 2) They cannot effectively recognize unseen intents under the generalized intent detection (GZSID) setting. A critical problem behind these limitations is that the representations of unseen intents cannot be learned in the training stage. To address this problem, we propose a novel framework that utilizes unseen class labels to learn Class-Transductive Intent Representations (CTIR). Specifically, we allow the model to predict unseen intents during training, with the corresponding label names serving as input utterances. On this basis, we introduce a multi-task learning objective, which encourages the model to learn the distinctions among intents, and a similarity scorer, which estimates the connections among intents more accurately. CTIR is easy to implement and can be integrated with existing ZSID and GZSID methods. Experiments on two real-world datasets show that CTIR brings considerable improvement to the baseline systems. Keywords: Natural Language Processing: Natural Language Processing Natural Language Processing: Text Classification},
  archive   = {C_IJCAI},
  author    = {Qingyi Si and Yuanxin Liu and Peng Fu and Zheng Lin and Jiangnan Li and Weiping Wang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/540},
  pages     = {3922-3928},
  title     = {Learning class-transductive intent representations for zero-shot intent detection},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MultiMirror: Neural cross-lingual word alignment for
multilingual word sense disambiguation. <em>IJCAI</em>, 3915–3921. (<a
href="https://doi.org/10.24963/ijcai.2021/539">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Word Sense Disambiguation (WSD), i.e., the task of assigning senses to words in context, has seen a surge of interest with the advent of neural models and a considerable increase in performance up to 80\% F1 in English. However, when considering other languages, the availability of training data is limited, which hampers scaling WSD to many languages. To address this issue, we put forward MultiMirror, a sense projection approach for multilingual WSD based on a novel neural discriminative model for word alignment: given as input a pair of parallel sentences, our model -- trained with a low number of instances -- is capable of jointly aligning, at the same time, all source and target tokens with each other, surpassing its competitors across several language combinations. We demonstrate that projecting senses from English by leveraging the alignments produced by our model leads a simple mBERT-powered classifier to achieve a new state of the art on established WSD datasets in French, German, Italian, Spanish and Japanese. We release our software and all our datasets at https://github.com/SapienzaNLP/multimirror. Keywords: Natural Language Processing: Natural Language Semantics Natural Language Processing: Resources and Evaluation},
  archive   = {C_IJCAI},
  author    = {Luigi Procopio and Edoardo Barba and Federico Martelli and Roberto Navigli},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/539},
  pages     = {3915-3921},
  title     = {MultiMirror: Neural cross-lingual word alignment for multilingual word sense disambiguation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A streaming end-to-end framework for spoken language
understanding. <em>IJCAI</em>, 3906–3914. (<a
href="https://doi.org/10.24963/ijcai.2021/538">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {End-to-end spoken language understanding (SLU) recently attracted increasing interest. Compared to the conventional tandem-based approach that combines speech recognition and language understanding as separate modules, the new approach extracts users&#39; intentions directly from the speech signals, resulting in joint optimization and low latency. Such an approach, however, is typically designed to process one intent at a time, which leads users to have to take multiple rounds to fulfill their requirements while interacting with a dialogue system. In this paper, we propose a streaming end-to-end framework that can process multiple intentions in an online and incremental way. The backbone of our framework is a unidirectional RNN trained with the connectionist temporal classification (CTC) criterion. By this design, an intention can be identified when sufficient evidence has been accumulated, and multiple intentions will be identified sequentially. We evaluate our solution on the Fluent Speech Commands (FSC) dataset and the detection accuracy is about 97\% on all multi-intent settings. This result is comparable to the performance of the state-of-the-art non-streaming models, but is achieved in an online and incremental way. We also employ our model to an keyword spotting task using the Google Speech Commands dataset, and the results are also highly promising. Keywords: Natural Language Processing: Dialogue Natural Language Processing: Speech},
  archive   = {C_IJCAI},
  author    = {Nihal Potdar and Anderson Raymundo Avila and Chao Xing and Dong Wang and Yiran Cao and Xiao Chen},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/538},
  pages     = {3906-3914},
  title     = {A streaming end-to-end framework for spoken language understanding},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Laughing heads: Can transformers detect what makes a
sentence funny? <em>IJCAI</em>, 3899–3905. (<a
href="https://doi.org/10.24963/ijcai.2021/537">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The automatic detection of humor poses a grand challenge for natural language processing. Transformer-based systems have recently achieved remarkable results on this task, but they usually (1) were evaluated in setups where serious vs humorous texts came from entirely different sources, and (2) focused on benchmarking performance without providing insights into how the models work. We make progress in both respects by training and analyzing transformer-based humor recognition models on a recently introduced dataset consisting of minimal pairs of aligned sentences, one serious, the other humorous. We find that, although our aligned dataset is much harder than previous datasets, transformer-based models recognize the humorous sentence in an aligned pair with high accuracy (78\%). In a careful error analysis, we characterize easy vs hard instances. Finally, by analyzing attention weights, we obtain important insights into the mechanisms by which transformers recognize humor. Most remarkably, we find clear evidence that one single attention head learns to recognize the words that make a test sentence humorous, even without access to this information at training time. Keywords: Natural Language Processing: Natural Language Semantics Natural Language Processing: Resources and Evaluation},
  archive   = {C_IJCAI},
  author    = {Maxime Peyrard and Beatriz Borges and Kristina Gligorić and Robert West},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/537},
  pages     = {3899-3905},
  title     = {Laughing heads: Can transformers detect what makes a sentence funny?},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-hop fact checking of political claims. <em>IJCAI</em>,
3892–3898. (<a href="https://doi.org/10.24963/ijcai.2021/536">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent work has proposed multi-hop models and datasets for studying complex natural language reasoning. One notable task requiring multi-hop reasoning is fact checking, where a set of connected evidence pieces leads to the final verdict of a claim. However, existing datasets either do not provide annotations for gold evidence pages, or the only dataset which does (FEVER) mostly consists of claims which can be fact-checked with simple reasoning and is constructed artificially. Here, we study more complex claim verification of naturally occurring claims with multiple hops over interconnected evidence chunks. We: 1) construct a small annotated dataset, PolitiHop, of evidence sentences for claim verification; 2) compare it to existing multi-hop datasets; and 3) study how to transfer knowledge from more extensive in- and out-of-domain resources to PolitiHop. We find that the task is complex and achieve the best performance with an architecture that specifically models reasoning over evidence pieces in combination with in-domain transfer learning. Keywords: Natural Language Processing: NLP Applications and Tools Natural Language Processing: Resources and Evaluation Natural Language Processing: Text Classification},
  archive   = {C_IJCAI},
  author    = {Wojciech Ostrowski and Arnav Arora and Pepa Atanasova and Isabelle Augenstein},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/536},
  pages     = {3892-3898},
  title     = {Multi-hop fact checking of political claims},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Consistent inference for dialogue relation extraction.
<em>IJCAI</em>, 3885–3891. (<a
href="https://doi.org/10.24963/ijcai.2021/535">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Relation Extraction is key to many downstream tasks. Dialogue relation extraction aims at discovering entity relations from multi-turn dialogue scenario. There exist utterance, topic and relation discrepancy mainly due to multi-speakers, utterances, and relations. In this paper, we propose a consistent learning and inference method to minimize possible contradictions from those distinctions. First, we design mask mechanisms to refine utterance-aware and speaker-aware representations respectively from the global dialogue representation for the utterance distinction. Then a gate mechanism is proposed to aggregate such bi-grained representations. Next, mutual attention mechanism is introduced to obtain the entity representation for various relation specific topic structures. Finally, the relational inference is performed through first order logic constraints over the labeled data to decrease logically contradictory predicted relations. Experimental results on two benchmark datasets show that the F1 performance improvement of the proposed method is at least 3.3\% compared with SOTA. Keywords: Natural Language Processing: Information Extraction Natural Language Processing: Dialogue},
  archive   = {C_IJCAI},
  author    = {Xinwei Long and Shuzi Niu and Yucheng Li},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/535},
  pages     = {3885-3891},
  title     = {Consistent inference for dialogue relation extraction},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving text generation with dynamic masking and
recovering. <em>IJCAI</em>, 3878–3884. (<a
href="https://doi.org/10.24963/ijcai.2021/534">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Due to different types of inputs, diverse text generation tasks may adopt different encoder-decoder frameworks. Thus most existing approaches that aim to improve the robustness of certain generation tasks are input-relevant, and may not work well for other generation tasks. Alternatively, in this paper we present a universal approach to enhance the language representation for text generation on the base of generic encoder-decoder frameworks. This is done from two levels. First, we introduce randomness by randomly masking some percentage of tokens on the decoder side when training the models. In this way, instead of using ground truth history context, we use its corrupted version to predict the next token. Then we propose an auxiliary task to properly recover those masked tokens. Experimental results on several text generation tasks including machine translation (MT), AMR-to-text generation, and image captioning show that the proposed approach can significantly improve over competitive baselines without using any task-specific techniques. This suggests the effectiveness and generality of our proposed approach. Keywords: Natural Language Processing: Machine Translation Natural Language Processing: Natural Language Generation},
  archive   = {C_IJCAI},
  author    = {Zhidong Liu and Junhui Li and Muhua Zhu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/534},
  pages     = {3878-3884},
  title     = {Improving text generation with dynamic masking and recovering},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Discourse-level event temporal ordering with
uncertainty-guided graph completion. <em>IJCAI</em>, 3871–3877. (<a
href="https://doi.org/10.24963/ijcai.2021/533">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Learning to order events at discourse-level is a crucial text understanding task. Despite many efforts for this task, the current state-of-the-art methods rely heavily on manually designed features, which are costly to produce and are often specific to tasks/domains/datasets. In this paper, we propose a new graph perspective on the task, which does not require complex feature engineering but can assimilate global features and learn inter-dependencies effectively. Specifically, in our approach, each document is considered as a temporal graph, in which the nodes and edges represent events and event-event relations respectively. In this sense, the temporal ordering task corresponds to constructing edges for an empty graph. To train our model, we design a graph mask pre-training mechanism, which can learn inter-dependencies of temporal relations by learning to recover a masked edge following graph topology. In the testing stage, we design an certain-first strategy based on model uncertainty, which can decide the prediction orders and reduce the risk of error propagation. The experimental results demonstrate that our approach outperforms previous methods consistently and can meanwhile maintain good global consistency. Keywords: Natural Language Processing: Information Extraction Natural Language Processing: Natural Language Processing},
  archive   = {C_IJCAI},
  author    = {Jian Liu and Jinan Xu and Yufeng Chen and Yujie Zhang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/533},
  pages     = {3871-3877},
  title     = {Discourse-level event temporal ordering with uncertainty-guided graph completion},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Keep the structure: A latent shift-reduce parser for
semantic parsing. <em>IJCAI</em>, 3864–3870. (<a
href="https://doi.org/10.24963/ijcai.2021/532">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Traditional end-to-end semantic parsing models treat a natural language utterance as a holonomic structure. However, hierarchical structures exist in natural languages, which also align with the hierarchical structures of logical forms. In this paper, we propose a latent shift-reduce parser, called LASP, which decomposes both natural language queries and logical form expressions according to their hierarchical structures and finds local alignment between them to enhance semantic parsing. LASP consists of a base parser and a shift-reduce splitter. The splitter dynamically separates an NL query into several spans. The base parser converts the relevant simple spans into logical forms, which are further combined to obtain the final logical form. We conducted empirical studies on two datasets across different domains and different types of logical forms. The results demonstrate that the proposed method significantly improves the performance of semantic parsing, especially on unseen scenarios. Keywords: Natural Language Processing: Natural Language Semantics},
  archive   = {C_IJCAI},
  author    = {Yuntao Li and Bei Chen and Qian Liu and Yan Gao and Jian-Guang Lou and Yan Zhang and Dongmei Zhang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/532},
  pages     = {3864-3870},
  title     = {Keep the structure: A latent shift-reduce parser for semantic parsing},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Asynchronous multi-grained graph network for interpretable
multi-hop reading comprehension. <em>IJCAI</em>, 3857–3863. (<a
href="https://doi.org/10.24963/ijcai.2021/531">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-hop machine reading comprehension (MRC) task aims to enable models to answer the compound question according to the bridging information. Existing methods that use graph neural networks to represent multiple granularities such as entities and sentences in documents update all nodes synchronously, ignoring the fact that multi-hop reasoning has a certain logical order across granular levels. In this paper, we introduce an Asynchronous Multi-grained Graph Network (AMGN) for multi-hop MRC. First, we construct a multigrained graph containing entity and sentence nodes. Particularly, we use independent parameters to represent relationship groups defined according to the level of granularity. Second, an asynchronous update mechanism based on multi-grained relationships is proposed to mimic human multi-hop reading logic. Besides, we present a question reformulation mechanism to update the latent representation of the compound question with updated graph nodes. We evaluate the proposed model on the HotpotQA dataset and achieve top competitive performance in distractor setting compared with other published models. Further analysis shows that the asynchronous update mechanism can effectively form interpretable reasoning chains at different granularity levels. Keywords: Natural Language Processing: Natural Language Processing Natural Language Processing: Question Answering},
  archive   = {C_IJCAI},
  author    = {Ronghan Li and Lifang Wang and Shengli Wang and Zejun Jiang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/531},
  pages     = {3857-3863},
  title     = {Asynchronous multi-grained graph network for interpretable multi-hop reading comprehension},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modelling general properties of nouns by selectively
averaging contextualised embeddings. <em>IJCAI</em>, 3850–3856. (<a
href="https://doi.org/10.24963/ijcai.2021/530">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {While the success of pre-trained language models has largely eliminated the need for high-quality static word vectors in many NLP applications, static word vectors continue to play an important role in tasks where word meaning needs to be modelled in the absence of linguistic context. In this paper, we explore how the contextualised embeddings predicted by BERT can be used to produce high-quality word vectors for such domains, in particular related to knowledge base completion, where our focus is on capturing the semantic properties of nouns. We find that a simple strategy of averaging the contextualised embeddings of masked word mentions leads to vectors that outperform the static word vectors learned by BERT, as well as those from standard word embedding models, in property induction tasks. We notice in particular that masking target words is critical to achieve this strong performance, as the resulting vectors focus less on idiosyncratic properties and more on general semantic properties. Inspired by this view, we propose a filtering strategy which is aimed at removing the most idiosyncratic mention vectors, allowing us to obtain further performance gains in property induction. Keywords: Natural Language Processing: Natural Language Semantics Natural Language Processing: Natural Language Processing},
  archive   = {C_IJCAI},
  author    = {Na Li and Zied Bouraoui and Jose Camacho-Collados and Luis Espinosa-Anke and Qing Gu and Steven Schockaert},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/530},
  pages     = {3850-3856},
  title     = {Modelling general properties of nouns by selectively averaging contextualised embeddings},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Enhancing label representations with relational inductive
bias constraint for fine-grained entity typing. <em>IJCAI</em>,
3843–3849. (<a href="https://doi.org/10.24963/ijcai.2021/529">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Fine-Grained Entity Typing (FGET) is a task that aims at classifying an entity mention into a wide range of entity label types. Recent researches improve the task performance by imposing the label-relational inductive bias based on the hierarchy of labels or label co-occurrence graph. However, they usually overlook explicit interactions between instances and labels which may limit the capability of label representations. Therefore, we propose a novel method based on a two-phase graph network for the FGET task to enhance the label representations, via imposing the relational inductive biases of instance-to-label and label-to-label. In the phase 1, instance features will be introduced into label representations to make the label representations more representative. In the phase 2, interactions of labels will capture dependency relationships among them thus make label representations more smooth. During prediction, we introduce a pseudo-label generator for the construction of the two-phase graph. The input instances differ from batch to batch so that the label representations are dynamic. Experiments on three public datasets verify the effectiveness and stability of our proposed method and achieve state-of-the-art results on their testing sets. Keywords: Natural Language Processing: Named Entities Natural Language Processing: Natural Language Processing Natural Language Processing: Text Classification},
  archive   = {C_IJCAI},
  author    = {Jinqing Li and Xiaojun Chen and Dakui Wang and Yuwei Li},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/529},
  pages     = {3843-3849},
  title     = {Enhancing label representations with relational inductive bias constraint for fine-grained entity typing},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). ALaSca: An automated approach for large-scale lexical
substitution. <em>IJCAI</em>, 3836–3842. (<a
href="https://doi.org/10.24963/ijcai.2021/528">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The lexical substitution task aims at finding suitable replacements for words in context. It has proved to be useful in several areas, such as word sense induction and text simplification, as well as in more practical applications such as writing-assistant tools. However, the paucity of annotated data has forced researchers to apply mainly unsupervised approaches, limiting the applicability of large pre-trained models and thus hampering the potential benefits of supervised approaches to the task. In this paper, we mitigate this issue by proposing ALaSca, a novel approach to automatically creating large-scale datasets for English lexical substitution. ALaSca allows examples to be produced for potentially any word in a language vocabulary and to cover most of the meanings it lists. Thanks to this, we can unleash the full potential of neural architectures and finetune them on the lexical substitution task. Indeed, when using our data, a transformer-based model performs substantially better than when using manually annotated data only. We release ALaSca at https://sapienzanlp.github.io/alasca/. Keywords: Natural Language Processing: Natural Language Semantics Natural Language Processing: Resources and Evaluation},
  archive   = {C_IJCAI},
  author    = {Caterina Lacerra and Tommaso Pasini and Rocco Tripodi and Roberto Navigli},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/528},
  pages     = {3836-3842},
  title     = {ALaSca: An automated approach for large-scale lexical substitution},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). FedSpeech: Federated text-to-speech with continual learning.
<em>IJCAI</em>, 3829–3835. (<a
href="https://doi.org/10.24963/ijcai.2021/527">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Federated learning enables collaborative training of machine learning models under strict privacy restrictions and federated text-to-speech aims to synthesize natural speech of multiple users with a few audio training samples stored in their devices locally. However, federated text-to-speech faces several challenges: very few training samples from each speaker are available, training samples are all stored in local device of each user, and global model is vulnerable to various attacks. In this paper, we propose a novel federated learning architecture based on continual learning approaches to overcome the difficulties above. Specifically, 1) we use gradual pruning masks to isolate parameters for preserving speakers&#39; tones; 2) we apply selective masks for effectively reusing knowledge from tasks; 3) a private speaker embedding is introduced to keep users&#39; privacy. Experiments on a reduced VCTK dataset demonstrate the effectiveness of FedSpeech: it nearly matches multi-task training in terms of multi-speaker speech quality; moreover, it sufficiently retains the speakers&#39; tones and even outperforms the multi-task training in the speaker similarity experiment. Keywords: Natural Language Processing: Speech Data Mining: Federated Learning Data Mining: Privacy Preserving Data Mining},
  archive   = {C_IJCAI},
  author    = {Ziyue Jiang and Yi Ren and Ming Lei and Zhou Zhao},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/527},
  pages     = {3829-3835},
  title     = {FedSpeech: Federated text-to-speech with continual learning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dialogue disentanglement in software engineering: How far
are we? <em>IJCAI</em>, 3822–3828. (<a
href="https://doi.org/10.24963/ijcai.2021/526">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Despite the valuable information contained in software chat messages, disentangling them into distinct conversations is an essential prerequisite for any in-depth analyses that utilize this information. To provide a better understanding of the current state-of-the-art, we evaluate five popular dialog disentanglement approaches on software-related chat. We find that existing approaches do not perform well on disentangling software-related dialogs that discuss technical and complex topics. Further investigation on how well the existing disentanglement measures reflect human satisfaction shows that existing measures cannot correctly indicate human satisfaction on disentanglement results. Therefore, in this paper, we introduce and evaluate a novel measure, named DLD. Using results of human satisfaction, we further summarize four most frequently appeared bad disentanglement cases on software-related chat to insight future improvements. These cases include (i) Ignoring Interaction Patterns, (ii) Ignoring Contextual Information, (iii) Mixing up Topics, and (iv) Ignoring User Relationships. We believe that our findings provide valuable insights on the effectiveness of existing dialog disentanglement approaches and these findings would promote a better application of dialog disentanglement in software engineering. Keywords: Natural Language Processing: Dialogue Natural Language Processing: NLP Applications and Tools Natural Language Processing: Resources and Evaluation},
  archive   = {C_IJCAI},
  author    = {Ziyou Jiang and Lin Shi and Celia Chen and Jun Hu and Qing Wang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/526},
  pages     = {3822-3828},
  title     = {Dialogue disentanglement in software engineering: How far are we?},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automatically paraphrasing via sentence reconstruction and
round-trip translation. <em>IJCAI</em>, 3815–3821. (<a
href="https://doi.org/10.24963/ijcai.2021/525">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Paraphrase generation plays key roles in NLP tasks such as question answering, machine translation, and information retrieval. In this paper, we propose a novel framework for paraphrase generation. It simultaneously decodes the output sentence using a pretrained wordset-to-sequence model and a round-trip translation model. We evaluate this framework on Quora, WikiAnswers, MSCOCO and Twitter, and show its advantage over previous state-of-the-art unsupervised methods and distantly-supervised methods by significant margins on all datasets. For Quora and WikiAnswers, our framework even performs better than some strongly supervised methods with domain adaptation. Further, we show that the generated paraphrases can be used to augment the training data for machine translation to achieve substantial improvements. Keywords: Natural Language Processing: Machine Translation Natural Language Processing: Natural Language Generation Natural Language Processing: NLP Applications and Tools},
  archive   = {C_IJCAI},
  author    = {Zilu Guo and Zhongqiang Huang and Kenny Q. Zhu and Guandan Chen and Kaibo Zhang and Boxing Chen and Fei Huang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/525},
  pages     = {3815-3821},
  title     = {Automatically paraphrasing via sentence reconstruction and round-trip translation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dialogue discourse-aware graph model and data augmentation
for meeting summarization. <em>IJCAI</em>, 3808–3814. (<a
href="https://doi.org/10.24963/ijcai.2021/524">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Meeting summarization is a challenging task due to its dynamic interaction nature among multiple speakers and lack of sufficient training data. Existing methods view the meeting as a linear sequence of utterances while ignoring the diverse relations between each utterance. Besides, the limited labeled data further hinders the ability of data-hungry neural models. In this paper, we try to mitigate the above challenges by introducing dialogue-discourse relations. First, we present a Dialogue Discourse-Dware Meeting Summarizer (DDAMS) to explicitly model the interaction between utterances in a meeting by modeling different discourse relations. The core module is a relational graph encoder, where the utterances and discourse relations are modeled in a graph interaction manner. Moreover, we devise a Dialogue Discourse-Aware Data Augmentation (DDADA) strategy to construct a pseudo-summarization corpus from existing input meetings, which is 20 times larger than the original dataset and can be used to pretrain DDAMS. Experimental results on AMI and ICSI meeting datasets show that our full system can achieve SOTA performance. Our codes and outputs are available at https://github.com/xcfcode/DDAMS/. Keywords: Natural Language Processing: Natural Language Summarization Natural Language Processing: Natural Language Generation},
  archive   = {C_IJCAI},
  author    = {Xiachong Feng and Xiaocheng Feng and Bing Qin and Xinwei Geng},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/524},
  pages     = {3808-3814},
  title     = {Dialogue discourse-aware graph model and data augmentation for meeting summarization},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Focus on interaction: A novel dynamic graph model for joint
multiple intent detection and slot filling. <em>IJCAI</em>, 3801–3807.
(<a href="https://doi.org/10.24963/ijcai.2021/523">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Intent detection and slot filling are two main tasks for building a spoken language understanding (SLU) system. Since the two tasks are closely related, the joint models for the two tasks always outperform the pipeline models in SLU. However, most joint models directly incorporate multiple intent information for each token, which introduces intent noise into the sentence semantics, causing a decrease in the performance of the joint model. In this paper, we propose a Dynamic Graph Model (DGM) for joint multiple intent detection and slot filling, in which we adopt a sentence-level intent-slot interactive graph to model the correlation between the intents and slot. Besides, we design a novel method of constructing the graph, which can dynamically update the interactive graph and further alleviate the error propagation. Experimental results on several multi-intent and single-intent datasets show that our model not only achieves the state-of-the-art (SOTA) performance but also boosts the speed by three to six times over the SOTA model. Keywords: Natural Language Processing: Dialogue Natural Language Processing: Natural Language Processing},
  archive   = {C_IJCAI},
  author    = {Zeyuan Ding and Zhihao Yang and Hongfei Lin and Jian Wang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/523},
  pages     = {3801-3807},
  title     = {Focus on interaction: A novel dynamic graph model for joint multiple intent detection and slot filling},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving context-aware neural machine translation with
source-side monolingual documents. <em>IJCAI</em>, 3794–3800. (<a
href="https://doi.org/10.24963/ijcai.2021/522">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Document context-aware machine translation remains challenging due to the lack of large-scale document parallel corpora. To make full use of source-side monolingual documents for context-aware NMT, we propose a Pre-training approach with Global Context (PGC). In particular, we first propose a novel self-supervised pre-training task, which contains two training objectives: (1) reconstructing the original sentence from a corrupted version; (2) generating a gap sentence from its left and right neighbouring sentences. Then we design a universal model for PGC which consists of a global context encoder, a sentence encoder and a decoder, with similar architecture to typical context-aware NMT models. We evaluate the effectiveness and generality of our pre-trained PGC model by adapting it to various downstream context-aware NMT models. Detailed experimentation on four different translation tasks demonstrates that our PGC approach significantly improves the translation performance of context-aware NMT. For example, based on the state-of-the-art SAN model, we achieve an averaged improvement of 1.85 BLEU scores and 1.59 Meteor scores on the four translation tasks. Keywords: Natural Language Processing: Machine Translation},
  archive   = {C_IJCAI},
  author    = {Linqing Chen and Junhui Li and Zhengxian Gong and Xiangyu Duan and Boxing Chen and Weihua Luo and Min Zhang and Guodong Zhou},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/522},
  pages     = {3794-3800},
  title     = {Improving context-aware neural machine translation with source-side monolingual documents},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Generating senses and RoLes: An end-to-end model for
dependency- and span-based semantic role labeling. <em>IJCAI</em>,
3786–3793. (<a href="https://doi.org/10.24963/ijcai.2021/521">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Despite the recent great success of the sequence-to-sequence paradigm in Natural Language Processing, the majority of current studies in Semantic Role Labeling (SRL) still frame the problem as a sequence labeling task. In this paper we go against the flow and propose GSRL (Generating Senses and RoLes), the first sequence-to-sequence model for end-to-end SRL. Our approach benefits from recently-proposed decoder-side pretraining techniques to generate both sense and role labels for all the predicates in an input sentence at once, in an end-to-end fashion. Evaluated on standard gold benchmarks, GSRL achieves state-of-the-art results in both dependency- and span-based English SRL, proving empirically that our simple generation-based model can learn to produce complex predicate-argument structures. Finally, we propose a framework for evaluating the robustness of an SRL model in a variety of synthetic low-resource scenarios which can aid human annotators in the creation of better, more diverse, and more challenging gold datasets. We release GSRL at github.com/SapienzaNLP/gsrl. Keywords: Natural Language Processing: Natural Language Semantics Natural Language Processing: Natural Language Generation Natural Language Processing: Natural Language Processing},
  archive   = {C_IJCAI},
  author    = {Rexhina Blloshmi and Simone Conia and Rocco Tripodi and Roberto Navigli},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/521},
  pages     = {3786-3793},
  title     = {Generating senses and RoLes: An end-to-end model for dependency- and span-based semantic role labeling},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exemplification modeling: Can you give me an example,
please? <em>IJCAI</em>, 3779–3785. (<a
href="https://doi.org/10.24963/ijcai.2021/520">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, generative approaches have been used effectively to provide definitions of words in their context. However, the opposite, i.e., generating a usage example given one or more words along with their definitions, has not yet been investigated. In this work, we introduce the novel task of Exemplification Modeling (ExMod), along with a sequence-to-sequence architecture and a training procedure for it. Starting from a set of (word, definition) pairs, our approach is capable of automatically generating high-quality sentences which express the requested semantics. As a result, we can drive the creation of sense-tagged data which cover the full range of meanings in any inventory of interest, and their interactions within sentences. Human annotators agree that the sentences generated are as fluent and semantically-coherent with the input definitions as the sentences in manually-annotated corpora. Indeed, when employed as training data for Word Sense Disambiguation, our examples enable the current state of the art to be outperformed, and higher results to be achieved than when using gold-standard datasets only. We release the pretrained model, the dataset and the software at https://github.com/SapienzaNLP/exmod. Keywords: Natural Language Processing: Natural Language Semantics Natural Language Processing: Resources and Evaluation},
  archive   = {C_IJCAI},
  author    = {Edoardo Barba and Luigi Procopio and Caterina Lacerra and Tommaso Pasini and Roberto Navigli},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/520},
  pages     = {3779-3785},
  title     = {Exemplification modeling: Can you give me an example, please?},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Objective-aware traffic simulation via inverse reinforcement
learning. <em>IJCAI</em>, 3771–3777. (<a
href="https://doi.org/10.24963/ijcai.2021/519">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Traffic simulators act as an essential component in the operating and planning of transportation systems. Conventional traffic simulators usually employ a calibrated physical car-following model to describe vehicles&#39; behaviors and their interactions with traffic environment. However, there is no universal physical model that can accurately predict the pattern of vehicle&#39;s behaviors in different situations. A fixed physical model tends to be less effective in a complicated environment given the non-stationary nature of traffic dynamics. In this paper, we formulate traffic simulation as an inverse reinforcement learning problem, and propose a parameter sharing adversarial inverse reinforcement learning model for dynamics-robust simulation learning. Our proposed model is able to imitate a vehicle&#39;s trajectories in the real world while simultaneously recovering the reward function that reveals the vehicle&#39;s true objective which is invariant to different dynamics. Extensive experiments on synthetic and real-world datasets show the superior performance of our approach compared to state-of-the-art methods and its robustness to variant dynamics of traffic. Keywords: Multidisciplinary Topics and Applications: Transportation Machine Learning Applications: Applications of Reinforcement Learning Data Mining: Mining Spatial, Temporal Data},
  archive   = {C_IJCAI},
  author    = {Guanjie Zheng and Hanyang Liu and Kai Xu and Zhenhui Li},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/519},
  pages     = {3771-3777},
  title     = {Objective-aware traffic simulation via inverse reinforcement learning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Long-term, short-term and sudden event: Trading volume
movement prediction with graph-based multi-view modeling.
<em>IJCAI</em>, 3764–3770. (<a
href="https://doi.org/10.24963/ijcai.2021/518">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Trading volume movement prediction is the key in a variety of financial applications. Despite its importance, there is few research on this topic because of its requirement for comprehensive understanding of information from different sources. For instance, the relation between multiple stocks, recent transaction data and suddenly released events are all essential for understanding trading market. However, most of the previous methods only take the fluctuation information of the past few weeks into consideration, thus yielding poor performance. To handle this issue, we propose a graph-based approach that can incorporate multi-view information, i.e., long-term stock trend, short-term fluctuation and sudden events information jointly into a temporal heterogeneous graph. Besides, our method is equipped with deep canonical analysis to highlight the correlations between different perspectives of fluctuation for better prediction. Experiment results show that our method outperforms strong baselines by a large margin. Keywords: Multidisciplinary Topics and Applications: Economic and Finance Machine Learning: Time-series; Data Streams},
  archive   = {C_IJCAI},
  author    = {Liang Zhao and Wei Li and Ruihan Bao and Keiko Harimoto and Yunfang Wu and Xu Sun},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/518},
  pages     = {3764-3770},
  title     = {Long-term, short-term and sudden event: Trading volume movement prediction with graph-based multi-view modeling},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). CSGNN: Contrastive self-supervised graph neural network for
molecular interaction prediction. <em>IJCAI</em>, 3756–3763. (<a
href="https://doi.org/10.24963/ijcai.2021/517">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Molecular interactions are significant resources for analyzing sophisticated biological systems. Identification of multifarious molecular interactions attracts increasing attention in biomedicine, bioinformatics, and human healthcare communities. Recently, a plethora of methods have been proposed to reveal molecular interactions in one specific domain. However, existing methods heavily rely on features or structures involving molecules, which limits the capacity of transferring the models to other tasks. Therefore, generalized models for the multifarious molecular interaction prediction (MIP) are in demand. In this paper, we propose a contrastive self-supervised graph neural network (CSGNN) to predict molecular interactions. CSGNN injects a mix-hop neighborhood aggregator into a graph neural network (GNN) to capture high-order dependency in the molecular interaction networks and leverages a contrastive self-supervised learning task as a regularizer within a multi-task learning paradigm to enhance the generalization ability. Experiments on seven molecular interaction networks show that CSGNN outperforms classic and state-of-the-art models. Comprehensive experiments indicate that the mix-hop aggregator and the self-supervised regularizer can effectively facilitate the link inference in multifarious molecular networks. Keywords: Multidisciplinary Topics and Applications: AI for Life Science Multidisciplinary Topics and Applications: Biology and Medicine Machine Learning Applications: Bio/Medicine},
  archive   = {C_IJCAI},
  author    = {Chengshuai Zhao and Shuai Liu and Feng Huang and Shichao Liu and Wen Zhang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/517},
  pages     = {3756-3763},
  title     = {CSGNN: Contrastive self-supervised graph neural network for molecular interaction prediction},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). GraphMI: Extracting private graph data from graph neural
networks. <em>IJCAI</em>, 3749–3755. (<a
href="https://doi.org/10.24963/ijcai.2021/516">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As machine learning becomes more widely used for critical applications, the need to study its implications in privacy becomes urgent. Given access to the target model and auxiliary information, model inversion attack aims to infer sensitive features of the training dataset, which leads to great privacy concerns. Despite its success in the grid domain, directly applying model inversion techniques on non grid domains such as graph achieves poor attack performance due to the difficulty to fully exploit the intrinsic properties of graphs and attributes of graph nodes used in GNN models. To bridge this gap, we present Graph Model Inversion attack, which aims to infer edges of the training graph by inverting Graph Neural Networks, one of the most popular graph analysis tools. Specifically, the projected gradient module in our method can tackle the discreteness of graph edges while preserving the sparsity and smoothness of graph features. Moreover, a well designed graph autoencoder module can efficiently exploit graph topology, node attributes, and target model parameters. With the proposed method, we study the connection between model inversion risk and edge influence and show that edges with greater influence are more likely to be recovered. Extensive experiments over several public datasets demonstrate the effectiveness of our method. We also show that differential privacy in its canonical form can hardly defend our attack while preserving decent utility. Keywords: Multidisciplinary Topics and Applications: Security and Privacy Data Mining: Mining Graphs, Semi Structured Data, Complex Data Data Mining: Privacy Preserving Data Mining},
  archive   = {C_IJCAI},
  author    = {Zaixi Zhang and Qi Liu and Zhenya Huang and Hao Wang and Chengqiang Lu and Chuanren Liu and Enhong Chen},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/516},
  pages     = {3749-3755},
  title     = {GraphMI: Extracting private graph data from graph neural networks},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Real-time pricing optimization for ride-hailing quality of
service. <em>IJCAI</em>, 3742–3748. (<a
href="https://doi.org/10.24963/ijcai.2021/515">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {When demand increases beyond the system capacity, riders in ride-hailing/ride-sharing systems often experience long waiting time, resulting in poor customer satisfaction. This paper proposes a spatio-temporal pricing framework (AP-RTRS) to alleviate this challenge and shows how it naturally complements state-of-the-art dispatching and routing algorithms. Specifically, the pricing optimization model regulates demand to ensure that every rider opting to use the system is served within reason-able time: it does so either by reducing demand to meet the capacity constraints or by prompting potential riders to postpone service to a later time. The pricing model is a model-predictive control algorithm that works at a coarser temporal and spatial granularity compared to the real-time dispatching and routing, and naturally integrates vehicle relocations. Simulation experiments indicate that the pricing optimization model achieves short waiting times without sacrificing revenues and geographical fairness. Keywords: Multidisciplinary Topics and Applications: Transportation Multidisciplinary Topics and Applications: Real-Time Systems},
  archive   = {C_IJCAI},
  author    = {Enpeng Yuan and Pascal Van Hentenryck},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/515},
  pages     = {3742-3748},
  title     = {Real-time pricing optimization for ride-hailing quality of service},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SafeDrug: Dual molecular graph encoders for recommending
effective and safe drug combinations. <em>IJCAI</em>, 3735–3741. (<a
href="https://doi.org/10.24963/ijcai.2021/514">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Medication recommendation is an essential task of AI for healthcare. Existing works focused on recommending drug combinations for patients with complex health conditions solely based on their electronic health records. Thus, they have the following limitations: (1) some important data such as drug molecule structures have not been utilized in the recommendation process. (2) drug-drug interactions (DDI) are modeled implicitly, which can lead to sub-optimal results. To address these limitations, we propose a DDI-controllable drug recommendation model named SafeDrug to leverage drugs’ molecule structures and model DDIs explicitly. SafeDrug is equipped with a global message passing neural network (MPNN) module and a local bipartite learning module to fully encode the connectivity and functionality of drug molecules. SafeDrug also has a controllable loss function to control DDI level in the recommended drug combinations effectively. On a benchmark dataset, our SafeDrug is relatively shown to reduce DDI by 19.43\% and improves 2.88\% on Jaccard similarity between recommended and actually prescribed drug combinations over previous approaches. Moreover, SafeDrug also requires much fewer parameters than previous deep learning based approaches, leading to faster training by about 14\% and around 2× speed-up in inference. Keywords: Multidisciplinary Topics and Applications: Biology and Medicine Machine Learning Applications: Applications of Supervised Learning Machine Learning Applications: Bio/Medicine},
  archive   = {C_IJCAI},
  author    = {Chaoqi Yang and Cao Xiao and Fenglong Ma and Lucas Glass and Jimeng Sun},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/514},
  pages     = {3735-3741},
  title     = {SafeDrug: Dual molecular graph encoders for recommending effective and safe drug combinations},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Change matters: Medication change prediction with recurrent
residual networks. <em>IJCAI</em>, 3728–3734. (<a
href="https://doi.org/10.24963/ijcai.2021/513">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep learning is revolutionizing predictive healthcare, including recommending medications to patients with complex health conditions. Existing approaches focus on predicting all medications for the current visit, which often overlaps with medications from previous visits. A more clinically relevant task is to identify medication changes. In this paper, we propose a new recurrent residual networks, named MICRON, for medication change prediction. MICRON takes the changes in patient health records as input and learns to update a hid- den medication vector and the medication set recurrently with a reconstruction design. The medication vector is like the memory cell that encodes longitudinal information of medications. Unlike traditional methods that require the entire patient history for prediction, MICRON has a residual-based inference that allows for sequential updating based only on new patient features (e.g., new diagnoses in the recent visit), which is efficient. We evaluated MICRON on real inpatient and outpatient datasets. MICRON achieves 3.5\% and 7.8\% relative improvements over the best baseline in F1 score, respectively. MICRON also requires fewer parameters, which significantly reduces the training time to 38.3s per epoch with 1.5× speed-up. Keywords: Multidisciplinary Topics and Applications: Biology and Medicine Machine Learning Applications: Applications of Supervised Learning Machine Learning Applications: Bio/Medicine},
  archive   = {C_IJCAI},
  author    = {Chaoqi Yang and Cao Xiao and Lucas Glass and Jimeng Sun},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/513},
  pages     = {3728-3734},
  title     = {Change matters: Medication change prediction with recurrent residual networks},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards generating summaries for lexically confusing code
through code erosion. <em>IJCAI</em>, 3721–3727. (<a
href="https://doi.org/10.24963/ijcai.2021/512">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Code summarization aims to summarize code functionality as high-level nature language descriptions to assist in code comprehension. Recent approaches in this field mainly focus on generating summaries for code with precise identifier names, in which meaningful words can be found indicating code functionality. When faced with lexically confusing code, current approaches are likely to fail since the correlation between code lexical tokens and summaries is scarce. To tackle this problem, we propose a novel summarization framework named VECOS. VECOS introduces an erosion mechanism to conquer the model&#39;s reliance on precisely defined lexical information. To facilitate learning the eroded code&#39;s functionality, we force the representation of the eroded code to align with the representation of its original counterpart via variational inference. Experimental results show that our approach outperforms the state-of-the-art approaches to generate coherent and reliable summaries for various lexically confusing code. Keywords: Multidisciplinary Topics and Applications: Knowledge-based Software Engineering Data Mining: Mining Codebase and Software Repository},
  archive   = {C_IJCAI},
  author    = {Fan Yan and Ming Li},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/512},
  pages     = {3721-3727},
  title     = {Towards generating summaries for lexically confusing code through code erosion},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Solving large-scale extensive-form network security games
via neural fictitious self-play. <em>IJCAI</em>, 3713–3720. (<a
href="https://doi.org/10.24963/ijcai.2021/511">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Securing networked infrastructures is important in the real world. The problem of deploying security resources to protect against an attacker in networked domains can be modeled as Network Security Games (NSGs). Unfortunately, existing approaches, including the deep learning-based approaches, are inefficient to solve large-scale extensive-form NSGs. In this paper, we propose a novel learning paradigm, NSG-NFSP, to solve large-scale extensive-form NSGs based on Neural Fictitious Self-Play (NFSP). Our main contributions include: i) reforming the best response (BR) policy network in NFSP to be a mapping from action-state pair to action-value, to make the calculation of BR possible in NSGs; ii) converting the average policy network of an NFSP agent into a metric-based classifier, helping the agent to assign distributions only on legal actions rather than all actions; iii) enabling NFSP with high-level actions, which can benefit training efficiency and stability in NSGs; and iv) leveraging information contained in graphs of NSGs by learning efficient graph node embeddings. Our algorithm significantly outperforms state-of-the-art algorithms in both scalability and solution quality. Keywords: Multidisciplinary Topics and Applications: Security and Privacy Multidisciplinary Topics and Applications: Computational Sustainability},
  archive   = {C_IJCAI},
  author    = {Wanqi Xue and Youzhi Zhang and Shuxin Li and Xinrun Wang and Bo An and Chai Kiat Yeo},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/511},
  pages     = {3713-3720},
  title     = {Solving large-scale extensive-form network security games via neural fictitious self-play},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hiding numerical vectors in local private and shuffled
messages. <em>IJCAI</em>, 3706–3712. (<a
href="https://doi.org/10.24963/ijcai.2021/510">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Numerical vector aggregation has numerous applications in privacy-sensitive scenarios, such as distributed gradient estimation in federated learning, and statistical analysis on key-value data. Within the framework of local differential privacy, this work gives tight minimax error bounds of O(d s/(n epsilon^2)), where d is the dimension of the numerical vector and s is the number of non-zero entries. An attainable mechanism is then designed to improve from existing approaches suffering error rate of O(d^2/(n epsilon^2)) or O(d s^2/(n epsilon^2)). To break the error barrier in the local privacy, this work further consider privacy amplification in the shuffle model with anonymous channels, and shows the mechanism satisfies centralized (14 ln(2/delta) (s e^epsilon+2s-1)/(n-1))^0.5, delta)-differential privacy, which is domain independent and thus scales to federated learning of large models. We experimentally validate and compare it with existing approaches, and demonstrate its significant error reduction. Keywords: Multidisciplinary Topics and Applications: Security and Privacy},
  archive   = {C_IJCAI},
  author    = {Shaowei Wang and Jin Li and Yuqiu Qian and Jiachun Du and Wenqing Lin and Wei Yang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/510},
  pages     = {3706-3712},
  title     = {Hiding numerical vectors in local private and shuffled messages},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). BACKDOORL: Backdoor attack against competitive reinforcement
learning. <em>IJCAI</em>, 3699–3705. (<a
href="https://doi.org/10.24963/ijcai.2021/509">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent research has confirmed the feasibility of backdoor attacks in deep reinforcement learning (RL) systems. However, the existing attacks require the ability to arbitrarily modify an agent&#39;s observation, constraining the application scope to simple RL systems such as Atari games. In this paper, we migrate backdoor attacks to more complex RL systems involving multiple agents and explore the possibility of triggering the backdoor without directly manipulating the agent&#39;s observation. As a proof of concept, we demonstrate that an adversary agent can trigger the backdoor of the victim agent with its own action in two-player competitive RL systems. We prototype and evaluate BackdooRL in four competitive environments. The results show that when the backdoor is activated, the winning rate of the victim drops by 17\% to 37\% compared to when not activated. The videos are hosted at https://github.com/wanglun1996/multi_agent_rl_backdoor_videos. Keywords: Multidisciplinary Topics and Applications: Security and Privacy Agent-based and Multi-agent Systems: Multi-agent Learning},
  archive   = {C_IJCAI},
  author    = {Lun Wang and Zaynah Javed and Xian Wu and Wenbo Guo and Xinyu Xing and Dawn Song},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/509},
  pages     = {3699-3705},
  title     = {BACKDOORL: Backdoor attack against competitive reinforcement learning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Hierarchical adaptive temporal-relational modeling for
stock trend prediction. <em>IJCAI</em>, 3691–3698. (<a
href="https://doi.org/10.24963/ijcai.2021/508">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Stock trend prediction is a challenging task due to the non-stationary dynamics and complex market dependencies. Existing methods usually regard each stock as isolated for prediction, or simply detect their correlations based on a fixed predefined graph structure. Genuinely, stock associations stem from diverse aspects, the underlying relation signals should be implicit in comprehensive graphs. On the other hand, the RNN network is mainly used to model stock historical data, while is hard to capture fine-granular volatility patterns implied in different time spans. In this paper, we propose a novel Hierarchical Adaptive Temporal-Relational Network (HATR) to characterize and predict stock evolutions. By stacking dilated causal convolutions and gating paths, short- and long-term transition features are gradually grasped from multi-scale local compositions of stock trading sequences. Particularly, a dual attention mechanism with Hawkes process and target-specific query is proposed to detect significant temporal points and scales conditioned on individual stock traits. Furthermore, we develop a multi-graph interaction module which consolidates prior domain knowledge and data-driven adaptive learning to capture interdependencies among stocks. All components are integrated seamlessly in a unified end-to-end framework. Experiments on three real-world stock market datasets validate the effectiveness of our model. Keywords: Multidisciplinary Topics and Applications: Economic and Finance Data Mining: Classification},
  archive   = {C_IJCAI},
  author    = {Heyuan Wang and Shun Li and Tengjiao Wang and Jiayi Zheng},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/508},
  pages     = {3691-3698},
  title     = {Hierarchical adaptive temporal-relational modeling for stock trend prediction},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adapting meta knowledge with heterogeneous information
network for COVID-19 themed malicious repository detection.
<em>IJCAI</em>, 3684–3690. (<a
href="https://doi.org/10.24963/ijcai.2021/507">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As cyberattacks caused by malware have proliferated during the pandemic, building an automatic system to detect COVID-19 themed malware in social coding platforms is in urgent need. The existing methods mainly rely on file content analysis while ignoring structured information among entities in social coding platforms. Additionally, they usually require sufficient data for model training, impairing their performances over cases with limited data which is common in reality. To address these challenges, we develop Meta-AHIN, a novel model for COVID-19 themed malicious repository detection in GitHub. In Meta-AHIN, we first construct an attributed heterogeneous information network (AHIN) to model the code content and social coding properties in GitHub; and then we exploit attention-based graph convolutional neural network (AGCN) to learn repository embeddings and present a meta-learning framework for model optimization. To utilize unlabeled information in AHIN and to consider task influence of different types of repositories, we further incorporate node attribute-based self-supervised module and task-aware attention weight into AGCN and meta-learning respectively. Extensive experiments on the collected data from GitHub demonstrate that Meta-AHIN outperforms state-of-the-art methods. Keywords: Multidisciplinary Topics and Applications: Security and Privacy Data Mining: Classification Data Mining: Mining Graphs, Semi Structured Data, Complex Data},
  archive   = {C_IJCAI},
  author    = {Yiyue Qian and Yiming Zhang and Yanfang Ye and Chuxu Zhang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/507},
  pages     = {3684-3690},
  title     = {Adapting meta knowledge with heterogeneous information network for COVID-19 themed malicious repository detection},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning unknown from correlations: Graph neural network for
inter-novel-protein interaction prediction. <em>IJCAI</em>, 3677–3683.
(<a href="https://doi.org/10.24963/ijcai.2021/506">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The study of multi-type Protein-Protein Interaction (PPI) is fundamental for understanding biological processes from a systematic perspective and revealing disease mechanisms. Existing methods suffer from significant performance degradation when tested in unseen dataset. In this paper, we investigate the problem and find that it is mainly attributed to the poor performance for inter-novel-protein interaction prediction. However, current evaluations overlook the inter-novel-protein interactions, and thus fail to give an instructive assessment. As a result, we propose to address the problem from both the evaluation and the methodology. Firstly, we design a new evaluation framework that fully respects the inter-novel-protein interactions and gives consistent assessment across datasets. Secondly, we argue that correlations between proteins must provide useful information for analysis of novel proteins, and based on this, we propose a graph neural network based method (GNN-PPI) for better inter-novel-protein interaction prediction. Experimental results on real-world datasets of different scales demonstrate that GNN-PPI significantly outperforms state-of-the-art PPI prediction methods, especially for the inter-novel-protein interaction prediction. Keywords: Multidisciplinary Topics and Applications: Biology and Medicine Machine Learning Applications: Bio/Medicine},
  archive   = {C_IJCAI},
  author    = {Guofeng Lv and Zhiqiang Hu and Yanguang Bi and Shaoting Zhang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/506},
  pages     = {3677-3683},
  title     = {Learning unknown from correlations: Graph neural network for inter-novel-protein interaction prediction},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Online credit payment fraud detection via structure-aware
hierarchical recurrent neural network. <em>IJCAI</em>, 3670–3676. (<a
href="https://doi.org/10.24963/ijcai.2021/505">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Online credit payment fraud detection plays a critical role in financial institutions due to the growing volume of fraudulent transactions. Recently, researchers have shown an increased interest in capturing users’ dynamic and evolving fraudulent tendencies from their behavior sequences. However, most existing methodologies for sequential modeling overlook the intrinsic structure information of web pages. In this paper, we adopt multi-scale behavior sequence generated from different granularities of web page structures and propose a model named SAH-RNN to consume the multi-scale behavior sequence for online payment fraud detection. The SAH-RNN has stacked RNN layers in which upper layers modeling for compendious behaviors are updated less frequently and receive the summarized representations from lower layers. A dual attention is devised to capture the impacts on both sequential information within the same sequence and structural information among different granularity of web pages. Experimental results on a large-scale real-world transaction dataset from Alibaba show that our proposed model outperforms state-of-the-art models. The code is available at https://github.com/WangliLin/SAH-RNN. Keywords: Multidisciplinary Topics and Applications: Economic and Finance Data Mining: Mining Text, Web, Social Media Humans and AI: Personalization and User Modeling},
  archive   = {C_IJCAI},
  author    = {Wangli Lin and Li Sun and Qiwei Zhong and Can Liu and Jinghua Feng and Xiang Ao and Hao Yang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/505},
  pages     = {3670-3676},
  title     = {Online credit payment fraud detection via structure-aware hierarchical recurrent neural network},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). CFR-MIX: Solving imperfect information extensive-form games
with combinatorial action space. <em>IJCAI</em>, 3663–3669. (<a
href="https://doi.org/10.24963/ijcai.2021/504">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In many real-world scenarios, a team of agents must coordinate with each other to compete against an opponent. The challenge of solving this type of game is that the team&#39;s joint action space grows exponentially with the number of agents, which results in the inefficiency of the existing algorithms, e.g., Counterfactual Regret Minimization (CFR). To address this problem, we propose a new framework of CFR: CFR-MIX. Firstly, we propose a new strategy representation that represents a joint action strategy using individual strategies of all agents and a consistency relationship to maintain the cooperation between agents. To compute the equilibrium with individual strategies under the CFR framework, we transform the consistency relationship between strategies to the consistency relationship between the cumulative regret values. Furthermore, we propose a novel decomposition method over cumulative regret values to guarantee the consistency relationship between the cumulative regret values. Finally, we introduce our new algorithm CFR-MIX which employs a mixing layer to estimate cumulative regret values of joint actions as a non-linear combination of cumulative regret values of individual actions. Experimental results show that CFR-MIX outperforms existing algorithms on various games significantly. Keywords: Multidisciplinary Topics and Applications: Security and Privacy Agent-based and Multi-agent Systems: Noncooperative Games Multidisciplinary Topics and Applications: Computational Sustainability},
  archive   = {C_IJCAI},
  author    = {Shuxin Li and Youzhi Zhang and Xinrun Wang and Wanqi Xue and Bo An},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/504},
  pages     = {3663-3669},
  title     = {CFR-MIX: Solving imperfect information extensive-form games with combinatorial action space},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Traffic congestion alleviation over dynamic road networks:
Continuous optimal route combination for trip query streams.
<em>IJCAI</em>, 3656–3662. (<a
href="https://doi.org/10.24963/ijcai.2021/503">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Route planning and recommendation have attracted much attention for decades. In this paper, we study a continuous optimal route combination problem: Given a dynamic road network and a stream of trip queries, we continuously find an optimal route combination for each new query batch over the query stream such that the total travel time for all routes is minimized. Each route corresponds to a planning result for a particular trip query in the current query batch. Our problem targets a variety of applications, including traffic-flow management, real-time route planning and continuous congestion prevention. The exact algorithm bears exponential time complexity and is computationally prohibitive for application scenarios in dynamic traffic networks. To address this problem, a self-aware batch processing algorithm is developed in this paper. Extensive experiments offer insight into the accuracy and efficiency of our proposed algorithms. Keywords: Multidisciplinary Topics and Applications: Transportation},
  archive   = {C_IJCAI},
  author    = {Ke Li and Lisi Chen and Shuo Shang and Panos Kalnis and Bin Yao},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/503},
  pages     = {3656-3662},
  title     = {Traffic congestion alleviation over dynamic road networks: Continuous optimal route combination for trip query streams},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Differentially private correlation alignment for domain
adaptation. <em>IJCAI</em>, 3649–3655. (<a
href="https://doi.org/10.24963/ijcai.2021/502">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Domain adaptation solves a learning problem in a target domain by utilizing the training data in a different but related source domain. As a simple and efficient method for domain adaptation, correlation alignment transforms the distribution of the source domain by utilizing the covariance matrix of the target domain, such that a model trained on the transformed source data can be applied to the target data. However, when source and target domains come from different institutes, exchanging information between the two domains might pose a potential privacy risk. In this paper, for the first time, we propose a differentially private correlation alignment approach for domain adaptation called PRIMA, which can provide privacy guarantees for both the source and target data. In PRIMA, to relieve the performance degradation caused by perturbing the covariance matrix in high dimensional setting, we present a random subspace ensemble based covariance estimation method which splits the feature spaces of source and target data into several low dimensional subspaces. Moreover, since perturbing the covariance matrix may destroy its positive semi-definiteness, we develop a shrinking based method for the recovery of positive semi-definiteness of the covariance matrix. Experimental results on standard benchmark datasets confirm the effectiveness of our approach. Keywords: Multidisciplinary Topics and Applications: Security and Privacy Machine Learning: Transfer, Adaptation, Multi-task Learning},
  archive   = {C_IJCAI},
  author    = {Kaizhong Jin and Xiang Cheng and Jiaxi Yang and Kaiyuan Shen},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/502},
  pages     = {3649-3655},
  title     = {Differentially private correlation alignment for domain adaptation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic lane traffic signal control with group attention and
multi-timescale reinforcement learning. <em>IJCAI</em>, 3642–3648. (<a
href="https://doi.org/10.24963/ijcai.2021/501">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Traffic signal control has achieved significant success with the development of reinforcement learning. However, existing works mainly focus on intersections with normal lanes with fixed outgoing directions. It is noticed that some intersections actually implement dynamic lanes, in addition to normal lanes, to adjust the outgoing directions dynamically. Existing methods fail to coordinate the control of traffic signal and that of dynamic lanes effectively. In addition, they lack proper structures and learning algorithms to make full use of traffic flow prediction, which is essential to set the proper directions for dynamic lanes. Motivated by the ineffectiveness of existing approaches when controlling the traffic signal and dynamic lanes simultaneously, we propose a new method, namely MT-GAD, in this paper. It uses a group attention structure to reduce the number of required parameters and to achieve a better generalizability, and uses multi-timescale model training to learn proper strategy that could best control both the traffic signal and the dynamic lanes. The experiments on real datasets demonstrate that MT-GAD outperforms existing approaches significantly. Keywords: Multidisciplinary Topics and Applications: Transportation Machine Learning Applications: Applications of Reinforcement Learning},
  archive   = {C_IJCAI},
  author    = {Qize Jiang and Jingze Li and Weiwei Sun and Baihua Zheng},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/501},
  pages     = {3642-3648},
  title     = {Dynamic lane traffic signal control with group attention and multi-timescale reinforcement learning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fine-tuning is not enough: A simple yet effective watermark
removal attack for DNN models. <em>IJCAI</em>, 3635–3641. (<a
href="https://doi.org/10.24963/ijcai.2021/500">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Watermarking has become the tendency in protecting the intellectual property of DNN models. Recent works, from the adversary&#39;s perspective, attempted to subvert watermarking mechanisms by designing watermark removal attacks. However, these attacks mainly adopted sophisticated fine-tuning techniques, which have certain fatal drawbacks or unrealistic assumptions. In this paper, we propose a novel watermark removal attack from a different perspective. Instead of just fine-tuning the watermarked models, we design a simple yet powerful transformation algorithm by combining imperceptible pattern embedding and spatial-level transformations, which can effectively and blindly destroy the memorization of watermarked models to the watermark samples. We also introduce a lightweight fine-tuning strategy to preserve the model performance. Our solution requires much less resource or knowledge about the watermarking scheme than prior works. Extensive experimental results indicate that our attack can bypass state-of-the-art watermarking solutions with very high success rates. Based on our attack, we propose watermark augmentation techniques to enhance the robustness of existing watermarks. Keywords: Multidisciplinary Topics and Applications: Economic and Finance Multidisciplinary Topics and Applications: Security and Privacy},
  archive   = {C_IJCAI},
  author    = {Shangwei Guo and Tianwei Zhang and Han Qiu and Yi Zeng and Tao Xiang and Yang Liu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/500},
  pages     = {3635-3641},
  title     = {Fine-tuning is not enough: A simple yet effective watermark removal attack for DNN models},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Predictive job scheduling under uncertain constraints in
cloud computing. <em>IJCAI</em>, 3627–3634. (<a
href="https://doi.org/10.24963/ijcai.2021/499">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Capacity management has always been a great challenge for cloud platforms due to massive, heterogeneous on-demand instances running at different times. To better plan the capacity for the whole platform, a class of cloud computing instances have been released to collect computing demands beforehand. To use such instances, users are allowed to submit jobs to run for a pre-specified uninterrupted duration in a flexible range of time in the future with a discount compared to the normal on-demand instances. Proactively scheduling those pre-collected job requests considering the capacity status over the platform can greatly help balance the computing workloads along time. In this work, we formulate the scheduling problem for these pre-collected job requests under uncertain available capacity as a Prediction + Optimization problem with uncertainty in constraints, and propose an effective algorithm called Controlling under Uncertain Constraints (CUC), where the predicted capacity guides the optimization of job scheduling and job scheduling results are leveraged to improve the prediction of capacity through Bayesian optimization. The proposed formulation and solution are commonly applicable for proactively scheduling problems in cloud computing. Our extensive experiments on three public, industrial datasets shows that CUC has great potential for supporting high reliability in cloud platforms. Keywords: Multidisciplinary Topics and Applications: Autonomic Computing Heuristic Search and Game Playing: Heuristic Search and Machine Learning},
  archive   = {C_IJCAI},
  author    = {Hang Dong and Boshi Wang and Bo Qiao and Wenqian Xing and Chuan Luo and Si Qin and Qingwei Lin and Dongmei Zhang and Gurpreet Virdi and Thomas Moscibroda},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/499},
  pages     = {3627-3634},
  title     = {Predictive job scheduling under uncertain constraints in cloud computing},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). TrafficStream: A streaming traffic flow forecasting
framework based on graph neural networks and continual learning.
<em>IJCAI</em>, 3620–3626. (<a
href="https://doi.org/10.24963/ijcai.2021/498">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With the rapid growth of traffic sensors deployed, a massive amount of traffic flow data are collected, revealing the long-term evolution of traffic flows and the gradual expansion of traffic networks. How to accurately forecasting these traffic flow attracts the attention of researchers as it is of great significance for improving the efficiency of transportation systems. However, existing methods mainly focus on the spatial-temporal correlation of static networks, leaving the problem of efficiently learning models on networks with expansion and evolving patterns less studied. To tackle this problem, we propose a Streaming Traffic Flow Forecasting Framework, TrafficStream, based on Graph Neural Networks (GNNs) and Continual Learning (CL), achieving accurate predictions and high efficiency. Firstly, we design a traffic pattern fusion method, cleverly integrating the new patterns that emerged during the long-term period into the model. A JS-divergence-based algorithm is proposed to mine new traffic patterns. Secondly, we introduce CL to consolidate the knowledge learned previously and transfer them to the current model. Specifically, we adopt two strategies: historical data replay and parameter smoothing. We construct a streaming traffic data set to verify the efficiency and effectiveness of our model. Extensive experiments demonstrate its excellent potential to extract traffic patterns with high efficiency on long-term streaming network scene. The source code is available at https://github.com/AprLie/TrafficStream. Keywords: Multidisciplinary Topics and Applications: Transportation Machine Learning Applications: Networks Data Mining: Mining Spatial, Temporal Data},
  archive   = {C_IJCAI},
  author    = {Xu Chen and Junshan Wang and Kunqing Xie},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/498},
  pages     = {3620-3626},
  title     = {TrafficStream: A streaming traffic flow forecasting framework based on graph neural networks and continual learning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Parallel subtrajectory alignment over massive-scale
trajectory data. <em>IJCAI</em>, 3613–3619. (<a
href="https://doi.org/10.24963/ijcai.2021/497">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the problem of subtrajectory alignment over massive-scale trajectory data. Given a collection of trajectories, a subtrajectory alignment query returns new targeted trajectories by splitting and aligning existing trajectories. The resulting functionality targets a range of applications, including trajectory data analysis, route planning and recommendation, ridesharing, and general location-based services. To enable efficient and effective subtrajectory alignment computation, we propose a novel search algorithm and filtering techniques that enable the use of the parallel processing capabilities of modern processors. Experiments with large trajectory datasets are conducted for evaluating the performance of our proposal. The results show that our solution to the subtrajectory alignment problem can generate high-quality results and are capable of achieving high efficiency and scalability. Keywords: Multidisciplinary Topics and Applications: Transportation Data Mining: Mining Spatial, Temporal Data},
  archive   = {C_IJCAI},
  author    = {Lisi Chen and Shuo Shang and Shanshan Feng and Panos Kalnis},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/497},
  pages     = {3613-3619},
  title     = {Parallel subtrajectory alignment over massive-scale trajectory data},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel sequence-to-subgraph framework for diagnosis
classification. <em>IJCAI</em>, 3606–3612. (<a
href="https://doi.org/10.24963/ijcai.2021/496">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Text-based diagnosis classification is a critical problem in AI-enabled healthcare studies, which assists clinicians in making correct decision and lowering the rate of diagnostic errors. Previous studies follow the routine of sequence based deep learning models in NLP literature to deal with clinical notes. However, recent studies find that structural information is important in clinical contents that greatly impacts the predictions. In this paper, a novel sequence-to-subgraph framework is introduced to process clinical texts for classification, which changes the paradigm of managing texts. Moreover, a new classification model under the framework is proposed that incorporates subgraph convolutional network and hierarchical diagnostic attentive network to extract the layered structural features of clinical texts. The evaluation conducted on both the real-world English and Chinese datasets shows that the proposed method outperforms the state-of-the-art deep learning based diagnosis classification models. Keywords: Multidisciplinary Topics and Applications: Biology and Medicine Machine Learning Applications: Bio/Medicine Natural Language Processing: NLP Applications and Tools},
  archive   = {C_IJCAI},
  author    = {Jun Chen and Quan Yuan and Chao Lu and Haifeng Huang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/496},
  pages     = {3606-3612},
  title     = {A novel sequence-to-subgraph framework for diagnosis classification},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Electrocardio panorama: Synthesizing new ECG views with
self-supervision. <em>IJCAI</em>, 3597–3605. (<a
href="https://doi.org/10.24963/ijcai.2021/495">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-lead electrocardiogram (ECG) provides clinical information of heartbeats from several fixed viewpoints determined by the lead positioning. However, it is often not satisfactory to visualize ECG signals in these fixed and limited views, as some clinically useful information is represented only from a few specific ECG viewpoints. For the first time, we propose a new concept, Electrocardio Panorama, which allows visualizing ECG signals from any queried viewpoints. To build Electrocardio Panorama, we assume that an underlying electrocardio field exists, representing locations, magnitudes, and directions of ECG signals. We present a Neural electrocardio field Network (Nef-Net), which first predicts the electrocardio field representation by using a sparse set of one or few input ECG views and then synthesizes Electrocardio Panorama based on the predicted representations. Specially, to better disentangle electrocardio field information from viewpoint biases, a new Angular Encoding is proposed to process viewpoint angles. Also, we propose a self-supervised learning approach called Standin Learning, which helps model the electrocardio field without direct supervision. Further, with very few modifications, Nef-Net can synthesize ECG signals from scratch. Experiments verify that our Nef-Net performs well on Electrocardio Panorama synthesis, and outperforms the previous work on the auxiliary tasks (ECG view transformation and ECG synthesis from scratch). The codes and the division labels of cardiac cycles and ECG deflections on Tianchi ECG and PTB datasets are available at https://github.com/WhatAShot/Electrocardio-Panorama. Keywords: Multidisciplinary Topics and Applications: Biology and Medicine Machine Learning Applications: Bio/Medicine Humans and AI: Computational Sustainability and Human Well-Being Machine Learning: Weakly Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Jintai Chen and Xiangshang Zheng and Hongyun Yu and Danny Z. Chen and Jian Wu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/495},
  pages     = {3597-3605},
  title     = {Electrocardio panorama: Synthesizing new ECG views with self-supervision},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A rule mining-based advanced persistent threats detection
system. <em>IJCAI</em>, 3589–3596. (<a
href="https://doi.org/10.24963/ijcai.2021/494">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Advanced persistent threats (APT) are stealthy cyber-attacks that are aimed at stealing valuable information from target organizations and tend to extend in time. Blocking all APTs is impossible, security experts caution, hence the importance of research on early detection and damage limitation. Whole-system provenance-tracking and provenance trace mining are considered promising as they can help find causal relationships between activities and flag suspicious event sequences as they occur. We introduce an unsupervised method that exploits OS-independent features reflecting process activity to detect realistic APT-like attacks from provenance traces. Anomalous processes are ranked using both frequent and rare event associations learned from traces. Results are then presented as implications which, since interpretable, help leverage causality in explaining the detected anomalies. When evaluated on Transparent Computing program datasets (DARPA), our method outperformed competing approaches. Keywords: Multidisciplinary Topics and Applications: Security and Privacy Data Mining: Frequent Pattern Mining Data Mining: Anomaly/Outlier Detection},
  archive   = {C_IJCAI},
  author    = {Sidahmed Benabderrahmane and Ghita Berrada and James Cheney and Petko Valtchev},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/494},
  pages     = {3589-3596},
  title     = {A rule mining-based advanced persistent threats detection system},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Multi-series time-aware sequence partitioning for disease
progression modeling. <em>IJCAI</em>, 3581–3587. (<a
href="https://doi.org/10.24963/ijcai.2021/493">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Electronic healthcare records (EHRs) are comprehensive longitudinal collections of patient data that play a critical role in modeling the disease progression to facilitate clinical decision-making. Based on EHRs, in this work, we focus on sepsis -- a broad syndrome that can develop from nearly all types of infections (e.g., influenza, pneumonia). The symptoms of sepsis, such as elevated heart rate, fever, and shortness of breath, are vague and common to other illnesses, making the modeling of its progression extremely challenging. Motivated by the recent success of a novel subsequence clustering approach: Toeplitz Inverse Covariance-based Clustering (TICC), we model the sepsis progression as a subsequence partitioning problem and propose a Multi-series Time-aware TICC (MT-TICC), which incorporates multi-series nature and irregular time intervals of EHRs. The effectiveness of MT-TICC is first validated via a case study using a real-world hand gesture dataset with ground-truth labels. Then we further apply it for sepsis progression modeling using EHRs. The results suggest that MT-TICC can significantly outperform competitive baseline models, including the TICC. More importantly, it unveils interpretable patterns, which sheds some light on better understanding the sepsis progression. Keywords: Machine Learning Applications: Applications of Unsupervised Learning Machine Learning: Time-series; Data Streams Machine Learning: Explainable/Interpretable Machine Learning},
  archive   = {C_IJCAI},
  author    = {Xi Yang and Yuan Zhang and Min Chi},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/493},
  pages     = {3581-3587},
  title     = {Multi-series time-aware sequence partitioning for disease progression modeling},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Boosting offline reinforcement learning with residual
generative modeling. <em>IJCAI</em>, 3574–3580. (<a
href="https://doi.org/10.24963/ijcai.2021/492">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Offline reinforcement learning (RL) tries to learn the near-optimal policy with recorded offline experience without online exploration.Current offline RL research includes: 1) generative modeling, i.e., approximating a policy using fixed data; and 2) learning the state-action value function. While most research focuses on the state-action function part through reducing the bootstrapping error in value function approximation induced by the distribution shift of training data, the effects of error propagation in generative modeling have been neglected. In this paper, we analyze the error in generative modeling. We propose AQL (action-conditioned Q-learning), a residual generative model to reduce policy approximation error for offline RL. We show that our method can learn more accurate policy approximations in different benchmark datasets. In addition, we show that the proposed offline RL method can learn more competitive AI agents in complex control tasks under the multiplayer online battle arena (MOBA) game, Honor of Kings. Keywords: Machine Learning Applications: Applications of Reinforcement Learning Machine Learning Applications: Game Playing Machine Learning: Reinforcement Learning},
  archive   = {C_IJCAI},
  author    = {Hua Wei and Deheng Ye and Zhao Liu and Hao Wu and Bo Yuan and Qiang Fu and Wei Yang and Zhenhui Li},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/492},
  pages     = {3574-3580},
  title     = {Boosting offline reinforcement learning with residual generative modeling},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Ordering-based causal discovery with reinforcement
learning. <em>IJCAI</em>, 3566–3573. (<a
href="https://doi.org/10.24963/ijcai.2021/491">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {It is a long-standing question to discover causal relations among a set of variables in many empirical sciences. Recently, Reinforcement Learning (RL) has achieved promising results in causal discovery from observational data. However, searching the space of directed graphs and enforcing acyclicity by implicit penalties tend to be inefficient and restrict the existing RL-based method to small scale problems. In this work, we propose a novel RL-based approach for causal discovery, by incorporating RL into the ordering-based paradigm. Specifically, we formulate the ordering search problem as a multi-step Markov decision process, implement the ordering generating process with an encoder-decoder architecture, and finally use RL to optimize the proposed model based on the reward mechanisms designed for each ordering. A generated ordering would then be processed using variable selection to obtain the final causal graph. We analyze the consistency and computational complexity of the proposed method, and empirically show that a pretrained model can be exploited to accelerate training. Experimental results on both synthetic and real data sets shows that the proposed method achieves a much improved performance over existing RL-based method. Keywords: Machine Learning Applications: Applications of Reinforcement Learning Uncertainty in AI: Bayesian Networks},
  archive   = {C_IJCAI},
  author    = {Xiaoqiang Wang and Yali Du and Shengyu Zhu and Liangjun Ke and Zhitang Chen and Jianye Hao and Jun Wang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/491},
  pages     = {3566-3573},
  title     = {Ordering-based causal discovery with reinforcement learning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive residue-wise profile fusion for low homologous
protein secondary structure prediction using external knowledge.
<em>IJCAI</em>, 3559–3565. (<a
href="https://doi.org/10.24963/ijcai.2021/490">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Protein secondary structure prediction (PSSP) is essential for protein function analysis. However, for low homologous proteins, the PSSP suffers from insufficient input features. In this paper, we explicitly import external self-supervised knowledge for low homologous PSSP under the guidance of residue-wise (amino acid wise) profile fusion. In practice, we firstly demonstrate the superiority of profile over Position-Specific Scoring Matrix (PSSM) for low homologous PSSP. Based on this observation, we introduce the novel self-supervised BERT features as the pseudo profile, which implicitly involves the residue distribution in all native discovered sequences as the complementary features. Furthermore, a novel residue-wise attention is specially designed to adaptively fuse different features (i.e., original low-quality profile, BERT based pseudo profile), which not only takes full advantage of each feature but also avoids noise disturbance. Besides, the feature consistency loss is proposed to accelerate the model learning from multiple semantic levels. Extensive experiments confirm that our method outperforms state-of-the-arts (i.e., 4.7\% for extremely low homologous cases on BC40 dataset). Keywords: Machine Learning Applications: Bio/Medicine Natural Language Processing: NLP Applications and Tools},
  archive   = {C_IJCAI},
  author    = {Qin Wang and Jun Wei and Boyuan Wang and Zhen Li and Sheng Wang and Shuguang Cui},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/490},
  pages     = {3559-3565},
  title     = {Adaptive residue-wise profile fusion for low homologous protein secondary structure prediction using external knowledge},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). TEC: A time evolving contextual graph model for speaker
state analysis in political debates. <em>IJCAI</em>, 3552–3558. (<a
href="https://doi.org/10.24963/ijcai.2021/489">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Political discourses provide a forum for representatives to express their opinions and contribute towards policy making. Analyzing these discussions is crucial for recognizing possible delegates and making better voting choices in an independent nation. A politician&#39;s vote on a proposition is usually associated with their past discourses and impacted by cohesion forces in political parties. We focus on predicting a speaker&#39;s vote on a bill by augmenting linguistic models with temporal and cohesion contexts. We propose TEC, a time evolving graph based model that jointly employs links between motions, speakers, and temporal politician states. TEC outperforms competitive models, illustrating the benefit of temporal and contextual signals for predicting a politician&#39;s stance. Keywords: Machine Learning Applications: Humanities Natural Language Processing: NLP Applications and Tools},
  archive   = {C_IJCAI},
  author    = {Ramit Sawhney and Shivam Agarwal and Arnav Wadhwa and Rajiv Shah},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/489},
  pages     = {3552-3558},
  title     = {TEC: A time evolving contextual graph model for speaker state analysis in political debates},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SPADE: A semi-supervised probabilistic approach for
detecting errors in tables. <em>IJCAI</em>, 3543–3551. (<a
href="https://doi.org/10.24963/ijcai.2021/488">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Error detection is one of the most important steps in data cleaning and usually requires extensive human interaction to ensure quality. Existing supervised methods in error detection require a significant amount of training data while unsupervised methods rely on fixed inductive biases, which are usually hard to generalize, to solve the problem. In this paper, we present SPADE, a novel semi-supervised probabilistic approach for error detection. SPADE introduces a novel probabilistic active learning model, where the system suggests examples to be labeled based on the agreements between user labels and indicative signals, which are designed to capture potential errors. SPADE uses a two-phase data augmentation process to enrich a dataset before training a deep learning classifier to detect unlabeled errors. In our evaluation, SPADE achieves an average F1-score of 0.91 over five datasets and yields a 10\% improvement compared with the state-of-the-art systems. Keywords: Machine Learning Applications: Applications of Supervised Learning Data Mining: Anomaly/Outlier Detection},
  archive   = {C_IJCAI},
  author    = {Minh Pham and Craig A. Knoblock and Muhao Chen and Binh Vu and Jay Pujara},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/488},
  pages     = {3543-3551},
  title     = {SPADE: A semi-supervised probabilistic approach for detecting errors in tables},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MDNN: A multimodal deep neural network for predicting
drug-drug interaction events. <em>IJCAI</em>, 3536–3542. (<a
href="https://doi.org/10.24963/ijcai.2021/487">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The interaction of multiple drugs could lead to serious events, which causes injuries and huge medical costs. Accurate prediction of drug-drug interaction (DDI) events can help clinicians make effective decisions and establish appropriate therapy programs. Recently, many AI-based techniques have been proposed for predicting DDI associated events. However, most existing methods pay less attention to the potential correlations between DDI events and other multimodal data such as targets and enzymes. To address this problem, we propose a Multimodal Deep Neural Network (MDNN) for DDI events prediction. In MDNN, we design a two-pathway framework including drug knowledge graph (DKG) based pathway and heterogeneous feature (HF) based pathway to obtain drug multimodal representations. Finally, a multimodal fusion neural layer is designed to explore the complementary among the drug multimodal representations. We conduct extensive experiments on real-world dataset. The results show that MDNN can accurately predict DDI events and outperform the state-of-the-art models. Keywords: Machine Learning Applications: Bio/Medicine Multidisciplinary Topics and Applications: Biology and Medicine Multidisciplinary Topics and Applications: AI for Life Science},
  archive   = {C_IJCAI},
  author    = {Tengfei Lyu and Jianliang Gao and Ling Tian and Zhao Li and Peng Zhang and Ji Zhang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/487},
  pages     = {3536-3542},
  title     = {MDNN: A multimodal deep neural network for predicting drug-drug interaction events},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Collaborative graph learning with auxiliary text for
temporal event prediction in healthcare. <em>IJCAI</em>, 3529–3535. (<a
href="https://doi.org/10.24963/ijcai.2021/486">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Accurate and explainable health event predictions are becoming crucial for healthcare providers to develop care plans for patients. The availability of electronic health records (EHR) has enabled machine learning advances in providing these predictions. However, many deep-learning-based methods are not satisfactory in solving several key challenges: 1) effectively utilizing disease domain knowledge; 2) collaboratively learning representations of patients and diseases; and 3) incorporating unstructured features. To address these issues, we propose a collaborative graph learning model to explore patient-disease interactions and medical domain knowledge. Our solution is able to capture structural features of both patients and diseases. The proposed model also utilizes unstructured text data by employing an attention manipulating strategy and then integrates attentive text features into a sequential learning process. We conduct extensive experiments on two important healthcare problems to show the competitive prediction performance of the proposed method compared with various state-of-the-art models. We also confirm the effectiveness of learned representations and model interpretability by a set of ablation and case studies. Keywords: Machine Learning Applications: Bio/Medicine Knowledge Representation and Reasoning: Leveraging Knowledge and Learning Machine Learning: Deep Learning},
  archive   = {C_IJCAI},
  author    = {Chang Lu and Chandan K Reddy and Prithwish Chakraborty and Samantha Kleinberg and Yue Ning},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/486},
  pages     = {3529-3535},
  title     = {Collaborative graph learning with auxiliary text for temporal event prediction in healthcare},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Solving math word problems with teacher supervision.
<em>IJCAI</em>, 3522–3528. (<a
href="https://doi.org/10.24963/ijcai.2021/485">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Math word problems (MWPs) have been recently addressed with Seq2Seq models by `translating&#39; math problems described in natural language to a mathematical expression, following a typical encoder-decoder structure. Although effective in solving classical math problems, these models fail when a subtle variation is applied to the word expression of a math problem, and leads to a remarkably different answer. We find the failure is because MWPs with different answers but similar math formula expression are encoded closely in the latent space. We thus designed a teacher module to make the MWP encoding vector match the correct solution and disaccord from the wrong solutions, which are manipulated from the correct solution. Experimental results on two benchmark MWPs datasets verified that our proposed solution outperforms the state-of-the-art models. Keywords: Machine Learning Applications: Applications of Supervised Learning Natural Language Processing: Question Answering},
  archive   = {C_IJCAI},
  author    = {Zhenwen Liang and Xiangliang Zhang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/485},
  pages     = {3522-3528},
  title     = {Solving math word problems with teacher supervision},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Two-sided wasserstein procrustes analysis. <em>IJCAI</em>,
3515–3521. (<a href="https://doi.org/10.24963/ijcai.2021/484">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Learning correspondence between sets of objects is a key component in many machine learning tasks.Recently, optimal Transport (OT) has been successfully applied to such correspondence problems and it is appealing as a fully unsupervised approach. However, OT requires pairwise instances be directly comparable in a common metric space. This limits its applicability when feature spaces are of different dimensions or not directly comparable. In addition, OT only focuses on pairwise correspondence without sensing global transformations. To address these challenges, we propose a new method to jointly learn the optimal coupling between twosets, and the optimal transformations (e.g. rotation, projection and scaling) of each set based on a two-sided Wassertein Procrustes analysis (TWP). Since the joint problem is a non-convex optimization problem, we present a reformulation that renders the problem component-wise convex. We then propose a novel algorithm to solve the problem harnessing a Gauss–Seidel method. We further present competitive results of TWP on various applicationscompared with state-of-the-art methods. Keywords: Machine Learning Applications: Applications of Unsupervised Learning Machine Learning: Transfer, Adaptation, Multi-task Learning Machine Learning Applications: Bio/Medicine},
  archive   = {C_IJCAI},
  author    = {Kun Jin and Chaoyue Liu and Cathy Xia},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/484},
  pages     = {3515-3521},
  title     = {Two-sided wasserstein procrustes analysis},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Self-guided community detection on networks with missing
edges. <em>IJCAI</em>, 3508–3514. (<a
href="https://doi.org/10.24963/ijcai.2021/483">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The vast majority of community detection algorithms assume that the networks are totally observed. However, in reality many networks cannot be fully observed. On such network is edges-missing network, where some relationships (edges) between two entities are missing. Recently, several works have been proposed to solve this problem by combining link prediction and community detection in a two-stage method or in a unified framework. However, the goal of link prediction, which is to predict as many correct edges as possible, is not consistent with the requirement for predicting the important edges for discovering community structure on edges-missing networks. Thus, combining link prediction and community detection cannot work very well in terms of detecting community structure for edges-missing network. In this paper, we propose a community self-guided generative model which jointly completes the edges-missing network and identifies communities. In our new model, completing missing edges and identifying communities are not isolated but closely intertwined. Furthermore, we developed an effective model inference method that combines a nested Expectation-Maximization (EM) algorithm and Metropolis-Hastings Sampling. Extensive experiments on real-world edges-missing networks show that our model can effectively detect community structures while completing missing edges. Keywords: Machine Learning Applications: Networks Uncertainty in AI: Graphical Models Data Mining: Mining Graphs, Semi Structured Data, Complex Data},
  archive   = {C_IJCAI},
  author    = {Dongxiao He and Shuai Li and Di Jin and Pengfei Jiao and Yuxiao Huang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/483},
  pages     = {3508-3514},
  title     = {Self-guided community detection on networks with missing edges},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sample efficient decentralized stochastic frank-wolfe
methods for continuous DR-submodular maximization. <em>IJCAI</em>,
3501–3507. (<a href="https://doi.org/10.24963/ijcai.2021/482">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Continuous DR-submodular maximization is an important machine learning problem, which covers numerous popular applications. With the emergence of large-scale distributed data, developing efficient algorithms for the continuous DR-submodular maximization, such as the decentralized Frank-Wolfe method, became an important challenge. However, existing decentralized Frank-Wolfe methods for this kind of problem have the sample complexity of $\mathcal{O}(1/\epsilon^3)$, incurring a large computational overhead. In this paper, we propose two novel sample efficient decentralized Frank-Wolfe methods to address this challenge. Our theoretical results demonstrate that the sample complexity of the two proposed methods is $\mathcal{O}(1/\epsilon^2)$, which is better than $\mathcal{O}(1/\epsilon^3)$ of the existing methods. As far as we know, this is the first published result achieving such a favorable sample complexity. Extensive experimental results confirm the effectiveness of the proposed methods. Keywords: Machine Learning Applications: Big data; Scalability},
  archive   = {C_IJCAI},
  author    = {Hongchang Gao and Hanzi Xu and Slobodan Vucetic},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/482},
  pages     = {3501-3507},
  title     = {Sample efficient decentralized stochastic frank-wolfe methods for continuous DR-submodular maximization},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Toward optimal solution for the context-attentive bandit
problem. <em>IJCAI</em>, 3493–3500. (<a
href="https://doi.org/10.24963/ijcai.2021/481">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In various recommender system applications, from medical diagnosis to dialog systems, due to observation costs only a small subset of a potentially large number of context variables can be observed at each iteration; however, the agent has a freedom to choose which variables to observe. In this paper, we analyze and extend an online learning framework known as Context-Attentive Bandit, We derive a novel algorithm, called Context-Attentive Thompson Sampling (CATS), which builds upon the Linear Thompson Sampling approach, adapting it to Context-Attentive Bandit setting. We provide a theoretical regret analysis and an extensive empirical evaluation demonstrating advantages of the proposed approach over several baseline methods on a variety of real-life datasets. Keywords: Machine Learning Applications: Applications of Reinforcement Learning Data Mining: Big Data, Large-Scale Systems Data Mining: Recommender Systems},
  archive   = {C_IJCAI},
  author    = {Djallel Bouneffouf and Raphael Feraud and Sohini Upadhyay and Irina Rish and Yasaman Khazaeni},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/481},
  pages     = {3493-3500},
  title     = {Toward optimal solution for the context-attentive bandit problem},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MapGo: Model-assisted policy optimization for goal-oriented
tasks. <em>IJCAI</em>, 3484–3491. (<a
href="https://doi.org/10.24963/ijcai.2021/480">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In Goal-oriented Reinforcement learning, relabeling the raw goals in past experience to provide agents with hindsight ability is a major solution to the reward sparsity problem. In this paper, to enhance the diversity of relabeled goals, we develop FGI (Foresight Goal Inference), a new relabeling strategy that relabels the goals by looking into the future with a learned dynamics model. Besides, to improve sample efficiency, we propose to use the dynamics model to generate simulated trajectories for policy training. By integrating these two improvements, we introduce the MapGo framework (Model-Assisted Policy optimization for Goal-oriented tasks). In our experiments, we first show the effectiveness of the FGI strategy compared with the hindsight one, and then show that the MapGo framework achieves higher sample efficiency when compared to model-free baselines on a set of complicated tasks. Keywords: Machine Learning: Deep Reinforcement Learning Machine Learning: Reinforcement Learning},
  archive   = {C_IJCAI},
  author    = {Menghui Zhu and Minghuan Liu and Jian Shen and Zhicheng Zhang and Sheng Chen and Weinan Zhang and Deheng Ye and Yong Yu and Qiang Fu and Wei Yang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/480},
  pages     = {3484-3491},
  title     = {MapGo: Model-assisted policy optimization for goal-oriented tasks},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). You get what you sow: High fidelity image synthesis with a
single pretrained network. <em>IJCAI</em>, 3477–3483. (<a
href="https://doi.org/10.24963/ijcai.2021/479">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {State-of-the-art image synthesis methods are mostly based on generative adversarial networks and require large dataset and extensive training. Although the model-inversion-oriented branch of methods eliminate the training requirement, the quality of the resulting image tends to be limited due to the lack of sufficient natural and class-specific information. In this paper, we introduce a novel strategy for high fidelity image synthesis with a single pretrained classification network. The strategy includes a class-conditional natural regularization design and a corresponding metadata collecting procedure for different scenarios. We show that our method can synthesize high quality natural images that closely follow the features of one or more given seed images. Moreover, our method achieves surprisingly decent results in the task of sketch-based image synthesis without training. Finally, our method further improves the performance in terms of accuracy and efficiency in the data-free knowledge distillation task. Keywords: Machine Learning: Classification Machine Learning: Deep Learning Machine Learning: Explainable/Interpretable Machine Learning},
  archive   = {C_IJCAI},
  author    = {Kefeng Zhu and Peilin Tong and Hongwei Kan and Rengang Li},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/479},
  pages     = {3477-3483},
  title     = {You get what you sow: High fidelity image synthesis with a single pretrained network},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). AutoReCon: Neural architecture search-based reconstruction
for data-free compression. <em>IJCAI</em>, 3470–3476. (<a
href="https://doi.org/10.24963/ijcai.2021/478">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Data-free compression raises a new challenge because the original training dataset for a pre-trained model to be compressed is not available due to privacy or transmission issues. Thus, a common approach is to compute a reconstructed training dataset before compression. The current reconstruction methods compute the reconstructed training dataset with a generator by exploiting information from the pre-trained model. However, current reconstruction methods focus on extracting more information from the pre-trained model but do not leverage network engineering. This work is the first to consider network engineering as an approach to design the reconstruction method. Specifically, we propose the AutoReCon method, which is a neural architecture search-based reconstruction method. In the proposed AutoReCon method, the generator architecture is designed automatically given the pre-trained model for reconstruction. Experimental results show that using generators discovered by the AutoRecon method always improve the performance of data-free compression. Keywords: Machine Learning: Deep Learning Machine Learning: Classification},
  archive   = {C_IJCAI},
  author    = {Baozhou Zhu and Peter Hofstee and Johan Peltenburg and Jinho Lee and Zaid Alars},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/478},
  pages     = {3470-3476},
  title     = {AutoReCon: Neural architecture search-based reconstruction for data-free compression},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-target invisibly trojaned networks for visual
recognition and detection. <em>IJCAI</em>, 3462–3469. (<a
href="https://doi.org/10.24963/ijcai.2021/477">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Visual backdoor attack is a recently-emerging task which aims to implant trojans in a deep neural model. A trojaned model responds to a trojan-invoking trigger in a fully predictable manner while functioning normally otherwise. As a key motivating fact to this work, most triggers adopted in existing methods, such as a learned patterned block that overlays a benigh image, can be easily noticed by human. In this work, we take image recognition and detection as the demonstration tasks, building trojaned networks that are significantly less human-perceptible and can simultaneously attack multiple targets in an image. The main technical contributions are two-folds: first, under a relaxed attack mode, we formulate trigger embedding as an image steganography-and-steganalysis problem that conceals a secret image in another image in a decipherable and almost invisible way. In specific, a variable number of different triggers can be encoded into a same secret image and fed to an encoder module that does steganography. Secondly, we propose a generic split-and-merge scheme for training a trojaned model. Neurons are split into two sets, trained either for normal image recognition / detection or trojaning the model. To merge them, we novelly propose to hide trojan neurons within the nullspace of the normal ones, such that the two sets do not interfere with each other and the resultant model exhibits similar parameter statistics to a clean model. Comprehensive experiments are conducted on the datasets PASCAL VOC and Microsoft COCO (for detection) and a subset of ImageNet (for recognition). All results clearly demonstrate the effectiveness of our proposed visual trojan method. Keywords: Machine Learning: Adversarial Machine Learning},
  archive   = {C_IJCAI},
  author    = {Xinzhe Zhou and Wenhao Jiang and Sheng Qi and Yadong Mu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/477},
  pages     = {3462-3469},
  title     = {Multi-target invisibly trojaned networks for visual recognition and detection},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Non-decreasing quantile function network with efficient
exploration for distributional reinforcement learning. <em>IJCAI</em>,
3455–3461. (<a href="https://doi.org/10.24963/ijcai.2021/476">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Although distributional reinforcement learning (DRL) has been widely examined in the past few years, there are two open questions people are still trying to address. One is how to ensure the validity of the learned quantile function, the other is how to efficiently utilize the distribution information. This paper attempts to provide some new perspectives to encourage the future in-depth studies in these two fields. We first propose a non-decreasing quantile function network (NDQFN) to guarantee the monotonicity of the obtained quantile estimates and then design a general exploration framework called distributional prediction error (DPE) for DRL which utilizes the entire distribution of the quantile function. In this paper, we not only discuss the theoretical necessity of our method but also show the performance gain it achieves in practice by comparing with some competitors on Atari 2600 Games especially in some hard-explored games. Keywords: Machine Learning: Deep Reinforcement Learning},
  archive   = {C_IJCAI},
  author    = {Fan Zhou and Zhoufan Zhu and Qi Kuang and Liwen Zhang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/476},
  pages     = {3455-3461},
  title     = {Non-decreasing quantile function network with efficient exploration for distributional reinforcement learning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Few-shot partial-label learning. <em>IJCAI</em>, 3448–3454.
(<a href="https://doi.org/10.24963/ijcai.2021/475">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Partial-label learning (PLL) generally focuses on inducing a noise-tolerant multi-class classifier by training on overly-annotated samples, each of which is annotated with a set of labels, but only one is the valid label. A basic promise of existing PLL solutions is that there are sufficient partial-label (PL) samples for training. However, it is more common than not to have just few PL samples at hand when dealing with new tasks. Furthermore, existing few-shot learning algorithms assume precise labels of the support set; as such, irrelevant labels may seriously mislead the meta-learner and thus lead to a compromised performance. How to enable PLL under a few-shot learning setting is an important problem, but not yet well studied. In this paper, we introduce an approach called FsPLL (Few-shot PLL). FsPLL first performs adaptive distance metric learning by an embedding network and rectifying prototypes on the tasks previously encountered. Next, it calculates the prototype of each class of a new task in the embedding network. An unseen example can then be classified via its distance to each prototype. Experimental results on widely-used few-shot datasets demonstrate that our FsPLL can achieve a superior performance than the state-of-the-art methods, and it needs fewer samples for quickly adapting to new tasks. Keywords: Machine Learning: Multi-instance; Multi-label; Multi-view learning Machine Learning: Transfer, Adaptation, Multi-task Learning Machine Learning: Weakly Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Yunfeng Zhao and Guoxian Yu and Lei Liu and Zhongmin Yan and Lizhen Cui and Carlotta Domeniconi},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/475},
  pages     = {3448-3454},
  title     = {Few-shot partial-label learning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Uncertainty-aware binary neural networks. <em>IJCAI</em>,
3441–3447. (<a href="https://doi.org/10.24963/ijcai.2021/474">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Binary Neural Networks (BNN) are promising machine learning solutions for deployment on resource-limited devices. Recent approaches to training BNNs have produced impressive results, but minimizing the drop in accuracy from full precision networks is still challenging. One reason is that conventional BNNs ignore the uncertainty caused by weights that are near zero, resulting in the instability or frequent flip while learning. In this work, we investigate the intrinsic uncertainty of vanishing near-zero weights, making the training vulnerable to instability. We introduce an uncertainty-aware BNN (UaBNN) by leveraging a new mapping function called certainty-sign (c-sign) to reduce these weights&#39; uncertainties. Our c-sign function is the first to train BNNs with a decreasing uncertainty for binarization. The approach leads to a controlled learning process for BNNs. We also introduce a simple but effective method to measure the uncertainty-based on a Gaussian function. Extensive experiments demonstrate that our method improves multiple BNN methods by maintaining stability of training, and achieves a higher performance over prior arts. Keywords: Machine Learning: Classification Machine Learning: Deep Learning},
  archive   = {C_IJCAI},
  author    = {Junhe Zhao and Linlin Yang and Baochang Zhang and Guodong Guo and David Doermann},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/474},
  pages     = {3441-3447},
  title     = {Uncertainty-aware binary neural networks},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Graph debiased contrastive learning with joint
representation clustering. <em>IJCAI</em>, 3434–3440. (<a
href="https://doi.org/10.24963/ijcai.2021/473">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {By contrasting positive-negative counterparts, graph contrastive learning has become a prominent technique for unsupervised graph representation learning. However, existing methods fail to consider the class information and will introduce false-negative samples in the random negative sampling, causing poor performance. To this end, we propose a graph debiased contrastive learning framework, which can jointly perform representation learning and clustering. Specifically, representations can be optimized by aligning with clustered class information, and simultaneously, the optimized representations can promote clustering, leading to more powerful representations and clustering results. More importantly, we randomly select negative samples from the clusters which are different from the positive sample&#39;s cluster. In this way, as the supervisory signals, the clustering results can be utilized to effectively decrease the false-negative samples. Extensive experiments on five datasets demonstrate that our method achieves new state-of-the-art results on graph clustering and classification tasks. Keywords: Machine Learning: Clustering Machine Learning: Unsupervised Learning},
  archive   = {C_IJCAI},
  author    = {Han Zhao and Xu Yang and Zhenru Wang and Erkun Yang and Cheng Deng},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/473},
  pages     = {3434-3440},
  title     = {Graph debiased contrastive learning with joint representation clustering},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automatic mixed-precision quantization search of BERT.
<em>IJCAI</em>, 3427–3433. (<a
href="https://doi.org/10.24963/ijcai.2021/472">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Pre-trained language models such as BERT have shown remarkable effectiveness in various natural language processing tasks. However, these models usually contain millions of parameters, which prevent them from the practical deployment on resource-constrained devices. Knowledge distillation, Weight pruning, and Quantization are known to be the main directions in model compression. However, compact models obtained through knowledge distillation may suffer from significant accuracy drop even for a relatively small compression ratio. On the other hand, there are only a few attempts based on quantization designed for natural language processing tasks, and they usually require manual setting on hyper-parameters. In this paper, we proposed an automatic mixed-precision quantization framework designed for BERT that can conduct quantization and pruning simultaneously. Specifically, our proposed method leverages Differentiable Neural Architecture Search to assign scale and precision for parameters in each sub-group automatically, and at the same pruning out redundant groups of parameters. Extensive evaluations on BERT downstream tasks reveal that our proposed method beats baselines by providing the same performance with much smaller model size. We also show the possibility of obtaining the extremely light-weight model by combining our solution with orthogonal methods such as DistilBERT. Keywords: Machine Learning: Deep Learning Natural Language Processing: NLP Applications and Tools Natural Language Processing: Text Classification},
  archive   = {C_IJCAI},
  author    = {Changsheng Zhao and Ting Hua and Yilin Shen and Qian Lou and Hongxia Jin},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/472},
  pages     = {3427-3433},
  title     = {Automatic mixed-precision quantization search of BERT},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Uncertainty-aware few-shot image classification.
<em>IJCAI</em>, 3420–3426. (<a
href="https://doi.org/10.24963/ijcai.2021/471">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Few-shot image classification learns to recognize new categories from limited labelled data. Metric learning based approaches have been widely investigated, where a query sample is classified by finding the nearest prototype from the support set based on their feature similarities. A neural network has different uncertainties on its calculated similarities of different pairs. Understanding and modeling the uncertainty on the similarity could promote the exploitation of limited samples in few-shot optimization. In this work, we propose Uncertainty-Aware Few-Shot framework for image classification by modeling uncertainty of the similarities of query-support pairs and performing uncertainty-aware optimization. Particularly, we exploit such uncertainty by converting observed similarities to probabilistic representations and incorporate them to the loss for more effective optimization. In order to jointly consider the similarities between a query and the prototypes in a support set, a graph-based model is utilized to estimate the uncertainty of the pairs. Extensive experiments show our proposed method brings significant improvements on top of a strong baseline and achieves the state-of-the-art performance. Keywords: Machine Learning: Classification Machine Learning: Cost-Sensitive Learning Computer Vision: Recognition: Detection, Categorization, Indexing, Matching, Retrieval, Semantic Interpretation Uncertainty in AI: Uncertainty Representations},
  archive   = {C_IJCAI},
  author    = {Zhizheng Zhang and Cuiling Lan and Wenjun Zeng and Zhibo Chen and Shih-Fu Chang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/471},
  pages     = {3420-3426},
  title     = {Uncertainty-aware few-shot image classification},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Combining tree search and action prediction for
state-of-the-art performance in DouDiZhu. <em>IJCAI</em>, 3413–3419. (<a
href="https://doi.org/10.24963/ijcai.2021/470">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {AlphaZero has achieved superhuman performance on various perfect-information games, such as chess, shogi and Go. However, directly applying AlphaZero to imperfect-information games (IIG) is infeasible, due to the fact that traditional MCTS methods cannot handle missing information of other players. Meanwhile, there have been several extensions of MCTS for IIGs, by implicitly or explicitly sampling a state of other players. But, due to the inability to handle private and public information well, the performance of these methods is not satisfactory. In this paper, we extend AlphaZero to multiplayer IIGs by developing a new MCTS method, Action-Prediction MCTS (AP-MCTS). In contrast to traditional MCTS extensions for IIGs, AP-MCTS first builds the search tree based on public information, adopts the policy-value network to generalize between hidden states, and finally predicts other players&#39; actions directly. This design bypasses the inefficiency of sampling and the difficulty of predicting the state of other players. We conduct extensive experiments on the popular 3-player poker game DouDiZhu to evaluate the performance of AP-MCTS combined with the framework AlphaZero. When playing against experienced human players, AP-MCTS achieved a 65.65\% winning rate, which is almost twice the human&#39;s winning rate. When comparing with state-of-the-art DouDiZhu AIs, the Elo rating of AP-MCTS is 50 to 200 higher than them. The ablation study shows that accurate action prediction is the key to AP-MCTS winning. Keywords: Machine Learning: Reinforcement Learning Heuristic Search and Game Playing: Game Playing and Machine Learning},
  archive   = {C_IJCAI},
  author    = {Yunsheng Zhang and Dong Yan and Bei Shi and Haobo Fu and Qiang Fu and Hang Su and Jun Zhu and Ning Chen},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/470},
  pages     = {3413-3419},
  title     = {Combining tree search and action prediction for state-of-the-art performance in DouDiZhu},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Neural relation inference for multi-dimensional temporal
point processes via message passing graph. <em>IJCAI</em>, 3406–3412.
(<a href="https://doi.org/10.24963/ijcai.2021/469">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Relation discovery for multi-dimensional temporal point processes (MTPP) has received increasing interest for its importance in prediction and interpretability of the underlying dynamics. Traditional statistical MTPP models like Hawkes Process have difficulty in capturing complex relation due to their limited parametric form of the intensity function. While recent neural-network-based models suffer poor interpretability. In this paper, we propose a neural relation inference model namely TPP-NRI. Given MTPP data, it adopts a variational inference framework to model the posterior relation of MTPP data for probabilistic estimation. Specifically, assuming the prior of the relation is known, the conditional probability of the MTPP conditional on a sampled relation is captured by a message passing graph neural network (GNN) based MTPP model. A variational distribution is introduced to approximate the true posterior. Experiments on synthetic and real-world data show that our model outperforms baseline methods on both inference capability and scalability for high-dimensional data. Keywords: Machine Learning: Relational Learning Machine Learning: Time-series; Data Streams},
  archive   = {C_IJCAI},
  author    = {Yunhao Zhang and Junchi Yan},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/469},
  pages     = {3406-3412},
  title     = {Neural relation inference for multi-dimensional temporal point processes via message passing graph},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). User retention: A causal approach with triple task
modeling. <em>IJCAI</em>, 3399–3405. (<a
href="https://doi.org/10.24963/ijcai.2021/468">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {For many Internet companies, it has been an important focus to improve user retention rate. To achieve this goal, we need to recommend proper services in order to meet the demands of users. Unlike conventional click-through rate (CTR) estimation, there are lots of noise in the collected data when modeling retention, caused by two major issues: 1) implicit impression-revisit effect: users could revisit the APP even if they do not explicitly interact with the recommender system; 2) selection bias: recommender system suffers from selection bias caused by user&#39;s self-selection. To address the above challenges, we propose a novel method named UR-IPW (User Retention Modeling with Inverse Propensity Weighting), which 1) makes full use of both explicit and implicit interactions in the observed data. 2) models revisit rate estimation from a causal perspective accounting for the selection bias problem. The experiments on both offline and online environments from different scenarios demonstrate the superiority of UR-IPW over previous methods. To the best of our knowledge, this is the first work to model user retention by estimating the revisit rate from a causal perspective. Keywords: Machine Learning: Deep Learning Machine Learning Applications: Applications of Supervised Learning Data Mining: Recommender Systems},
  archive   = {C_IJCAI},
  author    = {Yang Zhang and Dong Wang and Qiang Li and Yue Shen and Ziqi Liu and Xiaodong Zeng and Zhiqiang Zhang and Jinjie Gu and Derek F. Wong},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/468},
  pages     = {3399-3405},
  title     = {User retention: A causal approach with triple task modeling},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Rethink the connections among generalization, memorization,
and the spectral bias of DNNs. <em>IJCAI</em>, 3392–3398. (<a
href="https://doi.org/10.24963/ijcai.2021/467">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Over-parameterized deep neural networks (DNNs) with sufficient capacity to memorize random noise can achieve excellent generalization performance, challenging the bias-variance trade-off in classical learning theory. Recent studies claimed that DNNs first learn simple patterns and then memorize noise; some other works showed a phenomenon that DNNs have a spectral bias to learn target functions from low to high frequencies during training. However, we show that the monotonicity of the learning bias does not always hold: under the experimental setup of deep double descent, the high-frequency components of DNNs diminish in the late stage of training, leading to the second descent of the test error. Besides, we find that the spectrum of DNNs can be applied to indicating the second descent of the test error, even though it is calculated from the training set only. Keywords: Machine Learning: Deep Learning Machine Learning: Learning Theory},
  archive   = {C_IJCAI},
  author    = {Xiao Zhang and Haoyi Xiong and Dongrui Wu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/467},
  pages     = {3392-3398},
  title     = {Rethink the connections among generalization, memorization, and the spectral bias of DNNs},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Model-based multi-agent policy optimization with adaptive
opponent-wise rollouts. <em>IJCAI</em>, 3384–3391. (<a
href="https://doi.org/10.24963/ijcai.2021/466">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper investigates the model-based methods in multi-agent reinforcement learning (MARL). We specify the dynamics sample complexity and the opponent sample complexity in MARL, and conduct a theoretic analysis of return discrepancy upper bound. To reduce the upper bound with the intention of low sample complexity during the whole learning process, we propose a novel decentralized model-based MARL method, named Adaptive Opponent-wise Rollout Policy Optimization (AORPO). In AORPO, each agent builds its multi-agent environment model, consisting of a dynamics model and multiple opponent models, and trains its policy with the adaptive opponent-wise rollout. We further prove the theoretic convergence of AORPO under reasonable assumptions. Empirical experiments on competitive and cooperative tasks demonstrate that AORPO can achieve improved sample efficiency with comparable asymptotic performance over the compared MARL methods. Keywords: Machine Learning: Deep Reinforcement Learning Agent-based and Multi-agent Systems: Multi-agent Learning},
  archive   = {C_IJCAI},
  author    = {Weinan Zhang and Xihuai Wang and Jian Shen and Ming Zhou},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/466},
  pages     = {3384-3391},
  title     = {Model-based multi-agent policy optimization with adaptive opponent-wise rollouts},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Non-i.i.d. Multi-instance learning for predicting instance
and bag labels with variational auto-encoder. <em>IJCAI</em>, 3377–3383.
(<a href="https://doi.org/10.24963/ijcai.2021/465">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-instance learning is a type of weakly supervised learning. It deals with tasks where the data is a set of bags and each bag is a set of instances. Only the bag labels are observed whereas the labels for the instances are unknown. An important advantage of multi-instance learning is that by representing objects as a bag of instances, it is able to preserve the inherent dependencies among parts of the objects. Unfortunately, most existing algorithms assume all instances to be identically and independently distributed, which violates real-world scenarios since the instances within a bag are rarely independent. In this work, we propose the Multi-Instance Variational Autoencoder (MIVAE) algorithm which explicitly models the dependencies among the instances for predicting both bag labels and instance labels. Experimental results on several multi-instance benchmarks and end-to-end medical imaging datasets demonstrate that MIVAE performs better than state-of-the-art algorithms for both instance label and bag label prediction tasks. Keywords: Machine Learning: Multi-instance; Multi-label; Multi-view learning Machine Learning: Weakly Supervised Learning Data Mining: Classification},
  archive   = {C_IJCAI},
  author    = {Weijia Zhang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/465},
  pages     = {3377-3383},
  title     = {Non-I.I.D. multi-instance learning for predicting instance and bag labels with variational auto-encoder},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Private stochastic non-convex optimization with improved
utility rates. <em>IJCAI</em>, 3370–3376. (<a
href="https://doi.org/10.24963/ijcai.2021/464">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the differentially private (DP) stochastic nonconvex optimization with a focus on its under-studied utility measures in terms of the expected excess empirical and population risks. While the excess risks are extensively studied for convex optimization, they are rarely studied for nonconvex optimization, especially the expected population risk. For the convex case, recent studies show that it is possible for private optimization to achieve the same order of excess population risk as to the nonprivate optimization under certain conditions. It still remains an open question for the nonconvex case whether such ideal excess population risk is achievable. In this paper, we progress towards an affirmative answer to this open problem: DP nonconvex optimization is indeed capable of achieving the same excess population risk as to the nonprivate algorithm in most common parameter regimes, under certain conditions (i.e., well-conditioned nonconvexity). We achieve such improved utility rates compared to existing results by designing and analyzing the stagewise DP-SGD with early momentum algorithm. We obtain both excess empirical risk and excess population risk to achieve differential privacy. Our algorithm also features the first known results of excess and population risks for DP-SGD with momentum. Experiment results on both shallow and deep neural networks when respectively applied to simple and complex real datasets corroborate the theoretical results. Keywords: Machine Learning: Learning Theory Data Mining: Privacy Preserving Data Mining},
  archive   = {C_IJCAI},
  author    = {Qiuchen Zhang and Jing Ma and Jian Lou and Li Xiong},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/464},
  pages     = {3370-3376},
  title     = {Private stochastic non-convex optimization with improved utility rates},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Correlation-guided representation for multi-label text
classification. <em>IJCAI</em>, 3363–3369. (<a
href="https://doi.org/10.24963/ijcai.2021/463">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-label text classification is an essential task in natural language processing. Existing multi-label classification models generally consider labels as categorical variables and ignore the exploitation of label semantics. In this paper, we view the task as a correlation-guided text representation problem: an attention-based two-step framework is proposed to integrate text information and label semantics by jointly learning words and labels in the same space. In this way, we aim to capture high-order label-label correlations as well as context-label correlations. Specifically, the proposed approach works by learning token-level representations of words and labels globally through a multi-layer Transformer and constructing an attention vector through word-label correlation matrix to generate the text representation. It ensures that relevant words receive higher weights than irrelevant words and thus directly optimizes the classification performance. Extensive experiments over benchmark multi-label datasets clearly validate the effectiveness of the proposed approach, and further analysis demonstrates that it is competitive in both predicting low-frequency labels and convergence speed. Keywords: Machine Learning: Multi-instance; Multi-label; Multi-view learning Data Mining: Classification Natural Language Processing: Text Classification},
  archive   = {C_IJCAI},
  author    = {Qian-Wen Zhang and Ximing Zhang and Zhao Yan and Ruifang Liu and Yunbo Cao and Min-Ling Zhang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/463},
  pages     = {3363-3369},
  title     = {Correlation-guided representation for multi-label text classification},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). UNBERT: User-news matching BERT for news recommendation.
<em>IJCAI</em>, 3356–3362. (<a
href="https://doi.org/10.24963/ijcai.2021/462">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Nowadays, news recommendation has become a popular channel for users to access news of their interests. How to represent rich textual contents of news and precisely match users&#39; interests and candidate news lies in the core of news recommendation. However, existing recommendation methods merely learn textual representations from in-domain news data, which limits their generalization ability to new news that are common in cold-start scenarios. Meanwhile, many of these methods represent each user by aggregating the historically browsed news into a single vector and then compute the matching score with the candidate news vector, which may lose the low-level matching signals. In this paper, we explore the use of the successful BERT pre-training technique in NLP for news recommendation and propose a BERT-based user-news matching model, called UNBERT. In contrast to existing research, our UNBERT model not only leverages the pre-trained model with rich language knowledge to enhance textual representation, but also captures multi-grained user-news matching signals at both word-level and news-level. Extensive experiments on the Microsoft News Dataset (MIND) demonstrate that our approach constantly outperforms the state-of-the-art methods. Keywords: Machine Learning: Recommender Systems Data Mining: Recommender Systems},
  archive   = {C_IJCAI},
  author    = {Qi Zhang and Jingjie Li and Qinglin Jia and Chuyuan Wang and Jieming Zhu and Zhaowei Wang and Xiuqiang He},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/462},
  pages     = {3356-3362},
  title     = {UNBERT: User-news matching BERT for news recommendation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Independence-aware advantage estimation. <em>IJCAI</em>,
3349–3355. (<a href="https://doi.org/10.24963/ijcai.2021/461">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Most of existing advantage function estimation methods in reinforcement learning suffer from the problem of high variance, which scales unfavorably with the time horizon. To address this challenge, we propose to identify the independence property between current action and future states in environments, which can be further leveraged to effectively reduce the variance of the advantage estimation. In particular, the recognized independence property can be naturally utilized to construct a novel importance sampling advantage estimator with close-to-zero variance even when the Monte-Carlo return signal yields a large variance. To further remove the risk of the high variance introduced by the new estimator, we combine it with existing Monte-Carlo estimator via a reward decomposition model learned by minimizing the estimation variance. Experiments demonstrate that our method achieves higher sample efficiency compared with existing advantage estimation methods in complex environments. Keywords: Machine Learning: Reinforcement Learning Machine Learning: Deep Reinforcement Learning},
  archive   = {C_IJCAI},
  author    = {Pushi Zhang and Li Zhao and Guoqing Liu and Jiang Bian and Minlie Huang and Tao Qin and Tie-Yan Liu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/461},
  pages     = {3349-3355},
  title     = {Independence-aware advantage estimation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep descriptive clustering. <em>IJCAI</em>, 3342–3348. (<a
href="https://doi.org/10.24963/ijcai.2021/460">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent work on explainable clustering allows describing clusters when the features are interpretable. However, much modern machine learning focuses on complex data such as images, text, and graphs where deep learning is used but the raw features of data are not interpretable. This paper explores a novel setting for performing clustering on complex data while simultaneously generating explanations using interpretable tags. We propose deep descriptive clustering that performs sub-symbolic representation learning on complex data while generating explanations based on symbolic data. We form good clusters by maximizing the mutual information between empirical distribution on the inputs and the induced clustering labels for clustering objectives. We generate explanations by solving an integer linear programming that generates concise and orthogonal descriptions for each cluster. Finally, we allow the explanation to inform better clustering by proposing a novel pairwise loss with self-generated constraints to maximize the clustering and explanation module&#39;s consistency. Experimental results on public data demonstrate that our model outperforms competitive baselines in clustering performance while offering high-quality cluster-level explanations. Keywords: Machine Learning: Clustering Machine Learning: Explainable/Interpretable Machine Learning Constraints and SAT: Constraints and Data Mining; Constraints and Machine Learning},
  archive   = {C_IJCAI},
  author    = {Hongjing Zhang and Ian Davidson},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/460},
  pages     = {3342-3348},
  title     = {Deep descriptive clustering},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hindsight trust region policy optimization. <em>IJCAI</em>,
3335–3341. (<a href="https://doi.org/10.24963/ijcai.2021/459">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Reinforcement Learning (RL) with sparse rewards is a major challenge. We pro- pose Hindsight Trust Region Policy Optimization (HTRPO), a new RL algorithm that extends the highly successful TRPO algorithm with hindsight to tackle the challenge of sparse rewards. Hindsight refers to the algorithm’s ability to learn from information across goals, including past goals not intended for the current task. We derive the hindsight form of TRPO, together with QKL, a quadratic approximation to the KL divergence constraint on the trust region. QKL reduces variance in KL divergence estimation and improves stability in policy updates. We show that HTRPO has similar convergence property as TRPO. We also present Hindsight Goal Filtering (HGF), which further improves the learning performance for suitable tasks. HTRPO has been evaluated on various sparse-reward tasks, including Atari games and simulated robot control. Experimental results show that HTRPO consistently outperforms TRPO, as well as HPG, a state-of-the-art policy 14 gradient algorithm for RL with sparse rewards. Keywords: Machine Learning: Deep Reinforcement Learning Machine Learning: Reinforcement Learning},
  archive   = {C_IJCAI},
  author    = {Hanbo Zhang and Site Bai and Xuguang Lan and David Hsu and Nanning Zheng},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/459},
  pages     = {3335-3341},
  title     = {Hindsight trust region policy optimization},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Graph universal adversarial attacks: A few bad actors ruin
graph learning models. <em>IJCAI</em>, 3328–3334. (<a
href="https://doi.org/10.24963/ijcai.2021/458">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep neural networks, while generalize well, are known to be sensitive to small adversarial perturbations. This phenomenon poses severe security threat and calls for in-depth investigation of the robustness of deep learning models. With the emergence of neural networks for graph structured data, similar investigations are urged to understand their robustness. It has been found that adversarially perturbing the graph structure and/or node features may result in a significant degradation of the model performance. In this work, we show from a different angle that such fragility similarly occurs if the graph contains a few bad-actor nodes, which compromise a trained graph neural network through flipping the connections to any targeted victim. Worse, the bad actors found for one graph model severely compromise other models as well. We call the bad actors ``anchor nodes&#39;&#39; and propose an algorithm, named GUA, to identify them. Thorough empirical investigations suggest an interesting finding that the anchor nodes often belong to the same class; and they also corroborate the intuitive trade-off between the number of anchor nodes and the attack success rate. For the dataset Cora which contains 2708 nodes, as few as six anchor nodes will result in an attack success rate higher than 80\% for GCN and other three models. Keywords: Machine Learning: Adversarial Machine Learning Machine Learning: Semi-Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Xiao Zang and Yi Xie and Jie Chen and Bo Yuan},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/458},
  pages     = {3328-3334},
  title     = {Graph universal adversarial attacks: A few bad actors ruin graph learning models},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving sequential recommendation consistency with
self-supervised imitation. <em>IJCAI</em>, 3321–3327. (<a
href="https://doi.org/10.24963/ijcai.2021/457">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Most sequential recommendation models capture the features of consecutive items in a user-item interaction history. Though effective, their representation expressiveness is still hindered by the sparse learning signals. As a result, the sequential recommender is prone to make inconsistent predictions. In this paper, we propose a model, SSI, to improve sequential recommendation consistency with Self-Supervised Imitation. Precisely, we extract the consistency knowledge by utilizing three self-supervised pre-training tasks, where temporal consistency and persona consistency capture user-interaction dynamics in terms of the chronological order and persona sensitivities, respectively. Furthermore, to provide the model with a global perspective, global session consistency is introduced by maximizing the mutual information among global and local interaction sequences. Finally, to comprehensively take advantage of all three independent aspects of consistency-enhanced knowledge, we establish an integrated imitation learning framework. The consistency knowledge is effectively internalized and transferred to the student model by imitating the conventional prediction logit as well as the consistency-enhanced item representations. In addition, the flexible self-supervised imitation framework can also benefit other student recommenders. Experiments on four real-world datasets show that SSI effectively outperforms the state-of-the-art sequential recommendation methods. Keywords: Machine Learning: Recommender Systems Data Mining: Recommender Systems},
  archive   = {C_IJCAI},
  author    = {Xu Yuan and Hongshen Chen and Yonghao Song and Xiaofang Zhao and Zhuoye Ding},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/457},
  pages     = {3321-3327},
  title     = {Improving sequential recommendation consistency with self-supervised imitation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Understanding the effect of bias in deep anomaly detection.
<em>IJCAI</em>, 3314–3320. (<a
href="https://doi.org/10.24963/ijcai.2021/456">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Anomaly detection presents a unique challenge in machine learning, due to the scarcity of labeled anomaly data. Recent work attempts to mitigate such problems by augmenting training of deep anomaly detection models with additional labeled anomaly samples. However, the labeled data often does not align with the target distribution and introduces harmful bias to the trained model. In this paper, we aim to understand the effect of a biased anomaly set on anomaly detection. Concretely, we view anomaly detection as a supervised learning task where the objective is to optimize the recall at a given false positive rate. We formally study the relative scoring bias of an anomaly detector, defined as the difference in performance with respect to a baseline anomaly detector. We establish the first finite sample rates for estimating the relative scoring bias for deep anomaly detection, and empirically validate our theoretical results on both synthetic and real-world datasets. We also provide an extensive empirical study on how a biased training anomaly set affects the anomaly score function and therefore the detection performance on different anomaly classes. Our study demonstrates scenarios in which the biased anomaly set can be useful or problematic, and provides a solid benchmark for future research. Keywords: Machine Learning: Deep Learning Data Mining: Anomaly/Outlier Detection Machine Learning: Semi-Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Ziyu Ye and Yuxin Chen and Haitao Zheng},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/456},
  pages     = {3314-3320},
  title     = {Understanding the effect of bias in deep anomaly detection},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Blocking-based neighbor sampling for large-scale graph
neural networks. <em>IJCAI</em>, 3307–3313. (<a
href="https://doi.org/10.24963/ijcai.2021/455">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The exponential increase in computation and memory complexity with the depth of network has become the main impediment to the successful application of graph neural networks (GNNs) on large-scale graphs like graphs with hundreds of millions of nodes. In this paper, we propose a novel neighbor sampling strategy, dubbed blocking-based neighbor sampling (BNS), for efficient training of GNNs on large-scale graphs. Specifically, BNS adopts a policy to stochastically block the ongoing expansion of neighboring nodes, which can reduce the rate of the exponential increase in computation and memory complexity of GNNs. Furthermore, a reweighted policy is applied to graph convolution, to adjust the contribution of blocked and non-blocked neighbors to central nodes. We theoretically prove that BNS provides an unbiased estimation for the original graph convolution operation. Extensive experiments on three benchmark datasets show that, on large-scale graphs, BNS is 2X~5X faster than state-of-the-art methods when achieving the same accuracy. Moreover, even on the small-scale graphs, BNS also demonstrates the advantage of low time cost. Keywords: Machine Learning: Relational Learning Machine Learning Applications: Big data; Scalability Data Mining: Mining Graphs, Semi Structured Data, Complex Data},
  archive   = {C_IJCAI},
  author    = {Kai-Lang Yao and Wu-Jun Li},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/455},
  pages     = {3307-3313},
  title     = {Blocking-based neighbor sampling for large-scale graph neural networks},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Rethinking label-wise cross-modal retrieval from a semantic
sharing perspective. <em>IJCAI</em>, 3300–3306. (<a
href="https://doi.org/10.24963/ijcai.2021/454">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The main challenge of cross-modal retrieval is to learn the consistent embedding for heterogeneous modalities. To solve this problem, traditional label-wise cross-modal approaches usually constrain the inter-modal and intra-modal embedding consistency relying on the label ground-truths. However, the experiments reveal that different modal networks actually have various generalization capacities, thereby end-to-end joint training with consistency loss usually leads to sub-optimal uni-modal model, which in turn affects the learning of consistent embedding. Therefore, in this paper, we argue that what really needed for supervised cross-modal retrieval is a good shared classification model. In other words, we learn the consistent embedding by ensuring the classification performance of each modality on the shared model, without the consistency loss. Specifically, we consider a technique called Semantic Sharing, which directly trains the two modalities interactively by adopting a shared self-attention based classification model. We evaluate the proposed approach on three representative datasets. The results validate that the proposed semantic sharing can consistently boost the performance under NDCG metric. Keywords: Machine Learning: Multi-instance; Multi-label; Multi-view learning},
  archive   = {C_IJCAI},
  author    = {Yang Yang and Chubing Zhang and Yi-Chu Xu and Dianhai Yu and De-Chuan Zhan and Jian Yang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/454},
  pages     = {3300-3306},
  title     = {Rethinking label-wise cross-modal retrieval from a semantic sharing perspective},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). BESA: BERT-based simulated annealing for adversarial text
attacks. <em>IJCAI</em>, 3293–3299. (<a
href="https://doi.org/10.24963/ijcai.2021/453">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Modern Natural Language Processing (NLP) models are known immensely brittle towards text adversarial examples. Recent attack algorithms usually adopt word-level substitution strategies following a pre-computed word replacement mechanism. However, their resultant adversarial examples are still imperfect in achieving grammar correctness and semantic similarities, which is largely because of their unsuitable candidate word selections and static optimization methods. In this research, we propose BESA, a BERT-based Simulated Annealing algorithm, to address these two problems. Firstly, we leverage the BERT Masked Language Model (MLM) to generate contextual-aware candidate words to produce fluent adversarial text and avoid grammar errors. Secondly, we employ Simulated Annealing (SA) to adaptively determine the word substitution order. The SA provides sufficient word replacement options via internal simulations, with an objective to obtain both a high attack success rate and a low word substitution rate. Besides, our algorithm is able to jump out of local optima with a controlled probability, making it closer to achieve the best possible attack (i.e., the global optima). Experiments on five popular datasets manifest the superiority of BESA compared with existing methods, including TextFooler, BAE, BERT-Attack, PWWS, and PSO. Keywords: Machine Learning: Adversarial Machine Learning Natural Language Processing: Natural Language Processing},
  archive   = {C_IJCAI},
  author    = {Xinghao Yang and Weifeng Liu and Dacheng Tao and Wei Liu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/453},
  pages     = {3293-3299},
  title     = {BESA: BERT-based simulated annealing for adversarial text attacks},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Unsupervised path representation learning with curriculum
negative sampling. <em>IJCAI</em>, 3286–3292. (<a
href="https://doi.org/10.24963/ijcai.2021/452">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Path representations are critical in a variety of transportation applications, such as estimating path ranking in path recommendation systems and estimating path travel time in navigation systems. Existing studies often learn task-specific path representations in a supervised manner, which require a large amount of labeled training data and generalize poorly to other tasks. We propose an unsupervised learning framework Path InfoMax (PIM) to learn generic path representations that work for different downstream tasks. We first propose a curriculum negative sampling method, for each input path, to generate a small amount of negative paths, by following the principles of curriculum learning. Next, PIM employs mutual information maximization to learn path representations from both a global and a local view. In the global view, PIM distinguishes the representations of the input paths from those of the negative paths. In the local view, PIM distinguishes the input path representations from the representations of the nodes that appear only in the negative paths. This enables the learned path representations encode both global and local information at different scales. Extensive experiments on two downstream tasks, ranking score estimation and travel time estimation, using two road network datasets suggest that PIM significantly outperforms other unsupervised methods and is also able to be used as a pre-training method to enhance supervised path representation learning. Keywords: Machine Learning: Unsupervised Learning Multidisciplinary Topics and Applications: Transportation Machine Learning Applications: Applications of Unsupervised Learning},
  archive   = {C_IJCAI},
  author    = {Sean Bin Yang and Chenjuan Guo and Jilin Hu and Jian Tang and Bin Yang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/452},
  pages     = {3286-3292},
  title     = {Unsupervised path representation learning with curriculum negative sampling},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Progressive open-domain response generation with multiple
controllable attributes. <em>IJCAI</em>, 3279–3285. (<a
href="https://doi.org/10.24963/ijcai.2021/451">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {It is desirable to include more controllable attributes to enhance the diversity of generated responses in open-domain dialogue systems. However, existing methods can generate responses with only one controllable attribute or lack a flexible way to generate them with multiple controllable attributes. In this paper, we propose a Progressively trained Hierarchical Encoder-Decoder (PHED) to tackle this task. More specifically, PHED deploys Conditional Variational AutoEncoder (CVAE) on Transformer to include one aspect of attributes at one stage. A vital characteristic of the CVAE is to separate the latent variables at each stage into two types: a global variable capturing the common semantic features and a specific variable absorbing the attribute information at that stage. PHED then couples the CVAE latent variables with the Transformer encoder and is trained by minimizing a newly derived ELBO and controlled losses to produce the next stage&#39;s input and produce responses as required. Finally, we conduct extensive evaluations to show that PHED significantly outperforms the state-of-the-art neural generation models and produces more diverse responses as expected. Keywords: Machine Learning: Learning Generative Models Natural Language Processing: Dialogue},
  archive   = {C_IJCAI},
  author    = {Haiqin Yang and Xiaoyuan Yao and Yiqun Duan and Jianping Shen and Jie Zhong and Kun Zhang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/451},
  pages     = {3279-3285},
  title     = {Progressive open-domain response generation with multiple controllable attributes},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Secure deep graph generation with link differential privacy.
<em>IJCAI</em>, 3271–3278. (<a
href="https://doi.org/10.24963/ijcai.2021/450">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Many data mining and analytical tasks rely on the abstraction of networks (graphs) to summarize relational structures among individuals (nodes). Since relational data are often sensitive, we aim to seek effective approaches to generate utility-preserved yet privacy-protected structured data. In this paper, we leverage the differential privacy (DP) framework to formulate and enforce rigorous privacy constraints on deep graph generation models, with a focus on edge-DP to guarantee individual link privacy. In particular, we enforce edge-DP by injecting designated noise to the gradients of a link reconstruction based graph generation model, while ensuring data utility by improving structure learning with structure-oriented graph discrimination. Extensive experiments on two real-world network datasets show that our proposed DPGGAN model is able to generate graphs with effectively preserved global structure and rigorously protected individual link privacy. Keywords: Machine Learning: Learning Generative Models Data Mining: Mining Graphs, Semi Structured Data, Complex Data Data Mining: Privacy Preserving Data Mining},
  archive   = {C_IJCAI},
  author    = {Carl Yang and Haonan Wang and Ke Zhang and Liang Chen and Lichao Sun},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/450},
  pages     = {3271-3278},
  title     = {Secure deep graph generation with link differential privacy},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-level generative models for partial label learning
with non-random label noise. <em>IJCAI</em>, 3264–3270. (<a
href="https://doi.org/10.24963/ijcai.2021/449">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Partial label (PL) learning tackles the problem where each training instance is associated with a set of candidate labels that include both the true label and some irrelevant noise labels. In this paper, we propose a novel multi-level generative model for partial label learning (MGPLL), which tackles the PL problem by learning both a label level adversarial generator and a feature level adversarial generator under a bi-directional mapping framework between the label vectors and the data samples. MGPLL uses a conditional noise label generation network to model the non-random noise labels and perform label denoising, and uses a multi-class predictor to map the training instances to the denoised label vectors, while a conditional data feature generator is used to form an inverse mapping from the denoised label vectors to data samples. Both the noise label generator and the data feature generator are learned in an adversarial manner to match the observed candidate labels and data features respectively. We conduct extensive experiments on both synthesized and real-world partial label datasets. The proposed approach demonstrates the state-of-the-art performance for partial label learning. Keywords: Machine Learning: Classification Machine Learning: Weakly Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Yan Yan and Yuhong Guo},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/449},
  pages     = {3264-3270},
  title     = {Multi-level generative models for partial label learning with non-random label noise},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A clustering-based framework for classifying data streams.
<em>IJCAI</em>, 3257–3263. (<a
href="https://doi.org/10.24963/ijcai.2021/448">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The non-stationary nature of data streams strongly challenges traditional machine learning techniques. Although some solutions have been proposed to extend traditional machine learning techniques for handling data streams, these approaches either require an initial label set or rely on specialized design parameters. The overlap among classes and the labeling of data streams constitute other major challenges for classifying data streams. In this paper, we proposed a clustering-based data stream classification framework to handle non-stationary data streams without utilizing an initial label set. A density-based stream clustering procedure is used to capture novel concepts with a dynamic threshold and an effective active label querying strategy is introduced to continuously learn the new concepts from the data streams. The sub-cluster structure of each cluster is explored to handle the overlap among classes. Experimental results and quantitative comparison studies reveal that the proposed method provides statistically better or comparable performance than the existing methods. Keywords: Machine Learning: Online Learning Data Mining: Classification Data Mining: Mining Data Streams},
  archive   = {C_IJCAI},
  author    = {Xuyang Yan and Abdollah Homaifar and Mrinmoy Sarkar and Abenezer Girma and Edward Tunstel},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/448},
  pages     = {3257-3263},
  title     = {A clustering-based framework for classifying data streams},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Decomposable-net: Scalable low-rank compression for neural
networks. <em>IJCAI</em>, 3249–3256. (<a
href="https://doi.org/10.24963/ijcai.2021/447">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Compressing DNNs is important for the real-world applications operating on resource-constrained devices. However, we typically observe drastic performance deterioration when changing model size after training is completed. Therefore, retraining is required to resume the performance of the compressed models suitable for different devices. In this paper, we propose Decomposable-Net (the network decomposable in any size), which allows flexible changes to model size without retraining. We decompose weight matrices in the DNNs via singular value decomposition and adjust ranks according to the target model size. Unlike the existing low-rank compression methods that specialize the model to a fixed size, we propose a novel backpropagation scheme that jointly minimizes losses for both of full- and low-rank networks. This enables not only to maintain the performance of a full-rank network {\it without retraining} but also to improve low-rank networks in multiple sizes. Additionally, we introduce a simple criterion for rank selection that effectively suppresses approximation error. In experiments on the ImageNet classification task, Decomposable-Net yields superior accuracy in a wide range of model sizes. In particular, Decomposable-Net achieves the top-1 accuracy of 73.2\% with 0.27xMACs with ResNet-50, compared to Tucker decomposition (67.4\% / 0.30x), Trained Rank Pruning (70.6\% / 0.28x), and universally slimmable networks (71.4\% / 0.26x). Keywords: Machine Learning: Deep Learning Computer Vision: Statistical Methods and Machine Learning Computer Vision: Recognition: Detection, Categorization, Indexing, Matching, Retrieval, Semantic Interpretation Computer Vision: 2D and 3D Computer Vision},
  archive   = {C_IJCAI},
  author    = {Atsushi Yaguchi and Taiji Suzuki and Shuhei Nitta and Yukinobu Sakata and Akiyuki Tanizawa},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/447},
  pages     = {3249-3256},
  title     = {Decomposable-net: Scalable low-rank compression for neural networks},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Differentially private pairwise learning revisited.
<em>IJCAI</em>, 3242–3248. (<a
href="https://doi.org/10.24963/ijcai.2021/446">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Instead of learning with pointwise loss functions, learning with pairwise loss functions (pairwise learning) has received much attention recently as it is more capable of modeling the relative relationship between pairs of samples. However, most of the existing algorithms for pairwise learning fail to take into consideration the privacy issue in their design. To address this issue, previous work studied pairwise learning in the Differential Privacy (DP) model. However, their utilities (population errors) are far from optimal. To address the sub-optimal utility issue, in this paper, we proposed new pure or approximate DP algorithms for pairwise learning. Specifically, under the assumption that the loss functions are Lipschitz, our algorithms could achieve the optimal expected population risk for both strongly convex and general convex cases. We also conduct extensive experiments on real-world datasets to evaluate the proposed algorithms, experimental results support our theoretical analysis and show the priority of our algorithms. Keywords: Machine Learning: Classification Machine Learning: Learning Theory Multidisciplinary Topics and Applications: Security and Privacy},
  archive   = {C_IJCAI},
  author    = {Zhiyu Xue and Shaoyang Yang and Mengdi Huai and Di Wang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/446},
  pages     = {3242-3248},
  title     = {Differentially private pairwise learning revisited},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Clustering-induced adaptive structure enhancing network for
incomplete multi-view data. <em>IJCAI</em>, 3235–3241. (<a
href="https://doi.org/10.24963/ijcai.2021/445">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Incomplete multi-view clustering aims to cluster samples with missing views, which has drawn more and more research interest. Although several methods have been developed for incomplete multi-view clustering, they fail to extract and exploit the comprehensive global and local structure of multi-view data, so their clustering performance is limited. This paper proposes a Clustering-induced Adaptive Structure Enhancing Network (CASEN) for incomplete multi-view clustering, which is an end-to-end trainable framework that jointly conducts multi-view structure enhancing and data clustering. Our method adopts multi-view autoencoder to infer the missing features of the incomplete samples. Then, we perform adaptive graph learning and graph convolution on the reconstructed complete multi-view data to effectively extract data structure. Moreover, we use multiple kernel clustering to integrate the global and local structure for clustering, and the clustering results in turn are used to enhance the data structure. Extensive experiments on several benchmark datasets demonstrate that our method can comprehensively obtain the structure of incomplete multi-view data and achieve superior performance compared to the other methods. Keywords: Machine Learning: Clustering Machine Learning: Multi-instance; Multi-label; Multi-view learning Machine Learning: Unsupervised Learning},
  archive   = {C_IJCAI},
  author    = {Zhe Xue and Junping Du and Changwei Zheng and Jie Song and Wenqi Ren and Meiyu Liang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/445},
  pages     = {3235-3241},
  title     = {Clustering-induced adaptive structure enhancing network for incomplete multi-view data},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). KDExplainer: A task-oriented attention model for explaining
knowledge distillation. <em>IJCAI</em>, 3228–3234. (<a
href="https://doi.org/10.24963/ijcai.2021/444">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Knowledge distillation (KD) has recently emerged as an efficacious scheme for learning compact deep neural networks (DNNs). Despite the promising results achieved, the rationale that interprets the behavior of KD has yet remained largely understudied. In this paper, we introduce a novel task-oriented attention model, termed as KDExplainer, to shed light on the working mechanism underlying the vanilla KD. At the heart of KDExplainer is a Hierarchical Mixture of Experts (HME), in which a multi-class classification is reformulated as a multi-task binary one. Through distilling knowledge from a free-form pre-trained DNN to KDExplainer, we observe that KD implicitly modulates the knowledge conflicts between different subtasks, and in reality has much more to offer than label smoothing. Based on such findings, we further introduce a portable tool, dubbed as virtual attention module (VAM), that can be seamlessly integrated with various DNNs to enhance their performance under KD. Experimental results demonstrate that with a negligible additional cost, student models equipped with VAM consistently outperform their non-VAM counterparts across different benchmarks. Furthermore, when combined with other KD methods, VAM remains competent in promoting results, even though it is only motivated by vanilla KD. The code is available at https:// github.com/zju-vipa/KDExplainer. Keywords: Machine Learning: Deep Learning Machine Learning: Explainable/Interpretable Machine Learning Machine Learning: Transfer, Adaptation, Multi-task Learning},
  archive   = {C_IJCAI},
  author    = {Mengqi Xue and Jie Song and Xinchao Wang and Ying Chen and Xingen Wang and Mingli Song},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/444},
  pages     = {3228-3234},
  title     = {KDExplainer: A task-oriented attention model for explaining knowledge distillation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evolutionary gradient descent for non-convex optimization.
<em>IJCAI</em>, 3221–3227. (<a
href="https://doi.org/10.24963/ijcai.2021/443">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Non-convex optimization is often involved in artificial intelligence tasks, which may have many saddle points, and is NP-hard to solve. Evolutionary algorithms (EAs) are general-purpose derivative-free optimization algorithms with a good ability to find the global optimum, which can be naturally applied to non-convex optimization. Their performance is, however, limited due to low efficiency. Gradient descent (GD) runs efficiently, but only converges to a first-order stationary point, which may be a saddle point and thus arbitrarily bad. Some recent efforts have been put into combining EAs and GD. However, previous works either utilized only a specific component of EAs, or just combined them heuristically without theoretical guarantee. In this paper, we propose an evolutionary GD (EGD) algorithm by combining typical components, i.e., population and mutation, of EAs with GD. We prove that EGD can converge to a second-order stationary point by escaping the saddle points, and is more efficient than previous algorithms. Empirical results on non-convex synthetic functions as well as reinforcement learning (RL) tasks also show its superiority. Keywords: Machine Learning: Evolutionary Learning Heuristic Search and Game Playing: Heuristic Search Heuristic Search and Game Playing: Heuristic Search and Machine Learning},
  archive   = {C_IJCAI},
  author    = {Ke Xue and Chao Qian and Ling Xu and Xudong Fei},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/443},
  pages     = {3221-3227},
  title     = {Evolutionary gradient descent for non-convex optimization},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). K-nearest neighbors by means of sequence to sequence deep
neural networks and memory networks. <em>IJCAI</em>, 3214–3220. (<a
href="https://doi.org/10.24963/ijcai.2021/442">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {k-Nearest Neighbors is one of the most fundamental but effective classification models. In this paper, we propose two families of models built on a sequence to sequence model and a memory network model to mimic the k-Nearest Neighbors model, which generate a sequence of labels, a sequence of out-of-sample feature vectors and a final label for classification, and thus they could also function as oversamplers. We also propose &#39;out-of-core&#39; versions of our models which assume that only a small portion of data can be loaded into memory. Computational experiments show that our models on structured datasets outperform k-Nearest Neighbors, a feed-forward neural network, XGBoost, lightGBM, random forest and a memory network, due to the fact that our models must produce additional output and not just the label. On image and text datasets, the performance of our model is close to many state-of-the-art deep models. As an oversampler on imbalanced datasets, the sequence to sequence kNN model often outperforms Synthetic Minority Over-sampling Technique and Adaptive Synthetic Sampling. Keywords: Machine Learning: Deep Learning Data Mining: Class Imbalance and Unequal Cost Data Mining: Classification},
  archive   = {C_IJCAI},
  author    = {Yiming Xu and Diego Klabjan},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/442},
  pages     = {3214-3220},
  title     = {K-nearest neighbors by means of sequence to sequence deep neural networks and memory networks},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploiting spiking dynamics with spatial-temporal feature
normalization in graph learning. <em>IJCAI</em>, 3207–3213. (<a
href="https://doi.org/10.24963/ijcai.2021/441">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Biological spiking neurons with intrinsic dynamics underlie the powerful representation and learning capabilities of the brain for processing multimodal information in complex environments. Despite recent tremendous progress in spiking neural networks (SNNs) for handling Euclidean-space tasks, it still remains challenging to exploit SNNs in processing non-Euclidean-space data represented by graph data, mainly due to the lack of effective modeling framework and useful training techniques. Here we present a general spike-based modeling framework that enables the direct training of SNNs for graph learning. Through spatial-temporal unfolding for spiking data flows of node features, we incorporate graph convolution filters into spiking dynamics and formalize a synergistic learning paradigm. Considering the unique features of spike representation and spiking dynamics, we propose a spatial-temporal feature normalization (STFN) technique suitable for SNN to accelerate convergence. We instantiate our methods into two spiking graph models, including graph convolution SNNs and graph attention SNNs, and validate their performance on three node-classification benchmarks, including Cora, Citeseer, and Pubmed. Our model can achieve comparable performance with the state-of-the-art graph neural network (GNN) models with much lower computation costs, demonstrating great benefits for the execution on neuromorphic hardware and prompting neuromorphic applications in graphical scenarios. Keywords: Machine Learning: Learning Graphical Models Humans and AI: Cognitive Modeling Humans and AI: Cognitive Systems},
  archive   = {C_IJCAI},
  author    = {Mingkun Xu and Yujie Wu and Lei Deng and Faqiang Liu and Guoqi Li and Jing Pei},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/441},
  pages     = {3207-3213},
  title     = {Exploiting spiking dynamics with spatial-temporal feature normalization in graph learning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning deeper non-monotonic networks by softly
transferring solution space. <em>IJCAI</em>, 3200–3206. (<a
href="https://doi.org/10.24963/ijcai.2021/440">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Different from popular neural networks using quasiconvex activations, non-monotonic networks activated by periodic nonlinearities have emerged as a more competitive paradigm, offering revolutionary benefits: 1) compactly characterizing high-frequency patterns; 2) precisely representing high-order derivatives. Nevertheless, they are also well-known for being hard to train, due to easily over-fitting dissonant noise and only allowing for tiny architectures (shallower than 5 layers). The fundamental bottleneck is that the periodicity leads to many poor and dense local minima in solution space. The direction and norm of gradient oscillate continually during error backpropagation. Thus non-monotonic networks are prematurely stuck in these local minima, and leave out effective error feedback. To alleviate the optimization dilemma, in this paper, we propose a non-trivial soft transfer approach. It smooths their solution space close to that of monotonic ones in the beginning, and then improve their representational properties by transferring the solutions from the neural space of monotonic neurons to the Fourier space of non-monotonic neurons as the training continues. The soft transfer consists of two core components: 1) a rectified concrete gate is constructed to characterize the state of each neuron; 2) a variational Bayesian learning framework is proposed to dynamically balance the empirical risk and the intensity of transfer. We provide comprehensive empirical evidence showing that the soft transfer not only reduces the risk of non-monotonic networks on over-fitting noise, but also helps them scale to much deeper architectures (more than 100 layers) achieving the new state-of-the-art performance. Keywords: Machine Learning: Kernel Methods Machine Learning: Deep Learning Machine Learning: Classification},
  archive   = {C_IJCAI},
  author    = {Zheng-Fan Wu and Hui Xue and Weimin Bai},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/440},
  pages     = {3200-3206},
  title     = {Learning deeper non-monotonic networks by softly transferring solution space},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep reinforcement learning boosted partial domain
adaptation. <em>IJCAI</em>, 3192–3199. (<a
href="https://doi.org/10.24963/ijcai.2021/439">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Domain adaptation is critical for learning transferable features that effectively reduce the distribution difference among domains. In the era of big data, the availability of large-scale labeled datasets motivates partial domain adaptation (PDA) which deals with adaptation from large source domains to small target domains with less number of classes. In the PDA setting, it is crucial to transfer relevant source samples and eliminate irrelevant ones to mitigate negative transfer. In this paper, we propose a deep reinforcement learning based source data selector for PDA, which is capable of eliminating less relevant source samples automatically to boost existing adaptation methods. It determines to either keep or discard the source instances based on their feature representations so that more effective knowledge transfer across domains can be achieved via filtering out irrelevant samples. As a general module, the proposed DRL-based data selector can be integrated into any existing domain adaptation or partial domain adaptation models. Extensive experiments on several benchmark datasets demonstrate the superiority of the proposed DRL-based data selector which leads to state-of-the-art performance for various PDA tasks. Keywords: Machine Learning: Transfer, Adaptation, Multi-task Learning Machine Learning Applications: Applications of Reinforcement Learning},
  archive   = {C_IJCAI},
  author    = {Keyu Wu and Min Wu and Jianfei Yang and Zhenghua Chen and Zhengguo Li and Xiaoli Li},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/439},
  pages     = {3192-3199},
  title     = {Deep reinforcement learning boosted partial domain adaptation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). GSPL: A succinct kernel model for group-sparse projections
learning of multiview data. <em>IJCAI</em>, 3185–3191. (<a
href="https://doi.org/10.24963/ijcai.2021/438">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper explores a succinct kernel model for Group-Sparse Projections Learning (GSPL), to handle multiview feature selection task completely. Compared to previous works, our model has the following useful properties: 1) Strictness: GSPL innovatively learns group-sparse projections strictly on multiview data via ‘2; 0-norm constraint, which is different with previous works that encourage group-sparse projections softly. 2) Adaptivity: In GSPL model, when the total number of selected features is given, the numbers of selected features of different views can be determined adaptively, which avoids artificial settings. Besides, GSPL can capture the differences among multiple views adaptively, which handles the inconsistent problem among different views. 3) Succinctness: Except for the intrinsic parameters of projection-based feature selection task, GSPL does not bring extra parameters, which guarantees the applicability in practice. To solve the optimization problem involved in GSPL, a novel iterative algorithm is proposed with rigorously theoretical guarantees. Experimental results demonstrate the superb performance of GSPL on synthetic and real datasets. Keywords: Machine Learning: Learning Sparse Models Machine Learning: Multi-instance; Multi-label; Multi-view learning Machine Learning: Unsupervised Learning},
  archive   = {C_IJCAI},
  author    = {Danyang Wu and Jin Xu and Xia Dong and Meng Liao and Rong Wang and Feiping Nie and Xuelong Li},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/438},
  pages     = {3185-3191},
  title     = {GSPL: A succinct kernel model for group-sparse projections learning of multiview data},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Closing the BIG-LID: An effective local intrinsic
dimensionality defense for nonlinear regression poisoning.
<em>IJCAI</em>, 3176–3184. (<a
href="https://doi.org/10.24963/ijcai.2021/437">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Nonlinear regression, although widely used in engineering, financial and security applications for automated decision making, is known to be vulnerable to training data poisoning. Targeted poisoning attacks may cause learning algorithms to fit decision functions with poor predictive performance. This paper presents a new analysis of local intrinsic dimensionality (LID) of nonlinear regression under such poisoning attacks within a Stackelberg game, leading to a practical defense. After adapting a gradient-based attack on linear regression that significantly impairs prediction capabilities to nonlinear settings, we consider a multi-step unsupervised black-box defense. The first step identifies samples that have the greatest influence on the learner&#39;s validation error; we then use the theory of local intrinsic dimensionality, which reveals the degree of being an outlier of data samples, to iteratively identify poisoned samples via a generative probabilistic model, and suppress their influence on the prediction function. Empirical validation demonstrates superior performance compared to a range of recent defenses. Keywords: Machine Learning: Adversarial Machine Learning Multidisciplinary Topics and Applications: Security and Privacy Data Mining: Anomaly/Outlier Detection},
  archive   = {C_IJCAI},
  author    = {Sandamal Weerasinghe and Tamas Abraham and Tansu Alpcan and Sarah M. Erfani and Christopher Leckie and Benjamin I. P. Rubinstein},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/437},
  pages     = {3176-3184},
  title     = {Closing the BIG-LID: An effective local intrinsic dimensionality defense for nonlinear regression poisoning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reward-constrained behavior cloning. <em>IJCAI</em>,
3169–3175. (<a href="https://doi.org/10.24963/ijcai.2021/436">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep reinforcement learning (RL) has demonstrated success in challenging decision-making/control tasks. However, RL methods, which solve tasks through maximizing the expected reward, may generate undesirable behaviors due to inferior local convergence or incompetent reward design. These undesirable behaviors of agents may not reduce the total reward but destroy the user experience of the application. For example, in the autonomous driving task, the policy actuated by speed reward behaves much more sudden brakes while human drivers generally don’t do that. To overcome this problem, we present a novel method named Reward-Constrained Behavior Cloning (RCBC) which synthesizes imitation learning and constrained reinforcement learning. RCBC leverages human demonstrations to induce desirable or human-like behaviors and employs lower-bound reward constraints for policy optimization to maximize the expected reward. Empirical results on popular benchmark environments show that RCBC learns signiﬁcantly more human-desired policies with performance guarantees which meet the lower-bound reward constraints while performing better than or as well as baseline methods in terms of reward maximization. Keywords: Machine Learning: Deep Reinforcement Learning Machine Learning: Reinforcement Learning Constraints and SAT: Constraint Optimization},
  archive   = {C_IJCAI},
  author    = {Zhaorong Wang and Meng Wang and Jingqi Zhang and Yingfeng Chen and Chongjie Zhang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/436},
  pages     = {3169-3175},
  title     = {Reward-constrained behavior cloning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reinforcement learning based sparse black-box adversarial
attack on video recognition models. <em>IJCAI</em>, 3162–3168. (<a
href="https://doi.org/10.24963/ijcai.2021/435">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We explore the black-box adversarial attack on video recognition models. Attacks are only performed on selected key regions and key frames to reduce the high computation cost of searching adversarial perturbations on a video due to its high dimensionality. To select key frames, one way is to use heuristic algorithms to evaluate the importance of each frame and choose the essential ones. However, it is time inefficient on sorting and searching. In order to speed up the attack process, we propose a reinforcement learning based frame selection strategy. Specifically, the agent explores the difference between the original class and the target class of videos to make selection decisions. It receives rewards from threat models which indicate the quality of the decisions. Besides, we also use saliency detection to select key regions and only estimate the sign of gradient instead of the gradient itself in zeroth order optimization to further boost the attack process. We can use the trained model directly in the untargeted attack or with little fine-tune in the targeted attack, which saves computation time. A range of empirical results on real datasets demonstrate the effectiveness and efficiency of the proposed method. Keywords: Machine Learning: Adversarial Machine Learning Machine Learning Applications: Applications of Reinforcement Learning},
  archive   = {C_IJCAI},
  author    = {Zeyuan Wang and Chaofeng Sha and Su Yang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/435},
  pages     = {3162-3168},
  title     = {Reinforcement learning based sparse black-box adversarial attack on video recognition models},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust adversarial imitation learning via
adaptively-selected demonstrations. <em>IJCAI</em>, 3155–3161. (<a
href="https://doi.org/10.24963/ijcai.2021/434">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The agent in imitation learning (IL) is expected to mimic the behavior of the expert. Its performance relies highly on the quality of given expert demonstrations. However, the assumption that collected demonstrations are optimal cannot always hold in real-world tasks, which would seriously influence the performance of the learned agent. In this paper, we propose a robust method within the framework of Generative Adversarial Imitation Learning (GAIL) to address imperfect demonstration issue, in which good demonstrations can be adaptively selected for training while bad demonstrations are abandoned. Specifically, a binary weight is assigned to each expert demonstration to indicate whether to select it for training. The reward function in GAIL is employed to determine this weight (i.e. higher reward results in higher weight). Compared to some existing solutions that require some auxiliary information about this weight, we set up the connection between weight and model so that we can jointly optimize GAIL and learn the latent weight. Besides hard binary weighting, we also propose a soft weighting scheme. Experiments in the Mujoco demonstrate the proposed method outperforms other GAIL-based methods when dealing with imperfect demonstrations. Keywords: Machine Learning: Adversarial Machine Learning Machine Learning: Unsupervised Learning},
  archive   = {C_IJCAI},
  author    = {Yunke Wang and Chang Xu and Bo Du},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/434},
  pages     = {3155-3161},
  title     = {Robust adversarial imitation learning via adaptively-selected demonstrations},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Layer-assisted neural topic modeling over document
networks. <em>IJCAI</em>, 3148–3154. (<a
href="https://doi.org/10.24963/ijcai.2021/433">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Neural topic modeling provides a flexible, efficient, and powerful way to extract topic representations from text documents. Unfortunately, most existing models cannot handle the text data with network links, such as web pages with hyperlinks and scientific papers with citations. To resolve this kind of data, we develop a novel neural topic model , namely Layer-Assisted Neural Topic Model (LANTM), which can be interpreted from the perspective of variational auto-encoders. Our major motivation is to enhance the topic representation encoding by not only using text contents, but also the assisted network links. Specifically, LANTM encodes the texts and network links to the topic representations by an augmented network with graph convolutional modules, and decodes them by maximizing the likelihood of the generative process. The neural variational inference is adopted for efficient inference. Experimental results validate that LANTM significantly outperforms the existing models on topic quality, text classification and link prediction.. Keywords: Machine Learning: Learning Graphical Models Uncertainty in AI: Bayesian Networks Uncertainty in AI: Graphical Models},
  archive   = {C_IJCAI},
  author    = {Yiming Wang and Ximing Li and Jihong Ouyang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/433},
  pages     = {3148-3154},
  title     = {Layer-assisted neural topic modeling over document networks},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021d). Against membership inference attack: Pruning is all you
need. <em>IJCAI</em>, 3141–3147. (<a
href="https://doi.org/10.24963/ijcai.2021/432">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The large model size, high computational operations, and vulnerability against membership inference attack (MIA) have impeded deep learning or deep neural networks (DNNs) popularity, especially on mobile devices. To address the challenge, we envision that the weight pruning technique will help DNNs against MIA while reducing model storage and computational operation. In this work, we propose a pruning algorithm, and we show that the proposed algorithm can find a subnetwork that can prevent privacy leakage from MIA and achieves competitive accuracy with the original DNNs. We also verify our theoretical insights with experiments. Our experimental results illustrate that the attack accuracy using model compression is up to 13.6\% and 10\% lower than that of the baseline and Min-Max game, accordingly. Keywords: Machine Learning: Deep Learning Multidisciplinary Topics and Applications: Security and Privacy},
  archive   = {C_IJCAI},
  author    = {Yijue Wang and Chenghong Wang and Zigeng Wang and Shanglin Zhou and Hang Liu and Jinbo Bi and Caiwen Ding and Sanguthevar Rajasekaran},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/432},
  pages     = {3141-3147},
  title     = {Against membership inference attack: Pruning is all you need},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Self-supervised adversarial distribution regularization for
medication recommendation. <em>IJCAI</em>, 3134–3140. (<a
href="https://doi.org/10.24963/ijcai.2021/431">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Medication recommendation is a significant healthcare application due to its promise in effectively prescribing medications. Avoiding fatal side effects related to Drug-Drug Interaction (DDI) is among the critical challenges. Most existing methods try to mitigate the problem by providing models with extra DDI knowledge, making models complicated. While treating all patients with different DDI properties as a single cohort would put forward strict requirements on models&#39; generalization performance. In pursuit of a valuable model for a safe recommendation, we propose the Self-Supervised Adversarial Regularization Model for Medication Recommendation (SARMR). SARMR obtains the target distribution associated with safe medication combinations from raw patient records for adversarial regularization. In this way, the model can shape distributions of patient representations to achieve DDI reduction. To obtain accurate self-supervision information, SARMR models interactions between physicians and patients by building a key-value memory neural network and carrying out multi-hop reading to obtain contextual information for patient representations. SARMR outperforms all baseline methods in the experiment on a real-world clinical dataset. This model can achieve DDI reduction when considering the different number of DDI types, which demonstrates the robustness of adversarial regularization for safe medication recommendation. Keywords: Machine Learning: Deep Learning Multidisciplinary Topics and Applications: AI for Life Science Machine Learning Applications: Bio/Medicine},
  archive   = {C_IJCAI},
  author    = {Yanda Wang and Weitong Chen and Dechang PI and Lin Yue and Sen Wang and Miao Xu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/431},
  pages     = {3134-3140},
  title     = {Self-supervised adversarial distribution regularization for medication recommendation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Demiguise attack: Crafting invisible semantic adversarial
perturbations with perceptual similarity. <em>IJCAI</em>, 3125–3133. (<a
href="https://doi.org/10.24963/ijcai.2021/430">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep neural networks (DNNs) have been found to be vulnerable to adversarial examples. Adversarial examples are malicious images with visually imperceptible perturbations. While these carefully crafted perturbations restricted with tight Lp norm bounds are small, they are still easily perceivable by humans. These perturbations also have limited success rates when attacking black-box models or models with defenses like noise reduction filters. To solve these problems, we propose Demiguise Attack, crafting &quot;unrestricted&quot; perturbations with Perceptual Similarity. Specifically, we can create powerful and photorealistic adversarial examples by manipulating semantic information based on Perceptual Similarity. Adversarial examples we generate are friendly to the human visual system (HVS), although the perturbations are of large magnitudes. We extend widely-used attacks with our approach, enhancing adversarial effectiveness impressively while contributing to imperceptibility. Extensive experiments show that the proposed method not only outperforms various state-of-the-art attacks in terms of fooling rate, transferability, and robustness against defenses but can also improve attacks effectively. In addition, we also notice that our implementation can simulate illumination and contrast changes that occur in real-world scenarios, which will contribute to exposing the blind spots of DNNs. Keywords: Machine Learning: Adversarial Machine Learning Machine Learning: Deep Learning},
  archive   = {C_IJCAI},
  author    = {Yajie Wang and Shangbo Wu and Wenyi Jiang and Shengang Hao and Yu-an Tan and Quanxin Zhang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/430},
  pages     = {3125-3133},
  title     = {Demiguise attack: Crafting invisible semantic adversarial perturbations with perceptual similarity},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mean field equilibrium in multi-armed bandit game with
continuous reward. <em>IJCAI</em>, 3118–3124. (<a
href="https://doi.org/10.24963/ijcai.2021/429">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Mean field game facilitates analyzing multi-armed bandit (MAB) for a large number of agents by approximating their interactions with an average effect. Existing mean field models for multi-agent MAB mostly assume a binary reward function, which leads to tractable analysis but is usually not applicable in practical scenarios. In this paper, we study the mean field bandit game with a continuous reward function. Specifically, we focus on deriving the existence and uniqueness of mean field equilibrium (MFE), thereby guaranteeing the asymptotic stability of the multi-agent system. To accommodate the continuous reward function, we encode the learned reward into an agent state, which is in turn mapped to its stochastic arm playing policy and updated using realized observations. We show that the state evolution is upper semi-continuous, based on which the existence of MFE is obtained. As the Markov analysis is mainly for the case of discrete state, we transform the stochastic continuous state evolution into a deterministic ordinary differential equation (ODE). On this basis, we can characterize a contraction mapping for the ODE to ensure a unique MFE for the bandit game. Extensive evaluations validate our MFE characterization, and exhibit tight empirical regret of the MAB problem. Keywords: Machine Learning: Online Learning Agent-based and Multi-agent Systems: Algorithmic Game Theory Agent-based and Multi-agent Systems: Multi-agent Learning},
  archive   = {C_IJCAI},
  author    = {Xiong Wang and Riheng Jia},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/429},
  pages     = {3118-3124},
  title     = {Mean field equilibrium in multi-armed bandit game with continuous reward},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Discrete multiple kernel k-means. <em>IJCAI</em>, 3111–3117.
(<a href="https://doi.org/10.24963/ijcai.2021/428">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The multiple kernel k-means (MKKM) and its variants utilize complementary information from different kernels, achieving better performance than kernel k-means (KKM). However, the optimization procedures of previous works all comprise two stages, learning the continuous relaxed label matrix and obtaining the discrete one by extra discretization procedures. Such a two-stage strategy gives rise to a mismatched problem and severe information loss. To address this problem, we elaborate a novel Discrete Multiple Kernel k-means (DMKKM) model solved by an optimization algorithm that directly obtains the cluster indicator matrix without subsequent discretization procedures. Moreover, DMKKM can strictly measure the correlations among kernels, which is capable of enhancing kernel fusion by reducing redundancy and improving diversity. What’s more, DMKKM is parameter-free avoiding intractable hyperparameter tuning, which makes it feasible in practical applications. Extensive experiments illustrated the effectiveness and superiority of the proposed model. Keywords: Machine Learning: Clustering Machine Learning: Kernel Methods Machine Learning: Multi-instance; Multi-label; Multi-view learning},
  archive   = {C_IJCAI},
  author    = {Rong Wang and Jitao Lu and Yihang Lu and Feiping Nie and Xuelong Li},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/428},
  pages     = {3111-3117},
  title     = {Discrete multiple kernel k-means},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Stability and generalization for randomized coordinate
descent. <em>IJCAI</em>, 3104–3110. (<a
href="https://doi.org/10.24963/ijcai.2021/427">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Randomized coordinate descent (RCD) is a popular optimization algorithm with wide applications in various machine learning problems, which motivates a lot of theoretical analysis on its convergence behavior. As a comparison, there is no work studying how the models trained by RCD would generalize to test examples. In this paper, we initialize the generalization analysis of RCD by leveraging the powerful tool of algorithmic stability. We establish argument stability bounds of RCD for both convex and strongly convex objectives, from which we develop optimal generalization bounds by showing how to early-stop the algorithm to tradeoff the estimation and optimization. Our analysis shows that RCD enjoys better stability as compared to stochastic gradient descent. Keywords: Machine Learning: Learning Theory Machine Learning: Online Learning},
  archive   = {C_IJCAI},
  author    = {Puyu Wang and Liang Wu and Yunwen Lei},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/427},
  pages     = {3104-3110},
  title     = {Stability and generalization for randomized coordinate descent},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learn the highest label and rest label description degrees.
<em>IJCAI</em>, 3097–3103. (<a
href="https://doi.org/10.24963/ijcai.2021/426">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Although Label Distribution Learning (LDL) has found wide applications in varieties of classification problems, it may face the challenge of objective mismatch -- LDL neglects the optimal label for the sake of learning the whole label distribution, which leads to performance deterioration. To improve classification performance and solve the objective mismatch, we propose a new LDL algorithm called LDL-HR. LDL-HR provides a new perspective of label distribution, \textit{i.e.}, a combination of the \textbf{highest label} and the \textbf{rest label description degrees}. It works as follows. First, we learn the highest label by fitting the degenerated label distribution and large margin. Second, we learn the rest label description degrees to exploit generalization. Theoretical analysis shows the generalization of LDL-HR. Besides, the experimental results on 18 real-world datasets validate the statistical superiority of our method. Keywords: Machine Learning: Multi-instance; Multi-label; Multi-view learning Machine Learning: Structured Prediction},
  archive   = {C_IJCAI},
  author    = {Jing Wang and Xin Geng},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/426},
  pages     = {3097-3103},
  title     = {Learn the highest label and rest label description degrees},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-hop attention graph neural networks. <em>IJCAI</em>,
3089–3096. (<a href="https://doi.org/10.24963/ijcai.2021/425">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Self-attention mechanism in graph neural networks (GNNs) led to state-of-the-art performance on many graph representation learning tasks. Currently, at every layer, attention is computed between connected pairs of nodes and depends solely on the representation of the two nodes. However, such attention mechanism does not account for nodes that are not directly connected but provide important network context. Here we propose Multi-hop Attention Graph Neural Network (MAGNA), a principled way to incorporate multi-hop context information into every layer of attention computation. MAGNA diffuses the attention scores across the network, which increases the receptive field for every layer of the GNN. Unlike previous approaches, MAGNA uses a diffusion prior on attention values, to efficiently account for all paths between the pair of disconnected nodes. We demonstrate in theory and experiments that MAGNA captures large-scale structural information in every layer, and has a low-pass effect that eliminates noisy high-frequency information from graph data. Experimental results on node classification as well as the knowledge graph completion benchmarks show that MAGNA achieves state-of-the-art results: MAGNA achieves up to 5.7\% relative error reduction over the previous state-of-the-art on Cora, Citeseer, and Pubmed. MAGNA also obtains the best performance on a large-scale Open Graph Benchmark dataset. On knowledge graph completion MAGNA advances state-of-the-art on WN18RR and FB15k-237 across four different performance metrics. Keywords: Machine Learning: Deep Learning Machine Learning: Learning Graphical Models Machine Learning: Relational Learning},
  archive   = {C_IJCAI},
  author    = {Guangtao Wang and Rex Ying and Jing Huang and Jure Leskovec},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/425},
  pages     = {3089-3096},
  title     = {Multi-hop attention graph neural networks},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Probabilistic sufficient explanations. <em>IJCAI</em>,
3082–3088. (<a href="https://doi.org/10.24963/ijcai.2021/424">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Understanding the behavior of learned classifiers is an important task, and various black-box explanations, logical reasoning approaches, and model-specific methods have been proposed. In this paper, we introduce probabilistic sufficient explanations, which formulate explaining an instance of classification as choosing the &quot;simplest&quot; subset of features such that only observing those features is &quot;sufficient&quot; to explain the classification. That is, sufficient to give us strong probabilistic guarantees that the model will behave similarly when all features are observed under the data distribution. In addition, we leverage tractable probabilistic reasoning tools such as probabilistic circuits and expected predictions to design a scalable algorithm for finding the desired explanations while keeping the guarantees intact. Our experiments demonstrate the effectiveness of our algorithm in finding sufficient explanations, and showcase its advantages compared to Anchors and logical explanations. Keywords: Machine Learning: Explainable/Interpretable Machine Learning AI Ethics, Trust, Fairness: Explainability Uncertainty in AI: Exact Probabilistic Inference},
  archive   = {C_IJCAI},
  author    = {Eric Wang and Pasha Khosravi and Guy Van den Broeck},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/424},
  pages     = {3082-3088},
  title     = {Probabilistic sufficient explanations},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning from complementary labels via partial-output
consistency regularization. <em>IJCAI</em>, 3075–3081. (<a
href="https://doi.org/10.24963/ijcai.2021/423">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In complementary-label learning (CLL), a multi-class classifier is learned from training instances each associated with complementary labels, which specify the classes that the instance does not belong to. Previous studies focus on unbiased risk estimator or surrogate loss while neglect the importance of regularization in training phase. In this paper, we give the first attempt to leverage regularization techniques for CLL. By decoupling a label vector into complementary labels and partial unknown labels, we simultaneously inhibit the outputs of complementary labels with a complementary loss and penalize the sensitivity of the classifier on the partial outputs of these unknown classes by consistency regularization. Then we unify the complementary loss and consistency loss together by a specially designed dynamic weighting factor. We conduct a series of experiments showing that the proposed method achieves highly competitive performance in CLL. Keywords: Machine Learning: Classification Machine Learning: Weakly Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Deng-Bao Wang and Lei Feng and Min-Ling Zhang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/423},
  pages     = {3075-3081},
  title     = {Learning from complementary labels via partial-output consistency regularization},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sensitivity direction learning with neural networks using
domain knowledge as soft shape constraints. <em>IJCAI</em>, 3067–3074.
(<a href="https://doi.org/10.24963/ijcai.2021/422">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {If domain knowledge can be integrated as an appropriate constraint, it is highly possible that the generalization performance of a neural network model can be improved. We propose Sensitivity Direction Learning (SDL) for learning about the neural network model with user-specified relationships (e.g., monotonicity, convexity) between each input feature and the output of the model by imposing soft shape constraints which represent domain knowledge. To impose soft shape constraints, SDL uses a novel penalty function, Sensitivity Direction Error (SDE) function, which returns the squared error between coefficients of the approximation curve for each Individual Conditional Expectation plot and coefficient constraints which represent domain knowledge. The effectiveness of our concept was verified by simple experiments. Similar to those such as L2 regularization and dropout, SDL and SDE can be used without changing neural network architecture. We believe our algorithm can be a strong candidate for neural network users who want to incorporate domain knowledge. Keywords: Machine Learning: Explainable/Interpretable Machine Learning Constraints and SAT: Constraints and Data Mining; Constraints and Machine Learning},
  archive   = {C_IJCAI},
  author    = {Kazuyuki Wakasugi},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/422},
  pages     = {3067-3074},
  title     = {Sensitivity direction learning with neural networks using domain knowledge as soft shape constraints},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Compositional neural logic programming. <em>IJCAI</em>,
3059–3066. (<a href="https://doi.org/10.24963/ijcai.2021/421">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper introduces Compositional Neural Logic Programming (CNLP), a framework that integrates neural networks and logic programming for symbolic and sub-symbolic reasoning. We adopt the idea of compositional neural networks to represent first-order logic predicates and rules. A voting backward-forward chaining algorithm is proposed for inference with both symbolic and sub-symbolic variables in an argument-retrieval style. The framework is highly flexible in that it can be constructed incrementally with new knowledge, and it also supports batch reasoning in certain cases. In the experiments, we demonstrate the advantages of CNLP in discriminative tasks and generative tasks. Keywords: Machine Learning: Neuro-Symbolic Methods Knowledge Representation and Reasoning: Leveraging Knowledge and Learning},
  archive   = {C_IJCAI},
  author    = {Son N. Tran},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/421},
  pages     = {3059-3066},
  title     = {Compositional neural logic programming},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dual active learning for both model and data selection.
<em>IJCAI</em>, 3052–3058. (<a
href="https://doi.org/10.24963/ijcai.2021/420">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {To learn an effective model with less training examples, existing active learning methods typically assume that there is a given target model, and try to fit it by selecting the most informative examples. However, it is less likely to determine the best target model in prior, and thus may get suboptimal performance even if the data is perfectly selected. To tackle with this practical challenge, this paper proposes a novel framework of dual active learning (DUAL) to simultaneously perform model search and data selection. Specifically, an effective method with truncated importance sampling is proposed for Combined Algorithm Selection and Hyperparameter optimization (CASH), which mitigates the model evaluation bias on the labeled data. Further, we propose an active query strategy to label the most valuable examples. The strategy on one hand favors discriminative data to help CASH search the best model, and on the other hand prefers informative examples to accelerate the convergence of winner models. Extensive experiments are conducted on 12 openML datasets. The results demonstrate the proposed method can effectively learn a superior model with less labeled examples. Keywords: Machine Learning: Active Learning Machine Learning: Weakly Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Ying-Peng Tang and Sheng-Jun Huang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/420},
  pages     = {3052-3058},
  title     = {Dual active learning for both model and data selection},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Self-supervised network evolution for few-shot
classification. <em>IJCAI</em>, 3045–3051. (<a
href="https://doi.org/10.24963/ijcai.2021/419">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Few-shot classification aims to recognize new classes by learning reliable models from very few available samples. It could be very challenging when there is no intersection between the alreadyknown classes (base set) and the novel set (new classes). To alleviate this problem, we propose to evolve the network (for the base set) via label propagation and self-supervision to shrink the distribution difference between the base set and the novel set. Our network evolution approach transfers the latent distribution from the already-known classes to the unknown (novel) classes by: (a) label propagation of the novel/new classes (novel set); and (b) design of dual-task to exploit a discriminative representation to effectively diminish the overfitting on the base set and enhance the generalization ability on the novel set. We conduct comprehensive experiments to examine our network evolution approach against numerous state-of-the-art ones, especially in a higher way setup and cross-dataset scenarios. Notably, our approach outperforms the second best state-of-the-art method by a large margin of 3.25\% for one-shot evaluation over miniImageNet. Keywords: Machine Learning: Classification Machine Learning: Deep Learning Data Mining: Classification},
  archive   = {C_IJCAI},
  author    = {Xuwen Tang and Zhu Teng and Baopeng Zhang and Jianping Fan},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/419},
  pages     = {3045-3051},
  title     = {Self-supervised network evolution for few-shot classification},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hyperspectral band selection via spatial-spectral weighted
region-wise multiple graph fusion-based spectral clustering.
<em>IJCAI</em>, 3038–3044. (<a
href="https://doi.org/10.24963/ijcai.2021/418">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we propose a hyperspectral band selection method via spatial-spectral weighted region-wise multiple graph fusion-based spectral clustering, referred to as RMGF briefly. Considering that different objects have different reflection characteristics, we use a superpixel segmentation algorithm to segment the first principal component of original hyperspectral image cube into homogeneous regions. For each superpixel, we construct a corresponding similarity graph to reflect the similarity between band pairs. Then, a multiple graph diffusion strategy with theoretical convergence guarantee is designed to learn a unified graph for partitioning the whole hyperspectral cube into several subcubes via spectral clustering. During the graph diffusion process, the spatial and spectral information of each superpixel are embedded to make spatial/spectral similar superpixels contribute more to each other. Finally, the band containing minimum noise in each subcube is selected to represent the whole subcube. Extensive experiments are conducted on three public datasets to validate the superiority of the proposed method when compared with other state-of-the-art ones. Keywords: Machine Learning: Unsupervised Learning Machine Learning Applications: Applications of Unsupervised Learning},
  archive   = {C_IJCAI},
  author    = {Chang Tang and Xinwang Liu and En Zhu and Lizhe Wang and Albert Zomaya},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/418},
  pages     = {3038-3044},
  title     = {Hyperspectral band selection via spatial-spectral weighted region-wise multiple graph fusion-based spectral clustering},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Predicting traffic congestion evolution: A deep meta
learning approach. <em>IJCAI</em>, 3031–3037. (<a
href="https://doi.org/10.24963/ijcai.2021/417">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Many efforts are devoted to predicting congestion evolution using propagation patterns that are mined from historical traffic data. However, the prediction quality is limited to the intrinsic properties that are present in the mined patterns. In addition, these mined patterns frequently fail to sufficiently capture many realistic characteristics of true congestion evolution (e.g., asymmetric transitivity, local proximity). In this paper, we propose a representation learning framework to characterize and predict congestion evolution between any pair of road segments (connected via single or multiple paths). Specifically, we build dynamic attributed networks (DAN) to incorporate both dynamic and static impact factors while preserving dynamic topological structures. We propose a Deep Meta Learning Model (DMLM) for learning representations of road segments which support accurate prediction of congestion evolution. DMLM relies on matrix factorization techniques and meta-LSTM modules to exploit temporal correlations at multiple scales, and employ meta-Attention modules to merge heterogeneous features while learning the time-varying impacts of both dynamic and static features. Compared to all state-of-the-art methods, our framework achieves significantly better prediction performance on two congestion evolution behaviors (propagation and decay) when evaluated using real-world dataset. Keywords: Machine Learning: Deep Learning Multidisciplinary Topics and Applications: Transportation Machine Learning Applications: Applications of Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Yidan Sun and Guiyuan Jiang and Siew Kei Lam and Peilan He},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/417},
  pages     = {3031-3037},
  title     = {Predicting traffic congestion evolution: A deep meta learning approach},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards reducing biases in combining multiple experts
online. <em>IJCAI</em>, 3024–3030. (<a
href="https://doi.org/10.24963/ijcai.2021/416">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In many real life situations, including job and loan applications, gatekeepers must make justified and fair real-time decisions about a person’s fitness for a particular opportunity. In this paper, we aim to accomplish approximate group fairness in an online stochastic decision-making process, where the fairness metric we consider is equalized odds. Our work follows from the classical learning-from-experts scheme, assuming a finite set of classifiers (human experts, rules, options, etc) that cannot be modified. We run separate instances of the algorithm for each label class as well as sensitive groups, where the probability of choosing each instance is optimized for both fairness and regret. Our theoretical results show that approximately equalized odds can be achieved without sacrificing much regret. We also demonstrate the performance of the algorithm on real data sets commonly used by the fairness community. Keywords: Machine Learning: Online Learning AI Ethics, Trust, Fairness: Fairness},
  archive   = {C_IJCAI},
  author    = {Yi Sun and Iván Ramírez Díaz and Alfredo Cuesta Infante and Kalyan Veeramachaneni},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/416},
  pages     = {3024-3030},
  title     = {Towards reducing biases in combining multiple experts online},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MFNP: A meta-optimized model for few-shot next POI
recommendation. <em>IJCAI</em>, 3017–3023. (<a
href="https://doi.org/10.24963/ijcai.2021/415">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Next Point-of-Interest (POI) recommendation is of great value for location-based services. Existing solutions mainly rely on extensive observed data and are brittle to users with few interactions. Unfortunately, the problem of few-shot next POI recommendation has not been well studied yet. In this paper, we propose a novel meta-optimized model MFNP, which can rapidly adapt to users with few check-in records. Towards the cold-start problem, it seamlessly integrates carefully designed user-specific and region-specific tasks in meta-learning, such that region-aware user preferences can be captured via a rational fusion of region-independent personal preferences and region-dependent crowd preferences. In modelling region-dependent crowd preferences, a cluster-based adaptive network is adopted to capture shared preferences from similar users for knowledge transfer. Experimental results on two real-world datasets show that our model outperforms the state-of-the-art methods on next POI recommendation for cold-start users. Keywords: Machine Learning: Recommender Systems Data Mining: Mining Spatial, Temporal Data Humans and AI: Personalization and User Modeling},
  archive   = {C_IJCAI},
  author    = {Huimin Sun and Jiajie Xu and Kai Zheng and Pengpeng Zhao and Pingfu Chao and Xiaofang Zhou},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/415},
  pages     = {3017-3023},
  title     = {MFNP: A meta-optimized model for few-shot next POI recommendation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). TE-ESN: Time encoding echo state network for prediction
based on irregularly sampled time series data. <em>IJCAI</em>,
3010–3016. (<a href="https://doi.org/10.24963/ijcai.2021/414">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Prediction based on Irregularly Sampled Time Series (ISTS) is of wide concern in real-world applications. For more accurate prediction, methods had better grasp more data characteristics. Different from ordinary time series, ISTS is characterized by irregular time intervals of intra-series and different sampling rates of inter-series. However, existing methods have suboptimal predictions due to artificially introducing new dependencies in a time series and biasedly learning relations among time series when modeling these two characteristics. In this work, we propose a novel Time Encoding (TE) mechanism. TE can embed the time information as time vectors in the complex domain. It has the properties of absolute distance and relative distance under different sampling rates, which helps to represent two irregularities. Meanwhile, we create a new model named Time Encoding Echo State Network (TE-ESN). It is the first ESNs-based model that can process ISTS data. Besides, TE-ESN incorporates long short-term memories and series fusion to grasp horizontal and vertical relations. Experiments on one chaos system and three real-world datasets show that TE-ESN performs better than all baselines and has better reservoir property. Keywords: Machine Learning: Time-series; Data Streams Machine Learning Applications: Bio/Medicine Data Mining: Classification},
  archive   = {C_IJCAI},
  author    = {Chenxi Sun and Shenda Hong and Moxian Song and Yen-Hsiu Chou and Yongyue Sun and Derun Cai and Hongyan Li},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/414},
  pages     = {3010-3016},
  title     = {TE-ESN: Time encoding echo state network for prediction based on irregularly sampled time series data},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Neural architecture search of SPD manifold networks.
<em>IJCAI</em>, 3002–3009. (<a
href="https://doi.org/10.24963/ijcai.2021/413">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we propose a new neural architecture search (NAS) problem of Symmetric Positive Definite (SPD) manifold networks, aiming to automate the design of SPD neural architectures. To address this problem, we first introduce a geometrically rich and diverse SPD neural architecture search space for an efficient SPD cell design. Further, we model our new NAS problem with a one-shot training process of a single supernet. Based on the supernet modeling, we exploit a differentiable NAS algorithm on our relaxed continuous search space for SPD neural architecture search. Statistical evaluation of our method on drone, action, and emotion recognition tasks mostly provides better results than the state-of-the-art SPD networks and traditional NAS algorithms. Empirical results show that our algorithm excels in discovering better performing SPD network design and provides models that are more than three times lighter than searched by the state-of-the-art NAS algorithms. Keywords: Machine Learning: Classification Machine Learning: Deep Learning Machine Learning Applications: Networks},
  archive   = {C_IJCAI},
  author    = {Rhea Sanjay Sukthanker and Zhiwu Huang and Suryansh Kumar and Erik Goron Endsjo and Yan Wu and Luc Van Gool},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/413},
  pages     = {3002-3009},
  title     = {Neural architecture search of SPD manifold networks},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Positive-unlabeled learning from imbalanced data.
<em>IJCAI</em>, 2995–3001. (<a
href="https://doi.org/10.24963/ijcai.2021/412">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Positive-unlabeled (PU) learning deals with the binary classification problem when only positive (P) and unlabeled (U) data are available, without negative (N) data. Existing PU methods perform well on the balanced dataset. However, in real applications such as financial fraud detection or medical diagnosis, data are always imbalanced. It remains unclear whether existing PU methods can perform well on imbalanced data. In this paper, we explore this problem and propose a general learning objective for PU learning targeting specially at imbalanced data. By this general learning objective, state-of-the-art PU methods based on optimizing a consistent risk can be adapted to conquer the imbalance. We theoretically show that in expectation, optimizing our learning objective is equivalent to learning a classifier on the oversampled balanced data with both P and N data available, and further provide an estimation error bound. Finally, experimental results validate the effectiveness of our proposal compared to state-of-the-art PU methods. Keywords: Machine Learning: Semi-Supervised Learning Machine Learning: Weakly Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Guangxin Su and Weitong Chen and Miao Xu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/412},
  pages     = {2995-3001},
  title     = {Positive-unlabeled learning from imbalanced data},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Online risk-averse submodular maximization. <em>IJCAI</em>,
2988–2994. (<a href="https://doi.org/10.24963/ijcai.2021/411">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present a polynomial-time online algorithm for maximizing the conditional value at risk (CVaR) of a monotone stochastic submodular function. Given T i.i.d. samples from an underlying distribution arriving online, our algorithm produces a sequence of solutions that converges to a (1−1/e)-approximate solution with a convergence rate of O(T −1/4 ) for monotone continuous DR-submodular functions. Compared with previous offline algorithms, which require Ω(T) space, our online algorithm only requires O( √ T) space. We extend our on- line algorithm to portfolio optimization for mono- tone submodular set functions under a matroid constraint. Experiments conducted on real-world datasets demonstrate that our algorithm can rapidly achieve CVaRs that are comparable to those obtained by existing offline algorithms. Keywords: Machine Learning: Online Learning Heuristic Search and Game Playing: Combinatorial Search and Optimisation},
  archive   = {C_IJCAI},
  author    = {Tasuku Soma and Yuichi Yoshida},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/411},
  pages     = {2988-2994},
  title     = {Online risk-averse submodular maximization},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Unsupervised progressive learning and the STAM architecture.
<em>IJCAI</em>, 2979–2987. (<a
href="https://doi.org/10.24963/ijcai.2021/410">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We first pose the Unsupervised Progressive Learning (UPL) problem: an online representation learning problem in which the learner observes a non-stationary and unlabeled data stream, learning a growing number of features that persist over time even though the data is not stored or replayed. To solve the UPL problem we propose the Self-Taught Associative Memory (STAM) architecture. Layered hierarchies of STAM modules learn based on a combination of online clustering, novelty detection, forgetting outliers, and storing only prototypical features rather than specific examples. We evaluate STAM representations using clustering and classification tasks. While there are no existing learning scenarios that are directly comparable to UPL, we compare the STAM architecture with two recent continual learning models, Memory Aware Synapses (MAS) and Gradient Episodic Memories (GEM), after adapting them in the UPL setting. Keywords: Machine Learning: Incremental Learning Machine Learning: Online Learning Machine Learning: Unsupervised Learning},
  archive   = {C_IJCAI},
  author    = {James Smith and Cameron Taylor and Seth Baer and Constantine Dovrolis},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/410},
  pages     = {2979-2987},
  title     = {Unsupervised progressive learning and the STAM architecture},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Interpretable compositional convolutional neural networks.
<em>IJCAI</em>, 2971–2978. (<a
href="https://doi.org/10.24963/ijcai.2021/409">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper proposes a method to modify a traditional convolutional neural network (CNN) into an interpretable compositional CNN, in order to learn filters that encode meaningful visual patterns in intermediate convolutional layers. In a compositional CNN, each filter is supposed to consistently represent a specific compositional object part or image region with a clear meaning. The compositional CNN learns from image labels for classification without any annotations of parts or regions for supervision. Our method can be broadly applied to different types of CNNs. Experiments have demonstrated the effectiveness of our method. The code will be released when the paper is accepted. Keywords: Machine Learning: Explainable/Interpretable Machine Learning AI Ethics, Trust, Fairness: Explainability},
  archive   = {C_IJCAI},
  author    = {Wen Shen and Zhihua Wei and Shikun Huang and Binbin Zhang and Jiaqi Fan and Ping Zhao and Quanshi Zhang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/409},
  pages     = {2971-2978},
  title     = {Interpretable compositional convolutional neural networks},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Regularizing variational autoencoder with diversity and
uncertainty awareness. <em>IJCAI</em>, 2964–2970. (<a
href="https://doi.org/10.24963/ijcai.2021/408">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As one of the most popular generative models, Variational Autoencoder (VAE) approximates the posterior of latent variables based on amortized variational inference. However, when the decoder network is sufficiently expressive, VAE may lead to posterior collapse; that is, uninformative latent representations may be learned. To this end, in this paper, we propose an alternative model, DU-VAE, for learning a more Diverse and less Uncertain latent space, and thus the representation can be learned in a meaningful and compact manner. Specifically, we first theoretically demonstrate that it will result in better latent space with high diversity and low uncertainty awareness by controlling the distribution of posterior’s parameters across the whole data accordingly. Then, without the introduction of new loss terms or modifying training strategies, we propose to exploit Dropout on the variances and Batch-Normalization on the means simultaneously to regularize their distributions implicitly. Furthermore, to evaluate the generalization effect, we also exploit DU-VAE for inverse autoregressive flow based-VAE (VAE-IAF) empirically. Finally, extensive experiments on three benchmark datasets clearly show that our approach can outperform state-of-the-art baselines on both likelihood estimation and underlying classification tasks. Keywords: Machine Learning: Bayesian Learning Machine Learning: Probabilistic Machine Learning Machine Learning: Unsupervised Learning},
  archive   = {C_IJCAI},
  author    = {Dazhong Shen and Chuan Qin and Chao Wang and Hengshu Zhu and Enhong Chen and Hui Xiong},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/408},
  pages     = {2964-2970},
  title     = {Regularizing variational autoencoder with diversity and uncertainty awareness},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards robust model reuse in the presence of latent
domains. <em>IJCAI</em>, 2957–2963. (<a
href="https://doi.org/10.24963/ijcai.2021/407">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Model reuse tries to adapt well pre-trained models to a new target task, without access of raw data. It attracts much attention since it reduces the learning resources. Previous model reuse studies typically operate in a single-domain scenario, i.e., the target samples arise from one single domain. However, in practice the target samples often arise from multiple latent or unknown domains, e.g., the images for cars may arise from latent domains such as photo, line drawing, cartoon, etc. The methods based on single-domain may no longer be feasible for multiple latent domains and may sometimes even lead to performance degeneration. To address the above issue, in this paper we propose the MRL (Model Reuse for multiple Latent domains) method. Both domain characteristics and pre-trained models are considered for the exploration of instances in the target task. Theoretically, the overall considerations are packed in a bi-level optimization framework with a reliable generalization. Moreover, through an ensemble of multiple models, the model robustness is improved with a theoretical guarantee. Empirical results on diverse real-world data sets clearly validate the effectiveness of proposed algorithms. Keywords: Machine Learning: Transfer, Adaptation, Multi-task Learning Machine Learning: Semi-Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Jie-Jing Shao and Zhanzhan Cheng and Yu-Feng Li and Shiliang Pu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/407},
  pages     = {2957-2963},
  title     = {Towards robust model reuse in the presence of latent domains},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Don’t do what doesn’t matter: Intrinsic motivation with
action usefulness. <em>IJCAI</em>, 2950–2956. (<a
href="https://doi.org/10.24963/ijcai.2021/406">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Sparse rewards are double-edged training signals in reinforcement learning: easy to design but hard to optimize. Intrinsic motivation guidances have thus been developed toward alleviating the resulting exploration problem. They usually incentivize agents to look for new states through novelty signals. Yet, such methods encourage exhaustive exploration of the state space rather than focusing on the environment&#39;s salient interaction opportunities. We propose a new exploration method, called Don&#39;t Do What Doesn&#39;t Matter (DoWhaM), shifting the emphasis from state novelty to state with relevant actions. While most actions consistently change the state when used, e.g. moving the agent, some actions are only effective in specific states, e.g., opening a door, grabbing an object. DoWhaM detects and rewards actions that seldom affect the environment. We evaluate DoWhaM on the procedurally-generated environment MiniGrid against state-of-the-art methods. Experiments consistently show that DoWhaM greatly reduces sample complexity, installing the new state-of-the-art in MiniGrid. Keywords: Machine Learning: Reinforcement Learning Machine Learning: Deep Reinforcement Learning},
  archive   = {C_IJCAI},
  author    = {Mathieu Seurin and Florian Strub and Philippe Preux and Olivier Pietquin},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/406},
  pages     = {2950-2956},
  title     = {Don’t do what doesn’t matter: Intrinsic motivation with action usefulness},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Physics-aware spatiotemporal modules with auxiliary tasks
for meta-learning. <em>IJCAI</em>, 2943–2949. (<a
href="https://doi.org/10.24963/ijcai.2021/405">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Modeling the dynamics of real-world physical systems is critical for spatiotemporal prediction tasks, but challenging when data is limited. The scarcity of real-world data and the difficulty in reproducing the data distribution hinder directly applying meta-learning techniques. Although the knowledge of governing partial differential equations (PDE) of the data can be helpful for the fast adaptation to few observations, it is mostly infeasible to exactly find the equation for observations in real-world physical systems. In this work, we propose a framework, physics-aware meta-learning with auxiliary tasks, whose spatial modules incorporate PDE-independent knowledge and temporal modules utilize the generalized features from the spatial modules to be adapted to the limited data, respectively. The framework is inspired by a local conservation law expressed mathematically as a continuity equation and does not require the exact form of governing equation to model the spatiotemporal observations. The proposed method mitigates the need for a large number of real-world tasks for meta-learning by leveraging spatial information in simulated data to meta-initialize the spatial modules. We apply the proposed framework to both synthetic and real-world spatiotemporal prediction tasks and demonstrate its superior performance with limited observations. Keywords: Machine Learning: Deep Learning Machine Learning: Transfer, Adaptation, Multi-task Learning Multidisciplinary Topics and Applications: Natural Sciences},
  archive   = {C_IJCAI},
  author    = {Sungyong Seo and Chuizheng Meng and Sirisha Rambhatla and Yan Liu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/405},
  pages     = {2943-2949},
  title     = {Physics-aware spatiotemporal modules with auxiliary tasks for meta-learning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Stochastic shortest path with adversarially changing costs.
<em>IJCAI</em>, 2936–2942. (<a
href="https://doi.org/10.24963/ijcai.2021/404">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Stochastic shortest path (SSP) is a well-known problem in planning and control, in which an agent has to reach a goal state in minimum total expected cost. In this paper we present the adversarial SSP model that also accounts for adversarial changes in the costs over time, while the underlying transition function remains unchanged. Formally, an agent interacts with an SSP environment for K episodes, the cost function changes arbitrarily between episodes, and the transitions are unknown to the agent. We develop the first algorithms for adversarial SSPs and prove high probability regret bounds of square-root K assuming all costs are strictly positive, and sub-linear regret in the general case. We are the first to consider this natural setting of adversarial SSP and obtain sub-linear regret for it. Keywords: Machine Learning: Online Learning Machine Learning: Reinforcement Learning},
  archive   = {C_IJCAI},
  author    = {Aviv Rosenberg and Yishay Mansour},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/404},
  pages     = {2936-2942},
  title     = {Stochastic shortest path with adversarially changing costs},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exact acceleration of k-means++ and k-means||.
<em>IJCAI</em>, 2928–2935. (<a
href="https://doi.org/10.24963/ijcai.2021/403">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {K-Means++ and its distributed variant K-Means|| have become de facto tools for selecting the initial seeds of K-means. While alternatives have been developed, the effectiveness, ease of implementation, and theoretical grounding of the K-means++ and || methods have made them difficult to &quot;best&quot; from a holistic perspective. We focus on using triangle inequality based pruning methods to accelerate both of these algorithms to yield comparable or better run-time without sacrificing any of the benefits of these approaches. For both algorithms we are able to reduce distance computations by over 500×. For K-means++ this results in up to a 17×speedup in run-time and a551×speedup for K-means||. We achieve this with simple, but carefully chosen, modifications to known techniques which makes it easy to integrate our approach into existing implementations of these algorithms. Keywords: Machine Learning: Clustering Machine Learning Applications: Big data; Scalability Data Mining: Clustering},
  archive   = {C_IJCAI},
  author    = {Edward Raff},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/403},
  pages     = {2928-2935},
  title     = {Exact acceleration of K-means++ and K-means||},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Source-free domain adaptation via avatar prototype
generation and adaptation. <em>IJCAI</em>, 2921–2927. (<a
href="https://doi.org/10.24963/ijcai.2021/402">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study a practical domain adaptation task, called source-free unsupervised domain adaptation (UDA) problem, in which we cannot access source domain data due to data privacy issues but only a pre-trained source model and unlabeled target data are available. This task, however, is very difficult due to one key challenge: the lack of source data and target domain labels makes model adaptation very challenging. To address this, we propose to mine the hidden knowledge in the source model and exploit it to generate source avatar prototypes (i.e. representative features for each source class) as well as target pseudo labels for domain alignment. To this end, we propose a Contrastive Prototype Generation and Adaptation (CPGA) method. Specifically, CPGA consists of two stages: (1) prototype generation: by exploring the classification boundary information of the source model, we train a prototype generator to generate avatar prototypes via contrastive learning. (2) prototype adaptation: based on the generated source prototypes and target pseudo labels, we develop a new robust contrastive prototype adaptation strategy to align each pseudo-labeled target data to the corresponding source prototypes. Extensive experiments on three UDA benchmark datasets demonstrate the effectiveness and superiority of the proposed method. Keywords: Machine Learning: Classification Machine Learning: Transfer, Adaptation, Multi-task Learning},
  archive   = {C_IJCAI},
  author    = {Zhen Qiu and Yifan Zhang and Hongbin Lin and Shuaicheng Niu and Yanxia Liu and Qing Du and Mingkui Tan},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/402},
  pages     = {2921-2927},
  title     = {Source-free domain adaptation via avatar prototype generation and adaptation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-agent reinforcement learning for automated
peer-to-peer energy trading in double-side auction market.
<em>IJCAI</em>, 2913–2920. (<a
href="https://doi.org/10.24963/ijcai.2021/401">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With increasing prosumers employed with distributed energy resources (DER), advanced energy management has become increasingly important. To this end, integrating demand-side DER into electricity market is a trend for future smart grids. The double-side auction (DA) market is viewed as a promising peer-to-peer (P2P) energy trading mechanism that enables interactions among prosumers in a distributed manner. To achieve the maximum profit in a dynamic electricity market, prosumers act as price makers to simultaneously optimize their operations and trading strategies. However, the traditional DA market is difficult to be explicitly modelled due to its complex clearing algorithm and the stochastic bidding behaviors of the participants. For this reason, in this paper we model this task as a multi-agent reinforcement learning (MARL) problem and propose an algorithm called DA-MADDPG that is modified based on MADDPG by abstracting the other agents’ observations and actions through the DA market public information for each agent’s critic. The experiments show that 1) prosumers obtain more economic benefits in P2P energy trading w.r.t. the conventional electricity market independently trading with the utility company; and 2) DA-MADDPG performs better than the traditional Zero Intelligence (ZI) strategy and the other MARL algorithms, e.g., IQL, IDDPG, IPPO and MADDPG. Keywords: Machine Learning: Deep Reinforcement Learning Machine Learning Applications: Applications of Reinforcement Learning},
  archive   = {C_IJCAI},
  author    = {Dawei Qiu and Jianhong Wang and Junkai Wang and Goran Strbac},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/401},
  pages     = {2913-2920},
  title     = {Multi-agent reinforcement learning for automated peer-to-peer energy trading in double-side auction market},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-version tensor completion for time-delayed
spatio-temporal data. <em>IJCAI</em>, 2906–2912. (<a
href="https://doi.org/10.24963/ijcai.2021/400">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Real-world spatio-temporal data is often incomplete or inaccurate due to various data loading delays. For example, a location-disease-time tensor of case counts can have multiple delayed updates of recent temporal slices for some locations or diseases. Recovering such missing or noisy (under-reported) elements of the input tensor can be viewed as a generalized tensor completion problem. Existing tensor completion methods usually assume that i) missing elements are randomly distributed and ii) noise for each tensor element is i.i.d. zero-mean. Both assumptions can be violated for spatio-temporal tensor data. We often observe multiple versions of the input tensor with different under-reporting noise levels. The amount of noise can be time- or location-dependent as more updates are progressively introduced to the tensor. We model such dynamic data as a multi-version tensor with an extra tensor mode capturing the data updates. We propose a low-rank tensor model to predict the updates over time. We demonstrate that our method can accurately predict the ground-truth values of many real-world tensors. We obtain up to 27.2\% lower root mean-squared-error compared to the best baseline method. Finally, we extend our method to track the tensor data over time, leading to significant computational savings. Keywords: Machine Learning: Time-series; Data Streams Machine Learning: Unsupervised Learning Machine Learning Applications: Applications of Unsupervised Learning},
  archive   = {C_IJCAI},
  author    = {Cheng Qian and Nikos Kargas and Cao Xiao and Lucas Glass and Nicholas Sidiropoulos and Jimeng Sun},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/400},
  pages     = {2906-2912},
  title     = {Multi-version tensor completion for time-delayed spatio-temporal data},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Meta-reinforcement learning by tracking task
non-stationarity. <em>IJCAI</em>, 2899–2905. (<a
href="https://doi.org/10.24963/ijcai.2021/399">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Many real-world domains are subject to a structured non-stationarity which affects the agent&#39;s goals and the environmental dynamics. Meta-reinforcement learning (RL) has been shown successful for training agents that quickly adapt to related tasks. However, most of the existing meta-RL algorithms for non-stationary domains either make strong assumptions on the task generation process or require sampling from it at training time. In this paper, we propose a novel algorithm (TRIO) that optimizes for the future by explicitly tracking the task evolution through time. At training time, TRIO learns a variational module to quickly identify latent parameters from experience samples. This module is learned jointly with an optimal exploration policy that takes task uncertainty into account. At test time, TRIO tracks the evolution of the latent parameters online, hence reducing the uncertainty over future tasks and obtaining fast adaptation through the meta-learned policy. Unlike most existing methods, TRIO does not assume Markovian task-evolution processes, it does not require information about the non-stationarity at training time, and it captures complex changes undergoing in the environment. We evaluate our algorithm on different simulated problems and show it outperforms competitive baselines. Keywords: Machine Learning: Deep Reinforcement Learning Machine Learning: Reinforcement Learning Machine Learning: Transfer, Adaptation, Multi-task Learning},
  archive   = {C_IJCAI},
  author    = {Riccardo Poiani and Andrea Tirinzoni and Marcello Restelli},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/399},
  pages     = {2899-2905},
  title     = {Meta-reinforcement learning by tracking task non-stationarity},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning aggregation functions. <em>IJCAI</em>, 2892–2898.
(<a href="https://doi.org/10.24963/ijcai.2021/398">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Learning on sets is increasingly gaining attention in the machine learning community, due to its widespread applicability. Typically, representations over sets are computed by using fixed aggregation functions such as sum or maximum. However, recent results showed that universal function representation by sum- (or max-) decomposition requires either highly discontinuous (and thus poorly learnable) mappings, or a latent dimension equal to the maximum number of elements in the set. To mitigate this problem, we introduce LAF (Learning Aggregation Function), a learnable aggregator for sets of arbitrary cardinality. LAF can approximate several extensively used aggregators (such as average, sum, maximum) as well as more complex functions (e.g. variance and skewness). We report experiments on semi-synthetic and real data showing that LAF outperforms state-of-the-art sum- (max-) decomposition architectures such as DeepSets and library-based architectures like Principal Neighborhood Aggregation, and can be effectively combined with attention-based architectures. Keywords: Machine Learning: Deep Learning Machine Learning: Multi-instance; Multi-label; Multi-view learning Machine Learning: Relational Learning},
  archive   = {C_IJCAI},
  author    = {Giovanni Pellegrini and Alessandro Tibo and Paolo Frasconi and Andrea Passerini and Manfred Jaeger},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/398},
  pages     = {2892-2898},
  title     = {Learning aggregation functions},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Two birds with one stone: Series saliency for accurate and
interpretable multivariate time series forecasting. <em>IJCAI</em>,
2884–2891. (<a href="https://doi.org/10.24963/ijcai.2021/397">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {It is important yet challenging to perform accurate and interpretable time series forecasting. Though deep learning methods can boost forecasting accuracy, they often sacrifice interpretability. In this paper, we present a new scheme of series saliency to boost both accuracy and interpretability. By extracting series images from sliding windows of the time series, we design series saliency as a mixup strategy with a learnable mask between the series images and their perturbed versions. Series saliency is model agnostic and performs as an adaptive data augmentation method for training deep models. Moreover, by slightly changing the objective, we optimize series saliency to find a mask for interpretable forecasting in both feature and time dimensions. Experimental results on several real datasets demonstrate that series saliency is effective to produce accurate time-series forecasting results as well as generate temporal interpretations. Keywords: Machine Learning: Explainable/Interpretable Machine Learning Machine Learning: Time-series; Data Streams},
  archive   = {C_IJCAI},
  author    = {Qingyi Pan and Wenbo Hu and Ning Chen},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/397},
  pages     = {2884-2891},
  title     = {Two birds with one stone: Series saliency for accurate and interpretable multivariate time series forecasting},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Explaining deep neural network models with adversarial
gradient integration. <em>IJCAI</em>, 2876–2883. (<a
href="https://doi.org/10.24963/ijcai.2021/396">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep neural networks (DNNs) have became one of the most high performing tools in a broad range of machine learning areas. However, the multilayer non-linearity of the network architectures prevent us from gaining a better understanding of the models’ predictions. Gradient based attribution methods (e.g., Integrated Gradient (IG)) that decipher input features’ contribution to the prediction task have been shown to be highly effective yet requiring a reference input as the anchor for explaining model’s output. The performance of DNN model interpretation can be quite inconsistent with regard to the choice of references. Here we propose an Adversarial Gradient Integration (AGI) method that integrates the gradients from adversarial examples to the target example along the curve of steepest ascent to calculate the resulting contributions from all input features. Our method doesn’t rely on the choice of references, hence can avoid the ambiguity and inconsistency sourced from the reference selection. We demonstrate the performance of our AGI method and compare with competing methods in explaining image classification results. Code is available from https://github.com/pd90506/AGI. Keywords: Machine Learning: Adversarial Machine Learning Machine Learning: Explainable/Interpretable Machine Learning AI Ethics, Trust, Fairness: Explainability},
  archive   = {C_IJCAI},
  author    = {Deng Pan and Xin Li and Dongxiao Zhu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/396},
  pages     = {2876-2883},
  title     = {Explaining deep neural network models with adversarial gradient integration},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning embeddings from knowledge graphs with numeric edge
attributes. <em>IJCAI</em>, 2869–2875. (<a
href="https://doi.org/10.24963/ijcai.2021/395">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Numeric values associated to edges of a knowledge graph have been used to represent uncertainty, edge importance, and even out-of-band knowledge in a growing number of scenarios, ranging from genetic data to social networks. Nevertheless, traditional knowledge graph embedding models are not designed to capture such information, to the detriment of predictive power. We propose a novel method that injects numeric edge attributes into the scoring layer of a traditional knowledge graph embedding architecture. Experiments with publicly available numeric-enriched knowledge graphs show that our method outperforms traditional numeric-unaware baselines as well as the recent UKGE model. Keywords: Machine Learning: Relational Learning Natural Language Processing: Embeddings},
  archive   = {C_IJCAI},
  author    = {Sumit Pai and Luca Costabello},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/395},
  pages     = {2869-2875},
  title     = {Learning embeddings from knowledge graphs with numeric edge attributes},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). TIDOT: A teacher imitation learning approach for domain
adaptation with optimal transport. <em>IJCAI</em>, 2862–2868. (<a
href="https://doi.org/10.24963/ijcai.2021/394">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Using the principle of imitation learning and the theory of optimal transport we propose in this paper a novel model for unsupervised domain adaptation named Teacher Imitation Domain Adaptation with Optimal Transport (TIDOT). Our model includes two cooperative agents: a teacher and a student. The former agent is trained to be an expert on labeled data in the source domain, whilst the latter one aims to work with unlabeled data in the target domain. More specifically, optimal transport is applied to quantify the total of the distance between embedded distributions of the source and target data in the joint space, and the distance between predictive distributions of both agents, thus by minimizing this quantity TIDOT could mitigate not only the data shift but also the label shift. Comprehensive empirical studies show that TIDOT outperforms existing state-of-the-art performance on benchmark datasets. Keywords: Machine Learning: Transfer, Adaptation, Multi-task Learning},
  archive   = {C_IJCAI},
  author    = {Tuan Nguyen and Trung Le and Nhan Dam and Quan Hung Tran and Truyen Nguyen and Dinh Phung},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/394},
  pages     = {2862-2868},
  title     = {TIDOT: A teacher imitation learning approach for domain adaptation with optimal transport},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). What changed? Interpretable model comparison.
<em>IJCAI</em>, 2855–2861. (<a
href="https://doi.org/10.24963/ijcai.2021/393">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider the problem of distinguishing two machine learning (ML) models built for the same task in a human-interpretable way. As models can fail or succeed in different ways, classical accuracy metrics may mask crucial qualitative differences. This problem arises in a few contexts. In business applications with periodically retrained models, an updated model may deviate from its predecessor for some segments without a change in overall accuracy. In automated ML systems, where several ML pipelines are generated, the top pipelines have comparable accuracy but may have more subtle differences. We present a method for interpretable comparison of binary classification models by approximating them with Boolean decision rules. We introduce stabilization conditions that allow for the two rule sets to be more directly comparable. A method is proposed to compare two rule sets based on their statistical and semantic similarity by solving assignment problems and highlighting changes. An empirical evaluation on several benchmark datasets illustrates the insights that may be obtained and shows that artificially induced changes can be reliably recovered by our method. Keywords: Machine Learning: Explainable/Interpretable Machine Learning AI Ethics, Trust, Fairness: Explainability},
  archive   = {C_IJCAI},
  author    = {Rahul Nair and Massimiliano Mattetti and Elizabeth Daly and Dennis Wei and Oznur Alkan and Yunfeng Zhang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/393},
  pages     = {2855-2861},
  title     = {What changed? interpretable model comparison},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Accelerating neural architecture search via proxy data.
<em>IJCAI</em>, 2848–2854. (<a
href="https://doi.org/10.24963/ijcai.2021/392">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Despite the increasing interest in neural architecture search (NAS), the significant computational cost of NAS is a hindrance to researchers. Hence, we propose to reduce the cost of NAS using proxy data, i.e., a representative subset of the target data, without sacrificing search performance. Even though data selection has been used across various fields, our evaluation of existing selection methods for NAS algorithms offered by NAS-Bench-1shot1 reveals that they are not always appropriate for NAS and a new selection method is necessary. By analyzing proxy data constructed using various selection methods through data entropy, we propose a novel proxy data selection method tailored for NAS. To empirically demonstrate the effectiveness, we conduct thorough experiments across diverse datasets, search spaces, and NAS algorithms. Consequently, NAS algorithms with the proposed selection discover architectures that are competitive with those obtained using the entire dataset. It significantly reduces the search cost: executing DARTS with the proposed selection requires only 40 minutes on CIFAR-10 and 7.5 hours on ImageNet with a single GPU. Additionally, when the architecture searched on ImageNet using the proposed selection is inversely transferred to CIFAR-10, a state-of-the-art test error of 2.4\% is yielded. Our code is available at https://github.com/nabk89/NAS-with-Proxy-data. Keywords: Machine Learning: Deep Learning Machine Learning: Classification},
  archive   = {C_IJCAI},
  author    = {Byunggook Na and Jisoo Mok and Hyeokjun Choe and Sungroh Yoon},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/392},
  pages     = {2848-2854},
  title     = {Accelerating neural architecture search via proxy data},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fine-grained generalization analysis of structured output
prediction. <em>IJCAI</em>, 2841–2847. (<a
href="https://doi.org/10.24963/ijcai.2021/391">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In machine learning we often encounter structured output prediction problems (SOPPs), i.e. problems where the output space admits a rich internal structure. Application domains where SOPPs naturally occur include natural language processing, speech recognition, and computer vision. Typical SOPPs have an extremely large label set, which grows exponentially as a function of the size of the output. Existing generalization analysis implies generalization bounds with at least a square-root dependency on the cardinality d of the label set, which can be vacuous in practice. In this paper, we significantly improve the state of the art by developing novel high-probability bounds with a logarithmic dependency on d. Furthermore, we leverage the lens of algorithmic stability to develop generalization bounds in expectation without any dependency on d. Our results therefore build a solid theoretical foundation for learning in large-scale SOPPs. Furthermore, we extend our results to learning with weakly dependent data. Keywords: Machine Learning: Learning Theory Machine Learning: Structured Prediction},
  archive   = {C_IJCAI},
  author    = {Waleed Mustafa and Yunwen Lei and Antoine Ledent and Marius Kloft},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/391},
  pages     = {2841-2847},
  title     = {Fine-grained generalization analysis of structured output prediction},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Contrastive losses and solution caching for
predict-and-optimize. <em>IJCAI</em>, 2833–2840. (<a
href="https://doi.org/10.24963/ijcai.2021/390">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Many decision-making processes involve solving a combinatorial optimization problem with uncertain input that can be estimated from historic data. Recently, problems in this class have been successfully addressed via end-to-end learning approaches, which rely on solving one optimization problem for each training instance at every epoch. In this context, we provide two distinct contributions. First, we use a Noise Contrastive approach to motivate a family of surrogate loss functions, based on viewing non-optimal solutions as negative examples. Second, we address a major bottleneck of all predict-and-optimize approaches, i.e. the need to frequently recompute optimal solutions at training time. This is done via a solver-agnostic solution caching scheme, and by replacing optimization calls with a lookup in the solution cache. The method is formally based on an inner approximation of the feasible space and, combined with a cache lookup strategy, provides a controllable trade-off between training time and accuracy of the loss approximation. We empirically show that even a very slow growth rate is enough to match the quality of state-of-the-art methods, at a fraction of the computational cost. Keywords: Machine Learning: Neuro-Symbolic Methods Machine Learning: Structured Prediction Constraints and SAT: Constraint Optimization},
  archive   = {C_IJCAI},
  author    = {Maxime Mulamba and Jayanta Mandi and Michelangelo Diligenti and Michele Lombardi and Victor Bucarey and Tias Guns},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/390},
  pages     = {2833-2840},
  title     = {Contrastive losses and solution caching for predict-and-optimize},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Details (don’t) matter: Isolating cluster information in
deep embedded spaces. <em>IJCAI</em>, 2826–2832. (<a
href="https://doi.org/10.24963/ijcai.2021/389">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep clustering techniques combine representation learning with clustering objectives to improve their performance. Among existing deep clustering techniques, autoencoder-based methods are the most prevalent ones. While they achieve promising clustering results, they suffer from an inherent conflict between preserving details, as expressed by the reconstruction loss, and finding similar groups by ignoring details, as expressed by the clustering loss. This conflict leads to brittle training procedures, dependence on trade-off hyperparameters and less interpretable results. We propose our framework, ACe/DeC, that is compatible with Autoencoder Centroid based Deep Clustering methods and automatically learns a latent representation consisting of two separate spaces. The clustering space captures all cluster-specific information and the shared space explains general variation in the data. This separation resolves the above mentioned conflict and allows our method to learn both detailed reconstructions and cluster specific abstractions. We evaluate our framework with extensive experiments to show several benefits: (1) cluster performance – on various data sets we outperform relevant baselines; (2) no hyperparameter tuning – this improved performance is achieved without introducing new clustering specific hyperparameters; (3) interpretability – isolating the cluster specific information in a separate space is advantageous for data exploration and interpreting the clustering results; and (4) dimensionality of the embedded space – we automatically learn a low dimensional space for clustering. Our ACe/DeC framework isolates cluster information, increases stability and interpretability, while improving cluster performance. Keywords: Machine Learning: Deep Learning Machine Learning: Explainable/Interpretable Machine Learning Data Mining: Clustering},
  archive   = {C_IJCAI},
  author    = {Lukas Miklautz and Lena G. M. Bauer and Dominik Mautz and Sebastian Tschiatschek and Christian Böhm and Claudia Plant},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/389},
  pages     = {2826-2832},
  title     = {Details (Don&#39;t) matter: Isolating cluster information in deep embedded spaces},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Minimization of limit-average automata. <em>IJCAI</em>,
2819–2825. (<a href="https://doi.org/10.24963/ijcai.2021/388">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {LimAvg-automata are weighted automata over infinite words that aggregate weights along runs with the limit-average value function. In this paper, we study the minimization problem for (deterministic) LimAvg-automata. Our main contribution is an equivalence relation on words characterizing LimAvg-automata, i.e., the equivalence classes of this relation correspond to states of an equivalent LimAvg-automaton. In contrast to relations characterizing DFA, our relation depends not only on the function defined by the target automaton, but also on its structure. We show two applications of this relation. First, we present a minimization algorithm for LimAvg-automata, which returns a minimal LimAvg-automaton among those equivalent and structurally similar to the input one. Second, we present an extension of Angluin&#39;s L^*-algorithm with syntactic queries, which learns in polynomial time a LimAvg-automaton equivalent to the target one. Keywords: Machine Learning: Active Learning Agent-based and Multi-agent Systems: Formal Verification, Validation and Synthesis Multidisciplinary Topics and Applications: Validation and Verification},
  archive   = {C_IJCAI},
  author    = {Jakub Michaliszyn and Jan Otop},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/388},
  pages     = {2819-2825},
  title     = {Minimization of limit-average automata},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evaluating relaxations of logic for neural networks: A
comprehensive study. <em>IJCAI</em>, 2812–2818. (<a
href="https://doi.org/10.24963/ijcai.2021/387">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Symbolic knowledge can provide crucial inductive bias for training neural models, especially in low data regimes. A successful strategy for incorporating such knowledge involves relaxing logical statements into sub-differentiable losses for optimization. In this paper, we study the question of how best to relax logical expressions that represent labeled examples and knowledge about a problem; we focus on sub-differentiable t-norm relaxations of logic. We present theoretical and empirical criteria for characterizing which relaxation would perform best in various scenarios. In our theoretical study driven by the goal of preserving tautologies, the Lukasiewicz t-norm performs best. However, in our empirical analysis on the text chunking and digit recognition tasks, the product t-norm achieves best predictive performance. We analyze this apparent discrepancy, and conclude with a list of best practices for defining loss functions via logic. Keywords: Machine Learning: Neuro-Symbolic Methods Machine Learning: Knowledge Aided Learning Machine Learning: Deep Learning},
  archive   = {C_IJCAI},
  author    = {Mattia Medina Grespan and Ashim Gupta and Vivek Srikumar},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/387},
  pages     = {2812-2818},
  title     = {Evaluating relaxations of logic for neural networks: A comprehensive study},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Temporal and object quantification networks. <em>IJCAI</em>,
2804–2811. (<a href="https://doi.org/10.24963/ijcai.2021/386">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present Temporal and Object Quantification Networks (TOQ-Nets), a new class of neuro-symbolic networks with a structural bias that enables them to learn to recognize complex relational-temporal events. This is done by including reasoning layers that implement finite-domain quantification over objects and time. The structure allows them to generalize directly to input instances with varying numbers of objects in temporal sequences of varying lengths. We evaluate TOQ-Nets on input domains that require recognizing event-types in terms of complex temporal relational patterns. We demonstrate that TOQ-Nets can generalize from small amounts of data to scenarios containing more objects than were present during training and to temporal warpings of input sequences. Keywords: Machine Learning: Neuro-Symbolic Methods Machine Learning: Relational Learning},
  archive   = {C_IJCAI},
  author    = {Jiayuan Mao and Zhezheng Luo and Chuang Gan and Joshua B. Tenenbaum and Jiajun Wu and Leslie Pack Kaelbling and Tomer D. Ullman},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/386},
  pages     = {2804-2811},
  title     = {Temporal and object quantification networks},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Average-reward reinforcement learning with trust region
methods. <em>IJCAI</em>, 2797–2803. (<a
href="https://doi.org/10.24963/ijcai.2021/385">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Most of reinforcement learning algorithms optimize the discounted criterion which is beneficial to accelerate the convergence and reduce the variance of estimates. Although the discounted criterion is appropriate for certain tasks such as financial related problems, many engineering problems treat future rewards equally and prefer a long-run average criterion. In this paper, we study the reinforcement learning problem with the long-run average criterion. Firstly, we develop a unified trust region theory with discounted and average criteria. With the average criterion, a novel performance bound within the trust region is derived with the Perturbation Analysis (PA) theory. Secondly, we propose a practical algorithm named Average Policy Optimization (APO), which improves the value estimation with a novel technique named Average Value Constraint. To the best of our knowledge, our work is the first one to study the trust region approach with the average criterion and it complements the framework of reinforcement learning beyond the discounted criterion. Finally, experiments are conducted in the continuous control environment MuJoCo. In most tasks, APO performs better than the discounted PPO, which demonstrates the effectiveness of our approach. Keywords: Machine Learning: Deep Reinforcement Learning Machine Learning: Reinforcement Learning Uncertainty in AI: Markov Decision Processes},
  archive   = {C_IJCAI},
  author    = {Xiaoteng Ma and Xiaohang Tang and Li Xia and Jun Yang and Qianchuan Zhao},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/385},
  pages     = {2797-2803},
  title     = {Average-reward reinforcement learning with trust region methods},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-cause effect estimation with disentangled confounder
representation. <em>IJCAI</em>, 2790–2796. (<a
href="https://doi.org/10.24963/ijcai.2021/384">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {One fundamental problem in causality learning is to estimate the causal effects of one or multiple treatments (e.g., medicines in the prescription) on an important outcome (e.g., cure of a disease). One major challenge of causal effect estimation is the existence of unobserved confounders -- the unobserved variables that affect both the treatments and the outcome. Recent studies have shown that by modeling how instances are assigned with different treatments together, the patterns of unobserved confounders can be captured through their learned latent representations. However, the interpretability of the representations in these works is limited. In this paper, we focus on the multi-cause effect estimation problem from a new perspective by learning disentangled representations of confounders. The disentangled representations not only facilitate the treatment effect estimation but also strengthen the understanding of causality learning process. Experimental results on both synthetic and real-world datasets show the superiority of our proposed framework from different aspects. Keywords: Machine Learning: Explainable/Interpretable Machine Learning AI Ethics, Trust, Fairness: Trustable Learning},
  archive   = {C_IJCAI},
  author    = {Jing Ma and Ruocheng Guo and Aidong Zhang and Jundong Li},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/384},
  pages     = {2790-2796},
  title     = {Multi-cause effect estimation with disentangled confounder representation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hierarchical temporal multi-instance learning for
video-based student learning engagement assessment. <em>IJCAI</em>,
2782–2789. (<a href="https://doi.org/10.24963/ijcai.2021/383">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Video-based automatic assessment of a student&#39;s learning engagement on the fly can provide immense values for delivering personalized instructional services, a vehicle particularly important for massive online education. To train such an assessor, a major challenge lies in the collection of sufficient labels at the appropriate temporal granularity since a learner&#39;s engagement status may continuously change throughout a study session. Supplying labels at either frame or clip level incurs a high annotation cost. To overcome such a challenge, this paper proposes a novel hierarchical multiple instance learning (MIL) solution, which only requires labels anchored on full-length videos to learn to assess student engagement at an arbitrary temporal granularity and for an arbitrary duration in a study session. The hierarchical model mainly comprises a bottom module and a top module, respectively dedicated to learning the latent relationship between a clip and its constituent frames and that between a video and its constituent clips, with the constraints on the training stage that the average engagements of local clips is that of the video label. To verify the effectiveness of our method, we compare the performance of the proposed approach with that of several state-of-the-art peer solutions through extensive experiments. Keywords: Machine Learning: Multi-instance; Multi-label; Multi-view learning Computer Vision: Video: Events, Activities and Surveillance Humans and AI: Computer-Aided Education},
  archive   = {C_IJCAI},
  author    = {Jiayao Ma and Xinbo Jiang and Songhua Xu and Xueying Qin},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/383},
  pages     = {2782-2789},
  title     = {Hierarchical temporal multi-instance learning for video-based student learning engagement assessment},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Stochastic actor-executor-critic for image-to-image
translation. <em>IJCAI</em>, 2775–2781. (<a
href="https://doi.org/10.24963/ijcai.2021/382">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Training a model-free deep reinforcement learning model to solve image-to-image translation is difficult since it involves high-dimensional continuous state and action spaces. In this paper, we draw inspiration from the recent success of the maximum entropy reinforcement learning framework designed for challenging continuous control problems to develop stochastic policies over high dimensional continuous spaces including image representation, generation, and control simultaneously. Central to this method is the Stochastic Actor-Executor-Critic (SAEC) which is an off-policy actor-critic model with an additional executor to generate realistic images. Specifically, the actor focuses on the high-level representation and control policy by a stochastic latent action, as well as explicitly directs the executor to generate low-level actions to manipulate the state. Experiments on several image-to-image translation tasks have demonstrated the effectiveness and robustness of the proposed SAEC when facing high-dimensional continuous space problems. Keywords: Machine Learning: Deep Reinforcement Learning Machine Learning: Learning Generative Models Machine Learning Applications: Applications of Reinforcement Learning},
  archive   = {C_IJCAI},
  author    = {Ziwei Luo and Jing Hu and Xin Wang and Siwei Lyu and Bin Kong and Youbing Yin and Qi Song and Xi Wu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/382},
  pages     = {2775-2781},
  title     = {Stochastic actor-executor-critic for image-to-image translation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Graph entropy guided node embedding dimension selection for
graph neural networks. <em>IJCAI</em>, 2767–2774. (<a
href="https://doi.org/10.24963/ijcai.2021/381">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph representation learning has achieved great success in many areas, including e-commerce, chemistry, biology, etc. However, the fundamental problem of choosing the appropriate dimension of node embedding for a given graph still remains unsolved. The commonly used strategies for Node Embedding Dimension Selection (NEDS) based on grid search or empirical knowledge suffer from heavy computation and poor model performance. In this paper, we revisit NEDS from the perspective of minimum entropy principle. Subsequently, we propose a novel Minimum Graph Entropy (MinGE) algorithm for NEDS with graph data. To be specific, MinGE considers both feature entropy and structure entropy on graphs, which are carefully designed according to the characteristics of the rich information in them. The feature entropy, which assumes the embeddings of adjacent nodes to be more similar, connects node features and link topology on graphs. The structure entropy takes the normalized degree as basic unit to further measure the higher-order structure of graphs. Based on them, we design MinGE to directly calculate the ideal node embedding dimension for any graph. Finally, comprehensive experiments with popular Graph Neural Networks (GNNs) on benchmark datasets demonstrate the effectiveness and generalizability of our proposed MinGE. Keywords: Machine Learning: Dimensionality Reduction Data Mining: Mining Graphs, Semi Structured Data, Complex Data Data Mining: Theoretical Foundation of Data Mining},
  archive   = {C_IJCAI},
  author    = {Gongxu Luo and Jianxin Li and Hao Peng and Carl Yang and Lichao Sun and Philip S. Yu and Lifang He},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/381},
  pages     = {2767-2774},
  title     = {Graph entropy guided node embedding dimension selection for graph neural networks},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Transfer learning via optimal transportation for integrative
cancer patient stratification. <em>IJCAI</em>, 2760–2766. (<a
href="https://doi.org/10.24963/ijcai.2021/380">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Stratification of early-stage cancer patients for the prediction of clinical outcome is a challenging task since cancer is associated with various molecular aberrations. A single biomarker often cannot provide sufficient information to stratify early-stage patients effectively. Understanding the complex mechanism behind cancer development calls for exploiting biomarkers from multiple modalities of data such as histopathology images and genomic data. The integrative analysis of these biomarkers sheds light on cancer diagnosis, subtyping, and prognosis. Another difficulty is that labels for early-stage cancer patients are scarce and not reliable enough for predicting survival times. Given the fact that different cancer types share some commonalities, we explore if the knowledge learned from one cancer type can be utilized to improve prognosis accuracy for another cancer type. We propose a novel unsupervised multi-view transfer learning algorithm to simultaneously analyze multiple biomarkers in different cancer types. We integrate multiple views using non-negative matrix factorization and formulate the transfer learning model based on the Optimal Transport theory to align features of different cancer types. We evaluate the stratification performance on three early-stage cancers from the Cancer Genome Atlas (TCGA) project. Comparing with other benchmark methods, our framework achieves superior accuracy for patient outcome prediction. Keywords: Machine Learning: Transfer, Adaptation, Multi-task Learning Machine Learning Applications: Applications of Unsupervised Learning Machine Learning Applications: Bio/Medicine},
  archive   = {C_IJCAI},
  author    = {Ziyu Liu and Wei Shao and Jie Zhang and Min Zhang and Kun Huang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/380},
  pages     = {2760-2766},
  title     = {Transfer learning via optimal transportation for integrative cancer patient stratification},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Smart contract vulnerability detection: From pure neural
network to interpretable graph feature and expert pattern fusion.
<em>IJCAI</em>, 2751–2759. (<a
href="https://doi.org/10.24963/ijcai.2021/379">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Smart contracts hold digital coins worth billions of dollars, their security issues have drawn extensive attention in the past years. Towards smart contract vulnerability detection, conventional methods heavily rely on fixed expert rules, leading to low accuracy and poor scalability. Recent deep learning approaches alleviate this issue but fail to encode useful expert knowledge. In this paper, we explore combining deep learning with expert patterns in an explainable fashion. Specifically, we develop automatic tools to extract expert patterns from the source code. We then cast the code into a semantic graph to extract deep graph features. Thereafter, the global graph feature and local expert patterns are fused to cooperate and approach the final prediction, while yielding their interpretable weights. Experiments are conducted on all available smart contracts with source code in two platforms, Ethereum and VNT Chain. Empirically, our system significantly outperforms state-of-the-art methods. Our code is released. Keywords: Machine Learning: Explainable/Interpretable Machine Learning Machine Learning: Knowledge Aided Learning Multidisciplinary Topics and Applications: Security and Privacy},
  archive   = {C_IJCAI},
  author    = {Zhenguang Liu and Peng Qian and Xiang Wang and Lei Zhu and Qinming He and Shouling Ji},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/379},
  pages     = {2751-2759},
  title     = {Smart contract vulnerability detection: From pure neural network to interpretable graph feature and expert pattern fusion},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adversarial spectral kernel matching for unsupervised time
series domain adaptation. <em>IJCAI</em>, 2744–2750. (<a
href="https://doi.org/10.24963/ijcai.2021/378">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Unsupervised domain adaptation (UDA) has been received increasing attention since it does not require labels in target domain. Most existing UDA methods learn domain-invariant features by minimizing discrepancy distance computed by a certain metric between domains. However, these discrepancy-based methods cannot be robustly applied to unsupervised time series domain adaptation (UTSDA). That is because discrepancy metrics in these methods contain only low-order and local statistics, which have limited expression for time series distributions and therefore result in failure of domain matching. Actually, the real-world time series are always non-local distributions, i.e., with non-stationary and non-monotonic statistics. In this paper, we propose an Adversarial Spectral Kernel Matching (AdvSKM) method, where a hybrid spectral kernel network is specifically designed as inner kernel to reform the Maximum Mean Discrepancy (MMD) metric for UTSDA. The hybrid spectral kernel network can precisely characterize non-stationary and non-monotonic statistics in time series distributions. Embedding hybrid spectral kernel network to MMD not only guarantees precise discrepancy metric but also benefits domain matching. Besides, the differentiable architecture of the spectral kernel network enables adversarial kernel learning, which brings more discriminatory expression for discrepancy matching. The results of extensive experiments on several real-world UTSDA tasks verify the effectiveness of our proposed method. Keywords: Machine Learning: Kernel Methods Machine Learning: Transfer, Adaptation, Multi-task Learning},
  archive   = {C_IJCAI},
  author    = {Qiao Liu and Hui Xue},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/378},
  pages     = {2744-2750},
  title     = {Adversarial spectral kernel matching for unsupervised time series domain adaptation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Two-stage training for learning from label proportions.
<em>IJCAI</em>, 2737–2743. (<a
href="https://doi.org/10.24963/ijcai.2021/377">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Learning from label proportions (LLP) aims at learning an instance-level classifier with label proportions in grouped training data. Existing deep learning based LLP methods utilize end-to-end pipelines to obtain the proportional loss with Kullback-Leibler divergence between the bag-level prior and posterior class distributions. However, the unconstrained optimization on this objective can hardly reach a solution in accordance with the given proportions. Besides, concerning the probabilistic classifier, this strategy unavoidably results in high-entropy conditional class distributions at the instance level. These issues further degrade the performance of the instance-level classification. In this paper, we regard these problems as noisy pseudo labeling, and instead impose the strict proportion consistency on the classifier with a constrained optimization as a continuous training stage for existing LLP classifiers. In addition, we introduce the mixup strategy and symmetric cross-entropy to further reduce the label noise. Our framework is model-agnostic, and demonstrates compelling performance improvement in extensive experiments, when incorporated into other deep LLP models as a post-hoc phase. Keywords: Machine Learning: Classification Machine Learning: Deep Learning Machine Learning: Weakly Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Jiabin Liu and Bo Wang and Xin Shen and Zhiquan Qi and Yingjie Tian},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/377},
  pages     = {2737-2743},
  title     = {Two-stage training for learning from label proportions},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the intrinsic differential privacy of bagging.
<em>IJCAI</em>, 2730–2736. (<a
href="https://doi.org/10.24963/ijcai.2021/376">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Differentially private machine learning trains models while protecting privacy of the sensitive training data. The key to obtain differentially private models is to introduce noise/randomness to the training process. In particular, existing differentially private machine learning methods add noise to the training data, the gradients, the loss function, and/or the model itself. Bagging, a popular ensemble learning framework, randomly creates some subsamples of the training data, trains a base model for each subsample using a base learner, and takes majority vote among the base models when making predictions. Bagging has intrinsic randomness in the training process as it randomly creates subsamples. Our major theoretical results show that such intrinsic randomness already makes Bagging differentially private without the needs of additional noise. Moreover, we prove that if no assumptions about the base learner are made, our derived privacy guarantees are tight. We empirically evaluate Bagging on MNIST and CIFAR10. Our experimental results demonstrate that Bagging achieves significantly higher accuracies than state-of-the-art differentially private machine learning methods with the same privacy budgets. Keywords: Machine Learning: Ensemble Methods Multidisciplinary Topics and Applications: Security and Privacy},
  archive   = {C_IJCAI},
  author    = {Hongbin Liu and Jinyuan Jia and Neil Zhenqiang Gong},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/376},
  pages     = {2730-2736},
  title     = {On the intrinsic differential privacy of bagging},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Graph filter-based multi-view attributed graph clustering.
<em>IJCAI</em>, 2723–2729. (<a
href="https://doi.org/10.24963/ijcai.2021/375">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph clustering has become an important research topic due to the proliferation of graph data. However, existing methods suffer from two major drawbacks. On the one hand, most methods can not simultaneously exploit attribute and graph structure information. On the other hand, most methods are incapable of handling multi-view data which contain sets of different features and graphs. In this paper, we propose a novel Multi-view Attributed Graph Clustering (MvAGC) method, which is simple yet effective. Firstly, a graph filter is applied to features to obtain a smooth representation without the need of learning the parameters of neural networks. Secondly, a novel strategy is designed to select a few anchor points, so as to reduce the computation complexity. Thirdly, a new regularizer is developed to explore high-order neighborhood information. Our extensive experiments indicate that our method works surprisingly well with respect to state-of-the-art deep neural network methods. The source code is available at https://github.com/sckangz/MvAGC. Keywords: Machine Learning: Clustering Machine Learning: Multi-instance; Multi-label; Multi-view learning Data Mining: Clustering Machine Learning: Unsupervised Learning},
  archive   = {C_IJCAI},
  author    = {Zhiping Lin and Zhao Kang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/375},
  pages     = {2723-2729},
  title     = {Graph filter-based multi-view attributed graph clustering},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Residential electric load forecasting via attentive transfer
of graph neural networks. <em>IJCAI</em>, 2716–2722. (<a
href="https://doi.org/10.24963/ijcai.2021/374">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {An accurate short-term electric load forecasting is critical for modern electric power systems&#39; safe and economical operation. Electric load forecasting can be formulated as a multi-variate time series problem. Residential houses in the same neighborhood may be affected by similar factors and share some latent spatial dependencies. However, most of the existing works on electric load forecasting fail to explore such dependencies. In recent years, graph neural networks (GNNs) have shown impressive success in modeling such dependencies. However, such GNN based models usually would require a large amount of training data. We may have a minimal amount of data available to train a reliable forecasting model for houses in a new neighborhood area. At the same time, we may have a large amount of historical data collected from other houses that can be leveraged to improve the new neighborhood&#39;s prediction performance. In this paper, we propose an attentive transfer learning-based GNN model that can utilize the learned prior knowledge to improve the learning process in a new area. The transfer process is achieved by an attention network, which generically avoids negative transfer by leveraging knowledge from multiple sources. Extensive experiments have been conducted on real-world data sets. Results have shown that the proposed framework can consistently outperform baseline models in different areas. Keywords: Machine Learning: Time-series; Data Streams Multidisciplinary Topics and Applications: Computational Sustainability Multidisciplinary Topics and Applications: Natural Sciences},
  archive   = {C_IJCAI},
  author    = {Weixuan Lin and Di Wu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/374},
  pages     = {2716-2722},
  title     = {Residential electric load forecasting via attentive transfer of graph neural networks},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An adaptive news-driven method for CVaR-sensitive online
portfolio selection in non-stationary financial markets. <em>IJCAI</em>,
2708–2715. (<a href="https://doi.org/10.24963/ijcai.2021/373">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {CVaR-sensitive online portfolio selection (CS-OLPS) becomes increasingly important for investors because of its effectiveness to minimize conditional value at risk (CVaR) and control extreme losses. However, the non-stationary nature of financial markets makes it very difficult to address the CS-OLPS problem effectively. To address the CS-OLPS problem in non-stationary markets, we propose an effective news-driven method, named CAND, which adaptively exploits news to determine the adjustment tendency and adjustment scale for tracking the dynamic optimal portfolio with minimal CVaR in each trading round. In addition, we devise a filtering mechanism to reduce the errors caused by the noisy news for further improving CAND&#39;s effectiveness. We rigorously prove a sub-linear regret of CAND. Extensive experiments on three real-world datasets demonstrate CAND’s superiority over the state-of-the-art portfolio methods in terms of returns and risks. Keywords: Machine Learning: Online Learning Multidisciplinary Topics and Applications: Economic and Finance},
  archive   = {C_IJCAI},
  author    = {Qianqiao Liang and Mengying Zhu and Xiaolin Zheng and Yan Wang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/373},
  pages     = {2708-2715},
  title     = {An adaptive news-driven method for CVaR-sensitive online portfolio selection in non-stationary financial markets},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SHPOS: A theoretical guaranteed accelerated particle
optimization sampling method. <em>IJCAI</em>, 2701–2707. (<a
href="https://doi.org/10.24963/ijcai.2021/372">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, the Stochastic Particle Optimization Sampling (SPOS) method is proposed to solve the particle-collapsing pitfall of deterministic Particle Variational Inference methods by ultilizing the stochastic Overdamped Langevin dynamics to enhance exploration. In this paper, we propose an accelerated particle optimization sampling method called Stochastic Hamiltonian Particle Optimization Sampling (SHPOS). Compared to the first-order dynamics used in SPOS, SHPOS adopts an augmented second-order dynamics, which involves an extra momentum term to achieve acceleration. We establish a non-asymptotic convergence analysis for SHPOS, and show that it enjoys a faster convergence rate than SPOS. Besides, we also propose a variance-reduced stochastic gradient variant of SHPOS for tasks with large-scale datasets and complex models. Experiments on both synthetic and real data validate our theory and demonstrate the superiority of SHPOS over the state-of-the-art. Keywords: Machine Learning: Bayesian Learning Uncertainty in AI: Approximate Probabilistic Inference Uncertainty in AI: Exact Probabilistic Inference},
  archive   = {C_IJCAI},
  author    = {Zhijian Li and Chao Zhang and Hui Qian and Xin Du and Lingwei Peng},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/372},
  pages     = {2701-2707},
  title     = {SHPOS: A theoretical guaranteed accelerated particle optimization sampling method},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Pairwise half-graph discrimination: A simple graph-level
self-supervised strategy for pre-training graph neural networks.
<em>IJCAI</em>, 2694–2700. (<a
href="https://doi.org/10.24963/ijcai.2021/371">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Self-supervised learning has gradually emerged as a powerful technique for graph representation learning. However, transferable, generalizable, and robust representation learning on graph data still remains a challenge for pre-training graph neural networks. In this paper, we propose a simple and effective self-supervised pre-training strategy, named Pairwise Half-graph Discrimination (PHD), that explicitly pre-trains a graph neural network at graph-level. PHD is designed as a simple binary classification task to discriminate whether two half-graphs come from the same source. Experiments demonstrate that the PHD is an effective pre-training strategy that offers comparable or superior performance on 13 graph classification tasks compared with state-of-the-art strategies, and achieves notable improvements when combined with node-level strategies. Moreover, the visualization of learned representation revealed that PHD strategy indeed empowers the model to learn graph-level knowledge like the molecular scaffold. These results have established PHD as a powerful and effective self-supervised learning strategy in graph-level representation learning. Keywords: Machine Learning: Deep Learning Machine Learning: Unsupervised Learning Data Mining: Mining Graphs, Semi Structured Data, Complex Data},
  archive   = {C_IJCAI},
  author    = {Pengyong Li and Jun Wang and Ziliang Li and Yixuan Qiao and Xianggen Liu and Fei Ma and Peng Gao and Sen Song and Guotong Xie},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/371},
  pages     = {2694-2700},
  title     = {Pairwise half-graph discrimination: A simple graph-level self-supervised strategy for pre-training graph neural networks},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Regularising knowledge transfer by meta functional learning.
<em>IJCAI</em>, 2687–2693. (<a
href="https://doi.org/10.24963/ijcai.2021/370">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Machine learning classifiers’ capability is largely dependent on the scale of available training data and limited by the model overfitting in data-scarce learning tasks. To address this problem, this work proposes a novel Meta Functional Learning (MFL) by meta-learning a generalisable functional model from data-rich tasks whilst simultaneously regularising knowledge transfer to data-scarce tasks. The MFL computes meta-knowledge on functional regularisation generalisable to different learning tasks by which functional training on limited labelled data promotes more discriminative functions to be learned. Moreover, we adopt an Iterative Update strategy on MFL (MFL-IU). This improves knowledge transfer regularisation from MFL by progressively learning the functional regularisation in knowledge transfer. Experiments on three Few-Shot Learning (FSL) benchmarks (miniImageNet, CIFAR-FS and CUB) show that meta functional learning for regularisation knowledge transfer can benefit improving FSL classifiers. Keywords: Machine Learning: Classification Machine Learning: Transfer, Adaptation, Multi-task Learning Machine Learning: Weakly Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Pan Li and Yanwei Fu and Shaogang Gong},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/370},
  pages     = {2687-2693},
  title     = {Regularising knowledge transfer by meta functional learning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). TextGTL: Graph-based transductive learning for
semi-supervised text classification via structure-sensitive
interpolation. <em>IJCAI</em>, 2680–2686. (<a
href="https://doi.org/10.24963/ijcai.2021/369">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Compared with traditional sequential learning models, graph-based neural networks exhibit excellent properties when encoding text, such as the capacity of capturing global and local information simultaneously. Especially in the semi-supervised scenario, propagating information along the edge can effectively alleviate the sparsity of labeled data. In this paper, beyond the existing architecture of heterogeneous word-document graphs, for the first time, we investigate how to construct lightweight non-heterogeneous graphs based on different linguistic information to better serve free text representation learning. Then, a novel semi-supervised framework for text classification that refines graph topology under theoretical guidance and shares information across different text graphs, namely Text-oriented Graph-based Transductive Learning (TextGTL), is proposed. TextGTL also performs attribute space interpolation based on dense substructure in graphs to predict low-entropy labels with high-quality feature nodes for data augmentation. To verify the effectiveness of TextGTL, we conduct extensive experiments on various benchmark datasets, observing significant performance gains over conventional heterogeneous graphs. In addition, we also design ablation studies to dive deep into the validity of components in TextTGL. Keywords: Machine Learning: Semi-Supervised Learning Data Mining: Mining Graphs, Semi Structured Data, Complex Data},
  archive   = {C_IJCAI},
  author    = {Chen Li and Xutan Peng and Hao Peng and Jianxin Li and Lihong Wang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/369},
  pages     = {2680-2686},
  title     = {TextGTL: Graph-based transductive learning for semi-supervised text classification via structure-sensitive interpolation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). RetCL: A selection-based approach for retrosynthesis via
contrastive learning. <em>IJCAI</em>, 2673–2679. (<a
href="https://doi.org/10.24963/ijcai.2021/368">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Retrosynthesis, of which the goal is to find a set of reactants for synthesizing a target product, is an emerging research area of deep learning. While the existing approaches have shown promising results, they currently lack the ability to consider availability (e.g., stability or purchasability) of the reactants or generalize to unseen reaction templates (i.e., chemical reaction rules). In this paper, we propose a new approach that mitigates the issues by reformulating retrosynthesis into a selection problem of reactants from a candidate set of commercially available molecules. To this end, we design an efficient reactant selection framework, named RetCL (retrosynthesis via contrastive learning), for enumerating all of the candidate molecules based on selection scores computed by graph neural networks. For learning the score functions, we also propose a novel contrastive training scheme with hard negative mining. Extensive experiments demonstrate the benefits of the proposed selection-based approach. For example, when all 671k reactants in the USPTO database are given as candidates, our RetCL achieves top-1 exact match accuracy of 71.3\% for the USPTO-50k benchmark, while a recent transformer-based approach achieves 59.6\%. We also demonstrate that RetCL generalizes well to unseen templates in various settings in contrast to template-based approaches. Keywords: Machine Learning: Deep Learning Machine Learning Applications: Bio/Medicine},
  archive   = {C_IJCAI},
  author    = {Hankook Lee and Sungsoo Ahn and Seung-Woo Seo and You Young Song and Eunho Yang and Sung Ju Hwang and Jinwoo Shin},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/368},
  pages     = {2673-2679},
  title     = {RetCL: A selection-based approach for retrosynthesis via contrastive learning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Topological uncertainty: Monitoring trained neural networks
through persistence of activation graphs. <em>IJCAI</em>, 2666–2672. (<a
href="https://doi.org/10.24963/ijcai.2021/367">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Although neural networks are capable of reaching astonishing performance on a wide variety of contexts, properly training networks on complicated tasks requires expertise and can be expensive from a computational perspective. In industrial applications, data coming from an open-world setting might widely differ from the benchmark datasets on which a network was trained. Being able to monitor the presence of such variations without retraining the network is of crucial importance. In this paper, we develop a method to monitor trained neural networks based on the topological properties of their activation graphs. To each new observation, we assign a Topological Uncertainty, a score that aims to assess the reliability of the predictions by investigating the whole network instead of its final layer only as typically done by practitioners. Our approach entirely works at a post-training level and does not require any assumption on the network architecture, optimization scheme, nor the use of data augmentation or auxiliary datasets; and can be faithfully applied on a large range of network architectures and data types. We showcase experimentally the potential of Topological Uncertainty in the context of trained network selection, Out-Of-Distribution detection, and shift-detection, both on synthetic and real datasets of images and graphs. Keywords: Machine Learning: Deep Learning Uncertainty in AI: Uncertainty Representations},
  archive   = {C_IJCAI},
  author    = {Théo Lacombe and Yuichi Ike and Mathieu Carrière and Frédéric Chazal and Marc Glisse and Yuhei Umeda},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/367},
  pages     = {2666-2672},
  title     = {Topological uncertainty: Monitoring trained neural networks through persistence of activation graphs},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On guaranteed optimal robust explanations for NLP models.
<em>IJCAI</em>, 2658–2665. (<a
href="https://doi.org/10.24963/ijcai.2021/366">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We build on abduction-based explanations for machine learning and develop a method for computing local explanations for neural network models in natural language processing (NLP). Our explanations comprise a subset of the words of the input text that satisfies two key features: optimality w.r.t. a user-defined cost function, such as the length of explanation, and robustness, in that they ensure prediction invariance for any bounded perturbation in the embedding space of the left-out words. We present two solution algorithms, respectively based on implicit hitting sets and maximum universal subsets, introducing a number of algorithmic improvements to speed up convergence of hard instances. We show how our method can be configured with different perturbation sets in the embedded space and used to detect bias in predictions by enforcing include/exclude constraints on biased terms, as well as to enhance existing heuristic-based NLP explanation frameworks such as Anchors. We evaluate our framework on three widely used sentiment analysis tasks and texts of up to 100 words from SST, Twitter and IMDB datasets, demonstrating the effectiveness of the derived explanations. Keywords: Machine Learning: Adversarial Machine Learning Machine Learning: Explainable/Interpretable Machine Learning Natural Language Processing: Sentiment Analysis and Text Mining},
  archive   = {C_IJCAI},
  author    = {Emanuele La Malfa and Rhiannon Michelmore and Agnieszka M. Zbrzezny and Nicola Paoletti and Marta Kwiatkowska},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/366},
  pages     = {2658-2665},
  title     = {On guaranteed optimal robust explanations for NLP models},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Solving continuous control with episodic memory.
<em>IJCAI</em>, 2651–2657. (<a
href="https://doi.org/10.24963/ijcai.2021/365">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Episodic memory lets reinforcement learning algorithms remember and exploit promising experience from the past to improve agent performance. Previous works on memory mechanisms show benefits of using episodic-based data structures for discrete action problems in terms of sample-efficiency. The application of episodic memory for continuous control with a large action space is not trivial. Our study aims to answer the question: can episodic memory be used to improve agent&#39;s performance in continuous control? Our proposed algorithm combines episodic memory with Actor-Critic architecture by modifying critic&#39;s objective. We further improve performance by introducing episodic-based replay buffer prioritization. We evaluate our algorithm on OpenAI gym domains and show greater sample-efficiency compared with the state-of-the art model-free off-policy algorithms. Keywords: Machine Learning: Deep Reinforcement Learning Machine Learning: Reinforcement Learning},
  archive   = {C_IJCAI},
  author    = {Igor Kuznetsov and Andrey Filchenkov},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/365},
  pages     = {2651-2657},
  title     = {Solving continuous control with episodic memory},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards scalable complete verification of relu neural
networks via dependency-based branching. <em>IJCAI</em>, 2643–2650. (<a
href="https://doi.org/10.24963/ijcai.2021/364">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We introduce an efficient method for the complete verification of ReLU-based feed-forward neural networks. The method implements branching on the ReLU states on the basis of a notion of dependency between the nodes. This results in dividing the original verification problem into a set of sub-problems whose MILP formulations require fewer integrality constraints. We evaluate the method on all of the ReLU-based fully connected networks from the first competition for neural network verification. The experimental results obtained show 145\% performance gains over the present state-of-the-art in complete verification. Keywords: Machine Learning: Deep Learning Multidisciplinary Topics and Applications: Validation and Verification},
  archive   = {C_IJCAI},
  author    = {Panagiotis Kouvaros and Alessio Lomuscio},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/364},
  pages     = {2643-2650},
  title     = {Towards scalable complete verification of relu neural networks via dependency-based branching},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Epsilon best arm identification in spectral bandits.
<em>IJCAI</em>, 2636–2642. (<a
href="https://doi.org/10.24963/ijcai.2021/363">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose an analysis of Probably Approximately Correct (PAC) identification of an ϵ-best arm in graph bandit models with Gaussian distributions. We consider finite but potentially very large bandit models where the set of arms is endowed with a graph structure, and we assume that the arms&#39; expectations μ are smooth with respect to this graph. Our goal is to identify an arm whose expectation is at most ϵ below the largest of all means. We focus on the fixed-confidence setting: given a risk parameter δ, we consider sequential strategies that yield an ϵ-optimal arm with probability at least 1-δ. All such strategies use at least T*(μ)log(1/δ) samples, where R is the smoothness parameter. We identify the complexity term T*(μ) as the solution of a min-max problem for which we give a game-theoretic analysis and an approximation procedure. This procedure is the key element required by the asymptotically optimal Track-and-Stop strategy. Keywords: Machine Learning: Learning Theory Machine Learning: Online Learning},
  archive   = {C_IJCAI},
  author    = {Tomáš Kocák and Aurélien Garivier},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/363},
  pages     = {2636-2642},
  title     = {Epsilon best arm identification in spectral bandits},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Comparing kullback-leibler divergence and mean squared error
loss in knowledge distillation. <em>IJCAI</em>, 2628–2635. (<a
href="https://doi.org/10.24963/ijcai.2021/362">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Knowledge distillation (KD), transferring knowledge from a cumbersome teacher model to a lightweight student model, has been investigated to design efficient neural architectures. Generally, the objective function of KD is the Kullback-Leibler (KL) divergence loss between the softened probability distributions of the teacher model and the student model with the temperature scaling hyperparameter τ. Despite its widespread use, few studies have discussed how such softening influences generalization. Here, we theoretically show that the KL divergence loss focuses on the logit matching when τ increases and the label matching when τ goes to 0 and empirically show that the logit matching is positively correlated to performance improvement in general. From this observation, we consider an intuitive KD loss function, the mean squared error (MSE) between the logit vectors, so that the student model can directly learn the logit of the teacher model. The MSE loss outperforms the KL divergence loss, explained by the penultimate layer representations difference between the two losses. Furthermore, we show that sequential distillation can improve performance and that KD, using the KL divergence loss with small τ particularly, mitigates the label noise. The code to reproduce the experiments is publicly available online at https://github.com/jhoon-oh/kd_data/. Keywords: Machine Learning: Classification Machine Learning: Deep Learning},
  archive   = {C_IJCAI},
  author    = {Taehyeon Kim and Jaehoon Oh and Nak Yil Kim and Sangwook Cho and Se-Young Yun},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/362},
  pages     = {2628-2635},
  title     = {Comparing kullback-leibler divergence and mean squared error loss in knowledge distillation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Knowledge consolidation based class incremental online
learning with limited data. <em>IJCAI</em>, 2621–2627. (<a
href="https://doi.org/10.24963/ijcai.2021/361">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose a novel approach for class incremental online learning in a limited data setting. This problem setting is challenging because of the following constraints: (1) Classes are given incrementally, which necessitates a class incremental learning approach; (2) Data for each class is given in an online fashion, i.e., each training example is seen only once during training; (3) Each class has very few training examples; and (4) We do not use or assume access to any replay/memory to store data from previous classes. Therefore, in this setting, we have to handle twofold problems of catastrophic forgetting and overfitting. In our approach, we learn robust representations that are generalizable across tasks without suffering from the problems of catastrophic forgetting and overfitting to accommodate future classes with limited samples. Our proposed method leverages the meta-learning framework with knowledge consolidation. The meta-learning framework helps the model for rapid learning when samples appear in an online fashion. Simultaneously, knowledge consolidation helps to learn a robust representation against forgetting under online updates to facilitate future learning. Our approach significantly outperforms other methods on several benchmarks. Keywords: Machine Learning: Incremental Learning},
  archive   = {C_IJCAI},
  author    = {Mohammed Asad Karim and Vinay Kumar Verma and Pravendra Singh and Vinay Namboodiri and Piyush Rai},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/361},
  pages     = {2621-2627},
  title     = {Knowledge consolidation based class incremental online learning with limited data},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SalientSleepNet: Multimodal salient wave detection network
for sleep staging. <em>IJCAI</em>, 2614–2620. (<a
href="https://doi.org/10.24963/ijcai.2021/360">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Sleep staging is fundamental for sleep assessment and disease diagnosis. Although previous attempts to classify sleep stages have achieved high classification performance, several challenges remain open: 1) How to effectively extract salient waves in multimodal sleep data; 2) How to capture the multi-scale transition rules among sleep stages; 3) How to adaptively seize the key role of specific modality for sleep staging. To address these challenges, we propose SalientSleepNet, a multimodal salient wave detection network for sleep staging. Specifically, SalientSleepNet is a temporal fully convolutional network based on the $U^2$-Net architecture that is originally proposed for salient object detection in computer vision. It is mainly composed of two independent $U^2$-like streams to extract the salient features from multimodal data, respectively. Meanwhile, the multi-scale extraction module is designed to capture multi-scale transition rules among sleep stages. Besides, the multimodal attention module is proposed to adaptively capture valuable information from multimodal data for the specific sleep stage. Experiments on the two datasets demonstrate that SalientSleepNet outperforms the state-of-the-art baselines. It is worth noting that this model has the least amount of parameters compared with the existing deep neural network models. Keywords: Machine Learning: Time-series; Data Streams Multidisciplinary Topics and Applications: Biology and Medicine Humans and AI: Brain Sciences Machine Learning: Deep Learning},
  archive   = {C_IJCAI},
  author    = {Ziyu Jia and Youfang Lin and Jing Wang and Xuehui Wang and Peiyi Xie and Yingbin Zhang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/360},
  pages     = {2614-2620},
  title     = {SalientSleepNet: Multimodal salient wave detection network for sleep staging},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning to learn personalized neural network for
ventricular arrhythmias detection on intracardiac EGMs. <em>IJCAI</em>,
2606–2613. (<a href="https://doi.org/10.24963/ijcai.2021/359">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Life-threatening ventricular arrhythmias (VAs) detection on intracardiac electrograms (IEGMs) is essential to Implantable Cardioverter Defibrillators (ICDs). However, current VAs detection methods count on a variety of heuristic detection criteria, and require frequent manual interventions to personalize criteria parameters for each patient to achieve accurate detection. In this work, we propose a one-dimensional convolutional neural network (1D-CNN) based life-threatening VAs detection on IEGMs. The network architecture is elaborately designed to satisfy the extreme resource constraints of the ICD while maintaining high detection accuracy. We further propose a meta-learning algorithm with a novel patient-wise training tasks formatting strategy to personalize the 1D-CNN. The algorithm generates a well-generalized model initialization containing across-patient knowledge, and performs a quick adaptation of the model to the specific patient&#39;s IEGMs. In this way, a new patient could be immediately assigned with personalized 1D-CNN model parameters using limited input data. Compared with the conventional VAs detection method, the proposed method achieves 2.2\% increased sensitivity for detecting VAs rhythm and 8.6\% increased specificity for non-VAs rhythm. Keywords: Machine Learning: Transfer, Adaptation, Multi-task Learning Multidisciplinary Topics and Applications: Biology and Medicine Machine Learning Applications: Bio/Medicine},
  archive   = {C_IJCAI},
  author    = {Zhenge Jia and Zhepeng Wang and Feng Hong and Lichuan PING and Yiyu Shi and Jingtong Hu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/359},
  pages     = {2606-2613},
  title     = {Learning to learn personalized neural network for ventricular arrhythmias detection on intracardiac EGMs},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning CNF theories using MDL and predicate invention.
<em>IJCAI</em>, 2599–2605. (<a
href="https://doi.org/10.24963/ijcai.2021/358">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We revisit the problem of learning logical theories from examples, one of the most quintessential problems in machine learning. More specifically, we develop an approach to learn CNF-formulae from satisfiability. This is a setting in which the examples correspond to partial interpretations and an example is classified as positive when it is logically consistent with the theory. We present a novel algorithm, called Mistle -- Minimal SAT Theory Learner, for learning such theories. The distinguishing features are that 1) Mistle performs predicate invention and inverse resolution, 2) is based on the MDL principle to compress the data, and 3) combines this with frequent pattern mining to find the most interesting theories. The experiments demonstrate that Mistle can learn CNF theories accurately and works well in tasks involving compression and classification. Keywords: Machine Learning: Relational Learning Constraints and SAT: Constraints and Data Mining; Constraints and Machine Learning},
  archive   = {C_IJCAI},
  author    = {Arcchit Jain and Clément Gautrais and Angelika Kimmig and Luc De Raedt},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/358},
  pages     = {2599-2605},
  title     = {Learning CNF theories using MDL and predicate invention},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reinforcement learning for route optimization with
robustness guarantees. <em>IJCAI</em>, 2592–2598. (<a
href="https://doi.org/10.24963/ijcai.2021/357">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Application of deep learning to NP-hard combinatorial optimization problems is an emerging research trend, and a number of interesting approaches have been published over the last few years. In this work we address robust optimization, which is a more complex variant where a max-min problem is to be solved. We obtain robust solutions by solving the inner minimization problem exactly and apply Reinforcement Learning to learn a heuristic for the outer problem. The minimization term in the inner objective represents an obstacle to existing RL-based approaches, as its value depends on the full solution in a non-linear manner and cannot be evaluated for partial solutions constructed by the agent over the course of each episode. We overcome this obstacle by defining the reward in terms of the one-step advantage over a baseline policy whose role can be played by any fast heuristic for the given problem. The agent is trained to maximize the total advantage, which, as we show, is equivalent to the original objective. We validate our approach by solving min-max versions of standard benchmarks for the Capacitated Vehicle Routing and the Traveling Salesperson Problem, where our agents obtain near-optimal solutions and improve upon the baselines. Keywords: Machine Learning: Deep Reinforcement Learning Planning and Scheduling: Planning under Uncertainty Machine Learning Applications: Applications of Reinforcement Learning},
  archive   = {C_IJCAI},
  author    = {Tobias Jacobs and Francesco Alesiani and Gulcin Ermis},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/357},
  pages     = {2592-2598},
  title     = {Reinforcement learning for route optimization with robustness guarantees},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On explaining random forests with SAT. <em>IJCAI</em>,
2584–2591. (<a href="https://doi.org/10.24963/ijcai.2021/356">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Random Forest (RFs) are among the most widely used Machine Learning (ML) classifiers. Even though RFs are not interpretable, there are no dedicated non-heuristic approaches for computing explanations of RFs. Moreover, there is recent work on polynomial algorithms for explaining ML models, including naive Bayes classifiers. Hence, one question is whether finding explanations of RFs can be solved in polynomial time. This paper answers this question negatively, by proving that computing one PI-explanation of an RF is D^P-hard. Furthermore, the paper proposes a propositional encoding for computing explanations of RFs, thus enabling finding PI-explanations with a SAT solver. This contrasts with earlier work on explaining boosted trees (BTs) and neural networks (NNs), which requires encodings based on SMT/MILP. Experimental results, obtained on a wide range of publicly available datasets, demonstrate that the proposed SAT-based approach scales to RFs of sizes common in practical applications. Perhaps more importantly, the experimental results demonstrate that, for the vast majority of examples considered, the SAT-based approach proposed in this paper significantly outperforms existing heuristic approaches. Keywords: Machine Learning: Explainable/Interpretable Machine Learning Constraints and SAT: Constraints and Data Mining; Constraints and Machine Learning Constraints and SAT: SAT: Solvers and Applications},
  archive   = {C_IJCAI},
  author    = {Yacine Izza and Joao Marques-Silva},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/356},
  pages     = {2584-2591},
  title     = {On explaining random forests with SAT},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the neural tangent kernel of deep networks with
orthogonal initialization. <em>IJCAI</em>, 2577–2583. (<a
href="https://doi.org/10.24963/ijcai.2021/355">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The prevailing thinking is that orthogonal weights are crucial to enforcing dynamical isometry and speeding up training. The increase in learning speed that results from orthogonal initialization in linear networks has been well-proven. However, while the same is believed to also hold for nonlinear networks when the dynamical isometry condition is satisfied, the training dynamics behind this contention have not been thoroughly explored. In this work, we study the dynamics of ultra-wide networks across a range of architectures, including Fully Connected Networks (FCNs) and Convolutional Neural Networks (CNNs) with orthogonal initialization via neural tangent kernel (NTK). Through a series of propositions and lemmas, we prove that two NTKs, one corresponding to Gaussian weights and one to orthogonal weights, are equal when the network width is infinite. Further, during training, the NTK of an orthogonally-initialized infinite-width network should theoretically remain constant. This suggests that the orthogonal initialization cannot speed up training in the NTK (lazy training) regime, contrary to the prevailing thoughts. In order to explore under what circumstances can orthogonality accelerate training, we conduct a thorough empirical investigation outside the NTK regime. We find that when the hyper-parameters are set to achieve a linear regime in nonlinear activation, orthogonal initialization can improve the learning speed with a large learning rate or large depth. Keywords: Machine Learning: Deep Learning Machine Learning: Learning Theory},
  archive   = {C_IJCAI},
  author    = {Wei Huang and Weitao Du and Richard Yi Da Xu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/355},
  pages     = {2577-2583},
  title     = {On the neural tangent kernel of deep networks with orthogonal initialization},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Asynchronous active learning with distributed label
querying. <em>IJCAI</em>, 2570–2576. (<a
href="https://doi.org/10.24963/ijcai.2021/354">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Active learning tries to learn an effective model with lowest labeling cost. Most existing active learning methods work in a synchronous way, which implies that the label querying can be performed only after the model updating in each iteration. While training models is usually time-consuming, it may lead to serious latency between two queries, especially in the crowdsourcing environments where there are many online annotators working simultaneously. This will significantly decrease the labeling efficiency and strongly limit the application of active learning in real tasks. To overcome this challenge, we propose a multi-server multi-worker framework for asynchronous active learning in the distributed environment. By maintaining two shared pools of candidate queries and labeled data respectively, the servers, the workers and the annotators efficiently corporate with each other without synchronization. Moreover, diverse sampling strategies from distributed workers are incorporated to select the most useful instances for model improving. Both theoretical analysis and experimental study validate the effectiveness of the proposed approach. Keywords: Machine Learning: Active Learning Machine Learning: Weakly Supervised Learning Machine Learning: Semi-Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Sheng-Jun Huang and Chen-Chen Zong and Kun-Peng Ning and Hai-Bo Ye},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/354},
  pages     = {2570-2576},
  title     = {Asynchronous active learning with distributed label querying},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). UniGNN: A unified framework for graph and hypergraph neural
networks. <em>IJCAI</em>, 2563–2569. (<a
href="https://doi.org/10.24963/ijcai.2021/353">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Hypergraph, an expressive structure with flexibility to model the higher-order correlations among entities, has recently attracted increasing attention from various research domains. Despite the success of Graph Neural Networks (GNNs) for graph representation learning, how to adapt the powerful GNN-variants directly into hypergraphs remains a challenging problem. In this paper, we propose UniGNN, a unified framework for interpreting the message passing process in graph and hypergraph neural networks, which can generalize general GNN models into hypergraphs. In this framework, meticulously-designed architectures aiming to deepen GNNs can also be incorporated into hypergraphs with the least effort. Extensive experiments have been conducted to demonstrate the effectiveness of UniGNN on multiple real-world datasets, which outperform the state-of-the-art approaches with a large margin. Especially for the DBLP dataset, we increase the accuracy from 77.4\% to 88.8\% in the semi-supervised hypernode classification task. We further prove that the proposed message-passing based UniGNN models are at most as powerful as the 1-dimensional Generalized Weisfeiler-Leman (1-GWL) algorithm in terms of distinguishing non-isomorphic hypergraphs. Our code is available at https://github.com/OneForward/UniGNN. Keywords: Machine Learning: Learning Graphical Models Machine Learning: Semi-Supervised Learning Data Mining: Mining Graphs, Semi Structured Data, Complex Data Machine Learning: Classification},
  archive   = {C_IJCAI},
  author    = {Jing Huang and Jie Yang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/353},
  pages     = {2563-2569},
  title     = {UniGNN: A unified framework for graph and hypergraph neural networks},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Behavior mimics distribution: Combining individual and group
behaviors for federated learning. <em>IJCAI</em>, 2556–2562. (<a
href="https://doi.org/10.24963/ijcai.2021/352">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Federated Learning (FL) has become an active and promising distributed machine learning paradigm. As a result of statistical heterogeneity, recent studies clearly show that the performance of popular FL methods (e.g., FedAvg) deteriorates dramatically due to the client drift caused by local updates. This paper proposes a novel Federated Learning algorithm (called IGFL), which leverages both Individual and Group behaviors to mimic distribution, thereby improving the ability to deal with heterogeneity. Unlike existing FL methods, our IGFL can be applied to both client and server optimization. As a by-product, we propose a new attention-based federated learning in the server optimization of IGFL. To the best of our knowledge, this is the first time to incorporate attention mechanisms into federated optimization. We conduct extensive experiments and show that IGFL can significantly improve the performance of existing federated learning methods. Especially when the distributions of data among individuals are diverse, IGFL can improve the classification accuracy by about 13\% compared with prior baselines. Keywords: Machine Learning: Deep Learning Data Mining: Federated Learning},
  archive   = {C_IJCAI},
  author    = {Hua Huang and Fanhua Shang and Yuanyuan Liu and Hongying Liu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/352},
  pages     = {2556-2562},
  title     = {Behavior mimics distribution: Combining individual and group behaviors for federated learning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DEEPSPLIT: An efficient splitting method for neural network
verification via indirect effect analysis. <em>IJCAI</em>, 2549–2555.
(<a href="https://doi.org/10.24963/ijcai.2021/351">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose a novel, complete algorithm for the verification and analysis of feed-forward, ReLU-based neural networks. The algorithm, based on symbolic interval propagation, introduces a new method for determining split-nodes which evaluates the indirect effect that splitting has on the relaxations of successor nodes. We combine this with a new efficient linear-programming encoding of the splitting constraints to further improve the algorithm’s performance. The resulting implementation, DeepSplit, achieved speedups of 1–2 orders of magnitude and 21-34\% fewer timeouts when compared to the current SoA toolkits. Keywords: Machine Learning: Deep Learning Multidisciplinary Topics and Applications: Validation and Verification},
  archive   = {C_IJCAI},
  author    = {Patrick Henriksen and Alessio Lomuscio},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/351},
  pages     = {2549-2555},
  title     = {DEEPSPLIT: An efficient splitting method for neural network verification via indirect effect analysis},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Interpretable minority synthesis for imbalanced
classification. <em>IJCAI</em>, 2542–2548. (<a
href="https://doi.org/10.24963/ijcai.2021/350">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper proposes a novel oversampling approach that strives to balance the class priors with a considerably imbalanced data distribution of high dimensionality. The crux of our approach lies in learning interpretable latent representations that can model the synthetic mechanism of the minority samples by using a generative adversarial network(GAN). A Bayesian regularizer is imposed to guide the GAN to extract a set of salient features that are either disentangled or intensionally entangled, with their interplay controlled by a prescribed structure, defined with human-in-the-loop. As such, our GAN enjoys an improved sample complexity, being able to synthesize high-quality minority samples even if the sizes of minority classes are extremely small during training. Empirical studies substantiate that our approach can empower simple classifiers to achieve superior imbalanced classification performance over the state-of-the-art competitors and is robust across various imbalance settings. Code is released in github.com/fudonglin/IMSIC. Keywords: Machine Learning: Learning Generative Models Data Mining: Class Imbalance and Unequal Cost},
  archive   = {C_IJCAI},
  author    = {Yi He and Fudong Lin and Xu Yuan and Nian-Feng Tzeng},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/350},
  pages     = {2542-2548},
  title     = {Interpretable minority synthesis for imbalanced classification},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Beyond the spectrum: Detecting deepfakes via re-synthesis.
<em>IJCAI</em>, 2534–2541. (<a
href="https://doi.org/10.24963/ijcai.2021/349">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The rapid advances in deep generative models over the past years have led to highly realistic media, known as deepfakes, that are commonly indistinguishable from real to human eyes. These advances make assessing the authenticity of visual data increasingly difficult and pose a misinformation threat to the trustworthiness of visual content in general. Although recent work has shown strong detection accuracy of such deepfakes, the success largely relies on identifying frequency artifacts in the generated images, which will not yield a sustainable detection approach as generative models continue evolving and closing the gap to real images. In order to overcome this issue, we propose a novel fake detection that is designed to re-synthesize testing images and extract visual cues for detection. The re-synthesis procedure is flexible, allowing us to incorporate a series of visual tasks - we adopt super-resolution, denoising and colorization as the re-synthesis. We demonstrate the improved effectiveness, cross-GAN generalization, and robustness against perturbations of our approach in a variety of detection scenarios involving multiple generators over CelebA-HQ, FFHQ, and LSUN datasets. Source code is available at https://github.com/SSAW14/BeyondtheSpectrum. Keywords: Machine Learning: Classification Machine Learning: Deep Learning Multidisciplinary Topics and Applications: Security and Privacy},
  archive   = {C_IJCAI},
  author    = {Yang He and Ning Yu and Margret Keuper and Mario Fritz},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/349},
  pages     = {2534-2541},
  title     = {Beyond the spectrum: Detecting deepfakes via re-synthesis},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). State-based recurrent SPMNs for decision-theoretic planning
under partial observability. <em>IJCAI</em>, 2526–2533. (<a
href="https://doi.org/10.24963/ijcai.2021/348">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The sum-product network (SPN) has been extended to model sequence data with the recurrent SPN (RSPN), and to decision-making problems with sum-product-max networks (SPMN). In this paper, we build on the concepts introduced by these extensions and present state-based recurrent SPMNs (S-RSPMNs) as a generalization of SPMNs to sequential decision-making problems where the state may not be perfectly observed. As with recurrent SPNs, S-RSPMNs utilize a repeatable template network to model sequences of arbitrary lengths. We present an algorithm for learning compact template structures by identifying unique belief states and the transitions between them through a state matching process that utilizes augmented data. In our knowledge, this is the first data-driven approach that learns graphical models for planning under partial observability, which can be solved efficiently. S-RSPMNs retain the linear solution complexity of SPMNs, and we demonstrate significant improvements in compactness of representation and the run time of structure learning and inference in sequential domains. Keywords: Machine Learning: Learning Graphical Models Planning and Scheduling: Model-Based Reasoning Planning and Scheduling: Planning under Uncertainty},
  archive   = {C_IJCAI},
  author    = {Layton Hayes and Prashant Doshi and Swaraj Pawar and Hari Teja Tatavarti},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/348},
  pages     = {2526-2533},
  title     = {State-based recurrent SPMNs for decision-theoretic planning under partial observability},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Model-based reinforcement learning for infinite-horizon
discounted constrained markov decision processes. <em>IJCAI</em>,
2519–2525. (<a href="https://doi.org/10.24963/ijcai.2021/347">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In many real-world reinforcement learning (RL) problems, in addition to maximizing the objective, the learning agent has to maintain some necessary safety constraints. We formulate the problem of learning a safe policy as an infinite-horizon discounted Constrained Markov Decision Process (CMDP) with an unknown transition probability matrix, where the safety requirements are modeled as constraints on expected cumulative costs. We propose two model-based constrained reinforcement learning (CRL) algorithms for learning a safe policy, namely, (i) GM-CRL algorithm, where the algorithm has access to a generative model, and (ii) UC-CRL algorithm, where the algorithm learns the model using an upper confidence style online exploration method. We characterize the sample complexity of these algorithms, i.e., the the number of samples needed to ensure a desired level of accuracy with high probability, both with respect to objective maximization and constraint satisfaction. Keywords: Machine Learning: Reinforcement Learning Planning and Scheduling: Markov Decisions Processes},
  archive   = {C_IJCAI},
  author    = {Aria HasanzadeZonuzy and Dileep Kalathil and Srinivas Shakkottai},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/347},
  pages     = {2519-2525},
  title     = {Model-based reinforcement learning for infinite-horizon discounted constrained markov decision processes},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fine-grained air quality inference via multi-channel
attention model. <em>IJCAI</em>, 2512–2518. (<a
href="https://doi.org/10.24963/ijcai.2021/346">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we study the problem of fine-grained air quality inference that predicts the air quality level of any location from air quality readings of nearby monitoring stations. We point out the importance of explicitly modeling both static and dynamic spatial correlations, and consequently propose a novel multi-channel attention model (MCAM) that models static and dynamic spatial correlations as separate channels. The static channel combines the beauty of attention mechanisms and graph-based spatial modeling via an adapted bilateral filtering technique, which considers not only locations&#39; Euclidean distances but also their similarity of geo-context features. The dynamic channel learns stations&#39; time-dependent spatial influence on a target location at each time step via long short-term memory (LSTM) networks and attention mechanisms. In addition, we introduce two novel ideas, atmospheric dispersion theories and the hysteretic nature of air pollutant dispersion, to better model the dynamic spatial correlation. We also devise a multi-channel graph convolutional fusion network to effectively fuse the graph outputs, along with other features, from both channels. Our extensive experiments on real-world benchmark datasets demonstrate that MCAM significantly outperforms the state-of-the-art solutions. Keywords: Machine Learning: Time-series; Data Streams},
  archive   = {C_IJCAI},
  author    = {Qilong Han and Dan Lu and Rui Chen},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/346},
  pages     = {2512-2518},
  title     = {Fine-grained air quality inference via multi-channel attention model},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Riemannian stochastic recursive momentum method for
non-convex optimization. <em>IJCAI</em>, 2505–2511. (<a
href="https://doi.org/10.24963/ijcai.2021/345">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose a stochastic recursive momentum method for Riemannian non-convex optimization that achieves a nearly-optimal complexity to find epsilon-approximate solution with one sample. The new algorithm requires one-sample gradient evaluations per iteration and does not require restarting with a large batch gradient, which is commonly used to obtain a faster rate. Extensive experiment results demonstrate the superiority of the proposed algorithm. Extensions to nonsmooth and constrained optimization settings are also discussed. Keywords: Machine Learning: Online Learning},
  archive   = {C_IJCAI},
  author    = {Andi Han and Junbin Gao},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/345},
  pages     = {2505-2511},
  title     = {Riemannian stochastic recursive momentum method for non-convex optimization},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Enabling retrain-free deep neural network pruning using
surrogate lagrangian relaxation. <em>IJCAI</em>, 2497–2504. (<a
href="https://doi.org/10.24963/ijcai.2021/344">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Network pruning is a widely used technique to reduce computation cost and model size for deep neural networks. However, the typical three-stage pipeline, i.e., training, pruning and retraining (fine-tuning) significantly increases the overall training trails. In this paper, we develop a systematic weight-pruning optimization approach based on Surrogate Lagrangian relaxation (SLR), which is tailored to overcome difficulties caused by the discrete nature of the weight-pruning problem while ensuring fast convergence. We further accelerate the convergence of the SLR by using quadratic penalties. Model parameters obtained by SLR during the training phase are much closer to their optimal values as compared to those obtained by other state-of-the-art methods. We evaluate the proposed method on image classification tasks using CIFAR-10 and ImageNet, as well as object detection tasks using COCO 2014 and Ultra-Fast-Lane-Detection using TuSimple lane detection dataset. Experimental results demonstrate that our SLR-based weight-pruning optimization approach achieves higher compression rate than state-of-the-arts under the same accuracy requirement. It also achieves a high model accuracy even at the hard-pruning stage without retraining (reduces the traditional three-stage pruning to two-stage). Given a limited budget of retraining epochs, our approach quickly recovers the model accuracy. Keywords: Machine Learning: Deep Learning Computer Vision: 2D and 3D Computer Vision Machine Learning Applications: Networks},
  archive   = {C_IJCAI},
  author    = {Deniz Gurevin and Mikhail Bragin and Caiwen Ding and Shanglin Zhou and Lynn Pepin and Bingbing Li and Fei Miao},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/344},
  pages     = {2497-2504},
  title     = {Enabling retrain-free deep neural network pruning using surrogate lagrangian relaxation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust regularization with adversarial labelling of
perturbed samples. <em>IJCAI</em>, 2490–2496. (<a
href="https://doi.org/10.24963/ijcai.2021/343">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent researches have suggested that the predictive accuracy of neural network may contend with its adversarial robustness. This presents challenges in designing effective regularization schemes that also provide strong adversarial robustness. Revisiting Vicinal Risk Minimization (VRM) as a unifying regularization principle, we propose Adversarial Labelling of Perturbed Samples (ALPS) as a regularization scheme that aims at improving the generalization ability and adversarial robustness of the trained model. ALPS trains neural networks with synthetic samples formed by perturbing each authentic input sample towards another one along with an adversarially assigned label. The ALPS regularization objective is formulated as a min-max problem, in which the outer problem is minimizing an upper-bound of the VRM loss, and the inner problem is L1-ball constrained adversarial labelling on perturbed sample. The analytic solution to the induced inner maximization problem is elegantly derived, which enables computational efficiency. Experiments on the SVHN, CIFAR-10, CIFAR-100 and Tiny-ImageNet datasets show that the ALPS has a state-of-the-art regularization performance while also serving as an effective adversarial training scheme. Keywords: Machine Learning: Adversarial Machine Learning Machine Learning: Classification},
  archive   = {C_IJCAI},
  author    = {Xiaohui Guo and Richong Zhang and Yaowei Zheng and Yongyi Mao},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/343},
  pages     = {2490-2496},
  title     = {Robust regularization with adversarial labelling of perturbed samples},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DA-GCN: A domain-aware attentive graph convolution network
for shared-account cross-domain sequential recommendation.
<em>IJCAI</em>, 2483–2489. (<a
href="https://doi.org/10.24963/ijcai.2021/342">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Shared-account Cross-domain Sequential Recommendation (SCSR) is the task of recommending the next item based on a sequence of recorded user behaviors, where multiple users share a single account, and their behaviours are available in multiple domains. Existing work on solving SCSR mainly relies on mining sequential patterns via RNN-based models, which are not expressive enough to capture the relationships among multiple entities. Moreover, all existing algorithms try to bridge two domains via knowledge transfer in the latent space, and the explicit cross-domain graph structure is unexploited. In this work, we propose a novel graph-based solution, namely DA-GCN, to address the above challenges. Specifically, we first link users and items in each domain as a graph. Then, we devise a domain-aware graph convolution network to learn user-specific node representations. To fully account for users&#39; domain-specific preferences on items, two novel attention mechanisms are further developed to selectively guide the message passing process. Extensive experiments on two real-world datasets are conducted to demonstrate the superiority of our DA-GCN method. Keywords: Machine Learning: Recommender Systems Humans and AI: Personalization and User Modeling Data Mining: Information Retrieval},
  archive   = {C_IJCAI},
  author    = {Lei Guo and Li Tang and Tong Chen and Lei Zhu and Quoc Viet Hung Nguyen and Hongzhi Yin},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/342},
  pages     = {2483-2489},
  title     = {DA-GCN: A domain-aware attentive graph convolution network for shared-account cross-domain sequential recommendation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hindsight value function for variance reduction in
stochastic dynamic environment. <em>IJCAI</em>, 2476–2482. (<a
href="https://doi.org/10.24963/ijcai.2021/341">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Policy gradient methods are appealing in deep reinforcement learning but suffer from high variance of gradient estimate. To reduce the variance, the state value function is applied commonly. However, the effect of the state value function becomes limited in stochastic dynamic environments, where the unexpected state dynamics and rewards will increase the variance. In this paper, we propose to replace the state value function with a novel hindsight value function, which leverages the information from the future to reduce the variance of the gradient estimate for stochastic dynamic environments. Particularly, to obtain an ideally unbiased gradient estimate, we propose an information-theoretic approach, which optimizes the embeddings of the future to be independent of previous actions. In our experiments, we apply the proposed hindsight value function in stochastic dynamic environments, including discrete-action environments and continuous-action environments. Compared with the standard state value function, the proposed hindsight value function consistently reduces the variance, stabilizes the training, and improves the eventual policy. Keywords: Machine Learning: Deep Learning Machine Learning: Deep Reinforcement Learning Uncertainty in AI: Sequential Decision Making},
  archive   = {C_IJCAI},
  author    = {Jiaming Guo and Rui Zhang and Xishan Zhang and Shaohui Peng and Qi Yi and Zidong Du and Xing Hu and Qi Guo and Yunji Chen},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/341},
  pages     = {2476-2482},
  title     = {Hindsight value function for variance reduction in stochastic dynamic environment},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards understanding deep learning from noisy labels with
small-loss criterion. <em>IJCAI</em>, 2469–2475. (<a
href="https://doi.org/10.24963/ijcai.2021/340">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep neural networks need large amounts of labeled data to achieve good performance. In real-world applications, labels are usually collected from non-experts such as crowdsourcing to save cost and thus are noisy. In the past few years, deep learning methods for dealing with noisy labels have been developed, many of which are based on the small-loss criterion. However, there are few theoretical analyses to explain why these methods could learn well from noisy labels. In this paper, we theoretically explain why the widely-used small-loss criterion works. Based on the explanation, we reformalize the vanilla small-loss criterion to better tackle noisy labels. The experimental results verify our theoretical explanation and also demonstrate the effectiveness of the reformalization. Keywords: Machine Learning: Weakly Supervised Learning Machine Learning: Deep Learning Machine Learning: Classification Machine Learning: Learning Theory},
  archive   = {C_IJCAI},
  author    = {Xian-Jin Gui and Wei Wang and Zhang-Hao Tian},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/340},
  pages     = {2469-2475},
  title     = {Towards understanding deep learning from noisy labels with small-loss criterion},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning nash equilibria in zero-sum stochastic games via
entropy-regularized policy approximation. <em>IJCAI</em>, 2462–2468. (<a
href="https://doi.org/10.24963/ijcai.2021/339">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We explore the use of policy approximations to reduce the computational cost of learning Nash equilibria in zero-sum stochastic games. We propose a new Q-learning type algorithm that uses a sequence of entropy-regularized soft policies to approximate the Nash policy during the Q-function updates. We prove that under certain conditions, by updating the entropy regularization, the algorithm converges to a Nash equilibrium. We also demonstrate the proposed algorithm&#39;s ability to transfer previous training experiences, enabling the agents to adapt quickly to new environments. We provide a dynamic hyper-parameter scheduling scheme to further expedite convergence. Empirical results applied to a number of stochastic games verify that the proposed algorithm converges to the Nash equilibrium, while exhibiting a major speed-up over existing algorithms. Keywords: Machine Learning: Reinforcement Learning Agent-based and Multi-agent Systems: Multi-agent Learning Agent-based and Multi-agent Systems: Noncooperative Games},
  archive   = {C_IJCAI},
  author    = {Yue Guan and Qifan Zhang and Panagiotis Tsiotras},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/339},
  pages     = {2462-2468},
  title     = {Learning nash equilibria in zero-sum stochastic games via entropy-regularized policy approximation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The successful ingredients of policy gradient algorithms.
<em>IJCAI</em>, 2455–2461. (<a
href="https://doi.org/10.24963/ijcai.2021/338">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Despite the sublime success in recent years, the underlying mechanisms powering the advances of reinforcement learning are yet poorly understood. In this paper, we identify these mechanisms - which we call ingredients - in on-policy policy gradient methods and empirically determine their impact on the learning. To allow an equitable assessment, we conduct our experiments based on a unified and modular implementation. Our results underline the significance of recent algorithmic advances and demonstrate that reaching state-of-the-art performance may not need sophisticated algorithms but can also be accomplished by the combination of a few simple ingredients. Keywords: Machine Learning: Deep Reinforcement Learning AI Ethics, Trust, Fairness: Reproducibility Multidisciplinary Topics and Applications: Validation and Verification},
  archive   = {C_IJCAI},
  author    = {Sven Gronauer and Martin Gottwald and Klaus Diepold},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/338},
  pages     = {2455-2461},
  title     = {The successful ingredients of policy gradient algorithms},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hierarchical class-based curriculum loss. <em>IJCAI</em>,
2448–2454. (<a href="https://doi.org/10.24963/ijcai.2021/337">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Classification algorithms in machine learning often assume a flat label space. However, most real world data have dependencies between the labels, which can often be captured by using a hierarchy. Utilizing this relation can help develop a model capable of satisfying the dependencies and improving model accuracy and interpretability. Further, as different levels in the hierarchy correspond to different granularities, penalizing each label equally can be detrimental to model learning. In this paper, we propose a loss function, hierarchical curriculum loss, with two properties: (i) satisfy hierarchical constraints present in the label space, and (ii) provide non-uniform weights to labels based on their levels in the hierarchy, learned implicitly by the training paradigm. We theoretically show that the proposed hierarchical class-based curriculum loss is a tight bound of 0-1 loss among all losses satisfying the hierarchical constraints. We test our loss function on real world image data sets, and show that it significantly outperforms state-of-the-art baselines. Keywords: Machine Learning: Classification Machine Learning: Multi-instance; Multi-label; Multi-view learning Machine Learning: Deep Learning},
  archive   = {C_IJCAI},
  author    = {Palash Goyal and Divya Choudhary and Shalini Ghosh},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/337},
  pages     = {2448-2454},
  title     = {Hierarchical class-based curriculum loss},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). InverseNet: Augmenting model extraction attacks with
training data inversion. <em>IJCAI</em>, 2439–2447. (<a
href="https://doi.org/10.24963/ijcai.2021/336">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Cloud service providers, including Google, Amazon, and Alibaba, have now launched machine-learning-as-a-service (MLaaS) platforms, allowing clients to access sophisticated cloud-based machine learning models via APIs. Unfortunately, however, the commercial value of these models makes them alluring targets for theft, and their strategic position as part of the IT infrastructure of many companies makes them an enticing springboard for conducting further adversarial attacks. In this paper, we put forth a novel and effective attack strategy, dubbed InverseNet, that steals the functionality of black-box cloud-based models with only a small number of queries. The crux of the innovation is that, unlike existing model extraction attacks that rely on public datasets or adversarial samples, InverseNet constructs inversed training samples to increase the similarity between the extracted substitute model and the victim model. Further, only a small number of data samples with high confidence scores (rather than an entire dataset) are used to reconstruct the inversed dataset, which substantially reduces the attack cost. Extensive experiments conducted on three simulated victim models and Alibaba Cloud&#39;s commercially-available API demonstrate that InverseNet yields a model with significantly greater functional similarity to the victim model than the current state-of-the-art attacks at a substantially lower query budget. Keywords: Machine Learning: Adversarial Machine Learning Machine Learning: Deep Learning Multidisciplinary Topics and Applications: Security and Privacy},
  archive   = {C_IJCAI},
  author    = {Xueluan Gong and Yanjiao Chen and Wenbin Yang and Guanghao Mei and Qian Wang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/336},
  pages     = {2439-2447},
  title     = {InverseNet: Augmenting model extraction attacks with training data inversion},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fast multi-label learning. <em>IJCAI</em>, 2432–2438. (<a
href="https://doi.org/10.24963/ijcai.2021/335">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Embedding approaches have become one of the most pervasive techniques for multi-label classification. However, the training process of embedding methods usually involves a complex quadratic or semidefinite programming problem, or the model may even involve an NP-hard problem. Thus, such methods are prohibitive on large-scale applications. More importantly, much of the literature has already shown that the binary relevance (BR) method is usually good enough for some applications. Unfortunately, BR runs slowly due to its linear dependence on the size of the input data. The goal of this paper is to provide a simple method, yet with provable guarantees, which can achieve competitive performance without a complex training process. To achieve our goal, we provide a simple stochastic sketch strategy for multi-label classification and present theoretical results from both algorithmic and statistical learning perspectives. Our comprehensive empirical studies corroborate our theoretical findings and demonstrate the superiority of the proposed methods. Keywords: Machine Learning: Multi-instance; Multi-label; Multi-view learning},
  archive   = {C_IJCAI},
  author    = {Xiuwen Gong and Dong Yuan and Wei Bao},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/335},
  pages     = {2432-2438},
  title     = {Fast multi-label learning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bayesian experience reuse for learning from multiple
demonstrators. <em>IJCAI</em>, 2425–2431. (<a
href="https://doi.org/10.24963/ijcai.2021/334">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Learning from Demonstrations (LfD) is a powerful approach for incorporating advice from experts in the form of demonstrations. However, demonstrations often come from multiple sub-optimal experts with conflicting goals, rendering them difficult to incorporate effectively in online settings. To address this, we formulate a quadratic program whose solution yields an adaptive weighting over experts, that can be used to sample experts with relevant goals. In order to compare different source and target task goals safely, we model their uncertainty using normal-inverse-gamma priors, whose posteriors are learned from demonstrations using Bayesian neural networks with a shared encoder. Our resulting approach, which we call Bayesian Experience Reuse, can be applied for LfD in static and dynamic decision-making settings. We demonstrate its effectiveness for minimizing multi-modal functions, and optimizing a high-dimensional supply chain with cost uncertainty, where it is also shown to improve upon the performance of the demonstrators&#39; policies. Keywords: Machine Learning: Deep Reinforcement Learning Machine Learning: Transfer, Adaptation, Multi-task Learning Uncertainty in AI: Approximate Probabilistic Inference Uncertainty in AI: Bayesian Networks},
  archive   = {C_IJCAI},
  author    = {Mike Gimelfarb and Scott Sanner and Chi-Guhn Lee},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/334},
  pages     = {2425-2431},
  title     = {Bayesian experience reuse for learning from multiple demonstrators},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Method of moments for topic models with mixed discrete and
continuous features. <em>IJCAI</em>, 2418–2424. (<a
href="https://doi.org/10.24963/ijcai.2021/333">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Topic models are characterized by a latent class variable that represents the different topics. Traditionally, their observable variables are modeled as discrete variables like, for instance, in the prototypical latent Dirichlet allocation (LDA) topic model. In LDA, words in text documents are encoded by discrete count vectors with respect to some dictionary. The classical approach for learning topic models optimizes a likelihood function that is non-concave due to the presence of the latent variable. Hence, this approach mostly boils down to using search heuristics like the EM algorithm for parameter estimation. Recently, it was shown that topic models can be learned with strong algorithmic and statistical guarantees through Pearson&#39;s method of moments. Here, we extend this line of work to topic models that feature discrete as well as continuous observable variables (features). Moving beyond discrete variables as in LDA allows for more sophisticated features and a natural extension of topic models to other modalities than text, like, for instance, images. We provide algorithmic and statistical guarantees for the method of moments applied to the extended topic model that we corroborate experimentally on synthetic data. We also demonstrate the applicability of our model on real-world document data with embedded images that we preprocess into continuous state-of-the-art feature vectors. Keywords: Machine Learning: Learning Generative Models Machine Learning: Probabilistic Machine Learning Machine Learning: Unsupervised Learning},
  archive   = {C_IJCAI},
  author    = {Joachim Giesen and Paul Kahlmeyer and Sören Laue and Matthias Mitterreiter and Frank Nussbaum and Christoph Staudt and Sina Zarrieß},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/333},
  pages     = {2418-2424},
  title     = {Method of moments for topic models with mixed discrete and continuous features},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). BOBCAT: Bilevel optimization-based computerized adaptive
testing. <em>IJCAI</em>, 2410–2417. (<a
href="https://doi.org/10.24963/ijcai.2021/332">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Computerized adaptive testing (CAT) refers to a form of tests that are personalized to every student/test taker. CAT methods adaptively select the next most informative question/item for each student given their responses to previous questions, effectively reducing test length. Existing CAT methods use item response theory (IRT) models to relate student ability to their responses to questions and static question selection algorithms designed to reduce the ability estimation error as quickly as possible; therefore, these algorithms cannot improve by learning from large-scale student response data. In this paper, we propose BOBCAT, a Bilevel Optimization-Based framework for CAT to directly learn a data-driven question selection algorithm from training data. BOBCAT is agnostic to the underlying student response model and is computationally efficient during the adaptive testing process. Through extensive experiments on five real-world student response datasets, we show that BOBCAT outperforms existing CAT methods (sometimes significantly) at reducing test length. Keywords: Machine Learning: Transfer, Adaptation, Multi-task Learning Humans and AI: Computer-Aided Education Humans and AI: Personalization and User Modeling},
  archive   = {C_IJCAI},
  author    = {Aritra Ghosh and Andrew Lan},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/332},
  pages     = {2410-2417},
  title     = {BOBCAT: Bilevel optimization-based computerized adaptive testing},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Video summarization via label distributions dual-reward.
<em>IJCAI</em>, 2403–2409. (<a
href="https://doi.org/10.24963/ijcai.2021/331">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Reinforcement learning maps from perceived state representation to actions, which is adopted to solve the video summarization problem. The reward is crucial for deal with the video summarization task via reinforcement learning, since the reward signal defines the goal of video summarization. However, existing reward mechanism in reinforcement learning cannot handle the ambiguity which appears frequently in video summarization, i.e., the diverse consciousness by different people on the same video. To solve this problem, in this paper label distributions are mapped from the CNN and LSTM-based state representation to capture the subjectiveness of video summaries. The dual-reward is designed by measuring the similarity between user score distributions and the generated label distributions. Not only the average score but also the the variance of the subjective opinions are considered in summary generation. Experimental results on several benchmark datasets show that our proposed method outperforms other approaches under various settings. Keywords: Machine Learning: Multi-instance; Multi-label; Multi-view learning Machine Learning Applications: Applications of Reinforcement Learning},
  archive   = {C_IJCAI},
  author    = {Yongbiao Gao and Ning Xu and Xin Geng},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/331},
  pages     = {2403-2409},
  title     = {Video summarization via label distributions dual-reward},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning groupwise explanations for black-box models.
<em>IJCAI</em>, 2396–2402. (<a
href="https://doi.org/10.24963/ijcai.2021/330">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study two user demands that are important during the exploitation of explanations in practice: 1) understanding the overall model behavior faithfully with limited cognitive load and 2) predicting the model behavior accurately on unseen instances. We illustrate that the two user demands correspond to two major sub-processes in the human cognitive process and propose a unified framework to fulfill them simultaneously. Given a local explanation method, our framework jointly 1) learns a limited number of groupwise explanations that interpret the model behavior on most instances with high fidelity and 2) specifies the region where each explanation applies. Experiments on six datasets demonstrate the effectiveness of our method. Keywords: Machine Learning: Explainable/Interpretable Machine Learning},
  archive   = {C_IJCAI},
  author    = {Jingyue Gao and Xiting Wang and Yasha Wang and Yulan Yan and Xing Xie},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/330},
  pages     = {2396-2402},
  title     = {Learning groupwise explanations for black-box models},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the convergence of stochastic compositional gradient
descent ascent method. <em>IJCAI</em>, 2389–2395. (<a
href="https://doi.org/10.24963/ijcai.2021/329">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The compositional minimax problem covers plenty of machine learning models such as the distributionally robust compositional optimization problem. However, it is yet another understudied problem to optimize the compositional minimax problem. In this paper, we develop a novel efficient stochastic compositional gradient descent ascent method for optimizing the compositional minimax problem. Moreover, we establish the theoretical convergence rate of our proposed method. To the best of our knowledge, this is the first work achieving such a convergence rate for the compositional minimax problem. Finally, we conduct extensive experiments to demonstrate the effectiveness of our proposed method. Keywords: Machine Learning: Adversarial Machine Learning Machine Learning: Cost-Sensitive Learning},
  archive   = {C_IJCAI},
  author    = {Hongchang Gao and Xiaoqian Wang and Lei Luo and Xinghua Shi},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/329},
  pages     = {2389-2395},
  title     = {On the convergence of stochastic compositional gradient descent ascent method},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep reinforcement learning for multi-contact motion
planning of hexapod robots. <em>IJCAI</em>, 2381–2388. (<a
href="https://doi.org/10.24963/ijcai.2021/328">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Legged locomotion in a complex environment requires careful planning of the footholds of legged robots. In this paper, a novel Deep Reinforcement Learning (DRL) method is proposed to implement multi-contact motion planning for hexapod robots moving on uneven plum-blossom piles. First, the motion of hexapod robots is formulated as a Markov Decision Process (MDP) with a speciﬁed reward function. Second, a transition feasibility model is proposed for hexapod robots, which describes the feasibility of the state transition under the condition of satisfying kinematics and dynamics, and in turn determines the rewards. Third, the footholds and Center-of-Mass (CoM) sequences are sampled from a diagonal Gaussian distribution and the sequences are optimized through learning the optimal policies using the designed DRL algorithm. Both of the simulation and experimental results on physical systems demonstrate the feasibility and efficiency of the proposed method. Videos are shown at https://videoviewpage.wixsite.com/mcrl. Keywords: Machine Learning: Deep Reinforcement Learning Robotics: Learning in Robotics Robotics: Motion and Path Planning},
  archive   = {C_IJCAI},
  author    = {Huiqiao Fu and Kaiqiang Tang and Peng Li and Wenqi Zhang and Xinpeng Wang and Guizhou Deng and Tao Wang and Chunlin Chen},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/328},
  pages     = {2381-2388},
  title     = {Deep reinforcement learning for multi-contact motion planning of hexapod robots},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Contrastive model invertion for data-free knolwedge
distillation. <em>IJCAI</em>, 2374–2380. (<a
href="https://doi.org/10.24963/ijcai.2021/327">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Model inversion, whose goal is to recover training data from a pre-trained model, has been recently proved feasible. However, existing inversion methods usually suffer from the mode collapse problem, where the synthesized instances are highly similar to each other and thus show limited effectiveness for downstream tasks, such as knowledge distillation. In this paper, we propose Contrastive Model Inversion (CMI), where the data diversity is explicitly modeled as an optimizable objective, to alleviate the mode collapse issue. Our main observation is that, under the constraint of the same amount of data, higher data diversity usually indicates stronger instance discrimination. To this end, we introduce in CMI a contrastive learning objective that encourages the synthesizing instances to be distinguishable from the already synthesized ones in previous batches. Experiments of pre-trained models on CIFAR-10, CIFAR-100, and Tiny-ImageNet demonstrate that CMI not only generates more visually plausible instances than the state of the arts, but also achieves significantly superior performance when the generated data are used for knowledge distillation. Code is available at https://github.com/zju-vipa/DataFree. Keywords: Machine Learning: Deep Learning Machine Learning: Explainable/Interpretable Machine Learning Machine Learning: Transfer, Adaptation, Multi-task Learning},
  archive   = {C_IJCAI},
  author    = {Gongfan Fang and Jie Song and Xinchao Wang and Chengchao Shen and Xingen Wang and Mingli Song},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/327},
  pages     = {2374-2380},
  title     = {Contrastive model invertion for data-free knolwedge distillation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). BAMBOO: A multi-instance multi-label approach towards VDI
user logon behavior modeling. <em>IJCAI</em>, 2367–2373. (<a
href="https://doi.org/10.24963/ijcai.2021/326">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Different to traditional on-premise VDI , the virtual desktops in DaaS (Desktop as a Service) are hosted in public cloud where virtual machines are charged based on usage. Accordingly, an adaptive power management system which can turn off spare virtual machines without sacrificing end user experience is of significant customer value as it can greatly help reduce the running cost. Generally, logon behavior modeling for VDI users serves as the key enabling-technique to fulfill intelligent power management. Prior attempts work by modeling logon behavior in a user-dependent manner with tailored single-instance feature representation, where the strong relationships among pool-sharing VDI users are ignored in the modeling framework. In this paper, a novel formulation towards VDI user logon behavior modeling is proposed by employing the multi-instance multi-label (MIML) techniques. Specifically, each user is grouped with supporting users whose behaviors are jointly modeled in the feature space with multi-instance representation as well as in the output space with multi-label prediction. The resulting MIML formulation is optimized by adapting the popular MIML boosting procedure via balanced error-rate minimization. Experimental studies on real VDI customers&#39; data clearly validate the effectiveness of the proposed MIML-based approach against state-of-the-art VDI user logon behavior modeling techniques. Keywords: Machine Learning: Classification Machine Learning: Multi-instance; Multi-label; Multi-view learning Machine Learning Applications: Applications of Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Wenping Fan and Yao Zhang and Qichen Hao and Xinya Wu and Min-Ling Zhang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/326},
  pages     = {2367-2373},
  title     = {BAMBOO: A multi-instance multi-label approach towards VDI user logon behavior modeling},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Jointly learning prices and product features.
<em>IJCAI</em>, 2360–2366. (<a
href="https://doi.org/10.24963/ijcai.2021/325">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Product Design is an important problem in marketing research where a firm tries to learn what features of a product are more valuable to consumers. We study this problem from the viewpoint of online learning: a firm repeatedly interacts with a buyer by choosing a product configuration as well as a price and observing the buyer&#39;s purchasing decision. The goal of the firm is to maximize revenue throughout the course of $T$ rounds by learning the buyer&#39;s preferences. We study both the case of a set of discrete products and the case of a continuous set of allowable product features. In both cases we provide nearly tight upper and lower regret bounds. Keywords: Machine Learning: Online Learning Agent-based and Multi-agent Systems: Economic Paradigms, Auctions and Market-Based Systems},
  archive   = {C_IJCAI},
  author    = {Ehsan Emamjomeh-Zadeh and Renato Paes Leme and Jon Schneider and Balasubramanian Sivan},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/325},
  pages     = {2360-2366},
  title     = {Jointly learning prices and product features},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Time-series representation learning via temporal and
contextual contrasting. <em>IJCAI</em>, 2352–2359. (<a
href="https://doi.org/10.24963/ijcai.2021/324">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Learning decent representations from unlabeled time-series data with temporal dynamics is a very challenging task. In this paper, we propose an unsupervised Time-Series representation learning framework via Temporal and Contextual Contrasting (TS-TCC), to learn time-series representation from unlabeled data. First, the raw time-series data are transformed into two different yet correlated views by using weak and strong augmentations. Second, we propose a novel temporal contrasting module to learn robust temporal representations by designing a tough cross-view prediction task. Last, to further learn discriminative representations, we propose a contextual contrasting module built upon the contexts from the temporal contrasting module. It attempts to maximize the similarity among different contexts of the same sample while minimizing similarity among contexts of different samples. Experiments have been carried out on three real-world time-series datasets. The results manifest that training a linear classifier on top of the features learned by our proposed TS-TCC performs comparably with the supervised training. Additionally, our proposed TS-TCC shows high efficiency in few-labeled data and transfer learning scenarios. The code is publicly available at https://github.com/emadeldeen24/TS-TCC. Keywords: Machine Learning: Deep Learning Machine Learning: Semi-Supervised Learning Machine Learning: Time-series; Data Streams},
  archive   = {C_IJCAI},
  author    = {Emadeldeen Eldele and Mohamed Ragab and Zhenghua Chen and Min Wu and Chee Keong Kwoh and Xiaoli Li and Cuntai Guan},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/324},
  pages     = {2352-2359},
  title     = {Time-series representation learning via temporal and contextual contrasting},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automatic translation of music-to-dance for in-game
characters. <em>IJCAI</em>, 2344–2351. (<a
href="https://doi.org/10.24963/ijcai.2021/323">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Music-to-dance translation is an emerging and powerful feature in recent role-playing games. Previous works of this topic consider music-to-dance as a supervised motion generation problem based on time-series data. However, these methods require a large amount of training data pairs and may suffer from the degradation of movements. This paper provides a new solution to this task where we re-formulate the translation as a piece-wise dance phrase retrieval problem based on the choreography theory. With such a design, players are allowed to optionally edit the dance movements on top of our generation while other regression-based methods ignore such user interactivity. Considering that the dance motion capture is expensive that requires the assistance of professional dancers, we train our method under a semi-supervised learning fashion with a large unlabeled music dataset (20x than our labeled one) and also introduce self-supervised pre-training to improve the training stability and generalization performance. Experimental results suggest that our method not only generalizes well over various styles of music but also succeeds in choreography for game players. Our project including the large-scale dataset and supplemental materials is available at https://github.com/FuxiCV/music-to-dance. Keywords: Machine Learning: Semi-Supervised Learning Machine Learning Applications: Applications of Supervised Learning Multidisciplinary Topics and Applications: Art and Music},
  archive   = {C_IJCAI},
  author    = {Yinglin Duan and Tianyang Shi and Zhipeng Hu and Zhengxia Zou and Changjie Fan and Yi Yuan and Xi Li},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/323},
  pages     = {2344-2351},
  title     = {Automatic translation of music-to-dance for in-game characters},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Boosting variational inference with locally adaptive
step-sizes. <em>IJCAI</em>, 2337–2343. (<a
href="https://doi.org/10.24963/ijcai.2021/322">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Variational Inference makes a trade-off between the capacity of the variational family and the tractability of finding an approximate posterior distribution. Instead, Boosting Variational Inference allows practitioners to obtain increasingly good posterior approximations by spending more compute. The main obstacle to widespread adoption of Boosting Variational Inference is the amount of resources necessary to improve over a strong Variational Inference baseline. In our work, we trace this limitation back to the global curvature of the KL-divergence. We characterize how the global curvature impacts time and memory consumption, address the problem with the notion of local curvature, and provide a novel approximate backtracking algorithm for estimating local curvature. We give new theoretical convergence rates for our algorithms and provide experimental validation on synthetic and real-world datasets. Keywords: Machine Learning: Bayesian Learning Machine Learning: Probabilistic Machine Learning},
  archive   = {C_IJCAI},
  author    = {Gideon Dresdner and Saurav Shekhar and Fabian Pedregosa and Francesco Locatello and Gunnar Rätsch},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/322},
  pages     = {2337-2343},
  title     = {Boosting variational inference with locally adaptive step-sizes},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal ANN-SNN conversion for fast and accurate inference
in deep spiking neural networks. <em>IJCAI</em>, 2328–2336. (<a
href="https://doi.org/10.24963/ijcai.2021/321">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Spiking Neural Networks (SNNs), as bio-inspired energy-efficient neural networks, have attracted great attentions from researchers and industry. The most efficient way to train deep SNNs is through ANN-SNN conversion. However, the conversion usually suffers from accuracy loss and long inference time, which impede the practical application of SNN. In this paper, we theoretically analyze ANN-SNN conversion and derive sufficient conditions of the optimal conversion. To better correlate ANN-SNN and get greater accuracy, we propose Rate Norm Layer to replace the ReLU activation function in source ANN training, enabling direct conversion from a trained ANN to an SNN. Moreover, we propose an optimal fit curve to quantify the fit between the activation value of source ANN and the actual firing rate of target SNN. We show that the inference time can be reduced by optimizing the upper bound of the fit curve in the revised ANN to achieve fast inference. Our theory can explain the existing work on fast reasoning and get better results. The experimental results show that the proposed method achieves near loss-less conversion with VGG-16, PreActResNet-18, and deeper structures. Moreover, it can reach 8.6× faster reasoning performance under 0.265× energy consumption of the typical method. The code is available at https://github.com/DingJianhao/OptSNNConvertion-RNL-RIL. Keywords: Machine Learning: Deep Learning Humans and AI: Cognitive Modeling},
  archive   = {C_IJCAI},
  author    = {Jianhao Ding and Zhaofei Yu and Yonghong Tian and Tiejun Huang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/321},
  pages     = {2328-2336},
  title     = {Optimal ANN-SNN conversion for fast and accurate inference in deep spiking neural networks},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Graph-free knowledge distillation for graph neural networks.
<em>IJCAI</em>, 2321–2327. (<a
href="https://doi.org/10.24963/ijcai.2021/320">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Knowledge distillation (KD) transfers knowledge from a teacher network to a student by enforcing the student to mimic the outputs of the pretrained teacher on training data. However, data samples are not always accessible in many cases due to large data sizes, privacy, or confidentiality. Many efforts have been made on addressing this problem for convolutional neural networks (CNNs) whose inputs lie in a grid domain within a continuous space such as images and videos, but largely overlook graph neural networks (GNNs) that handle non-grid data with different topology structures within a discrete space. The inherent differences between their inputs make these CNN-based approaches not applicable to GNNs. In this paper, we propose to our best knowledge the first dedicated approach to distilling knowledge from a GNN without graph data. The proposed graph-free KD (GFKD) learns graph topology structures for knowledge transfer by modeling them with multinomial distribution. We then introduce a gradient estimator to optimize this framework. Essentially, the gradients w.r.t. graph structures are obtained by only using GNN forward-propagation without back-propagation, which means that GFKD is compatible with modern GNN libraries such as DGL and Geometric. Moreover, we provide the strategies for handling different types of prior knowledge in the graph data or the GNNs. Extensive experiments demonstrate that GFKD achieves the state-of-the-art performance for distilling knowledge from GNNs without training data. Keywords: Machine Learning: Classification Machine Learning: Deep Learning Machine Learning: Transfer, Adaptation, Multi-task Learning},
  archive   = {C_IJCAI},
  author    = {Xiang Deng and Zhongfei Zhang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/320},
  pages     = {2321-2327},
  title     = {Graph-free knowledge distillation for graph neural networks},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Isotonic data augmentation for knowledge distillation.
<em>IJCAI</em>, 2314–2320. (<a
href="https://doi.org/10.24963/ijcai.2021/319">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Knowledge distillation uses both real hard labels and soft labels predicted by teacher model as supervision. Intuitively, we expect the soft label probabilities and hard label probabilities to be concordant. However, in the real knowledge distillations, we found critical rank violations between hard labels and soft labels for augmented samples. For example, for an augmented sample x = 0.7 * cat + 0.3 * panda, a meaningful soft label distribution should have the same rank: P(cat|x)&gt;P(panda|x)&gt;P(other|x). But real teacher models usually violate the rank: P(tiger|x)&gt;P(panda|x)&gt;P(cat|x). We attribute the rank violations to the increased difficulty of understanding augmented samples for the teacher model. Empirically, we found the violations injuries the knowledge transfer. In this paper, we denote eliminating rank violations in data augmentation for knowledge distillation as isotonic data augmentation (IDA). We use isotonic regression (IR) -- a classic statistical algorithm -- to eliminate the rank violations. We show that IDA can be modeled as a tree-structured IR problem and gives an O(c*log(c)) optimal algorithm, where c is the number of labels. In order to further reduce the time complexity of the optimal algorithm, we also proposed a GPU-friendly approximation algorithm with linear time complexity. We have verified on variant datasets and data augmentation baselines that (1) the rank violation is a general phenomenon for data augmentation in knowledge distillation. And (2) our proposed IDA algorithms effectively increases the accuracy of knowledge distillation by solving the ranking violations. Keywords: Machine Learning: Deep Learning Machine Learning: Transfer, Adaptation, Multi-task Learning},
  archive   = {C_IJCAI},
  author    = {Wanyun Cui and Sen Yan},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/319},
  pages     = {2314-2320},
  title     = {Isotonic data augmentation for knowledge distillation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Convexified graph neural networks for distributed control in
robotic swarms. <em>IJCAI</em>, 2307–2313. (<a
href="https://doi.org/10.24963/ijcai.2021/318">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A network of robots can be viewed as a signal graph, describing the underlying network topology with naturally distributed architectures, whose nodes are assigned to data values associated with each robot. Graph neural networks (GNNs) learn representations from signal graphs, thus making them well-suited candidates for learning distributed controllers. Oftentimes, existing GNN architectures assume ideal scenarios, while ignoring the possibility that this distributed graph may change along time due to link failures or topology variations, which can be found in dynamic settings. A mismatch between the graphs on which GNNs were trained and the ones on which they are tested is thus formed. Utilizing online learning, GNNs can be retrained at testing time, overcoming this issue. However, most online algorithms are centralized and work on convex problems (which GNNs scarcely lead to). This paper introduces novel architectures which solve the convexity restriction and can be easily updated in a distributed, online manner. Finally, we provide experiments, showing how these models can be applied to optimizing formation control in a swarm of flocking robots. Keywords: Machine Learning: Deep Learning Machine Learning: Kernel Methods Machine Learning: Online Learning Robotics: Multi-Robot Systems},
  archive   = {C_IJCAI},
  author    = {Saar Cohen and Noa Agmon},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/318},
  pages     = {2307-2313},
  title     = {Convexified graph neural networks for distributed control in robotic swarms},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). CuCo: Graph representation with curriculum contrastive
learning. <em>IJCAI</em>, 2300–2306. (<a
href="https://doi.org/10.24963/ijcai.2021/317">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph-level representation learning is to learn low-dimensional representation for the entire graph, which has shown a large impact on real-world applications. Recently, limited by expensive labeled data, contrastive learning based graph-level representation learning attracts considerable attention. However, these methods mainly focus on graph augmentation for positive samples, while the effect of negative samples is less explored. In this paper, we study the impact of negative samples on learning graph-level representations, and a novel curriculum contrastive learning framework for self-supervised graph-level representation, called CuCo, is proposed. Specifically, we introduce four graph augmentation techniques to obtain the positive and negative samples, and utilize graph neural networks to learn their representations. Then a scoring function is proposed to sort negative samples from easy to hard and a pacing function is to automatically select the negative samples in each training procedure. Extensive experiments on fifteen graph classification real-world datasets, as well as the parameter analysis, well demonstrate that our proposed CuCo yields truly encouraging results in terms of performance on classification and convergence. Keywords: Machine Learning: Unsupervised Learning Data Mining: Feature Extraction, Selection and Dimensionality Reduction Data Mining: Mining Graphs, Semi Structured Data, Complex Data},
  archive   = {C_IJCAI},
  author    = {Guanyi Chu and Xiao Wang and Chuan Shi and Xunqiang Jiang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/317},
  pages     = {2300-2306},
  title     = {CuCo: Graph representation with curriculum contrastive learning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Variational model-based policy optimization. <em>IJCAI</em>,
2292–2299. (<a href="https://doi.org/10.24963/ijcai.2021/316">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Model-based reinforcement learning (RL) algorithms allow us to combine model-generated data with those collected from interaction with the real system in order to alleviate the data efficiency problem in RL. However, designing such algorithms is often challenging because the bias in simulated data may overshadow the ease of data generation. A potential solution to this challenge is to jointly learn and improve model and policy using a universal objective function. In this paper, we leverage the connection between RL and probabilistic inference, and formulate such an objective function as a variational lower-bound of a log-likelihood. This allows us to use expectation maximization (EM) and iteratively fix a baseline policy and learn a variational distribution, consisting of a model and a policy (E-step), followed by improving the baseline policy given the learned variational distribution (M-step). We propose model-based and model-free policy iteration (actor-critic) style algorithms for the E-step and show how the variational distribution learned by them can be used to optimize the M-step in a fully model-based fashion. Our experiments on a number of continuous control tasks show that our model-based (E-step) algorithm, called variational model-based policy optimization (VMBPO), is more sample-efficient and robust to hyper-parameter tuning than its model-free (E-step) counterpart. Using the same control tasks, we also compare VMBPO with several state-of-the-art model-based and model-free RL algorithms and show its sample efficiency and performance. Keywords: Machine Learning: Reinforcement Learning},
  archive   = {C_IJCAI},
  author    = {Yinlam Chow and Brandon Cui and Moonkyung Ryu and Mohammad Ghavamzadeh},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/316},
  pages     = {2292-2299},
  title     = {Variational model-based policy optimization},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Time-aware multi-scale RNNs for time series modeling.
<em>IJCAI</em>, 2285–2291. (<a
href="https://doi.org/10.24963/ijcai.2021/315">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-scale information is crucial for modeling time series. Although most existing methods consider multiple scales in the time-series data, they assume all kinds of scales are equally important for each sample, making them unable to capture the dynamic temporal patterns of time series. To this end, we propose Time-Aware Multi-Scale Recurrent Neural Networks (TAMS-RNNs), which disentangle representations of different scales and adaptively select the most important scale for each sample at each time step. First, the hidden state of the RNN is disentangled into multiple independently updated small hidden states, which use different update frequencies to model time-series multi-scale information. Then, at each time step, the temporal context information is used to modulate the features of different scales, selecting the most important time-series scale. Therefore, the proposed model can capture the multi-scale information for each time series at each time step adaptively. Extensive experiments demonstrate that the model outperforms state-of-the-art methods on multivariate time series classification and human motion prediction tasks. Furthermore, visualized analysis on music genre recognition verifies the effectiveness of the model. Keywords: Machine Learning: Deep Learning Machine Learning: Time-series; Data Streams},
  archive   = {C_IJCAI},
  author    = {Zipeng Chen and Qianli Ma and Zhenxi Lin},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/315},
  pages     = {2285-2291},
  title     = {Time-aware multi-scale RNNs for time series modeling},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On self-distilling graph neural network. <em>IJCAI</em>,
2278–2284. (<a href="https://doi.org/10.24963/ijcai.2021/314">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, the teacher-student knowledge distillation framework has demonstrated its potential in training Graph Neural Networks (GNNs). However, due to the difficulty of training over-parameterized GNN models, one may not easily obtain a satisfactory teacher model for distillation. Furthermore, the inefficient training process of teacher-student knowledge distillation also impedes its applications in GNN models. In this paper, we propose the first teacher-free knowledge distillation method for GNNs, termed GNN Self-Distillation (GNN-SD), that serves as a drop-in replacement of the standard training process. The method is built upon the proposed neighborhood discrepancy rate (NDR), which quantifies the non-smoothness of the embedded graph in an efficient way. Based on this metric, we propose the adaptive discrepancy retaining (ADR) regularizer to empower the transferability of knowledge that maintains high neighborhood discrepancy across GNN layers. We also summarize a generic GNN-SD framework that could be exploited to induce other distillation strategies. Experiments further prove the effectiveness and generalization of our approach, as it brings: 1) state-of-the-art GNN distillation performance with less training cost, 2) consistent and considerable performance enhancement for various popular backbones. Keywords: Machine Learning: Deep Learning Machine Learning: Knowledge Aided Learning Machine Learning: Transfer, Adaptation, Multi-task Learning},
  archive   = {C_IJCAI},
  author    = {Yuzhao Chen and Yatao Bian and Xi Xiao and Yu Rong and Tingyang Xu and Junzhou Huang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/314},
  pages     = {2278-2284},
  title     = {On self-distilling graph neural network},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Few-shot learning with part discovery and augmentation from
unlabeled images. <em>IJCAI</em>, 2271–2277. (<a
href="https://doi.org/10.24963/ijcai.2021/313">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Few-shot learning is a challenging task since only few instances are given for recognizing an unseen class. One way to alleviate this problem is to acquire a strong inductive bias via meta-learning on similar tasks. In this paper, we show that such inductive bias can be learned from a flat collection of unlabeled images, and instantiated as transferable representations among seen and unseen classes. Specifically, we propose a novel part-based self-supervised representation learning scheme to learn transferable representations by maximizing the similarity of an image to its discriminative part. To mitigate the overfitting in few-shot classification caused by data scarcity, we further propose a part augmentation strategy by retrieving extra images from a base dataset. We conduct systematic studies on miniImageNet and tieredImageNet benchmarks. Remarkably, our method yields impressive results, outperforming the previous best unsupervised methods by 7.74\% and 9.24\% under 5-way 1-shot and 5-way 5-shot settings, which are comparable with state-of-the-art supervised methods. Keywords: Machine Learning: Unsupervised Learning Machine Learning: Classification Machine Learning: Deep Learning},
  archive   = {C_IJCAI},
  author    = {Wentao Chen and Chenyang Si and Wei Wang and Liang Wang and Zilei Wang and Tieniu Tan},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/313},
  pages     = {2271-2277},
  title     = {Few-shot learning with part discovery and augmentation from unlabeled images},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dependent multi-task learning with causal intervention for
image captioning. <em>IJCAI</em>, 2263–2270. (<a
href="https://doi.org/10.24963/ijcai.2021/312">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent work for image captioning mainly followed an extract-then-generate paradigm, pre-extracting a sequence of object-based features and then formulating image captioning as a single sequence-to-sequence task. Although promising, we observed two problems in generated captions: 1) content inconsistency where models would generate contradicting facts; 2) not informative enough where models would miss parts of important information. From a causal perspective, the reason is that models have captured spurious statistical correlations between visual features and certain expressions (e.g., visual features of &quot;long hair&quot; and &quot;woman&quot;). In this paper, we propose a dependent multi-task learning framework with the causal intervention (DMTCI). Firstly, we involve an intermediate task, bag-of-categories generation, before the final task, image captioning. The intermediate task would help the model better understand the visual features and thus alleviate the content inconsistency problem. Secondly, we apply Pearl&#39;s do-calculus on the model, cutting off the link between the visual features and possible confounders and thus letting models focus on the causal visual features. Specifically, the high-frequency concept set is considered as the proxy confounders where the real confounders are inferred in the continuous space. Finally, we use a multi-agent reinforcement learning (MARL) strategy to enable end-to-end training and reduce the inter-task error accumulations. The extensive experiments show that our model outperforms the baseline models and achieves competitive performance with state-of-the-art models. Keywords: Machine Learning: Transfer, Adaptation, Multi-task Learning Natural Language Processing: Natural Language Generation Computer Vision: Language and Vision},
  archive   = {C_IJCAI},
  author    = {Wenqing Chen and Jidong Tian and Caoyun Fan and Hao He and Yaohui Jin},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/312},
  pages     = {2263-2270},
  title     = {Dependent multi-task learning with causal intervention for image captioning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Monte carlo filtering objectives. <em>IJCAI</em>, 2256–2262.
(<a href="https://doi.org/10.24963/ijcai.2021/311">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Learning generative models and inferring latent trajectories have shown to be challenging for time series due to the intractable marginal likelihoods of flexible generative models. It can be addressed by surrogate objectives for optimization. We propose Monte Carlo filtering objectives (MCFOs), a family of variational objectives for jointly learning parametric generative models and amortized adaptive importance proposals of time series. MCFOs extend the choices of likelihood estimators beyond Sequential Monte Carlo in state-of-the-art objectives, possess important properties revealing the factors for the tightness of objectives, and allow for less biased and variant gradient estimates. We demonstrate that the proposed MCFOs and gradient estimations lead to efficient and stable model learning, and learned generative models well explain data and importance proposals are more sample efficient on various kinds of time series data. Keywords: Machine Learning: Learning Generative Models Machine Learning: Time-series; Data Streams Machine Learning: Unsupervised Learning Uncertainty in AI: Approximate Probabilistic Inference},
  archive   = {C_IJCAI},
  author    = {Shuangshuang Chen and Sihao Ding and Yiannis Karayiannidis and Mårten Björkman},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/311},
  pages     = {2256-2262},
  title     = {Monte carlo filtering objectives},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Understanding structural vulnerability in graph
convolutional networks. <em>IJCAI</em>, 2249–2255. (<a
href="https://doi.org/10.24963/ijcai.2021/310">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent studies have shown that Graph Convolutional Networks (GCNs) are vulnerable to adversarial attacks on the graph structure. Although multiple works have been proposed to improve their robustness against such structural adversarial attacks, the reasons for the success of the attacks remain unclear. In this work, we theoretically and empirically demonstrate that structural adversarial examples can be attributed to the non-robust aggregation scheme (i.e., the weighted mean) of GCNs. Specifically, our analysis takes advantage of the breakdown point which can quantitatively measure the robustness of aggregation schemes. The key insight is that weighted mean, as the basic design of GCNs, has a low breakdown point and its output can be dramatically changed by injecting a single edge. We show that adopting the aggregation scheme with a high breakdown point (e.g., median or trimmed mean) could significantly enhance the robustness of GCNs against structural attacks. Extensive experiments on four real-world datasets demonstrate that such a simple but effective method achieves the best robustness performance compared to state-of-the-art models. Keywords: Machine Learning: Adversarial Machine Learning Data Mining: Mining Graphs, Semi Structured Data, Complex Data},
  archive   = {C_IJCAI},
  author    = {Liang Chen and Jintang Li and Qibiao Peng and Yang Liu and Zibin Zheng and Carl Yang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/310},
  pages     = {2249-2255},
  title     = {Understanding structural vulnerability in graph convolutional networks},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning attributed graph representation with communicative
message passing transformer. <em>IJCAI</em>, 2242–2248. (<a
href="https://doi.org/10.24963/ijcai.2021/309">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Constructing appropriate representations of molecules lies at the core of numerous tasks such as material science, chemistry, and drug designs. Recent researches abstract molecules as attributed graphs and employ graph neural networks (GNN) for molecular representation learning, which have made remarkable achievements in molecular graph modeling. Albeit powerful, current models either are based on local aggregation operations and thus miss higher-order graph properties or focus on only node information without fully using the edge information. For this sake, we propose a Communicative Message Passing Transformer (CoMPT) neural network to improve the molecular graph representation by reinforcing message interactions between nodes and edges based on the Transformer architecture. Unlike the previous transformer-style GNNs that treat molecule as a fully connected graph, we introduce a message diffusion mechanism to leverage the graph connectivity inductive bias and reduce the message enrichment explosion. Extensive experiments demonstrated that the proposed model obtained superior performances (around 4\% on average) against state-of-the-art baselines on seven chemical property datasets (graph-level tasks) and two chemical shift datasets (node-level tasks). Further visualization studies also indicated a better representation capacity achieved by our model. Keywords: Machine Learning: Deep Learning Multidisciplinary Topics and Applications: Biology and Medicine Machine Learning Applications: Bio/Medicine Machine Learning Applications: Applications of Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Jianwen Chen and Shuangjia Zheng and Ying Song and Jiahua Rao and Yuedong Yang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/309},
  pages     = {2242-2248},
  title     = {Learning attributed graph representation with communicative message passing transformer},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). AMA-GCN: Adaptive multi-layer aggregation graph
convolutional network for disease prediction. <em>IJCAI</em>, 2235–2241.
(<a href="https://doi.org/10.24963/ijcai.2021/308">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, Graph Convolutional Networks (GCNs) have proven to be a powerful mean for Computer Aided Diagnosis (CADx). This approach requires building a population graph to aggregate structural information, where the graph adjacency matrix represents the relationship between nodes. Until now, this adjacency matrix is usually defined manually based on phenotypic information. In this paper, we propose an encoder that automatically selects the appropriate phenotypic measures according to their spatial distribution, and uses the text similarity awareness mechanism to calculate the edge weights between nodes. The encoder can automatically construct the population graph using phenotypic measures which have a positive impact on the final results, and further realizes the fusion of multimodal information. In addition, a novel graph convolution network architecture using multi-layer aggregation mechanism is proposed. The structure can obtain deep structure information while suppressing over-smooth, and increase the similarity between the same type of nodes. Experimental results on two databases show that our method can significantly improve the diagnostic accuracy for Autism spectrum disorder and breast cancer, indicating its universality in leveraging multimodal data for disease prediction. Keywords: Machine Learning: Classification Machine Learning: Learning Graphical Models Machine Learning Applications: Bio/Medicine},
  archive   = {C_IJCAI},
  author    = {Hao Chen and Fuzhen Zhuang and Li Xiao and Ling Ma and Haiyan Liu and Ruifang Zhang and Huiqin Jiang and Qing He},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/308},
  pages     = {2235-2241},
  title     = {AMA-GCN: Adaptive multi-layer aggregation graph convolutional network for disease prediction},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Generative adversarial neural architecture search.
<em>IJCAI</em>, 2227–2234. (<a
href="https://doi.org/10.24963/ijcai.2021/307">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Despite the empirical success of neural architecture search (NAS) in deep learning applications, the optimality, reproducibility and cost of NAS schemes remain hard to assess. In this paper, we propose Generative Adversarial NAS (GA-NAS) with theoretically provable convergence guarantees, promoting stability and reproducibility in neural architecture search. Inspired by importance sampling, GA-NAS iteratively fits a generator to previously discovered top architectures, thus increasingly focusing on important parts of a large search space. Furthermore, we propose an efficient adversarial learning approach, where the generator is trained by reinforcement learning based on rewards provided by a discriminator, thus being able to explore the search space without evaluating a large number of architectures. Extensive experiments show that GA-NAS beats the best published results under several cases on three public NAS benchmarks. In the meantime, GA-NAS can handle ad-hoc search constraints and search spaces. We show that GA-NAS can be used to improve already optimized baselines found by other NAS methods, including EfficientNet and ProxylessNAS, in terms of ImageNet accuracy or the number of parameters, in their original search space. Keywords: Machine Learning: Adversarial Machine Learning Machine Learning Applications: Applications of Reinforcement Learning Heuristic Search and Game Playing: Combinatorial Search and Optimisation},
  archive   = {C_IJCAI},
  author    = {Seyed Saeed Changiz Rezaei and Fred X. Han and Di Niu and Mohammad Salameh and Keith Mills and Shuo Lian and Wei Lu and Shangling Jui},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/307},
  pages     = {2227-2234},
  title     = {Generative adversarial neural architecture search},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reinforcement learning for sparse-reward object-interaction
tasks in a first-person simulated 3D environment. <em>IJCAI</em>,
2219–2226. (<a href="https://doi.org/10.24963/ijcai.2021/306">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Learning how to execute complex tasks involving multiple objects in a 3D world is challenging when there is no ground-truth information about the objects or any demonstration to learn from. When an agent only receives a signal from task-completion, this makes it challenging to learn the object-representations which support learning the correct object-interactions needed to complete the task. In this work, we formulate learning an attentive object dynamics model as a classification problem, using random object-images to define incorrect labels for our object-dynamics model. We show empirically that this enables object-representation learning that captures an object&#39;s category (is it a toaster?), its properties (is it on?), and object-relations (is something inside of it?). With this, our core learner (a relational RL agent) receives the dense training signal it needs to rapidly learn object-interaction tasks. We demonstrate results in the 3D AI2Thor simulated kitchen environment with a range of challenging food preparation tasks. We compare our method&#39;s performance to several related approaches and against the performance of an oracle: an agent that is supplied with ground-truth information about objects in the scene. We find that our agent achieves performance closest to the oracle in terms of both learning speed and maximum success rate. Keywords: Machine Learning: Deep Reinforcement Learning Machine Learning: Deep Learning Machine Learning: Reinforcement Learning Machine Learning: Relational Learning},
  archive   = {C_IJCAI},
  author    = {Wilka Carvalho and Anthony Liang and Kimin Lee and Sungryull Sohn and Honglak Lee and Richard Lewis and Satinder Singh},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/306},
  pages     = {2219-2226},
  title     = {Reinforcement learning for sparse-reward object-interaction tasks in a first-person simulated 3D environment},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Thompson sampling for bandits with clustered arms.
<em>IJCAI</em>, 2212–2218. (<a
href="https://doi.org/10.24963/ijcai.2021/305">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose algorithms based on a multi-level Thompson sampling scheme, for the stochastic multi-armed bandit and its contextual variant with linear expected rewards, in the setting where arms are clustered. We show, both theoretically and empirically, how exploiting a given cluster structure can significantly improve the regret and computational cost compared to using standard Thompson sampling. In the case of the stochastic multi-armed bandit we give upper bounds on the expected cumulative regret showing how it depends on the quality of the clustering. Finally, we perform an empirical evaluation showing that our algorithms perform well compared to previously proposed algorithms for bandits with clustered arms. Keywords: Machine Learning: Online Learning Machine Learning: Learning Theory Machine Learning: Reinforcement Learning},
  archive   = {C_IJCAI},
  author    = {Emil Carlsson and Devdatt Dubhashi and Fredrik D. Johansson},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/305},
  pages     = {2212-2218},
  title     = {Thompson sampling for bandits with clustered arms},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards understanding the spectral bias of deep learning.
<em>IJCAI</em>, 2205–2211. (<a
href="https://doi.org/10.24963/ijcai.2021/304">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {An intriguing phenomenon observed during training neural networks is the spectral bias, which states that neural networks are biased towards learning less complex functions. The priority of learning functions with low complexity might be at the core of explaining the generalization ability of neural networks, and certain efforts have been made to provide a theoretical explanation for spectral bias. However, there is still no satisfying theoretical result justifying the underlying mechanism of spectral bias. In this paper, we give a comprehensive and rigorous explanation for spectral bias and relate it with the neural tangent kernel function proposed in recent work. We prove that the training process of neural networks can be decomposed along different directions defined by the eigenfunctions of the neural tangent kernel, where each direction has its own convergence rate and the rate is determined by the corresponding eigenvalue. We then provide a case study when the input data is uniformly distributed over the unit sphere, and show that lower degree spherical harmonics are easier to be learned by over-parameterized neural networks. Finally, we provide numerical experiments to demonstrate the correctness of our theory. Our experimental results also show that our theory can tolerate certain model misspecification in terms of the input data distribution. Keywords: Machine Learning: Deep Learning Machine Learning: Kernel Methods},
  archive   = {C_IJCAI},
  author    = {Yuan Cao and Zhiying Fang and Yue Wu and Ding-Xuan Zhou and Quanquan Gu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/304},
  pages     = {2205-2211},
  title     = {Towards understanding the spectral bias of deep learning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Partial multi-label optimal margin distribution machine.
<em>IJCAI</em>, 2198–2204. (<a
href="https://doi.org/10.24963/ijcai.2021/303">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Partial multi-label learning deals with the circumstance in which the ground-truth labels are not directly available but hidden in a candidate label set. Due to the presence of other irrelevant labels, vanilla multi-label learning methods are prone to be misled and fail to generalize well on unseen data, thus how to enable them to get rid of the noisy labels turns to be the core problem of partial multi-label learning. In this paper, we propose the Partial Multi-Label Optimal margin Distribution Machine (PML-ODM), which distinguishs the noisy labels through explicitly optimizing the distribution of ranking margin, and exhibits better generalization performance than minimum margin based counterparts. In addition, we propose a novel feature prototype representation to further enhance the disambiguation ability, and the non-linear kernels can also be applied to promote the generalization performance for linearly inseparable data. Extensive experiments on real-world data sets validates the superiority of our proposed method. Keywords: Machine Learning: Classification Machine Learning: Multi-instance; Multi-label; Multi-view learning Machine Learning: Weakly Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Nan Cao and Teng Zhang and Hai Jin},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/303},
  pages     = {2198-2204},
  title     = {Partial multi-label optimal margin distribution machine},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fast pareto optimization for subset selection with dynamic
cost constraints. <em>IJCAI</em>, 2191–2197. (<a
href="https://doi.org/10.24963/ijcai.2021/302">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Subset selection with cost constraints is a fundamental problem with various applications such as influence maximization and sensor placement. The goal is to select a subset from a ground set to maximize a monotone objective function such that a monotone cost function is upper bounded by a budget. Previous algorithms with bounded approximation guarantees include the generalized greedy algorithm, POMC and EAMC, all of which can achieve the best known approximation guarantee. In real-world scenarios, the resources often vary, i.e., the budget often changes over time, requiring the algorithms to adapt the solutions quickly. However, when the budget changes dynamically, all these three algorithms either achieve arbitrarily bad approximation guarantees, or require a long running time. In this paper, we propose a new algorithm FPOMC by combining the merits of the generalized greedy algorithm and POMC. That is, FPOMC introduces a greedy selection strategy into POMC. We prove that FPOMC can maintain the best known approximation guarantee efficiently. Keywords: Machine Learning: Evolutionary Learning Heuristic Search and Game Playing: Heuristic Search Heuristic Search and Game Playing: Heuristic Search and Machine Learning},
  archive   = {C_IJCAI},
  author    = {Chao Bian and Chao Qian and Frank Neumann and Yang Yu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/302},
  pages     = {2191-2197},
  title     = {Fast pareto optimization for subset selection with dynamic cost constraints},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient neural network verification via layer-based
semidefinite relaxations and linear cuts. <em>IJCAI</em>, 2184–2190. (<a
href="https://doi.org/10.24963/ijcai.2021/301">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We introduce an efficient and tight layer-based semidefinite relaxation for verifying local robustness of neural networks. The improved tightness is the result of the combination between semidefinite relaxations and linear cuts. We obtain a computationally efficient method by decomposing the semidefinite formulation into layerwise constraints. By leveraging on chordal graph decompositions, we show that the formulation here presented is provably tighter than current approaches. Experiments on a set of benchmark networks show that the approach here proposed enables the verification of more instances compared to other relaxation methods. The results also demonstrate that the SDP relaxation here proposed is one order of magnitude faster than previous SDP methods. Keywords: Machine Learning: Deep Learning Machine Learning: Explainable/Interpretable Machine Learning Multidisciplinary Topics and Applications: Validation and Verification},
  archive   = {C_IJCAI},
  author    = {Ben Batten and Panagiotis Kouvaros and Alessio Lomuscio and Yang Zheng},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/301},
  pages     = {2184-2190},
  title     = {Efficient neural network verification via layer-based semidefinite relaxations and linear cuts},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal algorithms for range searching over multi-armed
bandits. <em>IJCAI</em>, 2177–2183. (<a
href="https://doi.org/10.24963/ijcai.2021/300">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper studies a multi-armed bandit (MAB) version of the range-searching problem. In its basic form, range searching considers as input a set of points (on the real line) and a collection of (real) intervals. Here, with each specified point, we have an associated weight, and the problem objective is to find a maximum-weight point within every given interval. The current work addresses range searching with stochastic weights: each point corresponds to an arm (that admits sample access) and the point&#39;s weight is the (unknown) mean of the underlying distribution. In this MAB setup, we develop sample-efficient algorithms that find, with high probability, near-optimal arms within the given intervals, i.e., we obtain PAC (probably approximately correct) guarantees. We also provide an algorithm for a generalization wherein the weight of each point is a multi-dimensional vector. The sample complexities of our algorithms depend, in particular, on the size of the {optimal hitting set} of the given intervals. Finally, we establish lower bounds proving that the obtained sample complexities are essentially tight. Our results highlight the significance of geometric constructs (specifically, hitting sets) in our MAB setting. Keywords: Machine Learning: Online Learning},
  archive   = {C_IJCAI},
  author    = {Siddharth Barman and Ramakrishnan Krishnamurthy and Saladi Rahul},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/300},
  pages     = {2177-2183},
  title     = {Optimal algorithms for range searching over multi-armed bandits},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reconciling rewards with predictive state representations.
<em>IJCAI</em>, 2170–2176. (<a
href="https://doi.org/10.24963/ijcai.2021/299">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Predictive state representations (PSRs) are models of controlled non-Markov observation sequences which exhibit the same generative process governing POMDP observations without relying on an underlying latent state. In that respect, a PSR is indistinguishable from the corresponding POMDP. However, PSRs notoriously ignore the notion of rewards, which undermines the general utility of PSR models for control, planning, or reinforcement learning. Therefore, we describe a sufficient and necessary accuracy condition which determines whether a PSR is able to accurately model POMDP rewards, we show that rewards can be approximated even when the accuracy condition is not satisfied, and we find that a non-trivial number of POMDPs taken from a well-known third-party repository do not satisfy the accuracy condition. We propose reward-predictive state representations (R-PSRs), a generalization of PSRs which accurately models both observations and rewards, and develop value iteration for R-PSRs. We show that there is a mismatch between optimal POMDP policies and the optimal PSR policies derived from approximate rewards. On the other hand, optimal R-PSR policies perfectly match optimal POMDP policies, reconfirming R-PSRs as accurate state-less generative models of observations and rewards. Keywords: Machine Learning: Reinforcement Learning Planning and Scheduling: POMDPs Uncertainty in AI: Uncertainty Representations},
  archive   = {C_IJCAI},
  author    = {Andrea Baisero and Christopher Amato},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/299},
  pages     = {2170-2176},
  title     = {Reconciling rewards with predictive state representations},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robustly learning composable options in deep reinforcement
learning. <em>IJCAI</em>, 2161–2169. (<a
href="https://doi.org/10.24963/ijcai.2021/298">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Hierarchical reinforcement learning (HRL) is only effective for long-horizon problems when high-level skills can be reliably sequentially executed. Unfortunately, learning reliably composable skills is difficult, because all the components of every skill are constantly changing during learning. We propose three methods for improving the composability of learned skills: representing skill initiation regions using a combination of pessimistic and optimistic classifiers; learning re-targetable policies that are robust to non-stationary subgoal regions; and learning robust option policies using model-based RL. We test these improvements on four sparse-reward maze navigation tasks involving a simulated quadrupedal robot. Each method successively improves the robustness of a baseline skill discovery method, substantially outperforming state-of-the-art flat and hierarchical methods. Keywords: Machine Learning: Deep Reinforcement Learning Robotics: Learning in Robotics Machine Learning: Reinforcement Learning},
  archive   = {C_IJCAI},
  author    = {Akhil Bagaria and Jason Senthil and Matthew Slivinski and George Konidaris},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/298},
  pages     = {2161-2169},
  title     = {Robustly learning composable options in deep reinforcement learning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Verifying reinforcement learning up to infinity.
<em>IJCAI</em>, 2154–2160. (<a
href="https://doi.org/10.24963/ijcai.2021/297">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Formally verifying that reinforcement learning systems act safely is increasingly important, but existing methods only verify over finite time. This is of limited use for dynamical systems that run indefinitely. We introduce the first method for verifying the time-unbounded safety of neural networks controlling dynamical systems. We develop a novel abstract interpretation method which, by constructing adaptable template-based polyhedra using MILP and interval arithmetic, yields sound---safe and invariant---overapproximations of the reach set. This provides stronger safety guarantees than previous time-bounded methods and shows whether the agent has generalised beyond the length of its training episodes. Our method supports ReLU activation functions and systems with linear, piecewise linear and non-linear dynamics defined with polynomial and transcendental functions. We demonstrate its efficacy on a range of benchmark control problems. Keywords: Machine Learning: Deep Reinforcement Learning Multidisciplinary Topics and Applications: Validation and Verification Robotics: Learning in Robotics},
  archive   = {C_IJCAI},
  author    = {Edoardo Bacci and Mirco Giacobbe and David Parker},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/297},
  pages     = {2154-2160},
  title     = {Verifying reinforcement learning up to infinity},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DEHB: Evolutionary hyberband for scalable, robust and
efficient hyperparameter optimization. <em>IJCAI</em>, 2147–2153. (<a
href="https://doi.org/10.24963/ijcai.2021/296">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Modern machine learning algorithms crucially rely on several design decisions to achieve strong performance, making the problem of Hyperparameter Optimization (HPO) more important than ever. Here, we combine the advantages of the popular bandit-based HPO method Hyperband (HB) and the evolutionary search approach of Differential Evolution (DE) to yield a new HPO method which we call DEHB. Comprehensive results on a very broad range of HPO problems, as well as a wide range of tabular benchmarks from neural architecture search, demonstrate that DEHB achieves strong performance far more robustly than all previous HPO methods we are aware of, especially for high-dimensional problems with discrete input dimensions. For example, DEHB is up to 1000x faster than random search. It is also efficient in computational time, conceptually simple and easy to implement, positioning it well to become a new default HPO method. Keywords: Machine Learning: Evolutionary Learning},
  archive   = {C_IJCAI},
  author    = {Noor Awad and Neeratyoy Mallik and Frank Hutter},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/296},
  pages     = {2147-2153},
  title     = {DEHB: Evolutionary hyberband for scalable, robust and efficient hyperparameter optimization},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Conditional self-supervised learning for few-shot
classification. <em>IJCAI</em>, 2140–2146. (<a
href="https://doi.org/10.24963/ijcai.2021/295">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {How to learn a transferable feature representation from limited examples is a key challenge for few-shot classification. Self-supervision as an auxiliary task to the main supervised few-shot task is considered to be a conceivable way to solve the problem since self-supervision can provide additional structural information easily ignored by the main task. However, learning a good representation by traditional self-supervised methods is usually dependent on large training samples. In few-shot scenarios, due to the lack of sufficient samples, these self-supervised methods might learn a biased representation, which more likely leads to the wrong guidance for the main tasks and finally causes the performance degradation. In this paper, we propose conditional self-supervised learning (CSS) to use auxiliary information to guide the representation learning of self-supervised tasks. Specifically, CSS leverages supervised information as prior knowledge to shape and improve the learning feature manifold of self-supervision without auxiliary unlabeled data, so as to reduce representation bias and mine more effective semantic information. Moreover, CSS exploits more meaningful information through supervised and the improved self-supervised learning respectively and integrates the information into a unified distribution, which can further enrich and broaden the original representation. Extensive experiments demonstrate that our proposed method without any fine-tuning can achieve a significant accuracy improvement on the few-shot classification scenarios compared to the state-of-the-art few-shot learning methods. Keywords: Machine Learning: Classification Machine Learning: Transfer, Adaptation, Multi-task Learning Machine Learning: Unsupervised Learning},
  archive   = {C_IJCAI},
  author    = {Yuexuan An and Hui Xue and Xingyu Zhao and Lu Zhang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/295},
  pages     = {2140-2146},
  title     = {Conditional self-supervised learning for few-shot classification},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep reinforcement learning for navigation in AAA video
games. <em>IJCAI</em>, 2133–2139. (<a
href="https://doi.org/10.24963/ijcai.2021/294">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In video games, \non-player characters (NPCs) are used to enhance the players&#39; experience in a variety of ways, e.g., as enemies, allies, or innocent bystanders. A crucial component of NPCs is navigation, which allows them to move from one point to another on the map. The most popular approach for NPC navigation in the video game industry is to use a navigation mesh (NavMesh), which is a graph representation of the map, with nodes and edges indicating traversable areas. Unfortunately, complex navigation abilities that extend the character&#39;s capacity for movement, e.g., grappling hooks, jetpacks, teleportation, or double-jumps, increase the complexity of the NavMesh, making it intractable in many practical scenarios. Game designers are thus constrained to only add abilities that can be handled by a NavMesh. As an alternative to the NavMesh, we propose to use Deep Reinforcement Learning (Deep RL) to learn how to navigate 3D maps in video games using any navigation ability. We test our approach on complex 3D environments that are notably an order of magnitude larger than maps typically used in the Deep RL literature. One of these environments is from a recently released AAA video game called Hyper Scape. We find that our approach performs surprisingly well, achieving at least 90\% success rate in a variety of scenarios using complex navigation abilities. Keywords: Machine Learning: Deep Reinforcement Learning Machine Learning Applications: Applications of Reinforcement Learning Machine Learning Applications: Game Playing},
  archive   = {C_IJCAI},
  author    = {Eloi Alonso and Maxim Peter and David Goumard and Joshua Romoff},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/294},
  pages     = {2133-2139},
  title     = {Deep reinforcement learning for navigation in AAA video games},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Simulation of electron-proton scattering events by a
feature-augmented and transformed generative adversarial network
(FAT-GAN). <em>IJCAI</em>, 2126–2132. (<a
href="https://doi.org/10.24963/ijcai.2021/293">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We apply generative adversarial network (GAN) technology to build an event generator that simulates particle production in electron-proton scattering that is free of theoretical assumptions about underlying particle dynamics. The difficulty of efficiently training a GAN event simulator lies in learning the complicated patterns of the distributions of the particles physical properties. We develop a GAN that selects a set of transformed features from particle momenta that can be generated easily by the generator, and uses these to produce a set of augmented features that improve the sensitivity of the discriminator. The new Feature-Augmented and Transformed GAN (FAT-GAN) is able to faithfully reproduce the distribution of final state electron momenta in inclusive electron scattering, without the need for input derived from domain-based theoretical assumptions. The developed technology can play a significant role in boosting the science of existing and future accelerator facilities, such as the Electron-Ion Collider. Keywords: Machine Learning: Deep Learning Machine Learning: Learning Generative Models Multidisciplinary Topics and Applications: Natural Sciences},
  archive   = {C_IJCAI},
  author    = {Yasir Alanazi and Nobuo Sato and Tianbo Liu and Wally Melnitchouk and Pawel Ambrozewicz and Florian Hauenstein and Michelle P. Kuchera and Evan Pritchard and Michael Robertson and Ryan Strauss and Luisa Velasco and Yaohang Li},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/293},
  pages     = {2126-2132},
  title     = {Simulation of electron-proton scattering events by a feature-augmented and transformed generative adversarial network (FAT-GAN)},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Likelihood-free out-of-distribution detection with
invertible generative models. <em>IJCAI</em>, 2119–2125. (<a
href="https://doi.org/10.24963/ijcai.2021/292">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Likelihood of generative models has been used traditionally as a score to detect atypical (Out-of-Distribution, OOD) inputs. However, several recent studies have found this approach to be highly unreliable, even with invertible generative models, where computing the likelihood is feasible. In this paper, we present a different framework for generative model--based OOD detection that employs the model in constructing a new representation space, instead of using it directly in computing typicality scores, where it is emphasized that the score function should be interpretable as the similarity between the input and training data in the new space. In practice, with a focus on invertible models, we propose to extract low-dimensional features (statistics) based on the model encoder and complexity of input images, and then use a One-Class SVM to score the data. Contrary to recently proposed OOD detection methods for generative models, our method does not require computing likelihood values. Consequently, it is much faster when using invertible models with iteratively approximated likelihood (e.g. iResNet), while it still has a performance competitive with other related methods. Keywords: Machine Learning: Deep Learning Uncertainty in AI: Uncertainty Representations Data Mining: Anomaly/Outlier Detection},
  archive   = {C_IJCAI},
  author    = {Amirhossein Ahmadian and Fredrik Lindsten},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/292},
  pages     = {2119-2125},
  title     = {Likelihood-free out-of-distribution detection with invertible generative models},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The surprising power of graph neural networks with random
node initialization. <em>IJCAI</em>, 2112–2118. (<a
href="https://doi.org/10.24963/ijcai.2021/291">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph neural networks (GNNs) are effective models for representation learning on relational data. However, standard GNNs are limited in their expressive power, as they cannot distinguish graphs beyond the capability of the Weisfeiler-Leman graph isomorphism heuristic. In order to break this expressiveness barrier, GNNs have been enhanced with random node initialization (RNI), where the idea is to train and run the models with randomized initial node features. In this work, we analyze the expressive power of GNNs with RNI, and prove that these models are universal, a first such result for GNNs not relying on computationally demanding higher-order properties. This universality result holds even with partially randomized initial node features, and preserves the invariance properties of GNNs in expectation. We then empirically analyze the effect of RNI on GNNs, based on carefully constructed datasets. Our empirical findings support the superior performance of GNNs with RNI over standard GNNs. Keywords: Machine Learning: Deep Learning Machine Learning: Relational Learning},
  archive   = {C_IJCAI},
  author    = {Ralph Abboud and İsmail İlkan Ceylan and Martin Grohe and Thomas Lukasiewicz},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/291},
  pages     = {2112-2118},
  title     = {The surprising power of graph neural networks with random node initialization},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). AMEIR: Automatic behavior modeling, interaction exploration
and MLP investigation in the recommender system. <em>IJCAI</em>,
2104–2110. (<a href="https://doi.org/10.24963/ijcai.2021/290">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, deep learning models have been widely explored in recommender systems. Though having achieved remarkable success, the design of task-aware recommendation models usually requires manual feature engineering and architecture engineering from domain experts. To relieve those efforts, we explore the potential of neural architecture search (NAS) and introduce AMEIR for Automatic behavior Modeling, interaction Exploration and multi-layer perceptron (MLP) Investigation in the Recommender system. Specifically, AMEIR divides the complete recommendation models into three stages of behavior modeling, interaction exploration, MLP aggregation, and introduces a novel search space containing three tailored subspaces that cover most of the existing methods and thus allow for searching better models. To find the ideal architecture efficiently and effectively, AMEIR realizes the one-shot random search in recommendation progressively on the three stages and assembles the search results as the final outcome. The experiment over various scenarios reveals that AMEIR outperforms competitive baselines of elaborate manual design and leading algorithmic complex NAS methods with lower model complexity and comparable time cost, indicating efficacy, efficiency, and robustness of the proposed method. Keywords: Knowledge Representation and Reasoning: Preference Modelling and Preference-Based Reasoning Machine Learning: Recommender Systems Data Mining: Recommender Systems},
  archive   = {C_IJCAI},
  author    = {Pengyu Zhao and Kecheng Xiao and Yuanxing Zhang and Kaigui Bian and Wei Yan},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/290},
  pages     = {2104-2110},
  title     = {AMEIR: Automatic behavior modeling, interaction exploration and MLP investigation in the recommender system},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Causal discovery with multi-domain LiNGAM for latent
factors. <em>IJCAI</em>, 2097–2103. (<a
href="https://doi.org/10.24963/ijcai.2021/289">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Discovering causal structures among latent factors from observed data is a particularly challenging problem. Despite some efforts for this problem, existing methods focus on the single-domain data only. In this paper, we propose Multi-Domain Linear Non-Gaussian Acyclic Models for LAtent Factors (MD-LiNA), where the causal structure among latent factors of interest is shared for all domains, and we provide its identification results. The model enriches the causal representation for multi-domain data. We propose an integrated two-phase algorithm to estimate the model. In particular, we first locate the latent factors and estimate the factor loading matrix. Then to uncover the causal structure among shared latent factors of interest, we derive a score function based on the characterization of independence relations between external influences and the dependence relations between multi-domain latent factors and latent factors of interest. We show that the proposed method provides locally consistent estimators. Experimental results on both synthetic and real-world data demonstrate the efficacy and robustness of our approach. Keywords: Knowledge Representation and Reasoning: Action, Change and Causality Machine Learning: Learning Graphical Models},
  archive   = {C_IJCAI},
  author    = {Yan Zeng and Shohei Shimizu and Ruichu Cai and Feng Xie and Michio Yamamoto and Zhifeng Hao},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/289},
  pages     = {2097-2103},
  title     = {Causal discovery with multi-domain LiNGAM for latent factors},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Neighborhood intervention consistency: Measuring confidence
for knowledge graph link prediction. <em>IJCAI</em>, 2090–2096. (<a
href="https://doi.org/10.24963/ijcai.2021/288">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Link prediction based on knowledge graph embeddings (KGE) has recently drawn a considerable momentum. However, existing KGE models suffer from insufficient accuracy and hardly evaluate the confidence probability of each predicted triple. To fill this critical gap, we propose a novel confidence measurement method based on causal intervention, called Neighborhood Intervention Consistency (NIC). Unlike previous confidence measurement methods that focus on the optimal score in a prediction, NIC actively intervenes in the input entity vector to measure the robustness of the prediction result. The experimental results on ten popular KGE models show that our NIC method can effectively estimate the confidence score of each predicted triple. The top 10\% triples with high NIC confidence can achieve 30\% higher accuracy in the state-of-the-art KGE models. Keywords: Knowledge Representation and Reasoning: Action, Change and Causality Knowledge Representation and Reasoning: Reasoning about Knowledge and Belief Knowledge Representation and Reasoning: Semantic Web},
  archive   = {C_IJCAI},
  author    = {Kai Wang and Yu Liu and Quan Z. Sheng},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/288},
  pages     = {2090-2096},
  title     = {Neighborhood intervention consistency: Measuring confidence for knowledge graph link prediction},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Transforming robotic plans with timed automata to solve
temporal platform constraints. <em>IJCAI</em>, 2083–2089. (<a
href="https://doi.org/10.24963/ijcai.2021/287">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Task planning for mobile robots typically uses an abstract planning domain that ignores the low-level details of the specific robot platform. Therefore, executing a plan on an actual robot often requires additional steps to deal with the specifics of the robot platform. Such a platform can be modeled with timed automata and a set of temporal constraints that need to be satisfied during execution. In this paper, we describe how to transform an abstract plan into a platform-specific action sequence that satisfies all platform constraints. The transformation procedure first transforms the plan into a timed automaton, which is then combined with the platform automata while removing all transitions that violate any constraint. We then apply reachability analysis on the resulting automaton. From any solution trace one can obtain the abstract plan extended by additional platform actions such that all platform constraints are satisfied. We describe the transformation procedure in detail and provide an evaluation in two real-world robotics scenarios. Keywords: Knowledge Representation and Reasoning: Qualitative, Geometric, Spatial, Temporal Reasoning Robotics: Behavior and Control Robotics: Cognitive Robotics Planning and Scheduling: Temporal and Hybrid Planning},
  archive   = {C_IJCAI},
  author    = {Tarik Viehmann and Till Hofmann and Gerhard Lakemeyer},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/287},
  pages     = {2083-2089},
  title     = {Transforming robotic plans with timed automata to solve temporal platform constraints},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Abstract argumentation frameworks with domain assignments.
<em>IJCAI</em>, 2076–2082. (<a
href="https://doi.org/10.24963/ijcai.2021/286">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Argumentative discourse rarely consists of opinions whose claims apply universally. As with logical statements, an argument applies to specific objects in the universe or relations among them, and may have exceptions. In this paper, we propose an argumentation formalism that allows associating arguments with a domain of application. Appropriate semantics are given, which formalise the notion of partial argument acceptance, i.e. the set of objects or relations that an argument can be applied to. We show that our proposal is in fact equivalent to the standard Argumentation Frameworks of Dung, but allows a more intuitive and compact expression of some core concepts of commonsense and non-monotonic reasoning, such as the scope of an argument, exceptions, relevance and others. Keywords: Knowledge Representation and Reasoning: Computational Models of Argument Knowledge Representation and Reasoning: Non-monotonic Reasoning},
  archive   = {C_IJCAI},
  author    = {Alexandros Vassiliades and Theodore Patkos and Giorgos Flouris and Antonis Bikakis and Nick Bassiliades and Dimitris Plexousakis},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/286},
  pages     = {2076-2082},
  title     = {Abstract argumentation frameworks with domain assignments},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Skeptical reasoning with preferred semantics in abstract
argumentation without computing preferred extensions. <em>IJCAI</em>,
2069–2075. (<a href="https://doi.org/10.24963/ijcai.2021/285">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We address the problem of deciding skeptical acceptance wrt. preferred semantics of an argument in abstract argumentation frameworks, i.e., the problem of deciding whether an argument is contained in all maximally admissible sets, a.k.a. preferred extensions. State-of-the-art algorithms solve this problem with iterative calls to an external SAT-solver to determine preferred extensions. We provide a new characterisation of skeptical acceptance wrt. preferred semantics that does not involve the notion of a preferred extension. We then develop a new algorithm that also relies on iterative calls to an external SAT-solver but avoids the costly part of maximising admissible sets. We present the results of an experimental evaluation that shows that this new approach significantly outperforms the state of the art. We also apply similar ideas to develop a new algorithm for computing the ideal extension. Keywords: Knowledge Representation and Reasoning: Computational Models of Argument},
  archive   = {C_IJCAI},
  author    = {Matthias Thimm and Federico Cerutti and Mauro Vallati},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/285},
  pages     = {2069-2075},
  title     = {Skeptical reasoning with preferred semantics in abstract argumentation without computing preferred extensions},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Lifting symmetry breaking constraints with inductive logic
programming. <em>IJCAI</em>, 2062–2068. (<a
href="https://doi.org/10.24963/ijcai.2021/284">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Efficient omission of symmetric solution candidates is essential for combinatorial problem solving. Most of the existing approaches are instance-specific and focus on the automatic computation of Symmetry Breaking Constraints (SBCs) for each given problem instance. However, the application of such approaches to large-scale instances or advanced problem encodings might be problematic. Moreover, the computed SBCs are propositional and, therefore, can neither be meaningfully interpreted nor transferred to other instances. To overcome these limitations, we introduce a new model-oriented approach for Answer Set Programming that lifts the SBCs of small problem instances into a set of interpretable first-order constraints using the Inductive Logic Programming paradigm. Experiments demonstrate the ability of our framework to learn general constraints from instance-specific SBCs for a collection of combinatorial problems. The obtained results indicate that our approach significantly outperforms a state-of-the-art instance-specific method as well as the direct application of a solver. Keywords: Knowledge Representation and Reasoning: Leveraging Knowledge and Learning Machine Learning: Explainable/Interpretable Machine Learning Constraints and SAT: Constraints: Modeling, Solvers, Applications},
  archive   = {C_IJCAI},
  author    = {Alice Tarzariol and Martin Gebser and Konstantin Schekotihin},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/284},
  pages     = {2062-2068},
  title     = {Lifting symmetry breaking constraints with inductive logic programming},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Physics-informed spline learning for nonlinear dynamics
discovery. <em>IJCAI</em>, 2054–2061. (<a
href="https://doi.org/10.24963/ijcai.2021/283">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Dynamical systems are typically governed by a set of linear/nonlinear differential equations. Distilling the analytical form of these equations from very limited data remains intractable in many disciplines such as physics, biology, climate science, engineering and social science. To address this fundamental challenge, we propose a novel Physics-informed Spline Learning (PiSL) framework to discover parsimonious governing equations for nonlinear dynamics, based on sparsely sampled noisy data. The key concept is to (1) leverage splines to interpolate locally the dynamics, perform analytical differentiation and build the library of candidate terms, (2) employ sparse representation of the governing equations, and (3) use the physics residual in turn to inform the spline learning. The synergy between splines and discovered underlying physics leads to the robust capacity of dealing with high-level data scarcity and noise. A hybrid sparsity-promoting alternating direction optimization strategy is developed for systematically pruning the sparse coefficients that form the structure and explicit expression of the governing equations. The efficacy and superiority of the proposed method have been demonstrated by multiple well-known nonlinear dynamical systems, in comparison with two state-of-the-art methods. Keywords: Knowledge Representation and Reasoning: Leveraging Knowledge and Learning Machine Learning: Explainable/Interpretable Machine Learning Machine Learning: Learning Sparse Models},
  archive   = {C_IJCAI},
  author    = {Fangzheng Sun and Yang Liu and Hao Sun},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/283},
  pages     = {2054-2061},
  title     = {Physics-informed spline learning for nonlinear dynamics discovery},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ranking extensions in abstract argumentation.
<em>IJCAI</em>, 2047–2053. (<a
href="https://doi.org/10.24963/ijcai.2021/282">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Extension-based semantics in abstract argumentation provide a criterion to determine whether a set of arguments is acceptable or not. In this paper, we present the notion of extension-ranking semantics, which determines a preordering over sets of arguments, where one set is deemed more plausible than another if it is somehow more acceptable. We obtain extension-based semantics as a special case of this new approach, but it also allows us to make more fine-grained distinctions, such as one set being &quot;more complete&#39;&#39; or &quot;more admissible&#39;&#39; than another. We define a number of general principles to classify extension-ranking semantics and develop concrete approaches. We also study the relation between extension-ranking semantics and argument-ranking based semantics, which rank individual arguments instead of sets of arguments. Keywords: Knowledge Representation and Reasoning: Computational Models of Argument},
  archive   = {C_IJCAI},
  author    = {Kenneth Skiba and Tjitze Rienstra and Matthias Thimm and Jesse Heyninck and Gabriele Kern-Isberner},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/282},
  pages     = {2047-2053},
  title     = {Ranking extensions in abstract argumentation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A description logic for analogical reasoning.
<em>IJCAI</em>, 2040–2046. (<a
href="https://doi.org/10.24963/ijcai.2021/281">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Ontologies formalise how the concepts from a given domain are interrelated. Despite their clear potential as a backbone for explainable AI, existing ontologies tend to be highly incomplete, which acts as a significant barrier to their more widespread adoption. To mitigate this issue, we present a mechanism to infer plausible missing knowledge, which relies on reasoning by analogy. To the best of our knowledge, this is the first paper that studies analogical reasoning within the setting of description logic ontologies. After showing that the standard formalisation of analogical proportion has important limitations in this setting, we introduce an alternative semantics based on bijective mappings between sets of features. We then analyse the properties of analogies under the proposed semantics, and show among others how it enables two plausible inference patterns: rule translation and rule extrapolation. Keywords: Knowledge Representation and Reasoning: Common-Sense Reasoning Knowledge Representation and Reasoning: Description Logics and Ontologies},
  archive   = {C_IJCAI},
  author    = {Steven Schockaert and Yazmin Ibanez-Garcia and Victor Gutierrez-Basulto},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/281},
  pages     = {2040-2046},
  title     = {A description logic for analogical reasoning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Inconsistency measurement for paraconsistent inference.
<em>IJCAI</em>, 2033–2039. (<a
href="https://doi.org/10.24963/ijcai.2021/280">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {One of the main aims of the methods developed for reasoning under inconsistency, in particular paraconsistent inference, is to derive informative conclusions from inconsistent bases. In this paper, we introduce an approach based on inconsistency measurement for defining non-monotonic paraconsistent consequence relations. The main idea consists in adapting properties of classical reasoning under consistency to inconsistent propositional bases by involving inconsistency measures (IM). We first exhibit interesting properties of our consequence relations. We then study situations where they bring about consequences that are always jointly consistent. In particular, we introduce a property of inconsistency measures that guarantees the consistency of the set of all entailed formulas. We also show that this property leads to several interesting properties of our IM-based consequence relations. Finally, we discuss relationships between our framework and well-known consequence relations that are based on maximal consistent subsets. In this setting, we establish direct connections between the latter and properties of inconsistency measures. Keywords: Knowledge Representation and Reasoning: Logics for Knowledge Representation Knowledge Representation and Reasoning: Non-monotonic Reasoning Knowledge Representation and Reasoning: Reasoning about Knowledge and Belief},
  archive   = {C_IJCAI},
  author    = {Yakoub Salhi},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/280},
  pages     = {2033-2039},
  title     = {Inconsistency measurement for paraconsistent inference},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient PAC reinforcement learning in regular decision
processes. <em>IJCAI</em>, 2026–2032. (<a
href="https://doi.org/10.24963/ijcai.2021/279">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently regular decision processes have been proposed as a well-behaved form of non-Markov decision process. Regular decision processes are characterised by a transition function and a reward function that depend on the whole history, though regularly (as in regular languages). In practice both the transition and the reward functions can be seen as finite transducers. We study reinforcement learning in regular decision processes. Our main contribution is to show that a near-optimal policy can be PAC-learned in polynomial time in a set of parameters that describe the underlying decision process. We argue that the identified set of parameters is minimal and it reasonably captures the difficulty of a regular decision process. Keywords: Knowledge Representation and Reasoning: Action, Change and Causality Machine Learning: Reinforcement Learning Planning and Scheduling: Markov Decisions Processes},
  archive   = {C_IJCAI},
  author    = {Alessandro Ronca and Giuseppe De Giacomo},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/279},
  pages     = {2026-2032},
  title     = {Efficient PAC reinforcement learning in regular decision processes},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Unsupervised knowledge graph alignment by probabilistic
reasoning and semantic embedding. <em>IJCAI</em>, 2019–2025. (<a
href="https://doi.org/10.24963/ijcai.2021/278">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Knowledge Graph (KG) alignment is to discover the mappings (i.e., equivalent entities, relations, and others) between two KGs. The existing methods can be divided into the embedding-based models, and the conventional reasoning and lexical matching based systems. The former compute the similarity of entities via their cross-KG embeddings, but they usually rely on an ideal supervised learning setting for good performance and lack appropriate reasoning to avoid logically wrong mappings; while the latter address the reasoning issue but are poor at utilizing the KG graph structures and the entity contexts. In this study, we aim at combining the above two solutions and thus propose an iterative framework named PRASE which is based on probabilistic reasoning and semantic embedding. It learns the KG embeddings via entity mappings from a probabilistic reasoning system named PARIS, and feeds the resultant entity mappings and embeddings back into PARIS for augmentation. The PRASE framework is compatible with different embedding-based models, and our experiments on multiple datasets have demonstrated its state-of-the-art performance. Keywords: Knowledge Representation and Reasoning: Leveraging Knowledge and Learning Knowledge Representation and Reasoning: Semantic Web},
  archive   = {C_IJCAI},
  author    = {Zhiyuan Qi and Ziheng Zhang and Jiaoyan Chen and Xi Chen and Yuejia Xiang and Ningyu Zhang and Yefeng Zheng},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/278},
  pages     = {2019-2025},
  title     = {Unsupervised knowledge graph alignment by probabilistic reasoning and semantic embedding},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A ladder of causal distances. <em>IJCAI</em>, 2012–2018. (<a
href="https://doi.org/10.24963/ijcai.2021/277">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Causal discovery, the task of automatically constructing a causal model from data, is of major significance across the sciences. Evaluating the performance of causal discovery algorithms should ideally involve comparing the inferred models to ground-truth models available for benchmark datasets, which in turn requires a notion of distance between causal models. While such distances have been proposed previously, they are limited by focusing on graphical properties of the causal models being compared. Here, we overcome this limitation by defining distances derived from the causal distributions induced by the models, rather than exclusively from their graphical structure. Pearl and Mackenzie [2018] have arranged the properties of causal models in a hierarchy called the ``ladder of causation&#39;&#39; spanning three rungs: observational, interventional, and counterfactual. Following this organization, we introduce a hierarchy of three distances, one for each rung of the ladder. Our definitions are intuitively appealing as well as efficient to compute approximately. We put our causal distances to use by benchmarking standard causal discovery systems on both synthetic and real-world datasets for which ground-truth causal models are available. Keywords: Knowledge Representation and Reasoning: Action, Change and Causality Uncertainty in AI: Bayesian Networks},
  archive   = {C_IJCAI},
  author    = {Maxime Peyrard and Robert West},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/277},
  pages     = {2012-2018},
  title     = {A ladder of causal distances},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modeling precomputation in games played under computational
constraints. <em>IJCAI</em>, 2005–2011. (<a
href="https://doi.org/10.24963/ijcai.2021/276">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Understanding the properties of games played under computational constraints remains challenging. For example, how do we expect rational (but computationally bounded) players to play games with a prohibitively large number of states, such as chess? This paper presents a novel model for the precomputation (preparing moves in advance) aspect of computationally constrained games. A fundamental trade-off is shown between randomness of play, and susceptibility to precomputation, suggesting that randomization is necessary in games with computational constraints. We present efficient algorithms for computing how susceptible a strategy is to precomputation, and computing an $\epsilon$-Nash equilibrium of our model. Numerical experiments measuring the trade-off between randomness and precomputation are provided for Stockfish (a well-known chess playing algorithm). Keywords: Knowledge Representation and Reasoning: Computational Complexity of Reasoning Agent-based and Multi-agent Systems: Resource Allocation Heuristic Search and Game Playing: Meta-Reasoning and Meta-Heuristics},
  archive   = {C_IJCAI},
  author    = {Thomas Orton},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/276},
  pages     = {2005-2011},
  title     = {Modeling precomputation in games played under computational constraints},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Compressing exact cover problems with zero-suppressed binary
decision diagrams. <em>IJCAI</em>, 1996–2004. (<a
href="https://doi.org/10.24963/ijcai.2021/275">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Exact cover refers to the problem of finding subfamily F of a given family of sets S whose universe is D, where F forms a partition of D. Knuth’s Algorithm DLX is a state-of-the-art method for solving exact cover problems. Since DLX’s running time depends on the cardinality of input S, it can be slow if S is large. Our proposal can improve DLX by exploiting a novel data structure, DanceDD, which extends the zero-suppressed binary decision diagram (ZDD) by adding links to enable efficient modifications of the data structure. With DanceDD, we can represent S in a compressed way and perform search in linear time with the size of the structure by using link operations. The experimental results show that our method is an order of magnitude faster when the problem is highly compressed. Keywords: Knowledge Representation and Reasoning: Knowledge Representation Languages Heuristic Search and Game Playing: Combinatorial Search and Optimisation},
  archive   = {C_IJCAI},
  author    = {Masaaki Nishino and Norihito Yasuda and Kengo Nakamura},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/275},
  pages     = {1996-2004},
  title     = {Compressing exact cover problems with zero-suppressed binary decision diagrams},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Two forms of responsibility in strategic games.
<em>IJCAI</em>, 1989–1995. (<a
href="https://doi.org/10.24963/ijcai.2021/274">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The paper studies two forms of responsibility, seeing to it and being blamable, in the setting of strategic games with imperfect information. The paper shows that being blamable is definable through seeing to it, but not the other way around. In addition, it proposes a bimodal logical system that describes the interplay between the seeing to it modality and the individual knowledge modality. Keywords: Knowledge Representation and Reasoning: Action, Change and Causality Knowledge Representation and Reasoning: Knowledge Representation and Game Theory; Social Choice Knowledge Representation and Reasoning: Logics for Knowledge Representation},
  archive   = {C_IJCAI},
  author    = {Pavel Naumov and Jia Tao},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/274},
  pages     = {1989-1995},
  title     = {Two forms of responsibility in strategic games},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Faster smarter proof by induction in isabelle/HOL.
<em>IJCAI</em>, 1981–1988. (<a
href="https://doi.org/10.24963/ijcai.2021/273">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present sem_ind, a recommendation tool for proof by induction in Isabelle/HOL. Given an inductive problem, sem_ind produces candidate arguments for proof by induction, and selects promising ones using heuristics. Our evaluation based on 1, 095 inductive problems from 22 source files shows that sem_ind improves the accuracy of recommendation from 20.1\% to 38.2\% for the most promising candidates within 5.0 seconds of timeout compared to its predecessor while decreasing the median value of execution time from 2.79 seconds to 1.06 seconds. Keywords: Knowledge Representation and Reasoning: Automated Reasoning and Theorem Proving Multidisciplinary Topics and Applications: Validation and Verification Heuristic Search and Game Playing: Meta-Reasoning and Meta-Heuristics Knowledge Representation and Reasoning: Logics for Knowledge Representation},
  archive   = {C_IJCAI},
  author    = {Yutaka Nagashima},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/273},
  pages     = {1981-1988},
  title     = {Faster smarter proof by induction in Isabelle/HOL},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the relation between approximation fixpoint theory and
justification theory. <em>IJCAI</em>, 1973–1980. (<a
href="https://doi.org/10.24963/ijcai.2021/272">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Approximation Fixpoint Theory (AFT) and Justification Theory (JT) are two frameworks to unify logical formalisms. AFT studies semantics in terms of fixpoints of lattice operators, and JT in terms of so-called justifications, which are explanations of why certain facts do or do not hold in a model. While the approaches differ, the frameworks were designed with similar goals in mind, namely to study the different semantics that arise in (mainly) non-monotonic logics. The First contribution of our current paper is to provide a formal link between the two frameworks. To be precise, we show that every justification frame induces an approximator and that this mapping from JT to AFT preserves all major semantics. The second contribution exploits this correspondence to extend JT with a novel class of semantics, namely ultimate semantics: we formally show that ultimate semantics can be obtained in JT by a syntactic transformation on the justification frame, essentially performing some sort of resolution on the rules. Keywords: Knowledge Representation and Reasoning: Knowledge Representation Languages Knowledge Representation and Reasoning: Logics for Knowledge Representation Knowledge Representation and Reasoning: Non-monotonic Reasoning},
  archive   = {C_IJCAI},
  author    = {Simon Marynissen and Bart Bogaerts and Marc Denecker},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/272},
  pages     = {1973-1980},
  title     = {On the relation between approximation fixpoint theory and justification theory},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bounded predicates in description logics with counting.
<em>IJCAI</em>, 1966–1972. (<a
href="https://doi.org/10.24963/ijcai.2021/271">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Description Logics (DLs) support so-called anonymous objects, which significantly contribute to the expressiveness of these KR languages, but also cause substantial computational challenges. This paper investigates reasoning about upper bounds on predicate sizes for ontologies written in the expressive DL ALCHOIQ extended with closed predicates. We describe a procedure based on integer programming that allows us to decide the existence of upper bounds on the cardinality of some predicate in the models of a given ontology in a data-independent way. Our results yield a promising supporting tool for constructing higher quality ontologies, and provide a new way to push the decidability frontiers. To wit, we define a new safety condition for Datalog-based queries over DL ontologies, while retaining decidability of query entailment. Keywords: Knowledge Representation and Reasoning: Description Logics and Ontologies Knowledge Representation and Reasoning: Logics for Knowledge Representation},
  archive   = {C_IJCAI},
  author    = {Sanja Lukumbuzya and Mantas Simkus},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/271},
  pages     = {1966-1972},
  title     = {Bounded predicates in description logics with counting},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-agent belief base revision. <em>IJCAI</em>, 1959–1965.
(<a href="https://doi.org/10.24963/ijcai.2021/270">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present a generalization of belief base revision to the multi-agent case. In our approach agents have belief bases containing both propositional beliefs and higher-order beliefs about their own beliefs and other agents’ beliefs. Moreover, their belief bases are split in two parts: the mutable part, whose elements may change under belief revision, and the core part, whose elements do not change. We study a belief revision operator inspired by the notion of screened revision. We provide complexity results of model checking for our approach as well as an optimal model checking algorithm. Moreover, we study complexity of epistemic planning formulated in the context of our framework. Keywords: Knowledge Representation and Reasoning: Belief Change Knowledge Representation and Reasoning: Logics for Knowledge Representation Knowledge Representation and Reasoning: Reasoning about Knowledge and Belief},
  archive   = {C_IJCAI},
  author    = {Emiliano Lorini and Francois Schwarzentruber},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/270},
  pages     = {1959-1965},
  title     = {Multi-agent belief base revision},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reasoning about beliefs and meta-beliefs by regression in an
expressive probabilistic action logic. <em>IJCAI</em>, 1951–1958. (<a
href="https://doi.org/10.24963/ijcai.2021/269">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In a recent paper Belle and Lakemeyer proposed the logic DS, a probabilistic extension of a modal variant of the situation calculus with a model of belief based on weighted possible worlds. Among other things, they were able to precisely capture the beliefs of a probabilistic knowledge base in terms of the concept of only-believing. While intuitively appealing, the logic has a number of shortcomings. Perhaps the most severe is the limited expressiveness in that degrees of belief are restricted to constant rational numbers, which makes it impossible to express arbitrary belief distributions. In this paper we will address this and other shortcomings by extending the language and modifying the semantics of belief and only-believing. Among other things, we will show that belief retains many but not all of the properties of DS. Moreover, it turns out that only-believing arbitrary sentences, including those mentioning belief, is uniquely satisfiable in our logic. For an interesting class of knowledge bases we also show how reasoning about beliefs and meta-beliefs after performing noisy actions and sensing can be reduced to reasoning about the initial beliefs of an agent using a form of regression. Keywords: Knowledge Representation and Reasoning: Action, Change and Causality Knowledge Representation and Reasoning: Reasoning about Knowledge and Belief Uncertainty in AI: Uncertainty Representations},
  archive   = {C_IJCAI},
  author    = {Daxin Liu and Gerhard Lakemeyer},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/269},
  pages     = {1951-1958},
  title     = {Reasoning about beliefs and meta-beliefs by regression in an expressive probabilistic action logic},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Inferring time-delayed causal relations in POMDPs from the
principle of independence of cause and mechanism. <em>IJCAI</em>,
1944–1950. (<a href="https://doi.org/10.24963/ijcai.2021/268">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper introduces an algorithm for discovering implicit and delayed causal relations between events observed by a robot at regular or arbitrary times, with the objective of improving data-efficiency and interpretability of model-based reinforcement learning (RL) techniques. The proposed algorithm initially predicts observations with the Markov assumption, and incrementally introduces new hidden variables to explain and reduce the stochasticity of the observations. The hidden variables are memory units that keep track of pertinent past events. Such events are systematically identified by their information gains. A test of independence between inputs and mechanisms is performed to identify cases when there is a causal link between events and those when the information gain is due to confounding variables. The learned transition and reward models are then used in a Monte Carlo tree search for planning. Experiments on simulated and real robotic tasks, and the challenging 3D game Doom show that this method significantly improves over current RL techniques. Keywords: Knowledge Representation and Reasoning: Action, Change and Causality Robotics: Cognitive Robotics},
  archive   = {C_IJCAI},
  author    = {Junchi Liang and Abdeslam Boularias},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/268},
  pages     = {1944-1950},
  title     = {Inferring time-delayed causal relations in POMDPs from the principle of independence of cause and mechanism},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Scalable non-observational predicate learning in ASP.
<em>IJCAI</em>, 1936–1943. (<a
href="https://doi.org/10.24963/ijcai.2021/267">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, novel ILP systems under the answer set semantics have been proposed, some of which are robust to noise and scalable over large hypothesis spaces. One such system is FastLAS, which is significantly faster than other state-of-the-art ASP-based ILP systems. FastLAS is, however, only capable of Observational Predicate Learning (OPL), where the learned hypothesis defines predicates that are directly observed in the examples. It cannot learn knowledge that is indirectly observable, such as learning causes of observed events. This class of problems, known as non-OPL, is known to be difficult to handle in the context of non-monotonic semantics. Solving non-OPL learning tasks whilst preserving scalability is a challenging open problem. We address this problem with a new abductive method for translating examples of a non-OPL task to a set of examples, called possibilities, such that the original example is covered iff at least one of the possibilities is covered. This new method allows an ILP system capable of performing OPL tasks to be &quot;upgraded&quot; to solve non-OPL tasks. In particular, we present our new FastNonOPL system, which upgrades FastLAS with the new possibility generation. We compare it to other state-of-the-art ASP-based ILP systems capable of solving non-OPL tasks, showing that FastNonOPL is significantly faster, and in many cases more accurate, than these other systems. Keywords: Knowledge Representation and Reasoning: Non-monotonic Reasoning},
  archive   = {C_IJCAI},
  author    = {Mark Law and Alessandra Russo and Krysia Broda and Elisa Bertino},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/267},
  pages     = {1936-1943},
  title     = {Scalable non-observational predicate learning in ASP},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Signature-based abduction with fresh individuals and complex
concepts for description logics. <em>IJCAI</em>, 1929–1935. (<a
href="https://doi.org/10.24963/ijcai.2021/266">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Given a knowledge base and an observation as a set of facts, ABox abduction aims at computing a hypothesis that, when added to the knowledge base, is sufficient to entail the observation. In signature-based ABox abduction, the hypothesis is further required to use only names from a given set. This form of abduction has applications such as diagnosis, KB repair, or explaning missing entailments. It is possible that hypotheses for a given observation only exist if we admit the use of fresh individuals and/or complex concepts built from the given signature, something most approaches for ABox abduction so far do not allow or only allow with restrictions. In this paper, we investigate the computational complexity of this form of abduction---allowing either fresh individuals, complex concepts, or both---for various description logics, and give size bounds on the hypotheses if they exist. Keywords: Knowledge Representation and Reasoning: Description Logics and Ontologies Knowledge Representation and Reasoning: Diagnosis and Abductive Reasoning Knowledge Representation and Reasoning: Computational Complexity of Reasoning},
  archive   = {C_IJCAI},
  author    = {Patrick Koopmann},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/266},
  pages     = {1929-1935},
  title     = {Signature-based abduction with fresh individuals and complex concepts for description logics},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-agent abstract argumentation frameworks with
incomplete knowledge of attacks. <em>IJCAI</em>, 1922–1928. (<a
href="https://doi.org/10.24963/ijcai.2021/265">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We introduce a multi-agent, dynamic extension of abstract argumentation frameworks (AFs), strongly inspired by epistemic logic, where agents have only partial information about the conflicts between arguments. These frameworks can be used to model a variety of situations. For instance, those in which agents have bounded logical resources and therefore fail to spot some of the actual attacks, or those where some arguments are not explicitly and fully stated (enthymematic argumentation). Moreover, we include second-order knowledge and common knowledge of the attack relation in our structures (where the latter accounts for the state of the debate), so as to reason about different kinds of persuasion and about strategic features. This version of multi-agent AFs, as well as their updates with public announcements of attacks (more concretely, the effects of these updates on the acceptability of an argument) can be described using S5-PAL, a well-known dynamic-epistemic logic. We also discuss how to extend our proposal to capture arbitrary higher-order attitudes and uncertainty. Keywords: Knowledge Representation and Reasoning: Computational Models of Argument Knowledge Representation and Reasoning: Logics for Knowledge Representation Knowledge Representation and Reasoning: Reasoning about Knowledge and Belief},
  archive   = {C_IJCAI},
  author    = {Andreas Herzig and Antonio Yuste Ginel},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/265},
  pages     = {1922-1928},
  title     = {Multi-agent abstract argumentation frameworks with incomplete knowledge of attacks},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). HIP network: Historical information passing network for
extrapolation reasoning on temporal knowledge graph. <em>IJCAI</em>,
1915–1921. (<a href="https://doi.org/10.24963/ijcai.2021/264">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In recent years, temporal knowledge graph (TKG) reasoning has received significant attention. Most existing methods assume that all timestamps and corresponding graphs are available during training, which makes it difficult to predict future events. To address this issue, recent works learn to infer future events based on historical information. However, these methods do not comprehensively consider the latent patterns behind temporal changes, to pass historical information selectively, update representations appropriately and predict events accurately. In this paper, we propose the Historical Information Passing (HIP) network to predict future events. HIP network passes information from temporal, structural and repetitive perspectives, which are used to model the temporal evolution of events, the interactions of events at the same time step, and the known events respectively. In particular, our method considers the updating of relation representations and adopts three scoring functions corresponding to the above dimensions. Experimental results on five benchmark datasets show the superiority of HIP network, and the significant improvements on Hits@1 prove that our method can more accurately predict what is going to happen. Keywords: Knowledge Representation and Reasoning: Qualitative, Geometric, Spatial, Temporal Reasoning Natural Language Processing: Embeddings},
  archive   = {C_IJCAI},
  author    = {Yongquan He and Peng Zhang and Luchen Liu and Qi Liang and Wenyuan Zhang and Chuang Zhang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/264},
  pages     = {1915-1921},
  title     = {HIP network: Historical information passing network for extrapolation reasoning on temporal knowledge graph},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Using platform models for a guided explanatory diagnosis
generation for mobile robots. <em>IJCAI</em>, 1908–1914. (<a
href="https://doi.org/10.24963/ijcai.2021/263">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Plan execution on a mobile robot is inherently error-prone, as the robot needs to act in a physical world which can never be completely controlled by the robot. If an error occurs during execution, the true world state is unknown, as a failure may have unobservable consequences. One approach to deal with such failures is diagnosis, where the true world state is determined by identifying a set of faults based on sensed observations. In this paper, we present a novel approach to explanatory diagnosis, based on the assumption that most failures occur due to some robot hardware failure. We model the robot platform components with state machines and formulate action variants for the robots&#39; actions, modelling different fault modes. We apply diagnosis as planning with a top-k planning approach to determine possible diagnosis candidates and then use active diagnosis to find out which of those candidates is the true diagnosis. Finally, based on the platform model, we recover from the occurred failure such that the robot can continue to operate. We evaluate our approach in a logistics robots scenario by comparing it to having no diagnosis and diagnosis without platform models, showing a significant improvement to both alternatives. Keywords: Knowledge Representation and Reasoning: Diagnosis and Abductive Reasoning Robotics: Cognitive Robotics Robotics: Dependable Robots},
  archive   = {C_IJCAI},
  author    = {Daniel Habering and Till Hofmann and Gerhard Lakemeyer},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/263},
  pages     = {1908-1914},
  title     = {Using platform models for a guided explanatory diagnosis generation for mobile robots},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Updating the belief promotion operator. <em>IJCAI</em>,
1901–1907. (<a href="https://doi.org/10.24963/ijcai.2021/262">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this note, we introduce the local version of the operator for belief promotion proposed by Schwind et al. We propose a set of postulates and provide a representation theorem that characterizes the proposal. This family of operators is related to belief promotion in the same way that updating is related to revision, and we provide several results that allow us to show this relationship formally. Furthermore, we also show the relationship of the proposed operator with features of credibility-limited revision theory. Keywords: Knowledge Representation and Reasoning: Belief Change Knowledge Representation and Reasoning: Logics for Knowledge Representation Knowledge Representation and Reasoning: Reasoning about Knowledge and Belief},
  archive   = {C_IJCAI},
  author    = {Daniel A. Grimaldi and M. Vanina Martinez and Ricardo O. Rodriguez},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/262},
  pages     = {1901-1907},
  title     = {Updating the belief promotion operator},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Program synthesis as dependency quantified formula modulo
theory. <em>IJCAI</em>, 1894–1900. (<a
href="https://doi.org/10.24963/ijcai.2021/261">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Given a specification φ(X, Y ) over inputs X and output Y and defined over a background theory T, the problem of program synthesis is to design a program f such that Y = f (X), satisfies the specification φ. Over the past decade, syntax-guided synthesis (SyGuS) has emerged as a dominant approach to program synthesis where in addition to the specification φ, the end-user also specifies a grammar L to aid the underlying synthesis engine. This paper investigates the feasibility of synthesis techniques without grammar, a sub-class defined as T constrained synthesis. We show that T-constrained synthesis can be reduced to DQF(T), i.e., to the problem of finding a witness of a dependency quantified formula modulo theory. When the underlying theory is the theory of bitvectors, the corresponding DQF problem can be further reduced to Dependency Quantified Boolean Formulas (DQBF). We rely on the progress in DQBF solving to design DQBF-based synthesizers that outperform the domain-specific program synthesis techniques; thereby positioning DQBF as a core representation language for program synthesis. Our empirical analysis shows that T-constrained synthesis can achieve significantly better performance than syntax-guided approaches. Furthermore, the general-purpose DQBF solvers perform on par with domain-specific synthesis techniques. Keywords: Knowledge Representation and Reasoning: Knowledge Representation Languages Constraints and SAT: Satisfiability Modulo Theories},
  archive   = {C_IJCAI},
  author    = {Priyanka Golia and Subhajit Roy and Kuldeep S. Meel},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/261},
  pages     = {1894-1900},
  title     = {Program synthesis as dependency quantified formula modulo theory},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Actively learning concepts and conjunctive queries under
ELr-ontologies. <em>IJCAI</em>, 1887–1893. (<a
href="https://doi.org/10.24963/ijcai.2021/260">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider the problem to learn a concept or a query in the presence of an ontology formulated in the description logic ELr, in Angluin&#39;s framework of active learning that allows the learning algorithm to interactively query an oracle (such as a domain expert). We show that the following can be learned in polynomial time: (1) EL-concepts, (2) symmetry-free ELI-concepts, and (3) conjunctive queries (CQs) that are chordal, symmetry-free, and of bounded arity. In all cases, the learner can pose to the oracle membership queries based on ABoxes and equivalence queries that ask whether a given concept/query from the considered class is equivalent to the target. The restriction to bounded arity in (3) can be removed when we admit unrestricted CQs in equivalence queries. We also show that EL-concepts are not polynomial query learnable in the presence of ELI-ontologies. Keywords: Knowledge Representation and Reasoning: Description Logics and Ontologies},
  archive   = {C_IJCAI},
  author    = {Maurice Funk and Jean Christoph Jung and Carsten Lutz},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/260},
  pages     = {1887-1893},
  title     = {Actively learning concepts and conjunctive queries under ELr-ontologies},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Decomposition-guided reductions for argumentation and
treewidth. <em>IJCAI</em>, 1880–1886. (<a
href="https://doi.org/10.24963/ijcai.2021/259">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Argumentation is a widely applied framework for modeling and evaluating arguments and its reasoning with various applications. Popular frameworks are abstract argumentation (Dung’s framework) or logic-based argumentation (Besnard-Hunter’s framework). Their computational complexity has been studied quite in-depth. Incorporating treewidth into the complexity analysis is particularly interesting, as solvers oftentimes employ SAT-based solvers, which can solve instances of low treewidth fast. In this paper, we address whether one can design reductions from argumentation problems to SAT-problems while linearly preserving the treewidth, which results in decomposition-guided (DG) reductions. It turns out that the linear treewidth overhead caused by our DG reductions, cannot be significantly improved under reasonable assumptions. Finally, we consider logic-based argumentation and establish new upper bounds using DG reductions and lower bounds. Keywords: Knowledge Representation and Reasoning: Computational Complexity of Reasoning Knowledge Representation and Reasoning: Computational Models of Argument Constraints and SAT: Constraint Satisfaction},
  archive   = {C_IJCAI},
  author    = {Johannes Fichte and Markus Hecher and Yasir Mahmood and Arne Meier},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/259},
  pages     = {1880-1886},
  title     = {Decomposition-guided reductions for argumentation and treewidth},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improved algorithms for allen’s interval algebra: A dynamic
programming approach. <em>IJCAI</em>, 1873–1879. (<a
href="https://doi.org/10.24963/ijcai.2021/258">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The constraint satisfaction problem (CSP) is an important framework in artificial intelligence used to model e.g. qualitative reasoning problems such as Allen&#39;s interval algebra A. There is strong practical incitement to solve CSPs as efficiently as possible, and the classical complexity of temporal CSPs, including A, is well understood. However, the situation is more dire with respect to running time bounds of the form O(f(n)) (where n is the number of variables) where existing results gives a best theoretical upper bound 2^O(n * log n) which leaves a significant gap to the best (conditional) lower bound 2^o(n). In this paper we narrow this gap by presenting two novel algorithms for temporal CSPs based on dynamic programming. The first algorithm solves temporal CSPs limited to constraints of arity three in O(3^n) time, and we use this algorithm to solve A in O((1.5922n)^n) time. The second algorithm tackles A directly and solves it in O((1.0615n)^n), implying a remarkable improvement over existing methods since no previously published algorithm belongs to O((cn)^n) for any c. We also extend the latter algorithm to higher dimensions box algebras where we obtain the first explicit upper bound. Keywords: Knowledge Representation and Reasoning: Qualitative, Geometric, Spatial, Temporal Reasoning Constraints and SAT: Constraint Satisfaction},
  archive   = {C_IJCAI},
  author    = {Leif Eriksson and Victor Lagerkvist},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/258},
  pages     = {1873-1879},
  title     = {Improved algorithms for allen&#39;s interval algebra: A dynamic programming approach},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). How hard to tell? Complexity of belief manipulation through
propositional announcements. <em>IJCAI</em>, 1866–1872. (<a
href="https://doi.org/10.24963/ijcai.2021/257">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Consider a set of agents with initial beliefs and a formal operator for incorporating new information. Now suppose that, for each agent, we have a formula that we would like them to believe. Does there exist a single announcement that will lead all agents to believe the corresponding formula? This paper studies the problem of the existence of such an announcement in the context of model-preference definable revision operators. First, we provide two characterisation theorems for the existence of announcements: one in the general case, the other for total partial orderings. Second, we exploit the characterisation theorems to provide upper bound complexity results. Finally, we also provide matching optimal lower bounds for the Dalal and Ginsberg operators. Keywords: Knowledge Representation and Reasoning: Belief Change Knowledge Representation and Reasoning: Reasoning about Knowledge and Belief},
  archive   = {C_IJCAI},
  author    = {Thomas Eiter and Aaron Hunter and Francois Schwarzentruber},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/257},
  pages     = {1866-1872},
  title     = {How hard to tell? complexity of belief manipulation through propositional announcements},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). HyperLDLf: A logic for checking properties of finite traces
process logs. <em>IJCAI</em>, 1859–1865. (<a
href="https://doi.org/10.24963/ijcai.2021/256">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Temporal logics over finite traces, such as LTLf and its extension LDLf, have been adopted in several areas, including Business Process Management (BPM), to check properties of processes whose executions have an unbounded, but finite, length. These logics express properties of single traces in isolation, however, especially in BPM it is also of interest to express properties over the entire log, i.e., properties that relate multiple traces of the log at once. In the case of infinite-traces, HyperLTL has been proposed to express these ``hyper&#39;&#39; properties. In this paper, motivated by BPM, we introduce HyperLDLf, a logic that extends LDLf with the hyper features of HyperLTL. We provide a sound, complete and computationally optimal technique, based on DFAs manipulation, for the model checking problem in the relevant case where the set of traces (i.e., the log) is a regular language. We illustrate how this form of model checking can be used for verifying log of business processes and for advanced forms of process mining. Keywords: Knowledge Representation and Reasoning: Action, Change and Causality Agent-based and Multi-agent Systems: Formal Verification, Validation and Synthesis},
  archive   = {C_IJCAI},
  author    = {Giuseppe De Giacomo and Paolo Felli and Marco Montali and Giuseppe Perelli},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/256},
  pages     = {1859-1865},
  title     = {HyperLDLf: A logic for checking properties of finite traces process logs},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Finite-trace and generalized-reactivity specifications in
temporal synthesis. <em>IJCAI</em>, 1852–1858. (<a
href="https://doi.org/10.24963/ijcai.2021/255">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Linear Temporal Logic (LTL) synthesis aims at automatically synthesizing a program that complies with desired properties expressed in LTL. Unfortunately it has been proved to be too difficult computationally to perform full LTL synthesis. There have been two success stories with LTL synthesis, both having to do with the form of the specification. The first is the GR(1) approach: use safety conditions to determine the possible transitions in a game between the environment and the agent, plus one powerful notion of fairness, Generalized Reactivity(1), or GR(1). The second, inspired by AI planning, is focusing on finite-trace temporal synthesis, with LTLf (LTL on finite traces) as the specification language. In this paper we take these two lines of work and bring them together. We first study the case in which we have an LTLf agent goal and a GR(1) assumption. We then add to the framework safety conditions for both the environment and the agent, obtaining a highly expressive yet still scalable form of LTL synthesis. Keywords: Knowledge Representation and Reasoning: Action, Change and Causality Planning and Scheduling: Theoretical Foundations of Planning Agent-based and Multi-agent Systems: Formal Verification, Validation and Synthesis},
  archive   = {C_IJCAI},
  author    = {Giuseppe De Giacomo and Antonio Di Stasio and Lucas M. Tabajara and Moshe Vardi and Shufang Zhu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/255},
  pages     = {1852-1858},
  title     = {Finite-trace and generalized-reactivity specifications in temporal synthesis},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Abductive knowledge induction from raw data. <em>IJCAI</em>,
1845–1851. (<a href="https://doi.org/10.24963/ijcai.2021/254">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {For many reasoning-heavy tasks with raw inputs, it is challenging to design an appropriate end-to-end pipeline to formulate the problem-solving process. Some modern AI systems, e.g., Neuro-Symbolic Learning, divide the pipeline into sub-symbolic perception and symbolic reasoning, trying to utilise data-driven machine learning and knowledge-driven problem-solving simultaneously. However, these systems suffer from the exponential computational complexity caused by the interface between the two components, where the sub-symbolic learning model lacks direct supervision, and the symbolic model lacks accurate input facts. Hence, they usually focus on learning the sub-symbolic model with a complete symbolic knowledge base while avoiding a crucial problem: where does the knowledge come from? In this paper, we present Abductive Meta-Interpretive Learning (MetaAbd) that unites abduction and induction to learn neural networks and logic theories jointly from raw data. Experimental results demonstrate that MetaAbd not only outperforms the compared systems in predictive accuracy and data efficiency but also induces logic programs that can be re-used as background knowledge in subsequent learning tasks. To the best of our knowledge, MetaAbd is the first system that can jointly learn neural networks from scratch and induce recursive first-order logic theories with predicate invention. Keywords: Knowledge Representation and Reasoning: Diagnosis and Abductive Reasoning Knowledge Representation and Reasoning: Leveraging Knowledge and Learning Machine Learning: Knowledge Aided Learning Machine Learning: Neuro-Symbolic Methods},
  archive   = {C_IJCAI},
  author    = {Wang-Zhou Dai and Stephen Muggleton},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/254},
  pages     = {1845-1851},
  title     = {Abductive knowledge induction from raw data},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A uniform abstraction framework for generalized planning.
<em>IJCAI</em>, 1837–1844. (<a
href="https://doi.org/10.24963/ijcai.2021/253">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Generalized planning aims at finding a general solution for a set of similar planning problems. Abstractions are widely used to solve such problems. However, the connections among these abstraction works remain vague. Thus, to facilitate a deep understanding and further exploration of abstraction approaches for generalized planning, it is important to develop a uniform abstraction framework for generalized planning. Recently, Banihashemi et al. proposed an agent abstraction framework based on the situation calculus. However, expressiveness of such an abstraction framework is limited. In this paper, by extending their abstraction framework, we propose a uniform abstraction framework for generalized planning. We formalize a generalized planning problem as a triple of a basic action theory, a trajectory constraint, and a goal. Then we define the concepts of sound abstractions of a generalized planning problem. We show that solutions to a generalized planning problem are nicely related to those of its sound abstractions. We also define and analyze the dual notion of complete abstractions. Finally, we review some important abstraction works for generalized planning and show that they can be formalized in our framework. Keywords: Knowledge Representation and Reasoning: Action, Change and Causality},
  archive   = {C_IJCAI},
  author    = {Zhenhe Cui and Yongmei Liu and Kailun Luo},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/253},
  pages     = {1837-1844},
  title     = {A uniform abstraction framework for generalized planning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On belief change for multi-label classifier encodings.
<em>IJCAI</em>, 1829–1836. (<a
href="https://doi.org/10.24963/ijcai.2021/252">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {An important issue in ML consists in developing approaches exploiting background knowledge T for improving the accuracy and the robustness of learned classifiers C. Delegating the classification task to a Boolean circuit Σ exhibiting the same input-output behaviour as C, the problem of exploiting T within C can be viewed as a belief change scenario. However, usual change operations are not suited to the task of modifying the classifier encoding Σ in a minimal way, to make it complying with T. To fill the gap, we present a new belief change operation, called rectification. We characterize the family of rectification operators from an axiomatic perspective and exhibit operators from this family. We identify the standard belief change postulates that every rectification operator satisfies and those it does not. We also focus on some computational aspects of rectification and compliance. Keywords: Knowledge Representation and Reasoning: Belief Change Machine Learning: Explainable/Interpretable Machine Learning},
  archive   = {C_IJCAI},
  author    = {Sylvie Coste-Marquis and Pierre Marquis},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/252},
  pages     = {1829-1836},
  title     = {On belief change for multi-label classifier encodings},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Intensional and extensional views in DL-lite ontologies.
<em>IJCAI</em>, 1822–1828. (<a
href="https://doi.org/10.24963/ijcai.2021/251">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The use of virtual collections of data is often essential in several data and knowledge management tasks. In the literature, the standard way to define virtual data collections is via views, i.e., virtual relations defined using queries. In data and knowledge bases, the notion of views is a staple of data access, data integration and exchange, query optimization, and data privacy. In this work, we study views in Ontology-Based Data Access (OBDA) systems. OBDA is a powerful paradigm for accessing data through an ontology, i.e., a conceptual specification of the domain of interest written using logical axioms. Intuitively, users of an OBDA system interact with the data only through the ontology&#39;s conceptual lens. We present a novel framework to express natural and sophisticated forms of views in OBDA systems and introduce fundamental reasoning tasks for these views. We study the computational complexity of these tasks and present classes of views for which these tasks are tractable or at least decidable. Keywords: Knowledge Representation and Reasoning: Description Logics and Ontologies Knowledge Representation and Reasoning: Knowledge Representation Languages Knowledge Representation and Reasoning: Reasoning about Knowledge and Belief},
  archive   = {C_IJCAI},
  author    = {Marco Console and Giuseppe De Giacomo and Maurizio Lenzerini and Manuel Namici},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/251},
  pages     = {1822-1828},
  title     = {Intensional and extensional views in DL-lite ontologies},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Abductive learning with ground knowledge base.
<em>IJCAI</em>, 1815–1821. (<a
href="https://doi.org/10.24963/ijcai.2021/250">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Abductive Learning is a framework that combines machine learning with first-order logical reasoning. It allows machine learning models to exploit complex symbolic domain knowledge represented by first-order logic rules. However, it is challenging to obtain or express the ground-truth domain knowledge explicitly as first-order logic rules in many applications. The only accessible knowledge base is implicitly represented by groundings, i.e., propositions or atomic formulas without variables. This paper proposes Grounded Abductive Learning (GABL) to enhance machine learning models with abductive reasoning in a ground domain knowledge base, which offers inexact supervision through a set of logic propositions. We apply GABL on two weakly supervised learning problems and found that the model&#39;s initial accuracy plays a crucial role in learning. The results on a real-world OCR task show that GABL can significantly reduce the effort of data labeling than the compared methods. Keywords: Knowledge Representation and Reasoning: Diagnosis and Abductive Reasoning Machine Learning: Knowledge Aided Learning Machine Learning: Weakly Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Le-Wen Cai and Wang-Zhou Dai and Yu-Xuan Huang and Yu-Feng Li and Stephen Muggleton and Yuan Jiang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/250},
  pages     = {1815-1821},
  title     = {Abductive learning with ground knowledge base},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Budget-constrained coalition strategies with discounting.
<em>IJCAI</em>, 1808–1814. (<a
href="https://doi.org/10.24963/ijcai.2021/249">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Discounting future costs and rewards is a common practice in accounting, game theory, and machine learning. In spite of this, existing logics for reasoning about strategies with cost and resource constraints do not account for discounting. The paper proposes a sound and complete logical system for reasoning about budget-constrained strategic abilities that incorporates discounting into its semantics. Keywords: Knowledge Representation and Reasoning: Action, Change and Causality},
  archive   = {C_IJCAI},
  author    = {Lia Bozzone and Pavel Naumov},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/249},
  pages     = {1808-1814},
  title     = {Budget-constrained coalition strategies with discounting},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cardinality queries over DL-lite ontologies. <em>IJCAI</em>,
1801–1807. (<a href="https://doi.org/10.24963/ijcai.2021/248">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Ontology-mediated query answering (OMQA) employs structured knowledge and automated reasoning in order to facilitate access to incomplete and possibly heterogeneous data. While most research on OMQA adopts (unions of) conjunctive queries as the query language, there has been recent interest in handling queries that involve counting. In this paper, we advance this line of research by investigating cardinality queries (which correspond to Boolean atomic counting queries) coupled with DL-Lite ontologies. Despite its apparent simplicity, we show that such an OMQA setting gives rise to rich and complex behaviour. While we prove that cardinality query answering is tractable (TC0) in data complexity when the ontology is formulated in DL-Lite-core, the problem becomes coNP-hard as soon as role inclusions are allowed. For DL-Lite-pos-H (which allows only positive axioms), we establish a P-coNP dichotomy and pinpoint the TC0 cases; for DL-Lite-core-H (allowing also negative axioms), we identify new sources of coNP complexity and also exhibit L-complete cases. Interestingly, and in contrast to related tractability results, we observe that the canonical model may not give the optimal count value in the tractable cases, which led us to develop an entirely new approach based upon exploring a space of strategies to determine the minimum possible number of query matches. Keywords: Knowledge Representation and Reasoning: Computational Complexity of Reasoning Knowledge Representation and Reasoning: Description Logics and Ontologies},
  archive   = {C_IJCAI},
  author    = {Meghyn Bienvenu and Quentin Manière and Michaël Thomazo},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/248},
  pages     = {1801-1807},
  title     = {Cardinality queries over DL-lite ontologies},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Choice logics and their computational properties.
<em>IJCAI</em>, 1794–1800. (<a
href="https://doi.org/10.24963/ijcai.2021/247">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Qualitative Choice Logic (QCL) and Conjunctive Choice Logic (CCL) are formalisms for preference handling, with especially QCL being well established in the field of AI. So far, analyses of these logics need to be done on a case-by-case basis, albeit they share several common features. This calls for a more general choice logic framework, with QCL and CCL as well as some of their derivatives being particular instantiations. We provide such a framework, which allows us, on the one hand, to easily define new choice logics and, on the other hand, to examine properties of different choice logics in a uniform setting. In particular, we investigate strong equivalence, a core concept in non-classical logics for understanding formula simplification, and computational complexity. Our analysis also yields new results for QCL and CCL. For example, we show that the main reasoning task regarding preferred models is ϴ₂P-complete for QCL and CCL, while being Δ₂P-complete for a newly introduced choice logic. Keywords: Knowledge Representation and Reasoning: Preference Modelling and Preference-Based Reasoning Knowledge Representation and Reasoning: Computational Complexity of Reasoning Knowledge Representation and Reasoning: Logics for Knowledge Representation},
  archive   = {C_IJCAI},
  author    = {Michael Bernreiter and Jan Maly and Stefan Woltran},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/247},
  pages     = {1794-1800},
  title     = {Choice logics and their computational properties},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reasoning about agents that may know other agents’
strategies. <em>IJCAI</em>, 1787–1793. (<a
href="https://doi.org/10.24963/ijcai.2021/246">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the semantics of knowledge in strategic reasoning. Most existing works either implicitly assume that agents do not know one another’s strategies, or that all strategies are known to all; and some works present inconsistent mixes of both features. We put forward a novel semantics for Strategy Logic with Knowledge that cleanly models whose strategies each agent knows. We study how adopting this semantics impacts agents’ knowledge and strategic ability, as well as the complexity of the model-checking problem. Keywords: Knowledge Representation and Reasoning: Reasoning about Knowledge and Belief Agent-based and Multi-agent Systems: Formal Verification, Validation and Synthesis Agent-based and Multi-agent Systems: Multi-agent Planning},
  archive   = {C_IJCAI},
  author    = {Francesco Belardinelli and Sophia Knight and Alessio Lomuscio and Bastien Maubert and Aniello Murano and Sasha Rubin},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/246},
  pages     = {1787-1793},
  title     = {Reasoning about agents that may know other agents’ strategies},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On cycles, attackers and supporters — a contribution to the
investigation of dynamics in abstract argumentation. <em>IJCAI</em>,
1780–1786. (<a href="https://doi.org/10.24963/ijcai.2021/245">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Abstract argumentation as defined by Dung in his seminal 1995 paper is by now a major research area in knowledge representation and reasoning. Dynamics of abstract argumentation frameworks (AFs) as well as syntactical consequences of semantical facts of them are the central issues of this paper. The first main part is engaged with the systematical study of the influence of attackers and supporters regarding the acceptability status of whole sets and/or single arguments. In particular, we investigate the impact of addition or removal of arguments, a line of research that has been around for more than a decade. Apart from entirely new results, we revisit, generalize and sum up similar results from the literature. To gain a comprehensive formal and intuitive understanding of the behavior of AFs we put special effort in comparing different kind of semantics. We concentrate on classical admissibility-based semantics and also give pointers to semantics based on naivity and weak admissibility, a recently introduced mediating approach. In the second main part we show how to infer syntactical information from semantical one. For instance, it is well-known that if a finite AF possesses no stable extension, then it has to contain an odd-cycle. In this paper, we even present a characterization of this issue. Moreover, we show that the change of the number of extensions if adding or removing an argument allows to conclude the existence of certain even or odd cycles in the considered AF without having further information. Keywords: Knowledge Representation and Reasoning: Computational Models of Argument Knowledge Representation and Reasoning: Non-monotonic Reasoning},
  archive   = {C_IJCAI},
  author    = {Ringo Baumann and Markus Ulbricht},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/245},
  pages     = {1780-1786},
  title     = {On cycles, attackers and supporters --- a contribution to the investigation of dynamics in abstract argumentation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A game-theoretic account of responsibility allocation.
<em>IJCAI</em>, 1773–1779. (<a
href="https://doi.org/10.24963/ijcai.2021/244">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {When designing or analyzing multi-agent systems, a fundamental problem is responsibility ascription: to specify which agents are responsible for the joint outcome of their behaviors and to which extent. We model strategic multi-agent interaction as an extensive form game of imperfect information and define notions of forward (prospective) and backward (retrospective) responsibility. Forward responsibility identifies the responsibility of a group of agents for an outcome along all possible plays, whereas backward responsibility identifies the responsibility along a given play. We further distinguish between strategic and causal backward responsibility, where the former captures the epistemic knowledge of players along a play, while the latter formalizes which players – possibly unknowingly – caused the outcome. A formal connection between forward and backward notions is established in the case of perfect recall. We further ascribe quantitative responsibility through cooperative game theory. We show through a number of examples that our approach encompasses several prior formal accounts of responsibility attribution. Keywords: Knowledge Representation and Reasoning: Action, Change and Causality Agent-based and Multi-agent Systems: Multi-agent Planning Agent-based and Multi-agent Systems: Noncooperative Games},
  archive   = {C_IJCAI},
  author    = {Christel Baier and Florian Funke and Rupak Majumdar},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/244},
  pages     = {1773-1779},
  title     = {A game-theoretic account of responsibility allocation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Best-effort synthesis: Doing your best is not harder than
giving up. <em>IJCAI</em>, 1766–1772. (<a
href="https://doi.org/10.24963/ijcai.2021/243">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study best-effort synthesis under environment assumptions specified in LTL, and show that this problem has exactly the same computational complexity of standard LTL synthesis: 2EXPTIME-complete. We provide optimal algorithms for computing best-effort strategies, both in the case of LTL over infinite traces and LTL over finite traces (i.e., LTLf). The latter are particularly well suited for implementation. Keywords: Knowledge Representation and Reasoning: Action, Change and Causality Planning and Scheduling: Theoretical Foundations of Planning Agent-based and Multi-agent Systems: Formal Verification, Validation and Synthesis},
  archive   = {C_IJCAI},
  author    = {Benjamin Aminof and Giuseppe De Giacomo and Sasha Rubin},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/243},
  pages     = {1766-1772},
  title     = {Best-effort synthesis: Doing your best is not harder than giving up},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Type anywhere you want: An introduction to invisible mobile
keyboard. <em>IJCAI</em>, 1757–1764. (<a
href="https://doi.org/10.24963/ijcai.2021/242">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Contemporary soft keyboards possess limitations: the lack of physical feedback results in an increase of typos, and the interface of soft keyboards degrades the utility of the screen. To overcome these limitations, we propose an Invisible Mobile Keyboard (IMK), which lets users freely type on the desired area without any constraints. To facilitate a data-driven IMK decoding task, we have collected the most extensive text-entry dataset (approximately 2M pairs of typing positions and the corresponding characters). Additionally, we propose our baseline decoder along with a semantic typo correction mechanism based on self-attention, which decodes such unconstrained inputs with high accuracy (96.0\%). Moreover, the user study reveals that the users could type faster and feel convenience and satisfaction to IMK with our decoder. Lastly, we make the source code and the dataset public to contribute to the research community. Keywords: Humans and AI: Human-Computer Interaction Humans and AI: Intelligent User Interfaces Humans and AI: Personalization and User Modeling},
  archive   = {C_IJCAI},
  author    = {Sahng-Min Yoo and Ue-Hwan Kim and Yewon Hwang and Jong-Hwan Kim},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/242},
  pages     = {1757-1764},
  title     = {Type anywhere you want: An introduction to invisible mobile keyboard},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Item response ranking for cognitive diagnosis.
<em>IJCAI</em>, 1750–1756. (<a
href="https://doi.org/10.24963/ijcai.2021/241">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Cognitive diagnosis, a fundamental task in education area, aims at providing an approach to reveal the proficiency level of students on knowledge concepts. Actually, monotonicity is one of the basic conditions in cognitive diagnosis theory, which assumes that student&#39;s proficiency is monotonic with the probability of giving the right response to a test item. However, few of previous methods consider the monotonicity during optimization. To this end, we propose Item Response Ranking framework (IRR), aiming at introducing pairwise learning into cognitive diagnosis to well model the monotonicity between item responses. Specifically, we first use an item specific sampling method to sample item responses and construct response pairs based on their partial order, where we propose the two-branch sampling methods to handle the unobserved responses. After that, we use a pairwise objective function to exploit the monotonicity in the pair formulation. In fact, IRR is a general framework which can be applied to most of contemporary cognitive diagnosis models. Extensive experiments demonstrate the effectiveness and interpretability of our method. Keywords: Humans and AI: Personalization and User Modeling Humans and AI: Computer-Aided Education},
  archive   = {C_IJCAI},
  author    = {Shiwei Tong and Qi Liu and Runlong Yu and Wei Huang and Zhenya Huang and Zachary A. Pardos and Weijie Jiang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/241},
  pages     = {1750-1756},
  title     = {Item response ranking for cognitive diagnosis},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Event-based action recognition using motion information and
spiking neural networks. <em>IJCAI</em>, 1743–1749. (<a
href="https://doi.org/10.24963/ijcai.2021/240">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Event-based cameras have attracted increasing attention due to their advantages of biologically inspired paradigm and low power consumption. Since event-based cameras record the visual input as asynchronous discrete events, they are inherently suitable to cooperate with the spiking neural network (SNN). Existing works of SNNs for processing events mainly focus on the task of object recognition. However, events from the event-based camera are triggered by dynamic changes, which makes it an ideal choice to capture actions in the visual scene. Inspired by the dorsal stream in visual cortex, we propose a hierarchical SNN architecture for event-based action recognition using motion information. Motion features are extracted and utilized from events to local and finally to global perception for action recognition. To the best of the authors’ knowledge, it is the first attempt of SNN to apply motion information to event-based action recognition. We evaluate our proposed SNN on three event-based action recognition datasets, including our newly published DailyAction-DVS dataset comprising 12 actions collected under diverse recording conditions. Extensive experimental results show the effectiveness of motion information and our proposed SNN architecture for event-based action recognition. Keywords: Humans and AI: Cognitive Modeling},
  archive   = {C_IJCAI},
  author    = {Qianhui Liu and Dong Xing and Huajin Tang and De Ma and Gang Pan},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/240},
  pages     = {1743-1749},
  title     = {Event-based action recognition using motion information and spiking neural networks},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An entanglement-driven fusion neural network for video
sentiment analysis. <em>IJCAI</em>, 1736–1742. (<a
href="https://doi.org/10.24963/ijcai.2021/239">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Video data is multimodal in its nature, where an utterance can involve linguistic, visual and acoustic information. Therefore, a key challenge for video sentiment analysis is how to combine different modalities for sentiment recognition effectively. The latest neural network approaches achieve state-of-the-art performance, but they neglect to a large degree of how humans understand and reason about sentiment states. By contrast, recent advances in quantum probabilistic neural models have achieved comparable performance to the state-of-the-art, yet with better transparency and increased level of interpretability. However, the existing quantum-inspired models treat quantum states as either a classical mixture or as a separable tensor product across modalities, without triggering their interactions in a way that they are correlated or non-separable (i.e., entangled). This means that the current models have not fully exploited the expressive power of quantum probabilities. To fill this gap, we propose a transparent quantum probabilistic neural model. The model induces different modalities to interact in such a way that they may not be separable, encoding crossmodal information in the form of non-classical correlations. Comprehensive evaluation on two benchmarking datasets for video sentiment analysis shows that the model achieves significant performance improvement. We also show that the degree of non-separability between modalities optimizes the post-hoc interpretability. Keywords: Humans and AI: Cognitive Modeling Natural Language Processing: Embeddings},
  archive   = {C_IJCAI},
  author    = {Dimitris Gkoumas and Qiuchi Li and Yijun Yu and Dawei Song},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/239},
  pages     = {1736-1742},
  title     = {An entanglement-driven fusion neural network for video sentiment analysis},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Accounting for confirmation bias in crowdsourced label
aggregation. <em>IJCAI</em>, 1729–1735. (<a
href="https://doi.org/10.24963/ijcai.2021/238">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Collecting large-scale human-annotated datasets via crowdsourcing to train and improve automated models is a prominent human-in-the-loop approach to integrate human and machine intelligence. However, together with their unique intelligence, humans also come with their biases and subjective beliefs, which may influence the quality of the annotated data and negatively impact the effectiveness of the human-in-the-loop systems. One of the most common types of cognitive biases that humans are subject to is the confirmation bias, which is people&#39;s tendency to favor information that confirms their existing beliefs and values. In this paper, we present an algorithmic approach to infer the correct answers of tasks by aggregating the annotations from multiple crowd workers, while taking workers&#39; various levels of confirmation bias into consideration. Evaluations on real-world crowd annotations show that the proposed bias-aware label aggregation algorithm outperforms baseline methods in accurately inferring the ground-truth labels of different tasks when crowd workers indeed exhibit some degree of confirmation bias. Through simulations on synthetic data, we further identify the conditions when the proposed algorithm has the largest advantages over baseline methods. Keywords: Humans and AI: Human Computation and Crowdsourcing Humans and AI: Human-AI Collaboration Humans and AI: Human-Computer Interaction},
  archive   = {C_IJCAI},
  author    = {Meric Altug Gemalmaz and Ming Yin},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/238},
  pages     = {1729-1735},
  title     = {Accounting for confirmation bias in crowdsourced label aggregation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Human-AI collaboration with bandit feedback. <em>IJCAI</em>,
1722–1728. (<a href="https://doi.org/10.24963/ijcai.2021/237">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Human-machine complementarity is important when neither the algorithm nor the human yield dominant performance across all instances in a given domain. Most research on algorithmic decision-making solely centers on the algorithm&#39;s performance, while recent work that explores human-machine collaboration has framed the decision-making problems as classification tasks. In this paper, we first propose and then develop a solution for a novel human-machine collaboration problem in a bandit feedback setting. Our solution aims to exploit the human-machine complementarity to maximize decision rewards. We then extend our approach to settings with multiple human decision makers. We demonstrate the effectiveness of our proposed methods using both synthetic and real human responses, and find that our methods outperform both the algorithm and the human when they each make decisions on their own. We also show how personalized routing in the presence of multiple human decision-makers can further improve the human-machine team performance. Keywords: Humans and AI: Human-AI Collaboration Humans and AI: Personalization and User Modeling},
  archive   = {C_IJCAI},
  author    = {Ruijiang Gao and Maytal Saar-Tsechansky and Maria De-Arteaga and Ligong Han and Min Kyung Lee and Matthew Lease},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/237},
  pages     = {1722-1728},
  title     = {Human-AI collaboration with bandit feedback},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Pruning of deep spiking neural networks through gradient
rewiring. <em>IJCAI</em>, 1713–1721. (<a
href="https://doi.org/10.24963/ijcai.2021/236">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Spiking Neural Networks (SNNs) have been attached great importance due to their biological plausibility and high energy-efficiency on neuromorphic chips. As these chips are usually resource-constrained, the compression of SNNs is thus crucial along the road of practical use of SNNs. Most existing methods directly apply pruning approaches in artificial neural networks (ANNs) to SNNs, which ignore the difference between ANNs and SNNs, thus limiting the performance of the pruned SNNs. Besides, these methods are only suitable for shallow SNNs. In this paper, inspired by synaptogenesis and synapse elimination in the neural system, we propose gradient rewiring (Grad R), a joint learning algorithm of connectivity and weight for SNNs, that enables us to seamlessly optimize network structure without retraining. Our key innovation is to redefine the gradient to a new synaptic parameter, allowing better exploration of network structures by taking full advantage of the competition between pruning and regrowth of connections. The experimental results show that the proposed method achieves minimal loss of SNNs&#39; performance on MNIST and CIFAR-10 datasets so far. Moreover, it reaches a ~3.5\% accuracy loss under unprecedented 0.73\% connectivity, which reveals remarkable structure refining capability in SNNs. Our work suggests that there exists extremely high redundancy in deep SNNs. Our codes are available at https://github.com/Yanqi-Chen/Gradient-Rewiring. Keywords: Humans and AI: Brain Sciences Humans and AI: Cognitive Modeling Machine Learning: Classification},
  archive   = {C_IJCAI},
  author    = {Yanqi Chen and Zhaofei Yu and Wei Fang and Tiejun Huang and Yonghong Tian},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/236},
  pages     = {1713-1721},
  title     = {Pruning of deep spiking neural networks through gradient rewiring},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). UIBert: Learning generic multimodal representations for UI
understanding. <em>IJCAI</em>, 1705–1712. (<a
href="https://doi.org/10.24963/ijcai.2021/235">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {To improve the accessibility of smart devices and to simplify their usage, building models which understand user interfaces (UIs) and assist users to complete their tasks is critical. However, unique challenges are proposed by UI-specific characteristics, such as how to effectively leverage multimodal UI features that involve image, text, and structural metadata and how to achieve good performance when high-quality labeled data is unavailable. To address such challenges we introduce UIBert, a transformer-based joint image-text model trained through novel pre-training tasks on large-scale unlabeled UI data to learn generic feature representations for a UI and its components. Our key intuition is that the heterogeneous features in a UI are self-aligned, i.e., the image and text features of UI components, are predictive of each other. We propose five pretraining tasks utilizing this self-alignment among different features of a UI component and across various components in the same UI. We evaluate our method on nine real-world downstream UI tasks where UIBert outperforms strong multimodal baselines by up to 9.26\% accuracy. Keywords: Humans and AI: Human-Computer Interaction},
  archive   = {C_IJCAI},
  author    = {Chongyang Bai and Xiaoxue Zang and Ying Xu and Srinivas Sunkara and Abhinav Rastogi and Jindong Chen and Blaise Agüera y Arcas},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/235},
  pages     = {1705-1712},
  title     = {UIBert: Learning generic multimodal representations for UI understanding},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Choosing the right algorithm with hints from complexity
theory. <em>IJCAI</em>, 1697–1703. (<a
href="https://doi.org/10.24963/ijcai.2021/234">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Choosing a suitable algorithm from the myriads of different search heuristics is difficult when faced with a novel optimization problem. In this work, we argue that the purely academic question of what could be the best possible algorithm in a certain broad class of black-box optimizers can give fruitful indications in which direction to search for good established optimization heuristics. We demonstrate this approach on the recently proposed DLB benchmark, for which the only known results are O(n^3) runtimes for several classic evolutionary algorithms and an O(n^2 log n) runtime for an estimation-of-distribution algorithm. Our finding that the unary unbiased black-box complexity is only O(n^2) suggests the Metropolis algorithm as an interesting candidate and we prove that it solves the DLB problem in quadratic time. Since we also prove that better runtimes cannot be obtained in the class of unary unbiased algorithms, we shift our attention to algorithms that use the information of more parents to generate new solutions. An artificial algorithm of this type having an O(n log n) runtime leads to the result that the significance-based compact genetic algorithm (sig-cGA) can solve the DLB problem also in time O(n log n). Our experiments show a remarkably good performance of the Metropolis algorithm, clearly the best of all algorithms regarded for reasonable problem sizes. Keywords: Heuristic Search and Game Playing: Combinatorial Search and Optimisation Heuristic Search and Game Playing: Heuristic Search Heuristic Search and Game Playing: Meta-Reasoning and Meta-Heuristics},
  archive   = {C_IJCAI},
  author    = {Shouda Wang and Weijie Zheng and Benjamin Doerr},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/234},
  pages     = {1697-1703},
  title     = {Choosing the right algorithm with hints from complexity theory},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new upper bound based on vertex partitioning for the
maximum k-plex problem. <em>IJCAI</em>, 1689–1696. (<a
href="https://doi.org/10.24963/ijcai.2021/233">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Given an undirected graph, the Maximum k-plex Problem (MKP) is to find a largest induced subgraph in which each vertex has at most k−1 non-adjacent vertices. The problem arises in social network analysis and has found applications in many important areas employing graph-based data mining. Existing exact algorithms usually implement a branch-and-bound approach that requires a tight upper bound to reduce the search space. In this paper, we propose a new upper bound for MKP, which is a partitioning of the candidate vertex set with respect to the constructing solution. We implement a new branch-and-bound algorithm that employs the upper bound to reduce the number of branches. Experimental results show that the upper bound is very effective in reducing the search space. The new algorithm outperforms the state-of-the-art algorithms significantly on real-world massive graphs, DIMACS graphs and random graphs. Keywords: Heuristic Search and Game Playing: Combinatorial Search and Optimisation Heuristic Search and Game Playing: Heuristic Search Data Mining: Mining Graphs, Semi Structured Data, Complex Data},
  archive   = {C_IJCAI},
  author    = {Hua Jiang and Dongming Zhu and Zhichao Xie and Shaowen Yao and Zhang-Hua Fu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/233},
  pages     = {1689-1696},
  title     = {A new upper bound based on vertex partitioning for the maximum K-plex problem},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A runtime analysis of typical decomposition approaches in
MOEA/d framework for many-objective optimization problems.
<em>IJCAI</em>, 1682–1688. (<a
href="https://doi.org/10.24963/ijcai.2021/232">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Decomposition approach is an important component in multi-objective evolutionary algorithm based on decomposition (MOEA/D), which is a popular method for handing many-objective optimization problems (MaOPs). This paper presents a theoretical analysis on the convergence ability of using the typical weighted sum (WS), Tchebycheff (TCH) or penalty-based boundary intersection (PBI) approach in a basic MOEA/D for solving two benchmark MaOPs. The results show that using WS, the algorithm can always find an optimal solution for any subproblem in polynomial expected runtime. In contrast, the algorithm needs at least exponential expected runtime for some subproblems if using TCH or PBI. Moreover, our analyses discover an obvious shortcoming of using WS, that is, the optimal solutions of different subproblems are easily corresponding to the same solution. In addition, this analysis indicates that if using PBI, a small value of the penalty parameter is a good choice for faster converging to the Pareto front, but it may lose the diversity. This study reveals some optimization behaviors of using three typical decomposition approaches in the well-known MOEA/D framework for solving MaOPs. Keywords: Heuristic Search and Game Playing: Evaluation and Analysis Heuristic Search and Game Playing: Heuristic Search Heuristic Search and Game Playing: Combinatorial Search and Optimisation},
  archive   = {C_IJCAI},
  author    = {Zhengxin Huang and Yuren Zhou and Chuan Luo and Qingwei Lin},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/232},
  pages     = {1682-1688},
  title     = {A runtime analysis of typical decomposition approaches in MOEA/D framework for many-objective optimization problems},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bounded-cost search using estimates of uncertainty.
<em>IJCAI</em>, 1675–1681. (<a
href="https://doi.org/10.24963/ijcai.2021/231">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Many planning problems are too hard to solve optimally. In bounded-cost search, one attempts to find, as quickly as possible, a plan that costs no more than a user-provided absolute cost bound. Several algorithms have been previously proposed for this setting, including Potential Search (PTS) and Bounded-cost Explicit Estimation Search (BEES). BEES attempts to improve on PTS by predicting whether nodes will lead to plans within the cost bound or not. This paper introduces a relatively simple algorithm, Expected Effort Search (XES), which uses not just point estimates but belief distributions in order to estimate the probability that a node will lead to a plan within the bound. XES&#39;s expansion order minimizes expected search time in a simplified formal model. Experimental results on standard planning and search benchmarks show that it consistently exhibits strong performance, outperforming both PTS and BEES. We also derive improved variants of BEES that can exploit belief distributions. These new methods advance the recent trend of taking advantage of uncertainty estimates in deterministic single-agent search. Keywords: Heuristic Search and Game Playing: Heuristic Search Planning and Scheduling: Search in Planning and Scheduling},
  archive   = {C_IJCAI},
  author    = {Maximilian Fickert and Tianyi Gu and Wheeler Ruml},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/231},
  pages     = {1675-1681},
  title     = {Bounded-cost search using estimates of uncertainty},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DACBench: A benchmark library for dynamic algorithm
configuration. <em>IJCAI</em>, 1668–1674. (<a
href="https://doi.org/10.24963/ijcai.2021/230">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Dynamic Algorithm Configuration (DAC) aims to dynamically control a target algorithm&#39;s hyperparameters in order to improve its performance. Several theoretical and empirical results have demonstrated the benefits of dynamically controlling hyperparameters in domains like evolutionary computation, AI Planning or deep learning. Replicating these results, as well as studying new methods for DAC, however, is difficult since existing benchmarks are often specialized and incompatible with the same interfaces. To facilitate benchmarking and thus research on DAC, we propose DACBench, a benchmark library that seeks to collect and standardize existing DAC benchmarks from different AI domains, as well as provide a template for new ones. For the design of DACBench, we focused on important desiderata, such as (i) flexibility, (ii) reproducibility, (iii) extensibility and (iv) automatic documentation and visualization. To show the potential, broad applicability and challenges of DAC, we explore how a set of six initial benchmarks compare in several dimensions of difficulty. Keywords: Heuristic Search and Game Playing: Evaluation and Analysis Heuristic Search and Game Playing: Heuristic Search and Machine Learning Heuristic Search and Game Playing: Meta-Reasoning and Meta-Heuristics},
  archive   = {C_IJCAI},
  author    = {Theresa Eimer and André Biedenkapp and Maximilian Reimer and Steven Adriansen and Frank Hutter and Marius Lindauer},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/230},
  pages     = {1668-1674},
  title     = {DACBench: A benchmark library for dynamic algorithm configuration},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Faster guarantees of evolutionary algorithms for
maximization of monotone submodular functions. <em>IJCAI</em>,
1661–1667. (<a href="https://doi.org/10.24963/ijcai.2021/229">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, the monotone submodular maximization problem (SM) is studied. SM is to find a subset of size kappa from a universe of size n that maximizes a monotone submodular objective function f . We show using a novel analysis that the Pareto optimization algorithm achieves a worst-case ratio of (1 − epsilon)(1 − 1/e) in expectation for every cardinality constraint kappa &lt; P , where P ≤ n + 1 is an input, in O(nP ln(1/epsilon)) queries of f . In addition, a novel evolutionary algorithm called the biased Pareto optimization algorithm, is proposed that achieves a worst-case ratio of (1 − epsilon)(1 − 1/e − epsilon) in expectation for every cardinality constraint kappa &lt; P in O(n ln(P ) ln(1/epsilon)) queries of f . Further, the biased Pareto optimization algorithm can be modified in order to achieve a a worst-case ratio of (1 − epsilon)(1 − 1/e − epsilon) in expectation for cardinality constraint kappa in O(n ln(1/epsilon)) queries of f . An empirical evaluation corroborates our theoretical analysis of the algorithms, as the algorithms exceed the stochastic greedy solution value at roughly when one would expect based upon our analysis. Keywords: Heuristic Search and Game Playing: Combinatorial Search and Optimisation},
  archive   = {C_IJCAI},
  author    = {Victoria G. Crawford},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/229},
  pages     = {1661-1667},
  title     = {Faster guarantees of evolutionary algorithms for maximization of monotone submodular functions},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Knowledge-based residual learning. <em>IJCAI</em>,
1653–1659. (<a href="https://doi.org/10.24963/ijcai.2021/228">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Small data has been a barrier for many machine learning tasks, especially when applied in scientific domains. Fortunately, we can utilize domain knowledge to make up the lack of data. Hence, in this paper, we propose a hybrid model KRL that treats domain knowledge model as a weak learner and uses another neural net model to boost it. We prove that KRL is guaranteed to improve over pure domain knowledge model and pure neural net model under certain loss functions. Extensive experiments have shown the superior performance of KRL over baselines. In addition, several case studies have explained how the domain knowledge can assist the prediction. Keywords: Data Mining: Classification Data Mining: Mining Spatial, Temporal Data Data Mining: Theoretical Foundation of Data Mining},
  archive   = {C_IJCAI},
  author    = {Guanjie Zheng and Chang Liu and Hua Wei and Porter Jenkins and Chacha Chen and Tao Wen and Zhenhui Li},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/228},
  pages     = {1653-1659},
  title     = {Knowledge-based residual learning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Graph deformer network. <em>IJCAI</em>, 1646–1652. (<a
href="https://doi.org/10.24963/ijcai.2021/227">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Convolution learning on graphs draws increasing attention recently due to its potential applications to a large amount of irregular data. Most graph convolution methods leverage the plain summation/average aggregation to avoid the discrepancy of responses from isomorphic graphs. However, such an extreme collapsing way would result in a structural loss and signal entanglement of nodes, which further cause the degradation of the learning ability. In this paper, we propose a simple yet effective Graph Deformer Network (GDN) to fulfill anisotropic convolution filtering on graphs, analogous to the standard convolution operation on images. Local neighborhood subgraphs (acting like receptive fields) with different structures are deformed into a unified virtual space, coordinated by several anchor nodes. In the deformation process, we transfer components of nodes therein into affinitive anchors by learning their correlations, and build a multi-granularity feature space calibrated with anchors. Anisotropic convolutional kernels can be further performed over the anchor-coordinated space to well encode local variations of receptive fields. By parameterizing anchors and stacking coarsening layers, we build a graph deformer network in an end-to-end fashion. Theoretical analysis indicates its connection to previous work and shows the promising property of graph isomorphism testing. Extensive experiments on widely-used datasets validate the effectiveness of GDN in graph and node classifications. Keywords: Data Mining: Mining Graphs, Semi Structured Data, Complex Data Data Mining: Feature Extraction, Selection and Dimensionality Reduction Machine Learning: Classification},
  archive   = {C_IJCAI},
  author    = {Wenting Zhao and Yuan Fang and Zhen Cui and Tong Zhang and Jian Yang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/227},
  pages     = {1646-1652},
  title     = {Graph deformer network},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Heterogeneous graph information bottleneck. <em>IJCAI</em>,
1638–1645. (<a href="https://doi.org/10.24963/ijcai.2021/226">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Most attempts on extending Graph Neural Networks (GNNs) to Heterogeneous Information Networks (HINs) implicitly take the direct assumption that the multiple homogeneous attributed networks induced by different meta-paths are complementary. The doubts about the hypothesis of complementary motivate an alternative assumption of consensus. That is, the aggregated node attributes shared by multiple homogeneous attributed networks are essential for node representations, while the specific ones in each homogeneous attributed network should be discarded. In this paper, a novel Heterogeneous Graph Information Bottleneck (HGIB) is proposed to implement the consensus hypothesis in an unsupervised manner. To this end, information bottleneck (IB) is extended to unsupervised representation learning by leveraging self-supervision strategy. Specifically, HGIB simultaneously maximizes the mutual information between one homogeneous network and the representation learned from another homogeneous network, while minimizes the mutual information between the specific information contained in one homogeneous network and the representation learned from this homogeneous network. Model analysis reveals that the two extreme cases of HGIB correspond to the supervised heterogeneous GNN and the infomax on homogeneous graph, respectively. Extensive experiments on real datasets demonstrate that the consensus-based unsupervised HGIB significantly outperforms most semi-supervised SOTA methods based on complementary assumption. Keywords: Data Mining: Mining Graphs, Semi Structured Data, Complex Data},
  archive   = {C_IJCAI},
  author    = {Liang Yang and Fan Wu and Zichen Zheng and Bingxin Niu and Junhua Gu and Chuan Wang and Xiaochun Cao and Yuanfang Guo},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/226},
  pages     = {1638-1645},
  title     = {Heterogeneous graph information bottleneck},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Spatial-temporal sequential hypergraph network for crime
prediction with dynamic multiplex relation learning. <em>IJCAI</em>,
1631–1637. (<a href="https://doi.org/10.24963/ijcai.2021/225">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Crime prediction is crucial for public safety and resource optimization, yet is very challenging due to two aspects: i) the dynamics of criminal patterns across time and space, crime events are distributed unevenly on both spatial and temporal domains; ii) time-evolving dependencies between different types of crimes (e.g., Theft, Robbery, Assault, Damage) which reveal fine-grained semantics of crimes. To tackle these challenges, we propose Spatial-Temporal Sequential Hypergraph Network (ST-SHN) to collectively encode complex crime spatial-temporal patterns as well as the underlying category-wise crime semantic relationships. In specific, to handle spatial-temporal dynamics under the long-range and global context, we design a graph-structured message passing architecture with the integration of the hypergraph learning paradigm. To capture category-wise crime heterogeneous relations in a dynamic environment, we introduce a multi-channel routing mechanism to learn the time-evolving structural dependency across crime types. We conduct extensive experiments on two real-word datasets, showing that our proposed ST-SHN framework can significantly improve the prediction performance as compared to various state-of-the-art baselines. The source code is available at https://github.com/akaxlh/ST-SHN. Keywords: Data Mining: Mining Spatial, Temporal Data},
  archive   = {C_IJCAI},
  author    = {Lianghao Xia and Chao Huang and Yong Xu and Peng Dai and Liefeng Bo and Xiyue Zhang and Tianyi Chen},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/225},
  pages     = {1631-1637},
  title     = {Spatial-temporal sequential hypergraph network for crime prediction with dynamic multiplex relation learning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). User-as-graph: User modeling with heterogeneous graph
pooling for news recommendation. <em>IJCAI</em>, 1624–1630. (<a
href="https://doi.org/10.24963/ijcai.2021/224">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Accurate user modeling is critical for news recommendation. Existing news recommendation methods usually model users&#39; interest from their behaviors via sequential or attentive models. However, they cannot model the rich relatedness between user behaviors, which can provide useful contexts of these behaviors for user interest modeling. In this paper, we propose a novel user modeling approach for news recommendation, which models each user as a personalized heterogeneous graph built from user behaviors to better capture the fine-grained behavior relatedness. In addition, in order to learn user interest embedding from the personalized heterogeneous graph, we propose a novel heterogeneous graph pooling method, which can summarize both node features and graph topology, and be aware of the varied characteristics of different types of nodes. Experiments on large-scale benchmark dataset show the proposed methods can effectively improve the performance of user modeling for news recommendation. Keywords: Data Mining: Recommender Systems Humans and AI: Personalization and User Modeling},
  archive   = {C_IJCAI},
  author    = {Chuhan Wu and Fangzhao Wu and Yongfeng Huang and Xing Xie},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/224},
  pages     = {1624-1630},
  title     = {User-as-graph: User modeling with heterogeneous graph pooling for news recommendation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Federated learning with fair averaging. <em>IJCAI</em>,
1615–1623. (<a href="https://doi.org/10.24963/ijcai.2021/223">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Fairness has emerged as a critical problem in federated learning (FL). In this work, we identify a cause of unfairness in FL -- conflicting gradients with large differences in the magnitudes. To address this issue, we propose the federated fair averaging (FedFV) algorithm to mitigate potential conflicts among clients before averaging their gradients. We first use the cosine similarity to detect gradient conflicts, and then iteratively eliminate such conflicts by modifying both the direction and the magnitude of the gradients. We further show the theoretical foundation of FedFV to mitigate the issue conflicting gradients and converge to Pareto stationary solutions. Extensive experiments on a suite of federated datasets confirm that FedFV compares favorably against state-of-the-art methods in terms of fairness, accuracy and efficiency. The source code is available at https://github.com/WwZzz/easyFL. Keywords: Data Mining: Federated Learning AI Ethics, Trust, Fairness: Fairness},
  archive   = {C_IJCAI},
  author    = {Zheng Wang and Xiaoliang Fan and Jianzhong Qi and Chenglu Wen and Cheng Wang and Rongshan Yu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/223},
  pages     = {1615-1623},
  title     = {Federated learning with fair averaging},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Preference-adaptive meta-learning for cold-start
recommendation. <em>IJCAI</em>, 1607–1614. (<a
href="https://doi.org/10.24963/ijcai.2021/222">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In recommender systems, the cold-start problem is a critical issue. To alleviate this problem, an emerging direction adopts meta-learning frameworks and achieves success. Most existing works aim to learn globally shared prior knowledge across all users so that it can be quickly adapted to a new user with sparse interactions. However, globally shared prior knowledge may be inadequate to discern users’ complicated behaviors and causes poor generalization. Therefore, we argue that prior knowledge should be locally shared by users with similar preferences who can be recognized by social relations. To this end, in this paper, we propose a Preference-Adaptive Meta-Learning approach (PAML) to improve existing meta-learning frameworks with better generalization capacity. Specifically, to address two challenges imposed by social relations, we first identify reliable implicit friends to strengthen a user’s social relations based on our defined palindrome paths. Then, a coarse-fine preference modeling method is proposed to leverage social relations and capture the preference. Afterwards, a novel preference-specific adapter is designed to adapt the globally shared prior knowledge to the preference-specific knowledge so that users who have similar tastes share similar knowledge. We conduct extensive experiments on two publicly available datasets. Experimental results validate the power of social relations and the effectiveness of PAML. Keywords: Data Mining: Recommender Systems Machine Learning: Recommender Systems Machine Learning: Learning Preferences or Rankings},
  archive   = {C_IJCAI},
  author    = {Li Wang and Binbin Jin and Zhenya Huang and Hongke Zhao and Defu Lian and Qi Liu and Enhong Chen},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/222},
  pages     = {1607-1614},
  title     = {Preference-adaptive meta-learning for cold-start recommendation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Heuristic search for approximating one matrix in terms of
another matrix. <em>IJCAI</em>, 1600–1606. (<a
href="https://doi.org/10.24963/ijcai.2021/221">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the approximation of a target matrix in terms of several selected columns of another matrix, sometimes called &quot;a dictionary&quot;. This approximation problem arises in various domains, such as signal processing, computer vision, and machine learning. An optimal column selection algorithm for the special case where the target matrix has only one column is known since the 1970&#39;s, but most previously proposed column selection algorithms for the general case are greedy. We propose the first nontrivial optimal algorithm for the general case, using a heuristic search setting similar to the classical A* algorithm. We also propose practical sub-optimal algorithms in a setting similar to the classical Weighted A* algorithm. Experimental results show that our sub-optimal algorithms compare favorably with the current state-of-the-art greedy algorithms. They also provide bounds on how close their solutions are to the optimal solution. Keywords: Data Mining: Feature Extraction, Selection and Dimensionality Reduction Heuristic Search and Game Playing: Heuristic Search Machine Learning: Dimensionality Reduction Machine Learning: Learning Sparse Models},
  archive   = {C_IJCAI},
  author    = {Guihong Wan and Haim Schweitzer},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/221},
  pages     = {1600-1606},
  title     = {Heuristic search for approximating one matrix in terms of another matrix},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Pattern-enhanced contrastive policy learning network for
sequential recommendation. <em>IJCAI</em>, 1593–1599. (<a
href="https://doi.org/10.24963/ijcai.2021/220">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Sequential recommendation aims to predict users’ future behaviors given their historical interactions. However, due to the randomness and diversity of a user’s behaviors, not all historical items are informative to tell his/her next choice. It is obvious that identifying relevant items and extracting meaningful sequential patterns are necessary for a better recommendation. Unfortunately, few works have focused on this sequence denoising process. In this paper, we propose a PatteRn-enhanced ContrAstive Policy Learning Network (RAP for short) for sequential recommendation, RAP formalizes the denoising problem in the form of Markov Decision Process (MDP), and sample actions for each item to determine whether it is relevant with the target item. To tackle the lack of relevance supervision, RAP fuses a series of mined sequential patterns into the policy learning process, which work as a prior knowledge to guide the denoising process. After that, RAP splits the initial item sequence into two disjoint subsequences: a positive subsequence and a negative subsequence. At this, a novel contrastive learning mechanism is introduced to guide the sequence denoising and achieve preference estimation from the positive subsequence simultaneously. Extensive experiments on four public real-world datasets demonstrate the effectiveness of our approach for sequential recommendation. Keywords: Data Mining: Recommender Systems Data Mining: Frequent Pattern Mining},
  archive   = {C_IJCAI},
  author    = {Xiaohai Tong and Pengfei Wang and Chenliang Li and Long Xia and Shaozhang Niu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/220},
  pages     = {1593-1599},
  title     = {Pattern-enhanced contrastive policy learning network for sequential recommendation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cooperative joint attentive network for patient outcome
prediction on irregular multi-rate multivariate health data.
<em>IJCAI</em>, 1586–1592. (<a
href="https://doi.org/10.24963/ijcai.2021/219">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Due to the dynamic health status of patients and discrepant stability of physiological variables, health data often presents as irregular multi-rate multivariate time series (IMR-MTS) with significantly varying sampling rates. Existing methods mainly study changes of IMR-MTS values in the time domain, without considering their different dominant frequencies and varying data quality. Hence, we propose a novel Cooperative Joint Attentive Network (CJANet) to analyze IMR-MTS in frequency domain, which adaptively handling discrepant dominant frequencies while tackling diverse data qualities caused by irregular sampling. In particular, novel dual-channel joint attention is designed to jointly identify important magnitude and phase signals while detecting their dominant frequencies, automatically enlarging the positive influence of key variables and frequencies. Furthermore, a new cooperative learning module is introduced to enhance information exchange between magnitude and phase channels, effectively integrating global signals to optimize the network. A frequency-aware fusion strategy is finally designed to aggregate the learned features. Extensive experimental results on real-world medical datasets indicate that CJANet significantly outperforms existing methods and provides highly interpretable results. Keywords: Data Mining: Mining Spatial, Temporal Data},
  archive   = {C_IJCAI},
  author    = {Qingxiong Tan and Mang Ye and Grace Lai-Hung Wong and PongChi Yuen},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/219},
  pages     = {1586-1592},
  title     = {Cooperative joint attentive network for patient outcome prediction on irregular multi-rate multivariate health data},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Does every data instance matter? Enhancing sequential
recommendation by eliminating unreliable data. <em>IJCAI</em>,
1579–1585. (<a href="https://doi.org/10.24963/ijcai.2021/218">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Most sequential recommender systems (SRSs) predict next-item as target for each user given its preceding items as input, assuming that each input is related to its target. However, users may unintentionally click on items that are inconsistent with their preference. We empirically verify that SRSs can be misguided with such unreliable instances (i.e. targets mismatch inputs). This inspires us to design a novel SRS By Eliminating unReliable Data (BERD) guided with two observations: (1) unreliable instances generally have high training loss; and (2) high-loss instances are not necessarily unreliable but uncertain ones caused by blurry sequential pattern. Accordingly, BERD models both loss and uncertainty of each instance via a Gaussian distribution to better distinguish unreliable instances; meanwhile an uncertainty-aware graph convolution network is exploited to assist in mining unreliable instances by lowering uncertainty. Extensive experiments on four real-world datasets demonstrate the superiority of our proposed BERD. Keywords: Data Mining: Recommender Systems Humans and AI: Personalization and User Modeling},
  archive   = {C_IJCAI},
  author    = {Yatong Sun and Bin Wang and Zhu Sun and Xiaochun Yang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/218},
  pages     = {1579-1585},
  title     = {Does every data instance matter? enhancing sequential recommendation by eliminating unreliable data},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). LDP-FL: Practical private aggregation in federated learning
with local differential privacy. <em>IJCAI</em>, 1571–1578. (<a
href="https://doi.org/10.24963/ijcai.2021/217">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Training deep learning models on sensitive user data has raised increasing privacy concerns in many areas. Federated learning is a popular approach for privacy protection that collects the local gradient information instead of raw data. One way to achieve a strict privacy guarantee is to apply local differential privacy into federated learning. However, previous works do not give a practical solution due to two issues. First, the range difference of weights in different deep learning model layers has not been explicitly considered when applying local differential privacy mechanism. Second, the privacy budget explodes due to the high dimensionality of weights in deep learning models and many query iterations of federated learning. In this paper, we proposed a novel design of local differential privacy mechanism for federated learning to address the abovementioned issues. It makes the local weights update differentially private by adapting to the varying ranges at different layers of a deep neural network, which introduces a smaller variance of the estimated model weights, especially for deeper models. Moreover, the proposed mechanism bypasses the curse of dimensionality by parameter shuffling aggregation. A series of empirical evaluations on three commonly used datasets in prior differential privacy works, MNIST, Fashion-MNIST and CIFAR-10, demonstrate that our solution can not only achieve superior deep learning performance but also provide a strong privacy guarantee at the same time. Keywords: Data Mining: Federated Learning Data Mining: Privacy Preserving Data Mining Agent-based and Multi-agent Systems: Multi-agent Learning AI Ethics, Trust, Fairness: Trustable Learning},
  archive   = {C_IJCAI},
  author    = {Lichao Sun and Jianwei Qian and Xun Chen},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/217},
  pages     = {1571-1578},
  title     = {LDP-FL: Practical private aggregation in federated learning with local differential privacy},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Federated model distillation with noise-free differential
privacy. <em>IJCAI</em>, 1563–1570. (<a
href="https://doi.org/10.24963/ijcai.2021/216">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Conventional federated learning directly averages model weights, which is only possible for collaboration between models with homogeneous architectures. Sharing prediction instead of weight removes this obstacle and eliminates the risk of white-box inference attacks in conventional federated learning. However, the predictions from local models are sensitive and would leak training data privacy to the public. To address this issue, one naive approach is adding the differentially private random noise to the predictions, which however brings a substantial trade-off between privacy budget and model performance. In this paper, we propose a novel framework called FEDMD-NFDP, which applies a Noise-FreeDifferential Privacy (NFDP) mechanism into a federated model distillation framework. Our extensive experimental results on various datasets validate that FEDMD-NFDP can deliver not only comparable utility and communication efficiency but also provide a noise-free differential privacy guarantee. We also demonstrate the feasibility of our FEDMD-NFDP by considering both IID and Non-IID settings, heterogeneous model architectures, and unlabelled public datasets from a different distribution. Keywords: Data Mining: Federated Learning Data Mining: Privacy Preserving Data Mining Agent-based and Multi-agent Systems: Multi-agent Learning AI Ethics, Trust, Fairness: Trustable Learning},
  archive   = {C_IJCAI},
  author    = {Lichao Sun and Lingjuan Lyu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/216},
  pages     = {1563-1570},
  title     = {Federated model distillation with noise-free differential privacy},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Keyword-based knowledge graph exploration based on quadratic
group steiner trees. <em>IJCAI</em>, 1555–1562. (<a
href="https://doi.org/10.24963/ijcai.2021/215">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Exploring complex structured knowledge graphs (KGs) is challenging for non-experts as it requires knowledge of query languages and the underlying structure of the KGs. Keyword-based exploration is a convenient paradigm, and computing a group Steiner tree (GST) as an answer is a popular implementation. Recent studies suggested improving the cohesiveness of an answer where entities have small semantic distances from each other. However, how to efficiently compute such an answer is open. In this paper, to model cohesiveness in a generalized way, the quadratic group Steiner tree problem (QGSTP) is formulated where the cost function extends GST with quadratic terms representing semantic distances. For QGSTP we design a branch-and-bound best-first (B3F) algorithm where we exploit combinatorial methods to estimate lower bounds for costs. This exact algorithm shows practical performance on medium-sized KGs. Keywords: Data Mining: Mining Graphs, Semi Structured Data, Complex Data Data Mining: Information Retrieval Knowledge Representation and Reasoning: Semantic Web},
  archive   = {C_IJCAI},
  author    = {Yuxuan Shi and Gong Cheng and Trung-Kien Tran and Jie Tang and Evgeny Kharlamov},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/215},
  pages     = {1555-1562},
  title     = {Keyword-based knowledge graph exploration based on quadratic group steiner trees},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Masked label prediction: Unified message passing model for
semi-supervised classification. <em>IJCAI</em>, 1548–1554. (<a
href="https://doi.org/10.24963/ijcai.2021/214">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph neural network (GNN) and label propagation algorithm (LPA) are both message passing algorithms, which have achieved superior performance in semi-supervised classification. GNN performs feature propagation by a neural network to make predictions, while LPA uses label propagation across graph adjacency matrix to get results. However, there is still no effective way to directly combine these two kinds of algorithms. To address this issue, we propose a novel Unified Message Passaging Model (UniMP) that can incorporate feature and label propagation at both training and inference time. First, UniMP adopts a Graph Transformer network, taking feature embedding and label embedding as input information for propagation. Second, to train the network without overfitting in self-loop input label information, UniMP introduces a masked label prediction strategy, in which some percentage of input label information are masked at random, and then predicted. UniMP conceptually unifies feature propagation and label propagation and is empirically powerful. It obtains new state-of-the-art semi-supervised classification results in Open Graph Benchmark (OGB). Keywords: Data Mining: Mining Graphs, Semi Structured Data, Complex Data Machine Learning: Semi-Supervised Learning Data Mining: Classification},
  archive   = {C_IJCAI},
  author    = {Yunsheng Shi and Zhengjie Huang and Shikun Feng and Hui Zhong and Wenjing Wang and Yu Sun},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/214},
  pages     = {1548-1554},
  title     = {Masked label prediction: Unified message passing model for semi-supervised classification},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). GAEN: Graph attention evolving networks. <em>IJCAI</em>,
1541–1547. (<a href="https://doi.org/10.24963/ijcai.2021/213">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Real-world networked systems often show dynamic properties with continuously evolving network nodes and topology over time. When learning from dynamic networks, it is beneficial to correlate all temporal networks to fully capture the similarity/relevance between nodes. Recent work for dynamic network representation learning typically trains each single network independently and imposes relevance regularization on the network learning at different time steps. Such a snapshot scheme fails to leverage topology similarity between temporal networks for progressive training. In addition to the static node relationships within each network, nodes could show similar variation patterns (e.g., change of local structures) within the temporal network sequence. Both static node structures and temporal variation patterns can be combined to better characterize node affinities for unified embedding learning. In this paper, we propose Graph Attention Evolving Networks (GAEN) for dynamic network embedding with preserved similarities between nodes derived from their temporal variation patterns. Instead of training graph attention weights for each network independently, we allow model weights to share and evolve across all temporal networks based on their respective topology discrepancies. Experiments and validations, on four real-world dynamic graphs, demonstrate that GAEN outperforms the state-of-the-art in both link prediction and node classification tasks. Keywords: Data Mining: Feature Extraction, Selection and Dimensionality Reduction Data Mining: Mining Graphs, Semi Structured Data, Complex Data Data Mining: Mining Spatial, Temporal Data},
  archive   = {C_IJCAI},
  author    = {Min Shi and Yu Huang and Xingquan Zhu and Yufei Tang and Yuan Zhuang and Jianxun Liu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/213},
  pages     = {1541-1547},
  title     = {GAEN: Graph attention evolving networks},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Graph edit distance learning via modeling optimum matchings
with constraints. <em>IJCAI</em>, 1534–1540. (<a
href="https://doi.org/10.24963/ijcai.2021/212">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph edit distance (GED) is a fundamental measure for graph similarity analysis in many real applications. GED computation has known to be NP-hard and many heuristic methods are proposed. GED has two inherent characteristics: multiple optimum node matchings and one-to-one node matching constraints. However, these two characteristics have not been well considered in the existing learning-based methods, which leads to suboptimal models. In this paper, we propose a novel GED-specific loss function that simultaneously encodes the two characteristics. First, we propose an optimal partial node matching-based regularizer to encode multiple optimum node matchings. Second, we propose a plane intersection-based regularizer to impose the one-to-one constraints for the encoded node matchings. We use the graph neural network on the association graph of the two input graphs to learn the cross-graph representation. Our experiments show that our method is 4.2x-103.8x more accurate than the state-of-the-art methods on real-world benchmark graphs. Keywords: Data Mining: Big Data, Large-Scale Systems Data Mining: Intelligent Database Systems},
  archive   = {C_IJCAI},
  author    = {Yun Peng and Byron Choi and Jianliang Xu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/212},
  pages     = {1534-1540},
  title     = {Graph edit distance learning via modeling optimum matchings with constraints},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). GraphReach: Position-aware graph neural network using
reachability estimations. <em>IJCAI</em>, 1527–1533. (<a
href="https://doi.org/10.24963/ijcai.2021/211">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Majority of the existing graph neural networks(GNN) learn node embeddings that encode their local neighborhoods but not their positions. Consequently, two nodes that are vastly distant but located in similar local neighborhoods map to similar embeddings in those networks. This limitation prevents accurate performance in predictive tasks that rely on position information. In this paper, we develop GRAPHREACH , a position-aware inductive GNN that captures the global positions of nodes through reachability estimations with respect to a set of anchor nodes. The anchors are strategically selected so that reachability estimations across all the nodes are maximized. We show that this combinatorial anchor selection problem is NP-hard and, consequently, develop a greedy (1−1/e) approximation heuristic. Empirical evaluation against state-of-the-art GNN architectures reveal that GRAPHREACH provides up to 40\% relative improvement in accuracy. In addition, it is more robust to adversarial attacks. Keywords: Data Mining: Mining Graphs, Semi Structured Data, Complex Data},
  archive   = {C_IJCAI},
  author    = {Sunil Nishad and Shubhangi Agarwal and Arnab Bhattacharya and Sayan Ranu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/211},
  pages     = {1527-1533},
  title     = {GraphReach: Position-aware graph neural network using reachability estimations},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Node-wise localization of graph neural networks.
<em>IJCAI</em>, 1520–1526. (<a
href="https://doi.org/10.24963/ijcai.2021/210">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph neural networks (GNNs) emerge as a powerful family of representation learning models on graphs. To derive node representations, they utilize a global model that recursively aggregates information from the neighboring nodes. However, different nodes reside at different parts of the graph in different local contexts, making their distributions vary across the graph. Ideally, how a node receives its neighborhood information should be a function of its local context, to diverge from the global GNN model shared by all nodes. To utilize node locality without overfitting, we propose a node-wise localization of GNNs by accounting for both global and local aspects of the graph. Globally, all nodes on the graph depend on an underlying global GNN to encode the general patterns across the graph; locally, each node is localized into a unique model as a function of the global model and its local context. Finally, we conduct extensive experiments on four benchmark graphs, and consistently obtain promising performance surpassing the state-of-the-art GNNs. Keywords: Data Mining: Mining Graphs, Semi Structured Data, Complex Data},
  archive   = {C_IJCAI},
  author    = {Zemin Liu and Yuan Fang and Chenghao Liu and Steven C.H. Hoi},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/210},
  pages     = {1520-1526},
  title     = {Node-wise localization of graph neural networks},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MG-DVD: A real-time framework for malware variant detection
based on dynamic heterogeneous graph learning. <em>IJCAI</em>,
1512–1519. (<a href="https://doi.org/10.24963/ijcai.2021/209">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Detecting the newly emerging malware variants in real time is crucial for mitigating cyber risks and proactively blocking intrusions. In this paper, we propose MG-DVD, a novel detection framework based on dynamic heterogeneous graph learning, to detect malware variants in real time. Particularly, MG-DVD first models the fine-grained execution event streams of malware variants into dynamic heterogeneous graphs and investigates real-world meta-graphs between malware objects, which can effectively characterize more discriminative malicious evolutionary patterns between malware and their variants. Then, MG-DVD presents two dynamic walk-based heterogeneous graph learning methods to learn more comprehensive representations of malware variants, which significantly reduces the cost of the entire graph retraining. As a result, MG-DVD is equipped with the ability to detect malware variants in real time, and it presents better interpretability by introducing meaningful meta-graphs. Comprehensive experiments on large-scale samples prove that our proposed MG-DVD outperforms state-of-the-art methods in detecting malware variants in terms of effectiveness and efficiency. Keywords: Data Mining: Anomaly/Outlier Detection Machine Learning: Deep Learning Multidisciplinary Topics and Applications: Real-Time Systems},
  archive   = {C_IJCAI},
  author    = {Chen Liu and Bo Li and Jun Zhao and Ming Su and Xu-Dong Liu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/209},
  pages     = {1512-1519},
  title     = {MG-DVD: A real-time framework for malware variant detection based on dynamic heterogeneous graph learning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). RCA: A deep collaborative autoencoder approach for anomaly
detection. <em>IJCAI</em>, 1505–1511. (<a
href="https://doi.org/10.24963/ijcai.2021/208">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Unsupervised anomaly detection plays a crucial role in many critical applications. Driven by the success of deep learning, recent years have witnessed growing interests in applying deep neural networks (DNNs) to anomaly detection problems. A common approach is using autoencoders to learn a feature representation for the normal observations in the data. The reconstruction error of the autoencoder is then used as outlier scores to detect the anomalies. However, due to the high complexity brought upon by the over-parameterization of DNNs, the reconstruction error of the anomalies could also be small, which hampers the effectiveness of these methods. To alleviate this problem, we propose a robust framework using collaborative autoencoders to jointly identify normal observations from the data while learning its feature representation. We investigate the theoretical properties of the framework and empirically show its outstanding performance as compared to other DNN-based methods. Our experimental results also show the resiliency of the framework to missing values compared to other baseline methods. Keywords: Data Mining: Anomaly/Outlier Detection Machine Learning: Unsupervised Learning},
  archive   = {C_IJCAI},
  author    = {Boyang Liu and Ding Wang and Kaixiang Lin and Pang-Ning Tan and Jiayu Zhou},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/208},
  pages     = {1505-1511},
  title     = {RCA: A deep collaborative autoencoder approach for anomaly detection},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modeling trajectories with neural ordinary differential
equations. <em>IJCAI</em>, 1498–1504. (<a
href="https://doi.org/10.24963/ijcai.2021/207">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent advances in location-acquisition techniques have generated massive spatial trajectory data. Recurrent Neural Networks (RNNs) are modern tools for modeling such trajectory data. After revisiting RNN-based methods for trajectory modeling, we expose two common critical drawbacks in the existing uses. First, RNNs are discrete-time models that only update the hidden states upon the arrival of new observations, which makes them an awkward fit for learning real-world trajectories with continuous-time dynamics. Second, real-world trajectories are never perfectly accurate due to unexpected sensor noise. Most RNN-based approaches are deterministic and thereby vulnerable to such noise. To tackle these challenges, we devise a novel method entitled TrajODE for more natural modeling of trajectories. It combines the continuous-time characteristic of Neural Ordinary Differential Equations (ODE) with the robustness of stochastic latent spaces. Extensive experiments on the task of trajectory classification demonstrate the superiority of our framework against the RNN counterparts. Keywords: Data Mining: Mining Spatial, Temporal Data Multidisciplinary Topics and Applications: Ubiquitous Computing Systems},
  archive   = {C_IJCAI},
  author    = {Yuxuan Liang and Kun Ouyang and Hanshu Yan and Yiwei Wang and Zekun Tong and Roger Zimmermann},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/207},
  pages     = {1498-1504},
  title     = {Modeling trajectories with neural ordinary differential equations},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Discovering collaborative signals for next POI
recommendation with iterative Seq2Graph augmentation. <em>IJCAI</em>,
1491–1497. (<a href="https://doi.org/10.24963/ijcai.2021/206">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Being an indispensable component in location-based social networks, next point-of-interest (POI) recommendation recommends users unexplored POIs based on their recent visiting histories. However, existing work mainly models check-in data as isolated POI sequences, neglecting the crucial collaborative signals from cross-sequence check-in information. Furthermore, the sparse POI-POI transitions restrict the ability of a model to learn effective sequential patterns for recommendation. In this paper, we propose Sequence-to-Graph (Seq2Graph) augmentation for each POI sequence, allowing collaborative signals to be propagated from correlated POIs belonging to other sequences. We then devise a novel Sequence-to-Graph POI Recommender (SGRec), which jointly learns POI embeddings and infers a user&#39;s temporal preferences from the graph-augmented POI sequence. To overcome the sparsity of POI-level interactions, we further infuse category-awareness into SGRec with a multi-task learning scheme that captures the denser category-wise transitions. As such, SGRec makes full use of the collaborative signals for learning expressive POI representations, and also comprehensively uncovers multi-level sequential patterns for user preference modelling. Extensive experiments on two real-world datasets demonstrate the superiority of SGRec against state-of-the-art methods in next POI recommendation. Keywords: Data Mining: Mining Spatial, Temporal Data Data Mining: Recommender Systems},
  archive   = {C_IJCAI},
  author    = {Yang Li and Tong Chen and Yadan Luo and Hongzhi Yin and Zi Huang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/206},
  pages     = {1491-1497},
  title     = {Discovering collaborative signals for next POI recommendation with iterative Seq2Graph augmentation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Practical one-shot federated learning for cross-silo
setting. <em>IJCAI</em>, 1484–1490. (<a
href="https://doi.org/10.24963/ijcai.2021/205">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Federated learning enables multiple parties to collaboratively learn a model without exchanging their data. While most existing federated learning algorithms need many rounds to converge, one-shot federated learning (i.e., federated learning with a single communication round) is a promising approach to make federated learning applicable in cross-silo setting in practice. However, existing one-shot algorithms only support specific models and do not provide any privacy guarantees, which significantly limit the applications in practice. In this paper, we propose a practical one-shot federated learning algorithm named FedKT. By utilizing the knowledge transfer technique, FedKT can be applied to any classification models and can flexibly achieve differential privacy guarantees. Our experiments on various tasks show that FedKT can significantly outperform the other state-of-the-art federated learning algorithms with a single communication round. Keywords: Data Mining: Federated Learning Machine Learning: Classification},
  archive   = {C_IJCAI},
  author    = {Qinbin Li and Bingsheng He and Dawn Song},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/205},
  pages     = {1484-1490},
  title     = {Practical one-shot federated learning for cross-silo setting},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-scale contrastive siamese networks for self-supervised
graph representation learning. <em>IJCAI</em>, 1477–1483. (<a
href="https://doi.org/10.24963/ijcai.2021/204">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph representation learning plays a vital role in processing graph-structured data. However, prior arts on graph representation learning heavily rely on labeling information. To overcome this problem, inspired by the recent success of graph contrastive learning and Siamese networks in visual representation learning, we propose a novel self-supervised approach in this paper to learn node representations by enhancing Siamese self-distillation with multi-scale contrastive learning. Specifically, we first generate two augmented views from the input graph based on local and global perspectives. Then, we employ two objectives called cross-view and cross-network contrastiveness to maximize the agreement between node representations across different views and networks. To demonstrate the effectiveness of our approach, we perform empirical experiments on five real-world datasets. Our method not only achieves new state-of-the-art results but also surpasses some semi-supervised counterparts by large margins. Code is made available at https://github.com/GRAND-Lab/MERIT Keywords: Data Mining: Mining Graphs, Semi Structured Data, Complex Data Machine Learning: Unsupervised Learning},
  archive   = {C_IJCAI},
  author    = {Ming Jin and Yizhen Zheng and Yuan-Fang Li and Chen Gong and Chuan Zhou and Shirui Pan},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/204},
  pages     = {1477-1483},
  title     = {Multi-scale contrastive siamese networks for self-supervised graph representation learning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Temporal heterogeneous information network embedding.
<em>IJCAI</em>, 1470–1476. (<a
href="https://doi.org/10.24963/ijcai.2021/203">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Heterogeneous information network (HIN) embedding, learning the low-dimensional representation of multi-type nodes, has been applied widely and achieved excellent performance. However, most of the previous works focus more on static heterogeneous networks or learning node embedding within specific snapshots, and seldom attention has been paid to the whole evolution process and capturing all temporal dynamics. In order to fill the gap of obtaining multi-type node embeddings by considering all temporal dynamics during the evolution, we propose a novel temporal HIN embedding method (THINE). THINE not only uses attention mechanism and meta-path to preserve structures and semantics in HIN but also combines the Hawkes process to simulate the evolution of the temporal network. Our extensive evaluations with various real-world temporal HINs demonstrate that THINE achieves state-of-the-art performance in both static and dynamic tasks, including node classification, link prediction, and temporal link recommendation. Keywords: Data Mining: Mining Graphs, Semi Structured Data, Complex Data},
  archive   = {C_IJCAI},
  author    = {Hong Huang and Ruize Shi and Wei Zhou and Xiao Wang and Hai Jin and Xiaoming Fu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/203},
  pages     = {1470-1476},
  title     = {Temporal heterogeneous information network embedding},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Federated learning with sparsification-amplified privacy and
adaptive optimization. <em>IJCAI</em>, 1463–1469. (<a
href="https://doi.org/10.24963/ijcai.2021/202">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Federated learning (FL) enables distributed agents to collaboratively learn a centralized model without sharing their raw data with each other. However, data locality does not provide sufficient privacy protection, and it is desirable to facilitate FL with rigorous differential privacy (DP) guarantee. Existing DP mechanisms would introduce random noise with magnitude proportional to the model size, which can be quite large in deep neural networks. In this paper, we propose a new FL framework with sparsification-amplified privacy. Our approach integrates random sparsification with gradient perturbation on each agent to amplify privacy guarantee. Since sparsification would increase the number of communication rounds required to achieve a certain target accuracy, which is unfavorable for DP guarantee, we further introduce acceleration techniques to help reduce the privacy cost. We rigorously analyze the convergence of our approach and utilize Renyi DP to tightly account the end-to-end DP guarantee. Extensive experiments on benchmark datasets validate that our approach outperforms previous differentially-private FL approaches in both privacy guarantee and communication efficiency. Keywords: Data Mining: Federated Learning Multidisciplinary Topics and Applications: Security and Privacy Data Mining: Privacy Preserving Data Mining},
  archive   = {C_IJCAI},
  author    = {Rui Hu and Yanmin Gong and Yuanxiong Guo},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/202},
  pages     = {1463-1469},
  title     = {Federated learning with sparsification-amplified privacy and adaptive optimization},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning stochastic equivalence based on discrete ricci
curvature. <em>IJCAI</em>, 1456–1462. (<a
href="https://doi.org/10.24963/ijcai.2021/201">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Role-based network embedding methods aim to preserve node-centric connectivity patterns, which are expressions of node roles, into low-dimensional vectors. However, almost all the existing methods are designed for capturing a relaxation of automorphic equivalence or regular equivalence. They may be good at structure identification but could show poorer performance on role identification. Because automorphic equivalence and regular equivalence strictly tie the role of a node to the identities of all its neighbors. To mitigate this problem, we construct a framework called Curvature-based Network Embedding with Stochastic Equivalence (CNESE) to embed stochastic equivalence. More specifically, we estimate the role distribution of nodes based on discrete Ricci curvature for its excellent ability to concisely representing local topology. We use a Variational Auto-Encoder to generate embeddings while a degree-guided regularizer and a contrastive learning regularizer are leveraged to improving both its robustness and discrimination ability. The effectiveness of our proposed CNESE is demonstrated by extensive experiments on real-world networks. Keywords: Data Mining: Feature Extraction, Selection and Dimensionality Reduction Data Mining: Mining Graphs, Semi Structured Data, Complex Data Data Mining: Mining Text, Web, Social Media},
  archive   = {C_IJCAI},
  author    = {Xuan Guo and Qiang Tian and Wang Zhang and Wenjun Wang and Pengfei Jiao},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/201},
  pages     = {1456-1462},
  title     = {Learning stochastic equivalence based on discrete ricci curvature},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Guided attention network for concept extraction.
<em>IJCAI</em>, 1449–1455. (<a
href="https://doi.org/10.24963/ijcai.2021/200">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Concept extraction aims to find words or phrases describing a concept from massive texts. Recently, researchers propose many neural network-based methods to automatically extract concepts. Although these methods for this task show promising results, they ignore structured information in the raw textual data (e.g., title, topic, and clue words). In this paper, we propose a novel model, named Guided Attention Concept Extraction Network (GACEN), which uses title, topic, and clue words as additional supervision to provide guidance directly. Specifically, GACEN comprises two attention networks, one of them is to gather the relevant title and topic information for each context word in the document. The other one aims to model the implicit connection between informative words (clue words) and concepts. Finally, we aggregate information from two networks as input to Conditional Random Field (CRF) to model dependencies in the output. We collected clue words for three well-studied datasets. Extensive experiments demonstrate that our model outperforms the baseline models with a large margin, especially when the labeled data is insufficient. Keywords: Data Mining: Information Retrieval Data Mining: Mining Text, Web, Social Media},
  archive   = {C_IJCAI},
  author    = {Songtao Fang and Zhenya Huang and Ming He and Shiwei Tong and Xiaoqing Huang and Ye Liu and Jie Huang and Qi Liu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/200},
  pages     = {1449-1455},
  title     = {Guided attention network for concept extraction},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-channel pooling graph neural networks. <em>IJCAI</em>,
1442–1448. (<a href="https://doi.org/10.24963/ijcai.2021/199">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph pooling is a critical operation to downsample a graph in graph neural networks. Existing coarsening pooling methods (e.g. DiffPool) mostly focus on capturing the global topology structure by assigning the nodes into several coarse clusters, while dropping pooling methods (e.g. SAGPool) try to preserve the local topology structure by selecting the top-k representative nodes. However, there lacks an effective method to integrate the two types of methods so that both the local and the global topology structure of a graph can be well captured. To address this issue, we propose a Multi-channel Graph Pooling method named MuchPool, which captures the local structure, the global structure, and node feature simultaneously in graph pooling. Specifically, we use two channels to conduct dropping pooling based on the local topology and node features respectively, and one channel to conduct coarsening pooling. Then a cross-channel convolution operation is designed to refine the graph representations of different channels. Finally, the pooling results are aggregated as the final pooled graph. Extensive experiments on six benchmark datasets present the superior performance of MuchPool. The code of this work is publicly available at Github. Keywords: Data Mining: Mining Graphs, Semi Structured Data, Complex Data Machine Learning: Deep Learning Machine Learning: Classification},
  archive   = {C_IJCAI},
  author    = {Jinlong Du and Senzhang Wang and Hao Miao and Jiaqiang Zhang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/199},
  pages     = {1442-1448},
  title     = {Multi-channel pooling graph neural networks},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Masked contrastive learning for anomaly detection.
<em>IJCAI</em>, 1434–1441. (<a
href="https://doi.org/10.24963/ijcai.2021/198">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Detecting anomalies is one fundamental aspect of a safety-critical software system, however, it remains a long-standing problem. Numerous branches of works have been proposed to alleviate the complication and have shown promising results. In particular, self-supervised learning based methods are spurring interest due to their capability of learning diverse representations without additional labels. Among self-supervised learning tactics, contrastive learning is one specific framework showing pronounced results in various fields including anomaly detection. However, the primary objective of contrastive learning is to learn task-agnostic features without any labels, which is not entirely suited to discern anomalies. In this paper, we propose a task-specific variant of contrastive learning named masked contrastive learning, which is more befitted for anomaly detection. Moreover, we propose a new inference method dubbed self-ensemble inference that further boosts performance by leveraging the ability learned through auxiliary self-supervision tasks. By combining our models, we can outperform previous state-of-the-art methods by a significant margin on various benchmark datasets. Keywords: Data Mining: Anomaly/Outlier Detection Machine Learning: Clustering Data Mining: Clustering},
  archive   = {C_IJCAI},
  author    = {Hyunsoo Cho and Jinseok Seol and Sang-goo Lee},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/198},
  pages     = {1434-1441},
  title     = {Masked contrastive learning for anomaly detection},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploring periodicity and interactivity in multi-interest
framework for sequential recommendation. <em>IJCAI</em>, 1426–1433. (<a
href="https://doi.org/10.24963/ijcai.2021/197">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Sequential recommendation systems alleviate the problem of information overload, and have attracted increasing attention in the literature. Most prior works usually obtain an overall representation based on the user’s behavior sequence, which can not sufficiently reflect the multiple interests of the user. To this end, we propose a novel method called PIMI to mitigate this issue. PIMI can model the user’s multi-interest representation effectively by considering both the periodicity and interactivity in the item sequence. Specifically, we design a periodicity-aware module to utilize the time interval information between user’s behaviors. Meanwhile, an ingenious graph is proposed to enhance the interactivity between items in user’s behavior sequence, which can capture both global and local item features. Finally, a multi-interest extraction module is applied to describe user’s multiple interests based on the obtained item representation. Extensive experiments on two real-world datasets Amazon and Taobao show that PIMI outperforms state-of-the-art methods consistently. Keywords: Data Mining: Recommender Systems Data Mining: Big Data, Large-Scale Systems Machine Learning: Recommender Systems},
  archive   = {C_IJCAI},
  author    = {Gaode Chen and Xinghua Zhang and Yanyan Zhao and Cong Xue and Ji Xiang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/197},
  pages     = {1426-1433},
  title     = {Exploring periodicity and interactivity in multi-interest framework for sequential recommendation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Computing optimal hypertree decompositions with SAT.
<em>IJCAI</em>, 1418–1424. (<a
href="https://doi.org/10.24963/ijcai.2021/196">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Hypertree width is a prominent hypergraph invariant with many algorithmic applications in constraint satisfaction and databases. We propose a novel characterization for hypertree width in terms of linear elimination orderings. We utilize this characterization to generate a new SAT encoding that we evaluate on an extensive set of benchmark instances. We compare it to state-of-the-art exact methods for computing optimal hypertree width. Our results show that the encoding based on the new characterization is not only significantly more compact than known encodings but also outperforms the other methods. Keywords: Constraints and SAT: Constraint Satisfaction Constraints and SAT: Constraints: Modeling, Solvers, Applications Constraints and SAT: Satisfiability Modulo Theories},
  archive   = {C_IJCAI},
  author    = {Andre Schidler and Stefan Szeider},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/196},
  pages     = {1418-1424},
  title     = {Computing optimal hypertree decompositions with SAT},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning implicitly with noisy data in linear arithmetic.
<em>IJCAI</em>, 1410–1417. (<a
href="https://doi.org/10.24963/ijcai.2021/195">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Robust learning in expressive languages with real-world data continues to be a challenging task. Numerous conventional methods appeal to heuristics without any assurances of robustness. While probably approximately correct (PAC) Semantics offers strong guarantees, learning explicit representations is not tractable, even in propositional logic. However, recent work on so-called “implicit&quot; learning has shown tremendous promise in terms of obtaining polynomial-time results for fragments of first-order logic. In this work, we extend implicit learning in PAC-Semantics to handle noisy data in the form of intervals and threshold uncertainty in the language of linear arithmetic. We prove that our extended framework keeps the existing polynomial-time complexity guarantees. Furthermore, we provide the first empirical investigation of this hitherto purely theoretical framework. Using benchmark problems, we show that our implicit approach to learning optimal linear programming objective constraints significantly outperforms an explicit approach in practice. Keywords: Constraints and SAT: Constraints and Data Mining; Constraints and Machine Learning},
  archive   = {C_IJCAI},
  author    = {Alexander Rader and Ionela G Mocanu and Vaishak Belle and Brendan Juba},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/195},
  pages     = {1410-1417},
  title     = {Learning implicitly with noisy data in linear arithmetic},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Backdoor DNFs. <em>IJCAI</em>, 1403–1409. (<a
href="https://doi.org/10.24963/ijcai.2021/194">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We introduce backdoor DNFs, as a tool to measure the theoretical hardness of CNF formulas. Like backdoor sets and backdoor trees, backdoor DNFs are defined relative to a tractable class of CNF formulas. Each conjunctive term of a backdoor DNF defines a partial assignment that moves the input CNF formula into the base class. Backdoor DNFs are more expressive and potentially smaller than their predecessors backdoor sets and backdoor trees. We establish the fixed-parameter tractability of the backdoor DNF detection problem. Our results hold for the fundamental base classes Horn and 2CNF, and their combination. We complement our theoretical findings by an empirical study. Our experiments show that backdoor DNFs provide a significant improvement over their predecessors. Keywords: Constraints and SAT: SAT: Algorithms and Techniques},
  archive   = {C_IJCAI},
  author    = {Sebastian Ordyniak and Andre Schidler and Stefan Szeider},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/194},
  pages     = {1403-1409},
  title     = {Backdoor DNFs},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Solving graph homomorphism and subgraph isomorphism problems
faster through clique neighbourhood constraints. <em>IJCAI</em>,
1396–1402. (<a href="https://doi.org/10.24963/ijcai.2021/193">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph homomorphism problems involve finding adjacency-preserving mappings between two given graphs. Although theoretically hard, these problems can often be solved in practice using constraint programming algorithms. We show how techniques from the state-of-the-art in subgraph isomorphism solving can be applied to broader graph homomorphism problems, and introduce a new form of filtering based upon clique-finding. We demonstrate empirically that this filtering is effective for the locally injective graph homomorphism and subgraph isomorphism problems, and gives the first practical constraint programming approach to finding general graph homomorphisms. Keywords: Constraints and SAT: Constraint Satisfaction Constraints and SAT: Constraints: Modeling, Solvers, Applications},
  archive   = {C_IJCAI},
  author    = {Sonja Kraiczy and Ciaran McCreesh},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/193},
  pages     = {1396-1402},
  title     = {Solving graph homomorphism and subgraph isomorphism problems faster through clique neighbourhood constraints},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Decomposition strategies to count integer solutions over
linear constraints. <em>IJCAI</em>, 1389–1395. (<a
href="https://doi.org/10.24963/ijcai.2021/192">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Counting integer solutions of linear constraints has found interesting applications in various fields. It is equivalent to the problem of counting integer points inside a polytope. However, state-of-the-art algorithms for this problem become too slow for even a modest number of variables. In this paper, we propose new decomposition techniques which target both the elimination of variables as well as inequalities using structural properties of counting problems. Experiments on extensive benchmarks show that our algorithm improves the performance of state-of-the-art counting algorithms, while the overhead is usually negligible compared to the running time of integer counting. Keywords: Constraints and SAT: SAT: Algorithms and Techniques Constraints and SAT: SAT: Solvers and Applications Constraints and SAT: Satisfiability Modulo Theories},
  archive   = {C_IJCAI},
  author    = {Cunjing Ge and Armin Biere},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/192},
  pages     = {1389-1395},
  title     = {Decomposition strategies to count integer solutions over linear constraints},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficiently explaining CSPs with unsatisfiable subset
optimization. <em>IJCAI</em>, 1381–1388. (<a
href="https://doi.org/10.24963/ijcai.2021/191">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We build on a recently proposed method for explaining solutions of constraint satisfaction problems. An explanation here is a sequence of simple inference steps, where the simplicity of an inference step is measured by the number and types of constraints and facts used, and where the sequence explains all logical consequences of the problem. We build on these formal foundations and tackle two emerging questions, namely how to generate explanations that are provably optimal (with respect to the given cost metric) and how to generate them efficiently. To answer these questions, we develop 1) an implicit hitting set algorithm for finding optimal unsatisfiable subsets; 2) a method to reduce multiple calls for (optimal) unsatisfiable subsets to a single call that takes constraints on the subset into account, and 3) a method for re-using relevant information over multiple calls to these algorithms. The method is also applicable to other problems that require finding cost-optimal unsatiable subsets. We specifically show that this approach can be used to effectively find sequences of optimal explanation steps for constraint satisfaction problems like logic grid puzzles. Keywords: Constraints and SAT: Constraint Satisfaction Constraints and SAT: SAT: Algorithms and Techniques Constraints and SAT: SAT: Solvers and Applications},
  archive   = {C_IJCAI},
  author    = {Emilio Gamba and Bart Bogaerts and Tias Guns},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/191},
  pages     = {1381-1388},
  title     = {Efficiently explaining CSPs with unsatisfiable subset optimization},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improved CP-based lagrangian relaxation approach with an
application to the TSP. <em>IJCAI</em>, 1374–1380. (<a
href="https://doi.org/10.24963/ijcai.2021/190">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {CP-based Lagrangian relaxation (CP-LR) is an efficient optimization technique that combines cost-based filtering with Lagrangian relaxation in a constraint programming context. The state-of-the-art filtering algorithms for the WeightedCircuit constraint that encodes the traveling salesman problem (TSP) are based on this approach. In this paper, we propose an improved CP-LR approach that locally modifies the Lagrangian multipliers in order to increase the number of filtered values. We also introduce two new algorithms based on the latter to filter WeightedCircuit. The experimental results on TSP instances show that our algorithms allow significant gains on the resolution time and the size of the search space when compared to the state-of-the-art implementation. Keywords: Constraints and SAT: Global Constraints Constraints and SAT: Constraint Optimization Constraints and SAT: Constraints: Modeling, Solvers, Applications},
  archive   = {C_IJCAI},
  author    = {Raphaël Boudreault and Claude-Guy Quimper},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/190},
  pages     = {1374-1380},
  title     = {Improved CP-based lagrangian relaxation approach with an application to the TSP},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reducing SAT to Max2SAT. <em>IJCAI</em>, 1367–1373. (<a
href="https://doi.org/10.24963/ijcai.2021/189">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the literature, we find reductions from 3SAT to Max2SAT. These reductions are based on the usage of a gadget, i.e., a combinatorial structure that allows translating constraints of one problem to constraints of another. Unfortunately, the generation of these gadgets lacks an intuitive or efficient method. In this paper, we provide an efficient and constructive method for Reducing SAT to Max2SAT and show empirical results of how MaxSAT solvers are more efficient than SAT solvers solving the translation of hard formulas for Resolution. Keywords: Constraints and SAT: Constraint Optimization Constraints and SAT: MaxSAT, MinSAT Constraints and SAT: SAT: Solvers and Applications},
  archive   = {C_IJCAI},
  author    = {Carlos Ansótegui and Jordi Levy},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/189},
  pages     = {1367-1373},
  title     = {Reducing SAT to Max2SAT},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). PoseGTAC: Graph transformer encoder-decoder with atrous
convolution for 3D human pose estimation. <em>IJCAI</em>, 1359–1365. (<a
href="https://doi.org/10.24963/ijcai.2021/188">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph neural networks (GNNs) have been widely used in the 3D human pose estimation task, since the pose representation of a human body can be naturally modeled by the graph structure. Generally, most of the existing GNN-based models utilize the restricted receptive ﬁelds of ﬁlters and single-scale information, while neglecting the valuable multi-scale contextual information. To tackle this issue, we propose a novel Graph Transformer Encoder-Decoder with Atrous Convolution, named PoseGTAC, to effectively extract multi-scale context and long-range information. In our proposed PoseGTAC model, Graph Atrous Convolution (GAC) and Graph Transformer Layer (GTL), respectively for the extraction of local multi-scale and global long-range information, are combined and stacked in an encoder-decoder structure, where graph pooling and unpooling are adopted for the interaction of multi-scale information from local to global (e.g., part-scale and body-scale). Extensive experiments on the Human3.6M and MPI-INF-3DHP datasets demonstrate that the proposed PoseGTAC model exceeds all previous methods and achieves state-of-the-art performance. Keywords: Computer Vision: Action Recognition Computer Vision: Biometrics, Face and Gesture Recognition Humans and AI: Human-Computer Interaction},
  archive   = {C_IJCAI},
  author    = {Yiran Zhu and Xing Xu and Fumin Shen and Yanli Ji and Lianli Gao and Heng Tao Shen},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/188},
  pages     = {1359-1365},
  title     = {PoseGTAC: Graph transformer encoder-decoder with atrous convolution for 3D human pose estimation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A sketch-transformer network for face photo-sketch
synthesis. <em>IJCAI</em>, 1352–1358. (<a
href="https://doi.org/10.24963/ijcai.2021/187">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present a face photo-sketch synthesis model, which converts a face photo into an artistic face sketch or recover a photo-realistic facial image from a sketch portrait. Recent progress has been made by convolutional neural networks (CNNs) and generative adversarial networks (GANs), so that promising results can be obtained through real-time end-to-end architectures. However, convolutional architectures tend to focus on local information and neglect long-range spatial dependency, which limits the ability of existing approaches in keeping global structural information. In this paper, we propose a Sketch-Transformer network for face photo-sketch synthesis, which consists of three closely-related modules, including a multi-scale feature and position encoder for patch-level feature and position embedding, a self-attention module for capturing long-range spatial dependency, and a multi-scale spatially-adaptive de-normalization decoder for image reconstruction. Such a design enables the model to generate reasonable detail texture while maintaining global structural information. Extensive experiments show that the proposed method achieves significant improvements over state-of-the-art approaches on both quantitative and qualitative evaluations. Keywords: Computer Vision: 2D and 3D Computer Vision Computer Vision: Biometrics, Face and Gesture Recognition},
  archive   = {C_IJCAI},
  author    = {Mingrui Zhu and Changcheng Liang and Nannan Wang and Xiaoyu Wang and Zhifeng Li and Xinbo Gao},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/187},
  pages     = {1352-1358},
  title     = {A sketch-transformer network for face photo-sketch synthesis},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). PointLIE: Locally invertible embedding for point cloud
sampling and recovery. <em>IJCAI</em>, 1345–1351. (<a
href="https://doi.org/10.24963/ijcai.2021/186">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Point Cloud Sampling and Recovery (PCSR) is critical for massive real-time point cloud collection and processing since raw data usually requires large storage and computation. This paper addresses a fundamental problem in PCSR: How to downsample the dense point cloud with arbitrary scales while preserving the local topology of discarded points in a case-agnostic manner (i.e., without additional storage for point relationships)? We propose a novel Locally Invertible Embedding (PointLIE) framework to unify the point cloud sampling and upsampling into one single framework through bi-directional learning. Specifically, PointLIE decouples the local geometric relationships between discarded points from the sampled points by progressively encoding the neighboring offsets to a latent variable. Once the latent variable is forced to obey a pre-defined distribution in the forward sampling path, the recovery can be achieved effectively through inverse operations. Taking the recover-pleasing sampled points and a latent embedding randomly drawn from the specified distribution as inputs, PointLIE can theoretically guarantee the fidelity of reconstruction and outperform state-of-the-arts quantitatively and qualitatively. Keywords: Computer Vision: 2D and 3D Computer Vision Machine Learning: Deep Learning},
  archive   = {C_IJCAI},
  author    = {Weibing Zhao and Xu Yan and Jiantao Gao and Ruimao Zhang and Jiayan Zhang and Zhen Li and Song Wu and Shuguang Cui},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/186},
  pages     = {1345-1351},
  title     = {PointLIE: Locally invertible embedding for point cloud sampling and recovery},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Rescuing deep hashing from dead bits problem.
<em>IJCAI</em>, 1338–1344. (<a
href="https://doi.org/10.24963/ijcai.2021/185">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep hashing methods have shown great retrieval accuracy and efficiency in large-scale image retrieval. How to optimize discrete hash bits is always the focus in deep hashing methods. A common strategy in these methods is to adopt an activation function, e.g. sigmoid() or tanh(), and minimize a quantization loss to approximate discrete values. However, this paradigm may make more and more hash bits stuck into the wrong saturated area of the activation functions and never escaped. We call this problem &quot;Dead Bits Problem (DBP)&quot;. Besides, the existing quantization loss will aggravate DBP as well. In this paper, we propose a simple but effective gradient amplifier which acts before activation functions to alleviate DBP. Moreover, we devise an error-aware quantization loss to further alleviate DBP. It avoids the negative effect of quantization loss based on the similarity between two images. The proposed gradient amplifier and error-aware quantization loss are compatible with a variety of deep hashing methods. Experimental results on three datasets demonstrate the efficiency of the proposed gradient amplifier and the error-aware quantization loss. Keywords: Computer Vision: Recognition: Detection, Categorization, Indexing, Matching, Retrieval, Semantic Interpretation Data Mining: Information Retrieval},
  archive   = {C_IJCAI},
  author    = {Shu Zhao and Dayan Wu and Yucan Zhou and Bo Li and Weiping Wang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/185},
  pages     = {1338-1344},
  title     = {Rescuing deep hashing from dead bits problem},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sequential 3D human pose estimation using adaptive point
cloud sampling strategy. <em>IJCAI</em>, 1330–1337. (<a
href="https://doi.org/10.24963/ijcai.2021/184">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {3D human pose estimation is a fundamental problem in artificial intelligence, and it has wide applications in AR/VR, HCI and robotics. However, human pose estimation from point clouds still suffers from noisy points and estimated jittery artifacts because of handcrafted-based point cloud sampling and single-frame-based estimation strategies. In this paper, we present a new perspective on the 3D human pose estimation method from point cloud sequences. To sample effective point clouds from input, we design a differentiable point cloud sampling method built on density-guided attention mechanism. To avoid the jitter caused by previous 3D human pose estimation problems, we adopt temporal information to obtain more stable results. Experiments on the ITOP dataset and the NTU-RGBD dataset demonstrate that all of our contributed components are effective, and our method can achieve state-of-the-art performance. Keywords: Computer Vision: 2D and 3D Computer Vision Computer Vision: Motion and Tracking Machine Learning: Deep Learning},
  archive   = {C_IJCAI},
  author    = {Zihao Zhang and Lei Hu and Xiaoming Deng and Shihong Xia},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/184},
  pages     = {1330-1337},
  title     = {Sequential 3D human pose estimation using adaptive point cloud sampling strategy},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Context-aware image inpainting with learned semantic priors.
<em>IJCAI</em>, 1323–1329. (<a
href="https://doi.org/10.24963/ijcai.2021/183">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent advances in image inpainting have shown impressive results for generating plausible visual details on rather simple backgrounds. However, for complex scenes, it is still challenging to restore reasonable contents as the contextual information within the missing regions tends to be ambiguous. To tackle this problem, we introduce pretext tasks that are semantically meaningful to estimating the missing contents. In particular, we perform knowledge distillation on pretext models and adapt the features to image inpainting. The learned semantic priors ought to be partially invariant between the high-level pretext task and low-level image inpainting, which not only help to understand the global context but also provide structural guidance for the restoration of local textures. Based on the semantic priors, we further propose a context-aware image inpainting model, which adaptively integrates global semantics and local features in a unified image generator. The semantic learner and the image generator are trained in an end-to-end manner. We name the model SPL to highlight its ability to learn and leverage semantic priors. It achieves the state of the art on Places2, CelebA, and Paris StreetView datasets Keywords: Computer Vision: 2D and 3D Computer Vision Machine Learning: Deep Learning},
  archive   = {C_IJCAI},
  author    = {Wendong Zhang and Junwei Zhu and Ying Tai and Yunbo Wang and Wenqing Chu and Bingbing Ni and Chengjie Wang and Xiaokang Yang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/183},
  pages     = {1323-1329},
  title     = {Context-aware image inpainting with learned semantic priors},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). What if we could not see? Counterfactual analysis for
egocentric action anticipation. <em>IJCAI</em>, 1316–1322. (<a
href="https://doi.org/10.24963/ijcai.2021/182">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Egocentric action anticipation aims at predicting the near future based on past observation in first-person vision. While future actions may be wrongly predicted due to the dataset bias, we present a counterfactual analysis framework for egocentric action anticipation (CA-EAA) to enhance the capacity. In the factual case, we can predict the upcoming action based on visual features and semantic labels from past observation. Imagining one counterfactual situation where no visual representation had been observed, we would obtain a counterfactual predicted action only using past semantic labels. In this way, we can reduce the side-effect caused by semantic labels via a comparison between factual and counterfactual outcomes, which moves a step towards unbiased prediction for egocentric action anticipation. We conduct experiments on two large-scale egocentric video datasets. Qualitative and quantitative results validate the effectiveness of our proposed CA-EAA. Keywords: Computer Vision: Video: Events, Activities and Surveillance},
  archive   = {C_IJCAI},
  author    = {Tianyu Zhang and Weiqing Min and Jiahao Yang and Tao Liu and Shuqiang Jiang and Yong Rui},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/182},
  pages     = {1316-1322},
  title     = {What if we could not see? counterfactual analysis for egocentric action anticipation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning implicit temporal alignment for few-shot video
classification. <em>IJCAI</em>, 1309–1315. (<a
href="https://doi.org/10.24963/ijcai.2021/181">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Few-shot video classification aims to learn new video categories with only a few labeled examples, alleviating the burden of costly annotation in real-world applications. However, it is particularly challenging to learn a class-invariant spatial-temporal representation in such a setting. To address this, we propose a novel matching-based few-shot learning strategy for video sequences in this work. Our main idea is to introduce an implicit temporal alignment for a video pair, capable of estimating the similarity between them in an accurate and robust manner. Moreover, we design an effective context encoding module to incorporate spatial and feature channel context, resulting in better modeling of intra-class variations. To train our model, we develop a multi-task loss for learning video matching, leading to video features with better generalization. Extensive experimental results on two challenging benchmarks, show that our method outperforms the prior arts with a sizable margin on Something-Something-V2 and competitive results on Kinetics. Keywords: Computer Vision: Action Recognition Machine Learning: Deep Learning},
  archive   = {C_IJCAI},
  author    = {Songyang Zhang and Jiale Zhou and Xuming He},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/181},
  pages     = {1309-1315},
  title     = {Learning implicit temporal alignment for few-shot video classification},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Removing foreground occlusions in light field using
micro-lens dynamic filter. <em>IJCAI</em>, 1302–1308. (<a
href="https://doi.org/10.24963/ijcai.2021/180">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Foreground occlusion removal task aims to automatically detect and remove foreground occlusions and recover background objects. Since for Light Fields (LFs), background objects occluded in some views may be seen in other views, the foreground occlusion removal task for LFs is easy to achieve. In this paper, we propose a learning-based method combining ‘seeking’ and ‘generating’ to recover occluded background. Specifically, the micro-lens dynamic filters are proposed to ‘seek’ occluded background points in shifted micro-lens images and remove occlusions using angular information. The shifted images are then combined to further ‘generate’ background regions to supplement more background details using spatial information. By fully exploring the angular and spatial information in LFs, the dense and complex occlusions can be easily removed. Quantitative and qualitative experimental results show that our method outperforms other state-of-the-arts methods by a large margin. Keywords: Computer Vision: 2D and 3D Computer Vision Computer Vision: Computational Photography, Photometry, Shape from X},
  archive   = {C_IJCAI},
  author    = {Shuo Zhang and Zeqi Shen and Youfang Lin},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/180},
  pages     = {1302-1308},
  title     = {Removing foreground occlusions in light field using micro-lens dynamic filter},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Low resolution information also matters: Learning
multi-resolution representations for person re-identification.
<em>IJCAI</em>, 1295–1301. (<a
href="https://doi.org/10.24963/ijcai.2021/179">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As a prevailing task in video surveillance and forensics field, person re-identification (re-ID) aims to match person images captured from non-overlapped cameras. In unconstrained scenarios, person images often suffer from the resolution mismatch problem, i.e., Cross-Resolution Person Re-ID. To overcome this problem, most existing methods restore low resolution (LR) images to high resolution (HR) by super-resolution (SR). However, they only focus on the HR feature extraction and ignore the valid information from original LR images. In this work, we explore the influence of resolutions on feature extraction and develop a novel method for cross-resolution person re-ID called Multi-Resolution Representations Joint Learning (MRJL). Our method consists of a Resolution Reconstruction Network (RRN) and a Dual Feature Fusion Network (DFFN). The RRN uses an input image to construct a HR version and a LR version with an encoder and two decoders, while the DFFN adopts a dual-branch structure to generate person representations from multi-resolution images. Comprehensive experiments on five benchmarks verify the superiority of the proposed MRJL over the relevent state-of-the-art methods. Keywords: Computer Vision: Biometrics, Face and Gesture Recognition Machine Learning Applications: Applications of Supervised Learning Machine Learning Applications: Networks},
  archive   = {C_IJCAI},
  author    = {Guoqing Zhang and Yuhao Chen and Weisi Lin and Arun Chandran and Xuan Jing},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/179},
  pages     = {1295-1301},
  title     = {Low resolution information also matters: Learning multi-resolution representations for person re-identification},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Detecting deepfake videos with temporal dropout 3DCNN.
<em>IJCAI</em>, 1288–1294. (<a
href="https://doi.org/10.24963/ijcai.2021/178">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {While the abuse of deepfake technology has brought about a serious impact on human society, the detection of deepfake videos is still very challenging due to their highly photorealistic synthesis on each frame. To address that, this paper aims to leverage the possible inconsistent cues among video frames and proposes a Temporal Dropout 3-Dimensional Convolutional Neural Network (TD-3DCNN) to detect deepfake videos. In the approach, the fixed-length frame volumes sampled from a video are fed into a 3-Dimensional Convolutional Neural Network (3DCNN) to extract features across different scales and identified whether they are real or fake. Especially, a temporal dropout operation is introduced to randomly sample frames in each batch. It serves as a simple yet effective data augmentation and can enhance the representation and generalization ability, avoiding model overfitting and improving detecting accuracy. In this way, the resulting video-level classifier is accurate and effective to identify deepfake videos. Extensive experiments on benchmarks including Celeb-DF(v2) and DFDC clearly demonstrate the effectiveness and generalization capacity of our approach. Keywords: Computer Vision: Biometrics, Face and Gesture Recognition AI Ethics, Trust, Fairness: Fairness AI Ethics, Trust, Fairness: Surveillance, Manipulation of People},
  archive   = {C_IJCAI},
  author    = {Daichi Zhang and Chenyu Li and Fanzhao Lin and Dan Zeng and Shiming Ge},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/178},
  pages     = {1288-1294},
  title     = {Detecting deepfake videos with temporal dropout 3DCNN},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dual-cross central difference network for face
anti-spoofing. <em>IJCAI</em>, 1281–1287. (<a
href="https://doi.org/10.24963/ijcai.2021/177">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Face anti-spoofing (FAS) plays a vital role in securing face recognition systems. Recently, central difference convolution (CDC) has shown its excellent representation capacity for the FAS task via leveraging local gradient features. However, aggregating central difference clues from all neighbors/directions simultaneously makes the CDC redundant and sub-optimized in the training phase. In this paper, we propose two Cross Central Difference Convolutions (C-CDC), which exploit the difference of the center and surround sparse local features from the horizontal/vertical and diagonal directions, respectively. It is interesting to find that, with only five ninth parameters and less computational cost, C-CDC even outperforms the full directional CDC. Based on these two decoupled C-CDC, a powerful Dual-Cross Central Difference Network (DC-CDN) is established with Cross Feature Interaction Modules (CFIM) for mutual relation mining and local detailed representation enhancement. Furthermore, a novel Patch Exchange (PE) augmentation strategy for FAS is proposed via simply exchanging the face patches as well as their dense labels from random samples. Thus, the augmented samples contain richer live/spoof patterns and diverse domain distributions, which benefits the intrinsic and robust feature learning. Comprehensive experiments are performed on four benchmark datasets with three testing protocols to demonstrate our state-of-the-art performance. Keywords: Computer Vision: Biometrics, Face and Gesture Recognition Machine Learning: Deep Learning AI Ethics, Trust, Fairness: Surveillance, Manipulation of People},
  archive   = {C_IJCAI},
  author    = {Zitong Yu and Yunxiao Qin and Hengshuang Zhao and Xiaobai Li and Guoying Zhao},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/177},
  pages     = {1281-1287},
  title     = {Dual-cross central difference network for face anti-spoofing},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). CogTree: Cognition tree loss for unbiased scene graph
generation. <em>IJCAI</em>, 1274–1280. (<a
href="https://doi.org/10.24963/ijcai.2021/176">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Scene graphs are semantic abstraction of images that encourage visual understanding and reasoning. However, the performance of Scene Graph Generation (SGG) is unsatisfactory when faced with biased data in real-world scenarios. Conventional debiasing research mainly studies from the view of balancing data distribution or learning unbiased models and representations, ignoring the correlations among the biased classes. In this work, we analyze this problem from a novel cognition perspective: automatically building a hierarchical cognitive structure from the biased predictions and navigating that hierarchy to locate the relationships, making the tail relationships receive more attention in a coarse-to-fine mode. To this end, we propose a novel debiasing Cognition Tree (CogTree) loss for unbiased SGG. We first build a cognitive structure CogTree to organize the relationships based on the prediction of a biased SGG model. The CogTree distinguishes remarkably different relationships at first and then focuses on a small portion of easily confused ones. Then, we propose a debiasing loss specially for this cognitive structure, which supports coarse-to-fine distinction for the correct relationships. The loss is model-agnostic and consistently boosting the performance of several state-of-the-art models. The code is available at: https://github.com/CYVincent/Scene-Graph-Transformer-CogTree. Keywords: Computer Vision: Language and Vision},
  archive   = {C_IJCAI},
  author    = {Jing Yu and Yuan Chai and Yujing Wang and Yue Hu and Qi Wu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/176},
  pages     = {1274-1280},
  title     = {CogTree: Cognition tree loss for unbiased scene graph generation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). EmbedMask: Embedding coupling for instance segmentation.
<em>IJCAI</em>, 1266–1273. (<a
href="https://doi.org/10.24963/ijcai.2021/175">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Current instance segmentation methods can be categorized into segmentation-based methods and proposal-based methods. The former performs segmentation first and then does clustering, while the latter detects objects first and then predicts the mask for each object proposal. In this work, we propose a single-stage method, named EmbedMask, that unifies both methods by taking their advantages, so it can achieve good performance in instance segmentation and produce high-resolution masks in a high speed. EmbedMask introduces two newly defined embeddings for mask prediction, which are pixel embedding and proposal embedding. During training, we enforce the pixel embedding to be close to its coupled proposal embedding if they belong to the same instance. During inference, pixels are assigned to the mask of the proposal if their embeddings are similar. This mechanism brings several benefits. First, the pixel-level clustering enables EmbedMask to generate high-resolution masks and avoids the complicated two-stage mask prediction. Second, the existence of proposal embedding simplifies and strengthens the clustering procedure, so our method can achieve high speed and better performance than segmentation-based methods. Without any bell or whistle, EmbedMask outperforms the state-of-the-art instance segmentation method Mask R-CNN on the challenging COCO dataset, obtaining more detailed masks at a higher speed. Keywords: Computer Vision: Recognition: Detection, Categorization, Indexing, Matching, Retrieval, Semantic Interpretation},
  archive   = {C_IJCAI},
  author    = {Hui Ying and Zhaojin Huang and Shu Liu and Tianjia Shao and Kun Zhou},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/175},
  pages     = {1266-1273},
  title     = {EmbedMask: Embedding coupling for instance segmentation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multimodal transformer networks for pedestrian trajectory
prediction. <em>IJCAI</em>, 1259–1265. (<a
href="https://doi.org/10.24963/ijcai.2021/174">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider the problem of forecasting the future locations of pedestrians in an ego-centric view of a moving vehicle. Current CNNs or RNNs are flawed in capturing the high dynamics of motion between pedestrians and the ego-vehicle, and suffer from the massive parameter usages due to the inefficiency of learning long-term temporal dependencies. To address these issues, we propose an efficient multimodal transformer network that aggregates the trajectory and ego-vehicle speed variations at a coarse granularity and interacts with the optical flow in a fine-grained level to fill the vacancy of highly dynamic motion. Specifically, a coarse-grained fusion stage fuses the information between trajectory and ego-vehicle speed modalities to capture the general temporal consistency. Meanwhile, a fine-grained fusion stage merges the optical flow in the center area and pedestrian area, which compensates the highly dynamic motion of ego-vehicle and target pedestrian. Besides, the whole network is only attention-based that can efficiently model long-term sequences for better capturing the temporal variations. Our multimodal transformer is validated on the PIE and JAAD datasets and achieves state-of-the-art performance with the most light-weight model size. The codes are available at https://github.com/ericyinyzy/MTN_trajectory. Keywords: Computer Vision: 2D and 3D Computer Vision Computer Vision: Structural and Model-Based Approaches, Knowledge Representation and Reasoning Multidisciplinary Topics and Applications: Transportation},
  archive   = {C_IJCAI},
  author    = {Ziyi Yin and Ruijin Liu and Zhiliang Xiong and Zejian Yuan},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/174},
  pages     = {1259-1265},
  title     = {Multimodal transformer networks for pedestrian trajectory prediction},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adv-makeup: A new imperceptible and transferable attack on
face recognition. <em>IJCAI</em>, 1252–1258. (<a
href="https://doi.org/10.24963/ijcai.2021/173">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep neural networks, particularly face recognition models, have been shown to be vulnerable to both digital and physical adversarial examples. However, existing adversarial examples against face recognition systems either lack transferability to black-box models, or fail to be implemented in practice. In this paper, we propose a unified adversarial face generation method - Adv-Makeup, which can realize imperceptible and transferable attack under the black-box setting. Adv-Makeup develops a task-driven makeup generation method with the blending module to synthesize imperceptible eye shadow over the orbital region on faces. And to achieve transferability, Adv-Makeup implements a fine-grained meta-learning based adversarial attack strategy to learn more vulnerable or sensitive features from various models. Compared to existing techniques, sufficient visualization results demonstrate that Adv-Makeup is capable to generate much more imperceptible attacks under both digital and physical scenarios. Meanwhile, extensive quantitative experiments show that Adv-Makeup can significantly improve the attack success rate under black-box setting, even attacking commercial systems. Keywords: Computer Vision: Biometrics, Face and Gesture Recognition Computer Vision: Recognition: Detection, Categorization, Indexing, Matching, Retrieval, Semantic Interpretation Machine Learning: Adversarial Machine Learning},
  archive   = {C_IJCAI},
  author    = {Bangjie Yin and Wenxuan Wang and Taiping Yao and Junfeng Guo and Zelun Kong and Shouhong Ding and Jilin Li and Cong Liu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/173},
  pages     = {1252-1258},
  title     = {Adv-makeup: A new imperceptible and transferable attack on face recognition},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Object detection in densely packed scenes via
semi-supervised learning with dual consistency. <em>IJCAI</em>,
1245–1251. (<a href="https://doi.org/10.24963/ijcai.2021/172">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep neural networks have been shown to be very powerful tools for object detection in various scenes. Their remarkable performance, however, heavily depends on the availability of a large number of high quality labeled data, which are time-consuming and costly to acquire for scenes with densely packed objects. We present a novel semi-supervised approach to addressing this problem, which is designed based on a common teacher-student model, integrated with a novel intersection-over-union (IoU) aware consistency loss and a new proposal consistency loss. The IoU-aware consistency loss evaluates the IoU over the prediction pairs of the teacher model and the student model, which enforces the prediction of the student model to approach closely to that of the teacher model. The IoU-aware consistency loss also reweights the importance of different prediction pairs to suppress the low-confident pairs. The proposal consistency loss ensures proposal consistency between the two models, making it possible to involve the region proposal network in the training process with unlabeled data. We also construct a new dataset, namely RebarDSC, containing 2, 125 rebar images annotated with 350, 348 bounding boxes in total (164.9 annotations per image average), to evaluate the proposed method. Extensive experiments are conducted over both the RebarDSC dataset and the famous large public dataset SKU-110K. Experimental results corroborate that the proposed method is able to improve the object detection performance in densely packed scenes, consistently outperforming state-of-the-art approaches. Dataset is available in https://github.com/Armin1337/RebarDSC. Keywords: Computer Vision: Recognition: Detection, Categorization, Indexing, Matching, Retrieval, Semantic Interpretation Machine Learning: Deep Learning Machine Learning: Semi-Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Chao Ye and Huaidong Zhang and Xuemiao Xu and Weiwei Cai and Jing Qin and Kup-Sze Choi},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/172},
  pages     = {1245-1251},
  title     = {Object detection in densely packed scenes via semi-supervised learning with dual consistency},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Coupling intent and action for pedestrian crossing behavior
prediction. <em>IJCAI</em>, 1238–1244. (<a
href="https://doi.org/10.24963/ijcai.2021/171">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Accurate prediction of pedestrian crossing behaviors by autonomous vehicles can significantly improve traffic safety. Existing approaches often model pedestrian behaviors using trajectories or poses but do not offer a deeper semantic interpretation of a person&#39;s actions or how actions influence a pedestrian&#39;s intention to cross in the future. In this work, we follow the neuroscience and psychological literature to define pedestrian crossing behavior as a combination of an unobserved inner will (a probabilistic representation of binary intent of crossing vs. not crossing) and a set of multi-class actions (e.g., walking, standing, etc.). Intent generates actions, and the future actions in turn reflect the intent. We present a novel multi-task network that predicts future pedestrian actions and uses predicted future action as a prior to detect the present intent and action of the pedestrian. We also designed an attention relation network to incorporate external environmental contexts thus further improve intent and action detection performance. We evaluated our approach on two naturalistic driving datasets, PIE and JAAD, and extensive experiments show significantly improved and more explainable results for both intent detection and action prediction over state-of-the-art approaches. Our code is available at: https://github.com/umautobots/pedestrian_intent_action_detection Keywords: Computer Vision: Action Recognition Robotics: Robotics and Vision Robotics: Vision and Perception},
  archive   = {C_IJCAI},
  author    = {Yu Yao and Ella Atkins and Matthew Johnson-Roberson and Ram Vasudevan and Xiaoxiao Du},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/171},
  pages     = {1238-1244},
  title     = {Coupling intent and action for pedestrian crossing behavior prediction},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Non-contact pain recognition from video sequences with
remote physiological measurements prediction. <em>IJCAI</em>, 1231–1237.
(<a href="https://doi.org/10.24963/ijcai.2021/170">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Automatic pain recognition is paramount for medical diagnosis and treatment. The existing works fall into three categories: assessing facial appearance changes, exploiting physiological cues, or fusing them in a multi-modal manner. However, (1) appearance changes are easily affected by subjective factors which impedes objective pain recognition. Besides, the appearance-based approaches ignore long-range spatial-temporal dependencies that are important for modeling expressions over time; (2) the physiological cues are obtained by attaching sensors on human body, which is inconvenient and uncomfortable. In this paper, we present a novel multi-task learning framework which encodes both appearance changes and physiological cues in a non-contact manner for pain recognition. The framework is able to capture both local and long-range dependencies via the proposed attention mechanism for the learned appearance representations, which are further enriched by temporally attended physiological cues (remote photoplethysmography, rPPG) that are recovered from videos in the auxiliary task. This framework is dubbed rPPG-enriched Spatio-Temporal Attention Network (rSTAN) and allows us to establish the state-of-the-art performance of non-contact pain recognition on publicly available pain databases. It demonstrates that rPPG predictions can be used as an auxiliary task to facilitate non-contact automatic pain recognition. Keywords: Computer Vision: Biometrics, Face and Gesture Recognition Multidisciplinary Topics and Applications: AI for Life Science},
  archive   = {C_IJCAI},
  author    = {Ruijing Yang and Ziyu Guan and Zitong Yu and Xiaoyi Feng and Jinye Peng and Guoying Zhao},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/170},
  pages     = {1231-1237},
  title     = {Non-contact pain recognition from video sequences with remote physiological measurements prediction},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). RR-net: Injecting interactive semantics in human-object
interaction detection. <em>IJCAI</em>, 1224–1230. (<a
href="https://doi.org/10.24963/ijcai.2021/169">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Human-Object Interaction (HOI) detection devotes to learn how humans interact with surrounding objects. Latest end-to-end HOI detectors are short of relation reasoning, which leads to inability to learn HOI-specific interactive semantics for predictions. In this paper, we therefore propose novel relation reasoning for HOI detection. We first present a progressive Relation-aware Frame, which brings a new structure and parameter sharing pattern for interaction inference. Upon the frame, an Interaction Intensifier Module and a Correlation Parsing Module are carefully designed, where: a) interactive semantics from humans can be exploited and passed to objects to intensify interactions, b) interactive correlations among humans, objects and interactions are integrated to promote predictions. Based on modules above, we construct an end-to-end trainable framework named Relation Reasoning Network (abbr. RR-Net). Extensive experiments show that our proposed RR-Net sets a new state-of-the-art on both V-COCO and HICO-DET benchmarks and improves the baseline about 5.5\% and 9.8\% relatively, validating that this first effort in exploring relation reasoning and integrating interactive semantics has brought obvious improvement for end-to-end HOI detection. Keywords: Computer Vision: Recognition: Detection, Categorization, Indexing, Matching, Retrieval, Semantic Interpretation Computer Vision: Action Recognition Computer Vision: Video: Events, Activities and Surveillance},
  archive   = {C_IJCAI},
  author    = {Dongming Yang and Yuexian Zou and Can Zhang and Meng Cao and Jie Chen},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/169},
  pages     = {1224-1230},
  title     = {RR-net: Injecting interactive semantics in human-object interaction detection},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hierarchical self-supervised augmented knowledge
distillation. <em>IJCAI</em>, 1217–1223. (<a
href="https://doi.org/10.24963/ijcai.2021/168">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Knowledge distillation often involves how to define and transfer knowledge from teacher to student effectively. Although recent self-supervised contrastive knowledge achieves the best performance, forcing the network to learn such knowledge may damage the representation learning of the original class recognition task. We therefore adopt an alternative self-supervised augmented task to guide the network to learn the joint distribution of the original recognition task and self-supervised auxiliary task. It is demonstrated as a richer knowledge to improve the representation power without losing the normal classification capability. Moreover, it is incomplete that previous methods only transfer the probabilistic knowledge between the final layers. We propose to append several auxiliary classifiers to hierarchical intermediate feature maps to generate diverse self-supervised knowledge and perform the one-to-one transfer to teach the student network thoroughly. Our method significantly surpasses the previous SOTA SSKD with an average improvement of 2.56\% on CIFAR-100 and an improvement of 0.77\% on ImageNet across widely used network pairs. Codes are available at https://github.com/winycg/HSAKD. Keywords: Computer Vision: Recognition: Detection, Categorization, Indexing, Matching, Retrieval, Semantic Interpretation},
  archive   = {C_IJCAI},
  author    = {Chuanguang Yang and Zhulin An and Linhang Cai and Yongjun Xu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/168},
  pages     = {1217-1223},
  title     = {Hierarchical self-supervised augmented knowledge distillation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Tool- and domain-agnostic parameterization of style transfer
effects leveraging pretrained perceptual metrics. <em>IJCAI</em>,
1208–1216. (<a href="https://doi.org/10.24963/ijcai.2021/167">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Current deep learning techniques for style transfer would not be optimal for design support since their &quot;one-shot&quot; transfer does not fit exploratory design processes. To overcome this gap, we propose parametric transcription, which transcribes an end-to-end style transfer effect into parameter values of specific transformations available in an existing content editing tool. With this approach, users can imitate the style of a reference sample in the tool that they are familiar with and thus can easily continue further exploration by manipulating the parameters. To enable this, we introduce a framework that utilizes an existing pretrained model for style transfer to calculate a perceptual style distance to the reference sample and uses black-box optimization to find the parameters that minimize this distance. Our experiments with various third-party tools, such as Instagram and Blender, show that our framework can effectively leverage deep learning techniques for computational design support. Keywords: Computer Vision: 2D and 3D Computer Vision Humans and AI: Human-AI Collaboration Humans and AI: Intelligent User Interfaces},
  archive   = {C_IJCAI},
  author    = {Hiromu Yakura and Yuki Koyama and Masataka Goto},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/167},
  pages     = {1208-1216},
  title     = {Tool- and domain-agnostic parameterization of style transfer effects leveraging pretrained perceptual metrics},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adversarial feature disentanglement for long-term person
re-identification. <em>IJCAI</em>, 1201–1207. (<a
href="https://doi.org/10.24963/ijcai.2021/166">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Most existing person re-identification methods are effective in short-term scenarios because of their appearance dependencies. However, these methods may fail in long-term scenarios where people might change their clothes. To this end, we propose an adversarial feature disentanglement network (AFD-Net) which contains intra-class reconstruction and inter-class adversary to disentangle the identity-related and identity-unrelated (clothing) features. For intra-class reconstruction, the person images with the same identity are represented and disentangled into identity and clothing features by two separate encoders, and further reconstructed into original images to reduce intra-class feature variations. For inter-class adversary, the disentangled features across different identities are exchanged and recombined to generate adversarial clothes-changing images for training, which makes the identity and clothing features more independent. Especially, to supervise these new generated clothes-changing images, a re-feeding strategy is designed to re-disentangle and reconstruct these new images for image-level self-supervision in the original image space and feature-level soft-supervision in the disentangled feature space. Moreover, we collect a challenging Market-Clothes dataset and a real-world PKU-Market-Reid dataset for evaluation. The results on one large-scale short-term dataset (Market-1501) and five long-term datasets (three public and two we proposed) confirm the superiority of our method against other state-of-the-art methods. Keywords: Computer Vision: Recognition: Detection, Categorization, Indexing, Matching, Retrieval, Semantic Interpretation Machine Learning: Deep Learning Machine Learning: Learning Generative Models Data Mining: Classification},
  archive   = {C_IJCAI},
  author    = {Wanlu Xu and Hong Liu and Wei Shi and Ziling Miao and Zhisheng Lu and Feihu Chen},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/166},
  pages     = {1201-1207},
  title     = {Adversarial feature disentanglement for long-term person re-identification},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Segmenting transparent objects in the wild with transformer.
<em>IJCAI</em>, 1194–1200. (<a
href="https://doi.org/10.24963/ijcai.2021/165">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This work presents a new fine-grained transparent object segmentation dataset, termed Trans10K-v2, extending Trans10K-v1, the first large-scale transparent object segmentation dataset. Unlike Trans10K-v1 that only has two limited categories, our new dataset has several appealing benefits. (1) It has 11 fine-grained categories of transparent objects, commonly occurring in the human domestic environment, making it more practical for real-world application. (2) Trans10K-v2 brings more challenges for the current advanced segmentation methods than its former version. Furthermore, a novel Transformer-based segmentation pipeline termed Trans2Seg is proposed. Firstly, the Transformer encoder of Trans2Seg provides the global receptive field in contrast to CNN&#39;s local receptive field, which shows excellent advantages over pure CNN architectures. Secondly, by formulating semantic segmentation as a problem of dictionary look-up, we design a set of learnable prototypes as the query of Trans2Seg&#39;s Transformer decoder, where each prototype learns the statistics of one category in the whole dataset. We benchmark more than 20 recent semantic segmentation methods, demonstrating that Trans2Seg significantly outperforms all the CNN-based methods, showing the proposed algorithm&#39;s potential ability to solve transparent object segmentation.Code is available in https://github.com/xieenze/Trans2Seg. Keywords: Computer Vision: Perception Computer Vision: Recognition: Detection, Categorization, Indexing, Matching, Retrieval, Semantic Interpretation},
  archive   = {C_IJCAI},
  author    = {Enze Xie and Wenjia Wang and Wenhai Wang and Peize Sun and Hang Xu and Ding Liang and Ping Luo},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/165},
  pages     = {1194-1200},
  title     = {Segmenting transparent objects in the wild with transformer},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Micro-expression recognition enhanced by macro-expression
from spatial-temporal domain. <em>IJCAI</em>, 1186–1193. (<a
href="https://doi.org/10.24963/ijcai.2021/164">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Facial micro-expression recognition has attracted much attention due to its objectiveness to reveal the true emotion of a person. However, the limited micro-expression datasets have posed a great challenge to train a high performance micro-expression classifier. Since micro-expression and macro-expression share some similarities in both spatial and temporal facial behavior patterns, we propose a macro-to-micro transformation framework for micro-expression recognition. Specifically, we first pretrain two-stream baseline model from micro-expression data and macro-expression data respectively, named MiNet and MaNet. Then, we introduce two auxiliary tasks to align the spatial and temporal features learned from micro-expression data and macro-expression data. In spatial domain, we introduce a domain discriminator to align the features of MiNet and MaNet. In temporal domain, we introduce relation classifier to predict the correct relation for temporal features from MaNet and MiNet. Finally, we propose contrastive loss to encourage the MiNet to give closely aligned features to all entries from the same class in each instance. Experiments on three benchmark databases demonstrate the superiority of the proposed method. Keywords: Computer Vision: Biometrics, Face and Gesture Recognition},
  archive   = {C_IJCAI},
  author    = {Bin Xia and Shangfei Wang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/164},
  pages     = {1186-1193},
  title     = {Micro-expression recognition enhanced by macro-expression from spatial-temporal domain},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). GM-MLIC: Graph matching based multi-label image
classification. <em>IJCAI</em>, 1179–1185. (<a
href="https://doi.org/10.24963/ijcai.2021/163">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-Label Image Classification (MLIC) aims to predict a set of labels that present in an image. The key to deal with such problem is to mine the associations between image contents and labels, and further obtain the correct assignments between images and their labels. In this paper, we treat each image as a bag of instances, and reformulate the task of MLIC as a instance-label matching selection problem. To model such problem, we propose a novel deep learning framework named Graph Matching based Multi-Label Image Classification (GM-MLIC), where Graph Matching (GM) scheme is introduced owing to its excellent capability of excavating the instance and label relationship. Specifically, we first construct an instance spatial graph and a label semantic graph respectively, and then incorporate them into a constructed assignment graph by connecting each instance to all labels. Subsequently, the graph network block is adopted to aggregate and update all nodes and edges state on the assignment graph to form structured representations for each instance and label. Our network finally derives a prediction score for each instance-label correspondence and optimizes such correspondence with a weighted cross-entropy loss. Extensive experiments conducted on various datasets demonstrate the superiority of our proposed method. Keywords: Computer Vision: Recognition: Detection, Categorization, Indexing, Matching, Retrieval, Semantic Interpretation Machine Learning: Multi-instance; Multi-label; Multi-view learning Machine Learning Applications: Applications of Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Yanan Wu and He Liu and Songhe Feng and Yi Jin and Gengyu Lyu and Zizhang Wu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/163},
  pages     = {1179-1185},
  title     = {GM-MLIC: Graph matching based multi-label image classification},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Weakly-supervised spatio-temporal anomaly detection in
surveillance video. <em>IJCAI</em>, 1172–1178. (<a
href="https://doi.org/10.24963/ijcai.2021/162">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we introduce a novel task, referred to as Weakly-Supervised Spatio-Temporal Anomaly Detection (WSSTAD) in surveillance video. Specifically, given an untrimmed video, WSSTAD aims to localize a spatio-temporal tube (i.e., a sequence of bounding boxes at consecutive times) that encloses the abnormal event, with only coarse video-level annotations as supervision during training. To address this challenging task, we propose a dual-branch network which takes as input the proposals with multi-granularities in both spatial-temporal domains. Each branch employs a relationship reasoning module to capture the correlation between tubes/videolets, which can provide rich contextual information and complex entity relationships for the concept learning of abnormal behaviors. Mutually-guided Progressive Refinement framework is set up to employ dual-path mutual guidance in a recurrent manner, iteratively sharing auxiliary supervision information across branches. It impels the learned concepts of each branch to serve as a guide for its counterpart, which progressively refines the corresponding branch and the whole framework. Furthermore, we contribute two datasets, i.e., ST-UCF-Crime and STRA, consisting of videos containing spatio-temporal abnormal annotations to serve as the benchmarks for WSSTAD. We conduct extensive qualitative and quantitative evaluations to demonstrate the effectiveness of the proposed approach and analyze the key factors that contribute more to handle this task. Keywords: Computer Vision: Video: Events, Activities and Surveillance Machine Learning: Weakly Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Jie Wu and Wei Zhang and Guanbin Li and Wenhao Wu and Xiao Tan and Yingying Li and Errui Ding and Liang Lin},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/162},
  pages     = {1172-1178},
  title     = {Weakly-supervised spatio-temporal anomaly detection in surveillance video},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Tracklet proposal network for multi-object tracking on point
clouds. <em>IJCAI</em>, 1165–1171. (<a
href="https://doi.org/10.24963/ijcai.2021/161">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper proposes the first tracklet proposal network, named PC-TCNN, for Multi-Object Tracking (MOT) on point clouds. Our pipeline first generates tracklet proposals, then refines these tracklets and associates them to generate long trajectories. Specifically, object proposal generation and motion regression are first performed on a point cloud sequence to generate tracklet candidates. Then, spatial-temporal features of each tracklet are exploited and their consistency is used to refine the tracklet proposal. Finally, the refined tracklets across multiple frames are associated to perform MOT on the point cloud sequence. The PC-TCNN significantly improves the MOT performance by introducing the tracklet proposal design. On the KITTI tracking benchmark, it attains an MOTA of 91.75\%, outperforming all submitted results on the online leaderboard. Keywords: Computer Vision: Motion and Tracking},
  archive   = {C_IJCAI},
  author    = {Hai Wu and Qing Li and Chenglu Wen and Xin Li and Xiaoliang Fan and Cheng Wang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/161},
  pages     = {1165-1171},
  title     = {Tracklet proposal network for multi-object tracking on point clouds},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Weakly supervised dense video captioning via jointly usage
of knowledge distillation and cross-modal matching. <em>IJCAI</em>,
1157–1164. (<a href="https://doi.org/10.24963/ijcai.2021/160">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper proposes an approach to Dense Video Captioning (DVC) without pairwise event-sentence annotation. First, we adopt the knowledge distilled from relevant and well solved tasks to generate high-quality event proposals. Then we incorporate contrastive loss and cycle-consistency loss typically applied to cross-modal retrieval tasks to build semantic matching between the proposals and sentences, which are eventually used to train the caption generation module. In addition, the parameters of matching module are initialized via pre-training based on annotated images to improve the matching performance. Extensive experiments on ActivityNet-Caption dataset reveal the significance of distillation-based event proposal generation and cross-modal retrieval-based semantic matching to weakly supervised DVC, and demonstrate the superiority of our method to existing state-of-the-art methods. Keywords: Computer Vision: Language and Vision Machine Learning: Multi-instance; Multi-label; Multi-view learning},
  archive   = {C_IJCAI},
  author    = {Bofeng Wu and Guocheng Niu and Jun Yu and Xinyan Xiao and Jian Zhang and Hua Wu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/160},
  pages     = {1157-1164},
  title     = {Weakly supervised dense video captioning via jointly usage of knowledge distillation and cross-modal matching},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Local representation is not enough: Soft point-wise
transformer for descriptor and detector of local features.
<em>IJCAI</em>, 1150–1156. (<a
href="https://doi.org/10.24963/ijcai.2021/159">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Significant progress has been witnessed for the descriptor and detector of local features, but there still exist several challenging and intractable limitations, such as insufficient localization accuracy and non-discriminative description, especially in repetitive- or blank-texture regions, which haven&#39;t be well addressed. The coarse feature representation and limited receptive field are considered as the main issues for these limitations. To address these issues, we propose a novel Soft Point-Wise Transformer for Descriptor and Detector, simultaneously mining long-range intrinsic and cross-scale dependencies of local features. Furthermore, our model leverages the distinct transformers based on the soft point-wise attention, substantially decreasing the memory and computation complexity, especially for high-resolution feature maps. In addition, multi-level decoder is constructed to guarantee the high detection accuracy and discriminative description. Extensive experiments demonstrate that our model outperforms the existing state-of-the-art methods on the image matching and visual localization benchmarks. Keywords: Computer Vision: 2D and 3D Computer Vision Computer Vision: Recognition: Detection, Categorization, Indexing, Matching, Retrieval, Semantic Interpretation},
  archive   = {C_IJCAI},
  author    = {Zihao Wang and Xueyi Li and Zhen Li},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/159},
  pages     = {1150-1156},
  title     = {Local representation is not enough: Soft point-wise transformer for descriptor and detector of local features},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Domain-smoothing network for zero-shot sketch-based image
retrieval. <em>IJCAI</em>, 1143–1149. (<a
href="https://doi.org/10.24963/ijcai.2021/158">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Zero-Shot Sketch-Based Image Retrieval (ZS-SBIR) is a novel cross-modal retrieval task, where abstract sketches are used as queries to retrieve natural images under zero-shot scenario. Most existing methods regard ZS-SBIR as a traditional classification problem and employ a cross-entropy or triplet-based loss to achieve retrieval, which neglect the problems of the domain gap between sketches and natural images and the large intra-class diversity in sketches. Toward this end, we propose a novel Domain-Smoothing Network (DSN) for ZS-SBIR. Specifically, a cross-modal contrastive method is proposed to learn generalized representations to smooth the domain gap by mining relations with additional augmented samples. Furthermore, a category-specific memory bank with sketch features is explored to reduce intra-class diversity in the sketch domain. Extensive experiments demonstrate that our approach notably outperforms the state-of-the-art methods in both Sketchy and TU-Berlin datasets. Keywords: Computer Vision: Recognition: Detection, Categorization, Indexing, Matching, Retrieval, Semantic Interpretation Machine Learning: Transfer, Adaptation, Multi-task Learning},
  archive   = {C_IJCAI},
  author    = {Zhipeng Wang and Hao Wang and Jiexi Yan and Aming Wu and Cheng Deng},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/158},
  pages     = {1143-1149},
  title     = {Domain-smoothing network for zero-shot sketch-based image retrieval},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). HifiFace: 3D shape and semantic prior guided high fidelity
face swapping. <em>IJCAI</em>, 1136–1142. (<a
href="https://doi.org/10.24963/ijcai.2021/157">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this work, we propose a high fidelity face swapping method, called HifiFace, which can well preserve the face shape of the source face and generate photo-realistic results. Unlike other existing face swapping works that only use face recognition model to keep the identity similarity, we propose 3D shape-aware identity to control the face shape with the geometric supervision from 3DMM and 3D face reconstruction method. Meanwhile, we introduce the Semantic Facial Fusion module to optimize the combination of encoder and decoder features and make adaptive blending, which makes the results more photo-realistic. Extensive experiments on faces in the wild demonstrate that our method can preserve better identity, especially on the face shape, and can generate more photo-realistic results than previous state-of-the-art methods. Code is available at: https://johann.wang/HifiFace Keywords: Computer Vision: 2D and 3D Computer Vision Computer Vision: Biometrics, Face and Gesture Recognition},
  archive   = {C_IJCAI},
  author    = {Yuhan Wang and Xu Chen and Junwei Zhu and Wenqing Chu and Ying Tai and Chengjie Wang and Jilin Li and Yongjian Wu and Feiyue Huang and Rongrong Ji},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/157},
  pages     = {1136-1142},
  title     = {HifiFace: 3D shape and semantic prior guided high fidelity face swapping},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep unified cross-modality hashing by pairwise data
alignment. <em>IJCAI</em>, 1129–1135. (<a
href="https://doi.org/10.24963/ijcai.2021/156">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With the increasing amount of multimedia data, cross-modality hashing has made great progress as it achieves sub-linear search time and low memory space. However, due to the huge discrepancy between different modalities, most existing cross-modality hashing methods cannot learn unified hash codes and functions for modalities at the same time. The gap between separated hash codes and functions further leads to bad search performance. In this paper, to address the issues above, we propose a novel end-to-end Deep Unified Cross-Modality Hashing method named DUCMH, which is able to jointly learn unified hash codes and unified hash functions by alternate learning and data alignment. Specifically, to reduce the discrepancy between image and text modalities, DUCMH utilizes data alignment to learn an auxiliary image to text mapping under the supervision of image-text pairs. For text data, hash codes can be obtained by unified hash functions, while for image data, DUCMH first maps images to texts by the auxiliary mapping, and then uses the mapped texts to obtain hash codes. DUCMH utilizes alternate learning to update unified hash codes and functions. Extensive experiments on three representative image-text datasets demonstrate the superiority of our DUCMH over several state-of-the-art cross-modality hashing methods. Keywords: Computer Vision: Recognition: Detection, Categorization, Indexing, Matching, Retrieval, Semantic Interpretation Data Mining: Information Retrieval Machine Learning: Deep Learning},
  archive   = {C_IJCAI},
  author    = {Yimu Wang and Bo Xue and Quan Cheng and Yuhui Chen and Lijun Zhang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/156},
  pages     = {1129-1135},
  title     = {Deep unified cross-modality hashing by pairwise data alignment},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards compact single image super-resolution via
contrastive self-distillation. <em>IJCAI</em>, 1122–1128. (<a
href="https://doi.org/10.24963/ijcai.2021/155">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Convolutional neural networks (CNNs) are highly successful for super-resolution (SR) but often require sophisticated architectures with heavy memory cost and computational overhead significantly restricts their practical deployments on resource-limited devices. In this paper, we proposed a novel contrastive self-distillation (CSD) framework to simultaneously compress and accelerate various off-the-shelf SR models. In particular, a channel-splitting super-resolution network can first be constructed from a target teacher network as a compact student network. Then, we propose a novel contrastive loss to improve the quality of SR images and PSNR/SSIM via explicit knowledge transfer. Extensive experiments demonstrate that the proposed CSD scheme effectively compresses and accelerates several standard SR models such as EDSR, RCAN and CARN. Code is available at https://github.com/Booooooooooo/CSD. Keywords: Computer Vision: 2D and 3D Computer Vision},
  archive   = {C_IJCAI},
  author    = {Yanbo Wang and Shaohui Lin and Yanyun Qu and Haiyan Wu and Zhizhong Zhang and Yuan Xie and Angela Yao},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/155},
  pages     = {1122-1128},
  title     = {Towards compact single image super-resolution via contrastive self-distillation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dig into multi-modal cues for video retrieval with
hierarchical alignment. <em>IJCAI</em>, 1113–1121. (<a
href="https://doi.org/10.24963/ijcai.2021/154">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-modal cues presented in videos are usually beneficial for the challenging video-text retrieval task on internet-scale datasets. Recent video retrieval methods take advantage of multi-modal cues by aggregating them to holistic high-level semantics for matching with text representations in a global view. In contrast to this global alignment, the local alignment of detailed semantics encoded within both multi-modal cues and distinct phrases is still not well conducted. Thus, in this paper, we leverage the hierarchical video-text alignment to fully explore the detailed diverse characteristics in multi-modal cues for fine-grained alignment with local semantics from phrases, as well as to capture a high-level semantic correspondence. Specifically, multi-step attention is learned for progressively comprehensive local alignment and a holistic transformer is utilized to summarize multi-modal cues for global alignment. With hierarchical alignment, our model outperforms state-of-the-art methods on three public video retrieval datasets. Keywords: Computer Vision: Language and Vision Machine Learning: Deep Learning},
  archive   = {C_IJCAI},
  author    = {Wenzhe Wang and Mengdan Zhang and Runnan Chen and Guanyu Cai and Penghao Zhou and Pai Peng and Xiaowei Guo and Jian Wu and Xing Sun},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/154},
  pages     = {1113-1121},
  title     = {Dig into multi-modal cues for video retrieval with hierarchical alignment},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Norm-guided adaptive visual embedding for zero-shot
sketch-based image retrieval. <em>IJCAI</em>, 1106–1112. (<a
href="https://doi.org/10.24963/ijcai.2021/153">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Zero-shot sketch-based image retrieval (ZS-SBIR), which aims to retrieve photos with sketches under the zero-shot scenario, has shown extraordinary talents in real-world applications. Most existing methods leverage language models to generate class-prototypes and use them to arrange the locations of all categories in the common space for photos and sketches. Although great progress has been made, few of them consider whether such pre-defined prototypes are necessary for ZS-SBIR, where locations of unseen class samples in the embedding space are actually determined by visual appearance and a visual embedding actually performs better. To this end, we propose a novel Norm-guided Adaptive Visual Embedding (NAVE) model, for adaptively building the common space based on visual similarity instead of language-based pre-defined prototypes. To further enhance the representation quality of unseen classes for both photo and sketch modality, modality norm discrepancy and noisy label regularizer are jointly employed to measure and repair the modality bias of the learned common embedding. Experiments on two challenging datasets demonstrate the superiority of our NAVE over state-of-the-art competitors. Keywords: Computer Vision: Recognition: Detection, Categorization, Indexing, Matching, Retrieval, Semantic Interpretation Machine Learning: Deep Learning Machine Learning: Multi-instance; Multi-label; Multi-view learning},
  archive   = {C_IJCAI},
  author    = {Wenjie Wang and Yufeng Shi and Shiming Chen and Qinmu Peng and Feng Zheng and Xinge You},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/153},
  pages     = {1106-1112},
  title     = {Norm-guided adaptive visual embedding for zero-shot sketch-based image retrieval},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Audio2Head: Audio-driven one-shot talking-head generation
with natural head motion. <em>IJCAI</em>, 1098–1105. (<a
href="https://doi.org/10.24963/ijcai.2021/152">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose an audio-driven talking-head method to generate photo-realistic talking-head videos from a single reference image. In this work, we tackle two key challenges: (i) producing natural head motions that match speech prosody, and (ii) maintaining the appearance of a speaker in a large head motion while stabilizing the non-face regions. We first design a head pose predictor by modeling rigid 6D head movements with a motion-aware recurrent neural network (RNN). In this way, the predicted head poses act as the low-frequency holistic movements of a talking head, thus allowing our latter network to focus on detailed facial movement generation. To depict the entire image motions arising from audio, we exploit a keypoint based dense motion field representation. Then, we develop a motion field generator to produce the dense motion fields from input audio, head poses, and a reference image. As this keypoint based representation models the motions of facial regions, head, and backgrounds integrally, our method can better constrain the spatial and temporal consistency of the generated videos. Finally, an image generation network is employed to render photo-realistic talking-head videos from the estimated keypoint based motion fields and the input reference image. Extensive experiments demonstrate that our method produces videos with plausible head motions, synchronized facial expressions, and stable backgrounds and outperforms the state-of-the-art. Keywords: Computer Vision: Language and Vision Computer Vision: Motion and Tracking Computer Vision: Structural and Model-Based Approaches, Knowledge Representation and Reasoning},
  archive   = {C_IJCAI},
  author    = {Suzhen Wang and Lincheng Li and Yu Ding and Changjie Fan and Xin Yu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/152},
  pages     = {1098-1105},
  title     = {Audio2Head: Audio-driven one-shot talking-head generation with natural head motion},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Spline positional encoding for learning 3D implicit signed
distance fields. <em>IJCAI</em>, 1091–1097. (<a
href="https://doi.org/10.24963/ijcai.2021/151">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multilayer perceptrons (MLPs) have been successfully used to represent 3D shapes implicitly and compactly, by mapping 3D coordinates to the corresponding signed distance values or occupancy values. In this paper, we propose a novel positional encoding scheme, called Spline Positional Encoding, to map the input coordinates to a high dimensional space before passing them to MLPs, which help recover 3D signed distance fields with fine-scale geometric details from unorganized 3D point clouds. We verified the superiority of our approach over other positional encoding schemes on tasks of 3D shape reconstruction and 3D shape space learning from input point clouds. The efficacy of our approach extended to image reconstruction is also demonstrated and evaluated. Keywords: Computer Vision: 2D and 3D Computer Vision},
  archive   = {C_IJCAI},
  author    = {Peng-Shuai Wang and Yang Liu and Yu-Qi Yang and Xin Tong},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/151},
  pages     = {1091-1097},
  title     = {Spline positional encoding for learning 3D implicit signed distance fields},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Tag, copy or predict: A unified weakly-supervised learning
framework for visual information extraction using sequences.
<em>IJCAI</em>, 1082–1090. (<a
href="https://doi.org/10.24963/ijcai.2021/150">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Visual information extraction (VIE) has attracted increasing attention in recent years. The existing methods usually first organized optical character recognition (OCR) results in plain texts and then utilized token-level category annotations as supervision to train a sequence tagging model. However, it expends great annotation costs and may be exposed to label confusion, the OCR errors will also significantly affect the final performance. In this paper, we propose a unified weakly-supervised learning framework called TCPNet (Tag, Copy or Predict Network), which introduces 1) an efficient encoder to simultaneously model the semantic and layout information in 2D OCR results, 2) a weakly-supervised training method that utilizes only sequence-level supervision; and 3) a flexible and switchable decoder which contains two inference modes: one (Copy or Predict Mode) is to output key information sequences of different categories by copying a token from the input or predicting one in each time step, and the other (Tag Mode) is to directly tag the input sequence in a single forward pass. Our method shows new state-of-the-art performance on several public benchmarks, which fully proves its effectiveness. Keywords: Computer Vision: Language and Vision Computer Vision: Recognition: Detection, Categorization, Indexing, Matching, Retrieval, Semantic Interpretation Natural Language Processing: Information Extraction},
  archive   = {C_IJCAI},
  author    = {Jiapeng Wang and Tianwei Wang and Guozhi Tang and Lianwen Jin and Weihong Ma and Kai Ding and Yichao Huang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/150},
  pages     = {1082-1090},
  title     = {Tag, copy or predict: A unified weakly-supervised learning framework for visual information extraction using sequences},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cross-domain few-shot classification via adversarial task
augmentation. <em>IJCAI</em>, 1075–1081. (<a
href="https://doi.org/10.24963/ijcai.2021/149">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Few-shot classification aims to recognize unseen classes with few labeled samples from each class. Many meta-learning models for few-shot classification elaborately design various task-shared inductive bias (meta-knowledge) to solve such tasks, and achieve impressive performance. However, when there exists the domain shift between the training tasks and the test tasks, the obtained inductive bias fails to generalize across domains, which degrades the performance of the meta-learning models. In this work, we aim to improve the robustness of the inductive bias through task augmentation. Concretely, we consider the worst-case problem around the source task distribution, and propose the adversarial task augmentation method which can generate the inductive bias-adaptive &#39;challenging&#39; tasks. Our method can be used as a simple plug-and-play module for various meta-learning models, and improve their cross-domain generalization capability. We conduct extensive experiments under the cross-domain setting, using nine few-shot classification datasets: mini-ImageNet, CUB, Cars, Places, Plantae, CropDiseases, EuroSAT, ISIC and ChestX. Experimental results show that our method can effectively improve the few-shot classification performance of the meta-learning models under domain shift, and outperforms the existing works. Our code is available at https://github.com/Haoqing-Wang/CDFSL-ATA. Keywords: Computer Vision: Recognition: Detection, Categorization, Indexing, Matching, Retrieval, Semantic Interpretation Machine Learning: Adversarial Machine Learning Machine Learning: Deep Learning},
  archive   = {C_IJCAI},
  author    = {Haoqing Wang and Zhi-Hong Deng},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/149},
  pages     = {1075-1081},
  title     = {Cross-domain few-shot classification via adversarial task augmentation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Text-based person search via multi-granularity embedding
learning. <em>IJCAI</em>, 1068–1074. (<a
href="https://doi.org/10.24963/ijcai.2021/148">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Most existing text-based person search methods highly depend on exploring the corresponding relations between the regions of the image and the words in the sentence. However, these methods correlated image regions and words in the same semantic granularity. It 1) results in irrelevant corresponding relations between image and text, 2) causes an ambiguity embedding problem. In this study, we propose a novel multi-granularity embedding learning model for text-based person search. It generates multi-granularity embeddings of partial person bodies in a coarse-to-fine manner by revisiting the person image at different spatial scales. Specifically, we distill the partial knowledge from image scrips to guide the model to select the semantically relevant words from the text description. It can learn discriminative and modality-invariant visual-textual embeddings. In addition, we integrate the partial embeddings at each granularity and perform multi-granularity image-text matching. Extensive experiments validate the effectiveness of our method, which can achieve new state-of-the-art performance by the learned discriminative partial embeddings. Keywords: Computer Vision: Language and Vision Computer Vision: Recognition: Detection, Categorization, Indexing, Matching, Retrieval, Semantic Interpretation},
  archive   = {C_IJCAI},
  author    = {Chengji Wang and Zhiming Luo and Yaojin Lin and Shaozi Li},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/148},
  pages     = {1068-1074},
  title     = {Text-based person search via multi-granularity embedding learning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning interpretable concept groups in CNNs.
<em>IJCAI</em>, 1061–1067. (<a
href="https://doi.org/10.24963/ijcai.2021/147">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose a novel training methodology---Concept Group Learning (CGL)---that encourages training of interpretable CNN filters by partitioning filters in each layer into \emph{concept groups}, each of which is trained to learn a single visual concept. We achieve this through a novel regularization strategy that forces filters in the same group to be active in similar image regions for a given layer. We additionally use a regularizer to encourage a sparse weighting of the concept groups in each layer so that a few concept groups can have greater importance than others. We quantitatively evaluate CGL&#39;s model interpretability using standard interpretability evaluation techniques and find that our method increases interpretability scores in most cases. Qualitatively we compare the image regions which are most active under filters learned using CGL versus filters learned without CGL and find that CGL activation regions more strongly concentrate around semantically relevant features. Keywords: Computer Vision: 2D and 3D Computer Vision Machine Learning: Deep Learning Machine Learning: Explainable/Interpretable Machine Learning},
  archive   = {C_IJCAI},
  author    = {Saurabh Varshneya and Antoine Ledent and Robert A. Vandermeulen and Yunwen Lei and Matthias Enders and Damian Borth and Marius Kloft},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/147},
  pages     = {1061-1067},
  title     = {Learning interpretable concept groups in CNNs},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards cross-view consistency in semantic segmentation
while varying view direction. <em>IJCAI</em>, 1054–1060. (<a
href="https://doi.org/10.24963/ijcai.2021/146">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Several images are taken for the same scene with many view directions. Given a pixel in any one image of them, its correspondences may appear in the other images. However, by using existing semantic segmentation methods, we find that the pixel and its correspondences do not always have the same inferred label as expected. Fortunately, from the knowledge of multiple view geometry, if we keep the position of a camera unchanged, and only vary its orientation, there is a homography transformation to describe the relationship of corresponding pixels in such images. Based on this fact, we propose to generate images which are the same as real images of the scene taken in certain novel view directions for training and evaluation. We also introduce gradient guided deformable convolution to alleviate the inconsistency, by learning dynamic proper receptive field from feature gradients. Furthermore, a novel consistency loss is presented to enforce feature consistency. Compared with previous approaches, the proposed method gets significant improvement in both cross-view consistency and semantic segmentation performance on images with abundant view directions, while keeping comparable or better performance on the existing datasets. Keywords: Computer Vision: Recognition: Detection, Categorization, Indexing, Matching, Retrieval, Semantic Interpretation Robotics: Robotics and Vision},
  archive   = {C_IJCAI},
  author    = {Xin Tong and Xianghua Ying and Yongjie Shi and He Zhao and Ruibin Wang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/146},
  pages     = {1054-1060},
  title     = {Towards cross-view consistency in semantic segmentation while varying view direction},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). AVA: Adversarial vignetting attack against visual
recognition. <em>IJCAI</em>, 1046–1053. (<a
href="https://doi.org/10.24963/ijcai.2021/145">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Vignetting is an inherent imaging phenomenon within almost all optical systems, showing as a radial intensity darkening toward the corners of an image. Since it is a common effect for photography and usually appears as a slight intensity variation, people usually regard it as a part of a photo and would not even want to post-process it. Due to this natural advantage, in this work, we study the vignetting from a new viewpoint, i.e., adversarial vignetting attack (AVA), which aims to embed intentionally misleading information into the vignetting and produce a natural adversarial example without noise patterns. This example can fool the state-of-the-art deep convolutional neural networks (CNNs) but is imperceptible to human. To this end, we first propose the radial-isotropic adversarial vignetting attack (RI-AVA) based on the physical model of vignetting, where the physical parameters (e.g., illumination factor and focal length) are tuned through the guidance of target CNN models. To achieve higher transferability across different CNNs, we further propose radial-anisotropic adversarial vignetting attack (RA-AVA) by allowing the effective regions of vignetting to be radial-anisotropic and shape-free. Moreover, we propose the geometry-aware level-set optimization method to solve the adversarial vignetting regions and physical parameters jointly. We validate the proposed methods on three popular datasets, i.e., DEV, CIFAR10, and Tiny ImageNet, by attacking four CNNs, e.g., ResNet50, EfficientNet-B0, DenseNet121, and MobileNet-V2, demonstrating the advantages of our methods over baseline methods on both transferability and image quality. Keywords: Computer Vision: Recognition: Detection, Categorization, Indexing, Matching, Retrieval, Semantic Interpretation Machine Learning: Adversarial Machine Learning Machine Learning: Classification},
  archive   = {C_IJCAI},
  author    = {Binyu Tian and Felix Juefei-Xu and Qing Guo and Xiaofei Xie and Xiaohong Li and Yang Liu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/145},
  pages     = {1046-1053},
  title     = {AVA: Adversarial vignetting attack against visual recognition},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MatchVIE: Exploiting match relevancy between entities for
visual information extraction. <em>IJCAI</em>, 1039–1045. (<a
href="https://doi.org/10.24963/ijcai.2021/144">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Visual Information Extraction (VIE) task aims to extract key information from multifarious document images (e.g., invoices and purchase receipts). Most previous methods treat the VIE task simply as a sequence labeling problem or classification problem, which requires models to carefully identify each kind of semantics by introducing multimodal features, such as font, color, layout. But simply introducing multimodal features can&#39;t work well when faced with numeric semantic categories or some ambiguous texts. To address this issue, in this paper we propose a novel key-value matching model based on a graph neural network for VIE (MatchVIE). Through key-value matching based on relevancy evaluation, the proposed MatchVIE can bypass the recognitions to various semantics, and simply focuses on the strong relevancy between entities. Besides, we introduce a simple but effective operation, Num2Vec, to tackle the instability of encoded values, which helps model converge more smoothly. Comprehensive experiments demonstrate that the proposed MatchVIE can significantly outperform previous methods. Notably, to the best of our knowledge, MatchVIE may be the first attempt to tackle the VIE task by modeling the relevancy between keys and values and it is a good complement to the existing methods. Keywords: Computer Vision: Language and Vision Computer Vision: Structural and Model-Based Approaches, Knowledge Representation and Reasoning Natural Language Processing: Information Extraction},
  archive   = {C_IJCAI},
  author    = {Guozhi Tang and Lele Xie and Lianwen Jin and Jiapeng Wang and Jingdong Chen and Zhen Xu and Qianying Wang and Yaqiang Wu and Hui Li},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/144},
  pages     = {1039-1045},
  title     = {MatchVIE: Exploiting match relevancy between entities for visual information extraction},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Proposal-free one-stage referring expression via grid-word
cross-attention. <em>IJCAI</em>, 1032–1038. (<a
href="https://doi.org/10.24963/ijcai.2021/143">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Referring Expression Comprehension (REC) has become one of the most important tasks in visual reasoning, since it is an essential step for many vision-and-language tasks such as visual question answering. However, it has not been widely used in many downstream tasks because it suffers 1) two-stage methods exist heavy computation cost and inevitable error accumulation, and 2) one-stage methods have to depend on lots of hyper-parameters (such as anchors) to generate bounding box. In this paper, we present a proposal-free one-stage (PFOS) model that is able to regress the region-of-interest from the image, based on a textual query, in an end-to-end manner. Instead of using the dominant anchor proposal fashion, we directly take the dense-grid of image as input for a cross-attention transformer that learns grid-word correspondences. The final bounding box is predicted directly from the image without the time-consuming anchor selection process that previous methods suffer. Our model achieves the state-of-the-art performance on four referring expression datasets with higher efficiency, comparing to previous best one-stage and two-stage methods. Keywords: Computer Vision: Language and Vision Computer Vision: Structural and Model-Based Approaches, Knowledge Representation and Reasoning},
  archive   = {C_IJCAI},
  author    = {Wei Suo and MengYang Sun and Peng Wang and Qi Wu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/143},
  pages     = {1032-1038},
  title     = {Proposal-free one-stage referring expression via grid-word cross-attention},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Context-aware cross-level fusion network for camouflaged
object detection. <em>IJCAI</em>, 1025–1031. (<a
href="https://doi.org/10.24963/ijcai.2021/142">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Camouflaged object detection (COD) is a challenging task due to the low boundary contrast between the object and its surroundings. In addition, the appearance of camouflaged objects varies significantly, e.g., object size and shape, aggravating the difficulties of accurate COD. In this paper, we propose a novel Context-aware Crosslevel Fusion Network (C2F-Net) to address the challenging COD task. Specifically, we propose an Attention-induced Cross-level Fusion Module (ACFM) to integrate the multi-level features with informative attention coefficients. The fused features are then fed to the proposed Dual-branch Global Context Module (DGCM), which yields multi-scale feature representations for exploiting rich global context information. In C2F-Net, the two modules are conducted on high-level features using a cascaded manner. Extensive experiments on three widely used benchmark datasets demonstrate that our C2F-Net is an effective COD model and outperforms state-of-the-art models remarkably. Our code is publicly available at: https://github.com/thograce/C2FNet. Keywords: Computer Vision: 2D and 3D Computer Vision},
  archive   = {C_IJCAI},
  author    = {Yujia Sun and Geng Chen and Tao Zhou and Yi Zhang and Nian Liu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/142},
  pages     = {1025-1031},
  title     = {Context-aware cross-level fusion network for camouflaged object detection},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Speech2Talking-face: Inferring and driving a face with
synchronized audio-visual representation. <em>IJCAI</em>, 1018–1024. (<a
href="https://doi.org/10.24963/ijcai.2021/141">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {What can we picture solely from a clip of speech? Previous research has shown the possibility of directly inferring the appearance of a person&#39;s face by listening to a voice. However, within human speech lies not only the biometric identity signal but also the identity-irrelevant information such as the talking content. Our goal is to extract as much information from a clip of speech as possible. In particular, we aim at not only inferring the face of a person but also animating it. Our key insight is to synchronize audio and visual representations from two perspectives in a style-based generative framework. Specifically, contrastive learning is leveraged to map both the identity and speech content information within the speech to visual representation spaces. Furthermore, the identity space is strengthened with class centroids. Through curriculum learning, the style-based generator is capable of automatically balancing the information from the two latent spaces. Extensive experiments show that our approach encourages better speech-identity correlation learning while generating vivid faces whose identities are consistent with given speech samples. Moreover, by leveraging the same model, these inferred faces can be driven to talk by the audio. Keywords: Computer Vision: 2D and 3D Computer Vision Natural Language Processing: Speech},
  archive   = {C_IJCAI},
  author    = {Yasheng Sun and Hang Zhou and Ziwei Liu and Hideki Koike},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/141},
  pages     = {1018-1024},
  title     = {Speech2Talking-face: Inferring and driving a face with synchronized audio-visual representation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Enhance image as you like with unpaired learning.
<em>IJCAI</em>, 1011–1017. (<a
href="https://doi.org/10.24963/ijcai.2021/140">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Low-light image enhancement exhibits an ill-posed nature, as a given image may have many enhanced versions, yet recent studies focus on building a deterministic mapping from input to an enhanced version. In contrast, we propose a lightweight one-path conditional generative adversarial network (cGAN) to learn a one-to-many relation from low-light to normal-light image space, given only sets of low- and normal-light training images without any correspondence. By formulating this ill-posed problem as a modulation code learning task, our network learns to generate a collection of enhanced images from a given input conditioned on various reference images. Therefore our inference model easily adapts to various user preferences, provided with a few favorable photos from each user. Our model achieves competitive visual and quantitative results on par with fully supervised methods on both noisy and clean datasets, while being 6 to 10 times lighter than state-of-the-art generative adversarial networks (GANs) approaches. Keywords: Computer Vision: 2D and 3D Computer Vision Machine Learning Applications: Applications of Unsupervised Learning},
  archive   = {C_IJCAI},
  author    = {Xiaopeng Sun and Muxingzi Li and Tianyu He and Lubin Fan},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/140},
  pages     = {1011-1017},
  title     = {Enhance image as you like with unpaired learning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards unsupervised deformable-instances image-to-image
translation. <em>IJCAI</em>, 1004–1010. (<a
href="https://doi.org/10.24963/ijcai.2021/139">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Replacing objects in images is a practical functionality of Photoshop, e.g., clothes changing. This task is defined as Unsupervised Deformable-Instances Image-to-Image Translation (UDIT), which maps multiple foreground instances of a source domain to a target domain, involving significant changes in shape. In this paper, we propose an effective pipeline named Mask-Guided Deformable-instances GAN (MGD-GAN) which first generates target masks in batch and then utilizes them to synthesize corresponding instances on the background image, with all instances efficiently translated and background well preserved. To promote the quality of synthesized images and stabilize the training, we design an elegant training procedure which transforms the unsupervised mask-to-instance process into a supervised way by creating paired examples. To objectively evaluate the performance of UDIT task, we design new evaluation metrics which are based on the object detection. Extensive experiments on four datasets demonstrate the significant advantages of our MGD-GAN over existing methods both quantitatively and qualitatively. Furthermore, our training time consumption is hugely reduced compared to the state-of-the-art. The code could be available at https://github.com/sitongsu/MGD_GAN. Keywords: Computer Vision: 2D and 3D Computer Vision Computer Vision: Computational Photography, Photometry, Shape from X},
  archive   = {C_IJCAI},
  author    = {Sitong Su and Jingkuan Song and Lianli Gao and Junchen Zhu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/139},
  pages     = {1004-1010},
  title     = {Towards unsupervised deformable-instances image-to-image translation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Structure guided lane detection. <em>IJCAI</em>, 997–1003.
(<a href="https://doi.org/10.24963/ijcai.2021/138">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, lane detection has made great progress with the rapid development of deep neural networks and autonomous driving. However, there exist three mainly problems including characterizing lanes, modeling the structural relationship between scenes and lanes, and supporting more attributes (e.g., instance and type) of lanes. In this paper, we propose a novel structure guided framework to solve these problems simultaneously. In the framework, we first introduce a new lane representation to characterize each instance. Then a top-down vanishing point guided anchoring mechanism is proposed to produce intensive anchors, which efficiently capture various lanes. Next, multi-level structural constraints are used to improve the perception of lanes. In the process, pixel-level perception with binary segmentation is introduced to promote features around anchors and restore lane details from bottom up, a lane-level relation is put forward to model structures (i.e., parallel) around lanes, and an image-level attention is used to adaptively attend different regions of the image from the perspective of scenes. With the help of structural guidance, anchors are effectively classified and regressed to obtain precise locations and shapes. Extensive experiments on public benchmark datasets show that the proposed approach outperforms state-of-the-art methods with 117 FPS on a single GPU. Keywords: Computer Vision: Perception Computer Vision: Structural and Model-Based Approaches, Knowledge Representation and Reasoning},
  archive   = {C_IJCAI},
  author    = {Jinming Su and Chao Chen and Ke Zhang and Junfeng Luo and Xiaoming Wei and Xiaolin Wei},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/138},
  pages     = {997-1003},
  title     = {Structure guided lane detection},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning with selective forgetting. <em>IJCAI</em>, 989–996.
(<a href="https://doi.org/10.24963/ijcai.2021/137">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Lifelong learning aims to train a highly expressive model for a new task while retaining all knowledge for previous tasks. However, many practical scenarios do not always require the system to remember all of the past knowledge. Instead, ethical considerations call for selective and proactive forgetting of undesirable knowledge in order to prevent privacy issues and data leakage. In this paper, we propose a new framework for lifelong learning, called Learning with Selective Forgetting, which is to update a model for the new task with forgetting only the selected classes of the previous tasks while maintaining the rest. The key is to introduce a class-specific synthetic signal called mnemonic code. The codes are &quot;watermarked&quot; on all the training samples of the corresponding classes when the model is updated for a new task. This enables us to forget arbitrary classes later by only using the mnemonic codes without using the original data. Experiments on common benchmark datasets demonstrate the remarkable superiority of the proposed method over several existing methods. Keywords: Computer Vision: Recognition: Detection, Categorization, Indexing, Matching, Retrieval, Semantic Interpretation Machine Learning: Incremental Learning},
  archive   = {C_IJCAI},
  author    = {Takashi Shibata and Go Irie and Daiki Ikami and Yu Mitsuzumi},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/137},
  pages     = {989-996},
  title     = {Learning with selective forgetting},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning visual words for weakly-supervised semantic
segmentation. <em>IJCAI</em>, 982–988. (<a
href="https://doi.org/10.24963/ijcai.2021/136">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Current weakly-supervised semantic segmentation (WSSS) methods with image-level labels mainly adopt class activation maps (CAM) to generate the initial pseudo labels. However, CAM usually only identifies the most discriminative object extents, which is attributed to the fact that the network doesn&#39;t need to discover the integral object to recognize image-level labels. In this work, to tackle this problem, we proposed to simultaneously learn the image-level labels and local visual word labels. Specifically, in each forward propagation, the feature maps of the input image will be encoded to visual words with a learnable codebook. By enforcing the network to classify the encoded fine-grained visual words, the generated CAM could cover more semantic regions. Besides, we also proposed a hybrid spatial pyramid pooling module that could preserve local maximum and global average values of feature maps, so that more object details and less background were considered. Based on the proposed methods, we conducted experiments on the PASCAL VOC 2012 dataset. Our proposed method achieved 67.2\% mIoU on the val set and 67.3\% mIoU on the test set, which outperformed recent state-of-the-art methods. Keywords: Computer Vision: Recognition: Detection, Categorization, Indexing, Matching, Retrieval, Semantic Interpretation Machine Learning: Deep Learning},
  archive   = {C_IJCAI},
  author    = {Lixiang Ru and Bo Du and Chen Wu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/136},
  pages     = {982-988},
  title     = {Learning visual words for weakly-supervised semantic segmentation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-level graph encoding with structural-collaborative
relation learning for skeleton-based person re-identification.
<em>IJCAI</em>, 973–980. (<a
href="https://doi.org/10.24963/ijcai.2021/135">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Skeleton-based person re-identification (Re-ID) is an emerging open topic providing great value for safety-critical applications. Existing methods typically extract hand-crafted features or model skeleton dynamics from the trajectory of body joints, while they rarely explore valuable relation information contained in body structure or motion. To fully explore body relations, we construct graphs to model human skeletons from different levels, and for the first time propose a Multi-level Graph encoding approach with Structural-Collaborative Relation learning (MG-SCR) to encode discriminative graph features for person Re-ID. Specifically, considering that structurally-connected body components are highly correlated in a skeleton, we first propose a multi-head structural relation layer to learn different relations of neighbor body-component nodes in graphs, which helps aggregate key correlative features for effective node representations. Second, inspired by the fact that body-component collaboration in walking usually carries recognizable patterns, we propose a cross-level collaborative relation layer to infer collaboration between different level components, so as to capture more discriminative skeleton graph features. Finally, to enhance graph dynamics encoding, we propose a novel self-supervised sparse sequential prediction task for model pre-training, which facilitates encoding high-level graph semantics for person Re-ID. MG-SCR outperforms state-of-the-art skeleton-based methods, and it achieves superior performance to many multi-modal methods that utilize extra RGB or depth features. Our codes are available at https://github.com/Kali-Hac/MG-SCR. Keywords: Computer Vision: Recognition: Detection, Categorization, Indexing, Matching, Retrieval, Semantic Interpretation Machine Learning: Deep Learning},
  archive   = {C_IJCAI},
  author    = {Haocong Rao and Shihao Xu and Xiping Hu and Jun Cheng and Bin Hu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/135},
  pages     = {973-980},
  title     = {Multi-level graph encoding with structural-collaborative relation learning for skeleton-based person re-identification},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive edge attention for graph matching with outliers.
<em>IJCAI</em>, 966–972. (<a
href="https://doi.org/10.24963/ijcai.2021/134">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph matching aims at establishing correspondence between node sets of given graphs while keeping the consistency between their edge sets. However, outliers in practical scenarios and equivalent learning of edge representations in deep learning methods are still challenging. To address these issues, we present an Edge Attention-adaptive Graph Matching (EAGM) network and a novel description of edge features. EAGM transforms the matching relation between two graphs into a node and edge classification problem over their assignment graph. To explore the potential of edges, EAGM learns edge attention on the assignment graph to 1) reveal the impact of each edge on graph matching, as well as 2) adjust the learning of edge representations adaptively. To alleviate issues caused by the outliers, we describe an edge by aggregating the semantic information over the space spanned by the edge. Such rich information provides clear distinctions between different edges (e.g., inlier-inlier edges vs. inlier-outlier edges), which further distinguishes outliers in the view of their associated edges. Extensive experiments demonstrate that EAGM achieves promising matching quality compared with state-of-the-arts, on cases both with and without outliers. Our source code along with the experiments is available at https://github.com/bestwei/EAGM. Keywords: Computer Vision: Recognition: Detection, Categorization, Indexing, Matching, Retrieval, Semantic Interpretation Machine Learning: Deep Learning},
  archive   = {C_IJCAI},
  author    = {Jingwei Qu and Haibin Ling and Chenrui Zhang and Xiaoqing Lyu and Zhi Tang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/134},
  pages     = {966-972},
  title     = {Adaptive edge attention for graph matching with outliers},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Unsupervised hashing with contrastive information
bottleneck. <em>IJCAI</em>, 959–965. (<a
href="https://doi.org/10.24963/ijcai.2021/133">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Many unsupervised hashing methods are implicitly established on the idea of reconstructing the input data, which basically encourages the hashing codes to retain as much information of original data as possible. However, this requirement may force the models spending lots of their effort on reconstructing the unuseful background information, while ignoring to preserve the discriminative semantic information that is more important for the hashing task. To tackle this problem, inspired by the recent success of contrastive learning in learning continuous representations, we propose to adapt this framework to learn binary hashing codes. Specifically, we first propose to modify the objective function to meet the specific requirement of hashing and then introduce a probabilistic binary representation layer into the model to facilitate end-to-end training of the entire model. We further prove the strong connection between the proposed contrastive-learning-based hashing method and the mutual information, and show that the proposed model can be considered under the broader framework of the information bottleneck (IB). Under this perspective, a more general hashing model is naturally obtained. Extensive experimental results on three benchmark image datasets demonstrate that the proposed hashing method significantly outperforms existing baselines. Keywords: Computer Vision: Recognition: Detection, Categorization, Indexing, Matching, Retrieval, Semantic Interpretation Computer Vision: Statistical Methods and Machine Learning},
  archive   = {C_IJCAI},
  author    = {Zexuan Qiu and Qinliang Su and Zijing Ou and Jianxing Yu and Changyou Chen},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/133},
  pages     = {959-965},
  title     = {Unsupervised hashing with contrastive information bottleneck},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SiamRCR: Reciprocal classification and regression for visual
object tracking. <em>IJCAI</em>, 952–958. (<a
href="https://doi.org/10.24963/ijcai.2021/132">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, most siamese network based trackers locate targets via object classification and bounding-box regression. Generally, they select the bounding-box with maximum classification confidence as the final prediction. This strategy may miss the right result due to the accuracy misalignment between classification and regression. In this paper, we propose a novel siamese tracking algorithm called SiamRCR, addressing this problem with a simple, light and effective solution. It builds reciprocal links between classification and regression branches, which can dynamically re-weight their losses for each positive sample. In addition, we add a localization branch to predict the localization accuracy, so that it can work as the replacement of the regression assistance link during inference. This branch makes the training and inference more consistent. Extensive experimental results demonstrate the effectiveness of SiamRCR and its superiority over the state-of-the-art competitors on GOT-10k, LaSOT, TrackingNet, OTB-2015, VOT-2018 and VOT-2019. Moreover, our SiamRCR runs at 65 FPS, far above the real-time requirement. Keywords: Computer Vision: Motion and Tracking Computer Vision: Video: Events, Activities and Surveillance},
  archive   = {C_IJCAI},
  author    = {Jinlong Peng and Zhengkai Jiang and Yueyang Gu and Yang Wu and Yabiao Wang and Ying Tai and Chengjie Wang and Weiyao Lin},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/132},
  pages     = {952-958},
  title     = {SiamRCR: Reciprocal classification and regression for visual object tracking},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Self-boosting for feature distillation. <em>IJCAI</em>,
945–951. (<a href="https://doi.org/10.24963/ijcai.2021/131">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Knowledge distillation is a simple but effective method for model compression, which obtains a better-performing small network (Student) by learning from a well-trained large network (Teacher). However, when the difference in the model sizes of Student and Teacher is large, the gap in capacity leads to poor performance of Student. Existing methods focus on seeking simplified or more effective knowledge from Teacher to narrow the Teacher-Student gap, while we address this problem by Student&#39;s self-boosting. Specifically, we propose a novel distillation method named Self-boosting Feature Distillation (SFD), which eases the Teacher-Student gap by feature integration and self-distillation of Student. Three different modules are designed for feature integration to enhance the discriminability of Student&#39;s feature, which leads to improving the order of convergence in theory. Moreover, an easy-to-operate self-distillation strategy is put forward to stabilize the training process and promote the performance of Student, without additional forward propagation or memory consumption. Extensive experiments on multiple benchmarks and networks show that our method is significantly superior to existing methods. Keywords: Computer Vision: 2D and 3D Computer Vision Computer Vision: Recognition: Detection, Categorization, Indexing, Matching, Retrieval, Semantic Interpretation},
  archive   = {C_IJCAI},
  author    = {Yulong Pei and Yanyun Qu and Junping Zhang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/131},
  pages     = {945-951},
  title     = {Self-boosting for feature distillation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Few-shot neural human performance rendering from sparse RGBD
videos. <em>IJCAI</em>, 938–944. (<a
href="https://doi.org/10.24963/ijcai.2021/130">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent neural rendering approaches for human activities achieve remarkable view synthesis results, but still rely on dense input views or dense training with all the capture frames, leading to deployment difficulty and inefficient training overload. However, existing advances will be ill-posed if the input is both spatially and temporally sparse. To fill this gap, in this paper we propose a few-shot neural human rendering approach (FNHR) from only sparse RGBD inputs, which exploits the temporal and spatial redundancy to generate photo-realistic free-view output of human activities. Our FNHR is trained only on the key-frames which expand the motion manifold in the input sequences. We introduce a two-branch neural blending to combine the neural point render and classical graphics texturing pipeline, which integrates reliable observations over sparse key-frames. Furthermore, we adopt a patch-based adversarial training process to make use of the local redundancy and avoids over-fitting to the key-frames, which generates fine-detailed rendering results. Extensive experiments demonstrate the effectiveness of our approach to generate high-quality free view-point results for challenging human performances under the sparse setting. Keywords: Computer Vision: 2D and 3D Computer Vision Computer Vision: Biometrics, Face and Gesture Recognition Computer Vision: Motion and Tracking},
  archive   = {C_IJCAI},
  author    = {Anqi Pang and Xin Chen and Haimin Luo and Minye Wu and Jingyi Yu and Lan Xu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/130},
  pages     = {938-944},
  title     = {Few-shot neural human performance rendering from sparse RGBD videos},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Attention-based pyramid dilated lattice network for blind
image denoising. <em>IJCAI</em>, 931–937. (<a
href="https://doi.org/10.24963/ijcai.2021/129">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Though convolutional neural networks (CNNs) with residual and dense aggregations have obtained much attention in image denoising, they are incapable of exploiting different levels of contextual information at every convolutional unit in order to infer different levels of noise components with a single model. In this paper, to overcome this shortcoming we present a novel attention-based pyramid dilated lattice (APDL) architecture and investigate its capability for blind image denoising. The proposed framework can effectively harness the advantages of residual and dense aggregations to achieve a great trade-off between performance, parameter efficiency, and test time. It also employs a novel pyramid dilated convolution strategy to effectively capture contextual information corresponding to different noise levels through the training of a single model. Our extensive experimental investigation verifies the effectiveness and efficiency of the APDL architecture for image denoising as well as JPEG artifacts suppression tasks. Keywords: Computer Vision: 2D and 3D Computer Vision Machine Learning: Deep Learning},
  archive   = {C_IJCAI},
  author    = {Mohammad Nikzad and Yongsheng Gao and Jun Zhou},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/129},
  pages     = {931-937},
  title     = {Attention-based pyramid dilated lattice network for blind image denoising},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Look wide and interpret twice: Improving performance on
interactive instruction-following tasks. <em>IJCAI</em>, 923–930. (<a
href="https://doi.org/10.24963/ijcai.2021/128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {There is a growing interest in the community in making an embodied AI agent perform a complicated task while interacting with an environment following natural language directives. Recent studies have tackled the problem using ALFRED, a well-designed dataset for the task, but achieved only very low accuracy. This paper proposes a new method, which outperforms the previous methods by a large margin. It is based on a combination of several new ideas. One is a two-stage interpretation of the provided instructions. The method first selects and interprets an instruction without using visual information, yielding a tentative action sequence prediction. It then integrates the prediction with the visual information etc., yielding the final prediction of an action and an object. As the object&#39;s class to interact is identified in the first stage, it can accurately select the correct object from the input image. Moreover, our method considers multiple egocentric views of the environment and extracts essential information by applying hierarchical attention conditioned on the current instruction. This contributes to the accurate prediction of actions for navigation. A preliminary version of the method won the ALFRED Challenge 2020. The current version achieves the unseen environment&#39;s success rate of 4.45\% with a single view, which is further improved to 8.37\% with multiple views. Keywords: Computer Vision: Language and Vision},
  archive   = {C_IJCAI},
  author    = {Van-Quang Nguyen and Masanori Suganuma and Takayuki Okatani},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/128},
  pages     = {923-930},
  title     = {Look wide and interpret twice: Improving performance on interactive instruction-following tasks},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modality-aware style adaptation for RGB-infrared person
re-identification. <em>IJCAI</em>, 916–922. (<a
href="https://doi.org/10.24963/ijcai.2021/127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {RGB-infrared (IR) person re-identification is a challenging task due to the large modality gap between RGB and IR images. Many existing methods bridge the modality gap by style conversion, requiring high-similarity images exchanged by complex CNN structures, like GAN. In this paper, we propose a highly compact modality-aware style adaptation (MSA) framework, which aims to explore more potential relations between RGB and IR modalities by introducing new related modalities. Therefore, the attention is shifted from bridging to filling the modality gap with no requirement on high-quality generated images. To this end, we firstly propose a concise feature-free image generation structure to adapt the original modalities to two new styles that are compatible with both inputs by patch-based pixel redistribution. Secondly, we devise two image style quantification metrics to discriminate styles in image space using luminance and contrast. Thirdly, we design two image-level losses based on the quantified results to guide the style adaptation during an end-to-end four-modality collaborative learning process. Experimental results on two datasets SYSU-MM01 and RegDB show that MSA achieves significant improvements with little extra computation cost and outperforms the state-of-the-art methods. Keywords: Computer Vision: Recognition: Detection, Categorization, Indexing, Matching, Retrieval, Semantic Interpretation Machine Learning: Learning Generative Models Machine Learning: Transfer, Adaptation, Multi-task Learning},
  archive   = {C_IJCAI},
  author    = {Ziling Miao and Hong Liu and Wei Shi and Wanlu Xu and Hanrong Ye},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/127},
  pages     = {916-922},
  title     = {Modality-aware style adaptation for RGB-infrared person re-identification},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Point-based acoustic scattering for interactive sound
propagation via surface encoding. <em>IJCAI</em>, 909–915. (<a
href="https://doi.org/10.24963/ijcai.2021/126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present a novel geometric deep learning method to compute the acoustic scattering properties of geometric objects. Our learning algorithm uses a point cloud representation of objects to compute the scattering properties and integrates them with ray tracing for interactive sound propagation in dynamic scenes. We use discrete Laplacian-based surface encoders and approximate the neighborhood of each point using a shared multi-layer perceptron. We show that our formulation is permutation invariant and present a neural network that computes the scattering function using spherical harmonics. Our approach can handle objects with arbitrary topologies and deforming models, and takes less than 1ms per object on a commodity GPU. We have analyzed the accuracy and perform validation on thousands of unseen 3D objects and highlight the benefits over other point-based geometric deep learning methods. To the best of our knowledge, this is the first real-time learning algorithm that can approximate the acoustic scattering properties of arbitrary objects with high accuracy. Keywords: Computer Vision: 2D and 3D Computer Vision Multidisciplinary Topics and Applications: Interactive Entertainment},
  archive   = {C_IJCAI},
  author    = {Hsien-Yu Meng and Zhenyu Tang and Dinesh Manocha},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/126},
  pages     = {909-915},
  title     = {Point-based acoustic scattering for interactive sound propagation via surface encoding},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). CIMON: Towards high-quality hash codes. <em>IJCAI</em>,
902–908. (<a href="https://doi.org/10.24963/ijcai.2021/125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, hashing is widely used in approximate nearest neighbor search for its storage and computational efficiency. Most of the unsupervised hashing methods learn to map images into semantic similarity-preserving hash codes by constructing local semantic similarity structure from the pre-trained model as the guiding information, i.e., treating each point pair similar if their distance is small in feature space. However, due to the inefficient representation ability of the pre-trained model, many false positives and negatives in local semantic similarity will be introduced and lead to error propagation during the hash code learning. Moreover, few of the methods consider the robustness of models, which will cause instability of hash codes to disturbance. In this paper, we propose a new method named Comprehensive sImilarity Mining and cOnsistency learNing (CIMON). First, we use global refinement and similarity statistical distribution to obtain reliable and smooth guidance. Second, both semantic and contrastive consistency learning are introduced to derive both disturb-invariant and discriminative hash codes. Extensive experiments on several benchmark datasets show that the proposed method outperforms a wide range of state-of-the-art methods in both retrieval performance and robustness. Keywords: Computer Vision: Recognition: Detection, Categorization, Indexing, Matching, Retrieval, Semantic Interpretation Data Mining: Information Retrieval},
  archive   = {C_IJCAI},
  author    = {Xiao Luo and Daqing Wu and Zeyu Ma and Chong Chen and Minghua Deng and Jinwen Ma and Zhongming Jin and Jianqiang Huang and Xian-Sheng Hua},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/125},
  pages     = {902-908},
  title     = {CIMON: Towards high-quality hash codes},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). One-shot affordance detection. <em>IJCAI</em>, 895–901. (<a
href="https://doi.org/10.24963/ijcai.2021/124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Affordance detection refers to identifying the potential action possibilities of objects in an image, which is an important ability for robot perception and manipulation. To empower robots with this ability in unseen scenarios, we consider the challenging one-shot affordance detection problem in this paper, i.e., given a support image that depicts the action purpose, all objects in a scene with the common affordance should be detected. To this end, we devise a One-Shot Affordance Detection (OS-AD) network that firstly estimates the purpose and then transfers it to help detect the common affordance from all candidate images. Through collaboration learning, OS-AD can capture the common characteristics between objects having the same underlying affordance and learn a good adaptation capability for perceiving unseen affordances. Besides, we build a Purpose-driven Affordance Dataset (PAD) by collecting and labeling 4k images from 31 affordance and 72 object categories. Experimental results demonstrate the superiority of our model over previous representative ones in terms of both objective metrics and visual quality. The benchmark suite is at ProjectPage. Keywords: Computer Vision: Perception Machine Learning: Deep Learning Robotics: Vision and Perception},
  archive   = {C_IJCAI},
  author    = {Hongchen Luo and Wei Zhai and Jing Zhang and Yang Cao and Dacheng Tao},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/124},
  pages     = {895-901},
  title     = {One-shot affordance detection},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learn from concepts: Towards the purified memory for
few-shot learning. <em>IJCAI</em>, 888–894. (<a
href="https://doi.org/10.24963/ijcai.2021/123">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Human beings have a great generalization ability to recognize a novel category by only seeing a few number of samples. This is because humans possess the ability to learn from the concepts that already exist in our minds. However, many existing few-shot approaches fail in addressing such a fundamental problem, {\it i.e., } how to utilize the knowledge learned in the past to improve the prediction for the new task. In this paper, we present a novel purified memory mechanism that simulates the recognition process of human beings. This new memory updating scheme enables the model to purify the information from semantic labels and progressively learn consistent, stable, and expressive concepts when episodes are trained one by one. On its basis, a Graph Augmentation Module (GAM) is introduced to aggregate these concepts and knowledge learned from new tasks via a graph neural network, making the prediction more accurate. Generally, our approach is model-agnostic and computing efficient with negligible memory cost. Extensive experiments performed on several benchmarks demonstrate the proposed method can consistently outperform a vast number of state-of-the-art few-shot learning methods. Keywords: Computer Vision: 2D and 3D Computer Vision Computer Vision: Recognition: Detection, Categorization, Indexing, Matching, Retrieval, Semantic Interpretation},
  archive   = {C_IJCAI},
  author    = {Xuncheng Liu and Xudong Tian and Shaohui Lin and Yanyun Qu and Lizhuang Ma and Wang Yuan and Zhizhong Zhang and Yuan Xie},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/123},
  pages     = {888-894},
  title     = {Learn from concepts: Towards the purified memory for few-shot learning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Domain generalization under conditional and label shifts via
variational bayesian inference. <em>IJCAI</em>, 881–887. (<a
href="https://doi.org/10.24963/ijcai.2021/122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this work, we propose a domain generalization (DG) approach to learn on several labeled source domains and transfer knowledge to a target domain that is inaccessible in training. Considering the inherent conditional and label shifts, we would expect the alignment of p(x|y) and p(y). However, the widely used domain invariant feature learning (IFL) methods relies on aligning the marginal concept shift w.r.t. p(x), which rests on an unrealistic assumption that p(y) is invariant across domains. We thereby propose a novel variational Bayesian inference framework to enforce the conditional distribution alignment w.r.t. p(x|y) via the prior distribution matching in a latent space, which also takes the marginal label shift w.r.t. p(y) into consideration with the posterior alignment. Extensive experiments on various benchmarks demonstrate that our framework is robust to the label shift and the cross-domain accuracy is significantly improved, thereby achieving superior performance over the conventional IFL counterparts. Keywords: Computer Vision: Recognition: Detection, Categorization, Indexing, Matching, Retrieval, Semantic Interpretation Computer Vision: Statistical Methods and Machine Learning Machine Learning: Classification},
  archive   = {C_IJCAI},
  author    = {Xiaofeng Liu and Bo Hu and Linghao Jin and Xu Han and Fangxu Xing and Jinsong Ouyang and Jun Lu and Georges El Fakhri and Jonghye Woo},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/122},
  pages     = {881-887},
  title     = {Domain generalization under conditional and label shifts via variational bayesian inference},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Graph consistency based mean-teaching for unsupervised
domain adaptive person re-identification. <em>IJCAI</em>, 874–880. (<a
href="https://doi.org/10.24963/ijcai.2021/121">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent works show that mean-teaching is an effective framework for unsupervised domain adaptive person re-identification. However, existing methods perform contrastive learning on selected samples between teacher and student networks, which is sensitive to noises in pseudo labels and neglects the relationship among most samples. Moreover, these methods are not effective in cooperation of different teacher networks. To handle these issues, this paper proposes a Graph Consistency based Mean-Teaching (GCMT) method with constructing the Graph Consistency Constraint (GCC) between teacher and student networks. Specifically, given unlabeled training images, we apply teacher networks to extract corresponding features and further construct a teacher graph for each teacher network to describe the similarity relationships among training images. To boost the representation learning, different teacher graphs are fused to provide the supervise signal for optimizing student networks. GCMT fuses similarity relationships predicted by different teacher networks as supervision and effectively optimizes student networks with more sample relationships involved. Experiments on three datasets, i.e., Market-1501, DukeMTMCreID, and MSMT17, show that proposed GCMT outperforms state-of-the-art methods by clear margin. Specially, GCMT even outperforms the previous method that uses a deeper backbone. Experimental results also show that GCMT can effectively boost the performance with multiple teacher and student networks. Our code is available at https://github.com/liu-xb/GCMT . Keywords: Computer Vision: Recognition: Detection, Categorization, Indexing, Matching, Retrieval, Semantic Interpretation Machine Learning Applications: Applications of Unsupervised Learning},
  archive   = {C_IJCAI},
  author    = {Xiaobin Liu and Shiliang Zhang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/121},
  pages     = {874-880},
  title     = {Graph consistency based mean-teaching for unsupervised domain adaptive person re-identification},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dual reweighting domain generalization for face presentation
attack detection. <em>IJCAI</em>, 867–873. (<a
href="https://doi.org/10.24963/ijcai.2021/120">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Face anti-spoofing approaches based on domain generalization (DG) have drawn growing attention due to their robustness for unseen scenarios. Previous methods treat each sample from multiple domains indiscriminately during the training process, and endeavor to extract a common feature space to improve the generalization. However, due to complex and biased data distribution, directly treating them equally will corrupt the generalization ability. To settle the issue, we propose a novel Dual Reweighting Domain Generalization (DRDG) framework which iteratively reweights the relative importance between samples to further improve the generalization. Concretely, Sample Reweighting Module is first proposed to identify samples with relatively large domain bias, and reduce their impact on the overall optimization. Afterwards, Feature Reweighting Module is introduced to focus on these samples and extract more domain-irrelevant features via a self-distilling mechanism. Combined with the domain discriminator, the iteration of the two modules promotes the extraction of generalized features. Extensive experiments and visualizations are presented to demonstrate the effectiveness and interpretability of our method against the state-of-the-art competitors. Keywords: Computer Vision: Biometrics, Face and Gesture Recognition},
  archive   = {C_IJCAI},
  author    = {Shubao Liu and Ke-Yue Zhang and Taiping Yao and Kekai Sheng and Shouhong Ding and Ying Tai and Jilin Li and Yuan Xie and Lizhuang Ma},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/120},
  pages     = {867-873},
  title     = {Dual reweighting domain generalization for face presentation attack detection},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bipartite matching for crowd counting with point
supervision. <em>IJCAI</em>, 860–866. (<a
href="https://doi.org/10.24963/ijcai.2021/119">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {For crowd counting task, it has been demonstrated that imposing Gaussians to point annotations hurts generalization performance. Several methods attempt to utilize point annotations as supervision directly. And they have made significant improvement compared with density-map based methods. However, these point based methods ignore the inevitable annotation noises and still suffer from low robustness to noisy annotations. To address the problem, we propose a bipartite matching based method for crowd counting with only point supervision (BM-Count). In BM-Count, we select a subset of most similar pixels from the predicted density map to match annotated pixels via bipartite matching. Then loss functions can be defined based on the matching pairs to alleviate the bad effect caused by those annotated dots with incorrect positions. Under the noisy annotations, our method reduces MAE and RMSE by 9\% and 11.2\% respectively. Moreover, we propose a novel ranking distribution learning framework to address the imbalanced distribution problem of head counts, which encodes the head counts as classification distribution in the ranking domain and refines the estimated count map in the continuous domain. Extensive experiments on four datasets show that our method achieves state-of-the-art performance and performs better crowd localization. Keywords: Computer Vision: Perception Computer Vision: Video: Events, Activities and Surveillance Machine Learning: Deep Learning},
  archive   = {C_IJCAI},
  author    = {Hao Liu and Qiang Zhao and Yike Ma and Feng Dai},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/119},
  pages     = {860-866},
  title     = {Bipartite matching for crowd counting with point supervision},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning 3-d human pose estimation from catadioptric videos.
<em>IJCAI</em>, 852–859. (<a
href="https://doi.org/10.24963/ijcai.2021/118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {3-D human pose estimation is a crucial step for understanding human actions. However, reliably capturing precise 3-D position of human joints is non-trivial and tedious. Current models often suffer from the scarcity of high-quality 3-D annotated training data. In this work, we explore a novel way of obtaining gigantic 3-D human pose data without manual annotations. In catedioptric videos (\emph{e.g.}, people dance before a mirror), the camera records both the original and mirrored human poses, which provides cues for estimating 3-D positions of human joints. Following this idea, we crawl a large-scale Dance-before-Mirror (DBM) video dataset, which is about 24 times larger than existing Human3.6M benchmark. Our technical insight is that, by jointly harnessing the epipolar geometry and human skeleton priors, 3-D joint estimation can boil down to an optimization problem over two sets of 2-D estimations. To our best knowledge, this represents the first work that collects high-quality 3-D human data via catadioptric systems. We have conducted comprehensive experiments on cross-scenario pose estimation and visualization analysis. The results strongly demonstrate the usefulness of our proposed DBM human poses. Keywords: Computer Vision: 2D and 3D Computer Vision Computer Vision: Video: Events, Activities and Surveillance},
  archive   = {C_IJCAI},
  author    = {Chenchen Liu and Yongzhi Li and Kangqi Ma and Duo Zhang and Peijun Bao and Yadong Mu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/118},
  pages     = {852-859},
  title     = {Learning 3-D human pose estimation from catadioptric videos},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A multi-constraint similarity learning with adaptive
weighting for visible-thermal person re-identification. <em>IJCAI</em>,
845–851. (<a href="https://doi.org/10.24963/ijcai.2021/117">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The challenges of visible-thermal person re-identification (VT-ReID) lies in the inter-modality discrepancy and the intra-modality variations. An appropriate metric learning plays a crucial role in optimizing the feature similarity between the two modalities. However, most existing metric learning-based methods mainly constrain the similarity between individual instances or class centers, which are inadequate to explore the rich data relationships in the cross-modality data. Besides, most of these methods fail to consider the importance of different pairs, incurring an inefficiency and ineffectiveness of optimization. To address these issues, we propose a Multi-Constraint (MC) similarity learning method that jointly considers the cross-modality relationships from three different aspects, i.e., Instance-to-Instance (I2I), Center-to-Instance (C2I), and Center-to-Center (C2C). Moreover, we devise an Adaptive Weighting Loss (AWL) function to implement the MC efficiently. In the AWL, we first use an adaptive margin pair mining to select informative pairs and then adaptively adjust weights of mined pairs based on their similarity. Finally, the mined and weighted pairs are used for the metric learning. Extensive experiments on two benchmark datasets demonstrate the superior performance of the proposed over the state-of-the-art methods. Keywords: Computer Vision: Recognition: Detection, Categorization, Indexing, Matching, Retrieval, Semantic Interpretation Machine Learning: Deep Learning},
  archive   = {C_IJCAI},
  author    = {Yongguo Ling and Zhiming Luo and Yaojin Lin and Shaozi Li},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/117},
  pages     = {845-851},
  title     = {A multi-constraint similarity learning with adaptive weighting for visible-thermal person re-identification},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Direct measure matching for crowd counting. <em>IJCAI</em>,
837–844. (<a href="https://doi.org/10.24963/ijcai.2021/116">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Traditional crowd counting approaches usually use Gaussian assumption to generate pseudo density ground truth, which suffers from problems like inaccurate estimation of the Gaussian kernel sizes. In this paper, we propose a new measure-based counting approach to regress the predicted density maps to the scattered point-annotated ground truth directly. First, crowd counting is formulated as a measure matching problem. Second, we derive a semi-balanced form of Sinkhorn divergence, based on which a Sinkhorn counting loss is designed for measure matching. Third, we propose a self-supervised mechanism by devising a Sinkhorn scale consistency loss to resist scale changes. Finally, an efficient optimization method is provided to minimize the overall loss function. Extensive experiments on four challenging crowd counting datasets namely ShanghaiTech, UCF-QNRF, JHU++ and NWPU have validated the proposed method. Keywords: Computer Vision: Recognition: Detection, Categorization, Indexing, Matching, Retrieval, Semantic Interpretation Data Mining: Class Imbalance and Unequal Cost Constraints and SAT: Constraint Optimization},
  archive   = {C_IJCAI},
  author    = {Hui Lin and Xiaopeng Hong and Zhiheng Ma and Xing Wei and Yunfeng Qiu and Yaowei Wang and Yihong Gong},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/116},
  pages     = {837-844},
  title     = {Direct measure matching for crowd counting},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Noise2Grad: Extract image noise to denoise. <em>IJCAI</em>,
830–836. (<a href="https://doi.org/10.24963/ijcai.2021/115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In many image denoising tasks, the difficulty of collecting noisy/clean image pairs limits the application of supervised CNNs. We consider such a case in which paired data and noise statistics are not accessible, but unpaired noisy and clean images are easy to collect. To form the necessary supervision, our strategy is to extract the noise from the noisy image to synthesize new data. To ease the interference of the image background, we use a noise removal module to aid noise extraction. The noise removal module first roughly removes noise from the noisy image, which is equivalent to excluding much background information. A noise approximation module can therefore easily extract a new noise map from the removed noise to match the gradient of the noisy input. This noise map is added to a random clean image to synthesize a new data pair, which is then fed back to the noise removal module to correct the noise removal process. These two modules cooperate to extract noise finely. After convergence, the noise removal module can remove noise without damaging other background details, so we use it as our final denoising network. Experiments show that the denoising performance of the proposed method is competitive with other supervised CNNs. Keywords: Computer Vision: Computational Photography, Photometry, Shape from X Machine Learning: Weakly Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Huangxing Lin and Yihong Zhuang and Yue Huang and Xinghao Ding and Xiaoqing Liu and Yizhou Yu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/115},
  pages     = {830-836},
  title     = {Noise2Grad: Extract image noise to denoise},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Instance-aware coherent video style transfer for chinese ink
wash painting. <em>IJCAI</em>, 823–829. (<a
href="https://doi.org/10.24963/ijcai.2021/114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent researches have made remarkable achievements in fast video style transfer based on western paintings. However, due to the inherent different drawing techniques and aesthetic expressions of Chinese ink wash painting, existing methods either achieve poor temporal consistency or fail to transfer the key freehand brushstroke characteristics of Chinese ink wash painting. In this paper, we present a novel video style transfer framework for Chinese ink wash paintings. The two key ideas are a multi-frame fusion for temporal coherence and an instance-aware style transfer. The frame reordering and stylization based on reference frame fusion are proposed to improve temporal consistency. Meanwhile, the proposed method is able to adaptively leave the white spaces in the background and to select proper scales to extract features and depict the foreground subject by leveraging instance segmentation. Experimental results demonstrate the superiority of the proposed method over state-of-the-art style transfer methods in terms of both temporal coherence and visual quality. Our project website is available at https://oblivioussy.github.io/InkVideo/. Keywords: Computer Vision: 2D and 3D Computer Vision Machine Learning: Adversarial Machine Learning Multidisciplinary Topics and Applications: Art and Music},
  archive   = {C_IJCAI},
  author    = {Hao Liang and Shuai Yang and Wenjing Wang and Jiaying Liu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/114},
  pages     = {823-829},
  title     = {Instance-aware coherent video style transfer for chinese ink wash painting},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). PIANO: A parametric hand bone model from magnetic resonance
imaging. <em>IJCAI</em>, 816–822. (<a
href="https://doi.org/10.24963/ijcai.2021/113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Hand modeling is critical for immersive VR/AR, action understanding, or human healthcare. Existing parametric models account only for hand shape, pose, or texture, without modeling the anatomical attributes like bone, which is essential for realistic hand biomechanics analysis. In this paper, we present PIANO, the first parametric bone model of human hands from MRI data. Our PIANO model is biologically correct, simple to animate, and differentiable, achieving more anatomically precise modeling of the inner hand kinematic structure in a data-driven manner than the traditional hand models based on the outer surface only. Furthermore, our PIANO model can be applied in neural network layers to enable training with a fine-grained semantic loss, which opens up the new task of data-driven fine-grained hand bone anatomic and semantic understanding from MRI or even RGB images. We make our model publicly available. Keywords: Computer Vision: Biomedical Image Understanding Computer Vision: Recognition: Detection, Categorization, Indexing, Matching, Retrieval, Semantic Interpretation Computer Vision: Statistical Methods and Machine Learning},
  archive   = {C_IJCAI},
  author    = {Yuwei Li and Minye Wu and Yuyao Zhang and Lan Xu and Jingyi Yu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/113},
  pages     = {816-822},
  title     = {PIANO: A parametric hand bone model from magnetic resonance imaging},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Medical image segmentation using squeeze-and-expansion
transformers. <em>IJCAI</em>, 807–815. (<a
href="https://doi.org/10.24963/ijcai.2021/112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Medical image segmentation is important for computer-aided diagnosis. Good segmentation demands the model to see the big picture and fine details simultaneously, i.e., to learn image features that incorporate large context while keep high spatial resolutions. To approach this goal, the most widely used methods -- U-Net and variants, extract and fuse multi-scale features. However, the fused features still have small &quot;effective receptive fields&quot; with a focus on local image cues, limiting their performance. In this work, we propose Segtran, an alternative segmentation framework based on transformers, which have unlimited &quot;effective receptive fields&quot; even at high feature resolutions. The core of Segtran is a novel Squeeze-and-Expansion transformer: a squeezed attention block regularizes the self attention of transformers, and an expansion block learns diversified representations. Additionally, we propose a new positional encoding scheme for transformers, imposing a continuity inductive bias for images. Experiments were performed on 2D and 3D medical image segmentation tasks: optic disc/cup segmentation in fundus images (REFUGE&#39;20 challenge), polyp segmentation in colonoscopy images, and brain tumor segmentation in MRI scans (BraTS&#39;19 challenge). Compared with representative existing methods, Segtran consistently achieved the highest segmentation accuracy, and exhibited good cross-domain generalization capabilities. Keywords: Computer Vision: 2D and 3D Computer Vision Computer Vision: Biomedical Image Understanding},
  archive   = {C_IJCAI},
  author    = {Shaohua Li and Xiuchao Sui and Xiangde Luo and Xinxing Xu and Yong Liu and Rick Goh},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/112},
  pages     = {807-815},
  title     = {Medical image segmentation using squeeze-and-expansion transformers},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Deep automatic natural image matting. <em>IJCAI</em>,
800–806. (<a href="https://doi.org/10.24963/ijcai.2021/111">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Automatic image matting (AIM) refers to estimating the soft foreground from an arbitrary natural image without any auxiliary input like trimap, which is useful for image editing. Prior methods try to learn semantic features to aid the matting process while being limited to images with salient opaque foregrounds such as humans and animals. In this paper, we investigate the difficulties when extending them to natural images with salient transparent/meticulous foregrounds or non-salient foregrounds. To address the problem, a novel end-to-end matting network is proposed, which can predict a generalized trimap for any image of the above types as a unified semantic representation. Simultaneously, the learned semantic features guide the matting network to focus on the transition areas via an attention mechanism. We also construct a test set AIM-500 that contains 500 diverse natural images covering all types along with manually labeled alpha mattes, making it feasible to benchmark the generalization ability of AIM models. Results of the experiments demonstrate that our network trained on available composite matting datasets outperforms existing methods both objectively and subjectively. The source code and dataset are available at https://github.com/JizhiziLi/AIM. Keywords: Computer Vision: Perception Computer Vision: Recognition: Detection, Categorization, Indexing, Matching, Retrieval, Semantic Interpretation Machine Learning: Deep Learning},
  archive   = {C_IJCAI},
  author    = {Jizhizi Li and Jing Zhang and Dacheng Tao},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/111},
  pages     = {800-806},
  title     = {Deep automatic natural image matting},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). IMENet: Joint 3D semantic scene completion and 2D semantic
segmentation through iterative mutual enhancement. <em>IJCAI</em>,
793–799. (<a href="https://doi.org/10.24963/ijcai.2021/110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {3D semantic scene completion and 2D semantic segmentation are two tightly correlated tasks that are both essential for indoor scene understanding, because they predict the same semantic classes, using positively correlated high-level features. Current methods use 2D features extracted from early-fused RGB-D images for 2D segmentation to improve 3D scene completion. We argue that this sequential scheme does not ensure these two tasks fully benefit each other, and present an Iterative Mutual Enhancement Network (IMENet) to solve them jointly, which interactively refines the two tasks at the late prediction stage. Specifically, two refinement modules are developed under a unified framework for the two tasks. The first is a 2D Deformable Context Pyramid (DCP) module, which receives the projection from the current 3D predictions to refine the 2D predictions. In turn, a 3D Deformable Depth Attention (DDA) module is proposed to leverage the reprojected results from 2D predictions to update the coarse 3D predictions. This iterative fusion happens to the stable high-level features of both tasks at a late stage. Extensive experiments on NYU and NYUCAD datasets verify the effectiveness of the proposed iterative late fusion scheme, and our approach outperforms the state of the art on both 3D semantic scene completion and 2D semantic segmentation. Keywords: Computer Vision: 2D and 3D Computer Vision},
  archive   = {C_IJCAI},
  author    = {Jie Li and Laiyan Ding and Rui Huang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/110},
  pages     = {793-799},
  title     = {IMENet: Joint 3D semantic scene completion and 2D semantic segmentation through iterative mutual enhancement},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Noise doesn’t lie: Towards universal detection of deep
inpainting. <em>IJCAI</em>, 786–792. (<a
href="https://doi.org/10.24963/ijcai.2021/109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep image inpainting aims to restore damaged or missing regions in an image with realistic contents. While having a wide range of applications such as object removal and image recovery, deep inpainting techniques also have the risk of being manipulated for image forgery. A promising countermeasure against such forgeries is deep inpainting detection, which aims to locate the inpainted regions in an image. In this paper, we make the first attempt towards universal detection of deep inpainting, where the detection network can generalize well when detecting different deep inpainting methods. To this end, we first propose a novel data generation approach to generate a universal training dataset, which imitates the noise discrepancies exist in real versus inpainted image contents to train universal detectors. We then design a Noise-Image Cross-fusion Network (NIX-Net) to effectively exploit the discriminative information contained in both the images and their noise patterns. We empirically show, on multiple benchmark datasets, that our approach outperforms existing detection methods by a large margin and generalize well to unseen deep inpainting techniques. Our universal training dataset can also significantly boost the generalizability of existing detection methods. Keywords: Computer Vision: Recognition: Detection, Categorization, Indexing, Matching, Retrieval, Semantic Interpretation},
  archive   = {C_IJCAI},
  author    = {Ang Li and Qiuhong Ke and Xingjun Ma and Haiqin Weng and Zhiyuan Zong and Feng Xue and Rui Zhang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/109},
  pages     = {786-792},
  title     = {Noise doesn&#39;t lie: Towards universal detection of deep inpainting},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Information bottleneck approach to spatial attention
learning. <em>IJCAI</em>, 779–785. (<a
href="https://doi.org/10.24963/ijcai.2021/108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The selective visual attention mechanism in the human visual system (HVS) restricts the amount of information to reach visual awareness for perceiving natural scenes, allowing near real-time information processing with limited computational capacity. This kind of selectivity acts as an ‘Information Bottleneck (IB)’, which seeks a trade-off between information compression and predictive accuracy. However, such information constraints are rarely explored in the attention mechanism for deep neural networks (DNNs). In this paper, we propose an IB-inspired spatial attention module for DNN structures built for visual recognition. The module takes as input an intermediate representation of the input image, and outputs a variational 2D attention map that minimizes the mutual information (MI) between the attention-modulated representation and the input, while maximizing the MI between the attention-modulated representation and the task label. To further restrict the information bypassed by the attention map, we quantize the continuous attention scores to a set of learnable anchor values during training. Extensive experiments show that the proposed IB-inspired spatial attention mechanism can yield attention maps that neatly highlight the regions of interest while suppressing backgrounds, and bootstrap standard DNN structures for visual recognition tasks (e.g., image classification, fine-grained recognition, cross-domain classification). The attention maps are interpretable for the decision making of the DNNs as verified in the experiments. Our code is available at this https URL. Keywords: Computer Vision: 2D and 3D Computer Vision Machine Learning: Classification Machine Learning: Deep Learning},
  archive   = {C_IJCAI},
  author    = {Qiuxia Lai and Yu Li and Ailing Zeng and Minhao Liu and Hanqiu Sun and Qiang Xu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/108},
  pages     = {779-785},
  title     = {Information bottleneck approach to spatial attention learning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Planning with learned dynamic model for unsupervised point
cloud registration. <em>IJCAI</em>, 772–778. (<a
href="https://doi.org/10.24963/ijcai.2021/107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Point cloud registration is a fundamental problem in 3D computer vision. In this paper, we cast point cloud registration into a planning problem in reinforcement learning, which can seek the transformation between the source and target point clouds through trial and error. By modeling the point cloud registration process as a Markov decision process (MDP), we develop a latent dynamic model of point clouds, consisting of a transformation network and evaluation network. The transformation network aims to predict the new transformed feature of the point cloud after performing a rigid transformation (i.e., action) on it while the evaluation network aims to predict the alignment precision between the transformed source point cloud and target point cloud as the reward signal. Once the dynamic model of the point cloud is trained, we employ the cross-entropy method (CEM) to iteratively update the planning policy by maximizing the rewards in the point cloud registration process. Thus, the optimal policy, i.e., the transformation between the source and target point clouds, can be obtained via gradually narrowing the search space of the transformation. Experimental results on ModelNet40 and 7Scene benchmark datasets demonstrate that our method can yield good registration performance in an unsupervised manner. Keywords: Computer Vision: 2D and 3D Computer Vision Machine Learning Applications: Applications of Reinforcement Learning},
  archive   = {C_IJCAI},
  author    = {Haobo Jiang and Jianjun Qian and Jin Xie and Jian Yang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/107},
  pages     = {772-778},
  title     = {Planning with learned dynamic model for unsupervised point cloud registration},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Step-wise hierarchical alignment network for image-text
matching. <em>IJCAI</em>, 765–771. (<a
href="https://doi.org/10.24963/ijcai.2021/106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Image-text matching plays a central role in bridging the semantic gap between vision and language. The key point to achieve precise visual-semantic alignment lies in capturing the fine-grained cross-modal correspondence between image and text. Most previous methods rely on single-step reasoning to discover the visual-semantic interactions, which lacks the ability of exploiting the multi-level information to locate the hierarchical fine-grained relevance. Different from them, in this work, we propose a step-wise hierarchical alignment network (SHAN) that decomposes image-text matching into multi-step cross-modal reasoning process. Specifically, we first achieve local-to-local alignment at fragment level, following by performing global-to-local and global-to-global alignment at context level sequentially. This progressive alignment strategy supplies our model with more complementary and sufficient semantic clues to understand the hierarchical correlations between image and text. The experimental results on two benchmark datasets demonstrate the superiority of our proposed method. Keywords: Computer Vision: Language and Vision},
  archive   = {C_IJCAI},
  author    = {Zhong Ji and Kexin Chen and Haoran Wang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/106},
  pages     = {765-771},
  title     = {Step-wise hierarchical alignment network for image-text matching},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Perturb, predict &amp; paraphrase: Semi-supervised learning
using noisy student for image captioning. <em>IJCAI</em>, 758–764. (<a
href="https://doi.org/10.24963/ijcai.2021/105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent semi-supervised learning (SSL) methods are predominantly focused on multi-class classification tasks. Classification tasks allow for easy mixing of class labels during augmentation which does not trivially extend to structured outputs such as word sequences that appear in tasks like image captioning. Noisy Student Training is a recent SSL paradigm proposed for image classification that is an extension of self-training and teacher-student learning. In this work, we provide an in-depth analysis of the noisy student SSL framework for the task of image captioning and derive state-of-the-art results. The original algorithm relies on computationally expensive data augmentation steps that involve perturbing the raw images and computing features for each perturbed image. We show that, even in the absence of raw image augmentation, the use of simple model and feature perturbations to the input images for the student model are beneficial to SSL training. We also show how a paraphrase generator could be effectively used for label augmentation to improve the quality of pseudo labels and significantly improve performance. Our final results in the limited labeled data setting (1\% of the MS-COCO labeled data) outperform previous state-of-the-art approaches by 2.5 on BLEU4 and 11.5 on CIDEr scores. Keywords: Computer Vision: Language and Vision Machine Learning: Semi-Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Arjit Jain and Pranay Reddy Samala and Preethi Jyothi and Deepak Mittal and Maneesh Singh},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/105},
  pages     = {758-764},
  title     = {Perturb, predict &amp;amp; paraphrase: Semi-supervised learning using noisy student for image captioning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Self-supervised video representation learning with
constrained spatiotemporal jigsaw. <em>IJCAI</em>, 751–757. (<a
href="https://doi.org/10.24963/ijcai.2021/104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper proposes a novel pretext task for self-supervised video representation learning by exploiting spatiotemporal continuity in videos. It is motivated by the fact that videos are spatiotemporal by nature and a representation learned by detecting spatiotemporal continuity/discontinuity is thus beneficial for downstream video content analysis tasks. A natural choice of such a pretext task is to construct spatiotemporal (3D) jigsaw puzzles and learn to solve them. However, as we demonstrate in the experiments, this task turns out to be intractable. We thus propose Constrained Spatiotemporal Jigsaw (CSJ) whereby the 3D jigsaws are formed in a constrained manner to ensure that large continuous spatiotemporal cuboids exist. This provides sufficient cues for the model to reason about the continuity. Instead of solving them directly, which could still be extremely hard, we carefully design four surrogate tasks that are more solvable. The four tasks aim to learn representations sensitive to spatiotemporal continuity at both the local and global levels. Extensive experiments show that our CSJ achieves state-of-the-art on various benchmarks. Keywords: Computer Vision: Action Recognition Machine Learning: Unsupervised Learning},
  archive   = {C_IJCAI},
  author    = {Yuqi Huo and Mingyu Ding and Haoyu Lu and Ziyuan Huang and Mingqian Tang and Zhiwu Lu and Tao Xiang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/104},
  pages     = {751-757},
  title     = {Self-supervised video representation learning with constrained spatiotemporal jigsaw},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). AgeFlow: Conditional age progression and regression with
normalizing flows. <em>IJCAI</em>, 743–750. (<a
href="https://doi.org/10.24963/ijcai.2021/103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Age progression and regression aim to synthesize photorealistic appearance of a given face image with aging and rejuvenation effects, respectively. Existing generative adversarial networks (GANs) based methods suffer from the following three major issues: 1) unstable training introducing strong ghost artifacts in the generated faces, 2) unpaired training leading to unexpected changes in facial attributes such as genders and races, and 3) non-bijective age mappings increasing the uncertainty in the face transformation. To overcome these issues, this paper proposes a novel framework, termed AgeFlow, to integrate the advantages of both flow-based models and GANs. The proposed AgeFlow contains three parts: an encoder that maps a given face to a latent space through an invertible neural network, a novel invertible conditional translation module (ICTM) that translates the source latent vector to target one, and a decoder that reconstructs the generated face from the target latent vector using the same encoder network; all parts are invertible achieving bijective age mappings. The novelties of ICTM are two-fold. First, we propose an attribute-aware knowledge distillation to learn the manipulation direction of age progression while keeping other unrelated attributes unchanged, alleviating unexpected changes in facial attributes. Second, we propose to use GANs in the latent space to ensure the learned latent vector indistinguishable from the real ones, which is much easier than traditional use of GANs in the image domain. Experimental results demonstrate superior performance over existing GANs-based methods on two benchmarked datasets. The source code is available at https://github.com/Hzzone/AgeFlow. Keywords: Computer Vision: Biometrics, Face and Gesture Recognition Machine Learning: Unsupervised Learning Computer Vision: 2D and 3D Computer Vision},
  archive   = {C_IJCAI},
  author    = {Zhizhong Huang and Shouzhen Chen and Junping Zhang and Hongming Shan},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/103},
  pages     = {743-750},
  title     = {AgeFlow: Conditional age progression and regression with normalizing flows},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic inconsistency-aware DeepFake video detection.
<em>IJCAI</em>, 736–742. (<a
href="https://doi.org/10.24963/ijcai.2021/102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The spread of DeepFake videos causes a serious threat to information security, calling for effective detection methods to distinguish them. However, the performance of recent frame-based detection methods become limited due to their ignorance of the inter-frame inconsistency of fake videos. In this paper, we propose a novel Dynamic Inconsistency-aware Network to handle the inconsistent problem, which uses a Cross-Reference module (CRM) to capture both the global and local inter-frame inconsistencies. The CRM contains two parallel branches. The first branch takes faces from adjacent frames as input, and calculates a structure similarity map for a global inconsistency representation. The second branch only focuses on the inter-frame variation of independent critical regions, which captures the local inconsistency. To the best of our knowledge, this is the first work to totally use the inter-frame inconsistency information from the global and local perspectives. Compared with existing methods, our model provides a more accurate and robust detection on FaceForensics++, DFDC-preview and Celeb-DFv2 datasets. Keywords: Computer Vision: Biometrics, Face and Gesture Recognition Computer Vision: Recognition: Detection, Categorization, Indexing, Matching, Retrieval, Semantic Interpretation},
  archive   = {C_IJCAI},
  author    = {Ziheng Hu and Hongtao Xie and YuXin Wang and Jiahong Li and Zhongyuan Wang and Yongdong Zhang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/102},
  pages     = {736-742},
  title     = {Dynamic inconsistency-aware DeepFake video detection},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-scale selective feedback network with dual loss for
real image denoising. <em>IJCAI</em>, 729–735. (<a
href="https://doi.org/10.24963/ijcai.2021/101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The feedback mechanism in the human visual system extracts high-level semantics from noisy scenes. It then guides low-level noise removal, which has not been fully explored in image denoising networks based on deep learning. The commonly used fully-supervised network optimizes parameters through paired training data. However, unpaired images without noise-free labels are ubiquitous in the real world. Therefore, we proposed a multi-scale selective feedback network (MSFN) with the dual loss. We allow shallow layers to access valuable contextual information from the following deep layers selectively between two adjacent time steps. Iterative refinement mechanism can remove complex noise from coarse to fine. The dual regression is designed to reconstruct noisy images to establish closed-loop supervision that is training-friendly for unpaired data. We use the dual loss to optimize the primary clean-to-noisy task and the dual noisy-to-clean task simultaneously. Extensive experiments prove that our method achieves state-of-the-art results and shows better adaptability on real-world images than the existing methods. Keywords: Computer Vision: Computational Photography, Photometry, Shape from X Machine Learning: Deep Learning},
  archive   = {C_IJCAI},
  author    = {Xiaowan Hu and Yuanhao Cai and Zhihong Liu and Haoqian Wang and Yulun Zhang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/101},
  pages     = {729-735},
  title     = {Multi-scale selective feedback network with dual loss for real image denoising},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DeepME: Deep mixture experts for large-scale image
classification. <em>IJCAI</em>, 722–728. (<a
href="https://doi.org/10.24963/ijcai.2021/100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Although deep learning has demonstrated its outstanding performance on image classification, most well-known deep networks make efforts to optimize both their structures and their node weights for recognizing fewer (e.g., no more than 1000) object classes. Therefore, it is attractive to extend or mixture such well-known deep networks to support large-scale image classification. According to our best knowledge, how to adaptively and effectively fuse multiple CNNs for large-scale image classification is still under-explored. On this basis, a deep mixture algorithm is developed to support large-scale image classification in this paper. First, a soft spectral clustering method is developed to construct a two-layer ontology (group layer and category layer) by assigning large numbers of image categories into a set of groups according to their inter-category semantic correlations, where the semantically-related image categories under the neighbouring group nodes may share similar learning complexities. Then, such two-layer ontology is further used to generate the task groups, in which each task group contains partial image categories with similar learning complexities and one particular base deep network is learned. Finally, a gate network is learned to combine all base deep networks with fewer diverse outputs to generate a mixture network with larger outputs. Our experimental results on ImageNet10K have demonstrated that our proposed deep mixture algorithm can achieve very competitive results (top 1 accuracy: 32.13\%) on large-scale image classification tasks. Keywords: Computer Vision: Recognition: Detection, Categorization, Indexing, Matching, Retrieval, Semantic Interpretation Machine Learning: Deep Learning Machine Learning: Classification},
  archive   = {C_IJCAI},
  author    = {Ming He and Guangyi Lv and Weidong He and Jianping Fan and Guihua Zeng},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/100},
  pages     = {722-728},
  title     = {DeepME: Deep mixture experts for large-scale image classification},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Disentangled face attribute editing via instance-aware
latent space search. <em>IJCAI</em>, 715–721. (<a
href="https://doi.org/10.24963/ijcai.2021/99">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent works have shown that a rich set of semantic directions exist in the latent space of Generative Adversarial Networks (GANs), which enables various facial attribute editing applications. However, existing methods may suffer poor attribute variation disentanglement, leading to unwanted change of other attributes when altering the desired one. The semantic directions used by existing methods are at attribute level, which are difficult to model complex attribute correlations, especially in the presence of attribute distribution bias in GAN&#39;s training set. In this paper, we propose a novel framework (IALS) that performs Instance-Aware Latent-Space Search to find semantic directions for disentangled attribute editing. The instance information is injected by leveraging the supervision from a set of attribute classifiers evaluated on the input images. We further propose a Disentanglement-Transformation (DT) metric to quantify the attribute transformation and disentanglement efficacy and find the optimal control factor between attribute-level and instance-specific directions based on it. Experimental results on both GAN-generated and real-world images collectively show that our method outperforms state-of-the-art methods proposed recently by a wide margin. Code is available at https://github.com/yxuhan/IALS. Keywords: Computer Vision: 2D and 3D Computer Vision Machine Learning: Explainable/Interpretable Machine Learning},
  archive   = {C_IJCAI},
  author    = {Yuxuan Han and Jiaolong Yang and Ying Fu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/99},
  pages     = {715-721},
  title     = {Disentangled face attribute editing via instance-aware latent space search},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). AdaVQA: Overcoming language priors with adapted margin
cosine loss. <em>IJCAI</em>, 708–714. (<a
href="https://doi.org/10.24963/ijcai.2021/98">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A number of studies point out that current Visual Question Answering (VQA) models are severely affected by the language prior problem, which refers to blindly making predictions based on the language shortcut. Some efforts have been devoted to overcoming this issue with delicate models. However, there is no research to address it from the view of the answer feature space learning, despite the fact that existing VQA methods all cast VQA as a classification task. Inspired by this, in this work, we attempt to tackle the language prior problem from the viewpoint of the feature space learning. An adapted margin cosine loss is designed to discriminate the frequent and the sparse answer feature space under each question type properly. In this way, the limited patterns within the language modality can be largely reduced to eliminate the language priors. We apply this loss function to several baseline models and evaluate its effectiveness on two VQA-CP benchmarks. Experimental results demonstrate that our proposed adapted margin cosine loss can enhance the baseline models with an absolute performance gain of 15\% on average, strongly verifying the potential of tackling the language prior problem in VQA from the angle of the answer feature space learning. Keywords: Computer Vision: Language and Vision Machine Learning: Deep Learning},
  archive   = {C_IJCAI},
  author    = {Yangyang Guo and Liqiang Nie and Zhiyong Cheng and Feng Ji and Ji Zhang and Alberto Del Bimbo},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/98},
  pages     = {708-714},
  title     = {AdaVQA: Overcoming language priors with adapted margin cosine loss},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). EventDrop: Data augmentation for event-based learning.
<em>IJCAI</em>, 700–707. (<a
href="https://doi.org/10.24963/ijcai.2021/97">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The advantages of event-sensing over conventional sensors (e.g., higher dynamic range, lower time latency, and lower power consumption) have spurred research into machine learning for event data. Unsurprisingly, deep learning has emerged as a competitive methodology for learning with event sensors; in typical setups, discrete and asynchronous events are first converted into frame-like tensors on which standard deep networks can be applied. However, over-fitting remains a challenge, particularly since event datasets remain small relative to conventional datasets (e.g., ImageNet). In this paper, we introduce EventDrop, a new method for augmenting asynchronous event data to improve the generalization of deep models. By dropping events selected with various strategies, we are able to increase the diversity of training data (e.g., to simulate various levels of occlusion). From a practical perspective, EventDrop is simple to implement and computationally low-cost. Experiments on two event datasets (N-Caltech101 and N-Cars) demonstrate that EventDrop can significantly improve the generalization performance across a variety of deep networks. Keywords: Computer Vision: Recognition: Detection, Categorization, Indexing, Matching, Retrieval, Semantic Interpretation Data Mining: Classification},
  archive   = {C_IJCAI},
  author    = {Fuqiang Gu and Weicong Sng and Xuke Hu and Fangwen Yu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/97},
  pages     = {700-707},
  title     = {EventDrop: Data augmentation for event-based learning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Self-supervised video action localization with adversarial
temporal transforms. <em>IJCAI</em>, 693–699. (<a
href="https://doi.org/10.24963/ijcai.2021/96">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Weakly-supervised temporal action localization aims to locate intervals of action instances with only video-level action labels for training. However, the localization results generated from video classification networks are often not accurate due to the lack of temporal boundary annotation of actions. Our motivating insight is that the temporal boundary of action should be stably predicted under various temporal transforms. This inspires a self-supervised equivariant transform consistency constraint. We design a set of temporal transform operations, including naive temporal down-sampling to learnable attention-piloted time warping. In our model, a localization network aims to perform well under all transforms, and another policy network is designed to choose a temporal transform at each iteration that adversarially brings localization result inconsistent with the localization network&#39;s. Additionally, we devise a self-refine module to enhance the completeness of action intervals harnessing temporal and semantic contexts. Experimental results on THUMOS14 and ActivityNet demonstrate that our model consistently outperforms the state-of-the-art weakly-supervised temporal action localization methods. Keywords: Computer Vision: Action Recognition Computer Vision: Video: Events, Activities and Surveillance},
  archive   = {C_IJCAI},
  author    = {Guoqiang Gong and Liangfeng Zheng and Wenhao Jiang and Yadong Mu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/96},
  pages     = {693-699},
  title     = {Self-supervised video action localization with adversarial temporal transforms},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning spectral dictionary for local representation of
mesh. <em>IJCAI</em>, 685–692. (<a
href="https://doi.org/10.24963/ijcai.2021/95">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {For meshes, sharing the topology of a template is a common and practical setting in face-, hand-, and body-related applications. Meshes are irregular since each vertex&#39;s neighbors are unordered and their orientations are inconsistent with other vertices. Previous methods use isotropic filters or predefined local coordinate systems or learning weighting matrices for each vertex of the template to overcome the irregularity. Learning weighting matrices for each vertex to soft-permute the vertex&#39;s neighbors into an implicit canonical order is an effective way to capture the local structure of each vertex. However, learning weighting matrices for each vertex increases the parameter size linearly with the number of vertices and large amounts of parameters are required for high-resolution 3D shapes. In this paper, we learn spectral dictionary (i.e., bases) for the weighting matrices such that the parameter size is independent of the resolution of 3D shapes. The coefficients of the weighting matrix bases for each vertex are learned from the spectral features of the template&#39;s vertex and its neighbors in a weight-sharing manner. Comprehensive experiments demonstrate that our model produces state-of-the-art results with a much smaller model size. Keywords: Computer Vision: 2D and 3D Computer Vision Computer Vision: Structural and Model-Based Approaches, Knowledge Representation and Reasoning},
  archive   = {C_IJCAI},
  author    = {Zhongpai Gao and Junchi Yan and Guangtao Zhai and Xiaokang Yang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/95},
  pages     = {685-692},
  title     = {Learning spectral dictionary for local representation of mesh},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-view feature augmentation with adaptive class
activation mapping. <em>IJCAI</em>, 678–684. (<a
href="https://doi.org/10.24963/ijcai.2021/94">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose an end-to-end-trainable feature augmentation module built for image classification that extracts and exploits multi-view local features to boost model performance. Different from using global average pooling (GAP) to extract vectorized features from only the global view, we propose to sample and ensemble diverse multi-view local features to improve model robustness. To sample class-representative local features, we incorporate a simple auxiliary classifier head (comprising only one 1x1 convolutional layer) which efficiently and adaptively attends to class-discriminative local regions of feature maps via our proposed AdaCAM (Adaptive Class Activation Mapping). Extensive experiments demonstrate consistent and noticeable performance gains achieved by our multi-view feature augmentation module. Keywords: Computer Vision: Recognition: Detection, Categorization, Indexing, Matching, Retrieval, Semantic Interpretation Data Mining: Classification},
  archive   = {C_IJCAI},
  author    = {Xiang Gao and Yingjie Tian and Zhiquan Qi},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/94},
  pages     = {678-684},
  title     = {Multi-view feature augmentation with adaptive class activation mapping},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Feature space targeted attacks by statistic alignment.
<em>IJCAI</em>, 671–677. (<a
href="https://doi.org/10.24963/ijcai.2021/93">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {By adding human-imperceptible perturbations to images, DNNs can be easily fooled. As one of the mainstream methods, feature space targeted attacks perturb images by modulating their intermediate feature maps, for the discrepancy between the intermediate source and target features is minimized. However, the current choice of pixel-wise Euclidean Distance to measure the discrepancy is questionable because it unreasonably imposes a spatial-consistency constraint on the source and target features. Intuitively, an image can be categorized as &quot;cat&#39;&#39; no matter the cat is on the left or right of the image. To address this issue, we propose to measure this discrepancy using statistic alignment. Specifically, we design two novel approaches called Pair-wise Alignment Attack and Global-wise Alignment Attack, which attempt to measure similarities between feature maps by high-order statistics with translation invariance. Furthermore, we systematically analyze the layer-wise transferability with varied difficulties to obtain highly reliable attacks. Extensive experiments verify the effectiveness of our proposed method, and it outperforms the state-of-the-art algorithms by a large margin. Our code is publicly available at https://github.com/yaya-cheng/PAA-GAA. Keywords: Computer Vision: 2D and 3D Computer Vision Computer Vision: Recognition: Detection, Categorization, Indexing, Matching, Retrieval, Semantic Interpretation Machine Learning: Adversarial Machine Learning},
  archive   = {C_IJCAI},
  author    = {Lianli Gao and Yaya Cheng and Qilong Zhang and Xing Xu and Jingkuan Song},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/93},
  pages     = {671-677},
  title     = {Feature space targeted attacks by statistic alignment},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Chop chop BERT: Visual question answering by chopping
VisualBERT’s heads. <em>IJCAI</em>, 664–670. (<a
href="https://doi.org/10.24963/ijcai.2021/92">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Vision-and-Language (VL) pre-training has shown great potential on many related downstream tasks, such as Visual Question Answering (VQA), one of the most popular problems in the VL field. All of these pre-trained models (such as VisualBERT, ViLBERT, LXMERT and UNITER) are built with Transformer, which extends the classical attention mechanism to multiple layers and heads. To investigate why and how these models work on VQA so well, in this paper we explore the roles of individual heads and layers in Transformer models when handling 12 different types of questions. Specifically, we manually remove (chop) heads (or layers) from a pre-trained VisualBERT model at a time, and test it on different levels of questions to record its performance. As shown in the interesting echelon shape of the result matrices, experiments reveal different heads and layers are responsible for different question types, with higher-level layers activated by higher-level visual reasoning questions. Based on this observation, we design a dynamic chopping module that can automatically remove heads and layers of the VisualBERT at an instance level when dealing with different questions. Our dynamic chopping module can effectively reduce the parameters of the original model by 50\%, while only damaging the accuracy by less than 1\% on the VQA task. Keywords: Computer Vision: Language and Vision Computer Vision: Structural and Model-Based Approaches, Knowledge Representation and Reasoning},
  archive   = {C_IJCAI},
  author    = {Chenyu Gao and Qi Zhu and Peng Wang and Qi Wu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/92},
  pages     = {664-670},
  title     = {Chop chop BERT: Visual question answering by chopping VisualBERT’s heads},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). TCIC: Theme concepts learning cross language and vision for
image captioning. <em>IJCAI</em>, 657–663. (<a
href="https://doi.org/10.24963/ijcai.2021/91">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Existing research for image captioning usually represents an image using a scene graph with low-level facts (objects and relations) and fails to capture the high-level semantics. In this paper, we propose a Theme Concepts extended Image Captioning (TCIC) framework that incorporates theme concepts to represent high-level cross-modality semantics. In practice, we model theme concepts as memory vectors and propose Transformer with Theme Nodes (TTN) to incorporate those vectors for image captioning. Considering that theme concepts can be learned from both images and captions, we propose two settings for their representations learning based on TTN. On the vision side, TTN is configured to take both scene graph based features and theme concepts as input for visual representation learning. On the language side, TTN is configured to take both captions and theme concepts as input for text representation re-construction. Both settings aim to generate target captions with the same transformer-based decoder. During the training, we further align representations of theme concepts learned from images and corresponding captions to enforce the cross-modality learning. Experimental results on MS COCO show the effectiveness of our approach compared to some state-of-the-art models. Keywords: Computer Vision: Language and Vision Natural Language Processing: Natural Language Generation},
  archive   = {C_IJCAI},
  author    = {Zhihao Fan and Zhongyu Wei and Siyuan Wang and Ruize Wang and Zejun Li and Haijun Shan and Xuanjing Huang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/91},
  pages     = {657-663},
  title     = {TCIC: Theme concepts learning cross language and vision for image captioning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Direction-aware feature-level frequency decomposition for
single image deraining. <em>IJCAI</em>, 650–656. (<a
href="https://doi.org/10.24963/ijcai.2021/90">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present a novel direction-aware feature-level frequency decomposition network for single image deraining. Compared with existing solutions, the proposed network has three compelling characteristics. First, unlike previous algorithms, we propose to perform frequency decomposition at feature-level instead of image-level, allowing both low-frequency maps containing structures and high-frequency maps containing details to be continuously refined during the training procedure. Second, we further establish communication channels between low-frequency maps and high-frequency maps to interactively capture structures from high-frequency maps and add them back to low-frequency maps and, simultaneously, extract details from low-frequency maps and send them back to high-frequency maps, thereby removing rain streaks while preserving more delicate features in the input image. Third, different from existing algorithms using convolutional filters consistent in all directions, we propose a direction-aware filter to capture the direction of rain streaks in order to more effectively and thoroughly purge the input images of rain streaks. We extensively evaluate the proposed approach in three representative datasets and experimental results corroborate our approach consistently outperforms state-of-the-art deraining algorithms. Keywords: Computer Vision: 2D and 3D Computer Vision Computer Vision: Computational Photography, Photometry, Shape from X},
  archive   = {C_IJCAI},
  author    = {Sen Deng and Yidan Feng and Mingqiang Wei and Haoran Xie and Yiping Chen and Jonathan Li and Xiao-Ping Zhang and Jing Qin},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/90},
  pages     = {650-656},
  title     = {Direction-aware feature-level frequency decomposition for single image deraining},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Phonovisual biases in language: Is the lexicon tied to the
visual world? <em>IJCAI</em>, 643–649. (<a
href="https://doi.org/10.24963/ijcai.2021/89">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The present paper addresses the study of cross-linguistic and cross-modal iconicity within a deep learning framework. An LSTM-based Recurrent Neural Network is trained to associate the phonetic representation of a concrete word, encoded as a sequence of feature vectors, to the visual representation of its referent, expressed as an HCNN-transformed image. The processing network is then tested, without further training, in a language that does not appear in the training set and belongs to a different language family. The performance of the model is evaluated through a comparison with a randomized baseline; we show that such an imaginative network is capable of extracting language-independent generalizations in the mapping from linguistic sounds to visual features, providing empirical support for the hypothesis of a universal sound-symbolic substrate underlying all languages. Keywords: Computer Vision: Language and Vision Natural Language Processing: Phonology, Morphology, and Word Segmentation Natural Language Processing: Psycholinguistics},
  archive   = {C_IJCAI},
  author    = {Andrea Gregor de Varda and Carlo Strapparava},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/89},
  pages     = {643-649},
  title     = {Phonovisual biases in language: Is the lexicon tied to the visual world?},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hierarchical object-oriented spatio-temporal reasoning for
video question answering. <em>IJCAI</em>, 636–642. (<a
href="https://doi.org/10.24963/ijcai.2021/88">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Video Question Answering (Video QA) is a powerful testbed to develop new AI capabilities. This task necessitates learning to reason about objects, relations, and events across visual and linguistic domains in space-time. High-level reasoning demands lifting from associative visual pattern recognition to symbol like manipulation over objects, their behavior and interactions. Toward reaching this goal we propose an object-oriented reasoning approach in that video is abstracted as a dynamic stream of interacting objects. At each stage of the video event flow, these objects interact with each other, and their interactions are reasoned about with respect to the query and under the overall context of a video. This mechanism is materialized into a family of general-purpose neural units and their multi-level architecture called Hierarchical Object-oriented Spatio-Temporal Reasoning (HOSTR) networks. This neural model maintains the objects&#39; consistent lifelines in the form of a hierarchically nested spatio-temporal graph. Within this graph, the dynamic interactive object-oriented representations are built up along the video sequence, hierarchically abstracted in a bottom-up manner, and converge toward the key information for the correct answer. The method is evaluated on multiple major Video QA datasets and establishes new state-of-the-arts in these tasks. Analysis into the model&#39;s behavior indicates that object-oriented reasoning is a reliable, interpretable and efficient approach to Video QA. Keywords: Computer Vision: Language and Vision},
  archive   = {C_IJCAI},
  author    = {Long Hoang Dang and Thao Minh Le and Vuong Le and Truyen Tran},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/88},
  pages     = {636-642},
  title     = {Hierarchical object-oriented spatio-temporal reasoning for video question answering},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Boundary knowledge translation based reference semantic
segmentation. <em>IJCAI</em>, 629–635. (<a
href="https://doi.org/10.24963/ijcai.2021/87">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Given a reference object of an unknown type in an image, human observers can effortlessly find the objects of the same category in another image and precisely tell their visual boundaries. Such visual cognition capability of humans seems absent from the current research spectrum of computer vision. Existing segmentation networks, for example, rely on a humongous amount of labeled data, which is laborious and costly to collect and annotate; besides, the performance of segmentation networks tend to downgrade as the number of the category increases. In this paper, we introduce a novel Reference semantic segmentation Network (Ref-Net) to conduct visual boundary knowledge translation. Ref-Net contains a Reference Segmentation Module (RSM) and a Boundary Knowledge Translation Module (BKTM). Inspired by the human recognition mechanism, RSM is devised only to segment the same category objects based on the features of the reference objects. BKTM, on the other hand, introduces two boundary discriminator branches to conduct inner and outer boundary segmentation of the target object in an adversarial manner, and translate the annotated boundary knowledge of open-source datasets into the segmentation network. Exhaustive experiments demonstrate that, with tens of finely-grained annotated samples as guidance, Ref-Net achieves results on par with fully supervised methods on six datasets. Our code can be found in the supplementary material. Keywords: Computer Vision: 2D and 3D Computer Vision Machine Learning: Deep Learning Machine Learning: Transfer, Adaptation, Multi-task Learning},
  archive   = {C_IJCAI},
  author    = {Lechao Cheng and Zunlei Feng and Xinchao Wang and Ya Jie Liu and Jie Lei and Mingli Song},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/87},
  pages     = {629-635},
  title     = {Boundary knowledge translation based reference semantic segmentation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Leveraging human attention in novel object captioning.
<em>IJCAI</em>, 622–628. (<a
href="https://doi.org/10.24963/ijcai.2021/86">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Image captioning models depend on training with paired image-text corpora, which poses various challenges in describing images containing novel objects absent from the training data. While previous novel object captioning methods rely on external image taggers or object detectors to describe novel objects, we present the Attention-based Novel Object Captioner (ANOC) that complements novel object captioners with human attention features that characterize generally important information independent of tasks. It introduces a gating mechanism that adaptively incorporates human attention with self-learned machine attention, with a Constrained Self-Critical Sequence Training method to address the exposure bias while maintaining constraints of novel object descriptions. Extensive experiments conducted on the nocaps and Held-Out COCO datasets demonstrate that our method considerably outperforms the state-of-the-art novel object captioners. Our source code is available at https://github.com/chenxy99/ANOC. Keywords: Computer Vision: Language and Vision},
  archive   = {C_IJCAI},
  author    = {Xianyu Chen and Ming Jiang and Qi Zhao},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/86},
  pages     = {622-628},
  title     = {Leveraging human attention in novel object captioning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Zero-shot chinese character recognition with stroke-level
decomposition. <em>IJCAI</em>, 615–621. (<a
href="https://doi.org/10.24963/ijcai.2021/85">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Chinese character recognition has attracted much research interest due to its wide applications. Although it has been studied for many years, some issues in this field have not been completely resolved yet, \textit{e.g.} the zero-shot problem. Previous character-based and radical-based methods have not fundamentally addressed the zero-shot problem since some characters or radicals in test sets may not appear in training sets under a data-hungry condition. Inspired by the fact that humans can generalize to know how to write characters unseen before if they have learned stroke orders of some characters, we propose a stroke-based method by decomposing each character into a sequence of strokes, which are the most basic units of Chinese characters. However, we observe that there is a one-to-many relationship between stroke sequences and Chinese characters. To tackle this challenge, we employ a matching-based strategy to transform the predicted stroke sequence to a specific character. We evaluate the proposed method on handwritten characters, printed artistic characters, and scene characters. The experimental results validate that the proposed method outperforms existing methods on both character zero-shot and radical zero-shot tasks. Moreover, the proposed method can be easily generalized to other languages whose characters can be decomposed into strokes. Keywords: Computer Vision: Recognition: Detection, Categorization, Indexing, Matching, Retrieval, Semantic Interpretation},
  archive   = {C_IJCAI},
  author    = {Jingye Chen and Bin Li and Xiangyang Xue},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/85},
  pages     = {615-621},
  title     = {Zero-shot chinese character recognition with stroke-level decomposition},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Novelty detection via contrastive learning with negative
data augmentation. <em>IJCAI</em>, 606–614. (<a
href="https://doi.org/10.24963/ijcai.2021/84">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Novelty detection is the process of determining whether a query example differs from the learned training distribution. Previous generative adversarial networks based methods and self-supervised approaches suffer from instability training, mode dropping, and low discriminative ability. We overcome such problems by introducing a novel decoder-encoder framework. Firstly, a generative network (decoder) learns the representation by mapping the initialized latent vector to an image. In particular, this vector is initialized by considering the entire distribution of training data to avoid the problem of mode-dropping. Secondly, a contrastive network (encoder) aims to ``learn to compare&#39;&#39; through mutual information estimation, which directly helps the generative network to obtain a more discriminative representation by using a negative data augmentation strategy. Extensive experiments show that our model has significant superiority over cutting-edge novelty detectors and achieves new state-of-the-art results on various novelty detection benchmarks, e.g. CIFAR10 and DCASE. Moreover, our model is more stable for training in a non-adversarial manner, compared to other adversarial based novelty detection methods. Keywords: Computer Vision: 2D and 3D Computer Vision Data Mining: Anomaly/Outlier Detection},
  archive   = {C_IJCAI},
  author    = {Chengwei Chen and Yuan Xie and Shaohui Lin and Ruizhi Qiao and Jian Zhou and Xin Tan and Yi Zhang and Lizhuang Ma},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/84},
  pages     = {606-614},
  title     = {Novelty detection via contrastive learning with negative data augmentation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Themis: A fair evaluation platform for computer vision
competitions. <em>IJCAI</em>, 599–605. (<a
href="https://doi.org/10.24963/ijcai.2021/83">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {It has become increasingly thorny for computer vision competitions to preserve fairness when participants intentionally fine-tune their models against the test datasets to improve their performance. To mitigate such unfairness, competition organizers restrict the training and evaluation process of participants&#39; models. However, such restrictions introduce massive computation overheads for organizers and potential intellectual property leakage for participants. Thus, we propose Themis, a framework that trains a noise generator jointly with organizers and participants to prevent intentional fine-tuning by protecting test datasets from surreptitious manual labeling. Specifically, with the carefully designed noise generator, Themis adds noise to perturb test sets without twisting the performance ranking of participants&#39; models. We evaluate the validity of Themis with a wide spectrum of real-world models and datasets. Our experimental results show that Themis effectively enforces competition fairness by precluding manual labeling of test sets and preserving the performance ranking of participants&#39; models. Keywords: Computer Vision: Recognition: Detection, Categorization, Indexing, Matching, Retrieval, Semantic Interpretation AI Ethics, Trust, Fairness: Fairness Machine Learning Applications: Applications of Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Zinuo Cai and Jianyong Yuan and Yang Hua and Tao Song and Hao Wang and Zhengui Xue and Ningxin Hu and Jonathan Ding and Ruhui Ma and Mohammad Reza Haghighat and Haibing Guan},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/83},
  pages     = {599-605},
  title     = {Themis: A fair evaluation platform for computer vision competitions},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Explaining self-supervised image representations with visual
probing. <em>IJCAI</em>, 592–598. (<a
href="https://doi.org/10.24963/ijcai.2021/82">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently introduced self-supervised methods for image representation learning provide on par or superior results to their fully supervised competitors, yet the corresponding efforts to explain the self-supervised approaches lag behind. Motivated by this observation, we introduce a novel visual probing framework for explaining the self-supervised models by leveraging probing tasks employed previously in natural language processing. The probing tasks require knowledge about semantic relationships between image parts. Hence, we propose a systematic approach to obtain analogs of natural language in vision, such as visual words, context, and taxonomy. We show the effectiveness and applicability of those analogs in the context of explaining self-supervised representations. Our key findings emphasize that relations between language and vision can serve as an effective yet intuitive tool for discovering how machine learning models work, independently of data modality. Our work opens a plethora of research pathways towards more explainable and transparent AI. Keywords: Computer Vision: Language and Vision Machine Learning: Unsupervised Learning AI Ethics, Trust, Fairness: Explainability},
  archive   = {C_IJCAI},
  author    = {Dominika Basaj and Witold Oleszkiewicz and Igor Sieradzki and Michał Górszczak and Barbara Rychalska and Tomasz Trzcinski and Bartosz Zieliński},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/82},
  pages     = {592-598},
  title     = {Explaining self-supervised image representations with visual probing},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). GASP: Gated attention for saliency prediction.
<em>IJCAI</em>, 584–591. (<a
href="https://doi.org/10.24963/ijcai.2021/81">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Saliency prediction refers to the computational task of modeling overt attention. Social cues greatly influence our attention, consequently altering our eye movements and behavior. To emphasize the efficacy of such features, we present a neural model for integrating social cues and weighting their influences. Our model consists of two stages. During the first stage, we detect two social cues by following gaze, estimating gaze direction, and recognizing affect. These features are then transformed into spatiotemporal maps through image processing operations. The transformed representations are propagated to the second stage (GASP) where we explore various techniques of late fusion for integrating social cues and introduce two sub-networks for directing attention to relevant stimuli. Our experiments indicate that fusion approaches achieve better results for static integration methods, whereas non-fusion approaches for which the influence of each modality is unknown, result in better outcomes when coupled with recurrent models for dynamic saliency prediction. We show that gaze direction and affective representations contribute a prediction to ground-truth correspondence improvement of at least 5\% compared to dynamic saliency models without social cues. Furthermore, affective representations improve GASP, supporting the necessity of considering affect-biased attention in predicting saliency. Keywords: Computer Vision: 2D and 3D Computer Vision Computer Vision: Biometrics, Face and Gesture Recognition Machine Learning: Deep Learning},
  archive   = {C_IJCAI},
  author    = {Fares Abawi and Tom Weber and Stefan Wermter},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/81},
  pages     = {584-591},
  title     = {GASP: Gated attention for saliency prediction},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021c). Characteristic examples: High-robustness,
low-transferability fingerprinting of neural networks. <em>IJCAI</em>,
575–582. (<a href="https://doi.org/10.24963/ijcai.2021/80">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper proposes Characteristic Examples for effectively fingerprinting deep neural networks, featuring high-robustness to the base model against model pruning as well as low-transferability to unassociated models. This is the first work taking both robustness and transferability into consideration for generating realistic fingerprints, whereas current methods lack practical assumptions and may incur large false positive rates. To achieve better trade-off between robustness and transferability, we propose three kinds of characteristic examples: vanilla C-examples, RC-examples, and LTRC-example, to derive fingerprints from the original base model. To fairly characterize the trade-off between robustness and transferability, we propose Uniqueness Score, a comprehensive metric that measures the difference between robustness and transferability, which also serves as an indicator to the false alarm problem. Extensive experiments demonstrate that the proposed characteristic examples can achieve superior performance when compared with existing fingerprinting methods. In particular, for VGG ImageNet models, using LTRC-examples gives 4X higher uniqueness score than the baseline method and does not incur any false positives. Keywords: AI Ethics, Trust, Fairness: AI and Law, Governance, Regulation Multidisciplinary Topics and Applications: Security and Privacy Multidisciplinary Topics and Applications: Validation and Verification},
  archive   = {C_IJCAI},
  author    = {Siyue Wang and Xiao Wang and Pin-Yu Chen and Pu Zhao and Xue Lin},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/80},
  pages     = {575-582},
  title     = {Characteristic examples: High-robustness, low-transferability fingerprinting of neural networks},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An examination of fairness of AI models for deepfake
detection. <em>IJCAI</em>, 567–574. (<a
href="https://doi.org/10.24963/ijcai.2021/79">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent studies have demonstrated that deep learning models can discriminate based on protected classes like race and gender. In this work, we evaluate bias present in deepfake datasets and detection models across protected subgroups. Using facial datasets balanced by race and gender, we examine three popular deepfake detectors and find large disparities in predictive performances across races, with up to 10.7\% difference in error rate between subgroups. A closer look reveals that the widely used FaceForensics++ dataset is overwhelmingly composed of Caucasian subjects, with the majority being female Caucasians. Our investigation of the racial distribution of deepfakes reveals that the methods used to create deepfakes as positive training signals tend to produce ``irregular&quot; faces - when a person’s face is swapped onto another person of a different race or gender. This causes detectors to learn spurious correlations between the foreground faces and fakeness. Moreover, when detectors are trained with the Blended Image (BI) dataset from Face X-Rays, we find that those detectors develop systematic discrimination towards certain racial subgroups, primarily female Asians. Keywords: AI Ethics, Trust, Fairness: Fairness Machine Learning: Deep Learning Computer Vision: Biometrics, Face and Gesture Recognition},
  archive   = {C_IJCAI},
  author    = {Loc Trinh and Yan Liu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/79},
  pages     = {567-574},
  title     = {An examination of fairness of AI models for deepfake detection},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Decision making with differential privacy under a fairness
lens. <em>IJCAI</em>, 560–566. (<a
href="https://doi.org/10.24963/ijcai.2021/78">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Many agencies release datasets and statistics about groups of individuals that are used as input to a number of critical decision processes. To conform with privacy and confidentiality requirements, these agencies are often required to release privacy-preserving versions of the data. This paper studies the release of differentially private datasets and analyzes their impact on some critical resource allocation tasks under a fairness perspective. The paper shows that, when the decisions take as input differentially private data, the noise added to achieve privacy disproportionately impacts some groups over others. The paper analyzes the reasons for these disproportionate impacts and proposes guidelines to mitigate these effects. The proposed approaches are evaluated on critical decision problems that use differentially private census data. Keywords: AI Ethics, Trust, Fairness: Fairness Multidisciplinary Topics and Applications: Security and Privacy Data Mining: Privacy Preserving Data Mining Machine Learning: Classification},
  archive   = {C_IJCAI},
  author    = {Cuong Tran and Ferdinando Fioretto and Pascal Van Hentenryck and Zhiyan Yao},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/78},
  pages     = {560-566},
  title     = {Decision making with differential privacy under a fairness lens},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bias silhouette analysis: Towards assessing the quality of
bias metrics for word embedding models. <em>IJCAI</em>, 552–559. (<a
href="https://doi.org/10.24963/ijcai.2021/77">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Word embedding models reflect bias towards genders, ethnicities, and other social groups present in the underlying training data. Metrics such as ECT, RNSB, and WEAT quantify bias in these models based on predefined word lists representing social groups and bias-conveying concepts. How suitable these lists actually are to reveal bias - let alone the bias metrics in general - remains unclear, though. In this paper, we study how to assess the quality of bias metrics for word embedding models. In particular, we present a generic method, Bias Silhouette Analysis (BSA), that quantifies the accuracy and robustness of such a metric and of the word lists used. Given a biased and an unbiased reference embedding model, BSA applies the metric systematically for several subsets of the lists to the models. The variance and rate of convergence of the bias values of each model then entail the robustness of the word lists, whereas the distance between the models&#39; values gives indications of the general accuracy of the metric with the word lists. We demonstrate the behavior of BSA on two standard embedding models for the three mentioned metrics with several word lists from existing research. Keywords: AI Ethics, Trust, Fairness: Fairness AI Ethics, Trust, Fairness: Societal Impact of AI Natural Language Processing: Natural Language Processing},
  archive   = {C_IJCAI},
  author    = {Maximilian Spliethöver and Henning Wachsmuth},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/77},
  pages     = {552-559},
  title     = {Bias silhouette analysis: Towards assessing the quality of bias metrics for word embedding models},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-objective reinforcement learning for designing ethical
environments. <em>IJCAI</em>, 545–551. (<a
href="https://doi.org/10.24963/ijcai.2021/76">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {AI research is being challenged with ensuring that autonomous agents learn to behave ethically, namely in alignment with moral values. A common approach, founded on the exploitation of Reinforcement Learning techniques, is to design environments that incentivise agents to behave ethically. However, to the best of our knowledge, current approaches do not theoretically guarantee that an agent will learn to behave ethically. Here, we make headway along this direction by proposing a novel way of designing environments wherein it is formally guaranteed that an agent learns to behave ethically while pursuing its individual objectives. Our theoretical results develop within the formal framework of Multi-Objective Reinforcement Learning to ease the handling of an agent&#39;s individual and ethical objectives. As a further contribution, we leverage on our theoretical results to introduce an algorithm that automates the design of ethical environments. Keywords: AI Ethics, Trust, Fairness: Moral Decision Making Machine Learning: Reinforcement Learning},
  archive   = {C_IJCAI},
  author    = {Manel Rodriguez-Soto and Maite Lopez-Sanchez and Juan A. Rodriguez Aguilar},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/76},
  pages     = {545-551},
  title     = {Multi-objective reinforcement learning for designing ethical environments},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Addressing the long-term impact of ML decisions via policy
regret. <em>IJCAI</em>, 537–544. (<a
href="https://doi.org/10.24963/ijcai.2021/75">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Machine Learning (ML) increasingly informs the allocation of opportunities to individuals and communities in areas such as lending, education, employment, and beyond. Such decisions often impact their subjects&#39; future characteristics and capabilities in an a priori unknown fashion. The decision-maker, therefore, faces exploration-exploitation dilemmas akin to those in multi-armed bandits. Following prior work, we model communities as arms. To capture the long-term effects of ML-based allocation decisions, we study a setting in which the reward from each arm evolves every time the decision-maker pulls that arm. We focus on reward functions that are initially increasing in the number of pulls but may become (and remain) decreasing after a certain point. We argue that an acceptable sequential allocation of opportunities must take an arm&#39;s potential for growth into account. We capture these considerations through the notion of policy regret, a much stronger notion than the often-studied external regret, and present an algorithm with provably sub-linear policy regret for sufficiently long time horizons. We empirically compare our algorithm with several baselines and find that it consistently outperforms them, in particular for long time horizons. Keywords: AI Ethics, Trust, Fairness: Societal Impact of AI Uncertainty in AI: Sequential Decision Making Machine Learning: Online Learning AI Ethics, Trust, Fairness: Fairness},
  archive   = {C_IJCAI},
  author    = {David Lindner and Hoda Heidari and Andreas Krause},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/75},
  pages     = {537-544},
  title     = {Addressing the long-term impact of ML decisions via policy regret},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Location predicts you: Location prediction via bi-direction
speculation and dual-level association. <em>IJCAI</em>, 529–536. (<a
href="https://doi.org/10.24963/ijcai.2021/74">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Location prediction is of great importance in location-based applications for the construction of the smart city. To our knowledge, existing models for location prediction focus on the users&#39; preference on POIs from the perspective of the human side. However, modeling users&#39; interests from the historical trajectory is still limited by the data sparsity. Additionally, most of existing methods predict the next location according to the individual data independently. But the data sparsity makes it difficult to mine explicit mobility patterns or capture the casual behavior for each user. To address the issues above, we propose a novel Bi-direction Speculation and Dual-level Association method (BSDA), which considers both users&#39; interests in POIs and POIs&#39; appeal to users. Furthermore, we develop the cross-user and cross-POI association to alleviate the data sparsity by similar users and POIs to enrich the candidates. Experimental results on two public datasets demonstrate that BSDA achieves significant improvements over state-of-the-art methods. Keywords: AI Ethics, Trust, Fairness: Surveillance, Manipulation of People Multidisciplinary Topics and Applications: Social Sciences Data Mining: Mining Spatial, Temporal Data Data Mining: Recommender Systems},
  archive   = {C_IJCAI},
  author    = {Xixi Li and Ruimin Hu and Zheng Wang and Toshihiko Yamasaki},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/74},
  pages     = {529-536},
  title     = {Location predicts you: Location prediction via bi-direction speculation and dual-level association},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On smoother attributions using neural stochastic
differential equations. <em>IJCAI</em>, 522–528. (<a
href="https://doi.org/10.24963/ijcai.2021/73">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Several methods have recently been developed for computing attributions of a neural network&#39;s prediction over the input features. However, these existing approaches for computing attributions are noisy and not robust to small perturbations of the input. This paper uses the recently identified connection between dynamical systems and residual neural networks to show that the attributions computed over neural stochastic differential equations (SDEs) are less noisy, visually sharper, and quantitatively more robust. Using dynamical systems theory, we theoretically analyze the robustness of these attributions. We also experimentally demonstrate the efficacy of our approach in providing smoother, visually sharper and quantitatively robust attributions by computing attributions for ImageNet images using ResNet-50, WideResNet-101 models and ResNeXt-101 models. Keywords: AI Ethics, Trust, Fairness: Explainability Multidisciplinary Topics and Applications: Validation and Verification},
  archive   = {C_IJCAI},
  author    = {Sumit Jha and Rickard Ewetz and Alvaro Velasquez and Susmit Jha},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/73},
  pages     = {522-528},
  title     = {On smoother attributions using neural stochastic differential equations},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Interacting with explanations through critiquing.
<em>IJCAI</em>, 515–521. (<a
href="https://doi.org/10.24963/ijcai.2021/72">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Using personalized explanations to support recommendations has been shown to increase trust and perceived quality. However, to actually obtain better recommendations, there needs to be a means for users to modify the recommendation criteria by interacting with the explanation. We present a novel technique using aspect markers that learns to generate personalized explanations of recommendations from review texts, and we show that human users significantly prefer these explanations over those produced by state-of-the-art techniques. Our work&#39;s most important innovation is that it allows users to react to a recommendation by critiquing the textual explanation: removing (symmetrically adding) certain aspects they dislike or that are no longer relevant (symmetrically that are of interest). The system updates its user model and the resulting recommendations according to the critique. This is based on a novel unsupervised critiquing method for single- and multi-step critiquing with textual explanations. Empirical results show that our system achieves good performance in adapting to the preferences expressed in multi-step critiquing and generates consistent explanations. Keywords: AI Ethics, Trust, Fairness: Explainability Data Mining: Recommender Systems Humans and AI: Personalization and User Modeling},
  archive   = {C_IJCAI},
  author    = {Diego Antognini and Claudiu Musat and Boi Faltings},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/72},
  pages     = {515-521},
  title     = {Interacting with explanations through critiquing},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Data-efficient reinforcement learning for malaria control.
<em>IJCAI</em>, 507–513. (<a
href="https://doi.org/10.24963/ijcai.2021/71">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Sequential decision-making under cost-sensitive tasks is prohibitively daunting, especially for the problem that has a significant impact on people&#39;s daily lives, such as malaria control, treatment recommendation. The main challenge faced by policymakers is to learn a policy from scratch by interacting with a complex environment in a few trials. This work introduces a practical, data-efficient policy learning method, named Variance-Bonus Monte Carlo Tree Search~(VB-MCTS), which can copy with very little data and facilitate learning from scratch in only a few trials. Specifically, the solution is a model-based reinforcement learning method. To avoid model bias, we apply Gaussian Process~(GP) regression to estimate the transitions explicitly. With the GP world model, we propose a variance-bonus reward to measure the uncertainty about the world. Adding the reward to the planning with MCTS can result in more efficient and effective exploration. Furthermore, the derived polynomial sample complexity indicates that VB-MCTS is sample efficient. Finally, outstanding performance on a competitive world-level RL competition and extensive experimental results verify its advantage over the state-of-the-art on the challenging malaria control task. Keywords: Agent-based and Multi-agent Systems: Human-Agent Interaction Machine Learning Applications: Environmental},
  archive   = {C_IJCAI},
  author    = {Lixin Zou},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/71},
  pages     = {507-513},
  title     = {Data-efficient reinforcement learning for malaria control},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MFVFD: A multi-agent q-learning approach to cooperative and
non-cooperative tasks. <em>IJCAI</em>, 500–506. (<a
href="https://doi.org/10.24963/ijcai.2021/70">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Value function decomposition (VFD) methods under the popular paradigm of centralized training and decentralized execution (CTDE) have promoted multi-agent reinforcement learning progress. However, existing VFD methods proceed from a group&#39;s value function decomposition to only solve cooperative tasks. With the individual value function decomposition, we propose MFVFD, a novel multi-agent Q-learning approach for solving cooperative and non-cooperative tasks based on mean-field theory. Our analysis on the Hawk-Dove and Nonmonotonic Cooperation matrix games evaluate MFVFD&#39;s convergent solution. Empirical studies on the challenging mixed cooperative-competitive tasks where hundreds of agents coexist demonstrate that MFVFD significantly outperforms existing baselines. Keywords: Agent-based and Multi-agent Systems: Multi-agent Learning Agent-based and Multi-agent Systems: Noncooperative Games},
  archive   = {C_IJCAI},
  author    = {Tianhao Zhang and Qiwei Ye and Jiang Bian and Guangming Xie and Tie-Yan Liu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/70},
  pages     = {500-506},
  title     = {MFVFD: A multi-agent Q-learning approach to cooperative and non-cooperative tasks},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Altruism design in networked public goods games.
<em>IJCAI</em>, 493–499. (<a
href="https://doi.org/10.24963/ijcai.2021/69">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Many collective decision-making settings feature a strategic tension between agents acting out of individual self-interest and promoting a common good. These include wearing face masks during a pandemic, voting, and vaccination. Networked public goods games capture this tension, with networks encoding strategic interdependence among agents. Conventional models of public goods games posit solely individual self-interest as a motivation, even though altruistic motivations have long been known to play a significant role in agents&#39; decisions. We introduce a novel extension of public goods games to account for altruistic motivations by adding a term in the utility function that incorporates the perceived benefits an agent obtains from the welfare of others, mediated by an altruism graph. Most importantly, we view altruism not as immutable, but rather as a lever for promoting the common good. Our central algorithmic question then revolves around the computational complexity of modifying the altruism network to achieve desired public goods game investment profiles. We first show that the problem can be solved using linear programming when a principal can fractionally modify the altruism network. While the problem becomes in general intractable if the principal&#39;s actions are all-or-nothing, we exhibit several tractable special cases. Keywords: Agent-based and Multi-agent Systems: Algorithmic Game Theory Agent-based and Multi-agent Systems: Noncooperative Games},
  archive   = {C_IJCAI},
  author    = {Sixie Yu and David Kempe and Yevgeniy Vorobeychik},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/69},
  pages     = {493-499},
  title     = {Altruism design in networked public goods games},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dominant resource fairness with meta-types. <em>IJCAI</em>,
486–492. (<a href="https://doi.org/10.24963/ijcai.2021/68">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Inspired by the recent COVID-19 pandemic, we study a generalization of the multi-resource allocation problem with heterogeneous demands and Leontief utilities. Unlike existing settings, we allow each agent to specify requirements to only accept allocations from a subset of the total supply for each resource. These requirements can take form in location constraints (e.g. A hospital can only accept volunteers who live nearby due to commute limitations). This can also model a type of substitution effect where some agents need 1 unit of resource A \emph{or} B, both belonging to the same meta-type. But some agents specifically want A, and others specifically want B. We propose a new mechanism called Dominant Resource Fairness with Meta Types which determines the allocations by solving a small number of linear programs. The proposed method satisfies Pareto optimality, envy-freeness, strategy-proofness, and a notion of sharing incentive for our setting. To the best of our knowledge, we are the first to study this problem formulation, which improved upon existing work by capturing more constraints that often arise in real life situations. Finally, we show numerically that our method scales better to large problems than alternative approaches. Keywords: Agent-based and Multi-agent Systems: Economic Paradigms, Auctions and Market-Based Systems Agent-based and Multi-agent Systems: Resource Allocation},
  archive   = {C_IJCAI},
  author    = {Steven Yin and Shatian Wang and Lingyi Zhang and Christian Kroer},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/68},
  pages     = {486-492},
  title     = {Dominant resource fairness with meta-types},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). H-FL: A hierarchical communication-efficient and
privacy-protected architecture for federated learning. <em>IJCAI</em>,
479–485. (<a href="https://doi.org/10.24963/ijcai.2021/67">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The longstanding goals of federated learning (FL) require rigorous privacy guarantees and low communication overhead while holding a relatively high model accuracy. However, simultaneously achieving all the goals is extremely challenging. In this paper, we propose a novel framework called hierarchical federated learning (H-FL) to tackle this challenge. Considering the degradation of the model performance due to the statistic heterogeneity of the training data, we devise a runtime distribution reconstruction strategy, which reallocates the clients appropriately and utilizes mediators to rearrange the local training of the clients. In addition, we design a compression-correction mechanism incorporated into H-FL to reduce the communication overhead while not sacrificing the model performance. To further provide privacy guarantees, we introduce differential privacy while performing local training, which injects moderate amount of noise into only part of the complete model. Experimental results show that our H-FL framework achieves the state-of-art performance on different datasets for the real-world image recognition tasks. Keywords: Agent-based and Multi-agent Systems: Coordination and Cooperation Multidisciplinary Topics and Applications: Security and Privacy},
  archive   = {C_IJCAI},
  author    = {He Yang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/67},
  pages     = {479-485},
  title     = {H-FL: A hierarchical communication-efficient and privacy-protected architecture for federated learning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning with generated teammates to achieve type-free
ad-hoc teamwork. <em>IJCAI</em>, 472–478. (<a
href="https://doi.org/10.24963/ijcai.2021/66">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In ad-hoc teamwork, an agent is required to cooperate with unknown teammates without prior coordination. To swiftly adapt to an unknown teammate, most works adopt a type-based approach, which pre-trains the agent with a set of pre-prepared teammate types, then associates the unknown teammate with a particular type. Typically, these types are collected manually. This hampers previous works by both the availability and diversity of types they manage to obtain. To eliminate these limitations, this work addresses to achieve ad-hoc teamwork in a type-free approach. Specifically, we propose the model of Entropy-regularized Deep Recurrent Q-Network (EDRQN) to generate teammates automatically, meanwhile utilize them to pre-train our agent. These teammates are obtained from scratch and are designed to perform the task with various behaviors, therefore their availability and diversity are both ensured. We evaluate our model on several benchmark domains of ad-hoc teamwork. The result shows that even if our model has no access to any pre-prepared teammate types, it still achieves significant performance. Keywords: Agent-based and Multi-agent Systems: Cooperative Games Agent-based and Multi-agent Systems: Coordination and Cooperation Uncertainty in AI: Sequential Decision Making},
  archive   = {C_IJCAI},
  author    = {Dong Xing and Qianhui Liu and Qian Zheng and Gang Pan},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/66},
  pages     = {472-478},
  title     = {Learning with generated teammates to achieve type-free ad-hoc teamwork},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Budget-feasible maximum nash social welfare is almost
envy-free. <em>IJCAI</em>, 465–471. (<a
href="https://doi.org/10.24963/ijcai.2021/65">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Nash social welfare (NSW) is a well-known social welfare measurement that balances individual utilities and the overall efficiency. In the context of fair allocation of indivisible goods, it has been shown by Caragiannis et al. (EC 2016 and TEAC 2019) that an allocation maximizing the NSW is envy-free up to one good (EF1). In this paper, we are interested in the fairness of the NSW in a budget-feasible allocation problem, in which each item has a cost that will be incurred to the agent it is allocated to, and each agent has a budget constraint on the total cost of items she receives. We show that a budget-feasible allocation that maximizes the NSW achieves a 1/4-approximation of EF1 and the approximation ratio is tight. The approximation ratio improves gracefully when the items have small costs compared with the agents&#39; budgets; it converges to 1/2 when the budget-cost ratio approaches infinity. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice Agent-based and Multi-agent Systems: Economic Paradigms, Auctions and Market-Based Systems AI Ethics, Trust, Fairness: Fairness},
  archive   = {C_IJCAI},
  author    = {Xiaowei Wu and Bo Li and Jiarui Gan},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/65},
  pages     = {465-471},
  title     = {Budget-feasible maximum nash social welfare is almost envy-free},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). State-aware value function approximation with attention
mechanism for restless multi-armed bandits. <em>IJCAI</em>, 458–464. (<a
href="https://doi.org/10.24963/ijcai.2021/64">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The restless multi-armed bandit (RMAB) problem is a generalization of the multi-armed bandit with non-stationary rewards. Its optimal solution is intractable due to exponentially large state and action spaces with respect to the number of arms. Existing approximation approaches, e.g., Whittle&#39;s index policy, have difficulty in capturing either temporal or spatial factors such as impacts from other arms. We propose considering both factors using the attention mechanism, which has achieved great success in deep learning. Our state-aware value function approximation solution comprises an attention-based value function approximator and a Bellman equation solver. The attention-based coordination module capture both spatial and temporal factors for arm coordination. The Bellman equation solver utilizes the decoupling structure of RMABs to acquire solutions with significantly reduced computation overheads. In particular, the time complexity of our approximation is linear in the number of arms. Finally, we illustrate the effectiveness and investigate the properties of our proposed method with numerical experiments. Keywords: Agent-based and Multi-agent Systems: Multi-agent Planning Agent-based and Multi-agent Systems: Resource Allocation Planning and Scheduling: Planning and Scheduling Planning and Scheduling: Markov Decisions Processes},
  archive   = {C_IJCAI},
  author    = {Shuang Wu and Jingyu Zhao and Guangjian Tian and Jun Wang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/64},
  pages     = {458-464},
  title     = {State-aware value function approximation with attention mechanism for restless multi-armed bandits},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Manipulation of k-coalitional games on social networks.
<em>IJCAI</em>, 450–457. (<a
href="https://doi.org/10.24963/ijcai.2021/63">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In many coalition formation games the utility of the agents depends on a social network. In such scenarios there might be a manipulative agent that would like to manipulate his connections in the social network in order to increase his utility. We study a model of coalition formation in which a central organizer, who needs to form k coalitions, obtains information about the social network from the agents. The central organizer has her own objective: she might want to maximize the utilitarian social welfare, maximize the egalitarian social welfare, or only guarantee that every agent will have at least one connection within her coalition. In this paper we study the susceptibility for manipulation of these objectives, given the abilities and information that the manipulator has. Specifically, we show that if the manipulator has very limited information, namely he is only familiar with his immediate neighbours in the network, then a manipulation is almost always impossible. Moreover, if the manipulator is only able to add connections to the social network, then a manipulation is still impossible for some objectives, even if the manipulator has full information on the structure of the network. On the other hand, if the manipulator is able to hide some of his connections, then all objectives are susceptible to manipulation, even if the manipulator has limited information, i.e., when he is familiar with his immediate neighbours and with their neighbours. Keywords: Agent-based and Multi-agent Systems: Cooperative Games},
  archive   = {C_IJCAI},
  author    = {Naftali Waxman and Sarit Kraus and Noam Hazon},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/63},
  pages     = {450-457},
  title     = {Manipulation of k-coalitional games on social networks},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An axiom system for feedback centralities. <em>IJCAI</em>,
443–449. (<a href="https://doi.org/10.24963/ijcai.2021/62">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In recent years, the axiomatic approach to centrality measures has attracted attention in the literature. However, most papers propose a collection of axioms dedicated to one or two considered centrality measures. In result, it is hard to capture the differences and similarities between various measures. In this paper, we propose an axiom system for four classic feedback centralities: Eigenvector centrality, Katz centrality, Katz prestige and PageRank. We prove that each of these four centrality measures can be uniquely characterized with a subset of our axioms. Our system is the first one in the literature that considers all four feedback centralities. Keywords: Agent-based and Multi-agent Systems: Economic Paradigms, Auctions and Market-Based Systems Machine Learning Applications: Networks},
  archive   = {C_IJCAI},
  author    = {Tomasz Wąs and Oskar Skibski},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/62},
  pages     = {443-449},
  title     = {An axiom system for feedback centralities},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Emergent prosociality in multi-agent games through gifting.
<em>IJCAI</em>, 434–442. (<a
href="https://doi.org/10.24963/ijcai.2021/61">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Coordination is often critical to forming prosocial behaviors -- behaviors that increase the overall sum of rewards received by all agents in a multi-agent game. However, state of the art reinforcement learning algorithms often suffer from converging to socially less desirable equilibria when multiple equilibria exist. Previous works address this challenge with explicit reward shaping, which requires the strong assumption that agents can be forced to be prosocial. We propose using a less restrictive peer-rewarding mechanism, gifting, that guides the agents toward more socially desirable equilibria while allowing agents to remain selfish and decentralized. Gifting allows each agent to give some of their reward to other agents. We employ a theoretical framework that captures the benefit of gifting in converging to the prosocial equilibrium by characterizing the equilibria&#39;s basins of attraction in a dynamical system. With gifting, we demonstrate increased convergence of high risk, general-sum coordination games to the prosocial equilibrium both via numerical analysis and experiments. Keywords: Agent-based and Multi-agent Systems: Coordination and Cooperation Agent-based and Multi-agent Systems: Multi-agent Learning Agent-based and Multi-agent Systems: Noncooperative Games},
  archive   = {C_IJCAI},
  author    = {Woodrow Z. Wang and Mark Beliaev and Erdem Bıyık and Daniel A. Lazar and Ramtin Pedarsani and Dorsa Sadigh},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/61},
  pages     = {434-442},
  title     = {Emergent prosociality in multi-agent games through gifting},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reducing bus bunching with asynchronous multi-agent
reinforcement learning. <em>IJCAI</em>, 426–433. (<a
href="https://doi.org/10.24963/ijcai.2021/60">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The bus system is a critical component of sustainable urban transportation. However, due to the significant uncertainties in passenger demand and traffic conditions, bus operation is unstable in nature and bus bunching has become a common phenomenon that undermines the reliability and efficiency of bus services. Despite recent advances in multi-agent reinforcement learning (MARL) on traffic control, little research has focused on bus fleet control due to the tricky asynchronous characteristic---control actions only happen when a bus arrives at a bus stop and thus agents do not act simultaneously. In this study, we formulate route-level bus fleet control as an asynchronous multi-agent reinforcement learning (ASMR) problem and extend the classical actor-critic architecture to handle the asynchronous issue. Specifically, we design a novel critic network to effectively approximate the marginal contribution for other agents, in which graph attention neural network is used to conduct inductive learning for policy evaluation. The critic structure also helps the ego agent optimize its policy more efficiently. We evaluate the proposed framework on real-world bus services and actual passenger demand derived from smart card data. Our results show that the proposed model outperforms both traditional headway-based control methods and existing MARL methods. Keywords: Agent-based and Multi-agent Systems: Multi-agent Learning Multidisciplinary Topics and Applications: Transportation Machine Learning Applications: Applications of Reinforcement Learning},
  archive   = {C_IJCAI},
  author    = {Jiawei Wang and Lijun Sun},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/60},
  pages     = {426-433},
  title     = {Reducing bus bunching with asynchronous multi-agent reinforcement learning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fair pairwise exchange among groups. <em>IJCAI</em>,
419–425. (<a href="https://doi.org/10.24963/ijcai.2021/59">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the pairwise organ exchange problem among groups motivated by real-world applications and consider two types of group formulations. Each group represents either a certain type of patient-donor pairs who are compatible with the same set of organs, or a set of patient-donor pairs who reside in the same region. We address a natural research question, which asks how to match a maximum number of pairwise compatible patient-donor pairs in a fair and individually rational way. We first propose a natural fairness concept that is applicable to both types of group formulations and design a polynomial-time algorithm that checks whether a matching exists that satisfies optimality, individual rationality, and fairness. We also present several running time upper bounds for computing such matchings for different graph structures. Keywords: Agent-based and Multi-agent Systems: Economic Paradigms, Auctions and Market-Based Systems},
  archive   = {C_IJCAI},
  author    = {Zhaohong Sun and Taiki Todo and Toby Walsh},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/59},
  pages     = {419-425},
  title     = {Fair pairwise exchange among groups},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). New algorithms for japanese residency matching.
<em>IJCAI</em>, 412–418. (<a
href="https://doi.org/10.24963/ijcai.2021/58">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the Japanese Residency Matching Program (JRMP) in which hospitals are partitioned into disjoint regions and both hospitals and regions are subject to quotas. To achieve a balanced distribution of doctors across regions, hard bounds are imposed by the government to limit the number of doctors who can be placed in each region. However, such hard bounds lead to inefficiency in terms of wasted vacant positions. In this paper, we propose two suitable algorithms to reduce waste with minimal modification to the current system and show that they are superior to the algorithm currently deployed in JRMP by comparing them theoretically and empirically. Keywords: Agent-based and Multi-agent Systems: Economic Paradigms, Auctions and Market-Based Systems},
  archive   = {C_IJCAI},
  author    = {Zhaohong Sun and Taiki Todo and Makoto Yokoo},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/58},
  pages     = {412-418},
  title     = {New algorithms for japanese residency matching},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Game-theoretic analysis of effort allocation of contributors
to public projects. <em>IJCAI</em>, 405–411. (<a
href="https://doi.org/10.24963/ijcai.2021/57">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Public projects can succeed or fail for many reasons such as the feasibility of the original goal and coordination among contributors. One major reason for failure is that insufficient work leaves the project partially completed. For certain types of projects anything short of full completion is a failure (e.g., feature request on software projects in GitHub). Therefore, project success relies heavily on individuals allocating sufficient effort. When there are multiple public projects, each contributor needs to make decisions to best allocate his/her limited effort (e.g., time) to projects while considering the effort allocation decisions of other strategic contributors and his/her parameterized utilities based on values and costs for the projects. In this paper, we introduce a game-theoretic effort allocation model of contributors to public projects for modeling effort allocation of strategic contributors. We study the related Nash equilibrium (NE) computational problems and provide NP-hardness results for the existence of NE and polynomial-time algorithms for finding NE in restricted settings. Finally, we investigate the inefficiency of NE measured by the price of anarchy and price of stability. Keywords: Agent-based and Multi-agent Systems: Noncooperative Games Agent-based and Multi-agent Systems: Resource Allocation Agent-based and Multi-agent Systems: Algorithmic Game Theory},
  archive   = {C_IJCAI},
  author    = {Jared Soundy and Chenhao Wang and Clay Stevens and Hau Chan},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/57},
  pages     = {405-411},
  title     = {Game-theoretic analysis of effort allocation of contributors to public projects},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Vitality indices are equivalent to induced game-theoretic
centralities. <em>IJCAI</em>, 398–404. (<a
href="https://doi.org/10.24963/ijcai.2021/56">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Vitality indices form a class of centrality measures that assess the importance of a node based on the impact its removal has on the network. To date, theoretical analysis of this class is lacking. In this paper, we show that vitality indices can be characterized using the axiom of Balanced Contributions proposed by Myerson in the coalitional game theory literature. We explore the link between both fields and show an equivalence between vitality indices and induced game theoretic centralities based on the Shapley value. Our characterization allows us to easily determine which known centrality measures are vitality indices. Keywords: Agent-based and Multi-agent Systems: Cooperative Games Agent-based and Multi-agent Systems: Economic Paradigms, Auctions and Market-Based Systems Machine Learning Applications: Networks},
  archive   = {C_IJCAI},
  author    = {Oskar Skibski},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/56},
  pages     = {398-404},
  title     = {Vitality indices are equivalent to induced game-theoretic centralities},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Tango: Declarative semantics for multiagent communication
protocols. <em>IJCAI</em>, 391–397. (<a
href="https://doi.org/10.24963/ijcai.2021/55">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A flexible communication protocol is necessary to build a decentralized multiagent system whose member agents are not coupled to each other&#39;s decision making. Information-based protocol languages capture a protocol in terms of causality and integrity constraints based on the information exchanged by the agents. Thus, they enable highly flexible enactments in which the agents proceed asynchronously and messages may be arbitrarily reordered. However, the existing semantics for such languages can produce a large number of protocol enactments, which makes verification of a protocol property intractable. This paper formulates a protocol semantics declaratively via inference rules that determine when a message emission or reception becomes enabled during an enactment, and its effect on the local state of an agent. The semantics enables heuristics for determining when alternative extensions of a current enactment would be equivalent, thereby helping produce parsimonious models and yielding improved protocol verification methods. Keywords: Agent-based and Multi-agent Systems: Agent Communication Agent-based and Multi-agent Systems: Engineering Methods, Platforms, Languages and Tools},
  archive   = {C_IJCAI},
  author    = {Munindar P. Singh and Samuel H. Christie V.},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/55},
  pages     = {391-397},
  title     = {Tango: Declarative semantics for multiagent communication protocols},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Stochastic market games. <em>IJCAI</em>, 384–390. (<a
href="https://doi.org/10.24963/ijcai.2021/54">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Some of the most relevant future applications of multi-agent systems like autonomous driving or factories as a service display mixed-motive scenarios, where agents might have conflicting goals. In these settings agents are likely to learn undesirable outcomes in terms of cooperation under independent learning, such as overly greedy behavior. Motivated from real world societies, in this work we propose to utilize market forces to provide incentives for agents to become cooperative. As demonstrated in an iterated version of the Prisoner&#39;s Dilemma, the proposed market formulation can change the dynamics of the game to consistently learn cooperative policies. Further we evaluate our approach in spatially and temporally extended settings for varying numbers of agents. We empirically find that the presence of markets can improve both the overall result and agent individual returns via their trading activities. Keywords: Agent-based and Multi-agent Systems: Agent-Based Simulation and Emergence Agent-based and Multi-agent Systems: Coordination and Cooperation Agent-based and Multi-agent Systems: Agent Societies},
  archive   = {C_IJCAI},
  author    = {Kyrill Schmid and Lenz Belzner and Robert Müller and Johannes Tochtermann and Claudia Linnhoff-Popien},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/54},
  pages     = {384-390},
  title     = {Stochastic market games},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Matchings with group fairness constraints: Online and
offline algorithms. <em>IJCAI</em>, 377–383. (<a
href="https://doi.org/10.24963/ijcai.2021/53">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider the problem of assigning items to platforms in the presence of group fairness constraints. In the input, each item belongs to certain categories, called classes in this paper. Each platform specifies the group fairness constraints through an upper bound on the number of items it can serve from each class. Additionally, each platform also has an upper bound on the total number of items it can serve. The goal is to assign items to platforms so as to maximize the number of items assigned while satisfying the upper bounds of each class. This problem models several important real-world problems like ad-auctions, scheduling, resource allocations, school choice etc. We show that if the classes are arbitrary, then the problem is NP-hard and has a strong inapproximability. We consider the problem in both online and offline settings under natural restrictions on the classes. Under these restrictions, the problem continues to remain NP-hard but admits approximation algorithms with small approximation factors. We also implement some of the algorithms. Our experiments show that the algorithms work well in practice both in terms of efficiency and the number of items that get assigned to some platform. Keywords: Agent-based and Multi-agent Systems: Resource Allocation AI Ethics, Trust, Fairness: Fairness Heuristic Search and Game Playing: Combinatorial Search and Optimisation},
  archive   = {C_IJCAI},
  author    = {Govind S. Sankar and Anand Louis and Meghana Nasre and Prajakta Nimbhorkar},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/53},
  pages     = {377-383},
  title     = {Matchings with group fairness constraints: Online and offline algorithms},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Shortlisting rules and incentives in an end-to-end model for
participatory budgeting. <em>IJCAI</em>, 370–376. (<a
href="https://doi.org/10.24963/ijcai.2021/52">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We introduce an end-to-end model for participatory budgeting grounded in social choice theory. Our model accounts for the interplay between the two stages commonly encountered in real-life partici- patory budgeting. In the first stage participants pro- pose projects to be shortlisted, while in the second stage they vote on which of the shortlisted projects should be funded. Prior work of a formal nature has focused on analysing the second stage only. We in- troduce several shortlisting rules for the first stage and analyse them in both normative and algorith- mic terms. Our main focus is on the incentives of participants to engage in strategic behaviour during the first stage, in which they need to reason about how their proposals will impact the range of strate- gies available to everyone in the second stage. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice Agent-based and Multi-agent Systems: Voting},
  archive   = {C_IJCAI},
  author    = {Simon Rey and Ulle Endriss and Ronald de Haan},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/52},
  pages     = {370-376},
  title     = {Shortlisting rules and incentives in an end-to-end model for participatory budgeting},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Data-driven methods for balancing fairness and efficiency in
ride-pooling. <em>IJCAI</em>, 363–369. (<a
href="https://doi.org/10.24963/ijcai.2021/51">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Rideshare and ride-pooling platforms use artificial intelligence-based matching algorithms to pair riders and drivers. However, these platforms can induce unfairness either through an unequal income distribution or disparate treatment of riders. We investigate two methods to reduce forms of inequality in ride-pooling platforms: by incorporating fairness constraints into the objective function and redistributing income to drivers who deserve more. To test these out, we use New York City taxi data to evaluate their performance on both the rider and driver side. For the first method, we find that optimizing for driver fairness out-performs state-of-the-art models in terms of the number of riders serviced, showing that optimizing for fairness can assist profitability in certain circumstances. For the second method, we explore income redistribution as a method to combat income inequality by having drivers keep an $r$ fraction of their income, and contribute the rest to a redistribution pool. For certain values of $r$, most drivers earn near their Shapley value, while still incentivizing drivers to maximize income, thereby avoiding the free-rider problem and reducing income variability. While the first method is useful because it improves both rider and driver-side fairness, the second method is useful because it improves fairness without affecting profitability, and both methods can be combined to improve rider and driver-side fairness. Keywords: Agent-based and Multi-agent Systems: Economic Paradigms, Auctions and Market-Based Systems AI Ethics, Trust, Fairness: Fairness Multidisciplinary Topics and Applications: Transportation},
  archive   = {C_IJCAI},
  author    = {Naveen Raman and Sanket Shah and John Dickerson},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/51},
  pages     = {363-369},
  title     = {Data-driven methods for balancing fairness and efficiency in ride-pooling},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mean field games flock! The reinforcement learning way.
<em>IJCAI</em>, 356–362. (<a
href="https://doi.org/10.24963/ijcai.2021/50">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present a method enabling a large number of agents to learn how to flock. This problem has drawn a lot of interest but requires many structural assumptions and is tractable only in small dimensions. We phrase this problem as a Mean Field Game (MFG), where each individual chooses its own acceleration depending on the population behavior. Combining Deep Reinforcement Learning (RL) and Normalizing Flows (NF), we obtain a tractable solution requiring only very weak assumptions. Our algorithm finds a Nash Equilibrium and the agents adapt their velocity to match the neighboring flock’s average one. We use Fictitious Play and alternate: (1) computing an approximate best response with Deep RL, and (2) estimating the next population distribution with NF. We show numerically that our algorithm can learn multi-group or high-dimensional flocking with obstacles. Keywords: Agent-based and Multi-agent Systems: Multi-agent Learning Agent-based and Multi-agent Systems: Noncooperative Games Machine Learning Applications: Applications of Reinforcement Learning},
  archive   = {C_IJCAI},
  author    = {Sarah Perrin and Mathieu Laurière and Julien Pérolat and Matthieu Geist and Romuald Élie and Olivier Pietquin},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/50},
  pages     = {356-362},
  title     = {Mean field games flock! the reinforcement learning way},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Majority vote in social networks: Make random friends or be
stubborn to overpower elites. <em>IJCAI</em>, 349–355. (<a
href="https://doi.org/10.24963/ijcai.2021/49">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Consider a graph G, representing a social network. Assume that initially each node is colored either black or white, which corresponds to a positive or negative opinion regarding a consumer product or a technological innovation. In the majority model, in each round all nodes simultaneously update their color to the most frequent color among their connections. Experiments on the graph data from the real world social networks (SNs) suggest that if all nodes in an extremely small set of high-degree nodes, often referred to as the elites, agree on a color, that color becomes the dominant color at the end of the process. We propose two countermeasures that can be adopted by individual nodes relatively easily and guarantee that the elites will not have this disproportionate power to engineer the dominant output color. The first countermeasure essentially requires each node to make some new connections at random while the second one demands the nodes to be more reluctant towards changing their color (opinion). We verify their effectiveness and correctness both theoretically and experimentally. We also investigate the majority model and a variant of it when the initial coloring is random on the real world SNs and several random graph models. In particular, our results on the Erdős-Rényi, and regular random graphs confirm or support several theoretical findings or conjectures by the prior work regarding the threshold behavior of the process. Finally, we provide theoretical and experimental evidence for the existence of a poly-logarithmic bound on the expected stabilization time of the majority model. Keywords: Agent-based and Multi-agent Systems: Agent Theories and Models Agent-based and Multi-agent Systems: Computational Social Choice Agent-based and Multi-agent Systems: Voting},
  archive   = {C_IJCAI},
  author    = {Charlotte Out and Ahad N. Zehmakan},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/49},
  pages     = {349-355},
  title     = {Majority vote in social networks: Make random friends or be stubborn to overpower elites},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Winner determination and strategic control in conditional
approval voting. <em>IJCAI</em>, 342–348. (<a
href="https://doi.org/10.24963/ijcai.2021/48">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Our work focuses on a generalization of the classic Minisum approval voting rule, introduced by Barrot and Lang (2016), and referred to as Conditional Minisum (CMS), for multi-issue elections. Although the CMS rule provides much higher levels of expressiveness, this comes at the expense of increased computational complexity. In this work, we study further the issue of efficient algorithms for CMS, and we identify the condition of bounded treewidth (of an appropriate graph that emerges from the provided ballots), as the necessary and sufficient condition for polynomial algorithms, under common complexity assumptions. Additionally we investigate the complexity of problems related to the strategic control of such elections by the possibility of adding or deleting either voters or alternatives. We exhibit that in most variants of these problems, CMS is resistant against control. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice Agent-based and Multi-agent Systems: Voting Agent-based and Multi-agent Systems: Algorithmic Game Theory},
  archive   = {C_IJCAI},
  author    = {Evangelos Markakis and Georgios Papasotiropoulos},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/48},
  pages     = {342-348},
  title     = {Winner determination and strategic control in conditional approval voting},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Almost envy-freeness for groups: Improved bounds via
discrepancy theory. <em>IJCAI</em>, 335–341. (<a
href="https://doi.org/10.24963/ijcai.2021/47">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the allocation of indivisible goods among groups of agents using well-known fairness notions such as envy-freeness and proportionality. While these notions cannot always be satisfied, we provide several bounds on the optimal relaxations that can be guaranteed. For instance, our bounds imply that when the number of groups is constant and the $n$ agents are divided into groups arbitrarily, there exists an allocation that is envy-free up to $\Theta(\sqrt{n})$ goods, and this bound is tight. Moreover, we show that while such an allocation can be found efficiently, it is NP-hard to compute an allocation that is envy-free up to $o(\sqrt{n})$ goods even when a fully envy-free allocation exists. Our proofs make extensive use of tools from discrepancy theory. Keywords: Agent-based and Multi-agent Systems: Resource Allocation Agent-based and Multi-agent Systems: Computational Social Choice},
  archive   = {C_IJCAI},
  author    = {Pasin Manurangsi and Warut Suksompong},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/47},
  pages     = {335-341},
  title     = {Almost envy-freeness for groups: Improved bounds via discrepancy theory},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Generalized kings and single-elimination winners in random
tournaments. <em>IJCAI</em>, 328–334. (<a
href="https://doi.org/10.24963/ijcai.2021/46">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Tournaments can be used to model a variety of practical scenarios including sports competitions and elections. A natural notion of strength of alternatives in a tournament is a generalized king: an alternative is said to be a k-king if it can reach every other alternative in the tournament via a directed path of length at most k. In this paper, we provide an almost complete characterization of the probability threshold such that all, a large number, or a small number of alternatives are k-kings with high probability in two random models. We show that, perhaps surprisingly, all changes in the threshold occur in the regime of constant k, with the biggest change being between k = 2 and k = 3. In addition, we establish an asymptotically tight bound on the probability threshold for which all alternatives are likely able to win a single-elimination tournament under some bracket. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice},
  archive   = {C_IJCAI},
  author    = {Pasin Manurangsi and Warut Suksompong},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/46},
  pages     = {328-334},
  title     = {Generalized kings and single-elimination winners in random tournaments},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving welfare in one-sided matchings using simple
threshold queries. <em>IJCAI</em>, 321–327. (<a
href="https://doi.org/10.24963/ijcai.2021/45">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study one-sided matching problems where each agent must be assigned at most one object. In this classic problem it is often assumed that agents specify only ordinal preferences over objects and the goal is to return a matching that satisfies some desirable property such as Pareto optimality or rank-maximality. However, agents may have cardinal utilities describing their preference intensities and ignoring this can result in welfare loss. We investigate how to elicit additional cardinal information from agents using simple threshold queries and use it in turn to design algorithms that return a matching satisfying a desirable matching property, while also achieving a good approximation to the optimal welfare among all matchings satisfying that property. Overall, our results show how one can improve welfare by even non-adaptively asking agents for just one bit of extra information per object. Keywords: Agent-based and Multi-agent Systems: Algorithmic Game Theory Agent-based and Multi-agent Systems: Computational Social Choice Agent-based and Multi-agent Systems: Resource Allocation},
  archive   = {C_IJCAI},
  author    = {Thomas Ma and Vijay Menon and Kate Larson},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/45},
  pages     = {321-327},
  title     = {Improving welfare in one-sided matchings using simple threshold queries},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Budget-feasible mechanisms for representing groups of agents
proportionally. <em>IJCAI</em>, 313–320. (<a
href="https://doi.org/10.24963/ijcai.2021/44">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we consider the problem of designing budget-feasible mechanisms for selecting agents with private costs from various groups to ensure proportional representation, where the minimum proportion of the selected agents from each group is maximized. Depending on agents&#39; membership in the groups, we consider two main models: single group setting where each agent belongs to only one group, and multiple group setting where each agent may belong to multiple groups. We propose novel budget-feasible proportion-representative mechanisms for these models, which can select representative agents from different groups. The proposed mechanisms guarantee theoretical properties of individual rationality, budget-feasibility, truthfulness, and approximation performance on proportional representation. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice Agent-based and Multi-agent Systems: Economic Paradigms, Auctions and Market-Based Systems},
  archive   = {C_IJCAI},
  author    = {Xiang Liu and Hau Chan and Minming Li and Weiwei Wu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/44},
  pages     = {313-320},
  title     = {Budget-feasible mechanisms for representing groups of agents proportionally},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Strategyproof randomized social choice for restricted sets
of utility functions. <em>IJCAI</em>, 306–312. (<a
href="https://doi.org/10.24963/ijcai.2021/43">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {When aggregating preferences of multiple agents, strategyproofness is a fundamental requirement. For randomized voting rules, so-called social decision schemes (SDSs), strategyproofness is usually formalized with the help of utility functions. A classic result shown by Gibbard in 1977 characterizes the set of SDSs that are strategyproof with respect to all utility functions and shows that these SDSs are either indecisive or unfair. For finding more insights into the trade-off between strategyproofness and decisiveness, we propose the notion of U-strategyproofness which requires that only voters with a utility function in the set U cannot manipulate. In particular, we show that if the utility functions in U value the best alternative much more than other alternatives, there are U-strategyproof SDSs that choose an alternative with probability 1 whenever all but k voters rank it first. We also prove for rank-based SDSs that this large gap in the utilities is required to be strategyproof and that the gap must increase in k. On the negative side, we show that U-strategyproofness is incompatible with Condorcet-consistency if U satisfies minimal symmetry conditions and there are at least four alternatives. For three alternatives, the Condorcet rule can be characterized based on U-strategyproofness for the set U containing all equi-distant utility functions. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice Agent-based and Multi-agent Systems: Voting},
  archive   = {C_IJCAI},
  author    = {Patrick Lederer},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/43},
  pages     = {306-312},
  title     = {Strategyproof randomized social choice for restricted sets of utility functions},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fairness in long-term participatory budgeting.
<em>IJCAI</em>, 299–305. (<a
href="https://doi.org/10.24963/ijcai.2021/42">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Participatory Budgeting (PB) processes are usually designed to span several years, with referenda for new budget allocations taking place regularly. This paper presents a first formal framework for long-term PB, based on a sequence of budgeting problems as main input. We introduce a theory of fairness for this setting, focusing on three main concepts that apply to types (groups) of voters: (i) achieving equal welfare for all types, (ii) minimizing inequality of welfare (as measured by the Gini coefficient), and (iii) achieving equal welfare in the long run. We investigate under which conditions these criteria can be satisfied, and analyze the computational complexity of verifying whether they hold. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice Agent-based and Multi-agent Systems: Voting},
  archive   = {C_IJCAI},
  author    = {Martin Lackner and Jan Maly and Simon Rey},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/42},
  pages     = {299-305},
  title     = {Fairness in long-term participatory budgeting},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Two-stage facility location games with strategic clients and
facilities. <em>IJCAI</em>, 292–298. (<a
href="https://doi.org/10.24963/ijcai.2021/41">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider non-cooperative facility location games where both facilities and clients act strategically and heavily influence each other. This contrasts established game-theoretic facility location models with non-strategic clients that simply select the closest opened facility. In our model, every facility location has a set of attracted clients and each client has a set of shopping locations and a weight that corresponds to its spending capacity. Facility agents selfishly select a location for opening their facility to maximize the attracted total spending capacity, whereas clients strategically decide how to distribute their spending capacity among the opened facilities in their shopping range. We focus on a natural client behavior similar to classical load balancing: our selfish clients aim for a distribution that minimizes their maximum waiting time for getting serviced, where a facility’s waiting time corresponds to its total attracted client weight. We show that subgame perfect equilibria exist and we give almost tight constant bounds on the Price of Anarchy and the Price of Stability, which even hold for a broader class of games with arbitrary client behavior. Since facilities and clients influence each other, it is crucial for the facilities to anticipate the selfish clients’ behavior when selecting their location. For this, we provide an efficient algorithm that also implies an efficient check for equilibrium. Finally, we show that computing a socially optimal facility placement is NP-hard and that this result holds for all feasible client weight distributions. Keywords: Agent-based and Multi-agent Systems: Algorithmic Game Theory Agent-based and Multi-agent Systems: Noncooperative Games},
  archive   = {C_IJCAI},
  author    = {Simon Krogmann and Pascal Lenzner and Louise Molitor and Alexander Skopalik},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/41},
  pages     = {292-298},
  title     = {Two-stage facility location games with strategic clients and facilities},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Interaction considerations in learning from humans.
<em>IJCAI</em>, 283–291. (<a
href="https://doi.org/10.24963/ijcai.2021/40">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The ability to learn from large quantities of complex data has led to the development of intelligent agents such as self-driving cars and assistive devices. This data often comes from people via interactions such as labeling, providing rewards and punishments, and giving demonstrations or critiques. However, people&#39;s ability to provide high-quality data can be affected by human factors of an interaction, such as induced cognitive load and perceived usability. We show that these human factors differ significantly between interaction types. We first formalize interactions as a Markov Decision Process, and construct a taxonomy of these interactions to identify four archetypes: Showing, Categorizing, Sorting, and Evaluating. We then run a user study across two task domains. Our findings show that Evaluating interactions are more cognitively loading and less usable than the others, and Categorizing and Showing interactions are the least cognitively loading and most usable. Keywords: Agent-based and Multi-agent Systems: Human-Agent Interaction Humans and AI: Human-AI Collaboration},
  archive   = {C_IJCAI},
  author    = {Pallavi Koppol and Henny Admoni and Reid Simmons},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/40},
  pages     = {283-291},
  title     = {Interaction considerations in learning from humans},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Participatory budgeting with project groups. <em>IJCAI</em>,
276–282. (<a href="https://doi.org/10.24963/ijcai.2021/39">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study a generalization of the standard approval-based model of participatory budgeting (PB), in which voters are providing approval ballots over a set of predefined projects and---in addition to a global budget limit---there are several groupings of the projects, each group with its own budget limit. We study the computational complexity of identifying project bundles that maximize voter satisfaction while respecting all budget limits. We show that the problem is generally intractable and describe efficient exact algorithms for several special cases, including instances with only few groups and instances where the group structure is close to being hierarchical, as well as efficient approximation algorithms. Our results could allow, e.g., municipalities to hold richer PB processes that are thematically and geographically inclusive. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice Agent-based and Multi-agent Systems: Voting Agent-based and Multi-agent Systems: Economic Paradigms, Auctions and Market-Based Systems},
  archive   = {C_IJCAI},
  author    = {Pallavi Jain and Krzysztof Sornat and Nimrod Talmon and Meirav Zehavi},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/39},
  pages     = {276-282},
  title     = {Participatory budgeting with project groups},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A polynomial-time, truthful, individually rational and
budget balanced ridesharing mechanism. <em>IJCAI</em>, 268–275. (<a
href="https://doi.org/10.24963/ijcai.2021/38">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Ridesharing has great potential to improve transportation efficiency while reducing congestion and pollution. To realize this potential, mechanisms are needed that allocate vehicles optimally and provide the right incentives to riders. However, many existing approaches consider restricted settings (e.g., only one rider per vehicle or a common origin for all riders). Moreover, naive applications of standard approaches, such as the Vickrey-Clarke-Groves or greedy mechanisms, cannot achieve a polynomial-time, truthful, individually rational and budget balanced mechanism. To address this, we formulate a general ridesharing problem and apply mechanism design to develop a novel mechanism which satisfies all four properties and whose social cost is within 8.6\% of the optimal on average. Keywords: Agent-based and Multi-agent Systems: Coordination and Cooperation Agent-based and Multi-agent Systems: Economic Paradigms, Auctions and Market-Based Systems Multidisciplinary Topics and Applications: Transportation},
  archive   = {C_IJCAI},
  author    = {Tatsuya Iwase and Sebastian Stein and Enrico H. Gerding},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/38},
  pages     = {268-275},
  title     = {A polynomial-time, truthful, individually rational and budget balanced ridesharing mechanism},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic proportional rankings. <em>IJCAI</em>, 261–267. (<a
href="https://doi.org/10.24963/ijcai.2021/37">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Proportional ranking rules aggregate approval-style preferences of agents into a collective ranking such that groups of agents with similar preferences are adequately represented. Motivated by the application of live Q&amp;A platforms, where submitted questions need to be ranked based on the interests of the audience, we study a dynamic extension of the proportional rankings setting. In our setting, the goal is to maintain the proportionality of a ranking when alternatives (i.e., questions)---not necessarily from the top of the ranking---get selected sequentially. We propose generalizations of well-known aggregation rules to this setting and study their monotonicity and proportionality properties. We also evaluate the performance of these rules experimentally, using realistic probabilistic assumptions on the selection procedure. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice Agent-based and Multi-agent Systems: Voting},
  archive   = {C_IJCAI},
  author    = {Jonas Israel and Markus Brill},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/37},
  pages     = {261-267},
  title     = {Dynamic proportional rankings},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SURPRISE! And when to schedule it. <em>IJCAI</em>, 252–260.
(<a href="https://doi.org/10.24963/ijcai.2021/36">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Information flow measures, over the duration of a game, the audience’s belief of who will win, and thus can reflect the amount of surprise in a game. To quantify the relationship between information flow and audiences&#39; perceived quality, we conduct a case study where subjects watch one of the world’s biggest esports events, LOL S10. In addition to eliciting information flow, we also ask subjects to report their rating for each game. We find that the amount of surprise in the end of the game plays a dominant role in predicting the rating. This suggests the importance of incorporating when the surprise occurs, in addition to the amount of surprise, in perceived quality models. For content providers, it implies that everything else being equal, it is better for twists to be more likely to happen toward the end of a show rather than uniformly throughout. Keywords: Agent-based and Multi-agent Systems: Algorithmic Game Theory Agent-based and Multi-agent Systems: Computational Social Choice Humans and AI: Human Computation and Crowdsourcing},
  archive   = {C_IJCAI},
  author    = {Zhihuan Huang and Shengwei Xu and You Shan and Yuxuan Lu and Yuqing Kong and Tracy Xiao Liu and Grant Schoenebeck},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/36},
  pages     = {252-260},
  title     = {SURPRISE! and when to schedule it.},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Surprisingly popular voting recovers rankings, surprisingly!
<em>IJCAI</em>, 245–251. (<a
href="https://doi.org/10.24963/ijcai.2021/35">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The wisdom of the crowd has long become the de facto approach for eliciting information from individuals or experts in order to predict the ground truth. However, classical democratic approaches for aggregating individual \emph{votes} only work when the opinion of the majority of the crowd is relatively accurate. A clever recent approach, \emph{surprisingly popular voting}, elicits additional information from the individuals, namely their \emph{prediction} of other individuals&#39; votes, and provably recovers the ground truth even when experts are in minority. This approach works well when the goal is to pick the correct option from a small list, but when the goal is to recover a true ranking of the alternatives, a direct application of the approach requires eliciting too much information. We explore practical techniques for extending the surprisingly popular algorithm to ranked voting by partial votes and predictions and designing robust aggregation rules. We experimentally demonstrate that even a little prediction information helps surprisingly popular voting outperform classical approaches. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice Agent-based and Multi-agent Systems: Voting Humans and AI: Human Computation and Crowdsourcing},
  archive   = {C_IJCAI},
  author    = {Hadi Hosseini and Debmalya Mandal and Nisarg Shah and Kevin Shi},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/35},
  pages     = {245-251},
  title     = {Surprisingly popular voting recovers rankings, surprisingly!},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Guaranteeing maximin shares: Some agents left behind.
<em>IJCAI</em>, 238–244. (<a
href="https://doi.org/10.24963/ijcai.2021/34">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The maximin share (MMS) guarantee is a desirable fairness notion for allocating indivisible goods. While MMS allocations do not always exist, several approximation techniques have been developed to ensure that all agents receive a fraction of their maximin share. We focus on an alternative approximation notion, based on the population of agents, that seeks to guarantee MMS for a fraction of agents. We show that no optimal approximation algorithm can satisfy more than a constant number of agents, and discuss the existence and computation of MMS for all but one agent and its relation to approximate MMS guarantees. We then prove the existence of allocations that guarantee MMS for 2/3 of agents, and devise a polynomial time algorithm that achieves this bound for up to nine agents. A key implication of our result is the existence of allocations that guarantee the value that an agent receives by partitioning the goods into 3n/2 bundles, improving the best known guarantee when goods are partitioned into 2n-2 bundles. Finally, we provide empirical experiments using synthetic data. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice Agent-based and Multi-agent Systems: Economic Paradigms, Auctions and Market-Based Systems Agent-based and Multi-agent Systems: Resource Allocation},
  archive   = {C_IJCAI},
  author    = {Hadi Hosseini and Andrew Searns},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/34},
  pages     = {238-244},
  title     = {Guaranteeing maximin shares: Some agents left behind},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Accomplice manipulation of the deferred acceptance
algorithm. <em>IJCAI</em>, 231–237. (<a
href="https://doi.org/10.24963/ijcai.2021/33">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The deferred acceptance algorithm is an elegant solution to the stable matching problem that guarantees optimality and truthfulness for one side of the market. Despite these desirable guarantees, it is susceptible to strategic misreporting of preferences by the agents on the other side. We study a novel model of strategic behavior under the deferred acceptance algorithm: manipulation through an accomplice. Here, an agent on the proposed-to side (say, a woman) partners with an agent on the proposing side---an accomplice---to manipulate on her behalf (possibly at the expense of worsening his match). We show that the optimal manipulation strategy for an accomplice comprises of promoting exactly one woman in his true list (i.e., an inconspicuous manipulation). This structural result immediately gives a polynomial-time algorithm for computing an optimal accomplice manipulation. We also study the conditions under which the manipulated matching is stable with respect to the true preferences. Our experimental results show that accomplice manipulation outperforms self manipulation both in terms of the frequency of occurrence as well as the quality of matched partners. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice Agent-based and Multi-agent Systems: Economic Paradigms, Auctions and Market-Based Systems},
  archive   = {C_IJCAI},
  author    = {Hadi Hosseini and Fatima Umar and Rohit Vaish},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/33},
  pages     = {231-237},
  title     = {Accomplice manipulation of the deferred acceptance algorithm},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fair and efficient resource allocation with partial
information. <em>IJCAI</em>, 224–230. (<a
href="https://doi.org/10.24963/ijcai.2021/32">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the fundamental problem of allocating indivisible goods to agents with additive preferences. We consider eliciting from each agent only a ranking of her k most preferred goods instead of her full cardinal valuations. We characterize the amount of preference information that must be elicited in order to satisfy envy-freeness up to one good and approximate maximin share guarantee, two widely studied fairness notions. We also analyze the multiplicative loss in social welfare incurred due to the lack of full information with and without fairness requirements. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice Agent-based and Multi-agent Systems: Resource Allocation AI Ethics, Trust, Fairness: Fairness},
  archive   = {C_IJCAI},
  author    = {Daniel Halpern and Nisarg Shah},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/32},
  pages     = {224-230},
  title     = {Fair and efficient resource allocation with partial information},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Even more effort towards improved bounds and fixed-parameter
tractability for multiwinner rules. <em>IJCAI</em>, 217–223. (<a
href="https://doi.org/10.24963/ijcai.2021/31">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multiwinner elections have proven to be a fruitful research topic with many real world applications. We contribute to this line of research by improving the state of the art regarding the computational complexity of computing good committees. More formally, given a set of candidates C, a set of voters V, each ranking the candidates according to their preferences, and an integer k; a multiwinner voting rule identifies a committee of size k, based on these given voter preferences. In this paper we consider several utilitarian and egailitarian OWA (ordered weighted average) scoring rules, which are an extensively researched family of rules (and a subfamily of the family of committee scoring rules). First, we improve the result of Betzler et al. [JAIR, 2013], which gave a O(n^n) algorithm for computing winner under the Chamberlin Courant rule (CC), where n is the number of voters; to a running time of O(2^n), which is optimal. Furthermore, we study the parameterized complexity of the Pessimist voting rule and describe a few tractable and intractable cases. Apart from such utilitarian voting rules, we extend our study and consider egalitarian median and egalitarian mean (both committee scoring rules), showing some tractable and intractable results, based on nontrivial structural observations. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice Agent-based and Multi-agent Systems: Voting},
  archive   = {C_IJCAI},
  author    = {Sushmita Gupta and Pallavi Jain and Saket Saurabh and Nimrod Talmon},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/31},
  pages     = {217-223},
  title     = {Even more effort towards improved bounds and fixed-parameter tractability for multiwinner rules},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Worst-case bounds on power vs. Proportion in weighted voting
games with application to false-name manipulation. <em>IJCAI</em>,
210–216. (<a href="https://doi.org/10.24963/ijcai.2021/30">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Weighted voting games are applicable to a wide variety of multi-agent settings. They enable the formalization of power indices which quantify the coalitional power of players. We take a novel approach to the study of the power of big vs.~small players in these games. We model small (big) players as having single (multiple) votes. The aggregate relative power of big players is measured w.r.t.~their votes proportion. For this ratio, we show small constant worst-case bounds for the Shapley-Shubik and the Deegan-Packel indices. In sharp contrast, this ratio is unbounded for the Banzhaf index. As an application, we define a false-name strategic normal form game where each big player may split its votes between false identities, and study its various properties. Together our results provide foundations for the implications of players&#39; size, modeled as their ability to split, on their relative power. Keywords: Agent-based and Multi-agent Systems: Cooperative Games Agent-based and Multi-agent Systems: Voting},
  archive   = {C_IJCAI},
  author    = {Yotam Gafni and Ron Lavi and Moshe Tennenholtz},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/30},
  pages     = {210-216},
  title     = {Worst-case bounds on power vs. proportion in weighted voting games with application to false-name manipulation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Two-sided matching meets fair division. <em>IJCAI</em>,
203–209. (<a href="https://doi.org/10.24963/ijcai.2021/29">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We introduce a new model for two-sided matching which allows us to borrow popular fairness notions from the fair division literature such as envy-freeness up to one good and maximin share guarantee. In our model, each agent is matched to multiple agents on the other side over whom she has additive preferences. We demand fairness for each side separately, giving rise to notions such as double envy-freeness up to one match (DEF1) and double maximin share guarantee (DMMS). We show that (a slight strengthening of) DEF1 cannot always be achieved, but in the special case where both sides have identical preferences, the round-robin algorithm with a carefully designed agent ordering achieves it. In contrast, DMMS cannot be achieved even when both sides have identical preferences. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice Agent-based and Multi-agent Systems: Resource Allocation AI Ethics, Trust, Fairness: Fairness},
  archive   = {C_IJCAI},
  author    = {Rupert Freeman and Evi Micha and Nisarg Shah},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/29},
  pages     = {203-209},
  title     = {Two-sided matching meets fair division},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Kemeny consensus complexity. <em>IJCAI</em>, 196–202. (<a
href="https://doi.org/10.24963/ijcai.2021/28">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The computational study of election problems generally focuses on questions related to the winner or set of winners of an election. But social preference functions such as Kemeny rule output a full ranking of the candidates (a consensus). We study the complexity of consensus-related questions, with a particular focus on Kemeny and its qualitative version Slater. The simplest of these questions is the problem of determining whether a ranking is a consensus, and we show that this problem is coNP-complete. We also study the natural question of the complexity of manipulative actions that have a specific consensus as a goal. Though determining whether a ranking is a Kemeny consensus is hard, the optimal action for manipulators is to simply vote their desired consensus. We provide evidence that this simplicity is caused by the combination of election system (Kemeny), manipulative action (manipulation), and manipulative goal (consensus). In the process we provide the first completeness results at the second level of the polynomial hierarchy for electoral manipulation and for optimal solution recognition. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice Agent-based and Multi-agent Systems: Voting},
  archive   = {C_IJCAI},
  author    = {Zack Fitzsimmons and Edith Hemaspaandra},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/28},
  pages     = {196-202},
  title     = {Kemeny consensus complexity},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reasoning over argument-incomplete AAFs in the presence of
correlations. <em>IJCAI</em>, 189–195. (<a
href="https://doi.org/10.24963/ijcai.2021/27">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We introduce &quot;argument-incomplete Abstract Argumentation Frameworks with dependencies&quot;, that extend the traditional abstract argumentation reasoning to the case where some arguments are uncertain and correlated through logical dependencies (such as mutual exclusion, implication, etc.). We characterize the complexities of the problems DSAT of deciding the satisfiability of the dependencies and PDVER of verifying extensions, and show how they depend on the forms of dependencies and, for PDVER, also on the semantics of the extensions. Keywords: Agent-based and Multi-agent Systems: Agreement Technologies: Argumentation Knowledge Representation and Reasoning: Computational Complexity of Reasoning},
  archive   = {C_IJCAI},
  author    = {Bettina Fazzinga and Sergio Flesca and Filippo Furfaro},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/27},
  pages     = {189-195},
  title     = {Reasoning over argument-incomplete AAFs in the presence of correlations},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Relaxed core stability in fractional hedonic games.
<em>IJCAI</em>, 182–188. (<a
href="https://doi.org/10.24963/ijcai.2021/26">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The core is a well-known and fundamental notion of stability in games intended to model coalition formation such as hedonic games. The fact that the number of deviating agents (that have to coordinate themselves) can be arbitrarily high, and the fact that agents may benefit only by a tiny amount from their deviation (while they could incur in a cost for deviating), suggest that the core is not able to suitably model many practical scenarios in large and highly distributed multi-agent systems. For this reason, we consider relaxed core stable outcomes where the notion of permissible deviations is modified along two orthogonal directions: the former takes into account the size of the deviating coalition, and the latter the amount of utility gain for each member of the deviating coalition. These changes result in two different notions of stability, namely, the q-size core and k-improvement core. We investigate these concepts of stability in fractional hedonic games, that is a well-known subclass of hedonic games for which core stable outcomes are not guaranteed to exist and it is computationally hard to decide nonemptiness of the core. Interestingly, the considered relaxed notions of core also possess the appealing property of recovering, in some notable cases, the convergence, the existence and the possibility of computing stable solutions in polynomial time. Keywords: Agent-based and Multi-agent Systems: Algorithmic Game Theory Agent-based and Multi-agent Systems: Noncooperative Games Agent-based and Multi-agent Systems: Coordination and Cooperation},
  archive   = {C_IJCAI},
  author    = {Angelo Fanelli and Gianpiero Monaco and Luca Moscardelli},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/26},
  pages     = {182-188},
  title     = {Relaxed core stability in fractional hedonic games},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On a competitive secretary problem with deferred selections.
<em>IJCAI</em>, 175–181. (<a
href="https://doi.org/10.24963/ijcai.2021/25">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the secretary problem in multi-agent environments. In the standard secretary problem, a sequence of arbitrary awards arrive online, in a random order, and a single decision maker makes an immediate and irrevocable decision whether to accept each award upon its arrival. The requirement to make immediate decisions arises in many cases due to an implicit assumption regarding competition. Namely, if the decision maker does not take the offered award immediately, it will be taken by someone else. We introduce a novel multi-agent secretary model, in which the competition is explicit. In our model, multiple agents compete over the arriving awards, but the decisions need not be immediate; instead, agents may select previous awards as long as they are available (i.e., not taken by another agent). If an award is selected by multiple agents, ties are broken either randomly or according to a global ranking. This induces a multi-agent game in which the time of selection is not enforced by the rules of the games, rather it is an important component of the agent&#39;s strategy. We study the structure and performance of equilibria in this game. For random tie breaking, we characterize the equilibria of the game, and show that the expected social welfare in equilibrium is nearly optimal, despite competition among the agents. For ranked tie breaking, we give a full characterization of equilibria in the 3-agent game, and show that as the number of agents grows, the winning probability of every agent under non-immediate selections approaches her winning probability under immediate selections. Keywords: Agent-based and Multi-agent Systems: Agent Theories and Models Agent-based and Multi-agent Systems: Algorithmic Game Theory},
  archive   = {C_IJCAI},
  author    = {Tomer Ezra and Michal Feldman and Ron Kupfer},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/25},
  pages     = {175-181},
  title     = {On a competitive secretary problem with deferred selections},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Keep your distance: Land division with separation.
<em>IJCAI</em>, 168–174. (<a
href="https://doi.org/10.24963/ijcai.2021/24">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper is part of an ongoing endeavor to bring the theory of fair division closer to practice by handling requirements from real-life applications. We focus on two requirements originating from the division of land estates: (1) each agent should receive a plot of a usable geometric shape, and (2) plots of different agents must be physically separated. With these requirements, the classic fairness notion of proportionality is impractical, since it may be impossible to attain any multiplicative approximation of it. In contrast, the ordinal maximin share approximation, introduced by Budish in 2011, provides meaningful fairness guarantees. We prove upper and lower bounds on achievable maximin share guarantees when the usable shapes are squares, fat rectangles, or arbitrary axes-aligned rectangles, and explore the algorithmic and query complexity of finding fair partitions in this setting. Keywords: Agent-based and Multi-agent Systems: Resource Allocation Agent-based and Multi-agent Systems: Computational Social Choice},
  archive   = {C_IJCAI},
  author    = {Edith Elkind and Erel Segal-Halevi and Warut Suksompong},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/24},
  pages     = {168-174},
  title     = {Keep your distance: Land division with separation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Graphical cake cutting via maximin share. <em>IJCAI</em>,
161–167. (<a href="https://doi.org/10.24963/ijcai.2021/23">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the recently introduced cake-cutting setting in which the cake is represented by an undirected graph. This generalizes the canonical interval cake and allows for modeling the division of road networks. We show that when the graph is a forest, an allocation satisfying the well-known criterion of maximin share fairness always exists. Our result holds even when separation constraints are imposed; however, in the latter case no multiplicative approximation of proportionality can be guaranteed. Furthermore, while maximin share fairness is not always achievable for general graphs, we prove that ordinal relaxations can be attained. Keywords: Agent-based and Multi-agent Systems: Resource Allocation Agent-based and Multi-agent Systems: Computational Social Choice},
  archive   = {C_IJCAI},
  author    = {Edith Elkind and Erel Segal-Halevi and Warut Suksompong},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/23},
  pages     = {161-167},
  title     = {Graphical cake cutting via maximin share},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Online selection of diverse committees. <em>IJCAI</em>,
154–160. (<a href="https://doi.org/10.24963/ijcai.2021/22">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Citizens&#39; assemblies need to represent subpopulations according to their proportions in the general population. These large committees are often constructed in an online fashion by contacting people, asking for the demographic features of the volunteers, and deciding to include them or not. This raises a trade-off between the number of people contacted (and the incurring cost) and the representativeness of the committee. We study three methods, theoretically and experimentally: a greedy algorithm that includes volunteers as long as proportionality is not violated; a non-adaptive method that includes a volunteer with a probability depending only on their features, assuming that the joint feature distribution in the volunteer pool is known; and a reinforcement learning based approach when this distribution is not known a priori but learnt online. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice Planning and Scheduling: Markov Decisions Processes Planning and Scheduling: Applications of Planning},
  archive   = {C_IJCAI},
  author    = {Virginie Do and Jamal Atif and Jérôme Lang and Nicolas Usunier},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/22},
  pages     = {154-160},
  title     = {Online selection of diverse committees},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Neural regret-matching for distributed constraint
optimization problems. <em>IJCAI</em>, 146–153. (<a
href="https://doi.org/10.24963/ijcai.2021/21">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Distributed constraint optimization problems (DCOPs) are a powerful model for multi-agent coordination and optimization, where information and controls are distributed among multiple agents by nature. Sampling-based algorithms are important incomplete techniques for solving medium-scale DCOPs. However, they use tables to exactly store all the information (e.g., costs, confidence bounds) to facilitate sampling, which limits their scalability. This paper tackles the limitation by incorporating deep neural networks in solving DCOPs for the first time and presents a neural-based sampling scheme built upon regret-matching. In the algorithm, each agent trains a neural network to approximate the regret related to its local problem and performs sampling according to the estimated regret. Furthermore, to ensure exploration we propose a regret rounding scheme that rounds small regret values to positive numbers. We theoretically show the regret bound of our algorithm and extensive evaluations indicate that our algorithm can scale up to large-scale DCOPs and significantly outperform the state-of-the-art methods. Keywords: Agent-based and Multi-agent Systems: Coordination and Cooperation Constraints and SAT: Constraint Optimization Constraints and SAT: Distributed Constraints},
  archive   = {C_IJCAI},
  author    = {Yanchen Deng and Runsheng Yu and Xinrun Wang and Bo An},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/21},
  pages     = {146-153},
  title     = {Neural regret-matching for distributed constraint optimization problems},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The parameterized complexity of connected fair division.
<em>IJCAI</em>, 139–145. (<a
href="https://doi.org/10.24963/ijcai.2021/20">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the Connected Fair Division problem (CFD), which generalizes the fundamental problem of fairly allocating resources to agents by requiring that the items allocated to each agent form a connected subgraph in a provided item graph G. We expand on previous results by providing a comprehensive complexity-theoretic understanding of CFD based on several new algorithms and lower bounds while taking into account several well-established notions of fairness: proportionality, envy-freeness, EF1 and EFX. In particular, we show that to achieve tractability, one needs to restrict both the agents and the item graph in a meaningful way. We design (XP)-algorithms for the problem parameterized by (1) clique-width of G plus the number of agents and (2) treewidth of G plus the number of agent types, along with corresponding lower bounds. Finally, we show that to achieve fixed-parameter tractability, one needs to not only use a more restrictive parameterization of G, but also include the maximum item valuation as an additional parameter. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice Agent-based and Multi-agent Systems: Resource Allocation},
  archive   = {C_IJCAI},
  author    = {Argyrios Deligkas and Eduard Eiben and Robert Ganian and Thekla Hamm and Sebastian Ordyniak},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/20},
  pages     = {139-145},
  title     = {The parameterized complexity of connected fair division},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-agent intention progression with black-box agents.
<em>IJCAI</em>, 132–138. (<a
href="https://doi.org/10.24963/ijcai.2021/19">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose a new approach to intention progression in multi-agent settings where other agents are effectively black boxes. That is, while their goals are known, the precise programs used to achieve these goals are not known. In our approach, agents use an abstraction of their own program called a partially-ordered goal-plan tree (pGPT) to schedule their intentions and predict the actions of other agents. We show how a pGPT can be derived from the program of a BDI agent, and present an approach based on Monte Carlo Tree Search (MCTS) for scheduling an agent&#39;s intentions using pGPTs. We evaluate our pGPT-based approach in cooperative, selfish and adversarial multi-agent settings, and show that it out-performs MCTS-based scheduling where agents assume that other agents have the same program as themselves. Keywords: Agent-based and Multi-agent Systems: Agent Theories and Models Agent-based and Multi-agent Systems: Engineering Methods, Platforms, Languages and Tools},
  archive   = {C_IJCAI},
  author    = {Michael Dann and Yuan Yao and Brian Logan and John Thangarajah},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/19},
  pages     = {132-138},
  title     = {Multi-agent intention progression with black-box agents},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving multi-agent coordination by learning to estimate
contention. <em>IJCAI</em>, 125–131. (<a
href="https://doi.org/10.24963/ijcai.2021/18">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present a multi-agent learning algorithm, ALMA-Learning, for efficient and fair allocations in large-scale systems. We circumvent the traditional pitfalls of multi-agent learning (e.g., the moving target problem, the curse of dimensionality, or the need for mutually consistent actions) by relying on the ALMA heuristic as a coordination mechanism for each stage game. ALMA-Learning is decentralized, observes only own action/reward pairs, requires no inter-agent communication, and achieves near-optimal (&lt;5\% loss) and fair coordination in a variety of synthetic scenarios and a real-world meeting scheduling problem. The lightweight nature and fast learning constitute ALMA-Learning ideal for on-device deployment. Keywords: Agent-based and Multi-agent Systems: Coordination and Cooperation Agent-based and Multi-agent Systems: Multi-agent Learning Agent-based and Multi-agent Systems: Resource Allocation},
  archive   = {C_IJCAI},
  author    = {Panayiotis Danassis and Florian Wiedemair and Boi Faltings},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/18},
  pages     = {125-131},
  title     = {Improving multi-agent coordination by learning to estimate contention},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Identifying norms from observation using MCMC sampling.
<em>IJCAI</em>, 118–124. (<a
href="https://doi.org/10.24963/ijcai.2021/17">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {To promote efficient interactions in dynamic and multi-agent systems, there is much interest in techniques that allow agents to represent and reason about social norms that govern agent interactions. Much of this work assumes that norms are provided to agents, but some work has investigated how agents can identify the norms present in a society through observation and experience. However, the norm-identification techniques proposed in the literature often depend on a very specific and domain-specific representation of norms, or require that the possible norms can be enumerated in advance. This paper investigates the problem of identifying norm candidates from a normative language expressed as a probabilistic context-free grammar, using Markov Chain Monte Carlo (MCMC) search. We apply our technique to a simulated robot manipulator task and show that it allows effective identification of norms from observation. Keywords: Agent-based and Multi-agent Systems: Normative systems Agent-based and Multi-agent Systems: Agent Societies Machine Learning: Bayesian Learning},
  archive   = {C_IJCAI},
  author    = {Stephen Cranefield and Ashish Dhiman},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/17},
  pages     = {118-124},
  title     = {Identifying norms from observation using MCMC sampling},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning in markets: Greed leads to chaos but following the
price is right. <em>IJCAI</em>, 111–117. (<a
href="https://doi.org/10.24963/ijcai.2021/16">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study learning dynamics in distributed production economies such as blockchain mining, peer-to-peer file sharing and crowdsourcing. These economies can be modelled as multi-product Cournot competitions or all-pay auctions (Tullock contests) when individual firms have market power, or as Fisher markets with quasi-linear utilities when every firm has negligible influence on market outcomes. In the former case, we provide a formal proof that Gradient Ascent (GA) can be Li-Yorke chaotic for a step size as small as Θ(1/n), where n is the number of firms. In stark contrast, for the Fisher market case, we derive a Proportional Response (PR) protocol that converges to market equilibrium. The positive results on the convergence of the PR dynamics are obtained in full generality, in the sense that they hold for Fisher markets with any quasi-linear utility functions. Conversely, the chaos results for the GA dynamics are established even in the simplest possible setting of two firms and one good, and they hold for a wide range of price functions with different demand elasticities. Our findings suggest that by considering multi-agent interactions from a market rather than a game-theoretic perspective, we can formally derive natural learning protocols which are stable and converge to effective outcomes rather than being chaotic. Keywords: Agent-based and Multi-agent Systems: Economic Paradigms, Auctions and Market-Based Systems Agent-based and Multi-agent Systems: Multi-agent Learning Agent-based and Multi-agent Systems: Noncooperative Games},
  archive   = {C_IJCAI},
  author    = {Yun Kuen Cheung and Stefanos Leonardos and Georgios Piliouras},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/16},
  pages     = {111-117},
  title     = {Learning in markets: Greed leads to chaos but following the price is right},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cooperation in threshold public projects with binary
actions. <em>IJCAI</em>, 104–110. (<a
href="https://doi.org/10.24963/ijcai.2021/15">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {When can cooperation arise from self-interested decisions in public goods games? And how can we help agents to act cooperatively? We examine these classical questions in a pivotal participation game, a variant of public good games, where heterogeneous agents make binary participation decisions on contributing their endowments, and the public project succeeds when it has enough contributions. We prove it is NP-complete to decide the existence of a cooperative Nash equilibrium such that the project succeeds. We demonstrate that the decision problem becomes easy if agents are homogeneous enough. We then propose two algorithms to help cooperation in the game. Our first algorithm adds an external investment to the public project, and our second algorithm uses matching funds. We show the cost to induce a cooperative Nash equilibrium is near-optimal for both algorithms. Finally, the cost of matching funds can always be smaller than the cost of adding an external investment. Intuitively, matching funds provide a greater incentive for cooperation than adding an external investment does. Keywords: Agent-based and Multi-agent Systems: Algorithmic Game Theory Agent-based and Multi-agent Systems: Coordination and Cooperation},
  archive   = {C_IJCAI},
  author    = {Yiling Chen and Biaoshuai Tao and Fang-Yi Yu},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/15},
  pages     = {104-110},
  title     = {Cooperation in threshold public projects with binary actions},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Temporal induced self-play for stochastic bayesian games.
<em>IJCAI</em>, 96–103. (<a
href="https://doi.org/10.24963/ijcai.2021/14">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {One practical requirement in solving dynamic games is to ensure that the players play well from any decision point onward. To satisfy this requirement, existing efforts focus on equilibrium refinement, but the scalability and applicability of existing techniques are limited. In this paper, we propose Temporal-Induced Self-Play (TISP), a novel reinforcement learning-based framework to find strategies with decent performances from any decision point onward. TISP uses belief-space representation, backward induction, policy learning, and non-parametric approximation. Building upon TISP, we design a policy-gradient-based algorithm TISP-PG. We prove that TISP-based algorithms can find approximate Perfect Bayesian Equilibrium in zero-sum one-sided stochastic Bayesian games with finite horizon. We test TISP-based algorithms in various games, including finitely repeated security games and a grid-world game. The results show that TISP-PG is more scalable than existing mathematical programming-based methods and significantly outperforms other learning-based methods. Keywords: Agent-based and Multi-agent Systems: Multi-agent Learning Machine Learning Applications: Applications of Reinforcement Learning},
  archive   = {C_IJCAI},
  author    = {Weizhe Chen and Zihan Zhou and Yi Wu and Fei Fang},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/14},
  pages     = {96-103},
  title     = {Temporal induced self-play for stochastic bayesian games},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fractional matchings under preferences: Stability and
optimality. <em>IJCAI</em>, 89–95. (<a
href="https://doi.org/10.24963/ijcai.2021/13">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study generalizations of stable matching in which agents may be matched fractionally; this models time-sharing assignments. We focus on the so-called ordinal stability and cardinal stability, and investigate the computational complexity of finding an ordinally stable or cardinally stable fractional matching which either maximizes the social welfare (i.e., the overall utilities of the agents) or the number of fully matched agents (i.e., agents whose matching values sum up to one). We complete the complexity classification of both optimization problems for both ordinal stability and cardinal stability, distinguishing between the marriage (bipartite) and roommates (non-bipartite) cases and the presence or absence of ties in the preferences. In particular, we prove a surprising result that finding a cardinally stable fractional matching with maximum social welfare is NP-hard even for the marriage case without ties. This answers an open question and exemplifies a rare variant of stable marriage that remains hard for preferences without ties. We also complete the picture of the relations of the stability notions and derive structural properties. Keywords: Agent-based and Multi-agent Systems: Algorithmic Game Theory Agent-based and Multi-agent Systems: Computational Social Choice Agent-based and Multi-agent Systems: Economic Paradigms, Auctions and Market-Based Systems},
  archive   = {C_IJCAI},
  author    = {Jiehua Chen and Sanjukta Roy and Manuel Sorge},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/13},
  pages     = {89-95},
  title     = {Fractional matchings under preferences: Stability and optimality},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Picking sequences and monotonicity in weighted fair
division. <em>IJCAI</em>, 82–88. (<a
href="https://doi.org/10.24963/ijcai.2021/12">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the problem of fairly allocating indivisible items to agents with different entitlements, which captures, for example, the distribution of ministries among political parties in a coalition government. Our focus is on picking sequences derived from common apportionment methods, including five traditional divisor methods and the quota method. We paint a complete picture of these methods in relation to known envy-freeness and proportionality relaxations for indivisible items as well as monotonicity properties with respect to the resource, population, and weights. In addition, we provide characterizations of picking sequences satisfying each of the fairness notions, and show that the well-studied maximum Nash welfare solution fails resource- and population-monotonicity even in the unweighted setting. Our results serve as an argument in favor of using picking sequences in weighted fair division problems. Keywords: Agent-based and Multi-agent Systems: Resource Allocation Agent-based and Multi-agent Systems: Computational Social Choice},
  archive   = {C_IJCAI},
  author    = {Mithun Chakraborty and Ulrike Schmidt-Kraepelin and Warut Suksompong},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/12},
  pages     = {82-88},
  title     = {Picking sequences and monotonicity in weighted fair division},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Approximating the shapley value using stratified empirical
bernstein sampling. <em>IJCAI</em>, 73–81. (<a
href="https://doi.org/10.24963/ijcai.2021/11">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Shapley value is a well recognised method for dividing the value of joint effort in cooperative games. However, computing the Shapley value is known to be computationally hard, so stratified sample-based estimation is sometimes used. For this task, we provide two contributions to the state of the art. First, we derive a novel concentration inequality that is tailored to stratified Shapley value estimation using sample variance information. Second, by sequentially choosing samples to minimize our inequality, we develop a new and more efficient method of sampling to estimate the Shapley value. We evaluate our sampling method on a suite of test cooperative games, and our results demonstrate that it outperforms or is competitive with existing stratified sample-based estimation approaches to computing the Shapley value. Keywords: Agent-based and Multi-agent Systems: Cooperative Games Uncertainty in AI: Uncertainty Representations},
  archive   = {C_IJCAI},
  author    = {Mark A. Burgess and Archie C. Chapman},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/11},
  pages     = {73-81},
  title     = {Approximating the shapley value using stratified empirical bernstein sampling},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Loyalty in cardinal hedonic games. <em>IJCAI</em>, 66–72.
(<a href="https://doi.org/10.24963/ijcai.2021/10">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A common theme of decision making in multi-agent systems is to assign utilities to alternatives, which individuals seek to maximize. This rationale is questionable in coalition formation where agents are affected by other members of their coalition. Based on the assumption that agents are benevolent towards other agents they like to form coalitions with, we propose loyalty in hedonic games, a binary relation dependent on agents&#39; utilities. Given a hedonic game, we define a loyal variant where agents&#39; utilities are defined by taking the minimum of their utility and the utilities of agents towards which they are loyal. This process can be iterated to obtain various degrees of loyalty, terminating in a locally egalitarian variant of the original game. We investigate axioms of group stability and efficiency for different degrees of loyalty. Specifically, we consider the problem of finding coalition structures in the core and of computing best coalitions, obtaining both positive and intractability results. In particular, the limit game possesses Pareto optimal coalition structures in the core. Keywords: Agent-based and Multi-agent Systems: Cooperative Games Agent-based and Multi-agent Systems: Computational Social Choice},
  archive   = {C_IJCAI},
  author    = {Martin Bullinger and Stefan Kober},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/10},
  pages     = {66-72},
  title     = {Loyalty in cardinal hedonic games},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Putting a compass on the map of elections. <em>IJCAI</em>,
59–65. (<a href="https://doi.org/10.24963/ijcai.2021/9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In their AAMAS 2020 paper, Szufa et al. presented a &quot;map of elections&quot; that visualizes a set of 800 elections generated from various statistical cultures. While similar elections are grouped together on this map, there is no obvious interpretation of the elections&#39; positions. We provide such an interpretation by introducing four canonical “extreme” elections, acting as a compass on the map. We use them to analyze both a dataset provided by Szufa et al. and a number of real-life elections. In effect, we find a new parameterization of the Mallows model, based on measuring the expected swap distance from the central preference order, and show that it is useful for capturing real-life scenarios. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice Agent-based and Multi-agent Systems: Voting},
  archive   = {C_IJCAI},
  author    = {Niclas Boehmer and Robert Bredereck and Piotr Faliszewski and Rolf Niedermeier and Stanisław Szufa},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/9},
  pages     = {59-65},
  title     = {Putting a compass on the map of elections},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Winner robustness via swap- and shift-bribery: Parameterized
counting complexity and experiments. <em>IJCAI</em>, 52–58. (<a
href="https://doi.org/10.24963/ijcai.2021/8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the parameterized complexity of counting variants of Swap- and Shift-Bribery, focusing on the parameterizations by the number of swaps and the number of voters. Facing several computational hardness results, using sampling we show experimentally that Swap-Bribery offers a new approach to the robustness analysis of elections. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice Agent-based and Multi-agent Systems: Voting},
  archive   = {C_IJCAI},
  author    = {Niclas Boehmer and Robert Bredereck and Piotr Faliszewski and Rolf Niedermeier},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/8},
  pages     = {52-58},
  title     = {Winner robustness via swap- and shift-bribery: Parameterized counting complexity and experiments},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Two influence maximization games on graphs made temporal.
<em>IJCAI</em>, 45–51. (<a
href="https://doi.org/10.24963/ijcai.2021/7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {To address the dynamic nature of real-world networks, we generalize competitive diffusion games and Voronoi games from static to temporal graphs, where edges may appear or disappear over time. This establishes a new direction of studies in the area of graph games, motivated by applications such as influence spreading. As a first step, we investigate the existence of Nash equilibria in competitive diffusion and Voronoi games on different temporal graph classes. Even when restricting our studies to temporal paths and cycles, this turns out to be a challenging undertaking, revealing significant differences between the two games in the temporal setting. Notably, both games are equivalent on static paths and cycles. Our two main technical results are (algorithmic) proofs for the existence of Nash equilibria in temporal competitive diffusion and temporal Voronoi games when the edges are restricted not to disappear over time. Keywords: Agent-based and Multi-agent Systems: Algorithmic Game Theory Agent-based and Multi-agent Systems: Noncooperative Games},
  archive   = {C_IJCAI},
  author    = {Niclas Boehmer and Vincent Froese and Julia Henkel and Yvonne Lasars and Rolf Niedermeier and Malte Renken},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/7},
  pages     = {45-51},
  title     = {Two influence maximization games on graphs made temporal},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Combining fairness and optimality when selecting and
allocating projects. <em>IJCAI</em>, 38–44. (<a
href="https://doi.org/10.24963/ijcai.2021/6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider the problem of the conjoint selection and allocation of projects to a population of agents, e.g. students are assigned papers and shall present them to their peers. The selection can be constrained either by quotas over subcategories of projects, or by the preferences of the agents themselves. We explore fairness and optimality issues and refine the analysis of the rank-maximality and popularity optimality concepts. We show that they are compatible with reasonable fairness requirements related to rank-based envy-freeness and can be adapted to select globally good projects according to the preferences of the agents. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice Agent-based and Multi-agent Systems: Resource Allocation},
  archive   = {C_IJCAI},
  author    = {Khaled Belahcène and Vincent Mousseau and Anaëlle Wilczynski},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/6},
  pages     = {38-44},
  title     = {Combining fairness and optimality when selecting and allocating projects},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning within an instance for designing high-revenue
combinatorial auctions. <em>IJCAI</em>, 31–37. (<a
href="https://doi.org/10.24963/ijcai.2021/5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We develop a new framework for designing truthful, high-revenue (combinatorial) auctions for limited supply. Our mechanism learns within an instance. It generalizes and improves over previously-studied random-sampling mechanisms. It first samples a participatory group of bidders, then samples several learning groups of bidders from the remaining pool of bidders, learns a high-revenue auction from the learning groups, and finally runs that auction on the participatory group. Previous work on random-sampling mechanisms focused primarily on unlimited supply. Limited supply poses additional significant technical challenges, since allocations of items to bidders must be feasible. We prove guarantees on the performance of our mechanism based on a market-shrinkage term and a new complexity measure we coin partition discrepancy. Partition discrepancy simultaneously measures the intrinsic complexity of the mechanism class and the uniformity of the set of bidders. We then introduce new auction classes that can be parameterized in a way that does not depend on the number of bidders participating, and prove strong guarantees for these classes. We show how our mechanism can be implemented efficiently by leveraging practically-efficient routines for solving winner determination. Finally, we show how to use structural revenue maximization to decide what auction class to use with our framework when there is a constraint on the number of learning groups. Keywords: Agent-based and Multi-agent Systems: Economic Paradigms, Auctions and Market-Based Systems},
  archive   = {C_IJCAI},
  author    = {Maria-Florina Balcan and Siddharth Prasad and Tuomas Sandholm},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/5},
  pages     = {31-37},
  title     = {Learning within an instance for designing high-revenue combinatorial auctions},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). PROPm allocations of indivisible goods to multiple agents.
<em>IJCAI</em>, 24–30. (<a
href="https://doi.org/10.24963/ijcai.2021/4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the classic problem of fairly allocating a set of indivisible goods among a group of agents, and focus on the notion of approximate proportionality known as PROPm. Prior work showed that there exists an allocation that satisfies this notion of fairness for instances involving up to five agents, but fell short of proving that this is true in general. We extend this result to show that a PROPm allocation is guaranteed to exist for all instances, independent of the number of agents or goods. Our proof is constructive, providing an algorithm that computes such an allocation and, unlike prior work, the running time of this algorithm is polynomial in both the number of agents and the number of goods. Keywords: Agent-based and Multi-agent Systems: Resource Allocation},
  archive   = {C_IJCAI},
  author    = {Artem Baklanov and Pranav Garimidi and Vasilis Gkatzelis and Daniel Schoepflin},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/4},
  pages     = {24-30},
  title     = {PROPm allocations of indivisible goods to multiple agents},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). School choice with flexible diversity goals and specialized
seats. <em>IJCAI</em>, 17–23. (<a
href="https://doi.org/10.24963/ijcai.2021/3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present a new and rich model of school choice with flexible diversity goals and specialized seats. The model also applies to other settings such as public housing allocation with diversity objectives. Our method of expressing flexible diversity goals is also applicable to other settings in moral multi-agent decision making where competing policies need to be balanced when allocating scarce resources. For our matching model, we present a polynomial-time algorithm that satisfies desirable properties, including strategyproofness and stability under several natural subdomains of our problem. We complement the results by providing a clear understanding about what results do not extend when considering the general model. Keywords: Agent-based and Multi-agent Systems: Economic Paradigms, Auctions and Market-Based Systems},
  archive   = {C_IJCAI},
  author    = {Haris Aziz and Zhaohong Sun},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/3},
  pages     = {17-23},
  title     = {School choice with flexible diversity goals and specialized seats},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Diversity in kemeny rank aggregation: A parameterized
approach. <em>IJCAI</em>, 10–16. (<a
href="https://doi.org/10.24963/ijcai.2021/2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In its most traditional setting, the main concern of optimization theory is the search for optimal solutions for instances of a given computational problem. A recent trend of research in artificial intelligence, called solution diversity, has focused on the development of notions of optimality that may be more appropriate in settings where subjectivity is essential. The idea is that instead of aiming at the development of algorithms that output a single optimal solution, the goal is to investigate algorithms that output a small set of sufficiently good solutions that are sufficiently diverse from one another. In this way, the user has the opportunity to choose the solution that is most appropriate to the context at hand. It also displays the richness of the solution space. When combined with techniques from parameterized complexity theory, the paradigm of diversity of solutions offers a powerful algorithmic framework to address problems of practical relevance. In this work, we investigate the impact of this combination in the field of Kemeny Rank Aggregation, a well-studied class of problems lying in the intersection of order theory and social choice theory and also in the field of order theory itself. In particular, we show that KRA is fixed-parameter tractable with respect to natural parameters providing natural formalizations of the notions of diversity and of the notion of a sufficiently good solution. Our main results work both when considering the traditional setting of aggregation over linearly ordered votes, and in the more general setting where votes are partially ordered. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice Agent-based and Multi-agent Systems: Voting},
  archive   = {C_IJCAI},
  author    = {Emmanuel Arrighi and Henning Fernau and Daniel Lokshtanov and Mateus de Oliveira Oliveira and Petra Wolf},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/2},
  pages     = {10-16},
  title     = {Diversity in kemeny rank aggregation: A parameterized approach},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Distance polymatrix coordination games. <em>IJCAI</em>, 3–9.
(<a href="https://doi.org/10.24963/ijcai.2021/1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In polymatrix coordination games, each player x is a node of a graph and must select an action in her strategy set. Nodes are playing separate bimatrix games with their neighbors in the graph. Namely, the utility of x is given by the preference she has for her action plus, for each neighbor y, a payoff which strictly depends on the mutual actions played by x and y. We propose the new class of distance polymatrix coordination games, properly generalizing polymatrix coordination games, in which the overall utility of player x further depends on the payoffs arising by mutual actions of players v, z that are the endpoints of edges at any distance h Keywords: Agent-based and Multi-agent Systems: Algorithmic Game Theory Agent-based and Multi-agent Systems: Computational Social Choice Agent-based and Multi-agent Systems: Noncooperative Games Keywords: Agent-based and Multi-agent Systems: Algorithmic Game Theory Agent-based and Multi-agent Systems: Computational Social Choice Agent-based and Multi-agent Systems: Noncooperative Games},
  archive   = {C_IJCAI},
  author    = {Alessandro Aloisio and Michele Flammini and Bojana Kodric and Cosimo Vinci},
  booktitle = {Thirtieth International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2021/1},
  pages     = {3-9},
  title     = {Distance polymatrix coordination games},
  year      = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
