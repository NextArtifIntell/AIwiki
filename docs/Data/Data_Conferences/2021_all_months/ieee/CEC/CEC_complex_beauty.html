<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>CEC_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="cec---324">CEC - 324</h2>
<ul>
<li><details>
<summary>
(2021). Parallel evolutionary algorithm for EEG optimization
problems. <em>CEC</em>, 2577–2584. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504925">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Big data optimization has become an important research topic in many disciplines. These optimization problems involve a large volume of data, from different sources, in different formats, that are generated at a high speed. For example, in the healthcare sector, electroencephalography (EEG), which is a method for monitoring brain signals and typically used to diagnose neurological disorders, generates a large amount of data which, however, is often captured with artifacts added from non-brain sources. Evolutionary algorithms are considered one of the most successful approaches for solving many such complex optimization problems. In this paper, a differential evolution algorithm is developed to remove artifacts from EEG signals of interest, by using the parallel computing ability of a Graphics Processing Unit. Two levels of parallelization, variable and individual, are implemented, with a gradient-based local search and adaptive control parameters incorporated in order to enhance a search’s convergence. The proposed algorithm is tested using six single objective problems from the 2015 big data optimization competition problems with 1024, 3072 and 4864 decision variables, as both noise-free and with white noise. The results presented in this paper indicate that the proposed algorithm is capable of achieving high-quality solutions, and is up to 374.7 faster than the state-of-the-art algorithms.},
  archive   = {C_CEC},
  author    = {Mohamed A. Meselhi and Saber M. Elsayed and Ruhul A. Sarker and Daryl L. Essam},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504925},
  pages     = {2577-2584},
  title     = {Parallel evolutionary algorithm for EEG optimization problems},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Training convolutional neural networks with differential
evolution using concurrent task apportioning on hybrid CPU-GPU
architectures. <em>CEC</em>, 2567–2576. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504878">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The core algorithm for training of Artificial Neural Nets (ANNs) continues to remain the back-propagation (BP) algorithm – to an extent that it is now considered as a paradigm of Deep Learning (DL). Many important facets of DL, like hierarchical construction of features across layers in image recognition, vanishing gradients, etc., are taken for granted without recognizing that these may implicitly be induced by BP itself. Evolutionary Algorithms (EAs) perform global optimization in contrast to localized gradient descent of BP. If used extensively for ANN training, they can potentially disrupt these assumed facets of DL – and construct alternative and interesting perspectives. But they are severely constrained by the need for large computational resources, as they work concurrently on a population of candidate solutions. The bulk of processing occurs in the forward pass through the ANN of thousands of data samples – which can be efficiently parallelized on GPUs. However, the candidates themselves can be launched in small groups on different CPU cores – by exploiting their natural concurrency. Here we explore the possibility of launching training of ANNs with EAs on hybrid CPU-GPU systems with candidates split across CPUs and samples across GPU threads. We conduct a series of experiments from which we synthesize a successful mechanism for orders-of-magnitude speedup of EAs through efficient apportioning of multi-level computing tasks onto different classes of processing elements. This enables analysis of DL using EAs empowering alternative interpretations of the above facets.},
  archive   = {C_CEC},
  author    = {Rochan Avlur Venkat and Zakaria Oussalem and Arya Kumar Bhattacharya},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504878},
  pages     = {2567-2576},
  title     = {Training convolutional neural networks with differential evolution using concurrent task apportioning on hybrid CPU-GPU architectures},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Large scale distributed optimization using apache spark:
Distributed scalable shade-bat (DistSSB). <em>CEC</em>, 2559–2566. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504853">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Large Scale Global Optimization (LSGO) is interesting for its applications in machine learning, e.g. in deep learning or knowledge graph embeddings. Evolutionary algorithms (EA) have been found efficient in solving complex optimization problems. However, the performance of conventional EAs degrades with the increasing number of decision variables due to the lack of scalability. This paper proposes a scalable, parallel, distributed and hybrid EA named Distributed Scalable Shade-BatScalable Shade Bat (DistSSB) to solve LSGO problems. DistSSB is inspired by the exploration capability of the SHADE algorithm and exploitation feature of the Bat algorithm (BA). To achieve scalability, DistSSB is implemented using the popular distributed in-memory framework, Apache Spark. DistSSB distributes its population into multiple sub-populations using the island model. Each sub-population is independently evolved using SHADE or BA. After the migration interval, the best solutions are broadcasted employing the mesh topology. We have compared the scalability, efficiency, and efficacy of DistSSB with SHADE-ILS (CEC-2018 Winner) and GL-SHADE algorithm on the CEC-2013 LSGO benchmark function suite.For most functions, DistSSB has obtained better optimization results in lesser execution time as compared to SHADE-ILS and GL-SHADE. We have tested and shown the scalability of DistSSB for up to &quot;one million&quot; dimensions, whereas SHADE-ILS and GLSHADE fail to scale up for larger problems.},
  archive   = {C_CEC},
  author    = {Fahad Maqbool and Saad Razzaq and Asif Yar and Hajira Jabeen},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504853},
  pages     = {2559-2566},
  title     = {Large scale distributed optimization using apache spark: Distributed scalable shade-bat (DistSSB)},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Caching and vectorization schemes to accelerate local search
algorithms for assignment problems. <em>CEC</em>, 2549–2558. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504700">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Assignment Problems are a class of NP-hard combinatorial optimization problems with a wide range of real-world applications such as Vehicle Routing and FPGA Block Placement. Despite technological advances, solvers that target Assignment Problems still require significant computing resources and time, especially as problem sizes grow. This paper introduces novel cost function formulations to leverage vector processing elements in accelerating local search algorithms for solving Quadratic Assignment and Semi-Assignment problems. We incorporate these vectorization methods within a Parallel Tempering framework to solve some of the most difficult known Quadratic Assignment and Semi-Assignment Problems up to sizes of 729 integer variables and show that this solver system can perform upwards of 300 times faster than other state-of-the-art solvers. We then conduct experiments to quantify the performance and scaling of these vectorization methods and qualify their situational strengths and trade-offs for use in future algorithms and hardware systems.},
  archive   = {C_CEC},
  author    = {Mohammad Bagherbeik and Ali Sheikholeslami},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504700},
  pages     = {2549-2558},
  title     = {Caching and vectorization schemes to accelerate local search algorithms for assignment problems},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). GPU-accelerated parallel gene-pool optimal mixing applied to
multi-objective deformable image registration. <em>CEC</em>, 2539–2548.
(<a href="https://doi.org/10.1109/CEC45853.2021.9504840">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Real-Valued Gene-pool Optimal Mixing Evolutionary Algorithm (RV-GOMEA) has previously been successfully used to achieve highly scalable optimization of various real-world problems in a gray-box optimization setting. Deformable Image Registration (DIR) is a multi-objective problem, aimed at finding the most likely non-rigid deformation of a given source image so that it matches a given target image. We specifically consider the case where the deformation model allows for finite-element-type modeling of tissue properties. This optimization problem is non-smooth, necessitating techniques like EAs to get good results. Though the objectives of DIR are non-separable, non-neighboring regions of the deformation grid are conditionally independent. We show that GOMEA allows to exploit such knowledge through the large-scale parallel application of variation steps, where each is only accepted when leading to an improvement, on a Graphics Processing Unit (GPU). On various 2-dimensional DIR problems, we find that this way, similar results can be achieved as when sequential processing is performed, while allowing for substantial speed-ups (up to a factor of 111) for the highest-dimensional problems (i.e., the highest deformation-grid resolution). This work opens the door to the extension of this type of DIR to larger (3-dimensional) deformation grids, and its application to other real-world problems.},
  archive   = {C_CEC},
  author    = {Anton Bouter and Tanja Alderliesten and Peter A.N. Bosman},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504840},
  pages     = {2539-2548},
  title     = {GPU-accelerated parallel gene-pool optimal mixing applied to multi-objective deformable image registration},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Random selection of parameters in asynchronous pool-based
evolutionary algorithms. <em>CEC</em>, 2531–2538. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504880">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Synchronous operation is not the most natural, as in biologically inspired, mode to run distributed algorithms. In many grid, cloud or volunteer setups nodes are heterogeneous, or simply are not available at the exact same time; this is a challenge for the researcher if their full performance is going to be actually leveraged. Asynchronous distributed evolutionary algorithms try to solve this by dropping the homogeneity, as well as the synchronicity, assumption. These algorithms share the population between distributed workers which execute the actual evolutionary process by taking samples of the population, and replacing them in the population pool by evolved individuals. The performance of these EAs depends in part on the selection of parameters for the EA running in each worker. In this paper we study how randomly varying parameters in distributed evolutionary algorithms affects performance. Experiments were conducted in the AWS cloud using 2, 6 and 12 virtual machine configurations, with both homogeneous and heterogeneous random settings using five test functions for real-valued optimization and the OneMax binary problem. The results suggest that this method can produce a performance that is competitive with instances of the algorithm using workers with parameters specially tuned for the benchmark.},
  archive   = {C_CEC},
  author    = {Mario García-Valdez and René Márquez and Leonardo Trujillo and J.J. Merelo},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504880},
  pages     = {2531-2538},
  title     = {Random selection of parameters in asynchronous pool-based evolutionary algorithms},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Differential evolution neural network optimization with
individual dependent mechanism. <em>CEC</em>, 2523–2530. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504713">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With the increase of scenes where Neural Networks are used as a classifier, the expectation of the classifying accuracy for the network has risen. To improve classifying accuracy, Differential Evolution (DE) has been applied as an optimization method for Neural Networks. Compared to other DE methods, Differential Evolution with an Individual-Dependent Mechanism (IDE) takes in account of the differences between the fitness value of individuals. As a result, IDE has better results in terms of accuracy. Therefore in this paper, a Neural Network optimizer using IDE is proposed for further Neural Network improvement. Moreover, while most optimizers would use the loss function as the fitness value in DE, a method using accuracy is proposed because DE does not require the activation function to be differentiable. Experiments using the proposed framework has been conducted on classification problems, and comparative studies with other self-adaptive mutations and traditional optimizing methods have been performed. Experimental results showed that the proposed method outperformed other conventional methods in terms of accuracy.},
  archive   = {C_CEC},
  author    = {Naoya Ikushima and Keiko Ono and Yuya Maeda and Erina Makihara and Yoshiko Hanada},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504713},
  pages     = {2523-2530},
  title     = {Differential evolution neural network optimization with individual dependent mechanism},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An immuno-inspired transfer learning paradigm. <em>CEC</em>,
2515–2522. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504697">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Transfer learning in Artificial Neural Networks (ANN) is performed by transferring some or all the layers of neurons from within an already learned source ANN, to a target ANN which is then made to learn a new domain. Though such transfers are known to accelerate the convergence of the target ANN, there is no hard and fast method to ascertain which of the neurons or layers need to be transferred. While most methods advocate the transfer of complete layers of neurons, this paper describes an Immuno-inspired transfer learning paradigm that aids in ascertaining the pertinent or Hot neurons which when transferred facilitate faster convergence of a target ANN. The method uses the concept of an Idiotypic Network to evolve the temperatures associated with neurons within the various layers of the source ANN. Temperatures of those neurons which contribute more to the learning, increase making them hotter. This paper also presents results obtained from experiments performed on dissimilar datasets using this method, which clearly authenticate its efficacy.},
  archive   = {C_CEC},
  author    = {Divya D. Kulkarni and Shivashankar B. Nair},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504697},
  pages     = {2515-2522},
  title     = {An immuno-inspired transfer learning paradigm},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep neural network guided evolution of l-system trees.
<em>CEC</em>, 2507–2514. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504827">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Lindenmayer systems (L-systems) are mathematical formalisms used for generating recursive structures. They are particularly effective for defining realistic tree and plant models. It takes experience to use L-systems effectively, however, as the final rendered results are often difficult to predict. This research explores the use of genetic programming (GP) and deep learning towards the automatic evolution of L-system expressions that render 2D tree designs. As done before by other researchers, the L-system language is easily defined and manipulated by the GP system. It is challenging, however, to determine a fitness function to evaluate the suitability of evolved expressions. We train a deep convolutional neural network (CNN) to recognize suitable trees rendered in the style of the L-system language. Experiments explore a number of deep CNN strategies. Results in some experiments are very promising, as images conforming to specified styles of tree species were often produced. We found that underspecifying or over-complicating the training requirements can arise, and the results become unsatisfactory in such cases. Our results also confirm that of other researchers, in that deep learning can be fooled by evolutionary algorithms, and the criteria for success learned by deep neural networks might not conform with those of human users.},
  archive   = {C_CEC},
  author    = {Xuhao Eric Chen and Brian J. Ross},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504827},
  pages     = {2507-2514},
  title     = {Deep neural network guided evolution of L-system trees},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive navigation strategies in evolutionary robotics
controllers with location perception. <em>CEC</em>, 2499–2506. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504759">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This research proposed augmenting Evolutionary Robotics controllers with their own robotic simulator. The motivation behind this idea is that the controller could use the simulator to approximate the effects of its actions. This would allow the controller to maintain an approximation of the robot’s location and orientation. It was hypothesised that this information could enhance a controller’s navigation ability. Both regular and augmented controllers were tested and compared on a task that required them to employ adaptive navigation strategies to efficiently solve the task. Augmented controllers were shown to perform better and possess superior behaviours in comparison to regular controllers.},
  archive   = {C_CEC},
  author    = {Antin Phillips and Mathys C. Du Plessis},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504759},
  pages     = {2499-2506},
  title     = {Adaptive navigation strategies in evolutionary robotics controllers with location perception},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An immune-inspired approach to macro-level neural ensemble
search. <em>CEC</em>, 2491–2498. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504955">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent years have seen a renewed interest in evolutionary computation applied to the automatic design of deep neural network architectures, i.e. Neural Architecture Search (NAS). The advantages of evolutionary approaches in NAS include their conceptual simplicity and their flexibility with regards to search space definition and/or optimization objective.However, Artificial Immune Systems (AIS) that follow the evolutionary computation paradigm are less explored in NAS. In this research, we aim to leverage their intrinsic and excellent ability to balance performance and population diversity to develop a novel Neural Ensemble Search method, based on the Clonal Selection Algorithm [1]. For more generality, we focus on designing macro-architectures rather than architectural components.Experiments on popular computer vision benchmarks demonstrate that our method reaches competitive accuracy and efficiency despite minimal augmentation and post-processing. We show that the AIS brings tangible benefits, including maintaining the diversity of solutions, a semantically straightforward implementation, and high efficiency. Moreover, this AIS can exhibit a &quot;secondary response&quot;: when presented with a related but more difficult task, the ensemble will perform competently with zero modification to the architectures or the training protocol.},
  archive   = {C_CEC},
  author    = {Luc Frachon and Wei Pang and George M. Coghill},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504955},
  pages     = {2491-2498},
  title     = {An immune-inspired approach to macro-level neural ensemble search},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Building HVAC control via neural networks and natural
evolution strategies. <em>CEC</em>, 2483–2490. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504800">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Buildings are the highest consumers of electrical energy globally. Developing effective control strategies to enhance the operation of buildings to increase their energy efficiency has therefore become a very active area of research. This research proposes the use of evolutionary neural networks for the task of Heating Ventilation and Air Conditioning control. A neural network controller is trained using the exponential Natural Evolutionary Strategy algorithm is proposed. Its performance is bench-marked against multiple state of the art control strategies, including: a Genetic Algorithm trained neural network, the popular Deep Q-Network reinforcement learning algorithm and also a threshold based control policy. The results presented demonstrate that evolutionary neural networks are an effective strategy for reducing energy consumption while also minimizing thermal discomfort. The energy consumption and thermal discomfort achieved by evolutionary neural networks, are significantly lower than when using Deep Q-Network. This is particularly true for the Natural Evolutionary Strategy algorithm.},
  archive   = {C_CEC},
  author    = {Karl Mason and Santiago Grijalva},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504800},
  pages     = {2483-2490},
  title     = {Building HVAC control via neural networks and natural evolution strategies},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Many layer transfer learning genetic algorithm (MLTLGA): A
new evolutionary transfer learning approach applied to pneumonia
classification. <em>CEC</em>, 2476–2482. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504912">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Convolutional Neural Networks (CNNs) are considered the state-of-the-art in computer vision tasks, being able to surpass human performance in certain applications. The use of this technology in medical applications for automated or aided diagnosis of diseases is promising, especially in radiotherapy- based images. One of the most deadly diseases, Pneumonia, can be diagnosed from chest x-ray images. However, the use of Deep Learning relies on a huge amount of data to build models. In order to leverage the transferable knowledge from neural networks, transfer learning is usually used to create models from pre-trained networks on different source datasets. In this paper, a novel genetic algorithm (GA), Many Layer Transfer Learning Genetic Algorithm (MLTLGA), is proposed to select the trainable layers of the InceptionV3 CNN architecture to build a classifier of Pneumonia images from chest x-ray images. The MLTLGA shows better performance than other Genetic Algorithms in the literature and conventional transfer learning methods, providing a promising framework for applications that rely on Transfer Learning. The experiments show that the proposed method is at least 2\% more accurate than similar evolutionary approaches and transfer learning, more specifically, last layer training.},
  archive   = {C_CEC},
  author    = {Raphael de Lima Mendes and Alexandre Henrick da Silva Alves and Matheus de Souza Gomes and Pedro Luiz Lima Bertarini and Laurence Rodrigues do Amaral},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504912},
  pages     = {2476-2482},
  title     = {Many layer transfer learning genetic algorithm (MLTLGA): A new evolutionary transfer learning approach applied to pneumonia classification},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A two-stage hypervolume contribution approximation method
based on r2 indicator. <em>CEC</em>, 2468–2475. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504726">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Hypervolume-based multi-objective evolutionary algorithms (HV-MOEAs) are one of the popular algorithm classes in the evolutionary multi-objective optimization (EMO) com-munity. HV-MOEAs, which can directly optimize the HV of a solution set, are useful in various applications. However, the computation time of HV-MOEAs is very long for many-objective problems since the calculation of the hypervolume contribution (HVC) is computationally expensive. Therefore, a number of approximation methods for the HVC calculation were proposed to reduce its time cost. An R2-based hypervolume contribution approximation (R2-HVC) method was proposed for HVC approximation. However, for HV-MOEAs, the point is to find the worst solution, instead of accurately approximating the HVC of each solution. In this paper, a novel method (i.e., two-stage R2-HVC) is proposed for improving the ability of R2-HVC to correctly identify the worst solution (i.e., the solution with the smallest HVC value) in a solution set. In the proposed method, some candidate solutions are selected based on rough HVC approximation in the first stage, and they are carefully evaluated in the second stage. It is shown through computational experiments that the proposed method performs much better than the original R2-HVC method.},
  archive   = {C_CEC},
  author    = {Yang Nan and Ke Shang and Hisao Ishibuchi and Linjun He},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504726},
  pages     = {2468-2475},
  title     = {A two-stage hypervolume contribution approximation method based on r2 indicator},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An ensemble of scalarizing functions and weight vectors for
evolutionary multi-objective optimization. <em>CEC</em>, 2459–2467. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504941">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Ensembles have been used in the evolutionary computation literature to evolve several populations in an independent manner, using different search approaches. Moreover, each population’s parents compete with their offspring and the other population’s offspring to improve diversity. It has been shown that ensemble algorithms improve the performance of the techniques embedded within them, when considered independently. Furthermore, scalarizing functions have been successfully used in decomposition-based and some indicator-based Multi-objective Evolutionary Algorithms (MOEAs). However, it has been shown that the performance of scalarizing function tends to be tied to the geometrical shape of the Pareto front. In this work, we propose a new ensemble algorithm that adopts different scalarizing functions and weight vectors using Hungarian Differential Evolution as the baseline multi-objective optimizer. Our experimental study shows that our proposed approach outperforms the original HDE, and it is competitive with respect to modern MOEAs.},
  archive   = {C_CEC},
  author    = {Diana Cristina Valencia-Rodríguez and Carlos A. Coello Coello},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504941},
  pages     = {2459-2467},
  title     = {An ensemble of scalarizing functions and weight vectors for evolutionary multi-objective optimization},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hypervolume by slicing objective algorithm: An improved
version. <em>CEC</em>, 2451–2458. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504725">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The hypervolume remains a popular performance indicator in evolutionary multi-objective, mainly because of its nice mathematical properties (i.e., it’s the only performance indicator known to be Pareto-compliant). However, its high computational cost (which grows polynomially on the population size but exponentially on the number of objectives) has severely limited its use in many-objective optimization. This has motivated a variety of proposals that attempt to overcome this limitation. One of the most popular proposals currently available is the so-called Hypervolume by Slicing Objectives (HSO) algorithm. Here, we show that the worst-case time complexity of the HSO algorithm, as obtained by its authors, is incorrect. Then, we provide an efficient implementation of the HSO algorithm, which guarantees that unique slices are generated to compute the hypervolume.},
  archive   = {C_CEC},
  author    = {Sumit Mishra and Srinibas Swain and Sangita Sarmah and Carlos A. Coello Coello},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504725},
  pages     = {2451-2458},
  title     = {Hypervolume by slicing objective algorithm: An improved version},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evolutionary inherited neuromodulated neurocontrollers with
objective weighted ranking. <em>CEC</em>, 2443–2450. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504892">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the physical world, individuals compete against others within their own population or separately evolving populations. Robotic agents will soon face this coevolutionary and adversarial reality. Many challenges not encountered in the evolution of single populations are encountered in adversarial coevolution. These challenges can render single evolutionary approaches either less effective or ineffective. Most problems have a fundamental goal, but also feature secondary desirable objectives. Here, evader agents in the pursuit-evasion game that do not elude capture are effectively useless. Secondly, when applied to evolve real robots online in a coevolutionary context, non-optimal robots can be erratic and cause damage. Objective hierarchy can be used to define the importance of each objective, and promote quicker optimization of primary objectives such as evasion. The Evolutionary Inherited Neuromodulated Neurocontroller (EINN) method incorporates objective weighted ranking (OWR), a novel objective hierarchy method that promotes optimization of the primary objective in simultaneous multi-objective optimization. EINN is compared to the previously demonstrated Lamarckian-inherited Neuromodulated MultiObjective Evolutionary Neurocontroller (LNMOEN), and shown to be effective in a single evolutionary context.},
  archive   = {C_CEC},
  author    = {Ian Showalter and Howard Schwartz and Sidney N. Givigi},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504892},
  pages     = {2443-2450},
  title     = {Evolutionary inherited neuromodulated neurocontrollers with objective weighted ranking},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A reduced mixed representation based multi-objective
evolutionary algorithm for large-scale overlapping community detection.
<em>CEC</em>, 2435–2442. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504894">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In recent years, the application of multi-objective evolutionary algorithms (MOEAs) to overlapping community detection in complex networks has been a hot research topic. However, the existing MOEAs for detecting overlapping communities show poor scalability to large-scale networks due to the fact that the encoding length of individuals is usually equal to the number of all nodes in the network. To this end, we suggest a reduced mixed representation based multi-objective evolutionary algorithm named RMR-MOEA for large-scale overlapping community detection, where the length of the individual is recursively reduced as the evolution proceeds. Specifically, a mixed representation is adopted for fast encoding and decoding the individual in the population, which consists of two parts: one represents all potential overlapping nodes and the other represents all non-overlapping nodes. Then, in each individual length reduction, two strategies are suggested to respectively shorten the length of each part in the mixed representation, with the aim to greatly reduce the search space. Finally, the experimental results on 10 real-world complex networks demonstrate the effectiveness of the proposed RMR-MOEA in terms of both detection performance and running time, especially on large-scale networks.},
  archive   = {C_CEC},
  author    = {Yongkang Luo and Kening Zhang and Haipeng Yang and Feng Liu and Shuai Luo and Lei Zhang and Xiaoyan Sun},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504894},
  pages     = {2435-2442},
  title     = {A reduced mixed representation based multi-objective evolutionary algorithm for large-scale overlapping community detection},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An approximated domination relationship based on binary
classifiers for evolutionary multiobjective optimization. <em>CEC</em>,
2427–2434. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504781">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Preselection is an important strategy to improve evolutionary algorithms’ performance by filtering out unpromising solutions before fitness evaluations. This paper introduces a pre-selection strategy based on an approximated Pareto domination relationship for multiobjective evolutionary optimization. For each objective, a binary relation between each pair of solutions is constructed based on the current population, and a binary classifier is built based on the binary relation pairs. In this way, an approximated Pareto domination relationship can be defined. When new trial solutions are generated, the approximated Pareto domination is used to select promising solutions, which shall be evaluated by the real objective functions. The new preselection is integrated into two algorithms. The experimental results on two benchmark test suites suggest that the algorithms with preselection outperform their original ones.},
  archive   = {C_CEC},
  author    = {Hao Hao and Aimin Zhou and Hu Zhang},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504781},
  pages     = {2427-2434},
  title     = {An approximated domination relationship based on binary classifiers for evolutionary multiobjective optimization},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Temporal specification mining for IEC 61499 function blocks
using evolutionary algorithms and model checking. <em>CEC</em>,
2419–2426. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504765">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Model checking allows rigorously checking the compliance of a software model with a given formal specification described with temporal logics. In control applications, model checking is used for formal verification of controller code, and temporal logic is used as a formal specification language. However, not all industrial projects start with the creation of a formal specification. On the contrary, often model checking is introduced at later stages of project development, and formal specifications need to be written for already existing legacy code.In this work we developed a framework for automating the process of formal specification preparation for IEC 61499 function blocks, a programming language used in the area of industrial automation. The developed framework is based on multiobjective evolutionary algorithms and model checking, and allows inference of linear temporal logic formulas for basic IEC 61499 function blocks. Our experiments show that the temporal specifications generated by the proposed framework sufficiently approximate existing, manually prepared specifications.},
  archive   = {C_CEC},
  author    = {Daniil Chivilikhin},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504765},
  pages     = {2419-2426},
  title     = {Temporal specification mining for IEC 61499 function blocks using evolutionary algorithms and model checking},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Coverage-based grammar-guided genetic programming generation
of test suites. <em>CEC</em>, 2411–2418. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504969">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Software testing is fundamental to ensure the reliability of software. To properly test software, it is critical to generate test suites with high fault finding ability. We propose a new method to generate such test suites: a coverage-based grammar-guide genetic programming algorithm. This evolutionary computation based method allows us to generate test suites that conform with respect to a specification of the system under test using the coverage of such test suites as a guide. We considered scenarios for both black-box testing and white-box testing, depending on the different criteria we work with at each situation. Our experiments show that our proposed method outperforms other baseline methods, both in performance and execution time.},
  archive   = {C_CEC},
  author    = {Alfredo Ibias and Pablo Vazquez-Gomis and Miguel Benito-Parejo},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504969},
  pages     = {2411-2418},
  title     = {Coverage-based grammar-guided genetic programming generation of test suites},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Using genetic algorithms to select test cases for finite
state machines with timeouts. <em>CEC</em>, 2403–2410. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504764">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Testing software is an expensive and time consuming task. This drawback increases in the case that the system presents timeouts which affect the functional behaviour. In this case, it is necessary to invest more time to apply the test cases. Thus, it is desirable to diminish the amount of test cases to be applied and, consequently, the time devoted to test the system, as long as the fault detection capacity of the test cases is not affected. In this work, we introduce a genetic algorithm that selects a subset of test cases from an initial test suite for systems that present timeouts, with the goal of keeping a good level of effectiveness. We report on several experiments performed to compare the generated solutions with random selection and the original test suite.},
  archive   = {C_CEC},
  author    = {Miguel Benito-Parejo and Mercedes G. Merayo},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504764},
  pages     = {2403-2410},
  title     = {Using genetic algorithms to select test cases for finite state machines with timeouts},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Interactivity in the generation of test cases with
evolutionary computation. <em>CEC</em>, 2395–2402. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504786">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Test generation is a costly but necessary testing activity to increase the quality of software projects. Automated testing tools based on evolutionary computation principles constitute an appealing modern approach to support testing tasks. However, these tools still find difficulties to detect certain types of plausible faults in real-world projects. Besides, recent studies have shown that, in general, automatically-generated tests do not resemble those manually written and, consequently, testers are reluctant to adopt them. We observe two key issues, namely the opacity of the process and the lack of cooperation with the tester, currently hampering the acceptance of automated results. Based on these findings, we explore in this paper how the interaction between current tools and expert testers would help address the test case generation problem. More specifically, we identify a number of interaction opportunities related to the object-oriented test case design driven to boost their readability and detection power. Using EvoSuite as base implementation, we present a proof of concept focused on the possibility to integrate readability assessment of the most promising test suites into a genetic algorithm.},
  archive   = {C_CEC},
  author    = {Aurora Ramírez and Pedro Delgado-Pérez and Kevin J. Valle-Gómez and Inmaculada Medina-Bulo and José Raúl Romero},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504786},
  pages     = {2395-2402},
  title     = {Interactivity in the generation of test cases with evolutionary computation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Performance testing using a smart reinforcement
learning-driven test agent. <em>CEC</em>, 2385–2394. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504763">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Performance testing with the aim of generating an efficient and effective workload to identify performance issues is challenging. Many of the automated approaches mainly rely on analyzing system models, source code, or extracting the usage pattern of the system during the execution. However, such information and artifacts are not always available. Moreover, all the transactions within a generated workload do not impact the performance of the system the same way, a finely tuned workload could accomplish the test objective in an efficient way. Model-free reinforcement learning is widely used for finding the optimal behavior to accomplish an objective in many decision-making problems without relying on a model of the system. This paper proposes that if the optimal policy (way) for generating test workload to meet a test objective can be learned by a test agent, then efficient test automation would be possible without relying on system models or source code. We present a self-adaptive reinforcement learning-driven load testing agent, RELOAD, that learns the optimal policy for test workload generation and generates an effective workload efficiently to meet the test objective. Once the agent learns the optimal policy, it can reuse the learned policy in subsequent testing activities. Our experiments show that the proposed intelligent load test agent can accomplish the test objective with lower test cost compared to common load testing procedures, and results in higher test efficiency.},
  archive   = {C_CEC},
  author    = {Mahshid Helali Moghadam and Golrokh Hamidi and Markus Borg and Mehrdad Saadatmand and Markus Bohlin and Björn Lisper and Pasqualina Potena},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504763},
  pages     = {2385-2394},
  title     = {Performance testing using a smart reinforcement learning-driven test agent},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Unsupervised learning for refactoring pattern detection.
<em>CEC</em>, 2377–2384. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504804">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Software refactoring changes the structure of a program without modifying its external behavior, generally intending to improve software quality attributes. However, refactoring is a complex activity and, many times, a composition of refactorings is necessary. Besides, some code elements are refactored similarly, considering the kind and frequency of refactorings applied. Works in the refactoring literature usually investigate the impact and understanding of an individual refactoring, neglecting that developers have to apply more than one refactoring operation to reach their goals. There is a lack of studies to identify and characterize refactoring patterns. To fulfill this gap, this work explores the use of unsupervised learning, particularly cluster analysis, to group elements (Java classes) that are refactored similarly in software repositories. We used a total of 1435 projects and applied the K-Means algorithm to group classes that received the same refactoring with the same frequency. We obtained a set of seven clusters. Then, the main refactoring compositions associated with each cluster are analyzed to identify the corresponding pattern. Each pattern is described and also characterized using a set of metrics. The great majority of refactoring compositions include only one kind of refactoring, applied with low frequency. If we consider compositions including more than one type of refactorings, combinations of Extract Superclass and Pull Up Method are the most frequent.},
  archive   = {C_CEC},
  author    = {Paulo Roberto Farah and Thainá Mariani and Enrique A. da Roza and Rogério C. Silva and Silvia Regina Vergilio},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504804},
  pages     = {2377-2384},
  title     = {Unsupervised learning for refactoring pattern detection},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cultural weight-based fish school search: A flexible
optimization algorithm for engineering. <em>CEC</em>, 2370–2376. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504779">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Many real-life engineering applications are optimization problems. To find the best configuration of variables to minimize costs and maximize efficiency are typically used engineering software as CAD, CAE and CAM. In this context, Machine Learning can be used to automate and improve this type of application. This despite, those searches not seldomly evoke unreliable areas and suggest risky solutions. Because of inaccuracies, volatility, unfeasibility, and specificities of real environments, the easy incorporation of cultural practices (i.e. normative, situational, domain and historic knowledge) and as well as the production of multiple acceptable solutions for a problem is always welcome, especially in Engineering. The present article put forward a hybridization of a multi-modal algorithm (Weight-Based Fish School Search - wFSS) with Cultural Algorithms&#39; belief space. New cwFSS is able to guide the optimization also considering normative knowledge from experts, technical literature and problem domain readily available knowledge to prevent the incorporation of constraints into the fitness function. We also evaluated the use of temporal knowledge to guide the simulation. The proposed method was tested in a thermal power plant efficiency optimization and compared with standard wFSS and the Niching Migratory Multi-Swarm Optimizer (NMMSO), winner of CEC&#39;2015 niching competition. As results, cwFSS has outperformed at times NMMSO about time, fitness and variability, as well as traditional wFSS about time, stability, safeness and variability of the multimodal solutions. By avoiding penalties, the appropriation of a priori search directly into the search can effectively and elegantly help better support for engineering decisions.},
  archive   = {C_CEC},
  author    = {João L. Vilar-Dias and M. A. S. Galindo and Fernando B. Lima-Neto},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504779},
  pages     = {2370-2376},
  title     = {Cultural weight-based fish school search: A flexible optimization algorithm for engineering},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Intelligent-guided adaptive search for the traveling
backpacker problem. <em>CEC</em>, 2362–2369. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504937">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The solution of combinatorial problems has been largely performed by heuristics for their ability to obtain good solutions faster than exact methods. In this paper, we propose heuristic methods to approach a hard-to-solve combinatorial optimization problem. The target routing problem is the recently proposed Traveling Backpacker Problem (TBP), which has not been investigated by a heuristic method yet. The difficulty in constructing feasible solutions for such a problem drove us to approach the TBP by a metaheuristic with a learning stage in the search, the Intelligent Greedy Adaptive Search (IGAS). To validate the introduced solution methods, they were compared to the exact solution obtained by CPLEX. Besides, we analyze isolate parts of the methods to infer about the performance of the construction of the solution and the local search, the main phases of IGAS. The results of computational experiments show that IGAS outperformed the other introduced methods in small-sized and medium-sized instances, being competitive in larger instances. Moreover, IGAS presented reasonable gaps to the solutions obtained by the exact commercial solver.},
  archive   = {C_CEC},
  author    = {Calvin Rodrigues da Costa and Mariá C. V. Nascimento},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504937},
  pages     = {2362-2369},
  title     = {Intelligent-guided adaptive search for the traveling backpacker problem},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). ISklearn: Automated machine learning with irace.
<em>CEC</em>, 2354–2361. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504696">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Automated algorithm engineering has become an important asset for academia and industry. irace, for instance, is an algorithm configurator (AC) that has successfully designed effective algorithms for optimization problems. The major advantage of irace is combining learning and parallelization, but no fully-functional automated machine learning (AutoML) system powered by irace has yet been proposed. This is rather striking, as some of the most relevant existing AutoML tools are powered by ACs, of which irace is one of the most effective examples.In this work, we propose iSklearn, an irace-powered AutoML system. Our proposal improves existing work applying an AC to engineer a machine learning (ML) pipeline. First, our configuration space represents a minimalist pipeline template, demonstrating that simpler pipelines can be competitive with elaborate approaches (e.g. ensembles). Second, our configuration setup improves the application of AC-based AutoML to time series (TS) problems, and is more flexible to fit other applications.We evaluate iSklearn on three major ML domains, namely computer vision (CV), natural language processing (NLP), and TS. Results prove competitive to AUTOSKLEARN, a state-of-the-art AutoML system also built on scikit-learn. Furthermore, the compositions of the pipelines devised vary with the problem domain and dataset considered, providing further evidence for the need of AutoML tools. We conclude our investigation ablating through the proposed configuration space and setup to understand their impact on the performance of iSklearn.},
  archive   = {C_CEC},
  author    = {Carlos Vieira and Adelson de Araújo and José E. Andrade and Leonardo C. T. Bezerra},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504696},
  pages     = {2354-2361},
  title     = {ISklearn: Automated machine learning with irace},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Two stage quantum optimization for the school timetabling
problem. <em>CEC</em>, 2347–2353. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504701">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Timetabling is an NP-Hard problem that searches for periodic scheduling of events that must meet a set of hard and soft constraints. Because of the difficulty in finding an exact solution, the use of heuristics to address the problem is a common practice. When only the hard constraints are considered, the timetabling problem can be reduced to graph vertex coloring. This similarity between both problems has motivated the use of graph coloring heuristics as a means to solve the timetabling problem. We propose the use of the Quantum Approximate Optimization Algorithm as a heuristic to solve the school timetabling problem. The QAOA is a hybrid quantum-classical algorithm that can be used to address combinatorial optimization problems. We simulated QAOA in a minimal example with 42 qubits using the Ket Quantum Programming Language and our results showed that it is possible to apply QAOA to the school timetabling problem.},
  archive   = {C_CEC},
  author    = {Otto Menegasso Pires and Rafael de Santiago and Jerusa Marchi},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504701},
  pages     = {2347-2353},
  title     = {Two stage quantum optimization for the school timetabling problem},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A multi-objective iterated local search approach to solve
the insular traveling salesman problem. <em>CEC</em>, 2339–2346. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504830">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this work, we solve the bi-objective insular traveling salesman problem, which arises when a barge collects the waste generated by a set of islands. It considers selection and routing decisions coming from the selection of docks to be visited and the sequence of visits performed by the barge. Moreover, the cost of the tour performed by the barge and the waste ground transportation costs are minimized in a multi-objective approach. In this work, we propose a local search multi-objective approach to find approximations of the Pareto sets of efficient solutions. It uses an iterated local search method to find solutions in several areas of the front based on a weighted sum approach. We evaluated the performance of our proposal on a set of real-world problem instances from twenty-one islands in the south of Chile. Our results demonstrated the ability of the proposed approach to find high-quality approximations of the Pareto sets for all the problem instances evaluated in reduced times compared to an exact approach.},
  archive   = {C_CEC},
  author    = {Sebastián Rodríguez-Zbinden and Elizabeth Montero and Carola Blázquez and Pablo Miranda},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504830},
  pages     = {2339-2346},
  title     = {A multi-objective iterated local search approach to solve the insular traveling salesman problem},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An adaptive and near parameter-free BRKGA using q-learning
method. <em>CEC</em>, 2331–2338. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504766">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Biased Random-Key Genetic Algorithm (BRKGA) is an efficient metaheuristic to solve combinatorial optimization problems but requires parameter tuning so the intensification and diversification of the algorithm work in a balanced way. There is, however, not only one optimal parameter configuration, and the best configuration may differ according to the stages of the evolutionary process. Hence, in this research paper, a BRKGA with Q-Learning algorithm (BRKGA-QL) is proposed. The aim is to control the algorithm parameters during the evolutionary process using Reinforcement Learning, indicating the best configuration at each stage. In the experiments, BRKGA-QL was applied to the symmetric Traveling Salesman Problem, and the results show the efficiency and competitiveness of the proposed algorithm.},
  archive   = {C_CEC},
  author    = {Antônio Augusto Chaves and Luiz Henrique Nogueira Lorena},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504766},
  pages     = {2331-2338},
  title     = {An adaptive and near parameter-free BRKGA using Q-learning method},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A random walk analysis of search in metaheuristics.
<em>CEC</em>, 2323–2330. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504687">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Random walks are a useful modeling tool for stochastic processes. The addition of model features (e.g. finite travel in one direction) can provide insight into specific practical situations (e.g. gambler&#39;s ruin). A series of random walk experiments are designed to study the effects of selection, exploration, and exploitation during the search processes of metaheuristics. We present a set of random walk conditions which leads to greater movement as the dimensionality of the sampling distributions increases. We then implement a version of Simulated Annealing in a similar search space which also achieves improving performance with increasing dimensionality. Conversely, we show that standard Particle Swarm Optimization has decreasing performance with increasing dimensionality which is consistent with the expected effects of the Curse of Dimensionality. These experiments give us insights into future methods that metaheuristics might be able to employ to defeat the Curse of Dimensionality (in globally convex, continuous domain search spaces).},
  archive   = {C_CEC},
  author    = {Stephen Chen and Shehnaz Islam and Antonio Bolufé-Röhler and James Montgomery and Tim Hendtlass},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504687},
  pages     = {2323-2330},
  title     = {A random walk analysis of search in metaheuristics},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A graph-based approach for shepherding swarms with limited
sensing range. <em>CEC</em>, 2315–2322. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504706">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Within applications of swarm control, failing to maintain cohesion amongst the agents may lead to mission failure. We study the effect of limited sensing range of swarming agents when guided by a shepherd. A connectivity-aware approach is proposed to enhance the cohesion of the swarm. We combine a graph-based model of the flock with particle swarm optimization (assisted by DBSCAN) to improve the shepherd&#39;s performance in herding sheep (swarm members). The approach is evaluated using multiple initial swarm configurations. Simulation results on swarm sizes of 50 and 100 agents show up to 50\% reduction in the task completion time and an average improvement of 25\% in the success rate for low density sheep initialization scenarios and competitive results for the higher density scenarios.},
  archive   = {C_CEC},
  author    = {Reem E. Mohamed and Saber Elsayed and Robert Hunjet and Hussein Abbass},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504706},
  pages     = {2315-2322},
  title     = {A graph-based approach for shepherding swarms with limited sensing range},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An exploration of asocial and social learning in the
evolution of variable-length structures. <em>CEC</em>, 2307–2314. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504900">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We wish to explore the contribution that asocial and social learning might play as a mechanism for self-adaptation in the search for variable-length structures by an evolutionary algorithm. An extremely challenging, yet simple to understand problem landscape is adopted where the probability of randomly finding a solution is approximately one in a trillion. A number of learning mechanisms operating on variable-length structures are implemented and their performance analysed. The social learning setup, which combines forms of both social and asocial learning in combination with evolution is found to be most performant, while the setups exclusively adopting evolution are incapable of finding solutions.},
  archive   = {C_CEC},
  author    = {Michael O’Neill and Anthony Brabazon},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504900},
  pages     = {2307-2314},
  title     = {An exploration of asocial and social learning in the evolution of variable-length structures},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Visualizing and characterizing the parameter configuration
landscape of particle swarm optimization using physical landform
classification. <em>CEC</em>, 2299–2306. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504760">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {When designing effective parameter tuning and/or self-adaptive mechanisms for meta-heuristic optimizers, any insights about the configuration process and its associated landscape are of great benefit. Recently, the parameter configuration landscape (PCL) was proposed as a mechanism to formally study and characterize the landscape induced by the control parameter values of meta-heuristic search techniques. As an extension, the use of geomorphon landform types to further characterize and visualize the PCL was recently proposed. This study adopts the geomorphon classification scheme and applies it to particle swarm optimization (PSO). The methodology is applied on 20 minimization benchmark problems with various problem dimensions and swarm sizes, thereby providing deep insights into the PCL associated with PSO.},
  archive   = {C_CEC},
  author    = {Kyle Robert Harrison and Beatrice M. Ombuki-Berman and Andries P. Engelbrecht},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504760},
  pages     = {2299-2306},
  title     = {Visualizing and characterizing the parameter configuration landscape of particle swarm optimization using physical landform classification},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Predicting particle swarm optimization control parameters
from fitness landscape characteristics. <em>CEC</em>, 2289–2298. (<a
href="https://doi.org/10.1109/CEC45853.2021.9505006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Selecting appropriate control parameters for the particle swarm optimization algorithm can be extremely time consuming and expensive, yet it is necessary in order to achieve optimal performance on a problem. Despite its significance, the issue of control parameter selection remains an open problem. This work leverages techniques from the field of fitness landscape analysis to characterize a large suite of benchmark problems. Extensive experimentation is performed to identify strong control parameters for each problem, and machine learning techniques are used to predict strong control parameters from the characterization of a problem. The results demonstrate that good generalization is possible with minimal training data. This suggests that the cost of parameter selection can be significantly reduced.},
  archive   = {C_CEC},
  author    = {Cody Dennis and Beatrice M. Ombuki-Berman and Andries Engelbrecht},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9505006},
  pages     = {2289-2298},
  title     = {Predicting particle swarm optimization control parameters from fitness landscape characteristics},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel sampling method with lévy flight for
distribution-based discrete particle swarm optimization. <em>CEC</em>,
2281–2288. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504684">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We have proposed a novel sampling method (NS) for controlling step sizes and incorporating Lévy flight to distribution-based discrete particle swarm optimizations (DDP-SOs), which are discrete extended variants of particle swarm optimizations handling the continuous parameters of probability distributions over the variable values instead of directly handling discrete variables. Our previous work demonstrated that NS improved all DDPSOs on function optimization problems. However, on categorical problems, the NS did not improve DDPSOs designed for integer problems. For more detailed investigations, we conducted optimization experiments on NK landscapes. The results show that NS improves the DDPSOs&#39; efficiency and robustness to large solution space and non-separable problems. Besides, we found that NS is effective on integer DDPSOs even for categorical optimization in cases where decision variables have a few states. In addition, the proposed methods were tested on feature selection experiments and achieved superior results compared to some evolutionary algorithms designed for feature selection.},
  archive   = {C_CEC},
  author    = {Koya Ihara and Shohei Kato},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504684},
  pages     = {2281-2288},
  title     = {A novel sampling method with lévy flight for distribution-based discrete particle swarm optimization},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Investigating knowledge-based exploration-exploitation
balance in a minimalist swarm optimiser. <em>CEC</em>, 2273–2280. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504805">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {One of the key challenges in evolutionary, swarm and population-based optimisers is the balance between exploration and exploitation. The reliance on both guided and stochastic search in these algorithms allows researchers to take different approaches to the topic. This work uses a minimalist, vector-stripped swarm optimiser to present a theoretical analysis on the behaviour of the particles. Being a population-based continuous optimiser, dispersive flies optimisation or DEO, bears several similarities with the well-known particle swarm optimisers, differential evolution algorithms and their bare-bones variants. The distinctive feature of this algorithm is its sheer reliance on particles positions to update the population. The minimalist nature of the algorithm reduces the challenges of understanding particles oscillation around constantly changing centres, particles&#39; influence on one another, and their trajectories. This work presents a unified exploration-exploitation probability study which is derived from six scenarios in order to examine the population&#39;s dimensional behaviour in each iteration. This paves the way to propose and investigate adaptable, diversity promoting mechanisms. The proposed methods, which may be extendable to other optimisers, are then examined on a comprehensive set of benchmarks, and finally applied to high-dimensional tomographic reconstruction which is an important inverse problem in medical and industrial imaging.},
  archive   = {C_CEC},
  author    = {Mohammad Majid al-Rifaie},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504805},
  pages     = {2273-2280},
  title     = {Investigating knowledge-based exploration-exploitation balance in a minimalist swarm optimiser},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Tournament topology particle swarm optimization.
<em>CEC</em>, 2265–2272. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504863">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Particle swarm optimization (PSO) has become a popular algorithm for performing global numerical optimization; however, it is known that the topology of PSO has a large influence on its performance. Topologies with high connectivity can have fast convergence, but they are also susceptible to convergence to local minima. Topologies with low connectivity may avoid converging to local minima and achieve high quality solutions, but they tend to have slow convergence. In this paper, we propose a novel PSO topology based on a single-elimination tournament. In the proposed tournament topology, particles move up a tree structure through a fitness-based tournament. PSO updates then propagate information about the global best position from the top of the tree to the bottom. Experimental results on eleven benchmark functions show that the proposed topology can achieve both the high quality solutions of low-connectivity topologies and the fast convergence of high-connectivity topologies.},
  archive   = {C_CEC},
  author    = {Jason Kuo and John W. Sheppard},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504863},
  pages     = {2265-2272},
  title     = {Tournament topology particle swarm optimization},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The effect of mask usage on viral immune escape times: An
evolutionary strategies-inspired model. <em>CEC</em>, 2259–2264. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504724">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The COVID-19 pandemic has posed many challenges to the world in several spaces, including the public health, economic, and political spheres. At the start of the pandemic, non-pharmaceutical interventions (NPIs) such as lockdowns, social distancing, and mask-wearing were the only tools available to combat transmission of SARS-CoV-2, the virus that causes COVID-19. More recently, several vaccines have been approved for use, and mass inoculation of the population has begun in many countries.One pressing issue is the continued use of NPIs in the context of vaccine deployment: is there an advantage to perpetuating the use of these interventions even as inoculation proceeds? The present study aims to address this question, investigating the impact of masking on the time to viral immune evasion, i.e. how masking affects the length of time the immune response is effective against the virus before the virus mutates such that it can escape the immune system. Viral immune escape is formulated as an optimization problem. A simplified and idealized model of virus transmission is proposed, and an evolutionary strategies approach is used to model the evolution of the virus.Results indicate that there is strong justification for the continued use of masks, even as vaccines are deployed. Immune escape times for no masking, 50\% of the population masking, and 100\% of the population masking are 17.15 ± 1.92 generations, 21.13 ± 2.33 generations, and 62.27 ± 13.68 generations respectively. This increase in viral immune escape time attributable to masking is most likely caused by decreased transmission, such that significant increases in genetic diversity are required for viral immune evasion.},
  archive   = {C_CEC},
  author    = {Matthew Witten and Owen Clancey},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504724},
  pages     = {2259-2264},
  title     = {The effect of mask usage on viral immune escape times: An evolutionary strategies-inspired model},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimally weighted ensembles in model-based regression for
drug discovery. <em>CEC</em>, 2251–2258. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504835">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In drug discovery, classification is a well established in silico method based on machine learning algorithms. However, since the activity value on a target protein is described as a continuous value, a regressional approach is worth being considered as well. The results of the regression can then be turned into classification results with a given threshold value. To further improve the results, a new method called optimally weighted ensembles that uses a combination of more than one model to build a better performing ensemble of models, is applied here. This method is used in the context of drug discovery for the first time. Naturally, it is crucial to choose suitable models for the specific problem, if any prior knowledge is available. Statistical significance of the approach is verified using a second dataset with a different target. In this work, we show to what extent the obtained classification results compare to previous, highly optimized, single model results as presented in previous work. Furthermore, the results are compared to ensembles where none of the contributing models were optimized beforehand. All case studies are performed using the publicly available database ChEMBL 1 .},
  archive   = {C_CEC},
  author    = {Patrick Echtenbruck and Michael Emmerich and Martina Echtenbruck and Boris Naujoks},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504835},
  pages     = {2251-2258},
  title     = {Optimally weighted ensembles in model-based regression for drug discovery},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Score level fusion of multimodal biometrics using genetic
algorithm. <em>CEC</em>, 2242–2250. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504927">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multimodal biometric system fuses information from multiple biometric modalities to overcome limitations of unimodal biometric system. This fusion significantly enhances the performance of the system. One of the ways of fusing information for multimodal biometrics is score level fusion. In this paper, a novel score level fusion method is proposed. Here, fusion at score level is formulated as an optimization problem. The paper proposes a genetic algorithm (GA) based approach to solve this optimization problem. It minimizes the distances between an aggregated score list and each input score list from individual biometric modality. The proposed GA based method uses weighted Spearman footrule distance metric to compute the distance between a pair of score lists. Superiority of the proposed method over several state-of-the-art score level and rank level fusion methods is demonstrated experimentally.},
  archive   = {C_CEC},
  author    = {Shadab Ahmad and Rajarshi Pal and Avatharam Ganivada},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504927},
  pages     = {2242-2250},
  title     = {Score level fusion of multimodal biometrics using genetic algorithm},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SIMARD-LinearFold: Long sequence RNA design with simulated
annealing. <em>CEC</em>, 2234–2241. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504978">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {RNA Design is an essential problem in bioinformatics to tailor RNA Sequences that guide our biology and medicine. While there are many RNA Design solutions in literature, the field has been limited by the high runtime to estimate how a candidate RNA sequence will fold, especially with &quot;long sequences&quot; over 750 &quot;bases&quot;; as these folding algorithms are called millions of times per RNA Design problem, this limits RNA Design to shorter sequences despite the prevalence of long sequences in nature; for example, computationally designing COVID’s over 20000 bases RNA sequence is not feasible with current RNA Design algorithms. To address this issue, we are the first work to integrate LinearFold, a faster RNA prediction algorithm used by Baidu to analyze COVID with a higher efficiency, into RNA Design. We compare the runtime and solution quality of our Applied Research Lab&#39;s Simulated Annealing solution (SIMARD) with and without LinearFold to design sequences thousands of bases long that timeout after weeks of runtime with current algorithms. We also survey challenges in terms of solution quality and adjusting the cooling schedule parameters. This work is thus a first step into RNA Design for longer RNA sequences.},
  archive   = {C_CEC},
  author    = {Ryan McBride and Herbert H. Tsang},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504978},
  pages     = {2234-2241},
  title     = {SIMARD-LinearFold: Long sequence RNA design with simulated annealing},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evolution of generative adversarial networks using PSO for
synthesis of COVID-19 chest x-ray images. <em>CEC</em>, 2226–2233. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504743">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The use of biomedical images for the training of various Deep Learning (DL) systems oriented to health has reported a competitive performance. However, DL needs a large number of images for a correct generalization and, particularly in the case of biomedical images, these can be scarce. Generative Adversarial Networks (GANs) as Data Augmenting tools have reaped significant results to improve performance in tasks that involve the use of this kind of image. However, the architectural design of these generative models in the biomedical image area has been usually relegated to the expertise of researchers. Moreover, GANs are affected by training instability that may lead to poor quality results. This paper presents a neuroevolution algorithm based on Particle Swarm Optimization for the design and training of GANs for the generation of biomedical Chest X-Ray (CXR) images of pneumonia caused by COVID-19. The proposed approach allows having a swarm of GANs topologies, where each one of them grows progressively while being trained at the same time. The fitness value is based on the Frechet Inception Distance (FID). The proposed algorithm is able to obtain better FID results compared to handcrafted GANs for the synthesis of CXR images.},
  archive   = {C_CEC},
  author    = {Juan-Antonio Rodríguez-de-la-Cruz and Héctor-Gabriel Acosta-Mesa and Efrén Mezura-Montes},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504743},
  pages     = {2226-2233},
  title     = {Evolution of generative adversarial networks using PSO for synthesis of COVID-19 chest X-ray images},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Smart multi-objective evolutionary GAN. <em>CEC</em>,
2218–2225. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504858">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Generative Adversarial Network (GAN) is a family of machine learning algorithms designed to train neural networks able to imitate real data distributions. Unfortunately, GAN suffers from problems such as gradient vanishing and mode collapse. In Multi-Objective Evolutionary Generative Adversarial Network (MO-EGAN) these problems were addressed using an evolutionary technique combined with Multi-Objective selection, obtaining better results on synthetic datasets at the expense of larger computation times. In this works, we present the Smart MultiObjective Evolutionary Generative Adversarial Network (SMO-EGAN) algorithm, which reduces the computational cost of MO-EGAN and achieves better results on real data distributions.},
  archive   = {C_CEC},
  author    = {Marco Baioletti and Gabriele Di Bari and Valentina Poggioni and Carlos Artemio Coello Coello},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504858},
  pages     = {2218-2225},
  title     = {Smart multi-objective evolutionary GAN},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel evolving classifier with a false alarm class for
speed limit sign recognition. <em>CEC</em>, 2211–2217. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504710">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Automatic interpretation of information written on roadside signs is very useful in applications for conducting road surveys, driving autonomous vehicles, and improving the road safety and infrastructure. However, it is a very difficult problem because of high similarity and poor visibility of signs and challenging nature of road environment. In this paper, we propose a novel technique for automatic detection and recognition of speed limit signs. The proposed technique contains two novel concepts. Firstly, pixel-wise segmentation of all speed limit signs into one class instead of each sign in a separate class is proposed. Secondly, a novel classifier with a false alarm class that evolves its weights so that it can distinguish speed signs from non-speed signs is proposed. The proposed technique is evaluated on a real-world dataset provided by our industry partners. The dataset has been created from videos of all state roads in Queensland. The comparative analysis of results showed that the proposed technique is able to detect and classify speed limit signs with high accuracy.},
  archive   = {C_CEC},
  author    = {Pubudu Sanjeewani and Brijesh Verma and Joseph Affum},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504710},
  pages     = {2211-2217},
  title     = {A novel evolving classifier with a false alarm class for speed limit sign recognition},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An efficient and flexible automatic search algorithm for
convolution network architectures. <em>CEC</em>, 2203–2210. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504945">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As many superior convolutional neural networks (CNNs) have been proposed in recent years, CNNs have played an important role in computer vision. However, manually-designing CNN architecture is difficult since expertise is required. Therefore, several automatic search algorithms have been proposed for neural architecture search, which usually have considerable computational complexity and the search space is limited. To address these problems, an efficient and flexible CNN architecture search algorithm (EF-CNN) is proposed in this paper. In EF-CNN, a flexible architecture search space is constructed by considering the depth, width, and lightweight blocks. In order to improve the reliability of the architecture while reducing the computational time, a multi-objective fitness correction method is proposed in EF-CNN based on the divided datasets, where the accuracy and computational complexity of architecture are considered simultaneously to design CNN. The experimental results on CIFAR-10 and CIFAR-100 indicate that the performance of CNN architecture designed by EF-CNN is very competitive while the computational time is greatly reduced.},
  archive   = {C_CEC},
  author    = {Liang Zhao and Wei Fang},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504945},
  pages     = {2203-2210},
  title     = {An efficient and flexible automatic search algorithm for convolution network architectures},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DES-HyperNEAT: Towards multiple substrate deep ANNs.
<em>CEC</em>, 2195–2202. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504803">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Neuroevolution (NE), inspired by the natural evolution of biological brains, may be applied to the evolution of both weights and the topology of Artificial Neural Networks (ANNs). DES-HyperNEAT, proposed herein, further extends existing NE algorithms to enable evolvable substrate topologies with non-fixed node positions - a desirable feature for optimisation of deep ANNs. DES-HyperNEAT builds on HyperNEAT and ES-HyperNEAT whilst adding beneficial features from NEAT and MSS-HyperNEAT. The preliminary experiments in this work consider potential variants of DES-HyperNEAT, evaluating such variants in terms of performance and efficiency on the Iris, Wine and Retina datasets. Further, DES-HyperNEAT, ES-HyperNEAT, HyperNEAT and NEAT are compared to highlight whether the DES-HyperNEAT extension has merit in terms of performance and efficiency.},
  archive   = {C_CEC},
  author    = {Amund Tenstad and Pauline C. Haddow},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504803},
  pages     = {2195-2202},
  title     = {DES-HyperNEAT: Towards multiple substrate deep ANNs},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A multi-objective grammatical evolution framework to
generate convolutional neural network architectures. <em>CEC</em>,
2187–2194. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504822">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep Convolutional Neural Networks (CNNs) have reached the attention in the last decade due to their successful application to many computer vision domains. Several handcrafted architectures have been proposed in the literature, with increasing depth and millions of parameters. However, the optimal architecture size and parameters setup are dataset-dependent and challenging to find. For addressing this problem, this work proposes a Multi-Objective Grammatical Evolution framework to automatically generate suitable CNN architectures (layers and parameters) for a given classification problem. For this, a Context-free Grammar is developed, representing the search space of possible CNN architectures. The proposed method seeks to find suitable network architectures considering two objectives: accuracy and F1-score. We evaluated our method on CIFAR-10, and the results obtained show that our method generates simpler CNN architectures and overcomes the results achieved by larger (more complex) state-of-the-art CNN approaches and other grammars.},
  archive   = {C_CEC},
  author    = {Cleber A.C.F. da Silva and Daniel Carneiro Rosa and Péricles B.C. Miranda and Filipe R. Cordeiro and Tapas Si and André C.A. Nascimento and Rafael F. L. Mello and Paulo S. G. de Mattos Neto},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504822},
  pages     = {2187-2194},
  title     = {A multi-objective grammatical evolution framework to generate convolutional neural network architectures},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Decision space scalability analysis of multi-objective
particle swarm optimization algorithms. <em>CEC</em>, 2179–2186. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504846">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Particle swarm optimization (PSO) has been adapted to solve multi-objective optimization problems. However, these PSO-based multi-objective optimization algorithms typically face difficulties when the number of decision variables is increased and the problems turn into large-scale multi-objective problems (LSMOPs). This paper presents a decision space scalability analysis of five PSO-based multi-objective optimization algorithms, namely optimized multi-objective particle swarm op-timization (OMOPSO), speed-constrained multi-objective particle swarm optimization (SMPSO), multi-objective particle swarm optimization with multiple search strategies (MMOPSO), multi-guide particle swarm optimization (MGPSO), and competitive mechanism-based multi-objective particle swarm optimization (CMOPSO) for 24, 50, 100, 500 and 1000 dimensions (decision variables) to see how well each one of the algorithms scales as the number of decision variables is increased. The results indicate that, with an increase in the number of decision variables, MMOPSO and SMPSO had the best scalability, each dominating specific functions. Moreover, despite MGPSO&#39;s competitive performance on the 24-dimensional functions, it showed the worst overall scalability together with CMOPSO.},
  archive   = {C_CEC},
  author    = {Amirali Madani and Beatrice Ombuki-Berman and Andries Engelbrecht},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504846},
  pages     = {2179-2186},
  title     = {Decision space scalability analysis of multi-objective particle swarm optimization algorithms},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Prediction guided meta-learning for multi-objective
reinforcement learning. <em>CEC</em>, 2171–2178. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504972">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Many real-world control problems consist of several different, possibly conflicting, objectives, which require finding a high-quality set of policies that are optimal for different objective preferences. Extensive research mainly focused on how to obtain a high-quality approximated Pareto set of policies, while another important research direction studies how to adapt to new objective preferences quickly. In this paper, we propose a new multi-objective reinforcement learning (MORL) algorithm so-called PG-Meta-MORL for achieving both goals. PG-Meta-MORL frames MORL as a meta-learning problem and iteratively optimizes a meta-policy using multiple tasks with objective preferences selected based on a prediction model, which is trained to guide the optimization process towards best improving the quality of the current Pareto set of policies. The empirical results on several multi-objective continuous control problems show that PG-Meta-MORL can find a high-quality approximated Pareto set of policies, and meanwhile, the obtained meta-policy can be adapted well to new objective preferences using few-shot interactions with the environment.},
  archive   = {C_CEC},
  author    = {Fei-Yu Liu and Chao Qian},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504972},
  pages     = {2171-2178},
  title     = {Prediction guided meta-learning for multi-objective reinforcement learning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An improved MOEA/d framework with multoperator strategies
for multi-objective optimization problems with a large scale of
variables. <em>CEC</em>, 2164–2170. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504768">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A novel multi-objective evolutionary algorithm based on decomposition is proposed, in which a multi-population meta-heuristic algorithm named phase based optimization (PBO) is utilized as an effective search engine for enhancing the performance of the original MOEA/D, and is consequently termed MOEA/D-PBO. Three different sub-populations are divided by using the distance between the individuals and the reference point in accordance with the principle from high to low. On this basis, three different search strategies are executed to generate the better solutions according to the position characteristic of individuals with the reference point as the center. The empirical results demonstrate that MOEA/D-PBO can provide much better performance on large scale bi-objective and tri-objective optimization problems than MOEA/D-DE and IM-MOEA.},
  archive   = {C_CEC},
  author    = {Zijian Cao and Chen Liu and Zhenyu Wang and Haowen Jia},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504768},
  pages     = {2164-2170},
  title     = {An improved MOEA/D framework with multoperator strategies for multi-objective optimization problems with a large scale of variables},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An improved weighted optimization-based framework for
large-scale MOPs. <em>CEC</em>, 2156–2163. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504854">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper proposes an improved weighted optimization-based framework (iWOF) for solving large-scale multiobjective optimization problems (LSMOPs). Compared to the original framework, there are two main contributions in our work. Firstly, a novel evolutionary search strategy involving two different search operators with different search characteristics, i.e., a particle swarm optimization (PSO) operator and differential evolution (DE) operator, is designed in iWOF, which aims to provide a robust search ability on finding optimal solutions in a huge decision space. Secondly, different from the stage in the original framework that divides the whole evolutionary process into two independent stages, the evolutionary process in the proposed iWOF is simplified to only one stage, which effectively reduces the number of predefined parameters. Besides that, the evolving numbers of weight optimization and original optimization in iWOF are adjusted adaptively according to the evolutionary stage. The experimental results on three different groups of benchmark LSMOPs validate the superiority of the proposed iWOF over WOF and other several state-of-the-art multiobjective evolutionary algorithms.},
  archive   = {C_CEC},
  author    = {Junhao Zheng and Lingjie Li and Qiuzhen Lin and Zhong Ming},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504854},
  pages     = {2156-2163},
  title     = {An improved weighted optimization-based framework for large-scale MOPs},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Large-scale multiobjective optimization via problem
decomposition and reformulation. <em>CEC</em>, 2149–2155. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504820">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Large-scale multiobjective optimization problems (LSMOPs) are challenging for existing approaches due to the complexity of objective functions and the massive volume of decision space. Some large-scale multiobjective evolutionary algorithms (LSMOEAs) have recently been proposed, which have shown their effectiveness in solving some benchmarks and real-world applications. They merely focus on handling the massive volume of decision space and ignore the complexity of LSMOPs in terms of objective functions. The complexity issue is also important since the complexity grows along with the increment in the number of decision variables. Our previous study proposed a framework to accelerate evolutionary large-scale multiobjective optimization via problem reformulation for handling large-scale decision variables. Here, we investigate the effectiveness of LSMOF combined with decomposition-based MOEA (MOEA/D), aiming to handle the complexity of LSMOPs in both the decision and objective spaces. Specifically, MOEA/D is embedded in LSMOF via two different strategies, and the proposed algorithm is tested on various benchmark LSMOPs. Experimental results indicate the encouraging performance improvement benefited from the solution of the complexity issue in large-scale multiobjective optimization.},
  archive   = {C_CEC},
  author    = {Lianghao Li and Cheng He and Ran Cheng and Linqiang Pan},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504820},
  pages     = {2149-2155},
  title     = {Large-scale multiobjective optimization via problem decomposition and reformulation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Budget and SLA aware dynamic workflow scheduling in cloud
computing with heterogeneous resources. <em>CEC</em>, 2141–2148. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504709">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Workflow with different patterns and sizes arrive at a cloud data center dynamically to be processed at virtual machines in the data center, with the aim to minimize overall cost and makespan while satisfying Service Level Agreement (SLA) requirement. To efficiently schedule workflows, manually designed heuristics are proposed in the literature. However, it is time consuming to manually design heuristics. The designed heuristics may not work effectively for heterogeneous workflow since only simple problem related factors are considered in the heuristics. Further, most of the existing approaches ignore the deadline constraints set in SLAs. Genetic Programming Hyper Heuristic (GPHH) can be used to automatically design heuristics for scheduling problems. In this paper, we propose a GPHH approach to automatically generate heuristics for the dynamic workflow scheduling problem, with the goal of minimizing the VM rental fees and SLA penalties. Experiments have been conducted to evaluate the performance of the proposed approach. Compared with several existing heuristics and conventional Genetic Programming (GP) approaches, the proposed Dynamic Workflow Scheduling Genetic Programming (DWSGP) has better performance and is highly adaptable to variations in cloud environment.},
  archive   = {C_CEC},
  author    = {Yifan Yang and Gang Chen and Hui Ma and Mengjie Zhang and Victoria Huang},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504709},
  pages     = {2141-2148},
  title     = {Budget and SLA aware dynamic workflow scheduling in cloud computing with heterogeneous resources},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cheapest insertion and disruption of routes operators for
solving multi-depot electric vehicle location routing problem with time
windows and battery swapping via GRASP and RVND. <em>CEC</em>,
2133–2140. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504799">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Multi-Depot Electric Vehicle Location Routing Problem with Time Windows and Battery Swapping (MDEVLRPTW-BS) aims to mitigate the environmental impacts caused by the use of vehicles with an internal combustion engine and uses economically viable electric vehicles in transportation services with time window restrictions. This problem is complex as one must define (i) the location of the battery swapping stations, (ii) the depots to be used from a list of candidates, and (iii) the assignment and routing of a fleet of electric vehicles. We propose here two constructive methods to solve MDEVLRPTW-BS, namely, Cheapest Insertion and Disruption of Routes. These constructive approaches are used with the Greedy Randomized Adaptive Search Procedure (GRASP) and the Random Variable Neighborhood Descent (RVND) method with six movement operators. Two of these operators, namely Isolate and ChangeBSS, are also proposed here for solving MDEVLRPTW-BS. The proposals are compared with a technique from the literature using instances with 5, 10, and 15 customers, and the proposed approaches presented good results, mainly regarding the processing time. Also, we propose new sets of instances larger than those from the literature. Thus, the search techniques can be analyzed when subjected to greater and more realistic situations. These new instances are composed of 100, 144, 288, 360, 420, and 600 customers. For these cases, the approaches also obtained good and promising results, mainly when the Disruption of Routes approach (GRASP-DR-RVND) is used.},
  archive   = {C_CEC},
  author    = {Bráulio M.O. Portela and Heder S. Bernardino and Luciana B. Gonçalves and Stênio S. R. F. Soares},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504799},
  pages     = {2133-2140},
  title     = {Cheapest insertion and disruption of routes operators for solving multi-depot electric vehicle location routing problem with time windows and battery swapping via GRASP and RVND},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the application of ϵ-lexicase selection in the generation
of dispatching rules. <em>CEC</em>, 2125–2132. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504982">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Dynamic online scheduling is a difficult problem which commonly appears in the real world. This is because the decisions have to be performed in a small amount of time using only currently available incomplete information. In such cases dispatching rules (DRs) are the most commonly used methods. Since designing them manually is a difficult task, this process has been successfully automatised by using genetic programming (GP). The quality of the evolved rules depends on the problem instances that are used during the training process. Previous studies demonstrated that careful selection of problem instances on which the solutions should be evaluated during evolution improves the performance of the generated rules. This paper examines the application of the ε-lexicase selection to the design of DRs for the unrelated machines scheduling. This selection offers a better solution diversity since the individuals are selected based on a smaller subset of instances, which leads to the creation of DRs that perform well on the selected instances. The experiments demonstrate that this type of selection can significantly improve the results for the Roulette Wheel and Elimination GP variants, while achieving the same performance as the Steady State Tournament GP. Furthermore, the ε-lexicase based algorithms have a better convergence rate, which means that the increased diversity in the population has a positive effect on the evolution process.},
  archive   = {C_CEC},
  author    = {Lucija Planinić and Marko Đurasević and Domagoj Jakobović},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504982},
  pages     = {2125-2132},
  title     = {On the application of ϵ-lexicase selection in the generation of dispatching rules},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Genetic programming with archive for dynamic flexible job
shop scheduling. <em>CEC</em>, 2117–2124. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504752">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Genetic programming (GP) has achieved great success in evolving effective scheduling rules to make real-time decisions in dynamic flexible job shop scheduling (DFJSS). To improve generalization, a commonly used strategy is to change the training simulation(s) at each generation of the GP process. However, with such a simulation rotation, GP may lose potentially promising individuals that happen to perform poorly in one particular generation. To address this issue, this paper proposed a new multi-tree GP with archive (MTAGP) to evolve the routing and sequencing rules for DFJSS. The archive is used to store the potentially promising individuals of each generation during evolution of genetic programming. The individuals in the archive can then be fully utilized when the simulation is changed in subsequent generations. Through extensive experimental tests, the MTAGP algorithm proposed in this paper is more effective than the multi-tree GP without archive algorithm in a few scenarios. Further experiments were carried out to analyze the use of the archive and some possible guesses were ruled out. We argue that the use of archives does increase the diversity of the population. However, the number of individuals in the archive that ranked in the top five of the new population is small. Therefore, the archive may not be able to greatly improve the performance. In the future, we will investigate better ways to use the archive and better ways to update individuals in the archive.},
  archive   = {C_CEC},
  author    = {Meng Xu and Fangfang Zhang and Yi Mei and Mengjie Zhang},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504752},
  pages     = {2117-2124},
  title     = {Genetic programming with archive for dynamic flexible job shop scheduling},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). An evolutionary hyper-heuristic approach to the large scale
vehicle routing problem. <em>CEC</em>, 2109–2116. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504818">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Large Scale Vehicle Routing Problem (LSVRP) is a classical combinatorial optimisation problem that serves several customers on a graph using a set of vehicles. Due to the NP-hardness and large problem size, LSVRP cannot be efficiently solved by exact approaches. Heuristic methods such as the Iterative Local Search or the Hybrid Genetic Algorithm still struggle for finding effective solutions for large scale instances. For these methods to deal with the large search space, pruning techniques are applied in order to limit the number of explored solutions. However, effective pruning is a hard task, requiring domain knowledge to craft good ways of limiting the search space without losing the ability to find better solutions. Hyper-heuristics are types of methods that aim to reduce domain knowledge on the creation of heuristics, and in this work, we also apply them for effective heuristic pruning. Our Evolutionary Hyper-Heuristic (EHH) automatically evolves limits to the solution search space together with the heuristic utilised to build and improve solutions for the LSVRP. We utilise a Guided Local Search (GLS) as the base algorithm in which our EHH searches for the best heuristic configuration. Our results show that the EHH can find better solutions for most LSVRP test instances when compared to the manually designed pruning of the GLS.},
  archive   = {C_CEC},
  author    = {Joao Guilherme Cavalcanti Costa and Yi Mei and Mengjie Zhang},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504818},
  pages     = {2109-2116},
  title     = {An evolutionary hyper-heuristic approach to the large scale vehicle routing problem},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Investigating binary EAs for passive in-building distributed
antenna systems. <em>CEC</em>, 2101–2108. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504731">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A passive in-building distributed antenna system (IB-DAS) is often used to enhance indoor mobile data coverage by introducing indoor antennas inside buildings. Such systems are created to ensure that traffic generated indoors does not heavily depend on base stations installed outdoor, as penetration issues of wireless signals can affect the quality of connection. The focus of this paper is on the automation of IB-DAS design. Particularly, it provides an extensive analysis of the performance of four binary Evolutionary Algorithms (EAs) for this problem and shows that the two tested Estimation of Distribution Algorithms (EDAs) performs well on this problem. Furthermore, it investigates the effect of different genetic operators on the performance of the considered EAs. The practice outcome of this is to select the best algorithm among others to be implemented in a DAS network planning tool and to help our industrial partner reduce both the design time and deployment cost.},
  archive   = {C_CEC},
  author    = {Siddhartha Shakya and Kin Poon and Khawla AlShanqiti and Anis Ouali and Andrei Sleptchenko},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504731},
  pages     = {2101-2108},
  title     = {Investigating binary EAs for passive in-building distributed antenna systems},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Coevolution of AI and level generators for super mario game.
<em>CEC</em>, 2093–2100. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504742">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Procedural content generation (PCG) is now used in many games to generate a wide variety of content. One way of evaluating this content is by artificial intelligence (AI) controlled players. Inversely, PCG content can also be used when training AI players to ensure generalization. Evolutionary algorithms are employed in both AI and PCG fields, but rarely simultaneously. In this work, we use evolutionary algorithms for both AI players and level generation in the platformer game Super Mario. We further combine them into a coevolution, where the AI players are evaluated by adapting level generators, and vice versa, level generators are evaluated by adapting AI players. This yields an AI player trained on gradually more difficult levels and a sequence of level generators with gradually increasing difficulty. Such sequence of generators might be useful for human game playing in commercial games.},
  archive   = {C_CEC},
  author    = {Julius Flimmel and Jakub Gemrot and Vojtéch Černý},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504742},
  pages     = {2093-2100},
  title     = {Coevolution of AI and level generators for super mario game},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Portfolio search and optimization for general strategy
game-playing. <em>CEC</em>, 2085–2092. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504824">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Portfolio methods represent a simple but efficient type of action abstraction which has shown to improve the performance of search-based agents in a range of strategy games. We first review existing portfolio techniques and propose a new algorithm for optimization and action-selection based on the Rolling Horizon Evolutionary Algorithm. Moreover, a series of variants are developed to solve problems in different aspects. We further analyze the performance of discussed agents in a general strategy game-playing task. For this purpose, we run experiments on three different game-modes of the Stratega framework. For the optimization of the agents&#39; parameters and portfolio sets we study the use of the N-tuple Bandit Evolutionary Algorithm. The resulting portfolio sets suggest a high diversity in play-styles while being able to consistently beat the sample agents. An analysis of the agents&#39; performance shows that the proposed algorithm generalizes well to all game-modes and is able to outperform other portfolio methods.},
  archive   = {C_CEC},
  author    = {Alexander Dockhorn and Jorge Hurtado-Grueso and Dominik Jeurissen and Linjie Xu and Diego Perez-Liebana},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504824},
  pages     = {2085-2092},
  title     = {Portfolio search and optimization for general strategy game-playing},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Behavioral cloning in atari games using a combined
variational autoencoder and predictor model. <em>CEC</em>, 2077–2084.
(<a href="https://doi.org/10.1109/CEC45853.2021.9505001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We explore an approach to behavioral cloning in video games. We are motivated to pursue a learning architecture that is data efficient and provides opportunity for interpreting player strategies and replicating player actions in unseen situations. To this end, we have developed a generative model that learns latent features of a game that can be used for training an action predictor. Specifically, our architecture combines a Variational Autoencoder with a discriminator mapping the latent space to action predictions (predictor). We compare our model performance to two different behavior cloning architectures: a discriminative model (a Convolutional Neural Network) mapping game states directly to actions, and a Variational Autoencoder with a predictor trained separately. Finally, we demonstrate how we can use the advantage of generative modeling to sample new states from the latent space of the Variational Autoencoder to analyze player actions and provide meaning to certain latent features.},
  archive   = {C_CEC},
  author    = {Brian Chen and Siddhant Tandon and David Gorsich and Alex Gorodetsky and Shravan Veerapaneni},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9505001},
  pages     = {2077-2084},
  title     = {Behavioral cloning in atari games using a combined variational autoencoder and predictor model},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hullingversus clustering - two complementary applications of
non-negative matrix factorization. <em>CEC</em>, 2069–2076. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504734">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper we make a comparison of two NMF based techniques of dataset characterization: clustering and hulling. The characteristics of a dataset should be understood as describing the content of a data set through several characteristic representatives. Hulling (defined later) characterizes the data by saying that the data points are somewhere between the representatives, while clustering characterizes the data by saying that the data points are close to one or the other representative. The precision of such a characteristic will be measured as a deviation from the idea of characterization, i.e. the distance of the actual data points from the closest representatives in the case of clustering and from the interior of the hull spanned by the representatives. We show that for low-dimensional data the hull-based characterization precision is much better than in case of clustering. Clustering and hulling are two examples of sophisticated optimization problems. Evolutionary algorithms are an excellent tool for solving such problems. However, in the case of large, high-dimensional data sets, their usefulness decreases. In this paper, we discuss heuristics for hulling for massive data. We hope that it will inspire the creation of an effective evolutionary algorithm dedicated to solving such problems.},
  archive   = {C_CEC},
  author    = {Mieczysław A. Kłopotek and Sławomir T. Wierzchoń},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504734},
  pages     = {2069-2076},
  title     = {Hullingversus clustering - two complementary applications of non-negative matrix factorization},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evolving simple solutions to the CIFAR-10 benchmark using
tangled program graphs. <em>CEC</em>, 2061–2068. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504998">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The goal of the CIFAR-10 benchmark is recast from the perspective of discovering light-weight as well as accurate solutions. Specifically, the image data, on which CIFAR-10 is based, requires multiple practical issues to be addressed that are not often considered collectively when applying genetic programming to classification problems. Issues of particular interest include cardinality, multi-class classification and diversity maintenance. We demonstrate that diversity maintenance and cardinality can be approached simultaneously by adopting a data subset to compose pools of exemplars for lexicase selection. The issues of multi-class classification and solution simplicity are addressed by adopting the tangled program graph (TPG) approach to emergent modularity. In addition, the mutation operator is modified to ensure that class labels do not `die out&#39; during evolution. The resulting benchmarking study demonstrates solutions that are significantly more accurate than AutoML while providing comparable accuracies with solutions from unsupervised feature discovery, i.e. 70\% accuracy. However, unlike the latter TPG solutions are several orders of magnitude simpler.},
  archive   = {C_CEC},
  author    = {Robert J. Smith and Ryan Amaral and Malcolm I. Heywood},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504998},
  pages     = {2061-2068},
  title     = {Evolving simple solutions to the CIFAR-10 benchmark using tangled program graphs},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A grid-dominance based multi-objective algorithm for feature
selection in classification. <em>CEC</em>, 2053–2060. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504832">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Feature selection aims to select a small subset of relevant features while maintaining or even improving the classification performance over using all features. Feature selection can be considered as a multi-objective problem, i.e., minimizing the number of selected features and maximizing the classification accuracy (minimizing the classification error) simultaneously. Most evolutionary multi-objective algorithms encounter difficulties when handling a feature selection task due to the discrete search space, although they perform well on continuous/numeric optimization problems. This paper proposes a grid-dominance based multi-objective evolutionary algorithm to address feature selection. The aim is to explore the potential of the grid-dominance method to strengthen the selection pressure toward the optimal direction while maintaining an extensive distribution among the objective values of feature subsets. To increase the population diversity, a subset filtration mechanism is proposed. The performance of the proposed two algorithms is tested on fourteen datasets of varying difficulty. With the proposed methods, the performance metrics, hypervolume and inverted generational distance have been significantly improved compared with other commonly used multi-objective algorithms, and the population diversity has also been increased.},
  archive   = {C_CEC},
  author    = {Peng Wang and Bing Xue and Mengjie Zhang and Jing Liang},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504832},
  pages     = {2053-2060},
  title     = {A grid-dominance based multi-objective algorithm for feature selection in classification},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Complexity-based lambda layer for time series prediction.
<em>CEC</em>, 2046–2052. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504995">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Time series analysis forms the basis for the temporal sequences that we observe in everyday natural phenomenon. Examining and characterizing time series&#39; forms the basis for research in areas spanning classifying heart rate variability, temperature prediction and stock price prediction. In recent history combining powerful techniques such as Fourier Analysis with Machine Learning techniques has improved our ability to predict future time series based on historic data. Complexity is one of such tools that incorporates long-range dependency based on the inherent self-similarity that exists in many natural phenomena. Leveraging the prowess of recurrent neural networks with that of complexity measures combines two very powerful techniques to improve prediction accuracy. In this work a Complexity Lambda Layer was initialized in series with Artificial Neural Networks (ANN) architectures to improve prediction accuracy for synthesized Brownian Noise. Window size for recurrence and the stationary interval size was optimized for increased performance. For both non-temporal and temporal studies, a 2-4 fold improvement in root-mean-squared accuracy was obtained. This approach was implemented as a Lambda layer, meaning the improvement can be done on-the fly with minimal overhead.},
  archive   = {C_CEC},
  author    = {Kenneth Brezinski and Ken Ferens},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504995},
  pages     = {2046-2052},
  title     = {Complexity-based lambda layer for time series prediction},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evolutionary clustering algorithm using supervised
classifiers. <em>CEC</em>, 2039–2045. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504826">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Cluster analysis is a data mining tool for searching patterns automatically on different types of data. However, it is not always clear which clustering criterion would be the most accurate as this decision is domain-dependent. This paper focuses on the design of a single-objective evolutionary clustering algorithm that generates solutions that are less biased towards one cluster structure. This work&#39;s motivation starts from the idea that a good partition induces a well-trained classifier. The resulting evolutionary clustering algorithm using classifiers aims to enhance the generalization capability of the resulting partition. The proposed objective function trains a set of classifiers using an individual&#39;s chromosome as class labels. The obtained average area under the curve of the classifiers is used as the cluster quality index for measuring fitness. The experimental phase shows a similarity increase between the generated solutions and the reference partitions of the datasets.},
  archive   = {C_CEC},
  author    = {Benjamin Mario Sainz-Tinajero and Andres Eduardo Gutierrez-Rodriguez and Hector G. Ceballos and Francisco J. Cantu-Ortiz},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504826},
  pages     = {2039-2045},
  title     = {Evolutionary clustering algorithm using supervised classifiers},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Continuous encoding for community detection in attribute
networks with preserving node information. <em>CEC</em>, 2031–2038. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504842">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Community detection in complex attribute network is an indispensable but difficult task in data mining. Recently, using multiobjective evolutionary algorithm (MOEA) to address this task has become popular since it can be naturally modeled as a discrete multiobjective optimization problem (MOP). In this paper, we develop a continuous MOEA, in which a continuous encoding is proposed to convert the discrete MOP into a continuous one by introducing a set of auxiliary continuous variables. Further, we construct a similarity matrix to replace the adjacency matrix by making use of the network node degree information in the encoding. The new similarity matrix not only reserves the property of the adjacency matrix but includes the degree information of all the network nodes. In our experiments, various benchmark networks with or without ground truths are used to compare with some state-of-the-art MOEA-based and non-MOEA-based methods. The experimental results show that the proposed algorithm performs favorably against the compared methods.},
  archive   = {C_CEC},
  author    = {Wei Zheng and Xin Liu and Jianyong Sun},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504842},
  pages     = {2031-2038},
  title     = {Continuous encoding for community detection in attribute networks with preserving node information},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Contrapuntal composition and autonomous style development of
organum motets by using AntsOMG. <em>CEC</em>, 2023–2030. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504881">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Based on a previously proposed meta-framework, called ants on multiple graphs (AntsOMG), this paper further investigates into certain more complicated creative behavior, in which creators interact with their own creations in order to complete works and elevate the creation forms to a higher level, via computational mechanisms. Aiming to achieve the goal of this study, the target music genre, organum motets, is adopted because its composition process requires iterative interactions with composed music and quite resembles the creative behavior under investigation. AntsOMG is employed as a fundamental component for developing models and conducting creations according to the developed models. With the assistance of AntsOMG, the proposed approach firstly develops style models for section scheme planning and accordingly plans section schemes for the organum motets to be composed. Secondly, following the section scheme, cantus firmus is composed and also used to generate the graph models to be developed into the style models required for composing the corresponding contrapuntal parts for the polyphonic sections of the organum motets. For finalizing each contrapuntal section, a genetic algorithm is utilized to introduce variety and diversity. The outcomes demonstrate that contrapuntal composition and autonomous style development of organum motets can be achieved by the proposed approach. The contribution of this paper is twofold. First, the presented implementation is immediately applicable to compose unlimited amount of organum motets, which may not be possible for human composers. Second, the success of the proposal may shed light on gaining further understandings of complicated creative behavior.},
  archive   = {C_CEC},
  author    = {Chun-yien Chang and Ying-ping Chen},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504881},
  pages     = {2023-2030},
  title     = {Contrapuntal composition and autonomous style development of organum motets by using AntsOMG},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automatically extracting features using genetic programming
for low-quality fish image classification. <em>CEC</em>, 2015–2022. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504737">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Fish image classification is an important task in the protection of precious marine resources. However, this task is difficult due to the low-quality images and the high inter-class variations across images. Most existing methods use high-quality images for classification and need domain knowledge. In this paper, we develop a genetic programming (GP) approach to automatically selecting image operators to deal with the low-quality images and extracting effective features from these images for low-quality fish image classification. To achieve this, a new program structure and a new function set are developed. With these designs, the proposed GP approach can evolve solutions that use effective filtering or restoration operators to deal with the input image, select informative regions from the fish image, and extract effective global and/or local features from the fish images. The results show that the proposed approach achieves significantly better performance than 12 benchmark methods, including a state-of-the-art GP approach, on the well-known fish image classification dataset. Further analysis shows the high interpretability of the evolved GP trees and the effectiveness of the employed image filtering or restoration operators.},
  archive   = {C_CEC},
  author    = {Zichu Yan and Ying Bi and Bing Xue and Mengjie Zhang},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504737},
  pages     = {2015-2022},
  title     = {Automatically extracting features using genetic programming for low-quality fish image classification},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A hybrid BRKGA approach for the two stage capacitated
facility location problem. <em>CEC</em>, 2007–2014. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504856">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Finding optimal locations for installing factories and warehouses, fulfilling customers&#39; demand is the goal of the Two-Stage Capacitated Facility Location, which compounds a supply chain class of problems. Besides locating factories and warehouses, the problem&#39;s objective is to minimize the operational costs: opening facilities and product flow, satisfying customer demand, and without disregarding the capacity of factories and warehouses. A Hybrid Biased Random-Key Genetic Algorithm (HBRKGA), combining BRKGA with Local Search and Local Branching, was proposed to solve the problem. The computational experiments showed that the method was reliable and stood out among other approaches to the problem.},
  archive   = {C_CEC},
  author    = {Gabriel Souto and Igor Morais and Liss Faulhaber and Glaydston Mattos Ribeiro and Pedro Henrique González},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504856},
  pages     = {2007-2014},
  title     = {A hybrid BRKGA approach for the two stage capacitated facility location problem},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An evolutionary framework for real-time fraudulent credit
detection. <em>CEC</em>, 1999–2006. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504729">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Fraud has been a worldwide issue that is facing the major economies of the world. Within an economical system, undetected and unpunished fraudulent activities can erode the public trust in law enforcement institutions and even incentivize more fraud. Therefore, detection of fraudulent activities and prosecution of responsible entities is of utmost importance for financial regulatory bodies around the globe. Of the challenges rising with this task is the scarcity of detection resources (auditors) and the fraudsters constantly adapting to the new circumstances of the market. To address these issues, this paper proposes an evolutionary framework for credit fraud detection with the ability to incorporate (and adapt to) the incoming data in real-time. The goal of the framework is to identify the entities with high a risk of fraud for efficient targeting of the scarce resources. The data that is generated as a result of the audits are fed into the framework for further training.},
  archive   = {C_CEC},
  author    = {Behshad Mohebali and Gelareh Karbaschi and Amirhessam Tahmassebi and Anke Meyer-Baese and Amir H. Gandomi},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504729},
  pages     = {1999-2006},
  title     = {An evolutionary framework for real-time fraudulent credit detection},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Advancing genetic programming via information theory.
<em>CEC</em>, 1991–1998. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504859">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Genetic Programming (GP) is a powerful tool often used to solve optimization problems where analytical methods are unusable. While the general technique is well understood, there exist deficiencies in the multitude of implementations currently widely available. The primary areas of improvement are computation time, search space reduction, and accuracy. Despite significant advances in GP systems, a key deficiency remains in the structural randomization of symbolic GP trees. Our initial assumptions regarding the formation of expression trees in symbolic GP trees is at best highly limited and normally simply non-existent. In this paper, we introduce a new GP methodology that incorporates both current cutting- edge GP system solutions as well as an information-theoretic approach to expression tree initialization. Through a more informed initial tree construction, this approach reduces the search space and model complexity. We introduce in this work the methodology as well as the accompanying theoretical component and comparison benchmarks from tests. A key advantage of the algorithm proposed is its high parallelization potential which is highlighted in further discussion. The method consists of two parts. The first is a variable-interaction system termed Entropy Shaving that is used for both variable selection and initial expression structure generation. The second is a GP system that utilizes the variable-interaction system as input to determine a final solution.},
  archive   = {C_CEC},
  author    = {Aleksandr V Grin and Amir H Gandomi},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504859},
  pages     = {1991-1998},
  title     = {Advancing genetic programming via information theory},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Design of cyclone dust separators: A constrained
multiobjective optimization perspective. <em>CEC</em>, 1983–1990. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504991">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Cyclone dust separators (cyclones for short) are devices used to remove dispersed particles from a flue gas. They are widely applied because of their simple structure, low cost, ease of operation, and ability to operate in harsh environments. In contrast to previous work where the cyclone dust separator design was mainly regarded as an optimization problem with box constraints, we approach it as an optimization task involving the maximization of the collection efficiency and the minimization of the pressure drop, while regarding both box constraints and geometric constraints that limit the designs. We study three highefficiency cyclone configurations, define four test instances for each configuration, and analyze the feasibility ratios resulting from the constraints. In addition, we investigate the performance of three multiobjective optimization algorithms on this design problem. We analyze the results, both in the objective and the decision space, investigate the effect of the decision space size on the solution quality, and gain insights into problem properties relevant to cyclone designers. Finally, we illustrate the results with selected optimized cyclone designs.},
  archive   = {C_CEC},
  author    = {Aljoša Vodopija and Beate Breiderhoff and Boris Naujoks and Bogdan Filipič},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504991},
  pages     = {1983-1990},
  title     = {Design of cyclone dust separators: A constrained multiobjective optimization perspective},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A modified APSODEE for large scale optimization.
<em>CEC</em>, 1976–1982. (<a
href="https://doi.org/10.1109/CEC45853.2021.9505003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The balance of exploration and exploitation of particle swarm optimization (PSO) is still a great challenge in large scale optimization. In our previous work, an adaptive particle swarm optimizer with decoupled exploration and exploitation (APSODEE) has been proposed to solve this problem. However, it still shows room for further improvements. First, APSODEE guides particles with the best individual in each sub-swarm, which is adverse to swarm diversity preservation especially in case of large scale optimization. Second, APSODEE fails to lead particles moving to sparse areas which are also potentially promising. To address these issues, two modifications are incorporated into APSODEE including a partial updating strategy and a quality restrained local sparseness diversity measurement. The former is proposed to further enhance the algorithm&#39;s swarm diversity preservation ability while the latter is designed to help guiding updated particles moving towards the areas which are both sparse and potentially promising, resulting in the modified APSODEE. The experiments are conducted based on CEC 2013 benchmarks with 1000 dimensionality. The results show the competitiveness of the proposed algorithm.},
  archive   = {C_CEC},
  author    = {Dongyang Li and Weian Guo and Lei Wang and Qidi Wu},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9505003},
  pages     = {1976-1982},
  title     = {A modified APSODEE for large scale optimization},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Attention-oriented brain storm optimization for multimodal
optimization problems. <em>CEC</em>, 1968–1975. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504871">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Population-based methods are often used to solve multimodal optimization problems. By combining niching or clustering strategy, the state-of-the-art approaches generally divide the population into several subpopulations to find multiple solutions for a problem at hand. However, these methods only guided by the fitness value during iterations, which are suffering from determining the number of subpopulations, i.e., the number of niche areas or clusters. To compensate for this drawback, this paper presents an Attention-oriented Brain Storm Optimization (ABSO) method that introduces the attention mechanism into a relatively new swarm intelligence algorithm, i.e., Brain Storm Optimization (BSO). By converting the objective space from the fitness space into &quot;attention&quot; space, the individuals are clustered and updated iteratively according to their salient values. Rather than converge to a single global optimum, the proposed method can guide the search procedure to converge to multiple &quot;salient&quot; solutions. The preliminary results show that the proposed method can locate multiple global and local optimal solutions of several multimodal benchmark functions. The proposed method needs less prior knowledge of the problem and can automatically converge to multiple optimums guided by the attention mechanism, which has excellent potential for further development.},
  archive   = {C_CEC},
  author    = {Jian Yang and Yuhui Shi},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504871},
  pages     = {1968-1975},
  title     = {Attention-oriented brain storm optimization for multimodal optimization problems},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey of nearest-better clustering in swarm and
evolutionary computation. <em>CEC</em>, 1961–1967. (<a
href="https://doi.org/10.1109/CEC45853.2021.9505008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Nearest-Better Clustering (NBC) is an emergent niching technique in Swarm and Evolutionary Computation for optimization, which does not need to fix the number or radius of clusters in advance. The key idea of NBC is to first link each individual to its nearest better neighbor to form a spanning tree of all individuals in the population, and then partition all individuals into clusters by deleting the longer edges in the spanning tree. In this paper, a survey on the Nearest-Better Clustering algorithms and applications in multimodal and dynamic optimization is provided. First, the basic NBC algorithm is introduced. Second, the improvements of the basic NBC are detailed. Third, multimodal and dynamic optimization algorithms powered by NBC are enlisted and discussed.},
  archive   = {C_CEC},
  author    = {Wenjian Luo and Xin Lin and Jiajia Zhang and Mike Preuss},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9505008},
  pages     = {1961-1967},
  title     = {A survey of nearest-better clustering in swarm and evolutionary computation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A knowledge transfer-based evolutionary algorithm for
multimodal optimization. <em>CEC</em>, 1953–1960. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504774">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {There are some natural similarities among fitness landscapes of different modals involved in a multimodal optimization problem (MMOP). However, existing multimodal evolutionary algorithms (MMEAs) tend to handle these modals separately, which limits their performance to a great extent. As the first attempt, this study proposes a knowledge transfer-based MMEA by mining and exploiting modal similarities. To this end, a center-aligned normalization strategy (CANS) is first designed to map all the subpopulations corresponding to identified modals into a unified 0-1 space, and then a distribution similarity-based transfer strategy (DSTS) is proposed to guide knowledge transfer among subpopulations. DSTS explicitly quantifies the similarity between two subpopulations and probabilistically transfers elite individuals in the subpopulation of the largest similarity to the target subpopulation. By integrating CANS and DSTS into a well-known MMEA, i.e., NEA2, the final knowledge transfer-based NEA named KTNEA is developed. Experimental results on CEC&#39;2013 niching benchmark suite indicate that KTNEA performs competitively in comparison with state-of-the-art MMEAs.},
  archive   = {C_CEC},
  author    = {Wenhao Du and Zhigang Ren and An Chen and Hanqing Liu},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504774},
  pages     = {1953-1960},
  title     = {A knowledge transfer-based evolutionary algorithm for multimodal optimization},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Helper objective assisted evolutionary algorithm for
multi-modal optimization. <em>CEC</em>, 1946–1952. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504932">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Evolutionary algorithms (EAs) have been widely applied in various optimization problems. However, EAs are found as less effective on multi-modal optimization due to their multiple local optima. Inspired by the idea of self-paced learning, that is, problems can be solved step by step, from easy to difficult. In this study, we propose to design a helper objective function to assist the optimization of multi-modal problems via multitask optimization framework. In principle the helper objective function shares common features with the original function but is easier to solve. Thus, the information gained by solving the helper objective can be utilized to tackle the multi-modal problems. Specifically, the Gaussian process is applied to build the helper objective function. The multi-factorial evolutionary algorithm is applied to optimize the helper and original objective functions simultaneously. Experimental results show that the idea is effective on a set of multi-modal optimization benchmarks.},
  archive   = {C_CEC},
  author    = {Xu Yang and Rui Wang and Wenhua Li},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504932},
  pages     = {1946-1952},
  title     = {Helper objective assisted evolutionary algorithm for multi-modal optimization},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A reinforcement-learning-based evolutionary algorithm using
solution space clustering for multimodal optimization problems.
<em>CEC</em>, 1938–1945. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504896">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In evolutionary algorithms, how to effectively select interactive solutions for generating offspring is a challenging problem. Though many operators are proposed, most of them select interactive solutions (parents) randomly, having no specificity for the features of landscapes in various problems. To address this issue, this paper proposes a reinforcement-learning-based evolutionary algorithm to select solutions within the approximated basin of attraction. In the algorithm, the solution space is partitioned by the k-dimensional tree, and features of subspaces are approximated with respect to two aspects: objective values and uncertainties. Accordingly, two reinforcement learning (RL) systems are constructed to determine where to search: the objective-based RL exploits basins of attraction (clustered subspaces) and the uncertainty-based RL explores subspaces that have been searched comparatively less. Experiments are conducted on widely used benchmark functions, demonstrating that the algorithm outperforms three other popular multimodal optimization algorithms.},
  archive   = {C_CEC},
  author    = {Hai Xia and Changhe Li and Sanyou Zeng and Qingshan Tan and Junchen Wang and Shengxiang Yang},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504896},
  pages     = {1938-1945},
  title     = {A reinforcement-learning-based evolutionary algorithm using solution space clustering for multimodal optimization problems},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). A visualisation method for pareto front approximations in
many-objective optimisation. <em>CEC</em>, 1929–1937. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504904">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Visualisation of Pareto Front (PF) approximations of many-objective optimisation problems (MaOP) is critical in understanding and solving a MaOP. Research is ongoing on developing effective visualisation methods with desired properties, such as simultaneously revealing dominance relations, PF shape, and the diversity of approximations. State-of-the-art visualisation methods in the literature often retain some of the preferred properties, but there are still shortfalls to address others. A new visualisation method is proposed in this paper, which covers the majority of the desired properties for visualisation methods. The proposed method is based on displaying PF approximations via projections on a reference vector versus distances to the same reference vector. The reference vector is created using nominal Ideal and Nadir points of existing nondominated PF approximation sets. MaF benchmark problems are used to demonstrate the effectiveness; results show that the proposed method exhibits a more balanced performance than the state-of-the-art in capturing desired visualisation properties.},
  archive   = {C_CEC},
  author    = {Kai Eivind Wu and George Panoutsos},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504904},
  pages     = {1929-1937},
  title     = {A visualisation method for pareto front approximations in many-objective optimisation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Comparing selection hyper-heuristics for many-objective
numerical optimization. <em>CEC</em>, 1921–1928. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504934">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Mechanisms for automatic selection of parameters/heuristics used by evolutionary algorithms can provide more robust and independent approaches. In this work we propose an approach composed of a selection hyper-heuristic implemented within the MOEA/DD (Multi-objective Evolutionary Algorithm based on Dominance and Decomposition) algorithm based on Differential Evolution. Four selection hyper-heuristics are considered in this study: Thompson Sampling, Probability Matching, Adaptive Pursuit and Self-Adaptive Differential Evolution. The hyper-heuristics are employed to choose the crossover operator selected from a pool of operators, according to a probability that reflects the operator’s previous performance during the evolutionary process. The MaF benchmark is considered with 5, 10 and 15 objectives. This benchmark includes a diversity of characteristics, representing the challenges that real-world problems may pose. Statistical tests indicate that the proposed approach performs equally or even outperforms those with fixed crossover operator.},
  archive   = {C_CEC},
  author    = {Sandra M. Venske and Carolina P. Almeida and Myriam R. Delgado},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504934},
  pages     = {1921-1928},
  title     = {Comparing selection hyper-heuristics for many-objective numerical optimization},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Periodical generation update using an unbounded external
archive for multi-objective optimization. <em>CEC</em>, 1912–1920. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504831">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the evolutionary multi-objective optimization (EMO) community, an unbounded external archive has been used in some studies for evaluating the performance of EMO algorithms. Those studies show that the unbounded external archive often includes better solutions than the final population. Thus, it is likely that the search ability of an EMO algorithm can be improved by periodically updating the current population using the unbounded external archive (i.e., by periodically choosing good solutions from all the examined solutions as the current population). However, the usefulness of such a global generation update scheme has not been studied in the literature. In this paper, we examine the effect of the periodical global generation update on the performance of well-known and frequently-used EMO algorithms: NSGA-II, MOEA/D and NSGA-III. We use the PBI function with uniformly distributed weight vectors for the periodical global generation update. In our computational experiments, we obtain clearly improved results by the periodical global generation update. We also examine the effect of the frequency of the global generation update (e.g., every 20 generations) on the performance of each EMO algorithm and its run time.},
  archive   = {C_CEC},
  author    = {Longcan Chen and Lie Meng Pang and Hisao Ishibuchi and Ke Shang},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504831},
  pages     = {1912-1920},
  title     = {Periodical generation update using an unbounded external archive for multi-objective optimization},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-objective tabu-based differential evolution for
teleportation of smart virtual machines in private computing clouds.
<em>CEC</em>, 1904–1911. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504735">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose a multi-objective approach for using differential evolution algorithm with tabu search algorithm as an additional mutation for live migration (teleportation) of virtual machines. This issue is crucial in private computing clouds. Teleportation of virtual machines is supposed to be planned to determine Pareto-optimal solutions for several criteria such as workload of the bottleneck host, communication capacity of the critical node, electric power of hosts, and computer costs. Some numerical results are presented for the experimental cloud based on OpenStack platform for smart city and smart education systems.},
  archive   = {C_CEC},
  author    = {Balicki Jerzy and Dryja Piotr},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504735},
  pages     = {1904-1911},
  title     = {Multi-objective tabu-based differential evolution for teleportation of smart virtual machines in private computing clouds},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A many-objective evolutionary algorithm based on new angle
penalized distance. <em>CEC</em>, 1896–1903. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504935">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In evolutionary many-objective optimization, achieving better balance between convergence and diversity of the population is a crucial way to improve the efficiency of the algorithm. However, diversity measure may select the individuals having good diversity but degrade the convergence process to a certain extent. If the convergence measure focuses on the convergence of the individuals too much, it may lead to local convergence. The selection pressure achieves a severe loss, especially when the Pareto dominance selection mechanism is difficult to select solutions. To address these issues, a many-objective evolutionary algorithm based on new angle penalized distance is proposed in this paper, which is termed MaOEA-NAPD. In MaOEA-NAPD, it could dynamically balance the convergence and diversity of the population concerning their importance degree during the evolutionary process based on new angle penalized distance. In order to enhance the selection probability of better solutions in the mating pool, new convergence measure and diversity measure are introduced according to the achievement scalarizing function and angle based crowding degree estimation, respectively. The performance of the proposed method is evaluated and compared with five state-of-the-art algorithms on the WFG test suites with up to 15 objectives. Experimental results show the superior performance of MaOEA-NAPD than the compared algorithms on all the considered test instances.},
  archive   = {C_CEC},
  author    = {Junchao Fang and Wei Fang},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504935},
  pages     = {1896-1903},
  title     = {A many-objective evolutionary algorithm based on new angle penalized distance},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An adaptive formulation-based many-objective evolutionary
algorithm for multi-scenario optimization in data enrichment.
<em>CEC</em>, 1888–1895. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504806">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In many practical applications, data enrichment can generate a large amount of accurate data to alleviate the problem of data scarcity. In order to make the fake data generated in data enrichment as close to the real data as possible, the data enriching model must be tuned to meet the loss requirements of multiple objectives in different scenarios, which makes it a multi-scenario many-objective optimization problem. However, due to the curse of the dimensionality of the scenario space and the objective space, the existing many-objective evolutionary algorithms cannot solve the problem in data enrichment well. To effectively handle this problem, we propose an adaptive formulation-based multi-objective evolutionary algorithm, where the aggregation function is used to reduce the dimension of the scenario space to one and the multiple objectives into three objectives through the adaptive formulation of the original problem. In this way, a multi-scenario many-objective problem is converted into a multi-objective problem which could be solved by existing multi-objective evolutionary algorithms. The proposed algorithm is applied to the practical data enrichment problem to solve the multi-scenario many-objective optimization problem and compared with NSGA-III. The experimental results demonstrate the remarkable superiority of the proposed algorithm over NSGA-III.},
  archive   = {C_CEC},
  author    = {Liang Fan and Xudong Feng and Handing Wang},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504806},
  pages     = {1888-1895},
  title     = {An adaptive formulation-based many-objective evolutionary algorithm for multi-scenario optimization in data enrichment},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Achieving multi-objective scheduling of heterogeneous
workflows in cloud through a genetic programming based approach.
<em>CEC</em>, 1880–1887. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504695">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Traditional human-designed heuristics-based algorithms are commonly employed to address workflow scheduling problems. Such as Heterogeneous Earliest Finish Time (HEFT) and CriticalPath are two best-known list based heuristics. Generally, heuristics-based approaches can generate a single heuristic by making decisions based on the current status of the tasks and available resources and map the unscheduled tasks to the available resources. However, traditional heuristics can easily cause unbalancing load problem. For example, with the objective of minimizing the makespan, traditional heuristics prefer to use computation resources with high computation capacity. Usually, such resources are expensive, which will lead to a high cost as a result. Therefore it is hard for single traditional heuristics to do a trade-off; thus, traditional heuristics are hard to apply for multi-objective workflow scheduling. In this paper, we develop a novel algorithm for workflow scheduling by considering both minimizing cost and makespan. Experiments show that the MOSGP approach can effectively minimize makespan and cost simultaneously.},
  archive   = {C_CEC},
  author    = {Yongbo Yu and Hui Ma and Gang Chen},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504695},
  pages     = {1880-1887},
  title     = {Achieving multi-objective scheduling of heterogeneous workflows in cloud through a genetic programming based approach},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Look-ahead genetic programming for uncertain capacitated arc
routing problem. <em>CEC</em>, 1872–1879. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504785">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Genetic Programming Hyper-Heuristic (GPHH) has been successfully applied to evolve routing policies for the Uncertain Capacitated Arc Routing Problem (UCARP). However, the current GPHH approaches have a limitation that they only consider myopic information of the current decision step. In this paper, we proposed incorporating look-ahead information to the decision process of GP-evolved routing policies. We designed a number of potentially promising chains of candidate tasks, and expand the candidate task pool to consider both the single tasks and task chains. This way, the routing policy can consider the look-ahead information incorporated in the considered task chains. The proposed GP with Chain Policies (GPCP) was compared with the standard GPHH on a range of UCARP instances, and the results showed that the task chains can improve the effectiveness of the routing policies sometimes. The better performance of a routing policy largely depends on whether it can balance the selections of single tasks and task chains, and whether it can stick to the whole selected chain rather than only the first task of the chain. In addition, there are some abnormal runs with serious overfitting issue that we will address in our future work.},
  archive   = {C_CEC},
  author    = {Jordan MacLachlan and Yi Mei},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504785},
  pages     = {1872-1879},
  title     = {Look-ahead genetic programming for uncertain capacitated arc routing problem},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Learning initialisation heuristic for large scale vehicle
routing problem with genetic programming. <em>CEC</em>, 1864–1871. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504938">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Large Scale Vehicle Routing Problem is a classical NP-hard problem. It has several applications in the industry and has always been the focus of studies and development of new, ever more complex, techniques to solve it. An important group of these techniques are Local Search-based, which are sensitive to the initial solution given to them. However, finding effective initial solutions is not a trivial task, requiring domain knowledge for building them. Although some Genetic Programming Hyper-Heuristics (GPHH) have tried to build better heuristics automatically, they barely give an advantage for improving the solution afterwards. This paper aims to show that Genetic Programming can identify better regions of the search space, where the initial solutions can be improved more efficiently with optimisation steps. This is done by developing new terminals and a new fitness function, which are based on the width of the routes, a metric that was recently found to be an important feature for good solutions. The obtained results show that the proposed approach finds better final solutions than when using classical initial heuristics or other GPHH, for both time efficiency and effectiveness.},
  archive   = {C_CEC},
  author    = {Joao Guilherme Cavalcanti Costa and Yi Mei and Mengjie Zhang},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504938},
  pages     = {1864-1871},
  title     = {Learning initialisation heuristic for large scale vehicle routing problem with genetic programming},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A dynamic multiagent genetic algorithm for optimal charging
in wireless rechargeable sensor networks. <em>CEC</em>, 1856–1863. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504883">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Wireless energy charging is considered as a very promising technology for prolonging sensor lifetime in Wireless Rechargeable Sensor Networks (WRSNs). However, most existing studies suffers from charging scalability and efficiency problems. Under such a background, a new one to many charging model, which allows multiple sensors to be charged simultaneously by a single mobile reader, is designed. A dynamic multiagent genetic algorithm with a virtual force operator combined with K-means clustering for WRSNs (D_VF_MAGA_WRSNs) is proposed to optimize the charging problem in this paper. Agents representing candidate solutions compete or cooperate with their neighbors, and can also use knowledge. Memetic algorithm is applied in the process of evolution to guide readers moving to the tags&#39; clustering centers obtained by the K-means algorithm. Moreover, a special crossover operator is designed to dynamically adjust the number of reader charging positions in the network. To verify the effectiveness of D_VF_MAGA_WRSNs, various of experiments on different kinds of benchmarks are carried. Compared with other algorithms, our algorithm is illustrated to be superior for WRSNs in terms of total charging time, maximum charging load, charging efficiency, and total charging distance.},
  archive   = {C_CEC},
  author    = {Yating Cao and Jing Liu and Zhouwu Xu},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504883},
  pages     = {1856-1863},
  title     = {A dynamic multiagent genetic algorithm for optimal charging in wireless rechargeable sensor networks},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Genetic programming with algebraic simplification for
dynamic job shop scheduling. <em>CEC</em>, 1848–1855. (<a
href="https://doi.org/10.1109/CEC45853.2021.9505010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Genetic Programming (GP) has been successfully applied to evolve effective dispatching rules for Dynamic Job Shop Scheduling (DJSS). However, the GP-evolved rules are usually too complex and hard to interpret. In this paper, we aim to address this issue by evolving simpler rules without losing effectiveness. To this end, we develop a set of algebraic simplification operators based on our domain knowledge about dynamic scheduling, which can recursively convert a rule into a mathematically equivalent but simpler one. The algebraic simplification operators can guarantee that the individual stays equivalent before and after the simplification. Then, we develop a GP algorithm with these simplification operators. We compared the GP with the simplification operators with the baseline GP without simplification on a range of scheduling instances, and the results showed that using the algebraic simplification can slightly reduce the program size without sacrificing the test performance of the evolved dispatching rules. Furthermore, through deep analysis, we have also discovered the limitations of the pure algebraic simplification for GP to evolve DJSS dispatching rules, which can hardly simplify the individuals after the first generation.},
  archive   = {C_CEC},
  author    = {Sai Panda and Yi Mei},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9505010},
  pages     = {1848-1855},
  title     = {Genetic programming with algebraic simplification for dynamic job shop scheduling},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Preferred solutions of the ground station scheduling problem
using NSGA-III with weighted reference points selection. <em>CEC</em>,
1840–1847. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504886">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Ground station Scheduling Problem refers to the allocation of the communication tasks, among the ground stations and satellites. In general, the problem is formulated as a many-objective problem. The NSGA-III is an algorithm developed to solve such problems. Due to its selection operator that uses a number of reference points, the NSGA-III gives users the option to specify their own reference points. In this paper, we use this opportunity by generating distributed reference points, shifted depending on weights. A specific weight is assigned to each objective that corresponds to reference points for preferred solutions. The generation of these reference points and their effect on the final objective function values of the Pareto front are first tested on the DTLZ2 test function with 4 objectives and for a different combination of weights. Finally, various weights are applied to an instance of the Ground station Scheduling Problem, leading to Pareto fronts that favor specific objectives and feasible schedules.},
  archive   = {C_CEC},
  author    = {Margarita Antoniou and Gašper Petelin and Gregor Papa},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504886},
  pages     = {1840-1847},
  title     = {Preferred solutions of the ground station scheduling problem using NSGA-III with weighted reference points selection},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Quantum-inspired differential evolution for
resource-constrained project-scheduling: Preliminary study.
<em>CEC</em>, 1833–1839. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504970">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Resource-Constrained Project Scheduling Problem (RCPSP) is an NP-hard optimisation problem that can be found in many real-world applications. Considerable research effort has been put into overcoming the difficulties in solving the RCPSP by proposing innovative heuristics, meta-heuristics and their hybridisation. However, finding optimal solutions is still not guaranteed. It is known that quantum-inspired metaheuristics can improve population diversity and the quality of solutions but little has been published on adapting them to solving RCPSPs. Here, we examine the performance of a Quantum-Inspired Differential Evolution (QIDE) algorithm in solving such problems. The proposed QIDE uses a quantum population that is initialised using the rotation quantum gate and quantum superposition in the continuous domain, and then evolved using the differential-evolution operators. A local search is also adopted to accelerate convergence. The performance of the QIDE algorithm was tested by solving problems with 30 and 60 activities from the PSPLIB benchmark datasets. The QIDE algorithm outperformed another quantum-based particle swarm algorithm and some other meta-heuristics.},
  archive   = {C_CEC},
  author    = {Hatem M.H. Saad and Ripon K. Chakrabortty and Saber Elsayed},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504970},
  pages     = {1833-1839},
  title     = {Quantum-inspired differential evolution for resource-constrained project-scheduling: Preliminary study},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Genetic algorithms for error mitigation in quantum
measurement. <em>CEC</em>, 1826–1832. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504796">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Noisy Intermediate Scale Quantum (NISQ) devices are expected to demonstrate the real potential of quantum computing in solving hard problems. However, quantum noise that characterizes this kind of devices still remains an obstacle for their practical exploitation in real world scenarios. As a consequence, there is a strong emergence for error correction techniques aimed at making NISQ devices stable and fully operative. Unfortunately, current approaches for quantum error correction are prohibitive for NISQ devices because of the enormous multiplicative cost in resources that they require. For this reason, so-called quantum error mitigation methods are emerging as alternative approaches able to attenuate the quantum error as much as possible, without requiring a strong additional computational effort. Among the most error-prone operations, there is surely the quantum measurement. Conventionally, mitigation methods for quantum measurement error compute a so-called mitigation matrix capable of correcting results outputted by a quantum processor. In this paper, a new measurement error mitigation approach based on genetic algorithms is proposed to learn an appropriate mitigation matrix. As shown in the experimental session, the proposed measurement error mitigation method is comparable with or better than a conventional algebraic approach in terms of the Hellinger fidelity.},
  archive   = {C_CEC},
  author    = {Giovanni Acampora and Michele Grossi and Autilia Vitiello},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504796},
  pages     = {1826-1832},
  title     = {Genetic algorithms for error mitigation in quantum measurement},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Loading is the key: A novel genetic quantum algorithm for
SDVRP. <em>CEC</em>, 1817–1825. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504873">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper solves Split Demand Vehicle Routing Problem with minimal vehicles and controlled task splits. Our algorithm encodes the mapping between task splits and vehicles into a binary matrix and uses Genetic Quantum Algorithm to control the evolvement process. To convert the binary matrix solution into task loading schemes, we design a novel cost function and successfully convert task assignment problem to Transportation Problem which can be solved by Transportation Simplex Method. Our algorithm uses a simple nearest-neighborhood based heuristic to generate vehicle routes and adopts a local search method tailored for SDVRP to improve solution quality. The experimental results show that our algorithm splits few tasks and can obtain many solutions better than CVRP best-known in TSPLIB 95. Further analysis reveals that savings of SDVRP mostly come from CVRP’s failure to combine tasks geographically close into one route, when the number of vehicles are restricted to minimum.},
  archive   = {C_CEC},
  author    = {Weijian Ma and Xinyuan Zhang and Yichen Xu and Fei Gao},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504873},
  pages     = {1817-1825},
  title     = {Loading is the key: A novel genetic quantum algorithm for SDVRP},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A genetic algorithm for scheduling splittable tasks with
precedence constraints. <em>CEC</em>, 1808–1816. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504867">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In many applications, the logic of the program can be described using a task graph, where the data dependencies and execution time of each task are described. These dependencies create precedence constraints among tasks, which are requirements that some tasks must be finished before some other tasks. Many efforts have been put into scheduling parallelizable tasks that synchronically use multiple cores. In some cases, the task can be chunked into smaller pieces and scheduled independently, allowing further flexible schedules. However, it is usually either assumed that such splitting has no overhead, or that precedence constraints are not present, or that the user has to provide the way of splitting. This paper addresses the problem where these factors are considered together, that is scheduling splittable tasks with precedence constraints, where splitting introduces an overhead and the splitting of tasks are determined by the algorithm. The objective is to minimize the makespan of the schedule. We first present a mixed-integer quadratic program (MIQP) formulation of the problem. Then, a genetic algorithm (GA) is devised and its performance is compared with the MIQP solutions. We show that the genetic algorithm can produce reasonably good schedules compared with MIQP output within a significantly shorter time, and it has the potential to handle large task graphs.},
  archive   = {C_CEC},
  author    = {Yuanliang Gao and Sheung-Hung Poon},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504867},
  pages     = {1808-1816},
  title     = {A genetic algorithm for scheduling splittable tasks with precedence constraints},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Tracking the heritage of genes in evolutionary algorithms.
<em>CEC</em>, 1800–1807. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504916">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper aims to introduce a methodology to trace the influence of the initial population of an evolutionary algorithm to the final population. The major challenge concerns tracking the heritage of multiple parent operators. In this paper, we propose a new encoding for tracking purposes. In addition, we propose modifications to the corresponding metrics for measuring the impact of individuals. With this approach, we provide several tools to not only track the influence of the initial population on the results but also to study the effects of different crossover and mutation operators. In our experiments, we evaluate the differences between two selected crossover and mutation operators and provide insight into the proposed approach.},
  archive   = {C_CEC},
  author    = {Tobias Benecke and Sanaz Mostaghim},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504916},
  pages     = {1800-1807},
  title     = {Tracking the heritage of genes in evolutionary algorithms},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Genetic algorithm with multiple fitness functions for
generating adversarial examples. <em>CEC</em>, 1792–1799. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504790">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Studies have shown that deep neural networks (DNNs) are susceptible to adversarial attacks, which can cause misclassification. The adversarial attack problem can be regarded as an optimization problem, then the genetic algorithm (GA) that is problem-independent can naturally be designed to solve the optimization problem to generate effective adversarial examples. Considering the dimensionality curse in the image processing field, traditional genetic algorithms in high-dimensional problems often fall into local optima. Therefore, we propose a GA with multiple fitness functions (MF-GA). Specifically, we divide the evolution process into three stages, i.e., exploration stage, exploitation stage, and stable stage. Besides, different fitness functions are used for different stages, which could help the GA to jump away from the local optimum.Experiments are conducted on three datasets, and four classic algorithms as well as the basic GA are adopted for comparisons. Experimental results demonstrate that MF-GA is an effective black-box attack method. Furthermore, although MF-GA is a black-box attack method, experimental results demonstrate the performance of MF-GA under the black-box environments is competitive when comparing to four classic algorithms under the white-box attack environments. This shows that evolutionary algorithms have great potential in adversarial attacks.},
  archive   = {C_CEC},
  author    = {Chenwang Wu and Wenjian Luo and Nan Zhou and Peilan Xu and Tao Zhu},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504790},
  pages     = {1792-1799},
  title     = {Genetic algorithm with multiple fitness functions for generating adversarial examples},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fitness caching - from a minor mechanism to major
consequences in modern evolutionary computation. <em>CEC</em>,
1785–1791. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504686">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the field of Evolutionary Computation, the main objective is to find a high-quality solution to the considered problem. However, the other important issue is to find a solution efficiently. Therefore, evolutionary methods use various techniques to adjust to the problem and reduce the amount of resources consumed during an optimization process. One of the well-known and relatively simple techniques is storing the already evaluated genotypes and their ratings. Whenever an evolutionary method is to evaluate the fitness for a genotype that was already rated, instead of re-evaluating it, a method may use the value that was stored in the repository. Surprisingly, despite its simplicity, such a fitness caching technique was shown to cause many important phenomena. When an evolutionary method is stuck, fitness caching may cause such significant fitness function evaluation (FFE) reduction that FFE will not be a reliable resource consumption measure anymore. Moreover, fitness caching may help in detecting the drop in the number of new solutions investigated by a method. Thus, it may help in dynamic population-size management. Such a consequence is far more sophisticated than a simple FFE reduction. Therefore, in this paper, we investigate fitness caching in more detail. We analyze its influence on chosen state-of-the-art methods employed to solve well-known theoretical problems.},
  archive   = {C_CEC},
  author    = {Michal W. Przewozniczek and Marcin M. Komarnicki},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504686},
  pages     = {1785-1791},
  title     = {Fitness caching - from a minor mechanism to major consequences in modern evolutionary computation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Autonomous monitoring system for water resources based on
PSO and gaussian process. <em>CEC</em>, 1777–1784. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504936">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Monitoring water resources represents a crucial task not just for nature preservation worldwide but also for human survival. Traditional methods, based on manual sampling routines, are inefficient in the context of large bodies of water. For this reason the interest in new monitoring approaches based on autonomous vehicles has increased during the last few years. Among these, strategies based on fleets or swarms of vehicles have been proven especially efficient. One of the main components of these systems is the global mission planner, which is responsible for determining the optimal movements. In this paper a novel Particle Swarm Optimization (PSO), based on a surrogate model like a Gaussian Process, is proposed to guide a fleet of Autonomous Surface Vehicles (ASV). The proposed approach takes advantage of the uncertainty provided by the Bayesian model to guide the movements of the swarm towards unexplored areas of the search space. The proposed system has been validated using a benchmark function that models a water quality parameter, achieving better results than the original PSO algorithm.},
  archive   = {C_CEC},
  author    = {Micaela Jara Ten Kathen and Isabel Jurado Flores and Daniel Gutiérrez Reina and Alejandro Tapia Córdoba},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504936},
  pages     = {1777-1784},
  title     = {Autonomous monitoring system for water resources based on PSO and gaussian process},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploiting linear interpolation of variational autoencoders
for satisfying preferences in evolutionary design optimization.
<em>CEC</em>, 1767–1776. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504772">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the early design phase of automotive digital development, one of the key challenges for the designer is to consider multiple-criteria like aerodynamics and structural efficiency besides aesthetic aspects for designing a car shape. In our research, we imagine a cooperative design system in the automotive domain which provides guidance to the designer for finding sets of design options or well-performing designs for preferred search areas. In the present paper, we focus on two perspectives for this multi-criteria decision-making problem: First, a scenario without prior information about design preferences, where the designer aims to explore the search space for a diverse set of design alternatives. Second, a scenario where the designer has a prior intuition on preferred solutions of interest. For both scenarios, we assume that historic 3D car shape data exists, which we can utilize to learn a compact low-dimensional design representation based on a variational autoencoder (VAE). In contrast to evolutionary multi-objective optimization approaches where starting populations are randomly initialized, we propose to seed the population more efficiently by exploiting the advantage of linear interpolation in the latent space of the VAE. In our experiments, we demonstrate that the multi-objective optimization converges faster and achieves a diverse set of solutions. For the second scenario, when specifying design preferences by weights, we improve on the weighted-sum method, which simplifies the multi-objective problem and propose a strategy for efficiently adapting the weights towards the preferred design solution.},
  archive   = {C_CEC},
  author    = {Sneha Saha and Leandro L. Minku and Xin Yao and Bernhard Senhoff and Stefan Menzel},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504772},
  pages     = {1767-1776},
  title     = {Exploiting linear interpolation of variational autoencoders for satisfying preferences in evolutionary design optimization},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A multiobjective optimization approach for reducing air
traffic collision risk. <em>CEC</em>, 1759–1766. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504707">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Air transport contributes significantly to the globalization and world economic. With the increasing demand for both passengers and air cargo, future airspace may encounter unprecedented traffic pressure. It is always the paramount commitment of air transport to ensure flying safety. In the face of increasing traffic demand, it is pertinent to investigate how to reduce en-route collision risk without compromising the traffic demand. In this paper, we propose a multiobjective optimization based method to reduce the technical vertical risk (TVR) by controlling en-route air traffic speed. The suggested method simultaneously optimizes two objectives. The first one aims to minimize the TVR while the second tries to minimize the traffic delay. As the modeled optimization problem is non-convex and the two objectives conflict with each other, we therefore introduce two well-known multiobjective evolutionary algorithms named NSGA-II and NSGA-III and modify some of their operators to solve the proposed optimization problem. Finally, we carry out experiments on sixteen real-world daily traffic sample data that cover en-route flights within the Singapore flight information region (FIR). Experiments demonstrate that by optimizing the proposed problem using the introduced algorithms we obtain a set of speed control suggestions each of which can reduce the TVR for the Singapore FIR. This work will contribute both to strategical and tactical air traffic management as the aviation players can make the preferred choices based on the solutions yielded by the introduced algorithms.},
  archive   = {C_CEC},
  author    = {Qing Cai and Haojie Ang and Sameer Alam},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504707},
  pages     = {1759-1766},
  title     = {A multiobjective optimization approach for reducing air traffic collision risk},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimizing parameters of self-organizing model for swarm
robots via evolutionary algorithms. <em>CEC</em>, 1751–1758. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504922">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A swarm of robots is a typical self-organizing system. Parameters of self-organizing model can regulate the interaction among the individuals to achieve the desired collective motion. Thus, it makes sense to optimize the parameters for better performance in self-organization. The evolutionary algorithm (EA) is one promising heuristic optimization algorithm. However, quantitative evaluation of a self-organizing model is still an open scientific question. In this paper, we proposed three metrics for collective motion from the perspective of grouping, polarization and spatial distribution of group. Then, we designed the fitness function with the proposed metrics to bridge the gap between EA and parameter tuning of self-organizing model. In the experimental study, we optimized two kinds of self-organizing models using the differential evolution algorithm (DE) and validated the effectiveness in simulation. Moreover, we validated the optimized parameters on a swarm of physical robots. The experimental results show that the proposed metrics are effective to quantitatively evaluate the self-organizing model so that the DE performs well for the automatic parameter tuning of controlling swarm robots.},
  archive   = {C_CEC},
  author    = {Zhicheng Zheng and Yanan Li and Xiaokang Lei and Xingguang Peng},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504922},
  pages     = {1751-1758},
  title     = {Optimizing parameters of self-organizing model for swarm robots via evolutionary algorithms},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploiting artificial swarms for the virtual measurement of
backlash in industrial robots. <em>CEC</em>, 1743–1750. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504962">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The backlash is a lost motion in a mechanism created by gaps between its parts. It causes vibrations that increase over time and negatively affect accuracy and performance. The quickest and most precise way to measure the backlash is to use specific sensors, that have to be added to the standard equipment of the robot. However, this solution is little used in practice because raises the manufacturing costs. An alternative solution can be to exploit a virtual sensor, i.e., the information about phenomena that are not directly measured is reconstructed by signals from sensors used for other measurements.This work evaluates the use of bio-inspired swarm algorithms as the processing core of a virtual sensor for the backlash of a robotic joint. Swarm-based approaches, with their relatively modest occupation of memory and low computational load, could be ideal candidates to solve the problem. In this paper, we exploit four state-of-the-art swarm-based optimization algorithms: the Dragonfly Algorithm, the Ant Lion Optimizer, the Grasshopper Optimization Algorithm, and the Grey Wolf Optimizer. The four candidate algorithms are compared on 20 different datasets covering a range of backlash values that reflect an industrial case scenario. Numerical results indicate that, unfortunately, none of the algorithms considered provides satisfactory solutions for the problem analyzed. Therefore, even if promising, these algorithms cannot represent the final choice for the problem of interest.},
  archive   = {C_CEC},
  author    = {Eliana Giovannitti and Sayyidshahab Nabavi and Giovanni Squillero and Alberto Tonda},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504962},
  pages     = {1743-1750},
  title     = {Exploiting artificial swarms for the virtual measurement of backlash in industrial robots},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Particle swarm optimisation for analysing time-dependent
photoluminescence data. <em>CEC</em>, 1735–1742. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504908">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Next-generation photovoltaic materials such as per-ovskites and organic photovoltaics are promising candidates for cheap, solution-processable solar cells, which have the environmental and financial advantages compared to traditional silicon-based cells. To realise commercial solar cells, the development of new materials to improve the performance is needed. Time-resolved optical spectroscopy is a powerful technique for photovoltaic materials that allows measurement of reveal the energy-dependent dynamics of photoexcited species (charges and excitons), which are responsible for the device performance. Although time-resolved spectroscopy provides contains rich information, the data analysis can be time-consuming and labour-intensive. Automated data-processing is therefore an attractive proposition to facilitate higher throughput. This paper describes a new application of evolutionary computation technique - particle swarm optimisation (PSO) - to parametrise time-resolved photoluminescence (PL) data. PSO is used to convert time- and energy-resolved photoluminescence data into decay rate distributions. From this, the excited state lifetimes can be elucidated – a key parameter for the optimisation of photovoltaic performance. The implementation of PSO in enhanced LumiML proved advantageous, yielding considerable improvements over previous techniques LumiML by two orders of magnitude.},
  archive   = {C_CEC},
  author    = {Demelza Robinson and Qi Chen and Bing Xue and Isabella Wagner and Michael Price and Paul Hume and Kai Chen and Justin Hodgkiss and Mengjie Zhang},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504908},
  pages     = {1735-1742},
  title     = {Particle swarm optimisation for analysing time-dependent photoluminescence data},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evolutionary ensemble learning using multimodal
multi-objective optimization algorithm based on grid for wind speed
forecasting. <em>CEC</em>, 1727–1734. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504754">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Improving the accuracy of wind speed forecasting is essential for the usage of wind energy. This paper proposes an evolutionary ensemble learning (EEL) method, which consists of ensemble empirical mode decomposition (EEMD), random vector functional link network (RVFL) based ensemble learning, and grid-based multimodal multi-objective evolutionary algorithm (MMOG). Based on MMOG, the proposed ensemble learning model is improved in terms of accuracy. Several benchmark forecast methods are compared with the proposed EEL model on 12 wind speed forecasting datasets. The experiment results validate the superiority of the proposed EEL model in wind speed forecasting.},
  archive   = {C_CEC},
  author    = {Yi Hu and Jing Liang and Boyang Qu and Jie Wang and Yanli Wang and Panpan Wei},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504754},
  pages     = {1727-1734},
  title     = {Evolutionary ensemble learning using multimodal multi-objective optimization algorithm based on grid for wind speed forecasting},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Path planning based on multi-objective topological map.
<em>CEC</em>, 1719–1726. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504789">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, intelligent robot technology has developed rapidly. As an important topic, path planning has attracted more and more attention. However, the performance of multi-objective path planning is limited by the scale of the problem, and the results of path planning are generally not optimal. In this work, based on 12 problems defined in multimodal multiobjective path planning optimization contest for CEC 2021 [1], we present a multi-objective path planning optimization algorithm, which includes data preprocessing, multi-objective genetic evolution path planning algorithm, and non-dominated sorting algorithm with elite strategy. This algorithm flow can realize multi-objective path planning and generate the optimal solution set (i.e. Pareto solution set). We implement our algorithm flow to calculate the time complexity and space complexity indicators. Experimental results on problems indicate the proposed multi-objective path planning algorithm can solve the optimal solution set in time. Due to the constraints of the problem, the number of optimal solutions is different for different problems. We show the validity of our method with experiments for path planning. Finally, we visually present some experimental results intuitively. The code is released at https://github.com/zhangruihao/pathPlanning.},
  archive   = {C_CEC},
  author    = {Jiaqi Zhao and Zhijie Jia and Yong Zhou and Ruihao Zhang and Zeming Xie and Zikang Xu and Yuxin Li and Di Zhang},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504789},
  pages     = {1719-1726},
  title     = {Path planning based on multi-objective topological map},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new encoding mechanism embedded evolutionary algorithm for
UAV route planning. <em>CEC</em>, 1712–1718. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504874">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Evolutionary algorithms (EAs) are often applied to deal with UAV route planning. The solution encoding is one of important factor in designing effective EAs. In a traditional encoding mechanism, each individual represents one route. The whole population then consists of a number of routes. We argue that such an encoding is less effective in route planning, and then proposed an alternative encoding mechanism in which one individual represents only one navigation point. The whole population then represents one route. This implicitly turns EAs into single-point based search with high exploitation ability. To further improve the exploration ability of algorithms using this new encoding, a slightly modified differential evolution operator is applied. Combining the modified DE operator and the new encoding mechanism, the performance of the derived algorithm is significantly improved, obtaining much better route planning results than DE with the traditional encoding mechanism.},
  archive   = {C_CEC},
  author    = {Nanjiang Dong and Rui Wang and Tao Zhang},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504874},
  pages     = {1712-1718},
  title     = {A new encoding mechanism embedded evolutionary algorithm for UAV route planning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-objective a* algorithm for the multimodal
multi-objective path planning optimization. <em>CEC</em>, 1704–1711. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504943">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we consider the multimodal multi-objective path planning (MMOPP) optimization, which is the main topic of a special session in IEEE CEC 2021. The MMOPP aims at finding all the Pareto optimal paths from a start area to a goal area on a grid map, while passing through several designated must-visit areas. We propose an efficient approach based on the multi-objective A* algorithm to exactly solve the MMOPP. Experiments are conducted on the official MMOPP test suite to evaluate the performance of the proposed approach. We also show the admissibility of the proposed approach so that the computational results can be used as the standard answers to the MMOPP test suite.},
  archive   = {C_CEC},
  author    = {Bo Jin},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504943},
  pages     = {1704-1711},
  title     = {Multi-objective a* algorithm for the multimodal multi-objective path planning optimization},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An adaptive multi-objective multifactorial evolutionary
algorithm based on mixture gaussian distribution. <em>CEC</em>,
1696–1703. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504928">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In recent decades, multi-objective multifactorial evolutionary algorithm (MOMFEA) has become a very promising research direction. How to achieve effective knowledge transfer between similar tasks is the key issue to affect the performance of the algorithm. In this paper, an adaptive MOMFEA (AMOMFEA) is proposed by exploiting the mixture Gaussian distribution of the population distributions of related tasks to help solve the target task. Wasserstein distance is used to measure the inter-task relevance in that the weight coefficient in the mixture distribution is proportional to the inter-task relevance. Experimental results on benchmark problems validate the effectiveness and efficiency of the proposed method in comparison with MOMFEA and NSGA-II.},
  archive   = {C_CEC},
  author    = {Mengfan Xu and Zexuan Zhu and Yutao Qi and Lei Wang and Xiaoliang Ma},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504928},
  pages     = {1696-1703},
  title     = {An adaptive multi-objective multifactorial evolutionary algorithm based on mixture gaussian distribution},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A multi-task approach for maximum survival ratio problem in
large-scale wireless rechargeable sensor networks. <em>CEC</em>,
1688–1695. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504930">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With the breakthrough of electromagnetic power transfer technology, wireless charging has emerged as a hopeful solution for the energy provisioning problem in wireless sensor networks. One of the prominent issues that affect the potential exploitation of this technology is the charging scheduling problem. However, existing works on this topic either focus mainly on using a single mobile charger for the whole network or suffer from several common limitations such as enforcing the chargers to visit all sensors or applying the rigid full-charging scheme. Moreover, they rarely delve into maximizing the survival nodes ratio, which impacts directly on the multi-hop communication of the network. This paper addresses the charging scheduling for multiple mobile chargers without the above limitations. We first formulate a maximum survival ratio problem and prove its NP-hardness. A charging scheme that exploits the advantages of the multifactorial evolutionary algorithm is then proposed to optimize the charging paths of all chargers simultaneously. We finally evaluate the efficacy of the proposed algorithm through extensive simulations. The experimental results demonstrate that our scheduling scheme provides promising outcomes in terms of survival ratio and the traveling energy of chargers.},
  archive   = {C_CEC},
  author    = {Le Van Cuong and Tran Thi Huong and Huynh Thi Thanh Binh},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504930},
  pages     = {1688-1695},
  title     = {A multi-task approach for maximum survival ratio problem in large-scale wireless rechargeable sensor networks},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-task learning for multi-objective evolutionary neural
architecture search. <em>CEC</em>, 1680–1687. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504721">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Neural architecture search (NAS) is an exciting new field in automating machine learning. It can automatically search for the architecture of neural networks. But the current NAS has extremely high requirements for hardware equipment and time costs. In this work, we propose a predictor based on Radial basis function neural network (RBFNN) as a surrogate model of Bayesian optimization to predict the performance of neural architecture. The existing work does not consider the difficulty of directly searching for neural architectures that meet the performance requirements of NAS in real-world applications. Meanwhile, NAS needs to execute multiple times independently when facing multiple similar tasks. Therefore, we further propose a multi-task learning surrogate model with multiple RBFNNs. The model not only functions as a predictor, but also learns knowledge of similar tasks jointly. The performance of NAS is improved by processing multiple tasks simultaneously. Also, the current NAS is committed to searching for very high-performance networks and does not take into account that neural architectures are limited by device memory during actual deployment. The scale of architecture also needs to be considered. We use a multi-objective optimization algorithm to simultaneously balance the performance and the scale, and build a multi-objective evolutionary search framework to find the Pareto optimal front. Once the NAS is completed, decision-makers can choose the appropriate architecture for deployment according to different performance requirements and hardware conditions. Compared with existing NAS work, our proposed MT-ENAS algorithm is able to find a neural architecture with competitive performance and smaller scale in a shorter time.},
  archive   = {C_CEC},
  author    = {Ronghong Cai and Jianping Luo},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504721},
  pages     = {1680-1687},
  title     = {Multi-task learning for multi-objective evolutionary neural architecture search},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). EMT-ReMO: Evolutionary multitasking for high-dimensional
multi-objective optimization via random embedding. <em>CEC</em>,
1672–1679. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504857">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Since multi-objective optimization (MOO) involves multiple conflicting objectives, the high dimensionality of the solution space has a much more severe impact on multi-objective problems than single-objective optimization. Taking the advantage of random embedding, some related works have been proposed to scale derivative-free MOO methods to high-dimensional functions. However, with the premise of &quot;low effective dimensionality&quot;, a single randomly embedded subspace cannot guarantee the effectiveness of obtained solutions. Taking this cue, we propose an evolutionary multitasking paradigm for multi-objective optimization via random embedding (EMT-ReMO) to enhance the efficiency and effectiveness of current embedding-based methods in solving high-dimensional optimization problems with low effective dimensions. In EMT-ReMO, the target problem is firstly embedded into multiple low-dimensional subspaces by using different random embeddings, aiming to build up a multi-task environment for identifying the underlying effective subspace. Then the implicit multi-objective evolutionary multitasking is performed with seamless knowledge transfer to enhance the optimization process. Experimental results obtained on six high-dimensional MOO functions with or without low effective dimensions have confirmed the effectiveness as well as the efficiency of the proposed EMT-ReMO.},
  archive   = {C_CEC},
  author    = {Yinglan Feng and Liang Feng and Yaqing Hou and Kay Chen Tan and Sam Kwong},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504857},
  pages     = {1672-1679},
  title     = {EMT-ReMO: Evolutionary multitasking for high-dimensional multi-objective optimization via random embedding},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-armed bandits for many-task evolutionary optimization.
<em>CEC</em>, 1664–1671. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504691">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Inspired by the ability of human multitasking, there is a growing body of literature in the computational intelligence community dedicated to solving multiple problems concurrently. One of the research areas that have been receiving much attention in this topic is evolutionary multitasking, which is able to solve multiple complicated optimization problems together, yielding a better result than solving them in isolation. However, researches on evolutionary multitasking mostly focus on solving a small number of problems together. In an attempt to improve evolutionary multitasking, we propose Many-Task Multi-Armed Bandit Evolutionary Algorithm (Ma 2 BEA), including a new structure for the evolutionary multitasking algorithm. It also adopts a well-proven result of Multi-Armed Bandit (MAB) as the method to control the adaptive knowledge exchange between different tasks. In particular, the action of selecting which task to perform inter-task crossover is learned and decided by the designed MAB agent. We verify that Ma 2 BEA correctly learned the underlying relationship between tasks using the simple 10-task benchmarks. Besides, Ma 2 BEA is compared with other evolutionary many-tasking algorithms that have recently been proposed using the Single-Objective Many-task benchmark from the WCCI 2020 Competition on Evolutionary Multi-task Optimization. Empirical results show that Ma 2 BEA is competitive in terms of high solution quality and reasonable execution time.},
  archive   = {C_CEC},
  author    = {Le Tien Thanh and Le Van Cuong and Ta Bao Thang and Huynh Thi Thanh Binh},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504691},
  pages     = {1664-1671},
  title     = {Multi-armed bandits for many-task evolutionary optimization},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A multifactorial evolutionary algorithm for minimum energy
cost data aggregation tree in wireless sensor networks. <em>CEC</em>,
1656–1663. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504807">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In wireless sensor networks, the majority of data transmitted by sensor nodes is repeated over and over, and performing processes on them in many cases leads to increased power consumption and reduced network lifetime. Data aggregation is one of the techniques in reducing redundancy and improving energy efficiency; it also increases the lifespan of wireless sensor networks. In this paper, we address the issues of constructing the data aggregation tree that minimizes the total energy cost of data transmissions for two types of networks: without relay nodes and using relay nodes. Traditionally, evolutionary algorithms focus on constructing data aggregation trees for either without relay node networks or using relay nodes networks. Therefore, we propose Potential individuals based Multi-factorial Evolutionary Algorithm (P-MFEA) to solve both issues simultaneously. The proposed scheme shows improved performance in terms of energy consumption.},
  archive   = {C_CEC},
  author    = {Tran Cong Dao and Tran Huy Hung and Nguyen Thi Tam and Huynh Thi Thanh Binh},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504807},
  pages     = {1656-1663},
  title     = {A multifactorial evolutionary algorithm for minimum energy cost data aggregation tree in wireless sensor networks},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A genetic algorithm approach to compute mixed strategy
solutions for general stackelberg games. <em>CEC</em>, 1648–1655. (<a
href="https://doi.org/10.1109/CEC45853.2021.9505000">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Stackelberg games have found a role in a number of applications including modeling market competition, identifying traffic equilibrium, developing practical security applications and many others. While a number of solution approaches have been developed for these games in a variety of contexts that use mathematical optimization, analytical analysis or heuristic based solutions, literature has been quite sparse on the usage of Genetic Algorithm (GA) based techniques. In this paper, we develop a GA based solution to compute high quality mixed strategy solution for the leader to commit to in a General Stackelberg Game (GSG) using a normal form game formulation. The leader faces multiple types of followers with discrete utility functions where the mixed strategy of the leader (but not the actual action taken in the round) is known to the follower. Our experiments showcase that the GA developed here performs well in terms of scalability and provides reasonably good solution quality in terms of the average reward obtained. Given that finding the optimal mixed strategy solution for GSGs is NP-hard (and the optimal solution for leader lies in the mixed strategy space), we believe that the solution approach presented here can support further development of practical applications using GSGs.},
  archive   = {C_CEC},
  author    = {Srivathsa Gottipati and Praveen Paruchuri},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9505000},
  pages     = {1648-1655},
  title     = {A genetic algorithm approach to compute mixed strategy solutions for general stackelberg games},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Transfer learning based evolutionary algorithm for bi-level
optimization problems. <em>CEC</em>, 1643–1647. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504861">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Evolutionary algorithms for bi-level optimization suffer from the low efficiency in dealing with the multiple lower level optimization tasks required by the population based upper level search. In this paper, we design a transfer learning based covariance matrix adaptation evolution strategy (TL-CMA-ES) for bi-level optimization problems, where the tasks of searching for multiple lower level optimal solutions are conducted by a set of CMA-ES optimizers in a parallel manner. Furthermore, a transfer learning strategy is introduced in the parallel lower level CMA-ES search such that each CMA-ES optimizer can learn and utilize useful features gained by its neighbours. Experimental comparison and analysis are carried out to verify the effectiveness and efficiency of the proposed method.},
  archive   = {C_CEC},
  author    = {Lei Chen and Hai-Lin Liu},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504861},
  pages     = {1643-1647},
  title     = {Transfer learning based evolutionary algorithm for bi-level optimization problems},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Comparing expected improvement and kriging believer for
expensive bilevel optimization. <em>CEC</em>, 1635–1642. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504815">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Bilevel optimization refers to a specialized class of problems where one optimization task is nested as a constraint within another. Such problems emerge in a range of real-world scenarios involving hierarchical decision-making, and significant literature exists on classical and evolutionary approaches to solve them. However, computationally expensive bilevel optimization problems remain relatively less explored. Since each evaluation incurs a significant computational cost, one can only perform a limited number of function evaluations during the course of search. Surrogate-assisted strategies provide a promising way forward to deal with such classes of problems. Of particular interest to this study are the steady-state strategies which carefully pre-select a promising solution for true evaluation based on a surrogate model. The main aim of this paper is to compare two widely adopted steady-state infill strategies -Kriging believer (KB) and expected improvement (EI) - through systematic experiments within a nested optimization framework. Our experiments on a set of benchmark problems reveal some interesting and counter-intuitive observations. We discuss some of the underlying reasons and believe that the findings will inform further research on understanding and improving search strategies for expensive bilevel optimization.},
  archive   = {C_CEC},
  author    = {Bing Wang and Hemant Kumar Singh and Tapabrata Ray},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504815},
  pages     = {1635-1642},
  title     = {Comparing expected improvement and kriging believer for expensive bilevel optimization},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An approximation-based chemical reaction algorithm for
combinatorial multi-objective bi-level optimization problems.
<em>CEC</em>, 1627–1634. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504711">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-objective Bi-Level Optimization Problem (MBLOP) is defined as a mathematical program where one multi-objective optimization task is constrained with another one. In this way, the evaluation of a single upper level solution necessitates the evaluation of the whole lower level problem. This fact brings new complexities to the bi-level framework, added to the conflicting objectives and their evaluation which need a large number of Function Evaluations (FEs). Despite the number of works dedicated to solve bi-level optimization problems, the number of methods applied to the multi-objective combinatorial case is much reduced. Motivated by these observations, we propose in this paper an approximation-based version of our recently proposed Bi-level Multi-objective Chemical Reaction Optimization (BMCRO), which we called BMCROII. The approximation technique is adopted here as a surrogate to the lower level leading then to generate efficiently the lower level optimality. Our choice is justified by two main arguments. First, BMCRO applies a Quick Non-Dominated Sorting Algorithm (Q-NDSA) with quasi-linear computational time complexity. Second, the number of FEs savings gained by the approximation technique can hugely improve the whole efficiency of the method. The proposed algorithm is applied to a new multi-objective formulation of the well-known Bi-level Multi Depot Vehicle Routing Problem (BMDVRP). The statistical analysis demonstrates the outperformance of our algorithm compared to prominent baseline algorithms available in literature. Indeed, a large number of savings are detected which confirms the merits of our proposal for solving such type of NP-hard problems.},
  archive   = {C_CEC},
  author    = {Malek Abbassi and Abir Chaabani and Lamjed Ben Said and Nabil Absi},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504711},
  pages     = {1627-1634},
  title     = {An approximation-based chemical reaction algorithm for combinatorial multi-objective bi-level optimization problems},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The predator’s purpose: Intention perception in simulated
agent environments. <em>CEC</em>, 1619–1626. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504885">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We evaluate the benefits of intention perception, the ability of an agent to perceive the intentions and plans of others, in improving a software agent’s survival likelihood in a simulated virtual environment. To model intention perception, we set up a multi-agent predator and prey model, where the prey agents search for food and the predator agents seek to eat the prey. We then analyze the difference in average survival rates between prey with intention perception—knowledge of which predators are targeting them—and those without. We find that intention perception provides significant survival advantages in almost all cases tested, agreeing with other recent studies investigating intention perception in adversarial situations and environmental danger assessment.},
  archive   = {C_CEC},
  author    = {Amani R. Maina-Kilaas and Cynthia Hom and Kevin Ginta and George D. Montañez},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504885},
  pages     = {1619-1626},
  title     = {The predator’s purpose: Intention perception in simulated agent environments},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The effects of initial condition selection on the evolution
of a turn circle intercept feedback controller. <em>CEC</em>, 1609–1618.
(<a href="https://doi.org/10.1109/CEC45853.2021.9505011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We explore the effects of four different initial condition selection methods on the evolution of a feedback controller for the Turn Circle Intercept problem. In this problem, an Attacker with constant speed and bounded turn rate attempts to intercept a constantly turning Target in minimum time. This type of problem arises frequently in air combat and formation maintenance scenarios for winged aircraft. In general, calculating a feedback controller&#39;s true fitness requires evaluation from an infinite number of initial conditions. Since this is not practical for nonlinear systems such as this, we instead approximate the fitness by averaging the feedback controller&#39;s performance from a subset of initial conditions. How these initial conditions are selected and where they are located within the state space can have a large impact on the performance of the algorithm and resulting evolved solutions. In this research, we aim to quantify these differences by comparing four different methods for selecting initial conditions: Grid Sampling, Uniform Random Sampling, Randomized Step-Back Sampling, and Hybrid Random Sampling.},
  archive   = {C_CEC},
  author    = {Pavlos Androulakakis and Zachariah Fuchs},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9505011},
  pages     = {1609-1618},
  title     = {The effects of initial condition selection on the evolution of a turn circle intercept feedback controller},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-objective coevolution and decision-making for
cooperative and competitive environments. <em>CEC</em>, 1601–1608. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504868">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Co-evolutionary algorithms involve two co-evolving populations, each having its own set of objectives and constraints, that interact with each other during function evaluation. Co-evolutionary algorithms are of great interest in cooperative and competing games and search tasks in which multiple agents having different interests are in play. Despite a number of single-objective co-evolutionary studies, there has been limited interest in multi-objective co-evolutionary algorithms. A recent study has revealed that in addition to the challenges associated with the development of an efficient algorithm, a proper understanding of the conflicting objectives within a single population and their interaction among objectives of the second population becomes extremely difficult to comprehend. In this paper, we extend the previous proof-of-principle multi-objective co-evolutionary (MOCoEv) study in three important directions. First, we enhance MOCoEv&#39;s ability to handle mixed cooperating and conflicting scenarios among different players. Second, we propose an iterative multi-criterion decision-making (MCDM) approach to demonstrate how, in an arms-race type scenario, the most appropriate solution can be selected from the obtained Pareto-optimal solution set iteratively. Third, we extend the previous MOCoEv algorithm with a many-objective evolutionary algorithm (NSGA-III) to make them applicable to three or more objectives for each player. These three developments reveal better insights about the intricate issues related to multiple objectives and decision-making for co-evolutionary optimization and take MOCoEv a step closer to solving more complex multi-player problems.},
  archive   = {C_CEC},
  author    = {Anirudh Suresh and Jaturong Kongmanee and Kalyanmoy Deb and Vishnu Naresh Boddeti},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504868},
  pages     = {1601-1608},
  title     = {Multi-objective coevolution and decision-making for cooperative and competitive environments},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Necrotic behavioral control of agent behavior in the
iterated prisoner’s dilemma. <em>CEC</em>, 1593–1600. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504866">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As the Covid-19 pandemic of 2020 illustrates, con-trolling the behavior of social agents is a difficult problem. This study examines the potential for an immune-inspired technique called necrosis to steer the behavior of agent populations that are evolving to play the iterated version of the game prisoner’s dilemma. A key factor in this is detection of behavioral types. The use of a previously developed technique for fingerprinting the behavior of game playing agents, even complex ones, permits the modelling of control strategies with necrotic behavioral control (NBC). NBC consists of reducing the fitness of agents engaging in an unacceptable behavior. The impact of applying necrosis to a number of agent behaviors is investigated. The strategies always-defect, always-cooperate, and tit-for-two-tats are used as the foci for behavior control by zeroing out the fitness of agents whose behavior is similar to those agents. Our experiments demonstrate that NBC changes the distribution of prisoner’s dilemma strategies that arise both when the focal strategy is changed and when the similarity radius used to zero out agent fitness is changed. Filtration focused on the strategy tit-for-two-tats has the largest impact on the evolution of prisoner’s dilemma strategies while always cooperate is found to have the least.},
  archive   = {C_CEC},
  author    = {Amanda Saunders and Daniel Ashlock and Julie Greensmith},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504866},
  pages     = {1593-1600},
  title     = {Necrotic behavioral control of agent behavior in the iterated prisoner’s dilemma},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multiple-preys pursuit based on biquadratic assignment
problem. <em>CEC</em>, 1585–1592. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504823">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The multiple-preys pursuit (MPP) is the adversarial game between predators and preys. If the capture of a prey is defined as that it cannot move anymore due to the surrounding of predators, there are two kinds of task allocations. One is about assigning which prey to which group of predators so that all preys can be captured. The other is about assigning which capturing position to which predator to encircle the prey simultaneously. In this paper, the MPP is modeled as a dynamic optimization problem and each its time step is solved in two stages. Firstly, the first kind of task allocation problem is modeled as the biquadratic assignment problem (BiQAP) and a MPP fitness function is proposed for the evaluation of such BiQAP task allocations. In this way, the MPP is transformed to several single-prey pursuit (SPP) problems. Secondly, for each SPP, we extend the coordinated SPP strategy CCPSO-R (cooperative coevolutionary particle swarm optimization for robots) to its parallel version as PCCPSO-R to enable the parallel implicit capturing position allocating by parallel observation, decision making, and moving of predators. Through experiments of the current BiQAP solvers on the task allocation, we improve the best one of them in statistic based on the domain knowledge. Moreover, the advantages of PCCPSO-R in the capturing efficiency over CCPSO-R is testified in the MPP experiments.},
  archive   = {C_CEC},
  author    = {Lijun Sun and Chao Lyu and Yuhui Shi and Chin-Teng Lin},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504823},
  pages     = {1585-1592},
  title     = {Multiple-preys pursuit based on biquadratic assignment problem},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). IPOP-CMA-ES and the influence of different deviation
measures for agent-based model calibration. <em>CEC</em>, 1577–1584. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504694">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Calibration is a crucial task on building valid models before exploiting their results. This process consists of adjusting the model parameters in order to obtain the desired outputs. Automatic calibration can be performed by using an optimization algorithm and a fitness function, which involves a deviation measure to compare the time series coming from the model. In this paper, we apply a memetic IPOP-CMA-ES for the calibration of an agent-based model and we study the effect of different deviation measures in this calibration problem. Classical metrics calculate the mean point-to-point error, but we also propose using an extension of dynamic time warping, which considers trend series evolution. In order to determine if calibrating with an specific metric leads to better solutions, we carry out an exhaustive experimentation by including statistical tests, analysis on the values of the calibrated parameters, and qualitative results. Our results show IPOP-CMA-ES obtains better performance than a genetic algorithm. In addition, MAE, MAPE and Soft-DTW are the metrics which report best results, although we get a similar behavior for all of them.},
  archive   = {C_CEC},
  author    = {Víctor Vargas-Pérez and Manuel Chica and Óscar Cordón},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504694},
  pages     = {1577-1584},
  title     = {IPOP-CMA-ES and the influence of different deviation measures for agent-based model calibration},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evaluation of index tracking portfolios during the COVID-19
pandemic. <em>CEC</em>, 1569–1576. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504828">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Index tracking consists of mimicking a benchmark performance with a portfolio formed by a subset of assets contained in the index. Due to the cardinality constraint, obtaining an optimal solution for this problem can be impractical as the number of stocks in the index grows. Then, meta-heuristics, such as genetic algorithms, can obtain good solutions in a reason- able time, making it possible for the investor to run different configurations of the problem before deciding to rebalance or not his portfolio. Also, to evaluate an investment strategy, it is important to perform backtests considering different risk scenarios, especially in crisis scenarios, with a high volatile market. This work aims to analyze the integration of hybrid and pure genetic algorithms and two optimization models in a high volatility market scenario, the Brazilian market index IBOVESPA during the COVID-19 pandemic. We observed that the hybrid algorithms returned competitive solutions, tracking IBOVESPA even closer than the CPLEX solution on the linear model for a non-rebalancing strategy. However, they were not competitive in a rebalancing strategy, with solutions presenting a gap of more than 100\% relative to the general-purpose solver solution.},
  archive   = {C_CEC},
  author    = {Thiago Wanderley De Amorim and Julio Cezar Soares Silva and Adiel Teixeira De Almeida Filho},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504828},
  pages     = {1569-1576},
  title     = {Evaluation of index tracking portfolios during the COVID-19 pandemic},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A simulated IMO-DRSA approach for cognitive reduction in
multiobjective financial portfolio interactive optimization.
<em>CEC</em>, 1560–1568. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504906">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Obtaining the optimal Pareto front in multiobjective portfolio problems can be impractical when considering real- world constraints, such as portfolio cardinality. Thus, it is interesting to consider multiobjective evolutionary algorithms to solve this type of problem in a reasonable time, but without quality guarantees. IMO-DRSA can reduce the search space using the preference information of the investor until the single most preferable solution is found. The problem is that there is no evidence on how to reduce the number of representative portfolios to minimize decision-maker’s (DM) cognitive effort during the interaction, taking the satisfaction of preferences in future distributions of portfolio components returns into account. The objective of this work was to provide a way to support the reduction of the number of representative examples presented for the investor, while regarding out-of-sample preference satisfaction of the examples that compose a data table. A simulation approach was proposed to analyze and compare methods that select a small and robust sample of representative solutions to compose data tables.},
  archive   = {C_CEC},
  author    = {Julio Cezar Soares Silva and Adiel Teixeira de Almeida Filho},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504906},
  pages     = {1560-1568},
  title     = {A simulated IMO-DRSA approach for cognitive reduction in multiobjective financial portfolio interactive optimization},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hyperparameter optimization: Comparing genetic algorithm
against grid search and bayesian optimization. <em>CEC</em>, 1551–1559.
(<a href="https://doi.org/10.1109/CEC45853.2021.9504761">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The performance of machine learning algorithms are affected by several factors, some of these factors are related to data quantity, quality, or its features. Another element is the choice of an appropriate algorithm to solve the problem and one major influence is the parameter configuration based on the problem specification. Parameters in machine learning can be classified in two types: (1) model parameters that are internal, configurable, and its value can be estimated from data such as weights of a deep neural network; and (2) hyperparameters, which are external and its values can not be estimated from data such as the learning rate for the training of a neural network. Hyperparameter values may be specified by a practitioner or using a heuristic, or parameter values obtained from other problems can be used etc., however, the best values of these parameters are identified when the algorithm has the highest accuracy, and these could be achieved by tuning the parameters. The main goal of this paper is to conduct a comparison study between different algorithms that are used in the optimization process in order to find the best hyperparameter values for the neural network. The algorithms applied are grid search algorithm, bayesian algorithm, and genetic algorithm. Different evaluation measures are used to conduct this comparison such as accuracy and running time.},
  archive   = {C_CEC},
  author    = {Hussain Alibrahim and Simone A. Ludwig},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504761},
  pages     = {1551-1559},
  title     = {Hyperparameter optimization: Comparing genetic algorithm against grid search and bayesian optimization},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A genetic algorithm for investment tracking with stochastic
model predictive control. <em>CEC</em>, 1543–1550. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504714">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper proposes a genetic algorithm (GA) for the stochastic model predictive control (SMPC) approach to investment tracking in the presence of transaction costs and cardinality constraints. The methodology is based on minimizing a stochastic measure of the tracking error predicted for the next trading date. A conditional value at risk (CVaR) measure is proposed to determine the replicating portfolio&#39;s optimal composition, quantifying the average loss over a subset of worst- case realizations. The investment performance is tested and analyzed in an out-of-sample simulation using data from the Brazilian Stock Exchange. Results indicate that the proposed approach can effectively track the benchmark and satisfy the constraints.},
  archive   = {C_CEC},
  author    = {Maisa Kely de Melo and Rodrigo T. N. Cardoso and Tales Argolo Jesus},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504714},
  pages     = {1543-1550},
  title     = {A genetic algorithm for investment tracking with stochastic model predictive control},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient global multi-objective aerodynamic optimization
using combined multi-point infilling strategy and surrogate models.
<em>CEC</em>, 1537–1542. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504946">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Surrogate-based method can dramatically reduce the number of expensive function evaluations in real-world multi- objective optimization problems (MOP). When the number of objectives is small, using surrogate models combined with expected hypervolume improvement (EHVI) infill sampling criterion (ISC) has been proved to be efficient to provide a set of solutions with good diversity and good proximity to the Pareto front (PF) in aerodynamic shape optimization. However, traditional hypervolume-based infilling strategies use only one kind of ISC to generate one or multiple sample points, the advantages of various kinds of ISC cannot be comprehensively utilized and the parallelization is not easy to implement. This paper proposes a combined multi-point infilling strategy based on Kriging models and develops an efficient global multi-objective constrained optimization method (EGMOCO) to solve multi- objective aerodynamic shape optimization with complex constraints. Multiple sample points are generated by using four ISC considering hypervolume at each iteration and then evaluated in parallel. Firstly, the performance of EGMOCO is compared with that of single criterion EHVI strategy on six benchmarks within the same computational budget to prove its effectiveness, and then EGMOCO is implemented in an aerodynamic shape optimization problem with complex constraints. The result shows that EGMOCO has good performance in balancing local exploitation and global exploration with faster convergence rate and high robustness, the whole PF can be fully explored in limited evaluations and the constraint handling is effective especially for real-world problems with complex and nonlinear constraints, the comprehensive aerodynamic performance of the airfoil is greatly improved. It can be confirmed that Kriging-based multi-objective optimization method combined with multi-point infilling strategy performs better than single infilling criterion EHVI, since different sample infilling criteria can complement with each other, both local exploitation and global exploration can be considered and well balanced.},
  archive   = {C_CEC},
  author    = {Yiming Yao and Xudong Yang},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504946},
  pages     = {1537-1542},
  title     = {Efficient global multi-objective aerodynamic optimization using combined multi-point infilling strategy and surrogate models},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The performance effect of model accuracy on
classification-assisted evolutionary algorithms. <em>CEC</em>,
1527–1536. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504809">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Optimization problems with costly function evaluation widely exist in real-world applications. Surrogate models are commonly used in the field of optimization to deal with such expensive optimization problems. In surrogate model-assisted evolutionary algorithms (EAs), surrogate models like regression models, ranking models or classification models are built based on historical data and then used to compare candidate solutions in place of real function evaluations. Researchers have also proposed various methods to make better use of surrogate models in the optimization process of EAs. However, there is no comprehensive study about how much accuracy of the built model is accurate enough to bring benefits to the optimization. Motivated by this, this work proposes a method to study the performance effect of model accuracy on surrogate model-assisted EAs. Specifically, the method does not really build surrogate models but assumes different model accuracies in individual selection. Two classification-assisted EAs, classification-assisted differential evolution (CADE) and relationship classification-based preselection strategy (RCPS) are analyzed in this work. The experimental results on a set of test functions show that a weak learner with classification accuracy larger than 50\% is acceptable ignoring the cost of model building. Another observation is that the performances of CADE and RCPS increase monotonically and nonlinearly with the classification accuracy.},
  archive   = {C_CEC},
  author    = {Chang Cao and Xiaofen Lu and Yachen Li and Junda Zhu and Ke Tang},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504809},
  pages     = {1527-1536},
  title     = {The performance effect of model accuracy on classification-assisted evolutionary algorithms},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptation of search generations in extreme learning
assisted MOEA/d based on estimation accuracy of surrogate model.
<em>CEC</em>, 1519–1526. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504819">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the last decade, multi-objective evolutionary algorithms (MOEAs) have been utilized for many real-world applications. However, it takes a great deal of computation time for the majority of real-world problems to obtain the optimal solutions due to the expensive fitness evaluation cost. In order to reduce the computation time for optimization, surrogate-assisted MOEAs have been studied. Our previous study analyzed ELMOEA/D, one of the surrogate-assisted MOEA combining MOEA/D with an extreme learning machine (ELM), from the relation between search performance and search generations. Our previous analysis revealed that the search generations on the surrogate space must be determined to make the accuracy of the surrogate model low. For this fact, this paper proposes the automatic adjustment methods for the search generations of ELMOEA/D. We conduct experiments with several well-known multi-objective benchmark problems and compare the proposed methods with the conventional ELMOEA/D with the fixed number of generations. The experimental results reveal that the proposed methods achieve a more stable search performance than ELMOEA/D with the fixed number of generations regardless of the target problems.},
  archive   = {C_CEC},
  author    = {Koki Tsujino and Tomohiro Harada and Ruck Thawonmas},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504819},
  pages     = {1519-1526},
  title     = {Adaptation of search generations in extreme learning assisted MOEA/D based on estimation accuracy of surrogate model},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Monitoring water resources through a bayesian
optimization-based approach using multiple surface vehicles: The
ypacarai lake case study. <em>CEC</em>, 1511–1518. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504704">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Bayesian optimization is a popular sequential decision strategy that can be used for environmental monitoring. In this work, we propose an efficient multi-Autonomous Surface Vehicle system capable of monitoring the Ypacarai Lake (San Bernardino, Paraguay) (60 km 2 ) using the Bayesian optimization approach with a Voronoi Partition system. The system manages to quickly approximate the real unknown distribution map of a water quality parameter using Gaussian Processes as surrogate models. Furthermore, to select new water quality measurement locations, an acquisition function adapted to vehicle energy constraints is used. Moreover, a Voronoi Partition system helps to distributing the workload with all the available vehicles, so that robustness and scalability is assured. For evaluation purposes, we use both the mean squared error and computational efficiency. The results showed that our method manages to efficiently monitor the Ypacarai Lake, and also provides confident approximate models of water quality parameters. It has been observed that, for every vehicle, the resulting surrogate model improves by 38\%.},
  archive   = {C_CEC},
  author    = {Federico Peralta and Samuel Yanes and Daniel Gutiérrez Reina and Sergio Toral},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504704},
  pages     = {1511-1518},
  title     = {Monitoring water resources through a bayesian optimization-based approach using multiple surface vehicles: The ypacarai lake case study},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-objective bayesian optimisation using an exploitative
attainment front acquisition function. <em>CEC</em>, 1503–1510. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504899">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Efficient methods for optimising expensive black-box problems with multiple objectives can often themselves become prohibitively expensive as the number of objectives is increased. We propose an infill criterion based on the distance to the summary attainment front which does not rely on the expensive hypervolume or expected improvement computations, which are the principal causes of poor dimensional scaling in current state-of-the-art approaches. By evaluating performance on the well-known Walking Fish Group problem set, we show that our method delivers similar performance to the current state-of-the-art. We further show that methods based on surrogate mean predictions are more often than not superior to the widely used expected improvement, suggesting that the additional exploration produced by accounting for the uncertainty in the surrogate’s prediction of the optimisation landscape is often unnecessary and does not aid convergence towards the Pareto front.},
  archive   = {C_CEC},
  author    = {Finley J. Gibson and Richard M. Everson and Jonathan E. Fieldsend},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504899},
  pages     = {1503-1510},
  title     = {Multi-objective bayesian optimisation using an exploitative attainment front acquisition function},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Inconstant update of reference point value for parallel and
distributed MOEA/d. <em>CEC</em>, 1495–1502. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504979">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper proposes an update method to determine the reference point and nadir point when speeding up multi-objective evolutionary optimization algorithm based on decomposition (MOEA/D) with parallel and distributed processing in a many-core environment. We have already proposed a migration method that uses a virtual overlapping zone between partitions. Compared with simply partitioning the objective space or applying the standard island migration model, this method is shown to be effective in improving the hypervolume (HV) value, increasing diversity, and reducing regions where non-dominated solutions do not exist between partitions (sparse areas). However, this proposed method could not completely deal with the sparse areas&#39; problem in the early stage of solution searching. To resolve this problem, in addition to the virtual overlap method, we propose here a method that switches the update interval for determining the reference point and nadir point by taking into account the progress of solution searching. To evaluate our newly proposed method, we compare both convergence and diversity on single-core MOEA/D and parallel MOEA/D using a two-objective constrained knapsack problem, and show that our method is effective not only in reducing sparse areas in the early stage but also in improving diversity and increasing the HV value.},
  archive   = {C_CEC},
  author    = {Mikiko Sato and Yuji Sato and Mads Midtlyng and Minami Miyakawa},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504979},
  pages     = {1495-1502},
  title     = {Inconstant update of reference point value for parallel and distributed MOEA/D},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Using a genetic algorithm-based hyper-heuristic to tune
MOEA/d for a set of various test problems. <em>CEC</em>, 1486–1494. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504748">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The multi-objective evolutionary algorithm based on decomposition (MOEA/D) is one of the most popular algorithms in the field of evolutionary multi-objective optimization (EMO). Even though MOEA/D has been widely used in many studies, it is likely that the performance of MOEA/D is not always optimized since the same MOEA/D implementation is often used on various problems with different characteristics. However, obtaining an appropriate implementation of MOEA/D for a different problem is not always easy, since there exists a wide variety of choices for the components and parameters in MOEA/D. In this paper, we examine the use of a genetic algorithm-based hyper-heuristic procedure to offline tune MOEA/D on a single test problem, a set of similar test problems, and a set of various test problems. A total of 26 benchmark test problems are used in our study. Experimental results show that the MOEA/D tuned for a set of various test problems does not always perform well. It is also shown that the MOEA/D tuned for a single test problem and for a set of similar test problems always has high performance. Our experimental results strongly suggest the necessity of using a tuning procedure to obtain a different MOEA/D implementation for a different type of problems.},
  archive   = {C_CEC},
  author    = {Lie Meng Pang and Hisao Ishibuchi and Ke Shang},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504748},
  pages     = {1486-1494},
  title     = {Using a genetic algorithm-based hyper-heuristic to tune MOEA/D for a set of various test problems},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modified decomposition framework and algorithm for
many-objective topology and weight evolution of neural networks.
<em>CEC</em>, 1478–1485. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504953">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper presents a modified decomposition framework to support the Many-Objective Topology and Weight Evolution of Artificial Neural Networks (MaO-TWEANNs). Next, an algorithm, which is termed NEWS/D, is devised using the proposed framework. To validate its optimization capabilities, a numerical study is carried out. The performed numerical study includes demonstration problems ranging from three to seven objectives for which the ideal points are known. Finally, an additional numerical study is performed with respect to a possible real-life application. The latter study suggests that evolving class experts for multi-class classification problems could be enhanced using NEWS/D in a non-intuitive approach.},
  archive   = {C_CEC},
  author    = {Adham Salih and Amiram Moshaiov},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504953},
  pages     = {1478-1485},
  title     = {Modified decomposition framework and algorithm for many-objective topology and weight evolution of neural networks},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A dynamic penalty function within MOEA/d for constrained
multi-objective optimization problems. <em>CEC</em>, 1470–1477. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504940">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {For more than a decade, the efficiency and effectiveness of MOEA/D (Multi-Objective Evolutionary Algorithm based on Decomposition) when solving complicated problems has been shown. Due to this, several researchers have focused their investigations on MOEA/D&#39;s extensions that can deal with CMOPs (Constrained Multi-objective Optimization Problems). In this paper, we adhere to the MOEA/D framework, a simple penalty function to deal with CMOPs. The penalty function is dynamically adapted during the search. In this way, the interaction between feasible and infeasible solutions is promoted. As a result, the proposed approach (namely MOEA/D-DPF) extends MOEA/D to handle constraints. The proposed approach performance is evaluated on the well-known CF test problems taken from the CEC&#39;2009 suite. Using convergence and feasibility indicators, we compare the solutions produced by our algorithm against those produced by state-of-the-art MOEAs. Results show that MOEA/D-DPF is highly competitive and, in some cases, it performs better than the MOEAs adopted in our comparative study.},
  archive   = {C_CEC},
  author    = {Hugo Monzón Maldonado and Saúl Zapotecas-Martínez},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504940},
  pages     = {1470-1477},
  title     = {A dynamic penalty function within MOEA/D for constrained multi-objective optimization problems},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Weight vector arrangement using virtual objective vectors in
decomposition-based MOEA. <em>CEC</em>, 1462–1469. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504954">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This work proposes an arrangement method of weight vectors using virtual objective vectors supplementing the Pareto front estimation. In decomposition-based evolutionary multi-objective optimization, weight vectors decompose the Pareto front. Appropriate weight vector distribution depends on the Pareto front shape, which is generally unknown before the search. Objective vectors of obtained non-dominated solutions become a clue to estimate the Pareto front shape and arrange an appropriate weight vector set. However, a sizeable objective vector set is required for a high-quality Pareto front estimation and weight vector arrangement. The proposed method generates and utilizes a virtual objective vector set based on the objective vectors of obtained non-dominated solutions and an extended weight vector set for the Pareto front estimation. Experimental results using benchmark problems with different Pareto front shapes show that the virtual objective vectors generated from a limited number of actual objective vectors contribute to improving the search performance of decomposition-based evolutionary multi-objective optimization.},
  archive   = {C_CEC},
  author    = {Tomoaki Takagi and Keiki Takadama and Hiroyuki Sato},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504954},
  pages     = {1462-1469},
  title     = {Weight vector arrangement using virtual objective vectors in decomposition-based MOEA},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Local neighborhood-based adaptation of weights in
multi-objective evolutionary algorithms based on decomposition.
<em>CEC</em>, 1454–1461. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504688">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-objective algorithms based on decomposition have become popular for the reason that a uniform distribution of weight vectors may result in a better distribution of solutions along the Pareto front. However, for more complex Pareto fronts with irregular shapes, the initial weight vectors may not be adequate. One alternative to overcome this problem, is to adapt the weight vectors during the evolutionary process. In this paper an adaptive version of Multi-Objective Evolutionary Algorithm based on Decomposition (MOEA/D) is proposed to change the weight vectors based on the concept of local neighborhoods. The proposed method is called MOEA/D with local-neighborhood-based adaptation (MOEA/D-LNA). The proposed method is compared against a number of famous variants of MOEA/D in the literature. Initial experimental results have shown promising effectiveness on problems with irregular Pareto shapes.},
  archive   = {C_CEC},
  author    = {Paulo Pinheiro Junqueira and Ivan Reinaldo Meneghini and Frederico Gadelha Guimarães},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504688},
  pages     = {1454-1461},
  title     = {Local neighborhood-based adaptation of weights in multi-objective evolutionary algorithms based on decomposition},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Tackling the subset sum problem with fixed size using an
integer representation scheme. <em>CEC</em>, 1447–1453. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504889">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Addressing the subset sum problem is relevant to study resource management problems efficiently. In this paper, we study a new scheme to sample solutions for the subset sum problem based on swarm-based optimization algorithms with distinct forms of selection pressure, the balance of exploration-exploitation, the multimodality considerations, and a search space defined by numbers associated with subsets of fixed size. Our experiments show that it is feasible to find optimal subsets with few number of fitness evaluations, and that Particle Swarm Optimization with Fitness Euclidean Ratio converges faster to the global optima with zero variability over independent runs. Since the search space is one-dimensional and friendly to parallelization schemes, our work is potential to study further classes of combinatorial problems using swarm-based optimization algorithms and the representation based on numbers.},
  archive   = {C_CEC},
  author    = {Victor Parque},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504889},
  pages     = {1447-1453},
  title     = {Tackling the subset sum problem with fixed size using an integer representation scheme},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ensembled crossover based evolutionary algorithm for single
and multi-objective optimization. <em>CEC</em>, 1439–1446. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504698">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A unique way evolutionary algorithms (EAs) are different from other search and optimization methods is their recombination operator. For real-parameter problems, it takes two or more high-performing population members and blends them to create one or more new solutions. Many real-parameter recombination operators have been proposed in the literature. Each operator involves at least a parameter that controls the extent of exploration (diversity) of the generated offspring population. It has been observed that different recombination operators and specific parameters produce the best performance for different problems. This fact imposes the user to use different operator and parameter combinations for every new problem. While an automated algorithm configuration method can be applied to find the best combination, in this paper, we propose an Ensembled Crossover based Evolutionary Algorithm (EnXEA), which considers a number of recombination operators simultaneously. Their parameter values and applies them with a probability updated adaptively in proportion to their success in creating better offspring solutions. Results on single-objective and multi-objective, constrained, and unconstrained problems indicate that EnXEA&#39;s performance is close to the best individual recombination operation for each problem. This alleviates the use of expensive parameter tuning either adaptively or manually for solving a new problem.},
  archive   = {C_CEC},
  author    = {Shreya Sharma and Julian Blank and Kalyanmoy Deb and Bijaya Ketan Panigrahi},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504698},
  pages     = {1439-1446},
  title     = {Ensembled crossover based evolutionary algorithm for single and multi-objective optimization},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cheating like the neighbors: Logarithmic complexity for
fitness evaluation in genetic algorithms. <em>CEC</em>, 1431–1438. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504849">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {While neighborhood-based algorithms can use incremental evaluation to obtain the fitness of a modified solution candidate, genetic crossover makes changes that are too big to easily allow reusing previous quality values. In this paper, we extend our previous work and evaluate the possibility of extending persistent data structures to carry residual fitness values that can be reused for later evaluation of derived solution candidates when applied to Multidimensional 0–1 Knapsack Problems. We show potential speedups especially on very large problem instances when compared to classic array-based implementations.},
  archive   = {C_CEC},
  author    = {Erik Pitzer and Michael Affenzeller},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504849},
  pages     = {1431-1438},
  title     = {Cheating like the neighbors: Logarithmic complexity for fitness evaluation in genetic algorithms},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The impact of representation on the optimization of marker
panels for single-cell RNA data. <em>CEC</em>, 1423–1430. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504808">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The increasing number of single-cell transcriptomic and single-cell RNA sequencing studies are allowing for a deeper understanding of the molecular processes underlying the normal development of an organism as well as the onset of pathologies. These studies continuously refine the functional roles of known cell populations, and provide their characterization as soon as putatively novel cell populations are detected. In order to isolate the cell populations for further tailored analysis, succinct marker panels—composed of a few cell surface proteins and clusters of differentiation molecules—must be identified. The identification of these marker panels is a challenging computational problem due to its intrinsic combinatorial nature, which makes it an NP-hard problem. Genetic Algorithms (GAs) have been successfully used in Bioinformatics and other biomedical applications to tackle combinatorial problems. We present here a GA-based approach to solve the problem of the identification of succinct marker panels. Since the performance of a GA is strictly related to the representation of the candidate solutions, we propose and compare three alternative representations, able to implicitly introduce different constraints on the search space. For each representation, we perform a fine-tuning of the parameter settings to calibrate the GA, and we show that different representations yield different performance, where the most relaxed representations— in which the GA can also evolve the number of genes in the panel—turn out to be the more effective, especially in the case of 0-knowledge problems. Our results also show that the marker panels identified by GAs can outperform manually curated solutions.},
  archive   = {C_CEC},
  author    = {Andrea Tangherloni and Simone G. Riva and Simone Spolaor and Daniela Besozzi and Marco S. Nobile and Paolo Cazzaniga},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504808},
  pages     = {1423-1430},
  title     = {The impact of representation on the optimization of marker panels for single-cell RNA data},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). If you can’t beat it, squash it: Simplify global
optimization by evolving dilation functions. <em>CEC</em>, 1414–1422.
(<a href="https://doi.org/10.1109/CEC45853.2021.9504708">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Optimization problems represent a class of pervasive and complex tasks in Computer Science, aimed at identifying the global optimum of a given objective function. Optimization problems are typically noisy, multi-modal, non-convex, non-separable, and often non-differentiable. Because of these features, they mandate the use of sophisticated population-based meta-heuristics to effectively explore the search space. Additionally, computational techniques based on the manipulation of the optimization landscape, such as Dilation Functions (DFs), can be effectively exploited to either &quot;compress&quot; or &quot;dilate&quot; some target regions of the search space, in order to improve the exploration and exploitation capabilities of any meta-heuristic. The main limitation of DFs is that they must be tailored on the specific optimization problem under investigation. In this work, we propose a solution to this issue, based on the idea of evolving the DFs. Specifically, we introduce a two-layered evolutionary framework, which combines Evolutionary Computation and Swarm Intelligence to solve the meta-problem of optimizing both the structure and the parameters of DFs. We evolved optimal DFs on a variety of benchmark problems, showing that this approach yields extremely simpler versions of the original optimization problems.},
  archive   = {C_CEC},
  author    = {Daniele M. Papetti and Daniel A. Ashlock and Paolo Cazzaniga and Daniela Besozzi and Marco S. Nobile},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504708},
  pages     = {1414-1422},
  title     = {If you can’t beat it, squash it: Simplify global optimization by evolving dilation functions},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exponentially decaying explosion in fireworks algorithm.
<em>CEC</em>, 1406–1413. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504974">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Fireworks algorithm (FWA) as an efficient and robust swarm intelligence algorithm can successfully deal with complex multi-modal problems. In this paper, a novel new explosion operator called exponentially decaying explosion is proposed to enhance the local search ability of fireworks algorithm based on the principle of utilizing more information. The proposed method takes the idea of guided mutation a step further and dismantled the explosion process into an exponentially decaying series of guided explosion. The FWA variant with this explosion operator is called exponentially decaying fireworks algorithm (EDFWA). Theoretical analysis proved the superiority of EDFWA in terms of information utilization ratio compared with GFWA. Experimental results showed that EDFWA not only surpassed LoTFWA in low dimensional situations, but also exhibited powerful searching capability on 1000 dimensional high dimensional problems compared with multiple representative optimizers specially designed for large-scale problems.},
  archive   = {C_CEC},
  author    = {Maiyue Chen and Ying Tan},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504974},
  pages     = {1406-1413},
  title     = {Exponentially decaying explosion in fireworks algorithm},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). HIDMS-PSO with bio-inspired fission-fusion behaviour and a
quorum decision mechanism. <em>CEC</em>, 1398–1405. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504755">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this study, we propose a new variant of the HIDMS-PSO algorithm with a bio-inspired fission-fusion behaviour and a quorum decision mechanism (FFQ-HIDMS-PSO). In the new algorithm, units are conceptualised as self-organising fission-fusion societies that determine and adopt a suitable behaviour using unit-based quorum decisions. The incorporation of the two bio-inspired mechanisms provide &quot;diversity aware&quot; self-organising units that react to stagnation of particles by adopting a suitable fission-fusion behaviour, leading to a more efficient algorithm capable of maintaining significantly better population diversity throughout the search. The performance of the proposed algorithm was verified with three distinct experiments conducted using CEC’17 and CEC’05 test suites at 30 and 50 dimensions, comparing against 12 state-of-the-art metaheuristics and 12 state-of-the-art PSO variants. The proposed algorithm showed superior performance in these experiments by outperforming all 24 algorithms in all three experiments at 30 and 50 dimensions. The empirical evidence suggests that the proposed method also maintains significantly superior population diversity in comparison to the original HIDMS-PSO.},
  archive   = {C_CEC},
  author    = {Fevzi Tugrul Varna and Phil Husbands},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504755},
  pages     = {1398-1405},
  title     = {HIDMS-PSO with bio-inspired fission-fusion behaviour and a quorum decision mechanism},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The sectional art gallery and an evolutionary algorithm for
approaching its minimum point guard problem. <em>CEC</em>, 1390–1397.
(<a href="https://doi.org/10.1109/CEC45853.2021.9504843">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose an extension of Art Galleries in Computational Geometry towards a more real world application related definition, well suited for Evolutionary Algorithms. We introduce two additional sections inside the Art Gallery. One section defines locations where guards may be placed in order to cover the Art Gallery. A second section shall be observed by these guards. We show that our definition of a Sectional Art Gallery also includes the Regular Art Gallery as a special case. Furthermore, we present an Evolutionary Algorithm which can approach Minimum Point Guard Problems in such a way, that high quality approximations can be found in Sectional Art Galleries. Our algorithm is influenced by Particle Swarm Optimizers and Particle Filters. Depending on the application, relaxations of the problem can be handled by our algorithm. This way, state of the art methods on optimally solving Minimum Point Guard Problems in Regular Art Galleries can be outperformed by multiple guards, still reaching more than 99.99\% of coverage. By running our algorithm on public data sets, we show the effectiveness of our approach in both Regular and Sectional Art Galleries.},
  archive   = {C_CEC},
  author    = {Fynn Terhar and Christian Icking},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504843},
  pages     = {1390-1397},
  title     = {The sectional art gallery and an evolutionary algorithm for approaching its minimum point guard problem},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An evolutionary computation based model for testing transfer
learning strategies. <em>CEC</em>, 1380–1389. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504888">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {To study how Transfer Learning (TL) works and what are effective strategies for transfer learning, we propose to model the TL process using Evolutionary Computation. EC provides a clear model for a problem as searching through a set of potential solutions. We are able to more easily control and measure problem difficulty, problem similarity, and methods of information transfer and relate these to success. As a proof of concept, we will use a static source problem and three fixed target problems with simple known relationships (see Section III). We compare the effectiveness of several ways to transfer knowledge learned from solving one problem to solving the new problems in the context of the relationship between the problems. This we hope will demonstrate that using our EC model is a fruitful way to investigate TL. The results show there is an improvement for using some sampled methods representing the &quot;learned knowledge&quot; of the source problem S. Also, the results show that the diversity of the transferred population has some positive effect on finding the optimal solution depending on the relationship between source and target problems.},
  archive   = {C_CEC},
  author    = {Tami Alghamdi and Robert B. Heckendorn},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504888},
  pages     = {1380-1389},
  title     = {An evolutionary computation based model for testing transfer learning strategies},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Configuring the perturbation operations of an iterated local
search algorithm for cross-domain search: A probabilistic learning
approach. <em>CEC</em>, 1372–1379. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504841">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Hyper-heuristics are general-purpose heuristic search methodologies for solving combinatorial optimization problems (COPs). Research findings have revealed that hyper-heuristics still suffer generalization issues as different strategies vary in performance from an instance of a COP to another. In this paper, an approach based on Iterated Local Search (ILS) is proposed to raise the level of generality of hyper-heuristics on the problem domains of the HyFlex framework. The proposed approach utilizes a probabilistic learning technique to automatically configure the behavior of the ILS algorithm during the perturbation stage of the optimization process. In the proposed method, the mutation and ruin-recreate heuristics are treated as distinct entities and the learning layer automatically determines the level of utilization of these heuristic categories depending on the problem domain being solved. The concept of double shaking is also presented where a solution can be perturbed twice before the intensification phase. Experimental results reveal the level of generality achieved by the proposed method as it recorded a minimum formula one score of 30.0 on each tested problem domain. Direct comparison with a state-of-the-art ILS-based approach also establishes the significance of the learning layer added to the perturbation stage of the ILS metaheuristic. Finally, analysis of the perturbation behavior of the hyper-heuristic leads to an interesting conclusion concerning the type of low-level heuristics that are highly beneficial and non-beneficial to a given problem domain.},
  archive   = {C_CEC},
  author    = {Stephen A. Adubi and Olufunke O. Oladipupo and Oludayo O. Olugbara},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504841},
  pages     = {1372-1379},
  title     = {Configuring the perturbation operations of an iterated local search algorithm for cross-domain search: A probabilistic learning approach},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fast heuristics for traveling salesman problems with
multiple flying sidekicks. <em>CEC</em>, 1365–1371. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504975">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Speedy delivery of products is important for customers and the optimization of the last mile has particular challenges. In recent years drone-supported delivery has become increasingly feasible and therefore a topic of intense research. In this paper we address a traveling salesman problem where a truck has to serve customers and can use drones as flying sidekicks for the delivery of parcels. The goal is to assign customers to be either served by the truck or by some drone and schedule all events in order to minimize the total completion time of whole operation. We propose a heuristic for this problem, and introduce several novel components, including a multi-armed bandit selection for partitioning customers, an efficient matching-based heuristic for assigning drones to customers, local searches to improve solutions, and a fast greedy scheduler to estimate solution quality. In computational experiments we show that the combined approach finds better solutions than current methods, in less time.},
  archive   = {C_CEC},
  author    = {Gustavo Delazeri and Marcus Ritt},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504975},
  pages     = {1365-1371},
  title     = {Fast heuristics for traveling salesman problems with multiple flying sidekicks},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cooperative chaotic evolution. <em>CEC</em>, 1357–1364. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504825">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We introduce two new strategies into the conventional chaotic evolution (CE) to facilitate the exchange of information between individuals instead of searching independently, and propose a cooperative CE (CoCE) with stronger performance. The first strategy designs a new crossover operation to ensure that mutant individual&#39;s exchange genes with other better individuals. Specifically, a mutant individual does not cross with its parent individual, but with a randomly selected individual whose fitness is not worse than that of the parent individual. The second strategy introduces an additional attraction generated by the randomly selected individual acting on the mutant individual, which can allow the offspring individual to prefer potential areas and speed up the search process. To evaluate the performance of our proposed strategies, we configure CoCE and CE with the exact same parameter settings and run them on 28 benchmark functions from CEC 2013 test suites. Each benchmark function is run 30 times independently on three different dimensions (i.e., 2-D, 10-D, and 30-D), and we also apply the Friedman test and Holm&#39;s multiple comparison test to check significant differences between CE and its three variants at the termination condition. The experimental results confirmed that our proposed CoCE has a faster convergence speed and higher convergence accuracy, and the acceleration effect is more significant for high dimensional optimization problems.},
  archive   = {C_CEC},
  author    = {Jun Yu and Zitong Wang and Yan Pei},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504825},
  pages     = {1357-1364},
  title     = {Cooperative chaotic evolution},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A population size dynamic reduction criterion in PSO
algorithms. <em>CEC</em>, 1349–1356. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504791">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The size of the population is extremely important when executing a population-based algorithm. Its portioning impacts how much the algorithm will have for exploration and exploitation. An excessively large population can benefit exploration as opposed to exploitation. With a population below ideal, exploration may be impaired, and the algorithm may quickly converge to a local optimum. Unfortunately, the choice of population size is often made empirically, where the user experiences different values, several times, for different problems, without any well-defined criteria, often drawing only on his experience. This type of approach can under-use the algorithm, generating waste in both computational cost and results. In this work, we improve and study an approximation metamodel as a particle reduction criterion for particle swarm algorithms. This metamodel considers that if two particles are relatively close and with similar velocitys, they will tend to the same solution, allowing one of these to be eliminated. Five traditional benchmark problems in the literature in the field of engineering applications were performed and the results analyzed.},
  archive   = {C_CEC},
  author    = {Samuel C.A. Basílio and Afonso C. C. Lemonge and Érica C.R. Carvalho},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504791},
  pages     = {1349-1356},
  title     = {A population size dynamic reduction criterion in PSO algorithms},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Upper bounds for particle location variance convergence
measures in the stochastic model of particle swarm. <em>CEC</em>,
1341–1348. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504884">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Properties of the Particle Swarm Optimization method depend on the parameters configuring the behavior of single particles. In the stochastic particle stability analysis, there were proposed recurrent formulas of the expected value and the variance of particle location. Recently, a particle variance convergence time measure was defined, and for a selected set of configurations, a simple explicit formula for particle location variance under the stagnation assumption was derived. We propose an explicit formula for the upper bound of the particle variance convergence time for the same selected set of configurations. Furthermore, we propose an explicit formula for the upper bound for the earlier defined measure of the particle location variance stasis time. We visualize both upper bounds and verify them in simulations.},
  archive   = {C_CEC},
  author    = {Krzysztof Wójcik and Tomasz Kulpa and Krzysztof Trojanowski},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504884},
  pages     = {1341-1348},
  title     = {Upper bounds for particle location variance convergence measures in the stochastic model of particle swarm},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal train speed optimization under several safety points
by the PSO algorithm. <em>CEC</em>, 1333–1340. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504810">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Considering the safety factors in the railway, this paper mainly focuses on the optimal speed of high-speed train or locomotive from the starting station to the ending station. Firstly, some concepts in the railway safety, which include the risk source, hidden danger, accident and safety warning point, are introduced to better understand the railway safety factors. Secondly, the mathematical model including objective function and the corresponding constraints is analyzed to solve the optimal train speed problem. Thirdly, the PSO algorithm is used to provide and design the optimal speed train from the starting station to the ending station. Simulation results show that PSO algorithm can handle with the optimal train speed problem and the obtained optimal speed are provided to ensure the train safety in the constant transportation time.},
  archive   = {C_CEC},
  author    = {Jun Liu and Tianyun Shi and Xiaoning Ma and Rui Xue and Min Liu},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504810},
  pages     = {1333-1340},
  title     = {Optimal train speed optimization under several safety points by the PSO algorithm},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). PSO with coupled map lattice and worker ant’s law.
<em>CEC</em>, 1327–1332. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504693">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this study, we present two types of approaches for developing of particle swarm optimization (PSO). Firstly, we introduce coupled map lattice (CML) that is used a logistic map, to the moving equation of PSO. We consider that the PSO obtains two parts which are moving according to random vector and moving according similar vector by the CML phenomena. Secondly, we introduce Worker ant&#39;s law to the moving equation of PSO. The Worker ant&#39;s law is a variant of the Pareto&#39;s law. The ratio of ants is 2:6:2 that include hard working ants, normal ants, and not working ants, respectively. We give the different momentum term for each swarm that is divided according to Worker ant&#39;s law. It is considered that the search range can be expanded by the different momentum term without the divergence of solution search. We confirm that the CML and Worker ant&#39;s law improve the solution searching ability of PSO by comparison with the general PSOs.},
  archive   = {C_CEC},
  author    = {Kanta Matsumoto and Chihiro Ikuta},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504693},
  pages     = {1327-1332},
  title     = {PSO with coupled map lattice and worker ant’s law},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A niche based multi-objective particle swarm optimizer.
<em>CEC</em>, 1319–1326. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504907">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The aim of multi-objective particle swarm optimizer (MOPSO) is to find an accurate and well-distributed approximation of the true Pareto Front (PF). The intrinsic character of PSO puts convergence first, which can cause great loss of population diversity. How to maintain the convergence and diversity simultaneously is an essential issue for MOPSO. In this paper, we propose a niche based multi-objective particle swarm optimizer (NMOPSO) to balance the convergence and diversity. First, a niche based on the Euclidean distance is constructed for each particle, then the leading particle is chosen out either from the niche or from the whole swarm. After that, two position update strategies are designed to update the position of each particle. The position update strategies provide two guiding models for leaders, one is utilizing the difference vector between the leader and the current particle, the other is directly taking some components of leaders. Three well-known test suites are employed to verify the performance of NMOPSO. Compared with three popular MOPSOs, simulation results show that NMOPSO performs better on most of test problems.},
  archive   = {C_CEC},
  author    = {Jinglei Guo and Miaomiao Shao and Shouyong Jiang and Xinyu Zhou},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504907},
  pages     = {1319-1326},
  title     = {A niche based multi-objective particle swarm optimizer},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-objective optimisation of robotic active particle
swarms for continuous repair of large scale high value structures.
<em>CEC</em>, 1312–1318. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504749">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The manufacture and creation of large scale high value structures has been done by humans for centuries. Examples include the Egyptian pyramids, Bridges, Modern Skyscrapers to mention a few. These structures are large but also provide a high value in terms of economy, culture, display of prestige to mention a few. With advances in space technology, we are bound to see these large scale high value structures constructed in space. The vacuum of space present us with the challenges of repairing these structures. This is due to the inhospitable and dangerous environment of space. With increasing number of structures in space, there is bound to be more debris created resulting in high impact damages to these high value structures. Inspired by the biological blood clotting process and biological active particles, in this work, we propose the use of a swarm of live on artificial active particles for the purposes of continuous and timely repair of these structures. We tackle one of the challenges of artificial active particles research; the ability to navigate in crowded and obstacle filled environments. This challenge can be viewed from the perspective of a constrained multi-objective optimisation problem in which a balance between exploration of an environment and its exploitation needs to be achieved while taking into consideration the various other constraints that apply to an active particle. In this work, we show how artificial active particles could avoid obstacles in their environment through the use of an exploration mechanism and find damaged sites. Our results show that as the ability to explore increases, the active particles are able to navigate around obstacles and find a damaged site. However, there is a limit to this.},
  archive   = {C_CEC},
  author    = {John Oyekan},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504749},
  pages     = {1312-1318},
  title     = {Multi-objective optimisation of robotic active particle swarms for continuous repair of large scale high value structures},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Genetic algorithm assisted HIDMS-PSO: A new hybrid
algorithm for global optimisation. <em>CEC</em>, 1304–1311. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504852">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, a new hybrid algorithm, GA-HIDMS-PSO, is introduced by hybridising the state-of-the-art particle swarm optimisation (PSO) variant, the heterogeneous improved dynamic multi-swarm PSO (HIDMS-PSO) with a genetic algorithm (GA). The new hybrid model exploits the heterogeneous features of HIDMS-PSO and the evolutionary characteristics of the GA. In the GA-HIDMS-PSO architecture, HIDMS-PSO acts as the primary search engine, and the GA is employed as the secondary method to assist and slow down the loss of diversity for selected proportions of homogeneous and heterogeneous subpopulations of the HIDMS-PSO algorithm. Both methods run consecutively. As the primary search method, HIDMS-PSO runs for longer periods compared with the GA. The HIDMS-PSO pro-vides the initial solutions for the GA from both homogeneous and heterogeneous subpopulations and final solutions returned from the GA replace prior solutions in the HIDMS-PSO which resumes the search process with potentially more diverse particles to guide the swarm. The GA-HIDMS-PSO algorithm&#39;s performance was tested on the 30 and 50 dimensional CEC&#39;05 and CEC&#39;17 test suites. The results were compared with 24 algorithms, with 12 state-of-the-art PSO variants and 12 other metaheuristics. GA-HIDMS-PSO outperformed all 24 comparison algorithms on both test suites for both 30 and 50 dimensions.},
  archive   = {C_CEC},
  author    = {Fevzi Tugrul Varna and Phil Husbands},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504852},
  pages     = {1304-1311},
  title     = {Genetic algorithm assisted HIDMS-PSO: A new hybrid algorithm for global optimisation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Detecting anomalies in daily COVID-19 cases data from brazil
capitals using GSP theory. <em>CEC</em>, 1296–1303. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504844">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The COVID-19 pandemic has created an urgency for studies to understand the spread of the virus, in particular, to predict the number of daily cases. This type of investigation depends heavily on the data collected and made available manually. Therefore, data are susceptible to human errors which can cause anomalies in the dataset. Understanding and correcting anomalies in real-world application data is an important task to ensure the reliability of the data analysis and prediction tools. This paper presents a spectral anomaly detection and correction strategy that uses concepts from the graph signal processing (GSP) theory. The main advantage of the introduced strategy is to analyze the variation in the daily number of cases with the proximity relation between the investigated locations. Experiments were carried out with real meteorological and mobility data for predicting the number of COVID-19 cases by the classic prediction model known as autoregressive integrated moving average exogenous (ARIMAX). Then, the anomaly detection method was applied to determine the relationship between the prediction errors and the anomalous variations identified by the tool. The results show a strong relationship between the anomalous variations and the errors made by the model and attest to the increase in the accuracy of the prediction model after the normalization of the anomalies.},
  archive   = {C_CEC},
  author    = {Rodrigo Francisquini and Tiago T. da Silva and Mariá C. V. Nascimento},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504844},
  pages     = {1296-1303},
  title     = {Detecting anomalies in daily COVID-19 cases data from brazil capitals using GSP theory},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Heuristic strategies for solving complex interacting
large-scale stockpile blending problems. <em>CEC</em>, 1288–1295. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504901">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Stockpile blending problem is an important component of mine production scheduling, where stockpiles are used to store and blend raw material. The goal of blending material from stockpiles is to create parcels of concentrate which contain optimal metal grades based on the material available. The volume of material that each stockpile provides to a given parcel is dependent on a set of mine schedule conditions and customer demands. Therefore, the problem can be formulated as a continuous optimization problem. In the real-world application, there are several constraints required to guarantee parcels that meet the demand of downstream customers. It is a challenge in solving the stockpile blending problems since its scale can be very large. We introduce two repaired operators for the problems to convert the infeasible solutions into the solutions without violating the two tight constraints. Besides, we introduce a multi-component fitness function for solving the large-scale stockpile blending problem which can maximize the volume of metal over the plan and maintain the balance between stockpiles according to the usage of metal. Furthermore, we investigate the well-known approach in this paper, which is used to solve optimization problems over continuous space, namely the differential evolution (DE) algorithm. The experimental results show that the DE algorithm combined with two proposed duration repair methods is significantly better in terms of the values of results than the results on real-world instances for both one-month problems and large-scale problems.},
  archive   = {C_CEC},
  author    = {Yue Xie and Aneta Neumann and Frank Neumann},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504901},
  pages     = {1288-1295},
  title     = {Heuristic strategies for solving complex interacting large-scale stockpile blending problems},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi objective UAV network deployment for dynamic fire
coverage. <em>CEC</em>, 1280–1287. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504947">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent large wildfires and subsequent damage have increased the importance of wildfire monitoring and tracking. However, human monitoring on the ground or in the air may be too dangerous and we thus investigate deploying Unmanned Aerial Vehicles (UAVs) to track wildfires. Specifically, we attack the problem of distributed autonomous control of UAVs using a set of potential fields to track wildfire boundaries. A multiobjective evolutionary algorithm searches through the space of potential field parameters to maximize fire coverage while minimizing energy consumption. Fire spread is modelled by the well known FARSITE fire model. Preliminary simulation results show that our potential fields approach to UAV control leads to 100\% coverage of the boundary by UAVs and 78.1\% energy remaining on three testing scenarios.},
  archive   = {C_CEC},
  author    = {Kripash Shrestha and Rahul Dubey and Ashutosh Singandhupe and Sushil Louis and Hung La},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504947},
  pages     = {1280-1287},
  title     = {Multi objective UAV network deployment for dynamic fire coverage},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evaluation of decision-making strategies for robots in
intralogistics problems using multi-agent planning. <em>CEC</em>,
1272–1279. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504887">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Robots are currently being used in many real-world problems, especially intralogistics scenarios where manufacturing and warehousing are continuously performed. Those robots can be affected by exogenous events that cause failures during their execution, leading to a dynamic environment condition. Thus, robots interact not only with the environment but also with other agents, therefore they require a coordination protocol to guarantee cooperation and recovery from unexpected events. The intralogistics problem is a real-world application to a multi-agent planning model where agents are seen as autonomous mobile robots (AMR). Related work highlights the autonomy level and investigates different strategies for applying a decision-making process. However, there is a gap in the literature regarding an analysis of the conditions that make a decentralized decision-making process more suitable than a centralized control in a dynamic environment. This study investigates how strongly connected AMRs are, according to their nature, and the conditions and effects of the actions they can execute. We contribute to the research area by detailing how the analysis of features of the intralogistics scenario can be useful to identify the most suitable decision-making strategy for AMRs in such dynamic environments.},
  archive   = {C_CEC},
  author    = {Leonardo Henrique Moreira and Célia Ghedini Ralha},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504887},
  pages     = {1272-1279},
  title     = {Evaluation of decision-making strategies for robots in intralogistics problems using multi-agent planning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mitigating attacks on fake news detection systems using
genetic-based adversarial training. <em>CEC</em>, 1265–1271. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504723">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The study of adversarial effects on AI systems is not a new concept, but much of the research has been devoted to deep learning. In this paper we explore the effects of adversarial examples on 4 machine learning classifiers and measure the effectiveness of adversarial training. Additionally, we present a novel method for selecting adversarial training examples that lead to a more robust machine learning system. Our results suggest that adversarial examples can significantly hinder the classification performance and that adversarial training is an effective defensive counter-measure.},
  archive   = {C_CEC},
  author    = {Marcellus Smith and Brandon Brown and Gerry Dozier and Michael King},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504723},
  pages     = {1265-1271},
  title     = {Mitigating attacks on fake news detection systems using genetic-based adversarial training},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Aggregation or selection? Clustering many objectives for
vehicle routing problem with demand responsive transport. <em>CEC</em>,
1257–1264. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504919">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper discusses a dimensionality reduction procedure to tackle a many-objective formulation of a Vehicle Routing Problem with a Demand Responsive Transport (VRPDRT). The problem formulation presents eight objective functions that aim to reduce the operating costs while meeting passenger needs and providing a high-quality service. Two different dimensionality reduction-based approaches, aggregation and feature selection are employed to transform the many-objective formulation into a bi-objective one. The reduction, applied during the search evolution, follows a hierarchical clustering technique in which the objective functions’ similarity and conflict are explored. The proposed approaches are compared with a classic version of MOEA/D that solves the problem in its original formulation. Moreover, different dimensionality reduction frequencies are tested to assess the impact on the algorithms’ performance. When comparing the outcomes in the original objective space, the results show that the aggregation approach outperforms the feature selection method, regardless of the dimensionality reduction frequency. Furthermore, while there is no statistical difference between the MOEA/D and the aggregation approach and the MOEA/D outperforms the feature selection approaches.},
  archive   = {C_CEC},
  author    = {Renan S. Mendes and Elizabeth F. Wanner and Flávio V. C. Martins and Kalyanmoy Deb},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504919},
  pages     = {1257-1264},
  title     = {Aggregation or selection? clustering many objectives for vehicle routing problem with demand responsive transport},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evaluating anytime performance on NAS-bench-101.
<em>CEC</em>, 1249–1256. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504902">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Neural architecture search (NAS) is a field where computational effort poses a significant challenge, requiring large computing clusters and specialized hardware. Furthermore, the lack of common experimental guidelines often compromises NAS comparison or induces premature conclusions. In a recent work, NAS-Bench-101 was proposed to help mitigate those factors, providing both a common benchmark and experimental guidelines for its use. In this work, we discuss the design choices in NAS-Bench-101 and propose improvements that increase the potential of the benchmark. First, we bridge NAS and the research on anytime performance, showing how a bi-objective formulation of NAS can improve the insights provided by NAS-Bench-101. Then, we discuss choices made in the design of the benchmark, namely (i) the fixed-size encoding, (ii) the effects of the limited variability available, (iii) the assessment of algorithms only from a TPU time perspective, and; (iv) the number of repetitions proposed. We demonstrate our contributions assessing the best-performing algorithms originally benchmarked on NAS-Bench-101 and also irace, one of the best-performing algorithm configurators from the literature. Results indicate that (i) the anytime performance methodology enriches the insights obtained from the assessment on the original NAS-Bench-101; (ii) algorithm comparison is strongly affected by the design choices discussed, and; (iii) the performance of SMAC in this benchmark is significantly improved by our alternative setups.},
  archive   = {C_CEC},
  author    = {Carlos Vieira and Leslie Pérez Cáceres and Leonardo C. T. Bezerra},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504902},
  pages     = {1249-1256},
  title     = {Evaluating anytime performance on NAS-bench-101},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evolving neural networks for text classification using
genetic algorithm-based approaches. <em>CEC</em>, 1241–1248. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504920">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Convolutional Neural Networks (CNNs) have been well-known for their promising performance in text classification and sentiment analysis because they can preserve the 1D spatial orientation of a document, where the sequence of words is essential. However, designing the network architecture of CNNs is by no means an easy task, since it requires domain knowledge from both the deep CNN and text classification areas, which are often not available and can increase operating costs for anyone wishing to implement this method. Furthermore, such domain knowledge is often different in different text classification problems. To resolve these issues, this paper proposes the use of Genetic Algorithm to automatically search for the optimal network architecture without requiring any intervention from experts. The proposed approach is applied on the IMDB dataset, and the experimental results show that it achieves competitive performance with the current state-of-the-art and manually-designed approaches in terms of accuracy, and also it requires only a few hours of training time.},
  archive   = {C_CEC},
  author    = {Hayden Andersen and Sean Stevenson and Tuan Ha and Xiaoying Gao and Bing Xue},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504920},
  pages     = {1241-1248},
  title     = {Evolving neural networks for text classification using genetic algorithm-based approaches},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Differential evolution-based neural network training
incorporating a centroid-based strategy and dynamic opposition-based
learning. <em>CEC</em>, 1233–1240. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504801">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Training multi-layer neural networks (MLNNs), a challenging task, involves finding appropriate weights and biases. MLNN training is important since the performance of MLNNs is mainly dependent on these network parameters. However, conventional algorithms such as gradient-based methods, while extensively used for MLNN training, suffer from drawbacks such as a tendency to getting stuck in local optima. Population-based metaheuristic algorithms can be used to overcome these problems. In this paper, we propose a novel MLNN training algorithm, CenDE-DOBL, that is based on differential evolution (DE), a centroid-based strategy (Cen-S), and dynamic opposition-based learning (DOBL). The Cen-S approach employs the centroid of the best individuals as a member of population, while other members are updated using standard crossover and mutation operators. This improves exploitation since the new member is obtained based on the best individuals, while the employed DOBL strategy, which uses the opposite of an individual, leads to enhanced exploration. Our extensive experiments compare CenDE-DOBL to 26 conventional and population-based algorithms and confirm it to provide excellent MLNN training performance.},
  archive   = {C_CEC},
  author    = {Seyed Jalaleddin Mousavirad and Diego Oliva and Salvador Hinojosa and Gerald Schaefer},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504801},
  pages     = {1233-1240},
  title     = {Differential evolution-based neural network training incorporating a centroid-based strategy and dynamic opposition-based learning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-objective hyperparameter optimization for spiking
neural network neuroevolution. <em>CEC</em>, 1225–1232. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504897">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Neuroevolution has had significant success over recent years, but there has been relatively little work applying neuroevolution approaches to spiking neural networks (SNNs). SNNs are a type of neural networks that include temporal processing component, are not easily trained using other methods because of their lack of differentiable activation functions, and can be deployed into energy-efficient neuromorphic hardware. In this work, we investigate two evolutionary approaches for training SNNs. We explore the impact of the hyperparameters of the evolutionary approaches, including tournament size, population size, and representation type, on the performance of the algorithms. We present a multi-objective Bayesian-based hyperparameter optimization approach to tune the hyperparameters to produce the most accurate and smallest SNNs. We show that the hyperparameters can significantly affect the performance of these algorithms. We also perform sensitivity analysis and demonstrate that every hyperparameter value has the potential to perform well, assuming other hyperparameter values are set correctly.},
  archive   = {C_CEC},
  author    = {Maryam Parsa and Shruti R. Kulkarni and Mark Coletti and Jeffrey Bassett and J. Parker Mitchell and Catherine D. Schuman},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504897},
  pages     = {1225-1232},
  title     = {Multi-objective hyperparameter optimization for spiking neural network neuroevolution},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fast evolutionary neural architecture search based on
bayesian surrogate model. <em>CEC</em>, 1217–1224. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504999">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Neural Architecture Search (NAS) is studied to automatically design the deep neural network structure, freeing people from heavy network design tasks. Traditional NAS based on individual performance evaluation needs to train many networks generated by the search, and compare the performance of the networks according to their accuracy, which is very time-consuming. In this study, we propose to use a two-category comparator based random forest model as a surrogate to estimate the accuracy of the networks. thereby reducing heavy network training process and greatly saving search time. Instead of directly predicting the accuracy of each network, we propose to compare the relative performance between each two networks in our proposed two-category comparator. Furthermore, we implement the modeling process of the surrogate model in the sampling space of the original training data, which further accelerates the search process of the network in the NAS. Experimental results show that our proposed NAS framework can greatly reduce the search time, while the accuracy of the obtained network is comparable to that of other state-of-the art NAS algorithms.},
  archive   = {C_CEC},
  author    = {Rui Shi and Jianping Luo and Qiqi Liu},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504999},
  pages     = {1217-1224},
  title     = {Fast evolutionary neural architecture search based on bayesian surrogate model},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Comparative performances of neural networks of variant
architectures trained with backpropagation and differential evolution.
<em>CEC</em>, 1209–1216. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504984">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Work on Neuro-evolution has of late tended to focus on the design of alternative architectures and hyper-parameters for different classes of Neural Networks to improve performance and computational efficiency, using Evolutionary Algorithms (EA). Predominantly, the underlying mechanism for learning weight parameters remains traditional backpropagation (BP), now considered a paradigm of Deep Learning (DL). Many important facets of DL, like hierarchical construction of features across layers in image recognition, vanishing gradients, etc., are taken for granted without recognizing that these may implicitly be induced by the properties of BP itself. EAs that perform global optimization in contrast to local gradient descent of BP, if used extensively for ANN training, can potentially disrupt these assumed facets of DL – and construct alternative and interesting perspectives. There is a surprising lack of research activity towards one-to-one performance comparison between EA and BP, keeping precisely the same architectures, activation functions and datasets, for complex regression and classification problems. This work partially fills this gap. It is demonstrated that Differential Evolution enhanced with local search, can generate mildly better accuracies on regression problems on noisy industrial datasets compared to standard BP solutions, and comparable accuracies on popular image classification datasets. Consequently, this establishes the baseline for revisiting the above-mentioned assumed facets of DL, and potentially engender new and interesting perspectives.},
  archive   = {C_CEC},
  author    = {Zakaria Oussalem and Rochan Avlur Venkat and Jahnavi Malagavalli and Arya Kumar Bhattacharya},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504984},
  pages     = {1209-1216},
  title     = {Comparative performances of neural networks of variant architectures trained with backpropagation and differential evolution},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An empirical study on the use of the s-energy performance
indicator in mating restriction schemes for multi-objective optimizers.
<em>CEC</em>, 1201–1208. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504869">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Mating restrictions have been used to improve the performance of Multi-Objective Evolutionary Algorithms (MOEAs) by altering the way in which parents are selected in the recombination step. Originally proposed for single-objective optimization, mating restrictions have been implemented in different MOEAs obtaining mixed results. However, the role of mating restrictions in diversity management/maintenance and in the proper balance between exploration and exploitation within MOEAs has not been studied in sufficient detail in spite of its evident importance. In this paper, we present an empirical study on the impact of three new mating restrictions based on the s-energy performance indicator. When obtaining each individual’s contribution to the total s-energy, we implicitly obtain vicinity information, since a high contribution means that an individual is relatively close to at least some other individual, i.e., it is in a crowded region. Conversely, an individual with a low contribution is in a non-crowded region. Using this information we explore different strategies aiming to improve the diversity of the population during its execution, as well as exploiting the least crowded regions of the objective space. One of the main advantages of our proposal are both its simplicity and its ability to scale up (in objective function space). We evaluate the impact of our proposals by implementing them in NSGA-III and comparing the obtained results with respect to those of the original algorithm. Our experimental results show that the use of mating restrictions does provide improvements in most of the test instances adopted for some of our proposed strategies.},
  archive   = {C_CEC},
  author    = {Amín V. Bernabé Rodríguez and Carlos A. Coello Coello},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504869},
  pages     = {1201-1208},
  title     = {An empirical study on the use of the S-energy performance indicator in mating restriction schemes for multi-objective optimizers},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-modal multi-objective evolutionary optimization for
problems with solutions of variable-length. <em>CEC</em>, 1193–1200. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504705">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper focuses on solving a special kind of multimodal multi-objective optimization problems (MMOPs) in which solutions are of variable length. First, problem definition and solution framework is suggested to allow using standard multimodal multi-objective evolutionary algorithms (MMEAs) to solve the considered type of problems. Next, a real-life example of the considered type of problems is suggested concerning optimal antennas’ layout-allocation design for a wireless communication network. Finally, a modification to NSGA-II is suggested and employed to solve such layout problems. When compared with other MMEAs, it is shown that the proposed algorithm provides not only better solution diversity in the decision-space, but also solutions with superior performance vectors. It is suggested here that this is attributed to the type of archive that is used here.},
  archive   = {C_CEC},
  author    = {Amiram Moshaiov and Yosef Breslav and Eliran Farhi},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504705},
  pages     = {1193-1200},
  title     = {Multi-modal multi-objective evolutionary optimization for problems with solutions of variable-length},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards a more balanced reference set adaptation method:
First results. <em>CEC</em>, 1185–1192. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504769">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Reference sets are widely used by many multi-objective evolutionary algorithms (MOEAs) to decompose the objective space, define search directions, or calculate quality indicators (QIs) embedded into the selection mechanisms. Well-known MOEAs adopt the generation of uniformly distributed points on a unit simplex to construct such reference sets. Although these mechanisms are useful for approximating Pareto fronts with regular shapes, i.e., simplex-like shapes, they have difficulties representing Pareto fronts with irregular geometries. To overcome this drawback, many reference set adaptation methods have been proposed so far. However, some adaptation methods present a degraded performance on regular Pareto front shapes, while others promote a balanced performance. Nevertheless, an extensive assessment has not been made. In this paper, a MOEA based on the inverted generational distance plus indicator, using an adaptive reference set, is used to study the performance of well-known adaptation methods. Although an adaptation method promotes a balanced performance on both regular and irregular Pareto front shapes, results show some difficulties related to the distribution of solutions in complex Pareto front shapes. The results of this study allow detecting the main drawbacks of adaptation methods, which can be addressed by using diversity-oriented selection mechanisms in the generation of reference sets. Hence, these could impact the generation of reference set-based MOEAs achieving good coverage, convergence, and diversity regardless of the Pareto front shape.},
  archive   = {C_CEC},
  author    = {Luis A. Márquez-Vega and Jesús Guillermo Falcón-Cardona and Edgar Covantes Osuna},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504769},
  pages     = {1185-1192},
  title     = {Towards a more balanced reference set adaptation method: First results},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Investigating constraint relationship in evolutionary
many-constraint optimization. <em>CEC</em>, 1179–1184. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504839">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This study contributes to the treatment of numerous constraints in evolutionary many-constraint optimization through consideration of the relationships between pair-wise constraints. In a conflicting relationship, the functional value of one constraint increases as the value in another constraint decreases. In a harmonious relationship, the improvement in one constraint is rewarded with simultaneous improvement in the other constraint. In an independent relationship, the adjustment to one constraint never affects the adjustment to the other. Based on the different features, methods for identifying constraint relationships are investigated, helping to simplify many-constraint optimization problems (MCOPs). Additionally, the transitivity of the relationships is further discussed, facilitating the determination of the relationship in a new pair of constraints.},
  archive   = {C_CEC},
  author    = {Mengjun Ming and Rui Wang and Tao Zhang},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504839},
  pages     = {1179-1184},
  title     = {Investigating constraint relationship in evolutionary many-constraint optimization},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Revisiting pareto-optimal multi- and many-objective
reference fronts for continuous optimization. <em>CEC</em>, 1171–1178.
(<a href="https://doi.org/10.1109/CEC45853.2021.9504952">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The performance assessment of multi-objective heuristic algorithms is one of the most significant contributions from the evolutionary optimization algorithms community. By contrast, performance assessment in the context of many-objective optimization is still a challenging, open research field. Recent advances have demonstrated disagreements between Pareto-compliant performance metrics, and indicated that reference fronts produced by benchmark generators of Pareto-optimal fronts could be further improved. In this work, we investigate these reference fronts with the help of multi-dimensional visualization techniques and Pareto-monotonic archivers. Interestingly, reference fronts produced by benchmark generators for DTLZ and WFG continuous optimization problems show significant issues, even when only three objectives are considered. Furthermore, given that input solution sets for five-objective problems are not high-quality, archivers are unable to output reasonable approximation fronts. We conclude that the performance assessment of EMO algorithms needs to urgently address reference front generation.},
  archive   = {C_CEC},
  author    = {Gabriela Cavalcante da Silva and Elizabeth F. Wanner and Leonardo C. T. Bezerra and Thomas Stützle},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504952},
  pages     = {1171-1178},
  title     = {Revisiting pareto-optimal multi- and many-objective reference fronts for continuous optimization},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Enhancing moea/d with escape mechanisms. <em>CEC</em>,
1163–1170. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504957">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we investigate the design of escape mechanisms within the state-of-the-art decomposition-based evolutionary multi-objective Moea/d framework. We propose to track the number of improvements made with respect to the single-objective sub-problems defined by decomposition. This allows us to compute an estimated sub-problem improvement probability which serves as an activation signal for some solution perturbation mechanism to occur. We report the benefits of such an approach by conducting a comprehensive experimental analysis on a broad range of combinatorial bi-objective bit-string landscapes with variable dimensions and ruggedness. Our empirical findings provide evidence on the effectiveness of the proposed escape mechanism and its ability in providing substantial improvement over conventional Moea/d. Besides, we provide a detailed analysis of parameters impact and anytime behavior in order to better highlight the strength of the proposed techniques as a function of available budget and problem characteristics.},
  archive   = {C_CEC},
  author    = {Bilel Derbel and Geoffrey Pruvost and Byung-Woo Hong},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504957},
  pages     = {1163-1170},
  title     = {Enhancing moea/d with escape mechanisms},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automated design of unfolded metaheuristics and the effect
of population size. <em>CEC</em>, 1155–1162. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504879">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Metaheuristics are a fairly standard approach for solving optimisation problems due to their success, flexibility, and simplicity. However, there is a plethora of metaheuristics available, with different performance levels for various problems. This work proposes a methodology for designing heuristic-based procedures to solve continuous optimisation problems and study how the population size affects its performance. The technique comprises the well-known Simulated Annealing algorithm as a hyper-heuristic, and a heuristic sequence taken from unfolding the conventional scheme of population-based metaheuristics reported in the literature. Our results show that the proposed approach is a reliable alternative for tackling optimisation problems. We find exciting insights, according to our data, about this primary implementation when varying the population size in different challenging problems.},
  archive   = {C_CEC},
  author    = {Jorge M. Cruz-Duarte and Ivan Amaya and José Carlos Ortiz-Bayliss and Nelishia Pillay},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504879},
  pages     = {1155-1162},
  title     = {Automated design of unfolded metaheuristics and the effect of population size},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A neural approach to generation of constructive heuristics.
<em>CEC</em>, 1147–1154. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504989">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Both algorithm-selection methods and hyper-heuristic methods rely on a pool of complementary heuristics. Improving the pool with new heuristics can improve performance, however, designing new heuristics can be challenging. Methods such as genetic programming have proved successful in automating this process in the past. Typically, these make use of problem state-information and existing heuristics as components. Here we propose a novel neural approach for generating constructive heuristics, in which a neural network acts as a heuristic by generating decisions. We evaluate two architectures, an Encoder-Decoder LSTM and a Feed-Forward Neural Network. Both are trained using the decisions output from existing heuristics on a large set of instances. We consider streaming instances of bin-packing problems in a continual stream that must be packed immediately in strict order and using a limited number of resources. We show that the new heuristics generated are capable of solving a subset of instances better than the well-known heuristics forming the original pool, and hence the overall value of the pool is improved w.r.t. both Falkenauer&#39;s performance metric and the number of bins used.},
  archive   = {C_CEC},
  author    = {Mohamad Alissa and Kevin Sim and Emma Hart},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504989},
  pages     = {1147-1154},
  title     = {A neural approach to generation of constructive heuristics},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The effect of sampling methods on the invariance to function
transformations when using exploratory landscape analysis. <em>CEC</em>,
1139–1146. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504739">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Exploratory Landscape Analysis is a methodology for transforming the samples of an optimization problem into numerical descriptors called landscape features. Since Exploratory Landscape Analysis is sample based, recent studies have shown that the choice of the method used to collect the problem samples can have an effect on the calculation of landscape features.In our recent work, we have shown that certain landscape features are not invariant to even simple function transformations such as shifting or scaling. However, the analysis in our previous work was conducted using only Latin Hypercube Sampling. Since we are now aware that the choice of sampling method can affect the calculation of landscape features, this paper expands upon our earlier work by using a variety of different sampling methods. We show that different sampling methods do indeed have an effect on the invariance of landscape features, and present a list of landscape features that are invariant under all of our chosen sampling methods.},
  archive   = {C_CEC},
  author    = {Urban Škvorc and Tome Eftimov and Peter Korošec},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504739},
  pages     = {1139-1146},
  title     = {The effect of sampling methods on the invariance to function transformations when using exploratory landscape analysis},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Local optima network sampling for permutation flowshop.
<em>CEC</em>, 1131–1138. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504690">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This work presents an analysis of sampled Local Optima Networks (LONs) on flowshop instances. LON metrics are addressed here to scrutinize the performance of four sampling strategies, each one resulting from the combination of a local search (iterative or best improvement) and a perturbation operator (deconstruction with or without local search on partial solutions). The results highlight the superiority of iterative improvement and the advantages of exploiting partial solutions, especially when they are combined to discover new local optima regions on large problems. LON metrics are also useful for predicting performance of optimization algorithms - in particular, this work considers two Iterated Greedy variants when solving flowshop instances. The predictive capacity of metrics calculated from sampled LONs is evaluated here based on the R 2 and RMSE indicators. Results show that the best sampling strategies provide LON metrics capable of predicting 80\% and 73\% of variance for small and large flowshop instances, respectively.},
  archive   = {C_CEC},
  author    = {Lucas Marcondes Pavelski and Marie-Éléonore Kessaci and Myriam Delgado},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504690},
  pages     = {1131-1138},
  title     = {Local optima network sampling for permutation flowshop},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automated development of latent representations for
optimization of sequences using autoencoders. <em>CEC</em>, 1123–1130.
(<a href="https://doi.org/10.1109/CEC45853.2021.9504910">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we propose an automated method for the development of new representations of sequences. For this purpose, we introduce a two-way mapping from variable length sequence representations to a latent representation modelled as the bottleneck of an LSTM (long short-term memory) autoencoder. Desirable properties of such mappings include smooth fitness landscapes for optimization problems and better evolvability. This work explores the capabilities of such latent encodings in the context of optimization of 3D structures. Various improvements are adopted that include manipulating the autoencoder architecture and its training procedure. The results of evolutionary algorithms that use different variants of automatically developed encodings are compared.},
  archive   = {C_CEC},
  author    = {Piotr Kaszuba and Maciej Komosinski and Agnieszka Mensfelt},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504910},
  pages     = {1123-1130},
  title     = {Automated development of latent representations for optimization of sequences using autoencoders},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Machine learning for determining the transition point in
hybrid metaheuristics. <em>CEC</em>, 1115–1122. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504905">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {High-level relay hybrids are among the most effective metaheuristics in multiple domains. However, the relay aspect of hybridization raises the problem of when to perform the transition from one algorithm to the next. This problem becomes more relevant in exploration-only exploitation-only hybrids, where each algorithm specializes in a specific task and performs rather poorly in the other. This paper presents a novel way of approaching the transition problem as a classification problem. Different classifiers are trained and tested on the MPS-CMAES hybrid; computational results are presented for the CEC&#39;13 benchmark. The performance of the machine learning based hybrid confirms the effectiveness of the approach by achieving a significant improvement over the original hybrid.},
  archive   = {C_CEC},
  author    = {Antonio Bolufé-Röhler and Ye Yuan},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504905},
  pages     = {1115-1122},
  title     = {Machine learning for determining the transition point in hybrid metaheuristics},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A genetic algorithm for the nesting problem with continuous
rotations. <em>CEC</em>, 1107–1114. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504813">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Nesting problem, or the irregular cutting and packing problem, aims to find the best position of irregular pieces within a board, minimizing the space used by them. The problem&#39;s relevance is that it is widely used in the furniture, textile, and footwear industries. We consider a two-dimensional scope with convex and non-convex parts, with continuous rotation. We implement a genetic algorithm that uses five positioning rules, five sorting rules, and two rotation rules to create individuals and populations. Two positioning rules outperformed the others, obtaining promising results compared with the literature.},
  archive   = {C_CEC},
  author    = {Wesley H. B. Nunes and Mayron C. O. Moreira and Marina Andretta},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504813},
  pages     = {1107-1114},
  title     = {A genetic algorithm for the nesting problem with continuous rotations},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Distance-weighted exponential natural evolution strategy for
implicitly constrained black-box function optimization. <em>CEC</em>,
1099–1106. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504865">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper presents a natural evolution strategy for implicitly constrained black-box function optimization. The black-box function optimization is challenging because explicit representations of objective functions are not given, and only evaluation values of solutions can be used. In implicitly constrained black-box function problems, constraints are not explicitly given, and only the feasibility of a solution is obtained when the objective function is evaluated. In other words, the amount of constraint violation cannot be obtained, which makes the optimization difficult. Natural Evolution Strategies (NES) is one of the promising frameworks for black-box function optimization. DX-NES is an improved version of xNES which is a promising NES using a multivariate normal distribution as the probability distribution. DX-NES has been reported to show good performance on unconstrained black-box function optimization problems. However, DX-NES has a serious problem in that its performance degrades when applied to implicitly constrained problems. In order to address the problem, we propose DX-NES taking account of Implicit Constraint (DX-NES-IC). In experiments using benchmark problems and a lens system design problem, DX-NES-IC showed better performance than DX-NES, xNES, CMA-ES, and those with the resampling technique in terms of the number of successful trials and that of evaluations, where the resampling technique is a constraint handling method which can be used for implicitly constrained problems.},
  archive   = {C_CEC},
  author    = {Masahiro Nomura and Nobuyuki Sakai and Nobusumi Fukushima and Isao Ono},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504865},
  pages     = {1099-1106},
  title     = {Distance-weighted exponential natural evolution strategy for implicitly constrained black-box function optimization},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evolutionary algorithms for searching almost-equienergetic
graphs. <em>CEC</em>, 1093–1098. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504751">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Many real-world problems can be modeled using graphs. This representation allows us to understand some important aspects of problem behavior through the calculation of different measures. The energy of a graph is an invariant measure that has gained interest in network analysis due to its recent applications, then it is interesting to know the structural properties that make two graphs with similar energies.In this work we propose the search for almost-equienergetic graphs using evolutionary algorithms for Erdös-Rényi networks and trees. The proposed evolutionary algorithms are able to obtain almost-equienergetic graphs in larger instances with respect to traditional methods and the results lead to analyze interesting properties of the graphs found.},
  archive   = {C_CEC},
  author    = {Aarón Jiménez-Aparicio and Efrén Mezura-Montes and Héctor-Gabriel Acosta-Mesa},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504751},
  pages     = {1093-1098},
  title     = {Evolutionary algorithms for searching almost-equienergetic graphs},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). IG-CEE: An embedded information gain approach to genetic
algorithms. <em>CEC</em>, 1086–1092. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504776">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The classification task is among the most used in Data Mining and it is widely researched nowadays. Some works have already been developed using Genetic Algorithms (GAs) for classification tasks, building simple and small IF-THEN classification rules with good classification results. These methods produce understandable outputs (IF-THEN rules), unlike some of the traditional classifiers, e.g. SVM and Artificial Neural Networks, known as black-box type. In this paper, we proposed a new method called Information Gain-based Computational Evolutionary Environment (IG-CEE). The proposed method IG-CEE extends the GA proposed by Amaral and Hruschka named Computational Evolutionary Environment (CEE). The IG-CEE uses the Information Gain approach to select a better subset of attributes to compose the IF-THEN rules, improving classification accuracy and convergence rates. The IG-CEE was compared with CEE and four (4) traditional classifiers: J48, IBK, Naive Bayes, and SVM. To compare all methods, we built three (3) synthetic datasets, generated by GeNIe software. To realize a fair comparison, all methods were executed, with distinct random seeds, 100 times. For each method, the final result was calculated using a confidence interval with 95\% of confidence. The proposed method IG-CEE showed better classification rates in several comparisons.},
  archive   = {C_CEC},
  author    = {Alexandre Henrick da Silva Alves and Raphael de Lima Mendes and Matheus de Souza Gomes and Pedro Luiz Lima Bertarini and Laurence Rodrigues do Amaral},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504776},
  pages     = {1086-1092},
  title     = {IG-CEE: An embedded information gain approach to genetic algorithms},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A biologically-inspired model for mass extinction in genetic
algorithms. <em>CEC</em>, 1078–1085. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504851">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Mass extinction events have previously been shown to be a catalyst for accelerating the rate of evolution in genetic algorithms. This increased evolution rate combined with a destabilization of the dynamic equilibrium of the genetic algorithm can allow the algorithm to overcome local maxima in the solution space; however, most implementations of mass extinction squander the full benefit of the increased evolutionary rate by relying upon random chance to generate better solutions in the post-extinction generations. This paper examines the hypothesis that, by increasing variability and decreasing selection pressure immediately after an extinction event, the algorithm has a higher chance of yielding more fit individuals and overcoming local maxima in the post-extinction generations. We compare the performance of a genetic algorithm without extinction with the two approaches described above on a problem with a large search space containing many local optima, point scattering in the unit circle, and examine the effects of extinction methods on performance. The preliminary results presented here show that decreasing selection pressure and increasing variability help the genetic algorithm achieve higher success rates than with standard mass extinction.},
  archive   = {C_CEC},
  author    = {Kaelan Engholdt and H. David Mathias},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504851},
  pages     = {1078-1085},
  title     = {A biologically-inspired model for mass extinction in genetic algorithms},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A multi-objective approach to the protein structure
prediction problem using the biased random-key genetic algorithm.
<em>CEC</em>, 1070–1077. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504745">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Proteins are base molecules present in live organisms. The study of their structures and functions is of considerable importance for many application fields, particularly for the pharmaceutical area. This paper presents a multi-objective model to the Protein Structure Prediction problem, using three objectives: energy score, secondary structure information, and contact maps information. A BRKGA method is used as a global optimizer and adapted to work with multiple objective problems. Also, the MUFOLD-CL clustering method is applied to select a single predicted structure. Experiments were carried out to analyze the proposed model performance using state-of-the-art ab initio algorithms for comparison. Results obtained indicate that the proposed approach is competitive in terms of RMSD and GDT metrics.},
  archive   = {C_CEC},
  author    = {Felipe Marchi and Rafael Stubs Parpinelli},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504745},
  pages     = {1070-1077},
  title     = {A multi-objective approach to the protein structure prediction problem using the biased random-key genetic algorithm},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An exploration-only exploitation-only hybrid for large scale
global optimization. <em>CEC</em>, 1062–1069. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504812">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Two factors affect the effectiveness of exploration, the bias introduced by selection and the concurrence of exploration and exploitation. The Leaders and Followers metaheuristic was designed to reduce the bias from selection by using a two-population scheme. Minimum Population Search was designed to limit the concurrence of exploration and exploitation through the use of Thresheld Convergence in its sampling strategy. This paper presents Unbiased Exploratory Search, which combines both approaches and simultaneously addresses the effects of these two factors. An exploration-only exploitation-only hybrid is then presented using Unbiased Exploratory Search for the exploration-only phase of the hybrid. The hybrid is tested on the CEC large scale optimization benchmark.},
  archive   = {C_CEC},
  author    = {Antonio Bolufé-Röhler and Dania Tamayo-Vera},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504812},
  pages     = {1062-1069},
  title     = {An exploration-only exploitation-only hybrid for large scale global optimization},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Using MajorClust algorithm for sandbox-based ATM security.
<em>CEC</em>, 1054–1061. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504862">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Automated teller machines are affected by two kinds of attacks: physical and logical. It is common for most banks to look for zero-day protection for their devices. The most secure solutions available are based on complex security policies that are extremely hard to configure. The goal of this article is to present a concept of using the modified MajorClust algorithm for generating a sandbox-based security policy based on ATM usage data. The results obtained from the research prove the effectiveness of the used techniques and confirm that it is possible to create a division into sandboxes in an automated way.},
  archive   = {C_CEC},
  author    = {Michal Maliszewski and Urszula Boryczka},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504862},
  pages     = {1054-1061},
  title     = {Using MajorClust algorithm for sandbox-based ATM security},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Enhancing cooperative coevolution for large scale
optimization by exploiting decomposition solutions. <em>CEC</em>,
1047–1053. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504977">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Problem decomposition plays a vital role in ensuring the performance of cooperative coevolution (CC) for large scale global optimization (LSGO). However, existing high-precision decomposition algorithms require evaluating numerous solutions generally generated in a fixed style and directly abandon them after the decomposition process. This leads to the waste of many computation resources. Directing against this issue, this study attempts to sample decomposition solutions in a local-search manner such that these solutions not only satisfy the decomposition requirements but also possess high quality, and thus can provide a good initial population for the subsequent optimization process. Following this research idea, this study develops a new decomposition algorithm named recursive differential grouping with local search ability (LS-RDG) by embedding the Solis Wets local search operator into the recently developed RDG algorithm. LS-RDG can obtain more promising solutions without consuming extra fitness evaluations. Comprehensive experimental results on two widely used LSGO benchmark suites verify the effectiveness of LS-RDG and indicate that LS-RDG can help CC achieve better optimization performance.},
  archive   = {C_CEC},
  author    = {An Chen and Zhigang Ren and Yongsheng Liang and Daofu Guo},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504977},
  pages     = {1047-1053},
  title     = {Enhancing cooperative coevolution for large scale optimization by exploiting decomposition solutions},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). 3D-RadViz: Three dimensional radial visualization for
large-scale data visualization. <em>CEC</em>, 1037–1046. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504983">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper presents 3D-RadViz, a visualization method for high dimensional data using a three dimensional radial visualization technique. The proposed technique extends the capabilities of the classical two dimensional radial visualization (RadViz) in order to reduce overlapping data points. For evaluation purposes, the paper applies the proposed 3D-RadViz alongside with t-SNE and a recently published 3-dimensional radial visualization technique to the same real-world datasets from the UCI machine learning repository. The contribution of the work is an interactive, deterministic, and high-performance library, implemented in Python, that can be utilized to realize better high dimensional data visualization using the proposed 3D-RadViz technique. The paper also suggests some directions for future enhancements to the proposed visualization approach.},
  archive   = {C_CEC},
  author    = {Abdelrahman Elewah and Abeer A. Badawi and Haytham Khalil and Shahryar Rahnamayan and Khalid Elgazzar},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504983},
  pages     = {1037-1046},
  title     = {3D-RadViz: Three dimensional radial visualization for large-scale data visualization},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A hybrid dimension reduction based linear discriminant
analysis for classification of high-dimensional data. <em>CEC</em>,
1028–1036. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504951">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Linear discriminant analysis (LDA) is a notable classification algorithm thanks to its major success in many applications of the real-world. In spite of its successfulness for low-dimensional data, a dimension reduction is inevitable for its achievement with high-dimensional data, especially in which the number of features is more than the training sample size or close to the training sample size. Principal component analysis (PCA) plus LDA (PCA+LDA), a quite popular technique, is widely used for raising the classification performance of LDA over high-dimensional data. However, PCA ignores the label information in the data. On the other hand, the reduced dimensional data through PCA still includes indiscriminate (i.e., irrelevant) features. To cope with the dimensionality problem of LDA, a hybrid dimension reduction approach of supervised and unsupervised algorithms is proposed in this study. In the supervised part of the proposed hybrid dimension reduction method, called DBDERF+PCA, we propose to combine an ensemble classifier (i.e., random forest) with dichotomous binary differential evolution (DBDE), a recently proposed variant of binary differential evolution, by introducing a robust wrapper feature selection. On the other hand, unsupervised part of the proposed hybrid dimension reduction method utilizes PCA. The experimental results show that DBDERF+PCA outperforms PCA in terms of dimension reduction. Thereupon, this hybrid dimension reduction based LDA, called DBDERF+PCA+LDA, performs better than PCA+LDA and LDA in terms of run-time and classification performances.},
  archive   = {C_CEC},
  author    = {Ezgi Zorarpacı},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504951},
  pages     = {1028-1036},
  title     = {A hybrid dimension reduction based linear discriminant analysis for classification of high-dimensional data},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fuzzy filtering in large-scale prediction of intrinsically
disordered regions of proteins on apache spark. <em>CEC</em>, 1020–1027.
(<a href="https://doi.org/10.1109/CEC45853.2021.9504834">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Intrinsically disordered proteins (IDPs) participate in many cellular processes. They are also studied for their participation in the course and formation of many diseases. Experimental determination of disordered regions (IDRs) is costly and not always possible. Due to the exponential growth of protein sequences, for which the 3D structure cannot be experimentally determined, computational prediction becomes an important alternative. Spark-IDPP is the large-scale meta-predictor for IDRs and IDPs designed to run on the Apache Spark cluster. The meta-prediction with Spark-IDPP includes fuzzy filtering of produced prediction output. Here, we experimentally validate various fuzzy filters and show that a properly designed characteristic function for fuzzy filtering may improve the prediction quality in all modes of the Spark-IDPP execution.},
  archive   = {C_CEC},
  author    = {Bożena Małysiak-Mrozek and Łukasz Bożek and Dariusz Mrozek},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504834},
  pages     = {1020-1027},
  title     = {Fuzzy filtering in large-scale prediction of intrinsically disordered regions of proteins on apache spark},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Three-dimensional robot motion design by combining
interactive and non-interactive evolutionary computation for an
intelligent transformable phone robot: BaBi. <em>CEC</em>, 1012–1019.
(<a href="https://doi.org/10.1109/CEC45853.2021.9504933">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper presents an interactive method for designing robot facial expressions and motions of an intelligent transformable phone robot BaBi. Designing an objective function to evaluate facial expressions and motions suitable for BaBi with an original structure is quite hard although users can easily imagine favorite motions. Therefore, the proposed method employs Interactive Evolutionary Computation (IEC) in addition to general optimization. The method allows users to add candidates to a case base when finding satisfying candidates and evaluates candidates&#39; scores according to the case base. It applies a Different Evolution (DE) method to generate new candidates. Users may alternately push the buttons to generate face and body motion without making any selection of candidates with a selection interface. The method will make selection with the scores when users do not make any selection of candidates. Users can select or not select. It is an IEC process when users make selections, while it is a non-Interactive Evolutionary Computation (non-IEC) process when users do not make any selection, resulting in being a fusion of IEC and non-IEC. Adding more candidates to the case base can speed up generating the desired motion and promote the non-IEC progress and reduce the burden on users. Experimental results have shown that the proposed method produces the robot motions effectively.},
  archive   = {C_CEC},
  author    = {Jiansheng Liu and Satoshi Ono and Bilan Zhu},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504933},
  pages     = {1012-1019},
  title     = {Three-dimensional robot motion design by combining interactive and non-interactive evolutionary computation for an intelligent transformable phone robot: BaBi},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Geometry assisted energy efficient sweep coverage algorithm
for wireless sensor networks. <em>CEC</em>, 1005–1011. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504736">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With the rapid development of wireless sensing technology and the popularity of the internet of things, applications based on wireless sensor networks have been applied universally in many scenarios. Sweep coverage is an emerging technique to improve the quality of service by promoting the energy efficiency of the sensors. To solve the distance-sensitive-route scheduling problem, which considering the route scheduling taking advantage of the sensing radius to reduces the cycle path of the mobile sensors and improves the feedback time of the network, this article proposes a three-stage geometry assisted energy-efficient sweep coverage algorithm to determine the route of mobile sensors with minimal energy consumption. With analysis of the distribution of the static monitoring targets, initial sensing points are determined. To minimize the sweep path in a single cycle, we use an ant colony optimization algorithm to schedule an energy-efficient routing. In addition, the sensing point of each target is updated by a local optimization mechanism according to the route information. To demonstrate the effectiveness of the proposed algorithm, we compare our proposed algorithm to a wealth of wireless sensor network scenarios. The simulation results show that our algorithm can significantly reduce the length of the cycle route, so as to enhance the energy efficiency of the wireless sensor networks.},
  archive   = {C_CEC},
  author    = {Fuyou Li and Bei Dong and Xiaojun Wu and HongShang Xu},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504736},
  pages     = {1005-1011},
  title     = {Geometry assisted energy efficient sweep coverage algorithm for wireless sensor networks},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A multi-objective evolutionary approach to professional
course timetabling: A real-world case study. <em>CEC</em>, 997–1004. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504797">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper describes the concept and implementation of a multi-objective approach for professional training scheduling problem at Mandarine Academy. We address the timetabling of courses and trainers rostering in a highly constrained environment, in which we are required to optimize 5 different objectives. We describe the problem by providing a mathematical formulation of both hard/soft constraints and objectives. We propose the use of Multi-Objective Evolutionary Algorithms (MOEA&#39;s) like NSGA II and NSGA III with custom genetic operators (Mutation and Crossover) designed specifically for this problem. To evaluate the effectiveness of our approach, a parameter tuning phase using the i-race package is performed, followed by a performance comparison using real-world test instances varying in complexity. Final results shows a significant improvement in terms of computation time and solutions diversity with an interesting performance gap between NSGA II and NSGA III.},
  archive   = {C_CEC},
  author    = {Mounir Hafsa and Pamela Wattebled and Julie Jacques and Laetitia Jourdan},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504797},
  pages     = {997-1004},
  title     = {A multi-objective evolutionary approach to professional course timetabling: A real-world case study},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Predicting disease outbreaks with climate data.
<em>CEC</em>, 989–996. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504740">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The incidence of most diseases varies greatly with seasons, and global climate change is expected to increase its risk. Predictive models that automatically capture trends between climate and diseases are likely to be beneficial in minimizing disease outbreaks. Machine learning (ML) predictive analytic tools have been popularized across many health-care applications, however the optimal task performance of such ML tools largely depends on manual parameter tuning and calibration. Such manual tuning significantly limits the full potential of ML methods, especially for high-dimensional and complex task domains, as typified by real-world health-care application data-sets. Additionally, the inaccessibility of many health-care data-sets compounds innate problems of method comparison, predictive accuracy and the overall advancement of ML based health-care applications. In this study we investigate the impact of Relevance Estimation and Value Calibration, an evolutionary parameter optimization method applied to automate parameter tuning for comparative ML methods (Deep learning and Support Vector Machines) applied to predict daily diarrhoea cases across various geographic regions. Data-augmentation is also used to complement real-world noisy, sparse and incomplete data-sets with synthetic data-sets for training, validation and testing. Results support the efficacy of evolutionary parameter optimization and data synthesis to boost predictive accuracy in the given task, indicating a significant prediction accuracy boost for the deep-learning models across all data-sets.},
  archive   = {C_CEC},
  author    = {Tassallah Abdullahi and Geoff Nitschke},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504740},
  pages     = {989-996},
  title     = {Predicting disease outbreaks with climate data},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A binary NSGA-II model for de-clustering seismicity of
turkey and chile. <em>CEC</em>, 981–988. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504964">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Seismicity de-clustering is the technique to isolate the earthquake catalog into aftershock-foreshock (clustered) and background (random) events. These isolated events are widely used in seismology for hazard assessment and to design the model for future earthquake predictions. The key challenge in seismic de-clustering is due to significant overlapping and high correlation between the space-time domain of aftershock-foreshock and background events. In this manuscript, a new model is proposed to de-cluster earthquake catalog based on a binary Non-dominated sorting genetic (B/NSGA)-II algorithm. In the fundamental version of the popular NSGA-II algorithm, one apprehension is that crossover and mutation are performed only on real-valued population. Here binary domain logical crossover and mutation operators are employed to optimally segregate the seismic events. The proposed model is tested on thirty year historical earthquake catalog of Turkey and Chile. Comparative analysis has been demonstrated with five benchmark de-clustering techniques. The simulation results demonstrate the potential of the proposed model efficiently discriminates the aftershocks and background events in the two catalogs.},
  archive   = {C_CEC},
  author    = {Ashish Sharma and Satyasai Jagannath Nanda and Rahul Kumar Vijay},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504964},
  pages     = {981-988},
  title     = {A binary NSGA-II model for de-clustering seismicity of turkey and chile},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). New evolutionary method for studying physical properties of
magneto caloric materials. <em>CEC</em>, 973–980. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504988">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Magnetic refrigeration (MR) is an alternative technology to conventional vapour compression with a high potential to reduce energy consumption and greenhouse gases. The working principle of MR is based on the property of magneto caloric materials (MCMs) to respond to applied external magnetic field by a variation in their temperature. To find the inexpensive MCMs with needed physical properties is still an issue. This paper describes a new method, whose objective is to automate the characterization process of MCM physical properties. This method is based on a multi-objective evolutionary optimization to define the combination of Hamiltonian model free parameters, which corresponds to needed physical properties of MCM. The advantage of this method is that it doesn&#39;t need first-principles calculations or huge databases. The description is followed by a thorough validation of the proposed method for two alloys. The obtained results are in good agreement with the experimental measurements.},
  archive   = {C_CEC},
  author    = {Anna Ouskova Leonteva and Radia Hamane and Michel Risser and Anne Jeannin-Girardon and Pierre Parrend and Pierre Collet},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504988},
  pages     = {973-980},
  title     = {New evolutionary method for studying physical properties of magneto caloric materials},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evolutionary neural architecture search by mutual
information analysis. <em>CEC</em>, 966–972. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504845">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Neural architecture search (NAS) is a promising approach to fully automated machine learning that applies to arbitrary tasks. However, existing NAS methods tend to make a complex network that requires much time to train and predict. Since machine learning applications are now often run on mobile devices with limited computational resources, there is a need to obtain small, efficient, yet effective network models. This paper proposes MIA-NAS (Mutual Information Analysis Neural Architecture Search), an evolutionary NAS algorithm that extends Neural Architecture Search by Hill Climbing (NASH) by Elsken et al.. The proposed method introduces a procedure that removes layers that are less contributing to making predictions. The amount of contribution from each layer is quantified by estimating mutual information they have with true labels. The experiments showed that MIA-NAS produces smaller networks with comparative performance to the ones made by NASH. Besides, removing layers based on mutual information resulted in better performance than randomly selecting layers to be removed.},
  archive   = {C_CEC},
  author    = {Shizuma Namekawa and Taro Tezuka},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504845},
  pages     = {966-972},
  title     = {Evolutionary neural architecture search by mutual information analysis},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evolutionary hyperparameter optimisation for sentence
classification. <em>CEC</em>, 958–965. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504719">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The performance that Deep Neural Networks can achieve on a specific task is impacted significantly by the hyperparameters selected. In order to compare the performance of various Deep Neural Network architectures on sentence classification, an optimised set of hyperparameters needs to be found for each architecture. In this work we use a simple Genetic Algorithm to optimise the hyperparameters of three different architectures and we evaluate their performance on a suite of sentence classification benchmarks. We found that a single Genetic Algorithm is capable of optimising a variety of different architectures and that the evolved configurations found can compete with those chosen by experts while using fewer overall trainable parameters. The three architectures tested are a recurrent neural network and two types of convolutional networks with a large difference in complexity. Of the three architectures, optimised for sentence classification, a simple Convolutional Neural Network was the overall best performer consistently achieving good performance while using very few trainable parameters.},
  archive   = {C_CEC},
  author    = {Brendan Rogers and Nasimul Noman and Stephan Chalup and Pablo Moscato},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504719},
  pages     = {958-965},
  title     = {Evolutionary hyperparameter optimisation for sentence classification},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey of advances in evolutionary neural architecture
search. <em>CEC</em>, 950–957. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504890">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep neural networks (DNNs) have been frequently and widely applied for intelligent systems such as object detection, natural language understanding and speech recognition. Given a specific problem, we always aim to construct the most suitable DNN to solve it, which requires choosing the most appropriate model architecture and seeking the best model parameters values. However, most existing works focus on model parameters learning under the assumption that the model architecture can be manually specified as per prior knowledge and/or trial-and-error experimentation. To overcome this problem, evolutionary algorithms (EAs) have been widely used to design model architectures automatically. Further, EAs have been used for neural network optimization for more than 30 years. Therefore, in this paper, we review the evolutionary neural architecture search (ENAS) from the view of the advanced techniques. We hope this work can provide a comprehensive understanding of EAs’ roles for the readers and focus themselves on ENAS.},
  archive   = {C_CEC},
  author    = {Xun Zhou and A. K. Qin and Yanan Sun and Kay Chen Tan},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504890},
  pages     = {950-957},
  title     = {A survey of advances in evolutionary neural architecture search},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Two-stage genetic algorithm for designing long short term
memory (LSTM) ensembles. <em>CEC</em>, 942–949. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504788">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Long Short Term Memory (LSTM) is a special kind of Recurrent Neural Networks popularly used in various applications. However, using a single LSTM is often not enough to attain reliable performance on complicated machine learning tasks. This is because LSTM is sensitive to the specifics of the training data. Ensemble learning is a promising approach to improve the performance of LSTMs on complicated tasks. However, it is difficult to design an ensemble of LSTMs. LSTMs that constitute the ensemble should be both accurate and diverse. This paper proposes a new two-phase evolutionary algorithm to design ensembles. The first phase is to evolve best performing LSTMs automatically. A connection weight inheritance approach is used in the first phase to improve the effectiveness and efficiency of the evolutionary process. The second phase is to design ensembles by choosing suitable LSTMs without fixing the ensemble size in advance. We use bagging to train the selected LSTMs to build the ensemble to achieve good diversity among the LSTMs. The proposed approach is evaluated on various classification tasks. The results show the effectiveness of the proposed approach and its significant improvement in performance over many state-of-the-art machine learning models. The results also show the efficiency of the proposed approach in comparison with the baseline algorithm.},
  archive   = {C_CEC},
  author    = {Ramya Anasseriyil Viswambaran and Gang Chen and Bing Xue and Mohammad Nekooei},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504788},
  pages     = {942-949},
  title     = {Two-stage genetic algorithm for designing long short term memory (LSTM) ensembles},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A flexible variable-length particle swarm optimization
approach to convolutional neural network architecture design.
<em>CEC</em>, 934–941. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504716">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The great success of convolutional neural networks (CNNs) in image classification benefits from the powerful feature learning abilities of their architectures. However, arbitrarily constructing these architectures is very costly in terms of manpower and computation resources. Recently, particle swarm optimization (PSO), as a promising evolutionary computation (EC) method, has been used to automatically search for the CNN architectures and achieved encouraging results on image classification, but these existing methods are not well-designed and/or do not have good search capabilities. In this paper, a flexible variable-length PSO algorithm is proposed for automated CNN architecture design for image classification tasks. Particularly, an improved encoding scheme is proposed to truly break the fixed-length representation constraint of PSO and encode the parameters in a more meaningful way. In addition, a novel velocity and position updating approach is developed to update variable-length particles. Experiments on four benchmark datasets are carried out to confirm the superiority of the proposed algorithm. It is shown that the proposed method leads to better results comparing to the state-of-the-art algorithms in terms of classification performance, parameter size and computational complexity.},
  archive   = {C_CEC},
  author    = {Junhao Huang and Bing Xue and Yanan Sun and Mengjie Zhang},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504716},
  pages     = {934-941},
  title     = {A flexible variable-length particle swarm optimization approach to convolutional neural network architecture design},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-objective evolutionary design of composite data-driven
models. <em>CEC</em>, 926–933. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504773">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, a multi-objective approach for the design of composite data-driven mathematical models is proposed. It allows automating the identification of graph-based heterogeneous pipelines that consist of different blocks: machine learning models, data preprocessing blocks, etc. The implemented approach is based on a parameter-free genetic algorithm (GA) for model design called GPComp@Free. It is developed to be part of automated machine learning solutions and to increase the efficiency of the modeling pipeline automation. A set of experiments was conducted to verify the correctness and efficiency of the proposed approach and substantiate the selected solutions. The experimental results confirm that a multi-objective approach to the model design allows us to achieve better diversity and quality of obtained models. The implemented approach is available as a part of the open-source AutoML framework FEDOT.},
  archive   = {C_CEC},
  author    = {Iana S. Polonskaia and Nikolay O. Nikitin and Ilia Revin and Pavel Vychuzhanin and Anna V. Kalyuzhnaya},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504773},
  pages     = {926-933},
  title     = {Multi-objective evolutionary design of composite data-driven models},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hyper-parameter optimization for deep learning by
surrogate-based model with weighted distance exploration. <em>CEC</em>,
917–925. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504777">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {To improve deep neural net hyper-parameter optimization we develop a deterministic surrogate optimization algorithm as an efficient alternative to Bayesian optimization. A deterministic Radial Basis Function (RBF) surrogate model is built to interpolate previously evaluated points, and this surrogate model is incrementally updated in each iteration. The stochastic algorithm CMA-ES is used to search the acquisition function based on the surrogate. The acquisition function at a point is based on a weighted average of the surrogate at x and the minimum distance from x to a previously evaluated point. We evaluate the proposed algorithm RBF-CMA on hyper-parameter optimization tasks for deep convolutional neural networks on datasets of CIFAR-10, SVHN, and CIFAR-100. We show that RBF-CMA achieves a promising performance especially when the search space dimension is high in comparison to other algorithms including GP-EI, GP-LCB, and SMBO.},
  archive   = {C_CEC},
  author    = {Zhenhua Li and Christine A. Shoemaker},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504777},
  pages     = {917-925},
  title     = {Hyper-parameter optimization for deep learning by surrogate-based model with weighted distance exploration},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A data-driven multi-objective evolutionary algorithm based
on combinatorial parallel infilling criterion. <em>CEC</em>, 909–916.
(<a href="https://doi.org/10.1109/CEC45853.2021.9504757">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Data-driven multi-objective evolutionary algorithm provides an effective way to solve multi-objective optimization problems with computationally expensive black-box functions. In this paper, a data-driven multi-objective evolutionary algorithm based on combinatorial parallel infilling (DDMOEA-CPI) is proposed. The DDMOEA-CPI uses the Kriging model in lieu of the real function, and combines the infilling criteria based on the multi-objective lower confidence bound (MLCB), as well as the maximum Kriging error of the Pareto front, in order to guide the population evolution to quickly obtain the accurate Pareto solutions. Within the criteria, the hyper volume improvement function is used to select new samples from the solutions of the MLCB. A set of benchmark tests in 20 dimensions are taken to validate and evaluate the performance of the DDMOEA-CPI. The results show that the proposed method behaves well in the convergence and diversity of Pareto solutions.},
  archive   = {C_CEC},
  author    = {Chunna Li and Lianbo Yang and Chunlin Gong},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504757},
  pages     = {909-916},
  title     = {A data-driven multi-objective evolutionary algorithm based on combinatorial parallel infilling criterion},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Surrogate-assisted reference vector adaptation to various
pareto front shapes for many-objective bayesian optimization.
<em>CEC</em>, 901–908. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504917">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose a surrogate-assisted reference vector adaptation (SRVA) method to solve expensive multi- and many-objective optimization problems with various Pareto front shapes. SRVA is coupled with a multi-objective Bayesian optimization (MBO) algorithm using reference vectors for scalarization of objective functions. The Kriging surrogate models for MBO is used to estimate the Pareto front shape and generate adaptive reference vectors uniformly distributed on the estimated Pareto front. We combine SRVA with expected improvement of penalty-based boundary intersection as an infill criterion for MBO. The proposed algorithm is compared with two other MBO algorithms by applying them to benchmark problems with various Pareto front shapes. Experimental results show that the proposed algorithm outperforms the other two in the problems whose objective functions are reasonably approximated by the Kriging models. SRVA improves diversity of non-dominated solutions for these problems with continuous, discontinuous, and degenerated Pareto fronts. Besides, the proposed algorithm obtains much better solutions from early stages of optimization especially in many-objective problems.},
  archive   = {C_CEC},
  author    = {Nobuo Namura},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504917},
  pages     = {901-908},
  title     = {Surrogate-assisted reference vector adaptation to various pareto front shapes for many-objective bayesian optimization},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A population prescreening strategy for kriging-assisted
evolutionary computation. <em>CEC</em>, 893–900. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504976">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Prescreening strategies have been widely used in surrogate-assisted evolutionary algorithms for screening out poor solutions. Existing prescreening strategies are designed for individual-level selection, i.e. they are used to select individuals from a set of population members. In this work, we propose a population prescreening strategy based on the multi-point expected improvement criterion for Kriging-assisted evolutionary algorithms. In each generation of the proposed algorithm, the evolutionary operators are used repeatedly to generate a set of candidate populations. Then, these candidate populations are prescreened by the multi-point expected improvement criterion and the population with highest multi-point expected improvement value is selected for the next generation. Following this, infill criteria are used to select promising solutions from the selected population for expensive evaluation. Numerical experiments on eighteen test problems show that the proposed population prescreening strategy can improve the optimization efficiency of the Kriging-assisted evolutionary algorithms significantly without introducing too much additional computational cost.},
  archive   = {C_CEC},
  author    = {Dawei Zhan and Huanlai Xing},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504976},
  pages     = {893-900},
  title     = {A population prescreening strategy for kriging-assisted evolutionary computation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Using double well function as a benchmark function for
optimization algorithm. <em>CEC</em>, 886–892. (<a
href="https://doi.org/10.1109/CEC45853.2021.9505009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The double well function (DWF) is an important theoretical model originating from quantum physics and has been used to describe the energy constraint problem in quantum mechanics and structural chemistry. Although its form may vary, the DWF has two different local minima in the one-dimensional case, and the number of local minima increases as its dimension grows. As a multi-stable function, the DWF is assumed to be a potential candidate for testing the performance of the heuristic optimization algorithm, which aims to seek the global minimum. To verify this idea, a typical DWF is employed in this paper, and a mathematical analysis is presented herein, and its properties as a benchmark function are discussed in different cases. In addition, we conducted a set of experiments utilizing a few optimization algorithms, such as the multi-scale quantum harmonic oscillator algorithm and covariance matrix adaptation evolution strategy; thus the analysis has been illustrated by the results of the numerical experiment. Moreover, to guide the design of an ideal DWF used as a benchmark function in experiment, different values of the decisive parameters were tested corresponding to our analysis, and some useful rules were given based on the discussion of the results.},
  archive   = {C_CEC},
  author    = {Peng Wang and Guosong Yang},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9505009},
  pages     = {886-892},
  title     = {Using double well function as a benchmark function for optimization algorithm},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Blending dynamic programming with monte carlo simulation for
bounding the running time of evolutionary algorithms. <em>CEC</em>,
878–885. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504775">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With the goal to provide absolute lower bounds for the best possible running times that can be achieved by (1 + λ)-type search heuristics on common benchmark problems, we recently suggested a dynamic programming approach that computes optimal expected running times and the regret values inferred when deviating from the optimal parameter choice.Our previous work is restricted to problems for which transition probabilities between different states can be expressed by relatively simple mathematical expressions. With the goal to cover broader sets of problems, we suggest in this work an extension of the dynamic programming approach to settings in which it may be difficult or impossible to compute the transition probabilities exactly, but it is possible to approximate them numerically, up to arbitrary precision, by Monte Carlo sampling.We apply our hybrid Monte Carlo dynamic programming approach to a concatenated jump function and demonstrate how the obtained bounds can be used to gain a deeper understanding into parameter control schemes.},
  archive   = {C_CEC},
  author    = {Kirill Antonov and Maxim Buzdalov and Arina Buzdalova and Carola Doerr},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504775},
  pages     = {878-885},
  title     = {Blending dynamic programming with monte carlo simulation for bounding the running time of evolutionary algorithms},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Benchmark set reduction for cheap empirical algorithmic
studies. <em>CEC</em>, 871–877. (<a
href="https://doi.org/10.1109/CEC45853.2021.9505012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The present paper introduces a benchmark set reduction strategy that can degrade the experimental evaluation cost for the algorithmic studies. Algorithm design is an iterative development process within in a test-revise loop. Starting a devised algorithm&#39;s initial version, it needs to be tested for revealing its advantages and drawbacks. Its shortcomings lead the designers to modify the algorithm. Then, the modified algorithm is again tested. This two-step pipeline is repeated until the algorithm meets the expectations such as delivering the state-of-the-art results on a set of benchmarks for a specific problem. That recurring testing step can be a burden for whom with limited computational resources. The mentioned computational cost can mainly occur due either high per instance runtime cost or having a large benchmark set. This study focuses on the cases when a target algorithm needs to be assessed across large benchmark sets. The idea is to automatically extract problem instance representation through an instance-algorithm performance data. The derived representation in the form of latent features is utilized to determine a small yet a representative subset of a given large instance set. The proposed strategy is investigated on the Traveling Thief Problem of 9720 instances. The corresponding performance data is collected by the help of 21 TTP algorithms. The resulting computational analysis showed that the proposed method is capable of substantially minimizing the benchmark instance set size.},
  archive   = {C_CEC},
  author    = {Mustafa Mısır},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9505012},
  pages     = {871-877},
  title     = {Benchmark set reduction for cheap empirical algorithmic studies},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Comparison with state-of-the-art: Traps and pitfalls.
<em>CEC</em>, 863–870. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504747">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {When a new metaheuristic is proposed, its results are compared with the results of the state-of-the-art methods. The results of that comparison are the outcome of algorithms’ implementations, but the origin, names, and versions of the implementations are usually not revealed. Instead, only papers that introduced state-of-the-art are cited. That approach is generally wrong because algorithms are usually described in articles in a way that explains the idea that is hidden behind them but omits the technical details. Therefore, developers have to fill in these details, and they might do so in different ways. The paper shows that even implementations made by one author who is the creator of an algorithm give results which differ considerably from one another. Therefore, for the comparison purpose, the best possible implementation should be identified and used. To illustrate how details that are hidden in the code of implementations influence the quality of the results, sources of quality differences are tracked down for selected implementations. It was found that sources of the differences are hidden in auxiliary code and also stem from implementing a different version of the algorithm which undergoes development. These findings imply best practice recommendations for researchers, implementation developers, and authors of the algorithms.},
  archive   = {C_CEC},
  author    = {Rafał Biedrzycki},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504747},
  pages     = {863-870},
  title     = {Comparison with state-of-the-art: Traps and pitfalls},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Novel zigzag-based benchmark functions for bound constrained
single objective optimization. <em>CEC</em>, 857–862. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504720">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The development and comparison of new optimization methods in general, and evolutionary algorithms in particular, rely heavily on benchmarking. In this paper, the construction of novel zigzag-based benchmark functions for bound constrained single objective optimization is presented. The new benchmark functions are non-differentiable, highly multimodal, and have a built-in parameter that controls the complexity of the function. To investigate the properties of the new benchmark functions two of the best algorithms from the CEC&#39;20 Competition on Single Objective Bound Constrained Optimization, as well as one standard evolutionary algorithm, were utilized in a computational study. The results of the study suggest that the new benchmark functions are very well suited for algorithmic comparison.},
  archive   = {C_CEC},
  author    = {Jakub Kudela},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504720},
  pages     = {857-862},
  title     = {Novel zigzag-based benchmark functions for bound constrained single objective optimization},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Differential evolution with distance-based
mutation-selection applied to CEC 2021 single objective numerical
optimisation. <em>CEC</em>, 849–856. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504795">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A Differential Evolution (DE) algorithm with distance-based mutation-selection, population size reduction, and an optional external archive (DEDMNA) is proposed and tested on the CEC 2021 benchmark suite. The three well-known mutation variants are chosen in combination with one crossover for this model. The distances of three newly generated positions are computed to select the most proper position to evaluate. In the proposed algorithm, an efficient linear population-size reduction mechanism is applied. Moreover, an archive is employed to store older effective solutions. The provided results show that the proposed variant of DEDMNA is able to solve 64 out of 160 optimisation problems. Moreover, DEDMNA outperforms the efficient adaptive j2020 variant in 102 problems, and it is worse only in 15 problems out of 160. From the comparison of DEDMNA with five state-of-the-art DE algorithms, the superiority of DEDMNA is obvious.},
  archive   = {C_CEC},
  author    = {Petr Bujok and Patrik Kolenovsky},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504795},
  pages     = {849-856},
  title     = {Differential evolution with distance-based mutation-selection applied to CEC 2021 single objective numerical optimisation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Gaining-sharing knowledge based algorithm with adaptive
parameters hybrid with IMODE algorithm for solving CEC 2021 benchmark
problems. <em>CEC</em>, 841–848. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504814">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The initiative to introduce new benchmark problems has drawn attention to the development of new optimization algorithms. Recently, a set of constrained benchmark problems has been developed as a addition to CEC benchmark series. This paper proposed a hybrid variant of gaining sharing knowledge based algorithm with adaptive parameters and improved multi-operator differential evolution (IMODE) algorithm, called APGSK-IMODE. It enhanced the performance of recently developed adaptive gaining sharing knowledge based algorithm. The performance of APGSK-IMODE has been tested on CEC2021 benchmark problems which contains 10 test functions with dimensions 10 and 20. The results obtained from the proposed algorithm have been compared with those obtained from the rival algorithms. The results elaborate the superiority of APGSK-IMODE. APGSK-IMODE outperforms the competing algorithms with regard to quality of solution, robustness and convergence.},
  archive   = {C_CEC},
  author    = {Ali Wagdy Mohamed and Anas A. Hadi and Prachi Agrawal and Karam M. Sallam and Ali Khater Mohamed},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504814},
  pages     = {841-848},
  title     = {Gaining-sharing knowledge based algorithm with adaptive parameters hybrid with IMODE algorithm for solving CEC 2021 benchmark problems},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving differential evolution through bayesian
hyperparameter optimization. <em>CEC</em>, 832–840. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504792">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose a novel Evolutionary Algorithm (EA) based on the Differential Evolution algorithm for solving global numerical optimization problem in real-valued continuous parameter space. The proposed MadDE algorithm leverages the power of the multiple adaptation strategy with respect to the control parameters and search mechanisms, and is tested on the benchmark functions taken from the CEC 2021 special session &amp; competition on single-objective bound-constrained optimization. Experimental results indicate that MadDE is able to achieve superior performance on global numerical optimization problems when compared against state-of-the-art real-parameter optimizers. We also provide a hyperparameter optimization algorithm SUBHO for improving the search performance of any EA by finding an optimal set of control parameters, and demonstrate its efficacy in enhancing MadDE&#39;s performance on the same benchmark. The source code of our implementation is publicly available at https://github.com/subhodipbiswas/MadDE.},
  archive   = {C_CEC},
  author    = {Subhodip Biswas and Debanjan Saha and Shuvodeep De and Adam D Cobb and Swagatam Das and Brian A Jalaian},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504792},
  pages     = {832-840},
  title     = {Improving differential evolution through bayesian hyperparameter optimization},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new step-size adaptation rule for CMA-ES based on the
population midpoint fitness. <em>CEC</em>, 825–831. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504829">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we present the CMA-ES algorithm with a step-size adaptation rule which is inspired by the 1/5-th success rule. The method, called PPMF (Previous Population Midpoint Fitness), adjusts the step-size multiplier σ using the comparison of fitness values of the current population of points and the midpoint of the previous population. In the paper we compare the performance of CMA-ES coupled with PPMF and with two other step-size adaptation rules: Cumulative Step-size Adaptation (CSA) and Median Success Rule (MSR). For the comparison we apply a version of the IPOP-CMA-ES strategy and we test its performance using three benchmark suites: CEC 2013, CEC 2017 and CEC 2021. The results evidence that the efficiency of PPMF is comparable with CSA and superior to MSR.},
  archive   = {C_CEC},
  author    = {Eryk Warchulski and Jarosław Arabas},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504829},
  pages     = {825-831},
  title     = {A new step-size adaptation rule for CMA-ES based on the population midpoint fitness},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Self-adaptive differential evolution algorithm with
population size reduction for single objective bound-constrained
optimization: Algorithm j21. <em>CEC</em>, 817–824. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504782">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we propose a new algorithm for solving real parameter single-objective optimization problems that were prepared for the CEC 2021 Special Session and Competition on Single Objective Bound Constrained Numerical Optimization. Single-objective optimization problems are often very complex and computationally expensive. The presented algorithm, called j21, uses several mechanisms: two populations, vectors are chosen from both sub-populations in the mutation operation, crowding in the big population, population size reduction, etc. We show the experimental results for each benchmark function for two scenarios of different dimensions and eight configuration scenarios as required by the organizers of the CEC 2021 Special Session. We also compare the obtained results of j21 in a scenario with larger dimension and on one selected configuration with the original DE and j2020 algorithms.},
  archive   = {C_CEC},
  author    = {Janez Brest and Mirjam Sepesy Maučec and Borko Bošković},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504782},
  pages     = {817-824},
  title     = {Self-adaptive differential evolution algorithm with population size reduction for single objective bound-constrained optimization: Algorithm j21},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). NL-SHADE-RSP algorithm with adaptive archive and selective
pressure for CEC 2021 numerical optimization. <em>CEC</em>, 809–816. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504959">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper proposes a variant of the adaptive differential evolution algorithm, which combines several important concepts, including non-linear population size reduction, rank-based selective pressure in the mutation strategy, adaptive archive set usage, as well as a set of rules to control crossover rate. The developed approach is applied to solve the CEC 2021 Bound Constrained Single Objective Optimization Parametrized Benchmark problems. The performed computational experiments and their statistical analysis show that the proposed NL-SHADE-RSP algorithm is capable of demonstrating high efficiency of fining solutions to biased, shifted and rotated functions compared to other state-of-the-art algorithms, including the winners of the previous competitions.},
  archive   = {C_CEC},
  author    = {Vladimir Stanovov and Shakhnaz Akhmedova and Eugene Semenkin},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504959},
  pages     = {809-816},
  title     = {NL-SHADE-RSP algorithm with adaptive archive and selective pressure for CEC 2021 numerical optimization},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Feature selection for polygenic risk scores using genetic
algorithm and network science. <em>CEC</em>, 802–808. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504993">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Many human diseases can be attributed to genetic variations in the genome. Scientists have been identifying genetic variants associated with disease risks using population-based data. With this knowledge, an individual’s genetic liability to a disease can be estimated using the polygenic risk score (PRS), calculated based on their genotype profile. However, selecting the most predictive genetic variants is challenged by the high dimensionality of genomics data. Typically, hundreds of thousands of genetic variants are being tested on their association with a disease risk. Moreover, the effect of a genetic variant on a disease risk is often influenced by other variants. It is their interactions that contribute to a disease risk. In this research, we propose a feature selection method for PRS assessment that is able to search for combinations of genetic variants using a genetic algorithm and network science. Our method provides accurate predictive models for PRS computation, as well as useful insights into the intertwined relationships among a large number of genetic variants.},
  archive   = {C_CEC},
  author    = {Zhendong Sha and Ting Hu and Yuanzhu Chen},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504993},
  pages     = {802-808},
  title     = {Feature selection for polygenic risk scores using genetic algorithm and network science},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Binary differential evolution based feature selection method
with mutual information for imbalanced classification problems.
<em>CEC</em>, 794–801. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504882">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The feature selection process aims to eliminate redundant attributes in the data set, thus it leads to improved classification accuracy. The solution to a feature selection problem is challenging due to the ever-increasing data volume. This problem gets more complicated in the case of imbalanced data sets. Most of the traditional feature selection methods weigh on the majority class when selecting the informative feature subset, thus the selected features often get a bias towards the majority class and neglect the significance of the minority class in the whole process, which results in poor classification performance in the case of minority class objects. Multiple evolutionary algorithms based feature selection methods have been introduced in the past but most of them ignore the class imbalance problem while selecting the most informative feature subset. In this article, we propose a binary differential evolution algorithm with Manhattan distance-based mutation, which employs a joint mutual information maximization based feature selection criteria along with a novel class distribution-based weight assignment scheme to tackle the class imbalance problem. In the experimental studies, we have tested the performance of the proposed method on well-known data sets using three widely-used performance metrics (Average Classification Accuracy, F-measure, G-Means). According to the empirical results, the proposed method performs better than its contenders in most of the data sets.},
  archive   = {C_CEC},
  author    = {Arka Ghosh and Bing Xue and Mengjie Zhang},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504882},
  pages     = {794-801},
  title     = {Binary differential evolution based feature selection method with mutual information for imbalanced classification problems},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A forward search inspired particle swarm optimization
algorithm for feature selection in classification. <em>CEC</em>,
786–793. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504949">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Particle swarm optimization (PSO) has been widely used for feature selection (FS) in classification. However, FS is still a challenging optimization task for PSO when the dimensionality of data is high. In this paper, we propose a forward search inspired PSO (FSIPSO) algorithm to build a wrapper-based FS method. In FSIPSO, the search space dynamically changes during the evolutionary process. Specifically, we rank the features according to their single-feature classification performance and divide the search space into several sub-spaces. A forward search scheme is proposed to sequentially select the sub-spaces. The selected sub-spaces construct the search space for FSIPSO. With this scheme, FSIPSO first searches in a small space to quickly find candidate solutions (feature subsets) with relatively good performance. Then, the search space expands with the selection of more sub-spaces, and FSIPSO can further select informative features in the expanded search space. Moreover, mutation operations are used in FSIPSO to avoid the premature problem. The experimental results on 8 UCI datasets have shown that FSIPSO obtains better FS results with less computation time compared with benchmark PSO-based FS methods. FSIPSO also obtains better convergence performance than these methods.},
  archive   = {C_CEC},
  author    = {An-Da Li and Bing Xue and Mengjie Zhang},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504949},
  pages     = {786-793},
  title     = {A forward search inspired particle swarm optimization algorithm for feature selection in classification},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Surrogate-assisted genetic algorithm for wrapper feature
selection. <em>CEC</em>, 776–785. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504718">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Feature selection is an intractable problem, therefore practical algorithms often trade off the solution accuracy against the computation time. In this paper, we propose a novel multi-stage feature selection framework utilizing multiple levels of approximations, or surrogates. Such a framework allows for using wrapper approaches in a much more computationally efficient way, significantly increasing the quality of feature selection solutions achievable, especially on large datasets. We design and evaluate a Surrogate-Assisted Genetic Algorithm (SAGA) which utilizes this concept to guide the evolutionary search during the early phase of exploration. SAGA only switches to evaluating the original function at the final exploitation phase.We prove that the run-time upper bound of SAGA surrogate-assisted stage is at worse equal to the wrapper GA, and it scales better for induction algorithms of high order of complexity in number of instances. We demonstrate, using 14 datasets from the UCI ML repository, that in practice SAGA significantly reduces the computation time compared to a baseline wrapper Genetic Algorithm (GA), while converging to solutions of significantly higher accuracy. Our experiments show that SAGA can arrive at near-optimal solutions three times faster than a wrapper GA, on average. We also showcase the importance of evolution control approach designed to prevent surrogates from misleading the evolutionary search towards false optima.},
  archive   = {C_CEC},
  author    = {Mohammed Ghaith Altarabichi and Sławomir Nowaczyk and Sepideh Pashami and Peyman Sheikholharam Mashhadi},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504718},
  pages     = {776-785},
  title     = {Surrogate-assisted genetic algorithm for wrapper feature selection},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An entropy driven multiobjective particle swarm optimization
algorithm for feature selection. <em>CEC</em>, 768–775. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504837">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Feature selection is an important research field in machine learning since high-dimensionality is a common characteristic of real-world data. It has two main objectives, which are to maximize the classification accuracy while minimizing the number of selected features. As the two objectives are usually in conflict with each other, it makes feature selection a multi-objective problem. However, the large search space and discrete Pareto front makes it not easy for existing evolutionary multi-objective algorithms. In order to deal with the above mentioned difficulties in feature selection, an entropy driven multiobjective particle swarm optimization algorithm is proposed to remove redundant feature and decrease computational complexity. First, its basic idea is to model feature selection as a multiobjective optimization problem by optimizing the number of features and the classification accuracy in supervised condition simultaneously. Second, a particle initialization strategy based on information entropy is designed to improve the quality of initial solutions, and an adaptive velocity update rule is used to swap between local search and global search. Besides, a specified discrete nondominated sorting is designed. These strategies enable the proposed algorithm to gain better performance on both the quality and size of feature subset. The experimental results show that the proposed algorithm can maintain or improve the quality of Pareto fronts evolved by the state-of-the-art algorithms for feature selection.},
  archive   = {C_CEC},
  author    = {Juanjuan Luo and Dongqing Zhou and Lingling Jiang and Huadong Ma},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504837},
  pages     = {768-775},
  title     = {An entropy driven multiobjective particle swarm optimization algorithm for feature selection},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-objective multi-label feature selection with an
aggregated performance metric and dominance-based initialisation.
<em>CEC</em>, 760–767. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504960">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Feature selection (FS) is an essential pre-processing step that selects small and informative feature subsets. However, most FS methods focus on single-label classification, where each instance has one class label. Multi-label classification (MLC) is increasingly more common as instances possess a set of class labels. It is more challenging to perform FS for MLC since it needs to consider the interactions between labels. Furthermore, since the target output is a set of labels, there are various metrics for evaluating MLC performance, and each metric assesses the quality of a feature subset on various aspects. However, certain MLC metrics are shown to possess conflicting behaviour. To evolve high-quality feature subsets, it is essential to consider the trade-offs between metrics, making FS for MLC even more challenging. Evolutionary multi-objective optimisation (EMO) is a great technique to optimise multiple (potentially) conflicting metrics, representing different objectives. However, given a large number of objectives, EMO algorithms usually do not evolve a diverse set of good feature subsets, especially when there is a limited computational resource. This paper proposes a novel approach to reducing the number of objectives, which is expected to maintain or improve the evolved feature subsets over the original objectives. We also propose a new decomposition mechanism based on multiple reference points and a novel initialization mechanism to enhance the quality of the evolved feature subsets. The experimental results show that the proposed algorithm can evolve diverse feature subsets with better trade-off between multiple performance metrics than recent FS algorithms for MLC.},
  archive   = {C_CEC},
  author    = {Kaan Demir and Bach Hoai Nguyen and Bing Xue and Mengjie Zhang},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504960},
  pages     = {760-767},
  title     = {Multi-objective multi-label feature selection with an aggregated performance metric and dominance-based initialisation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Particle swarm optimization for feature selection in emotion
categorization. <em>CEC</em>, 752–759. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504986">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Emotion categorization plays an important role in understanding human emotions by artificial intelligence systems such as robots. It is a difficult task as humans express many features, which vary over time when showing an emotion. Thus, existing classification techniques are overwhelmed, and the creation of a subset of appropriate features is needed. Feature selection can be used to improve the performance of an emotion categorization task by selecting a subset of features. This removes irrelevant features. Particle swarm optimization (PSO) is a meta-heuristic algorithm which has demonstrated excellent performance in feature selection tasks. However, traditional PSO algorithms often get trapped in local optima as they use their personal best and global best to determine their search direction, which may lead to premature convergence. In this paper, we present a time-based PSO variant by introducing a time-constant into the velocity update function of the PSO algorithm to avoid premature convergence, particularly in an emotion video-frame dataset. The method has been incorporated into binary and continuous PSO, then compared with the two standard versions on an emotion video-frame (CK+) dataset, as well as on static emotional datasets (i.e. the JAFFE and NIMH-ChEFS) to ensure that bias has not been introduced into the algorithm. While the time-based PSO variant (both binary and the continuous PSO) have achieved non-significantly higher performance than the standard PSO algorithms on the JAFFE (77.15\% vs 75.61\%) and NIMH-ChEFS (71.57\% vs 70.53\%) dataset, the performance is significantly higher on the CK+ (96.19\% vs 94.06\%) dataset.},
  archive   = {C_CEC},
  author    = {Harisu Abdullahi Shehu and Will Browne and Hedwig Eisenbarth},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504986},
  pages     = {752-759},
  title     = {Particle swarm optimization for feature selection in emotion categorization},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Weighted ensemble of deep learning models based on
comprehensive learning particle swarm optimization for medical image
segmentation. <em>CEC</em>, 744–751. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504929">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In recent years, deep learning has rapidly become a method of choice for segmentation of medical images. Deep neural architectures such as UNet and FPN have achieved high performances on many medical datasets. However, medical image analysis algorithms are required to be reliable, robust, and accurate for clinical applications which can be difficult to achieve for some single deep learning methods. In this study, we introduce an ensemble of classifiers for semantic segmentation of medical images. The ensemble of classifiers here is a set of various deep learning-based classifiers, aiming to achieve better performance than using a single classifier. We propose a weighted ensemble method in which the weighted sum of segmentation outputs by classifiers is used to choose the final segmentation decision. We use a swarm intelligence algorithm namely Comprehensive Learning Particle Swarm Optimization to optimize the combining weights. Dice coefficient, a popular performance metric for image segmentation, is used as the fitness criteria. Experiments conducted on some medical datasets of the CAMUS competition on cardiographic image segmentation show that our method achieves better results than both the constituent segmentation models and the reported model of the CAMUS competition.},
  archive   = {C_CEC},
  author    = {Truong Dang and Tien Thanh Nguyen and Carlos Francisco Moreno-García and Eyad Elyan and John McCall},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504929},
  pages     = {744-751},
  title     = {Weighted ensemble of deep learning models based on comprehensive learning particle swarm optimization for medical image segmentation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Probabilistic fitting of glucose models with real-coded
genetic algorithms. <em>CEC</em>, 736–743. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504836">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Type 1 Diabetes patients have to control their blood glucose levels using insulin therapy. Numerous factors (such as carbohydrate intake, physical activity, time of day, etc.) greatly complicate this task. In this article we propose a modeling method that will allow us to make predictions of blood glucose level evolution with a time horizon of 24 hours. This may allow the adjustment of insulin doses in advance and could help to improve the living conditions of diabetes patients. Our approach starts from a system of finite difference equations that characterizes the interaction between insulin and glucose (in the field, this is known as a minimal model). This model has several parameters whose values vary widely depending on patient characteristics and time. Thus, in the first phase of our strategy, We will enrich the patient&#39;s historical data by adding white Gaussian noise, which will allow us to perform a probabilistic fitting with a 95\% confidence interval. Then, the model&#39;s parameters are adjusted based on the history of each patient using a genetic algorithm and dividing the day into 12 time intervals. In the final stage, we will perform a whole-day forecast from an ensemble of the models fitted in the previous phase. The validity of our strategy will be tested using the Parkers&#39; error grid analysis. Our experimental results based on data from real diabetic patients show that this technique is capable of robust predictions that take into account all the uncertainty associated with the interaction between insulin and glucose.},
  archive   = {C_CEC},
  author    = {Carlos Cervigón and J. Manuel Velasco and Clara Burgos-Simón and Rafael J. Villanueva and J. Ignacio Hidalgo},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504836},
  pages     = {736-743},
  title     = {Probabilistic fitting of glucose models with real-coded genetic algorithms},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimization and adaptation of a resource planning tool for
hospitals under special consideration of the COVID-19 pandemic.
<em>CEC</em>, 728–735. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504732">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Hospitals and health-care institutions need to plan the resources required for handling the increased load, i.e., beds and ventilators during the COVID-19 pandemic. BaB-Sim.Hospital, an open-source tool for capacity planning based on discrete event simulation, was developed over the last year to support doctors, administrations, health authorities, and crisis teams in Germany. To obtain reliable results, 29 simulation parameters such as durations and probabilities must be specified. While reasonable default values were obtained in detailed discussions with medical professionals, the parameters have to be regularly and automatically optimized based on current data.We investigate how a set of parameters that is tailored to the German health system can be transferred to other regions. Therefore, we use data from the UK. Our study demonstrates the flexibility of the discrete event simulation approach. However, transferring the optimal German parameter settings to the UK situation does not work-parameter ranges must be modified. The adaptation has been shown to reduce simulation error by nearly 70\%. The simulation-via-optimization approach is not restricted to health-care institutions, it is applicable to many other real-world problems, e.g., the development of new elevator systems to cover the last mile or simulation of student flow in academic study periods.},
  archive   = {C_CEC},
  author    = {Thomas Bartz-Beielstein and Marcel Dröscher and Alpar Gür and Alexander Hinterleitner and Tom Lawton and Olaf Mersmann and Dessislava Peeva and Lennard Reese and Nicolas Rehbach and Frederik Rehbach and Amrita Sen and Aleksandr Subbotin and Martin Zaefferer},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504732},
  pages     = {728-735},
  title     = {Optimization and adaptation of a resource planning tool for hospitals under special consideration of the COVID-19 pandemic},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal control policies to address the pandemic
health-economy dilemma. <em>CEC</em>, 720–727. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504758">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Non-pharmaceutical interventions (NPIs) are effective measures to contain a pandemic. Yet, such control measures commonly have a negative effect on the economy. Here, we propose a macro-level approach to support resolving this Health-Economy Dilemma (HED). First, an extension to the well-known SEIR model is suggested which includes an economy model. Second, a bi-objective optimization problem is defined to study optimal control policies in view of the HED problem. Third, four multi-objective evolutionary algorithms are applied to perform a study on the health-economy performance trade-offs that are inherent to the obtained optimal policies. Finally, the results from the applied algorithms are compared to select a preferred algorithm for future studies. As expected, for the proposed models and strategies, a clear conflict between the health and economy performances is found. Furthermore, the results suggest that the guided usage of NPIs is preferable as compared to refraining from employing such strategies at all. This study contributes to pandemic modeling and simulation by providing a novel concept that elaborates on integrating economic aspects while exploring the optimal moment to enable NPIs.},
  archive   = {C_CEC},
  author    = {Rohit Salgotra and Amiram Moshaiov and Thomas Seidelmann and Dominik Fischer and Sanaz Mostaghim},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504758},
  pages     = {720-727},
  title     = {Optimal control policies to address the pandemic health-economy dilemma},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Blood glucose prediction using a two phase TSK fuzzy rule
based system. <em>CEC</em>, 712–719. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504992">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Blood glucose management is a difficult task that people with diabetes usually have to perform by themselves. An accurate and timely prediction is vital in order to take decisions and recommend corrective actions to the patient when the future blood glucose value lies outside of a target range. It is crucial to predict events like hyperglycemia and hypoglycemia that may cause health damages in the short term and potential permanent damages in the long term. The aim of this paper is to describe our research on predicting blood glucose values using a two phase Takagi-Sugeno-Kang Fuzzy Rule Based System. The first phase is a learning process where membership functions and rules are optimised by a genetic algorithm. In the second phase of tuning, we used a genetic algorithm to perform the selection and optimisation of the rules. To train our model we used two different scenarios, What-if and Agnostic; in both of them the inputs are values measured by a continuous monitoring glucose system as well as previous carbohydrate intake and insulin injections. In the What-if scenario, assumed future values of meals and insulin injections are permitted. On the other hand, in the Agnostic scenario, only information of the past and present events are available for the prediction. We trained and tested our system with real data collected from 10 different diabetic patients, producing 30, 60, 90 and 120 minutes predictions with encouraging accuracy results.},
  archive   = {C_CEC},
  author    = {J. Alvarado and J. Manuel Velasco and F. Chávez and J. Ignacio Hidalgo and F. Fernández de Vega},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504992},
  pages     = {712-719},
  title     = {Blood glucose prediction using a two phase TSK fuzzy rule based system},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Using genetic programming to find functional mappings for
UMAP embeddings. <em>CEC</em>, 704–711. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504848">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Manifold learning is a widely used technique for reducing the dimensionality of complex data to make it more understandable and more efficient to work with. However, current state-of-the-art manifold learning techniques — such as Uniform Manifold Approximation and Projection (UMAP) — have a critical limitation. They do not provide a functional mapping from the higher dimensional space to the lower-dimensional space, instead, they produce only the lower-dimensional embedding. This means they are &quot;black-boxes&quot; that cannot be used in domains where explainability is paramount. Recently, there has been work on using genetic programming to perform manifold learning with functional mappings (represented by tree/s), however, these methods are limited in their performance compared to UMAP. To address this, in this work we propose utilising UMAP to create functional mappings with genetic programming-based manifold learning. We compare two different approaches: one that uses the embedding produced by UMAP as the target for the functional mapping; and the other which directly optimises the UMAP cost function by using it as the fitness function. Experimental results reinforce the value of producing a functional mapping and show promising performance compared to UMAP. Additionally, we visualise two-dimensional embeddings produced by our technique compared to UMAP to further analyse the behaviour of each of the algorithms.},
  archive   = {C_CEC},
  author    = {Finn Schofield and Andrew Lensen},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504848},
  pages     = {704-711},
  title     = {Using genetic programming to find functional mappings for UMAP embeddings},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hybrid multiobjective evolutionary algorithms for
unsupervised QPSO, BBPSO and fuzzy clustering. <em>CEC</em>, 696–703.
(<a href="https://doi.org/10.1109/CEC45853.2021.9504968">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {While there has been many new developments in multiobjective evolutionary algorithms, they have not been applied or investigated in clustering problems. In this paper, ten different unsupervised clustering techniques applying different MOEA (SPEA2, IBEA, MOEA/D and MOEA/GLU), PSO (QPSO and BBPSO) and Fuzzy approaches are experimented on ten public datasets. The rationale to apply MOEA is to increase the exploitation capabilities of clustering techniques to further refine the cluster solutions found by fuzzy or PSO clustering. The aim is to investigate in the performance of different types of MOEA applications in clustering, determining whether MOEA Fuzzy clustering outperform MOEA PSO variants. Overall, MOEA/D BBPSO was found to produced the best results. It outperformed MOEA Fuzzy techniques, having tested on datasets with high number of classes, that are imbalanced and/or overlapping classes. IBEA Fuzzy clustering was found to produce the worst results. MOEA/D clustering was found to perform better than other MOEA techniques. In this work, we showed that MOEA/D BBPSO clustering produced the best results on challenging datasets. It was able to use MOEA/D to deepen its exploitation capability while benefiting from the exploratory ability of BBPSO when clustering challenging datasets.},
  archive   = {C_CEC},
  author    = {Daphne Teck Ching Lai and Yuji Sato},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504968},
  pages     = {696-703},
  title     = {Hybrid multiobjective evolutionary algorithms for unsupervised QPSO, BBPSO and fuzzy clustering},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Genetic programming for evolving similarity functions
tailored to clustering algorithms. <em>CEC</em>, 688–695. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504855">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Clustering is the process of grouping related instances of unlabelled data into distinct subsets called clusters. While there are many different clustering methods available, almost all of them use simple distance-based (dis)similarity functions such as Euclidean Distance. However, these and most other predefined dissimilarity functions can be rather inflexible by considering each feature equally and not properly capturing feature interactions in the data. Genetic Programming is an evolutionary computation approach that evolves programs in an iterative process that naturally lends itself to the evolution of functions. This paper introduces a novel framework to automatically evolve dissimilarity measures for a provided clustering dataset and algorithm. The results show that the evolved functions create clusters exhibiting high measures of cluster quality.},
  archive   = {C_CEC},
  author    = {Hayden Andersen and Andrew Lensen and Bing Xue},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504855},
  pages     = {688-695},
  title     = {Genetic programming for evolving similarity functions tailored to clustering algorithms},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Polar bear optimization for industrial computed tomography
with incomplete data. <em>CEC</em>, 681–687. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504750">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this article, Polar Bear Optimization Algorithm (PBO) is parallelized to solve the problem of computed tomography (CT) with incomplete data. It is vary hard to model correctly 2D and 3D objects by using CT scanners when information is incomplete. Our approach is to use PBO to reduce recovery time and simplify specificity of the phenomenon. Results from our research show that proposed approach is enabling fast and accurate reconstruction of objects modeled in projection space.},
  archive   = {C_CEC},
  author    = {Mariusz Pleszczyński and Adam Zielonka and Dawid Połap and Marcin Woźniak and Jacek Mańdziuk},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504750},
  pages     = {681-687},
  title     = {Polar bear optimization for industrial computed tomography with incomplete data},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Heuristic optimization of 18-pulse rectifier system.
<em>CEC</em>, 673–680. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504783">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The paper proposes a model of regulation for transformer secondary voltages in order to improve quality of rectified voltage. For this purpose, a simulation model for an 18-pulse rectifier system was presented. We have defined optimization task by using proposed parallel version of the Polar Bear Optimization (PBO) algorithm. For the developed method simulation results are presented and discussed. Research show that proposed parallelization enabled efficient optimization of the large number of parameters and, at the same time, shortens simulation time.},
  archive   = {C_CEC},
  author    = {Andrzej Sikora and Adam Zielonka and Marcin Woźniak},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504783},
  pages     = {673-680},
  title     = {Heuristic optimization of 18-pulse rectifier system},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Meta-heuristic algorithm as feature selector for
convolutional neural networks. <em>CEC</em>, 666–672. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504915">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The huge popularity of heuristics contributes not only to the improvement and modeling of new solutions but also to their adaptation to selected goals. Recent years have shown the popularity of their use also in machine learning as a training algorithm or allowing for the selection of optimal architecture or hyper-parameters. In this paper, we propose an adaptation of a nature-inspired algorithm for preprocessing images in a parallel way for obtaining higher classification results. The proposed idea is based on analyzing images by heuristic representative which is Red Fox Optimization Algorithm and returning a specific value. These values are used in deciding to classify the entire image or trim it to eliminate unnecessary objects. We modeled this solution and evaluated using the learning transfer method for VOC 2007 dataset. The obtained results were compared on selected classes to show the advantages of a proposal.},
  archive   = {C_CEC},
  author    = {Dawid Połap and Marcin Woźniak and Jacek Mańdziuk},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504915},
  pages     = {666-672},
  title     = {Meta-heuristic algorithm as feature selector for convolutional neural networks},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Embedded representations of wikipedia categories.
<em>CEC</em>, 660–665. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504802">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we present an approach to building neural representations of the Wikipedia category graph. We test four different methods and examine the neural embeddings in terms of preservation of graphs edges, neighborhood coverage in representation space, and their influence on the results of a task predicting parent of two categories. The main contribution of this paper is application of neural representations for improving the structure of Wikipedia categories graph. We also show that a neural representation based solely on categories&#39; names can be an alternative to the other representations build using more complex approaches.},
  archive   = {C_CEC},
  author    = {Jan Majkutewicz and Julian Szymański and Andrzej Sobecki and Higinio Mora and David Gil},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504802},
  pages     = {660-665},
  title     = {Embedded representations of wikipedia categories},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A hybrid discrete differential evolution approach for the
single machine total stepwise tardiness problem with release dates.
<em>CEC</em>, 652–659. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504914">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, a novel hybrid discrete differential evolution based approach is proposed to address a single machine scheduling problem where each job has a release date and the tardiness cost of the job increases stepwise with respect to various due dates. In the literature, this problem is termed as the single machine total stepwise tardiness problem with release dates (SMTSTP-R). The objective of the problem is to find a schedule of jobs which minimizes the total tardiness cost. The stepwise increase in tardiness cost is more prevalent in several real life scenario, especially in transportation. We have used two constructive heuristics and concept of opposition based solutions to generate initial population. Our proposed approach uses a series of local searches to further enhance the quality of solutions obtained by the proposed discrete differential evolution approach. In order to justify the superiority of proposed approach, various comparisons are done with the existing approaches available in the literature. The results of these comparisons validate the superiority of our approach in comparison to the existing state-of-the-art approaches.},
  archive   = {C_CEC},
  author    = {Gaurav Srivastava and Alok Singh and Rammohan Mallipeddi},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504914},
  pages     = {652-659},
  title     = {A hybrid discrete differential evolution approach for the single machine total stepwise tardiness problem with release dates},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Feature selection for evolving many-objective job shop
scheduling dispatching rules with genetic programming. <em>CEC</em>,
644–651. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504895">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {JSS (Job Shop Scheduling) is a significant and challenging combinatorial optimization issue. Dispatching rules have been successfully used to determine scheduling decisions in the JSS challenges. Genetic programming (GP) has been widely used to discover and develop dispatching rules for various scheduling problems. However, there has been relatively little research into feature selection in GP-HH for many-objective JSS. In many conflicting objective contexts, it&#39;s also vital to quantify the contribution of features. This work presents a new two-stage GP-HH methodology for many-objective JSS with feature selection for changing rules. The quality of the solutions (dispatching rules) after incorporating the many-objective algorithm with feature selection is investigated in this paper. On a four-objective JSS problem, the suggested algorithm (FS-GP-NSGA-III) is compared to the standard GP-NSGA-III. The experimental results show that using GP to pick relevant features improves the algorithm&#39;s performance. Furthermore, the proposed technique generates rules that are minimal in size and easy to understand.},
  archive   = {C_CEC},
  author    = {Atiya Masood and Gang Chen and Mengjie Zhang},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504895},
  pages     = {644-651},
  title     = {Feature selection for evolving many-objective job shop scheduling dispatching rules with genetic programming},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A multi-objective genetic programming approach with
self-adaptive α dominance to uncertain capacitated arc routing problem.
<em>CEC</em>, 636–643. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504956">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Uncertain Capacitated Arc Routing Problem (UCARP) has a variety of real-world applications. Genetic Programming Hyper-heuristic (GPHH) is considered a promising technique to handle UCARP. Many scholars have shown the power of GPHH of evolving effective routing policies. However, the size of the evolved routing policies is ignored. Typically, smaller routing policies can have better interpretability and generalisation. Thus, it is necessary to optimise the size along with the effectiveness. The objective selection bias issue arises as the size is much easier to be optimised than effectiveness. The Pareto front is biased to the size gradually during the evolutionary process. To address this issue, we develop an α dominance criteria based Multi-Objective GP with a self-adaptive α scheme (αMOGP-sa). The basic idea of the α dominance criteria is to set tradeoff rates between objectives. For different instances, the search space can be very different. In this case, the self-adaptive α scheme is employed to automatically tuning the α value during the evolutionary process so that we can identify a valid α value for different instances. This paper examines the proposed algorithm in eight different problem instances. The experimental results showed that αMOGP-sa could effectively handle the objective selection bias issue, and evolve much better Pareto front on Hyper-Volume and Inverted Generational Distance than the current state-of-the-art MOGP approach for UCARP in terms of effectiveness and size on all instances. Also, αMOGP-sa can evolve much smaller routing policies than the state-of-art single-objective GPHH without sacrificing effectiveness.},
  archive   = {C_CEC},
  author    = {Shaolin Wang and Yi Mei and Mengjie Zhang},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504956},
  pages     = {636-643},
  title     = {A multi-objective genetic programming approach with self-adaptive α dominance to uncertain capacitated arc routing problem},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Surrogate-assisted genetic programming with diverse transfer
for the uncertain capacitated arc routing problem. <em>CEC</em>,
628–635. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504817">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Uncertain Capacited Arc Routing Problem (UCARP) is an important routing problem that can model uncertainties of real-world scenarios. Genetic Programming (GP) is a powerful method for evolving routing policies for vehicles to enable them make real-time decisions and handle environmental uncertainties. When facing various problem domains, knowledge transfer can improve the effectiveness of the GP training. Previous studies have demonstrated that due to the existence of duplicated GP individuals in the source domain, the existing transfer learning methods do not perform satisfactorily for UCARP. To address this issue, in this work, we propose a method for detecting duplicates in the source domain and initialising the GP population in the target domain with phenotypically unique individuals. Additionally, since the presence of duplicates can limit the number of good GP individuals, we propose a surrogate-assisted initialisation approach that is able to generate much more diversely distributed initial individuals in the target domain. Our experiments demonstrate that our proposed transfer learning method can significantly improve the effectiveness of GP for training new UCARP routing policies. Compared with the state-of-the-art GP with knowledge transfer, the proposed approach can obtain significantly better solutions on a wide range of UCRP instances, in terms of both initial and final quality.},
  archive   = {C_CEC},
  author    = {Mazhar Ansari Ardeh and Yi Mei and Mengjie Zhang},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504817},
  pages     = {628-635},
  title     = {Surrogate-assisted genetic programming with diverse transfer for the uncertain capacitated arc routing problem},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A max-min ant system based on decomposition for the
multi-depot cumulative capacitated vehicle routing problem.
<em>CEC</em>, 620–627. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504891">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-depot Cumulative Capacited Vehicle Routing Problem (MDCCVRP) is a relatively new research field in Vehicle Routing Problems (VRP), which is composed of several traditional VRP variants. This model is usually applicable to the logistics and transportation problems after the disaster. A decomposition-based Max-Min ant system (DMMAS) algorithm is proposed to solve MDCCVRP in this paper. First of all, a new indicator which measures the nearness between two routes for multi-depot problems is proposed. The original problem is decomposed into a series of smaller subproblems, and then, after the optimization phase, a specific pheromone communication rule between the master problem and subproblems is adopted to guide the search direction of ants. Finally, when the search gets into a halt, a mechanism of perturbation is used to get rid of the local optimality. The algorithm is tested on many benchmark problems and the experimental results show that our algorithm can effectively improve the performance in most cases compared to several state-of-the-art evolutionary algorithms.},
  archive   = {C_CEC},
  author    = {Mengyi Niu and Ruochen Liu and Handing Wang},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504891},
  pages     = {620-627},
  title     = {A max-min ant system based on decomposition for the multi-depot cumulative capacitated vehicle routing problem},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modular analysis and development of a genetic algorithm with
standardized representation for resource-constrained project scheduling.
<em>CEC</em>, 612–619. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504950">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {There has been a considerable amount of research on the development of metaheuristic methods for resource-constrained project scheduling problems. Early methods followed the building blocks and even the formulation of well-understood metaheuristic methods as well as simple but effective heuristics such as forward-backward improvement. In contrast, more recent methods employ less familiar, more complex (hybrid) metaheuristics and non-standard components and formulations. Although the former may provide better results on standard test problems, it is not easy to understand how each component has contributed to improving the results and why a deviation from well-established formulations, components and methods was necessary. This research advances our knowledge about the impact of different strategies and components of customized genetic algorithms (some of which have been proposed in this study) on the optimization results. This task is performed by developing a comprehensive genetic algorithm with several familiar and potentially effective components. A modular analysis is then performed in which one component is suppressed at a time, and the resultant performance decline is analyzed. With hindsight from the modular analysis, a simple method is suggested and the importance of each component is clarified. Thus, no further simplification can be performed without compromising efficiency. Our preliminary results reveal that this customized genetic algorithm outperforms many existing methods and can compete with the most successful ones, which, in many cases, are much more complex than our approach.},
  archive   = {C_CEC},
  author    = {Ali Ahrari and Saber Elsayed and Ruhul Sarker and Daryl Essam and Carlos A. Coello Coello},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504950},
  pages     = {612-619},
  title     = {Modular analysis and development of a genetic algorithm with standardized representation for resource-constrained project scheduling},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). GP with a hybrid tree-vector representation for instance
selection and symbolic regression on incomplete data. <em>CEC</em>,
604–611. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504767">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Data incompleteness is a pervasive problem in symbolic regression, and machine learning in general. Unfortunately, most symbolic regression methods are only applicable when the given data is complete. One common approach to handling this situation is data imputation. It works by estimating missing values based on existing data. However, which existing data should be used for imputing the missing values? The answer to this question is important when dealing with incomplete data. To address this question, this work proposes a mixed tree-vector representation for genetic programming to perform instance selection and symbolic regression on incomplete data. In this representation, each individual has two components: an expression tree and a bit vector. While the tree component constructs symbolic regression models, the vector component selects the instances that are used to impute missing values by the weighted k-nearest neighbour (WKNN) imputation method. The complete imputed instances are then used to evaluate the GP-based symbolic regression model. The obtained experimental results show the applicability of the proposed method on real-world data sets with different missingness scenarios. When compared with existing methods, the proposed method not only produces more effective symbolic regression models but also achieves more efficient imputations.},
  archive   = {C_CEC},
  author    = {Baligh Al-Helali and Qi Chen and Bing Xue and Mengjie Zhang},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504767},
  pages     = {604-611},
  title     = {GP with a hybrid tree-vector representation for instance selection and symbolic regression on incomplete data},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-objective discovery of PDE systems using evolutionary
approach. <em>CEC</em>, 596–603. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504712">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Usually, the data-driven methods of the systems of partial differential equations (PDEs) discovery are limited to the scenarios, when the result can be manifested as the single vector equation form. However, this approach restricts the application to the real cases, where, for example, the form of the external forcing is of interest for the researcher and can not be described by the component of the vector equation. In the paper, a multi-objective co-evolution algorithm is proposed. The single equations within the system and the system itself are evolved simultaneously to obtain the system. This approach allows discovering the systems with the form-independent equations. In contrast to the single vector equation, a component-wise system is more suitable for expert interpretation and, therefore, for applications. The example of the two-dimensional Navier-Stokes equation is considered.},
  archive   = {C_CEC},
  author    = {Mikhail Maslyaev and Alexander Hvatov},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504712},
  pages     = {596-603},
  title     = {Multi-objective discovery of PDE systems using evolutionary approach},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Genetic programming for symbolic regression: A study on fish
weight prediction. <em>CEC</em>, 588–595. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504963">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The fish weight is a very important factor in fisheries science and management since it explains the growth and living conditions of fish populations. A power regression model has been commonly used to explain the relationship between the fish length and the weight. In this work, Genetic Programming (GP) for symbolic regression is used to build a new model for predicting the fish weight, which allows us to include more features into the model to discover any hidden relationship, and the GP based symbolic regression makes the model interpretable comparing with other machine learning methods. A publicly available dataset is taken with four species of fish which includes more features than just the fish length that is commonly used in existing models. The proposed GP based symbolic regression method has been examined on those four species. The results are compared with the weight prediction baseline methods including Linear Regression, Power Regression model, k-Nearest Neighbour, Ridge Regression, Decision Tree, Random Forest, Gradient Boosting, and Multilayer Perceptron. GP performs better, or at least as good as the baseline methods on the test set. Furthermore, the generated GP models also can select different features for different species to improve the prediction performance due to GP&#39;s explicit feature selection ability. Some models are interpretable with relatively simple expression. The GP method is also able to find models that are similar to the power regression model, but more features are included rather than a single length feature to gain improved prediction performance.},
  archive   = {C_CEC},
  author    = {Yunhan Yang and Bing Xue and Linley Jesson and Mengjie Zhang},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504963},
  pages     = {588-595},
  title     = {Genetic programming for symbolic regression: A study on fish weight prediction},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Semantic neighborhood ordering in multi-objective genetic
programming based on decomposition. <em>CEC</em>, 580–587. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504860">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Semantic diversity in Genetic Programming has proved to be highly beneficial in evolutionary search. We have witnessed a surge in the number of scientific works in the area, starting first in discrete spaces and moving then to continuous spaces. The vast majority of these works, however, have focused their attention on single-objective genetic programming paradigms, with a few exceptions focusing on Evolutionary Multi-objective Optimization (EMO). The latter works have used well-known robust algorithms, including the Non-dominated Sorting Genetic Algorithm II and the Strength Pareto Evolutionary Algorithm, both heavily influenced by the notion of Pareto dominance. These inspiring works led us to make a step forward in EMO by considering Multi-objective Evolutionary Algorithms Based on Decomposition (MOEA/D). We show, for the first time, how we can naturally promote semantic diversity in MOEA/D in Genetic Programming.},
  archive   = {C_CEC},
  author    = {Fergal Stapleton and Edgar Galván},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504860},
  pages     = {580-587},
  title     = {Semantic neighborhood ordering in multi-objective genetic programming based on decomposition},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Stabilization of higher periodic orbits of the lozi and
hénon maps using meta-evolutionary approaches. <em>CEC</em>, 572–579.
(<a href="https://doi.org/10.1109/CEC45853.2021.9504798">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper deals with an advanced adjustment of stabilization sequences for selected discrete chaotic systems by means of meta-evolutionary approaches. As the representative models of deterministic chaotic systems, a two dimensional Lozi map and two dimensional Hénon map were used. The novelty of the approach is in an effective use of a new type of objective function, which is essential for the whole optimization process of higher periodic orbits as well as an effective use of advanced metaheuristic optimization methods. Although the task of stabilizing the Lozi and Hénon chaotic systems is known, its solution presented for periodic orbit four is not trivial. The task of stabilizing the Lozi chaotic systems for period four is a new approach. Furthermore, modern meta-heuristics were used for own design of the external disturbance sequences. The used optimization methods are a naive grid-based algorithm (NG), a grid-based Nelder-Mead Algorithm (NM), a Genetic Algorithm (GA) as well as Genetic Programming (GP). A connection of GP and second level optimization using GA displays significantly better results than the given stand-alone meta-heuristic techniques.},
  archive   = {C_CEC},
  author    = {Radomil Matousek and René Pierre Lozi and Tomas Hulka},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504798},
  pages     = {572-579},
  title     = {Stabilization of higher periodic orbits of the lozi and hénon maps using meta-evolutionary approaches},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Genetic programming with random binary decomposition for
multi-class classification problems. <em>CEC</em>, 564–571. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504967">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper introduces a new Genetic Programming (GP) based classification framework for multiclass classification problems. The proposed framework uses a binary decomposition-based GP method to extract new features to enhance the performance of classifiers in the multiclass classification task. We firstly introduce a random binary decomposition method that uses a part-vs-part strategy to decompose the multiclass problems which increase the number of binary problems that can be decomposed from a multiclass problem. Then the details of combining GP with this binary decomposition method for feature extraction are explained. Finally, we compare our method to several popular ML methods and traditional GP methods in a broad set of benchmark problems. The outcome shows the performance of classifiers is enhanced for multi-class classification tasks when combined with this technique. The effect of applying this framework to different classifiers and large real-world data set is also explored. The results suggest the effectiveness and universality of our method.},
  archive   = {C_CEC},
  author    = {Lushen Liao and Adam Kotaro Pindur and Hitoshi Iba},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504967},
  pages     = {564-571},
  title     = {Genetic programming with random binary decomposition for multi-class classification problems},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new subspace multi-objective approach for the clustering
and selection of regions of interests in histopathological images.
<em>CEC</em>, 556–563. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504811">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Histopathology images represent a source of assistance for pathologists when diagnosing Cancer. However, in histopathology or in cancer image analysis, pathologists mostly diagnose the pathology as positive if a small part of it is considered cancer tissue. These small parts are called regions of interest (ROI) or patches. Finding the relevant patches is crucial as it can save computation time and memory. Subspace clustering discovers clusters embedded in multiple, overlapping subspaces of high dimensional data. It is an extension of feature selection, which tries to identify relevant subsets of features that are relevant to the clustering process. However, subspace clustering algorithms provide a partition of the data based on one cluster validity measure, assuming a homogeneous similarity measure over the entire data set makes the algorithms not robust to variations in the data characteristics. Therefore, it is beneficial to optimize multiple validity indices simultaneously to capture different aspects of the datasets. The goal of Multi-Objective clustering methods (MOC) is to derive significant clusters by applying two or more objective functions. This paper proposes a new clustering algorithm for patch selection based on subspace and multi-objective clustering to find the data’s best partitioning and the images’ most relevant patches.},
  archive   = {C_CEC},
  author    = {Mohammed Oualid Attaoui and Hanene Azzag and Nabil Keskes and Mustapha Lebbah},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504811},
  pages     = {556-563},
  title     = {A new subspace multi-objective approach for the clustering and selection of regions of interests in histopathological images},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hybrid MLP-PSO-based technique to predict process parameters
and alloying compositions in ADI for sustainable manufacturing.
<em>CEC</em>, 549–555. (<a
href="https://doi.org/10.1109/CEC45853.2021.9505007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Due to some of the attractive physical properties, e.g., high ductility and strength, and machinability, austempered ductile iron (ADI) has been widely used to produce components, in heavy industries, automobiles, farm machineries, and railways. Depending on the design requirements, a component requires ADI with specific physical characteristics. Several alloying elements are added to molten iron and then it undergoes a complex austempering thermal process to produce ADI. During the austempering process, the alloying elements interact with iron in a highly nonlinear complex manner that leads to formation of microstructure which determines its physical properties. However, currently, there is no technique available that can specify the austempering temperature and time, and alloying element proportions to produce ADI with a specific characteristic. In this paper, we propose a novel hybrid multilayer perceptron (MLP) and particle swarm optimization (PSO)-based technique to predict the austempering process parameters and alloying compositions to produce ADI with a specific physical characteristic, e.g., Vickers hardness number (VHN). In the first phase, an MLP is trained to learn the austempering process in a forward modeling scheme using the experimental data taken from literature. In the second phase, in an inverse modeling scheme, using the trained MLP and PSO algorithm, a solution is obtained that provides the predicted austempered process parameters and alloying elements to produce ADI with a specific VHN. With extensive simulation results it is shown that the proposed technique can provide feasible and accurate solutions that provide optimum use of expensive alloying materials leading to sustainable manufacturing.},
  archive   = {C_CEC},
  author    = {Ravindra V. Savangouder and Jagdish C. Patra and Suresh Palanisamy},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9505007},
  pages     = {549-555},
  title     = {Hybrid MLP-PSO-based technique to predict process parameters and alloying compositions in ADI for sustainable manufacturing},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Domain-driven correlation-aware recombination and mutation
operators for complex real-world applications. <em>CEC</em>, 540–548.
(<a href="https://doi.org/10.1109/CEC45853.2021.9504931">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Evolutionary algorithms are a very general method for optimization problems that allow adaption to many different use cases. Application to real-world problems usually comes with features as constraints, dependencies and approximations. When a multidimensional search space comes with strings attached- namely dependencies between its dimensions- an expression in two ways is possible: Restrictive-as equalities or inequalities- or vague-as correlations between dimensions, for example. Correlations between dimensions are not as easy to grasp as constraints. Therefore, well-known techniques as death penalty or penalty functions do not apply directly. We propose new mutation and recombination operators that incorporate domain knowledge to increase the offspring fraction that adheres to these correlations. We evaluate our approach with several benchmark functions and different assumptions on the dependencies of the search space. We compare the likelihood of valid (in terms of adhering correlations) outcomes of algorithms using standard mutation and recombination operators to those with the proposed operators. We find that the correlation-aware operators preserve population&#39;s features in terms of dependencies.},
  archive   = {C_CEC},
  author    = {Christina Plump and Bernhard J. Berger and Rolf Drechsler},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504931},
  pages     = {540-548},
  title     = {Domain-driven correlation-aware recombination and mutation operators for complex real-world applications},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new optimization approach for task scheduling problem
using water cycle algorithm in mobile cloud computing. <em>CEC</em>,
530–539. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504780">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Mobile devices are used by numerous applications that continuously need computing power to grow. Due to limited resources for complex computing, offloading, a service offered for mobile devices, is commonly used in cloud computing. In Mobile Cloud Computing (MCC), offloading decides where to execute the tasks to efficiently maximize the benefits. Hence, we represent offloading as a Task Scheduling Problem (TSP). This latter is a Multi-Objective Optimization (MOO) problem where the goal is to find the best schedule for processing mobile source tasks, while minimizing both the average processor energy consumption and the average task processing time. Owing to the combinatorial nature of the problem, the TSP in MCC is known as NP-hard. To overcome this difficulty in practice, we adopt meta-heuristic search techniques as they offer a good trade-off between solution quality and scalability. More precisely, we introduce a new optimization approach, that we call Multi-objective Discrete Water Cycle Algorithm (MDWCA), to schedule tasks from mobile source nodes to processor resources in a hybrid MCC architecture, including public cloud, cloudlets, and mobile devices. To evaluate the performance of our proposed approach, we conducted several comparative experiments on many generated TSP instances in MCC. The simulation results show that MDWCA outperforms the state-of-the-art optimization algorithms for several quality metrics.},
  archive   = {C_CEC},
  author    = {Behzad Saemi and Mehdi Sadeghilalimi and Ali Asghar Rahmani Hosseinabadi and Malek Mouhoub and Samira Sadaoui},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504780},
  pages     = {530-539},
  title     = {A new optimization approach for task scheduling problem using water cycle algorithm in mobile cloud computing},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). A differential particle scheme with successful parent
selection and its application to PID control tuning. <em>CEC</em>,
522–529. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504971">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Proportional-integral-derivative (PID) control is ubiquitous in industrial automation tasks, and the parameter tuning of the gains is challenging due to nonlinearity and stagnation in local optima. In this paper we present a differential particle scheme based on stagnation-based selection mechanism, and evaluate its effectiveness in the stabilization of a nonlinear inverted pendulum and a magnetic levitation system. Our computational experiments show the feasibility to avoid stagnation, the lower variability of convergence over independent runs, and the feasibility to converge to significantly better fitness values compared to relevant heuristics in the literature. We believe our approach offers the building blocks to build stagnation-free nature inspired optimization algorithms useful for adaptive control and tuning.},
  archive   = {C_CEC},
  author    = {Victor Parque},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504971},
  pages     = {522-529},
  title     = {A differential particle scheme with successful parent selection and its application to PID control tuning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploiting local geometric features in vehicle design
optimization with 3D point cloud autoencoders. <em>CEC</em>, 514–521.
(<a href="https://doi.org/10.1109/CEC45853.2021.9504746">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Methods for learning and compressing high-dimensional data allow designers to generate novel and low-dimensional design representations for shape optimization problems. By using compact design spaces, global optimization algorithms require less function evaluations to characterize the problem landscape. Furthermore, data-driven representations are often domain-agnostic and independent of the user expertise, and thus potentially capture more relevant design features than a human designer would suggest. However, more factors than the dimensionality play a role in the efficiency of design representations. In this paper, we perform a comparative analysis of design representations for 3D shape optimization problems obtained with principal component analysis, kernel-principal component analysis and a 3D point cloud autoencoder, which we apply on a benchmark data set of computer aided engineering car models. We evaluate the shape-generative capabilities of these methods and show that we can modify the geometries more locally with the autoencoder than with the remaining methods. In a vehicle aerodynamic optimization framework, we verify that this property of the autoencoder representation improves the optimization performance by enabling potentially complementary degrees of freedom for the optimizer. With our study, we provide insights on the qualitative properties and quantifiable measures on the efficiency of deep neural networks as shape generative models for engineering optimization problems, as well as analyses of geometric representations for engineering optimization with evolutionary algorithms.},
  archive   = {C_CEC},
  author    = {Thiago Rios and Bas van Stein and Patricia Wollstadt and Thomas Bäck and Bernhard Sendhoff and Stefan Menzel},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504746},
  pages     = {514-521},
  title     = {Exploiting local geometric features in vehicle design optimization with 3D point cloud autoencoders},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A comparison of evolutionary and neural attention modeling
relative to adversarial learning. <em>CEC</em>, 506–513. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504958">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {State-of-the-art machine learning, for computer vision applications, is based on data-driven feature learning. While these extraction paradigms often yield impressive results that outperform human hand-crafted solutions, they unfortunately suffer from a lack of explainability. In response to this, both the neural network and evolutionary communities have provided techniques tailored to visually explain how machines process new observations. Examples range from gradient-weighted class activation mapping to guided backpropagation, and from convolutional matrix transpose to improved evolutionary constructed computing. Previously, we put forth a framework called the Adversarial Modifier Set (AMS). In AMS, adversarial imagery is generated based on evolutionary feature identified regions. In this article, we seek to improve both AMS and general adversarial systems by performing a comparative analysis between neural attention modeling techniques and our previously used evolutionary strategy. Preliminary results on a computer vision dataset show that while the neural techniques are faster, evolutionary algorithms yield diverse and higher fidelity attention maps that give rise to improved features for adversarial learning.},
  archive   = {C_CEC},
  author    = {Charlie Veal and Marshall Lindsay and Scott Kovaleski and Derek T. Anderson and Stanton R. Price},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504958},
  pages     = {506-513},
  title     = {A comparison of evolutionary and neural attention modeling relative to adversarial learning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploration of encoding and decoding methods for spiking
neural networks on the cart pole and lunar lander problems using
evolutionary training. <em>CEC</em>, 498–505. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504921">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Spiking Neural Networks are increasingly drawing interest due to their potential for large efficiency gains when used with neuromorphic computers. However, when attempting to replicate the successes of Artificial Neural Networks, challenges are faced due to their vastly different architectures and therefore differing methods for training and optimisation. There has been minimal analysis of the differences between encoding and decoding methods and the effect of state space exposure periods on the performance of these networks. The core contribution of this paper is the detailed analysis of decoding methods, state exposure periods, and a learned input encoding method of an evolved Spiking Neural Network within the Reinforcement Learning context. This is demonstrated using the Cart Pole and Lunar Lander Reinforcement Learning problems. The paper discovers a negative correlation between the generation to reach the goal and the state space exposure period over all decoding methods tested. The state exposure period is also found to influence the number of random actions taken due to the decoding methods being unable to select an action. This paper explores the differences in temporal and rate-based decoding as well as identifying benefits in resetting networks to their default states between episode steps. Additionally, the novel input encoder, is effective at pre-processing state information using the same evolutionary algorithm as the rest of the network.},
  archive   = {C_CEC},
  author    = {Andrew W. Rafe and Jaime A. Garcia and William L. Raffe},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504921},
  pages     = {498-505},
  title     = {Exploration of encoding and decoding methods for spiking neural networks on the cart pole and lunar lander problems using evolutionary training},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Solar irradiance forecasting in tropical weather using an
evolutionary lean neural network. <em>CEC</em>, 490–497. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504875">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Clean electricity system based on solar energy is rapidly growing. However, the intermittency of solar power remains an issue. An accurate solar irradiance forecast can mitigate the impact of variable solar power generation. In this paper, we present the Evolutionary Lean Neural Network (EVLNN) for time-series solar irradiance forecasting. The key novelty of EVLNN lies in incorporating a feedback structure to a partially connected neural network while using an improved genetic algorithm to optimize its architecture. We train the model with tropical weather data to provide a days-ahead forecast of solar irradiance at four different time-steps: 1-min, 15-min, 30-min, and hourly. We investigate the effects of fewer input features in model training and assess the model accuracy using a combination of Root Mean Square Error (RMSE), Mean Absolute Error (MAE), and Adjusted Coefficient of Determination (Adjusted R 2 ) metrics. We then compare the results with those obtained from neural networks modeled using other evolutionary algorithms (EA), namely the Particle Swarm Optimization, the Differential Evolution, and the classic Genetic Algorithm. We include the fully connected nonlinear time-delay backpropagation neural network as a benchmark against which to evaluate the EA-based models. The results demonstrated EVLNN&#39;s good generalization capability, specifically in the presence of a sparse dataset. Moreover, our proposed model trained with a single input variable achieved improved performance for the hourly, 30-min, and 15-min time-step predictions compared with those modeled using other learning algorithms.},
  archive   = {C_CEC},
  author    = {Yong Wee Foo and Cindy Goh},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504875},
  pages     = {490-497},
  title     = {Solar irradiance forecasting in tropical weather using an evolutionary lean neural network},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A genetic algorithm with tree-structured mutation for
hyperparameter optimisation of graph neural networks. <em>CEC</em>,
482–489. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504717">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In recent years, graph neural networks (GNNs) have gained increasing attention, as they possess the excellent capability of processing graph-related problems. In practice, hyperparameter optimisation (HPO) is critical for GNNs to achieve satisfactory results, but this process is costly because the evaluations of different hyperparameter settings require excessively training many GNNs. Many approaches have been proposed for HPO, which aims to identify promising hyperparameters efficiently. In particular, the genetic algorithm (GA) for HPO has been explored, which treats GNNs as a black-box model, of which only the outputs can be observed given a set of hyperparameters. However, because GNN models are sophisticated and the evaluations of hyperparameters on GNNs are expensive, GA requires advanced techniques to balance the exploration and exploitation of the search and make the optimisation more effective given limited computational resources. Therefore, we proposed a tree-structured mutation strategy for GA to alleviate this issue. Meanwhile, we reviewed the recent HPO works, which gives room for the idea of tree-structure to develop, and we hope our approach can further improve these HPO methods in the future.},
  archive   = {C_CEC},
  author    = {Yingfang Yuan and Wenjun Wang and Wei Pang},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504717},
  pages     = {482-489},
  title     = {A genetic algorithm with tree-structured mutation for hyperparameter optimisation of graph neural networks},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Human activity recognition using parallel cartesian genetic
programming. <em>CEC</em>, 474–481. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504793">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Human activity recognition (HAR) is applicable to a wide range of real-life situations. While machine learning algorithms can be applied for solving this problem, difficulties remain, such as handling a large amount of data available for training and selecting the most appropriate features. Hence, the advent of methods to reduce these issues and improve the currently available algorithms is relevant. Thus, we propose here the application of Cartesian Genetic Programming of Artificial Neural Networks (CGPANN) for training models for HAR. As the computational cost is a relevant issue in this context, high-performance computing strategies in graphic processing units (GPU) are proposed for CGPANN. Two computational experiments are executed and the results show a decrease in computational time spent with the usage of different data structures for the parallel CGPANN on the GPU. Moreover, the CGPANN models for HAR are promising when compared to results from the literature.},
  archive   = {C_CEC},
  author    = {Bruno M. P. Silva and Heder S. Bernardino and Helio J. C. Barbosa},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504793},
  pages     = {474-481},
  title     = {Human activity recognition using parallel cartesian genetic programming},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multistage evolutionary strategies for adjusting a cellular
automata-based epidemiological model. <em>CEC</em>, 466–473. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504738">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {An epidemiological model based on cellular automata (CA) rules is tuned through several parameters to provide a more accurate simulation of the real phenomena. CA are dynamic systems capable of describing complexity from simple components and local iterations. The parameters setting discussed here is guided by reference values that were obtained with real field data. We started from a recent study in which an adequate parameters configuration was sought for a stochastic CA-based epidemiological model of Chagas Disease through an evolutionary approach. The results were satisfactory but the performance of the standard genetic algorithm (GA) previously employed declines with the expansion of the search space. In order to improve performance, we present a multistage evolutionary strategy, where different settings are applied based on the current stage of the GA search. The proposed evolutionary approach provided solutions with the least error in the set of experiments, confirming the improvement over the previous approach.},
  archive   = {C_CEC},
  author    = {Larissa M. Fraga and Gina M. B. de Oliveira and Luiz G. A. Martins},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504738},
  pages     = {466-473},
  title     = {Multistage evolutionary strategies for adjusting a cellular automata-based epidemiological model},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Applying never-ending learning (NEL) principles to build a
gene ontology (GO) biocurator. <em>CEC</em>, 458–465. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504981">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The exponentially growing of generated data and the advanced computing techniques, catalyzed the necessity of innovative strategies to store, analyze and capture biological data. The biocuration was created due to the number and scope of scientific databases in recent years. Biocuration is an essential part of biological and biomedical research discovery. Extracted from the literature, curated data is so important to accomplish computational analysis and to train data mining algorithms. Concurrently, the researchers need a rapidly and more decisive approach to understand unknown domains. In this paper, we propose an architecture to help biocurators in Gene Ontology (GO) classification tasks. Our approach is based on a semi-supervised environment that couples evolutionary computation (i.e. Genetic Algorithms (GA)) and traditional classifiers (i.e. Decision Trees and Naive Bayes). Furthermore, our approach provides high level knowledge (IF-THEN rules and decision trees), balancing accuracy, interpretability and comprehensibility that can help GO biocurators in their classification tasks. Our architecture shows higher classification rates (about 94\%, i.e., 17,820 correct samples of 18,959), starting from a small training set, only 2,707 samples (12.5\% of 21,666 samples).},
  archive   = {C_CEC},
  author    = {Laurence Rodrigues do Amaral and Alexandre Henrick da Silva Alves and Raphael de Lima Mendes and Matheus de Souza Gomes and Pedro Luiz Lima Bertarini and Estevam Rafael Hruschka},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504981},
  pages     = {458-465},
  title     = {Applying never-ending learning (NEL) principles to build a gene ontology (GO) biocurator},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Weighting on the world to change… an epidemic. <em>CEC</em>,
450–457. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504685">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A generative evolutionary algorithm is used to create personal contact networks representing which individuals can infect others during an infectious disease scenario. Two problems are considered: (i) finding networks that maximize the length of a simulated epidemic, and (ii) finding networks that match given epidemic profiles. A significant innovation is the introduction of weighted edges to represent the strength of the contact between individuals. Different weight initialization conditions are investigated and evaluated for their performance using a parameter selection mechanism designed to explore the parameter space. Results show that weighted edges were able to increase the overall performance achieved by the evolved networks for both problems considered. Furthermore, it is shown that initializing the weights with a value greater than one further improves performance. The results of the parameter selection mechanism were used to test additional parameter settings thoroughly which further maximize the length of the simulated epidemic for the evolved graphs.},
  archive   = {C_CEC},
  author    = {Rodrigo Vega Jimenez and Michael Dubé and Sheridan Houghten and James Hughes},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504685},
  pages     = {450-457},
  title     = {Weighting on the world to change… an epidemic},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimisation of cancer status prediction pipelines using
bio-inspired computing. <em>CEC</em>, 442–449. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504911">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Cancer is one of the leading causes of death globally, and early detection is a fundamental factor in improving patient outcomes. The advent of high-throughput genetic profiling techniques in the last few decades has led to an explosion of genetic data related to cancer. Machine learning methods, and classification algorithms in particular, have been used to find underlying patterns in cancer data and make diagnostic predictions. The addition of feature selection to classification pipelines can lead to improvements in predictive capabilities, since the removal of non-important features benefits the construction of classification models. We developed a classification pipeline for cancer status prediction composed of a feature selection step with SelectKBest and an ensemble classifier system with five popular supervised learning algorithms. We used three bio-inspired optimization techniques to select the optimal sets of hyperparameters for the classification pipeline and compared these approaches on three cancer microarray datasets. The results indicate that the optimized pipelines have better predictive performance in all but one of the experiments compared to the ensemble alone.},
  archive   = {C_CEC},
  author    = {Mariel Barbachan e Silva and Pedro Henrique Narloch and Marcio Dorn and Pilib Ó Broin},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504911},
  pages     = {442-449},
  title     = {Optimisation of cancer status prediction pipelines using bio-inspired computing},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evaluation of communities from exploratory evolutionary
compression of weighted graphs. <em>CEC</em>, 434–441. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504833">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Contact networks are used as a representation for the modeling of illness transmission. In this study, we represent not only the links of the transmissions but also utilize a weighted graph to represent the probability of transfer. These graphs can be large and complex when taking into account the number of contacts used in tracing. Compression of the graph allows for the development of community detection as well as providing a simpler graph. By examining the contact networks developed by an evolutionary algorithm for compression, it is discovered that the choice of fitness function and the appropriate weighting of edges leads to a different compressed graph, finding different connected communities; this is also true when compared to the communities identified by the Louvain community detection algorithm. This demonstrates the importance of considering weighting in contact networks, and suggests that in the future an understanding of the community structure should be utilized by public health officials.},
  archive   = {C_CEC},
  author    = {Emilia Rutkowski and James Sargant and Sheridan Houghten and Joseph Alexander Brown},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504833},
  pages     = {434-441},
  title     = {Evaluation of communities from exploratory evolutionary compression of weighted graphs},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evolution of amino acid properties in the context of protein
secondary structure prediction. <em>CEC</em>, 426–433. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504939">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Amino acid properties were optimized for protein secondary structure prediction. The artificial properties were evolved using differential evolution in a property space of arbitrary dimensionality. These properties were optimized to provide the correct results in predicting the elements of the protein secondary structure using a simple classifier model and with standard benchmark sets. A comparison is performed with respect to the use of the commonly employed orthogonal and neutral encoding of the amino acids of the protein chain, together with a discussion of the similarities of the evolved artificial properties with respect to physical properties of amino acids.},
  archive   = {C_CEC},
  author    = {José Santos and Héctor Rivas},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504939},
  pages     = {426-433},
  title     = {Evolution of amino acid properties in the context of protein secondary structure prediction},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Quantum-inspired estimation of distribution algorithm to
solve the travelling salesman problem. <em>CEC</em>, 416–425. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504821">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A novel Quantum-Inspired Estimation of Distribution Algorithm (QIEDA) is proposed to solve the Travelling Salesman Problem (TSP). The QIEDA uses a modified version of the W state quantum circuits to sample new solutions during the algorithm runtime. The algorithm behaviour is compared with other state-of-the-art population-based algorithms. QIEDA convergence is faster than other algorithms, and the obtained solutions improve as the size of the problem increases. Moreover, we show that quantum noise enhances the search of an optimal solution. Because quantum computers differ from each other, partly due to the topology that distributes the qubits, the computational cost of executing the QIEDA in different topologies is analyzed and an ideal topology is proposed for the TSP solved with the QIEDA.},
  archive   = {C_CEC},
  author    = {Vicente P. Soloviev and Concha Bielza and Pedro Larrañaga},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504821},
  pages     = {416-425},
  title     = {Quantum-inspired estimation of distribution algorithm to solve the travelling salesman problem},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An evolutionary approach for solving multi-objective WCSPs
using mini-bucket elimination heuristics. <em>CEC</em>, 408–415. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504973">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A Weighted Constraint Satisfaction Problem (WCSP) is a generalization of a constraint satisfaction problem (CSP) where some of the constraints can be violated at some cost and thus preferences among solutions can be expressed. Most research has focused on developing algorithms for solving single-objective problems. However, many real world constraint satisfaction problems involve multiple measures of performance that should be optimized simultaneously. In this paper, we introduce a new scheme that tackles the Multi-Objective WCSP combining multi-objective stochastic search and inference methods. The new approach exploits the efficiency of an evolutionary algorithm and the advantage of adaptable inference levels offered by the Mini-Bucket Elimination algorithm. Experiments conducted on the single-objective and the bi-objective variant of the Weighted Vertex Cover problem demonstrate the performance of the new approach, highlighting the benefits the inference step brings to the evolutionary algorithm.},
  archive   = {C_CEC},
  author    = {Vlad-Ioan Lupoaie and Ivona-Alexandra Chili and Madalina Raschip and Mihaela Elena Breaban},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504973},
  pages     = {408-415},
  title     = {An evolutionary approach for solving multi-objective WCSPs using mini-bucket elimination heuristics},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automated hypotheses generation via combinatorial causal
optimization. <em>CEC</em>, 399–407. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504816">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A powerful form of causal inference employed in many tasks, such as medical diagnosis, criminology, root cause analysis, biology, is abduction. Given an effect, it aims at generating a plausible and useful set of explanatory hypotheses for its causes. This article formulates the abductive hypotheses generation activity as an optimization problem, introducing a new class called Combinatorial Causal Optimization Problems (CCOP). In a CCOP, solutions are in the form of cause-effect combinations: algorithms are required to construct hypothetical solutions automatically assessed for plausibility - a mechanism mimicking the human reasoning when he skims the best solutions from a set of hypotheses - and for novelty with respect to already known solutions. The paper presents the CCOP formulation and four real-world benchmark problems from various domains, released along with artefacts to implement, run and properly evaluate algorithms for CCOP solutions. Then, for illustrative purpose, four conventional evolutionary algorithms are customized to solve CCOPs. Their application demonstrates the possibility of generating useful solutions (i.e., novel and realistic hypotheses for a given effect), but also evidences a great margin for improvement in terms of ratio of good vs bad solutions.},
  archive   = {C_CEC},
  author    = {Roberto Pietrantuono},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504816},
  pages     = {399-407},
  title     = {Automated hypotheses generation via combinatorial causal optimization},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A general framework based on walsh decomposition for
combinatorial optimization problems. <em>CEC</em>, 391–398. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504699">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper we pursue the use of the Fourier transform for a general analysis of combinatorial optimization problems. While combinatorial optimization problems are defined by means of different notions like weights in a graph, set of numbers, distance between cities, etc., the Fourier transform allows to put all of them in the same framework, the Fourier coefficients. This permits its comparison looking for similarities and differences. Particularly, the Walsh transform has recently been used over pseudo-boolean functions in order to design new surrogate models in the black-box scenario and to generate new algorithms for the linkage discovery problem, among others, presenting very promising results. In this paper we focus on binary problems and the Walsh transform. After presenting the Walsh decomposition and some main properties, we compute the transform of the Unconstrained Binary Quadratic Problem and several particular cases of this problem such as the Max-Cut Problem and the Number Partitioning Problem. The obtained Walsh coefficients not only reinforce the similarities and differences among the problems which are known in the literature, but given a set of Walsh coefficients we can say whether or not they are produced by any of the problems analyzed. Finally, a geometrical interpretation of the space of Walsh coefficients with maximum order 2 and the subspace of each analyzed problem is presented.},
  archive   = {C_CEC},
  author    = {Imanol Unanue and María Merino and Jose A. Lozano},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504699},
  pages     = {391-398},
  title     = {A general framework based on walsh decomposition for combinatorial optimization problems},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An evolutionary algorithm taking account of epistasis among
parameters for black-box discrete optimization. <em>CEC</em>, 383–390.
(<a href="https://doi.org/10.1109/CEC45853.2021.9504771">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose an evolutionary algorithm that takes account of epistasis among parameters for black-box discrete optimization problems. The black-box discrete optimization (BB-DO) is an important problem that appears in various real-world problems such as hyper-parameter optimization of machine learning and is a difficult class of optimization problems to which optimization methods that require derivative of an objective function cannot be applied. In addition, epistasis among parameters, or the dependencies among variables, makes BB-DO problems more difficult. The bayesian optimization algorithm (BOA) has been proposed as a promising method to address epistasis in BB-DO problems. However, BOA suffers from a serious problem. The problem is that the diversity of a population is likely to be lost. Therefore, BOA requires a large population size for optimization. In order to remedy the problem of BOA, we introduce three schemes to maintain the diversity of the population into BOA. In experiments, we use two benchmark problems, a 3-deceptive function and a NK-landscape, and a structural optimization of neural networks to show the effectiveness of the proposed method. The experimental results showed that the proposed method improved the number of evaluations by 31.5\% and the population size by 96.9\% in a 180-dimensional 3-deceptive function and found comparable or better solutions in all NK-landscape settings compared to BOA. In the structural optimization of neural networks, the proposed method improved the number of evaluations by 21.3\% and the population size by 92.3\% compared to BOA. In addition, the proposed method was superior to conventional optimization methods used in this field, ASNG-NAS, regularized evolution, reinforcement learning, TPE, and random search, in terms of the evaluation value.},
  archive   = {C_CEC},
  author    = {Sho Shimazu and Isao Ono},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504771},
  pages     = {383-390},
  title     = {An evolutionary algorithm taking account of epistasis among parameters for black-box discrete optimization},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A biased random-key genetic algorithm with a local search
component for the optimal bucket order problem. <em>CEC</em>, 375–382.
(<a href="https://doi.org/10.1109/CEC45853.2021.9504985">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Aggregating ranks into a consensus is an important task applied in different fields of science. This paper deals with a specific variation that aggregate ranks into a consensus considering ties between its elements. This approach is more flexible and meaningful for modeling some circumstances where a strict order is considered too restrictive. A ranking considering ties is also known as a bucket order in literature, and the problem that considers the rank aggregation of bucket orders is defined as the Optimal Bucket Order Problem (OBOP). It is an NP-hard problem, hence several heuristics have been proposed in the literature. The current state-of-the-art results for this problem were achieved through an Evolution Strategy (ES) metaheuristic. This paper proposes the application of the adaptive Biased Random-key Genetic Algorithm (A-BRKGA) with Variable Neighborhood Descent (VND) as a local search to solve it. The A-BRKGA is a metaheuristic with on-line parameter control, in which the strategy for parameter tuning is based on deterministic rules and self-adaptive schemes. The proposed approach was compared with ES in 152 instances, improving the fitness of the best solutions in 35.52\% of the instances, providing better average solutions for 70.39\%, and equal results for the remaining instances.},
  archive   = {C_CEC},
  author    = {Luiz Henrique Nogueira Lorena and Luiz Antonio Nogueira Lorena and Antonio Augusto Chaves},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504985},
  pages     = {375-382},
  title     = {A biased random-key genetic algorithm with a local search component for the optimal bucket order problem},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel evolutionary algorithm with adaptation mechanism for
fuzzy permutation flow-shop scheduling. <em>CEC</em>, 367–374. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504870">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As a scheduling problem with wide application backgrounds, the flow-shop scheduling problem (FSP) in deterministic cases has attracted much attention. However, the neglecting of uncertainty will greatly diminish the application value of scheduling results, which makes it necessary to incorporate the uncertainty in the FSP. In this paper, a fuzzy permutation flow-shop scheduling problem (FPFSP) is considered and a novel evolutionary algorithm with adaptation mechanism (AMEA) is proposed to minimize fuzzy makespan. In the initialization phase, two initialization strategies based on the NEH heuristic are proposed to improve the quality of initial population. In the evolution phase, to enhance the exploitation, multiple local search operators are conducted in a collaborative way where the utilizations of operators are adjusted adaptively according to the feedback of their performances; besides, to save computing resources and balance the exploration and exploitation, the population size is adjusted adaptively with the number of generations. Benchmark instances are generated to evaluate the performance of the AMEA. The experimental results and statistical comparisons show that the proposed algorithm has great advantages in solving the FPFSP.},
  archive   = {C_CEC},
  author    = {Zi-Xiao Pan and Ling Wang and Jing-Fang Chen and Yu-Ting Wu},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504870},
  pages     = {367-374},
  title     = {A novel evolutionary algorithm with adaptation mechanism for fuzzy permutation flow-shop scheduling},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Memetic differential evolution using coordinate descent.
<em>CEC</em>, 359–366. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504762">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Differential Evolution (DE) is one of the well-established population-based optimization algorithms which has received a lot of attention regarding its potential to solve complex optimization problems. However, DE is capable to explore a huge search space in its early run phase, called exploration phase, its weakness in exploitation avoids local refinement of the promising shrunk region. Therefore, employing a local search can be an efficient strategy to improve the search performance of DE via accelerating of fine tuning phase. This paper purposes an effective Memetic DE algorithm using a well-known single-solution-based optimization method, i.e., Coordinate Descent (CD) algorithm. Local coordinate search is applied on the promising region resulted by top ranked individuals selected from the final population of DE. The proposed method updates the value of each coordinate iteratively by evaluating the sampled points from the local region to improve the resulted candidate solution. Since coordinate search algorithm shrinks the region rapidly, it requires a very small portion of the computational budget to find the optimal coordinates&#39; value. In order to evaluate the proposed Memetic DE, several experiment series are conducted on functions of CEC-2017 benchmark for different number of dimensions (i.e., D=30, 50, and 100). Results clearly indicate that the utilized local coordinate search improves the quality of resulted solution by DE significantly using a very low computational budget, i.e., 20×D.},
  archive   = {C_CEC},
  author    = {Azam Asilian Bidgoli and Shahryar Rahnamayan},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504762},
  pages     = {359-366},
  title     = {Memetic differential evolution using coordinate descent},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hybrid quantum computing - tabu search algorithm for
partitioning problems: Preliminary study on the traveling salesman
problem. <em>CEC</em>, 351–358. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504923">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Quantum Computing is considered as the next frontier in computing, and it is attracting a lot of attention from the current scientific community. This kind of computation provides to researchers with a revolutionary paradigm for addressing complex optimization problems, offering a significant speed advantage and an efficient search ability. Anyway, Quantum Computing is still in an incipient stage of development. For this reason, present architectures show certain limitations, which have motivated the carrying out of this paper. In this paper, we introduce a novel solving scheme coined as hybrid Quantum Computing - Tabu Search Algorithm. Main pillars of operation of the proposed method are a greater control over the access to quantum resources, and a considerable reduction of non-profitable accesses. To assess the quality of our method, we have used 7 different Traveling Salesman Problem instances as benchmarking set. The obtained outcomes support the preliminary conclusion that our algorithm is an approach which offers promising results for solving partitioning problems while it drastically reduces the access to quantum computing resources. We also contribute to the field of Transfer Optimization by developing an evolutionary multiform multitasking algorithm as initialization method.},
  archive   = {C_CEC},
  author    = {Eneko Osaba and Esther Villar-Rodriguez and Izaskun Oregi and Aitor Moreno-Fernandez-de-Leceta},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504923},
  pages     = {351-358},
  title     = {Hybrid quantum computing - tabu search algorithm for partitioning problems: Preliminary study on the traveling salesman problem},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Designing urban transit network using memetic algorithm.
<em>CEC</em>, 343–350. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504756">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Urban transit network design (UTND) problem represents a challenge in designing routes, with a trade-off between serving passengers and operators benefits. In this study, a Memetic Algorithm (MA) is proposed to solve the UTND problem. The algorithm uses the hill climbing local search (HCLS) algorithm as an additional operator for Genetic Algorithm (GA) to improve routes construction during the global search. The proposed method consists of two phases. In the first phase, a set of solutions (transit network designs) is generated as an initial population for MA, where each solution consists of a set of routes. The predefined set of solutions satisfies the constraints such as route length or number of routes, and requirements like lack of loops, and that all nodes are covered by at least one route. In the second phase, the suggested Memetic Algorithm (MA) is used to generate all possible solutions from the predefined set. The MA tries to find the best structured solution that represents the flawless transit network. The proposed MA is applied on the widely examined benchmark problems: Mandl and Mumford networks. The experiment results show that the suggested MA provides significant improvements in terms of the direct trip percentage and average travel time compared to the previous studies.},
  archive   = {C_CEC},
  author    = {Hanan Ba Ali and Adam Roman},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504756},
  pages     = {343-350},
  title     = {Designing urban transit network using memetic algorithm},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Covariance pattern search with eigenvalue-determined radii.
<em>CEC</em>, 335–342. (<a
href="https://doi.org/10.1109/CEC45853.2021.9505002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Effective implementations of Memetic Algorithms often integrate, within their design, problem-based pieces of information. When no information is known, an efficient MA can still be designed after a preliminary analysis of the problem. This approach is usually referred to as Fitness Landscape Analysis (FLA). This paper proposes a FLA technique to analyse the epistasis of continuous optimisation problems and estimate those directions, within a multi-dimensional space, associated with maximum and minimum directional derivatives. This estimation is achieved by making use of the covariance matrix associated with a distribution of points whose objective function value is below (in case of minimisation) a threshold. The eigenvectors and eigenvalues of the covariance matrix provide important pieces of information about the geometry of the problem and are then used to design a memetic operator that is a local search belonging to the family of generalised Pattern Search. A restarting mechanism enables a progressive characterisation of the fitness landscape. Numerical results show that the proposed approach successfully explore ill-conditioned basins of attractions and outperforms the standard pattern search as well as a pattern search recently proposed in the literature and partially based on a similar design logic. The proposed local search based on FLA also displays a performance competitive with that of other types of local search.},
  archive   = {C_CEC},
  author    = {Ferrante Neri and Yuyang Zhou},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9505002},
  pages     = {335-342},
  title     = {Covariance pattern search with eigenvalue-determined radii},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A memetic algorithm for optimizing inter-links to enhance
the robustness of interdependent networks against malicious attacks.
<em>CEC</em>, 327–334. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504787">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In real life, independent networks exist widely and their robustness has received significant attention. When an interdependent network faces attacks, the failure can propagate along inter-links to the whole network and the damage caused by malicious attacks is more serious. However, in terms of designing the robust inter-links of interdependent networks, most of the existing strategies target at random attacks and make little use of the inner structure of interdependent networks. In this paper, we propose a specific memetic algorithm (MA) for optimizing the inter-links to enhance the robustness of interdependent networks against malicious attacks, termed as MA-RINint. Moreover, we design an effective crossover operator based on retaining the inter-links of adjacent nodes and a local search operator according to the degree of nodes. In the experiments, we compare the proposed algorithm with five existing methods on three types of interdependent networks with different sizes, and the experimental results show that MA-RINint performs excellently in enhancing the robustness of interdependent networks.},
  archive   = {C_CEC},
  author    = {Junyuan Chen and Jing Liu},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504787},
  pages     = {327-334},
  title     = {A memetic algorithm for optimizing inter-links to enhance the robustness of interdependent networks against malicious attacks},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Pattern classification applying neighbourhood component
analysis and swarm evolutionary algorithms: A coupled methodology.
<em>CEC</em>, 319–326. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504702">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this work we present a pattern classification approach coupling the Neighbourhood Component Analysis (NCA) classifier with the Canonical Differential Evolutionary Particle Swarm Optimization (C-DEEPSO). The standard NCA uses the conjugate gradient method to minimize the classification error. Here we propose an approach using the C-DEEPSO instead. In the experimental design, the coupled approach is applied to 20 benchmark data sets, and its performance is compared with the standard NCA using the conjugate gradient. The experimental analysis shows the usage of an evolutionary approach to enhance the performance of a machine learning algorithm can be competitive when compared to well-known iterative optimization techniques, and even outperform them in some problems. A real-world problem classifying cyber-attacks to an industrial control system of gas pipelines is also solved by the proposed approach. The results obtained indicate the proposed approach can successfully identify possible cyber-attacks to the control system. In this way, the NCA coupled to C-DEEPSO can work as an Intrusion Detection Systems (IDS), being able to guarantee an acceptable security level.},
  archive   = {C_CEC},
  author    = {Gabriel M. C. Leite and Carolina G. Marcelino and Elizabeth F. Wanner and Carlos E. Pedreira and Silvia Jiménez-Fernández and Sancho Salcedo-Sanz},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504702},
  pages     = {319-326},
  title     = {Pattern classification applying neighbourhood component analysis and swarm evolutionary algorithms: A coupled methodology},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Increasing accuracy and interpretability of high-dimensional
rules for learning classifier system. <em>CEC</em>, 311–318. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504733">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper proposes ELPSDeCS (Encoding, Learning, &quot;Plausible&quot; Sampling, and Decoding Classifier System) by extending ELSDeCS (Encoding, Learning, Sampling, and Decoding Classifier System) to increase both the accuracy and interpretability of the generated classifiers which matches the high-dimensional input such as images. The experimental results on the complex multi-class classification problem of the handwritten numerals show that both the accuracy and interpretability of ELPSDeCS are higher than that of ELSDeCS.},
  archive   = {C_CEC},
  author    = {Hiroki Shiraishi and Masakazu Tadokoro and Yohei Hayamizu and Yukiko Fukumoto and Hiroyuki Sato and Keiki Takadama},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504733},
  pages     = {311-318},
  title     = {Increasing accuracy and interpretability of high-dimensional rules for learning classifier system},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). XCS with weight-based matching in VAE latent space and
additional learning of high-dimensional data. <em>CEC</em>, 304–310. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504909">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we propose MVN-ELSDeCS, which is a combination of VAE, a dimensionality reduction network, and MVN-XCSR, an XCSR extended to a distributional representation. In addition, additional learning of high-dimensional data with XCS is performed to reduce the information loss in learning caused by dimensionality reduction. We applied the proposed method to the benchmark problem of 10-class classification of handwritten digit images, and the experimental results have the following implications: 1) MVN-XCSR, which is a component of MVN-ELSDeCS, not only shows higher classification performance from the early stage of training in the dimensionally compressed latent space, but also 2) the reconstructed rules generated by MVN-ELSDeCS shows higher classification performance for the original high-dimensional data. Furthermore, 3) by applying additional learning with XCS to the reconstructed rules, the classification accuracy of rules for the 10-class classification task was significantly improved.},
  archive   = {C_CEC},
  author    = {Masakazu Tadokoro and Hiroyuki Sato and Keiki Takadama},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504909},
  pages     = {304-310},
  title     = {XCS with weight-based matching in VAE latent space and additional learning of high-dimensional data},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Constructing complexity-efficient features in XCS with
tree-based rule conditions. <em>CEC</em>, 296–303. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504784">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A major goal of machine learning is to create techniques that abstract away irrelevant information. The generalisation property of standard Learning Classifier Systems (LCSs) removes such information at the feature level but not at the feature interaction level. Code Fragments (CFs), a form of tree-based programs, introduced feature manipulation to discover important interactions, but they often contain irrelevant information, which causes structural inefficiency. XOF is a recently introduced LCS that uses CFs to encode building blocks of knowledge about feature interaction. This paper aims to optimise the structural efficiency of CFs in XOF. We propose two measures to improve constructing CFs to achieve this goal. Firstly, a new CF-fitness update estimates the applicability of CFs to the problem while also considering the structural complexity. The second measure is a niche-based method for generating CFs. These approaches were tested on Even-parity and Hierarchical problems, which require highly complex combinations of input features to capture the data patterns. The results show that the proposed methods significantly increase the structural efficiency of CFs, which is estimated by the rule &quot;generality rate&quot;. This results in faster learning performance in the Hierarchical Majority-on problem. Furthermore, a user-set depth limit for CF generation is not needed as the learning agent will not adopt higher-level CFs once optimal CFs are constructed.},
  archive   = {C_CEC},
  author    = {Trung B. Nguyen and Will N. Browne and Mengjie Zhang},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504784},
  pages     = {296-303},
  title     = {Constructing complexity-efficient features in XCS with tree-based rule conditions},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep learning model with GA-based visual feature selection
and context integration. <em>CEC</em>, 288–295. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504753">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep learning models have been very successful in computer vision and image processing applications. Since its inception, Convolutional Neural Network (CNN)-based deep learning models have consistently outperformed other machine learning methods on many significant image processing benchmarks. Many top-performing methods for image segmentation are also based on deep CNN models. However, deep CNN models fail to integrate global and local context alongside visual features despite having complex multi-layer architectures. We propose a novel three-layered deep learning model that learns independently global and local contextual information alongside visual features, and visual feature selection based on a genetic algorithm. The novelty of the proposed model is that One-vs-All binary class-based learners are introduced to learn Genetic Algorithm (GA) optimized features in the visual layer, followed by the contextual layer that learns global and local contexts of an image, and finally the third layer integrates all the information optimally to obtain the final class label. Stanford Background and CamVid benchmark image parsing datasets were used for our model evaluation, and our model shows promising results. The empirical analysis reveals that optimized visual features with global and local contextual information play a significant role to improve accuracy and produce stable predictions comparable to state-of-the-art deep CNN models.},
  archive   = {C_CEC},
  author    = {Ranju Mandal and Basim Azam and Brijesh Verma and Mengjie Zhang},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504753},
  pages     = {288-295},
  title     = {Deep learning model with GA-based visual feature selection and context integration},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Document clustering with evolved single word search queries.
<em>CEC</em>, 280–287. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504770">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present a novel, hybrid approach for clustering text databases. We use a genetic algorithm to generate and evolve a set of single word search queries in Apache Lucene format. Clusters are formed as the set of documents matching a search query. The queries are optimized to maximize the number of documents returned and to minimize the overlap between clusters (documents returned by more than one query in a set). Optionally, the number of clusters can be specified in advance, which will normally result in an improvement in performance. Not all documents in a collection are returned by any of the search queries in a set, so once the search query evolution is completed a second stage is performed whereby a KNN algorithm is applied to assign all unassigned documents to their nearest cluster. We describe the method and compare effectiveness with other well-known existing systems on 8 different text datasets. We note that search query format has the qualitative benefits of being interpretable and providing an explanation of cluster construction.},
  archive   = {C_CEC},
  author    = {Laurence Hirsch and Alessandro Di Nuovo and Prasanna Haddela},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504770},
  pages     = {280-287},
  title     = {Document clustering with evolved single word search queries},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Genetic algorithm for feature and latent variable selection
for nutrient assessment in horticultural products. <em>CEC</em>,
272–279. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504794">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Vibrational spectroscopy can be used for rapid determination of chemical quality markers in horticultural produce to improve quality control, optimize harvest times and maximize profits. Most commonly, spectral data are calibrated against chemical reference data (acquired using traditional, slower analytical methods) using partial least squares regression (PLSR). However, predictive performance of PLSR can be limited by the small number of instances, high dimensionality and collinearity of spectroscopic data. Here, a new genetic algorithm (GA) for PLSR feature and latent variable selection is proposed to predict concentrations of 18 important bioactive components across three New Zealand horticultural products from infrared, near-infrared and Raman spectral data sets. Models generated using the GA-enhanced PLSR method have notably better generalization and are less complex than the standard PLSR method. GA-enhanced PLSR models are produced from each spectroscopic data set individually, and from a data set that combines all three techniques.},
  archive   = {C_CEC},
  author    = {Demelza Robinson and Qi Chen and Bing Xue and Daniel Killeen and Sara Fraser-Miller and Keith C Gordon and Indrawati Oey and Mengjie Zhang},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504794},
  pages     = {272-279},
  title     = {Genetic algorithm for feature and latent variable selection for nutrient assessment in horticultural products},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Using a genetic algorithm for planning interesting tourist
routes in the city on the basis of open street map data. <em>CEC</em>,
264–271. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504741">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Walking is a good way to get to know a new district or city. However, it may be difficult for a tourist not familiar with the area to choose a route for a walk because they do not know, what places of interest there are nearby. This is especially true for areas unpopular with tourists and not mentioned in guidebooks. But even if attractions are listed there, it can be challenging to think of the best route to see them all. In this case, a special navigation service can help, which is able to build more interesting walking routes rather than shorter ones (as existing popular navigation services do). Such routes may be longer but they include local places of interest, green areas and embankments. The article proposes an algorithm that uses data on places of interest from Open Street Map and applies a modernized A* algorithm as well as a genetic algorithm to build such routes. Creation of two route options is considered: a route between two different points (if the tourist wants to reach a specific destination while seeing some places of interest along the way) and a circular route returning to the starting point in a specified time (e.g., if the tourist wants to walk around the hotel or a train station).},
  archive   = {C_CEC},
  author    = {Egor Smirnov and Sergei Kudinov},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504741},
  pages     = {264-271},
  title     = {Using a genetic algorithm for planning interesting tourist routes in the city on the basis of open street map data},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal production scheduling using a production simulator
by modified brain storm optimization. <em>CEC</em>, 256–263. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504730">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper proposes optimal production scheduling using a practical production simulator and modified brain storm optimization (MBSO). So far, in a production scheduling research area, for the purpose of practical applications, various practical performance measures and constraints have been proposed. Recently, production scheduling researches in consideration of energy consumptions and CO 2 emissions have been conducted. However, in the various production scheduling researches, each research only treats practical performance measures, practical constraints, energy consumptions, and CO 2 emissions partially. Hence, no researches have considered the various practical performance measures and constraints, energy consumptions, and CO 2 emissions totally. In this paper, a production schedule optimization framework is proposed using a production simulator considering constraints that cannot be mathematically formulated. It is verified that the proposed MBSO based method can find higher quality solutions than the conventional PSO and DEEPSO based methods. It is also verified that there is a significant difference among the conventional PSO and DEEPSO based methods, and the proposed MBSO based method with 0.05 significant level using the Friedman test.},
  archive   = {C_CEC},
  author    = {Kenjiro Takahashi and Yoshikazu Fukuyama and Shuhei Kawaguchi and Takaomi Sato},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504730},
  pages     = {256-263},
  title     = {Optimal production scheduling using a production simulator by modified brain storm optimization},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Knowledge embedding-assisted multi-exemplar learning
particle swarm optimization for traffic signal timing optimization.
<em>CEC</em>, 248–255. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504703">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Traffic signal timing optimization (TSTO) has aroused extensive attention, which aims to optimize the signal timing to improve the service capability of intersections. In recent years, particle swarm optimization (PSO) has played a vital role in optimization field. However, the PSO may get stuck in the local optimum when handling TSTO. In this paper, we propose a multi-exemplar learning PSO (MEL-PSO) algorithm, which enhances the exploration capability of the algorithm by letting particles have more opportunities to learn from more exemplars. Moreover, a knowledge embedded solution generating (KESG) strategy is proposed by exploiting the characteristic of input traffic volume distribution as pre-knowledge, which helps MEL-PSO generate an initial population covering promising search space. Furthermore, in order to make MEL-PSO suitable for different kinds of saturation situations of the intersection, we adopt multiple indicators to measure the performance of the signal timing scheme. Comparison experiments for validating the performance of MEL-PSO are carried out on a single intersection in both undersaturated and oversaturated traffic flow conditions. Experimental results show that MEL-PSO outperforms the classic numerical timing method, random timing method, and some other PSO-based algorithms.},
  archive   = {C_CEC},
  author    = {Zhuang-Jie Deng and Liu-Yue Luo and Zhi-Hui Zhan and Jun Zhang},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504703},
  pages     = {248-255},
  title     = {Knowledge embedding-assisted multi-exemplar learning particle swarm optimization for traffic signal timing optimization},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ant colony system based drone scheduling for ship emission
monitoring. <em>CEC</em>, 241–247. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504944">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Emission control area has been set up in many countries to reduce the environmental impact of vessels’ emissions. However, the regulations for controlling emissions are frequently violated due to the cost of high-quality fuel. Drones currently have become an accurate and efficient way to monitor the vessels’ emissions, which should be properly scheduled to cover more and higher risk of violations when facing a large number of vessels. In this paper, a scheduling model is proposed to simulate the drone scheduling monitoring problem. Due to the movement of vessels over time, the complexity of the model is too large to be solved by classical optimization methods such as CPLEX. An ant colony system algorithm is proposed to solve the scheduling problem of drones. Our method is proved to be more effective and efficient when facing a large number of vessels and drone stations in numerical experiments.},
  archive   = {C_CEC},
  author    = {Xiaosong Luo and Zhao-Hui Sun and Siqi Qiu},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504944},
  pages     = {241-247},
  title     = {Ant colony system based drone scheduling for ship emission monitoring},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DSO contract market for demand response using evolutionary
computation. <em>CEC</em>, 233–240. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504987">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this article, a cost optimization problem in local energy markets is analyzed considering fixed-term flexibility contracts between the DSO and aggregators. The DSO procures flexibility while aggregators of different types (e.g., conventional demand response or thermo-load aggregators) offer the service. We solve the proposed model using evolutionary algorithms based on the well-known differential evolution (DE). First, a parameter-tuning analysis is done to assess the impact of the DE parameters on the quality of solutions to the problem. Later, after finding the best set of parameters for the &quot;tuned&quot; DE strategies, we compare their performance with other self-adaptive parameter algorithms, namely the HyDE, HyDE-DF, and vortex search algorithms. Results show that with the identification of the best set of parameters to be used for each strategy, the tuned DE versions lead to better results than the other tested EAs. Overall, the algorithms are able to find near-optimal solutions to the problem and can be considered an alternative solver for more complex instances of the model.},
  archive   = {C_CEC},
  author    = {Eduardo Lacerda and Fernando Lezama and Joao Soares and Zita Vale},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504987},
  pages     = {233-240},
  title     = {DSO contract market for demand response using evolutionary computation},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evolutionary algorithms for energy scheduling under
uncertainty considering multiple aggregators. <em>CEC</em>, 225–232. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504942">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The ever-increasing number of electric vehicles (EVs) circulating on the roads and renewable energy production to achieve carbon footprint reduction targets has brought many challenges to the electrical grid. The increasing integration of distributed energy resources (DER) in the grid is causing severe operational challenges, such as congestion and overloading for the grid. Active management of distribution network using the smart grid (SG) technologies and artificial intelligence (AI) techniques can support the grid&#39;s operation under such situations. Implementing evolutionary computational algorithms has become possible using SG technologies. This paper proposes an optimal day-ahead resource scheduling to minimize multiple aggregators&#39; operational costs in a SG, considering a high DER penetration. The optimization is achieved considering three metaheuristics (DE, HyDE-DF, CUMDANCauchy++). Results show that CUMDANCauchy++ and HyDE-DF present the best overall results in comparison to the standard DE.},
  archive   = {C_CEC},
  author    = {José Almeida and João Soares and Bruno Canizes and Fernando Lezama and Mohammad Ali Ghazvini Fotouhi and Zita Vale},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504942},
  pages     = {225-232},
  title     = {Evolutionary algorithms for energy scheduling under uncertainty considering multiple aggregators},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Effective partial charging scheme for minimizing the energy
depletion and charging cost in wireless rechargeable sensor networks.
<em>CEC</em>, 217–224. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504948">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Wireless Rechargeable Sensor Network has emerged as a potential solution for the constrained energy problem in sensor networks in recent years. The charging process has been employed to prolong the sensor’s lifetime. An effective charging algorithm requires simultaneously optimize the charging path and charging time at each charging location under the Mobile Charger’s limited energy. The existing methods, however, are generally lacking in the literature. Moreover, most works are based on the assumption that Mobile Charger has sufficient or infinite energy to visit and charge all sensors within each charging cycle. This constraint leads to prolonging the waiting charging time of energy-hurry sensors and unnecessary visiting of energy-sufficient sensors. In this paper, we aim at minimizing energy depletion and the charging cost of Mobile Charger in Wireless Rechargeable Sensor Networks without the mentioned limitations above. We first mathematically formulate the investigated problem as mixed integer and linear programming. We propose a novel partial charging scheme based on fuzzy logic and genetic algorithms to determine which sensors should be charged in each cycle and optimize both charging paths and charging time simultaneously. A range of experimental simulations is conducted to demonstrate the effectiveness of our charging scheme. The simulation results show our proposed algorithm’s effectiveness compared to the existing works concerning various performance metrics.},
  archive   = {C_CEC},
  author    = {Tran Thi Huong and Le Van Cuong and Nguyen Ngoc Bao and Ngo Minh Hai and Huynh Thi Thanh Binh},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504948},
  pages     = {217-224},
  title     = {Effective partial charging scheme for minimizing the energy depletion and charging cost in wireless rechargeable sensor networks},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A reactive multi-agent system for self-healing in smart
distribution grids. <em>CEC</em>, 209–216. (<a
href="https://doi.org/10.1109/CEC45853.2021.9505004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In general, conventional power distribution systems lack communication and automation capabilities, making almost impossible the provision of features where self topology reconfiguration is necessary. This scenario can be changed through the emergence of smart grids technologies, where those capabilities are mandatory. An example of feature possible by smart grids technology is the &quot;self-healing&quot;, in other words, the automatic loads restoration of the grid affected by a fault. This paper describes and models a reactive multi-agent system based in smart grid characteristics to provide the self-healing feature. Following a sequence of steps, the modeled multi-agent system managed to perform the network reconfiguration in a decentralized manner, using the tie lines available in the grid. To validate the proposal, 20 different computational simulations scenarios were implemented for two test systems - 33 and 119 bus - defined in the literature. The obtained results presented and discussed in this paper ensure that the approach worked as expected.},
  archive   = {C_CEC},
  author    = {Italo Campos and Filipe Saraiva},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9505004},
  pages     = {209-216},
  title     = {A reactive multi-agent system for self-healing in smart distribution grids},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Compressor schedule optimization for a refrigerated
warehouse using metaheuristic algorithms. <em>CEC</em>, 201–208. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504924">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper investigates the suitability of several metaheuristic algorithms for the problem of compressor schedule optimization for a refrigerated warehouse. A realistic simulator of such a warehouse is used, based on domain knowledge, and tuned to match an actual experimental cooling appliance. The problem consists in finding an on-off sequence for the adopted optimization horizon and time step that minimizes the energy cost while preserving cooling chamber temperature constraints. To enable the application of metaheuristic optimization algorithms, the problem has to be appropriately encoded. Three different encoding schemes have been designed, suited to both binary and continuous optimization methods. Several metaheuristic algorithms known from the literature are used. Most of them deliver solutions considerably better than a common-sense heuristic compressor schedule. Interestingly, the classical genetic algorithm setup, as well as a setup that was applied to a similar problem in prior research, appear not to work well. The best results are achieved for an alternative genetic algorithm configuration, determined by a series of tuning experiments. Comparable results can be also obtained by the IPOP-CMA-ES or PBIL algorithms, which do not require such extensive tuning and may be preferred by practitioners.},
  archive   = {C_CEC},
  author    = {Rafał Biedrzycki and Kamil Kwiatkowski and Paweł Cichosz},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504924},
  pages     = {201-208},
  title     = {Compressor schedule optimization for a refrigerated warehouse using metaheuristic algorithms},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A hybrid multiobjective solution for the short-term
hydro-power dispatch problem: A swarm evolutionary approach.
<em>CEC</em>, 193–200. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504898">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The unit dispatch problem is defined as the attribution of operational values to each generation unit inside a hydro-power plant (HPP), given some criteria such as the total power to be generated, or the operational bounds of each unit. An optimal dispatch programming for hydroelectric units in HPP provides a larger production of electricity, with minimal water use. This paper presents an evolutionary approach to optimize the multi-criteria electric dispatch problem in a general HPP, based on a Multi-objective Evolutionary Swarm Hybridization (MESH) algorithm. The proposed approach integrates mathematical models and evolutionary swarm computation. The experimental analysis shows that the proposed MESH algorithm is able to reach competitive results when compared with classical evolutionary algorithms, the NGA-II and SPEA2 basing on ANOVA inference test. Results also show that the proposed MESH is able to save a large amount of water in the energy production process, supplying the requested load, and minimizing blackout risks and generating a profit around $275,000 monthly.},
  archive   = {C_CEC},
  author    = {Carolina G. Marcelino and Lucas B. de Oliveira and Elizabeth F. Wanner and Carla A. D. M. Delgado and Silvia Jiménez-Fernández and Sancho Salcedo-Sanz},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504898},
  pages     = {193-200},
  title     = {A hybrid multiobjective solution for the short-term hydro-power dispatch problem: A swarm evolutionary approach},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Empirical studies on the role of the decision maker in
interactive evolutionary multi-objective optimization. <em>CEC</em>,
185–192. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504980">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The interactive evolutionary multi-objective optimization (IEMO) algorithms aim to learn and utilize the preference information from the decision maker (DM) during the optimization process to guide the search towards preferred solutions. In this paper, we are devoted to figuring out the effects of interaction patterns, DM calls, preference changes, and DM inconsistencies on the quality of the solutions generated by the IEMO algorithms. The investigation is done in the context of I-MOEA/D-PLVF algorithm, a recently proposed interactive optimization algorithm based on MOEA/D.The experimental results indicate that different interaction patterns and the number of DM calls do result in significant impacts on the quality of the obtained solutions generated by the IEMO algorithm used in our experiments. Meanwhile, preference changes and DM inconsistencies in the process of interactions will impose irreversibly negative effects on obtained solutions.},
  archive   = {C_CEC},
  author    = {Guiyu Lai and Minhui Liao and Ke Li},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504980},
  pages     = {185-192},
  title     = {Empirical studies on the role of the decision maker in interactive evolutionary multi-objective optimization},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MOEA/d using dynamic weight vectors and stable matching
schemes for the deployment of multiple airships in the earth observing
system. <em>CEC</em>, 177–184. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504918">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The utilization of stratosphere in earth observing is getting more attention. For maximizing the usage of stratosphere space, it is of vital importance to deploy the platforms of which airship is the representative, properly. Under such a background, a multiobjective model for the deployment problem of multiple airships in the earth observing system (MOM_DP_MAEOS), considering the number of covered tasks and the total profits of the observable tasks, is designed. Furthermore, a multiobjective evolutionary algorithm based on decomposition (MOEA/D) with dynamic weight vectors (DW) and stable matching (STM) schemes (MOEA/D_DW-STM) is proposed to optimize the deployment problem in this paper. DW is applied in the process of updating the individuals in the neighborhoods, playing the role of assisting local search. STM, including a bi-direction selection process, is designed to overcome the shortage that only the process of choosing solutions to subproblems exists in MOEA/D. Besides, K-means clustering operator applied in the initialization and the normalization operator for balancing the search efforts of each objective are applied. A variety of experiments are carried out on different kinds of benchmarks to verify the effectiveness of MOEA/D_DW-STM and the rationality of MOM_DP_MAEOS. Compared with the original MOEA/D and nondominated sorting genetic algorithm II (NSGA-II), the designed algorithm obtains better Pareto fronts (PF) under the same computational cost.},
  archive   = {C_CEC},
  author    = {Zhouwu Xu and Jing Liu and Baihao Qiao and Yating Cao},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504918},
  pages     = {177-184},
  title     = {MOEA/D using dynamic weight vectors and stable matching schemes for the deployment of multiple airships in the earth observing system},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Approximating pareto optimal set by an incremental learning
model. <em>CEC</em>, 169–176. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504996">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Combining a machine learning model within the search procedure has shown great potentials in evolutionary multiobjective optimization (EMO). The priori knowledge obtained from the property of Pareto optimal set (PS) is a great help for reproducing high-quality offspring solutions. However, the existing learning model in the framework of EMO is also accompanied with a high computational cost resulted from its iterative strategy or repetitive learning. To overcome this shortcoming, the paper proposes to approximate the PS by an incremental learning model. Specifically, it consists of two interdependent parts, i.e., a learning module and a forgetting module. The basic idea is to take the all new high-quality offspring solutions at the current evolution iteration as a data stream, and incrementally train a model based on Gaussian mixture models with the data stream to discover the manifold structure of the PS and guide the evolutionary search. The learning module is used to obtain the knowledge from the data stream in a batch manner, while the forgetting module is applied to delete the information from the relatively poor solution as is removed incrementally. The proposed algorithm is employed to test suites, and the numerical experiments demonstrates that the incremental learning model can help to improve the algorithm performance with less computational cost compared with the representative algorithms.},
  archive   = {C_CEC},
  author    = {Tingrui Liu and Shenmin Song and Xin Li and Liguo Tan},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504996},
  pages     = {169-176},
  title     = {Approximating pareto optimal set by an incremental learning model},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Comparison of adaptive differential evolution algorithms on
the MOEA/d-DE framework. <em>CEC</em>, 161–168. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504997">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Existing works have reported that adaptive differential evolution algorithms, i.e., adaptive DEs, improve the MOEA/D-DE algorithm, but this result is limited to small-scale multi-objective optimization problems. This paper compares four popular adaptive DEs on the MOEA/D-DE framework to evaluate their scalability to the number of decision variables and objectives. Specifically, we employ jDE, JADE, EPSDE, and SaDE in this paper. Our experimental results provide the following novel observations. MOEA/D-DE with JADE derives the best average rank on small-scale problems. However, the performances of MOEA/D-DE with JADE, EPSDE, and SaDE gradually degrade with the increase of the problem scale. In contrast, jDE stably improves the performance of MOEA/D-DE on large-scale problems employed in this paper (i.e., 11 objectives and 100 decision variables). Thus, we find a critical tradeoff among adaptive DEs in terms of the scalability of the MOEA/D-DE framework; a statistical adaption like JADE is suitable for small-scale problems, but a randomization adaptation like jDE is effective with the increase of the problem scale. Our results also suggest that parameter-only adaptation can be suitable for MOEA/D-DE regardless of the problem scale.},
  archive   = {C_CEC},
  author    = {Kei Nishihara and Masaya Nakata},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504997},
  pages     = {161-168},
  title     = {Comparison of adaptive differential evolution algorithms on the MOEA/D-DE framework},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A competition-cooperation evolutionary algorithm with
bidirectional multi-population local search and local hypervolume-based
strategy for multi-objective optimization. <em>CEC</em>, 153–160. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504689">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper proposes a competition-cooperation algorithm with bidirectional multi-population local search and local hypervolume-based strategy (CCLS) to solve multi-objective optimization problems. In the proposed method, a bidirectional multi-population local search is devised and used to speed up convergence while keeping rich population diversity. It searches along two completely opposite directions, and adopts a unique strategy to perform replacement operation. Furthermore, a local hypervolume-based strategy has been designed. It combines Pareto dominance relation with hypervolume indicator to maintain population diversity. The proposed algorithm is applied to the widely used bi-objective and tri-objective test problems, and compared with related methods. The results demonstrate that the proposed algorithm generally outperforms related methods.},
  archive   = {C_CEC},
  author    = {Shenghao Zhou and Zuling Wang and Tingting Pang and Jing Wei and Ze Chen},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504689},
  pages     = {153-160},
  title     = {A competition-cooperation evolutionary algorithm with bidirectional multi-population local search and local hypervolume-based strategy for multi-objective optimization},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). A new diversity performance indicator for many-objective
optimisation problems. <em>CEC</em>, 144–152. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504903">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Current performance indicators for assessing the diversity of many-objective optimisation approximations are often underperforming as the number of objectives increases, particularly for complex optimisation problems. In this article, a new pure unary diversity indicator is proposed, Inverse Ratio of Net Avertence angle (IRNA), which is formulated by minimising the sum of the included angles between approximation set and a set of reference vectors. It is achieved by effectively rotating the reference vectors system in all dimensions simultaneously with an optimised spatial angle. Any potential systematic bias in included angles is removed, and the highest possible diversity score of a solution set is obtained. Numerical results from evaluating performance on synthetic solutions on a unit simplex plane and benchmark functions of MaF show that the proposed performance indicator IRNA is more sensitive to capturing diversity changes as the number of objectives increases compared to other popular indicators.},
  archive   = {C_CEC},
  author    = {Kai Eivind Wu and George Panoutsos},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504903},
  pages     = {144-152},
  title     = {A new diversity performance indicator for many-objective optimisation problems},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic optimal power flow based on a spatio-temporal wind
speed forecast model. <em>CEC</em>, 136–143. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504847">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With large wind energy penetration to power grid, power system operation has become more complex due to the intermittency of wind. For an efficient operation of wind energy, accurate wind speed forecast is in urgent need. Here, a statistical wind speed forecast model is proposed which considers the spatial and temporal correlations in wind speed and wind direction among geographically dispersed wind farms. Then the forecast model was incorporated in the one-day ahead dynamic optimal power flow for power system operation. Dynamic optimal power flow is a highly non-linear and non-convex with large control variable optimization problem. Modern heuristic optimization techniques have proven their efficiency and robustness to such problem, so this work focuses on a novel heuristic method, artificial bee colony. The original artificial bee colony was modified in this work for dynamic optimization. The forecast model has been verified by comparing with actual wind speed. Several case studies are implemented on a modified IEEE 30-bus system to verify the performances.},
  archive   = {C_CEC},
  author    = {Wenlei Bai and Xinxin Zhu and Kwang Y. Lee},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504847},
  pages     = {136-143},
  title     = {Dynamic optimal power flow based on a spatio-temporal wind speed forecast model},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Improving evolutionary algorithms by enhancing an
approximative fitness function through prediction intervals.
<em>CEC</em>, 127–135. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504722">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Evolutionary algorithms are a successful application of bio-inspired behaviour in the field of Artificial Intelligence. Transferring mechanisms such as selection, mutation, and recombination, evolutionary algorithms are capable of surmounting the disadvantages of traditional methods. Adjusting an evolutionary algorithm to a specific problem requires both, a good understanding of the problem and deep knowledge of the effects of choosing one or another operator in the algorithm. This becomes an especially difficult task when the fitness function is not analytically given - that is, exists only as an approximation, that is highly dependent on the present training data. We propose using prediction intervals to modify the fitness function such, that worse fitness values are less penalized if they occur in a poorly fitted area. We evaluate this with an example from material sciences as well as four standard benchmark algorithms for evolutionary algorithms using a Support Vector Regression for training the approximative fitness function and find that our approach outperforms the naive approximative function.},
  archive   = {C_CEC},
  author    = {Christina Plump and Bernhard J. Berger and Rolf Drechsler},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504722},
  pages     = {127-135},
  title     = {Improving evolutionary algorithms by enhancing an approximative fitness function through prediction intervals},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Historical information-based differential evolution for
dynamic optimization problem. <em>CEC</em>, 119–126. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504965">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Dynamic optimization problems (DOP) widely exist in many application fields and remain a challenge. The multi-population evolutionary computation approach is an efficient framework for solving the DOPs. The key issue of the multi-population approach is how to efficiently generate subpopulations in new environment by well reusing historical information in past environments. However, most existing works try to divide the population into small ones merely considering the individuals&#39; distribution, which may have the limitation that the partition leads to the unbalanced computational resources allocation among subpopulations. To address this limitation, we propose a historical information-based differential evolution (HIDE) to effectively solve the DOP. Firstly, a region-based subpopulation initialization (RSI) strategy is proposed to generate multiple subpopulations in the new environment in a balanced way. By initializing multiple subpopulations in different regions of the search space, the diversity of the population is enhanced, which is helpful to solve the DOP with multiple peaks. Secondly, to fully make use of the found peaks of the previous environments, an archive-based historical information reuse (AHIR) strategy is put forward to manage and reuse the historical information to guide the search in the new environment. Experiments have been carried out on the moving peaks benchmark (MPB), which is a commonly used DOP test suite. Experimental results show that the proposed HIDE algorithm generally outperforms the classic DE algorithms with different parameter settings and some existing competitive state-of-the-art DOP approaches.},
  archive   = {C_CEC},
  author    = {Sheng-Hao Wu and Ke-Jing Du and Zhi-Hui Zhan and Hua Wang and Jun Zhang},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504965},
  pages     = {119-126},
  title     = {Historical information-based differential evolution for dynamic optimization problem},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel scalable framework for constructing dynamic
multi-objective optimization problems. <em>CEC</em>, 111–118. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504961">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Modeling dynamic multi-objective optimization problems (DMOPs) has been one of the most challenging tasks in the field of dynamic evolutionary optimization. Based on the analysis of the existing DMOPs, several features widely existed in real-world applications are not taken into account: different objectives may have different function models and variables to be optimized; and the number of conflicting variables should be independent from the number of objectives; the time-linkage property is not considered. In order to overcome the above issues, a novel framework for constructing DMOPs is proposed, where all objectives can be designed independently, and the number of the conflicting variables can be tuned by users. Moreover, it is easy to add new dynamic features to this framework. Several classical dynamic multi-objective optimization algorithms are tested on four scenarios, results show that these characteristics are challenging for the existing algorithms.},
  archive   = {C_CEC},
  author    = {Qingshan Tan and Changhe Li and Hai Xia and Sanyou Zeng and Shengxiang Yang},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504961},
  pages     = {111-118},
  title     = {A novel scalable framework for constructing dynamic multi-objective optimization problems},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improved population prediction strategy for dynamic
multi-objective optimization algorithms using transfer learning.
<em>CEC</em>, 103–110. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504877">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Many real-world optimization problems have dynamic multiple objectives and constrains, such problems are called dynamic multi-objective optimization problems (DMOPs). Although many dynamic multi-objective evolutionary algorithms (DMOEAs) have been proposed to solve DMOPs, how to effectively track the optimal solutions in dynamic environments is still a major challenge for dynamic multi-objective optimization. Two classical DMOEAs, population prediction strategy (PPS) and transfer learning based DMOEA (Tr-DMOEA) are validated to have great performance because they integrate machine learning mechanism for optimization. However, there are still some disadvantages in both algorithms. In this paper, we propose a combined algorithm to make up the respective disadvantages of PPS and Tr-DMOEA. Our algorithm retains the prediction method of PPS considering sufficient historical information. Then, we improve the prediction strategy in Tr-DMOEA to further modify the solutions provided by PPS. These modified solutions finally construct the initial population for optimization in the new environment. The experiment results indicate that our algorithm has the overall best performance comparing with PPS and Tr-DMOEA on the test problems.},
  archive   = {C_CEC},
  author    = {Zhening Liu and Handing Wang},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504877},
  pages     = {103-110},
  title     = {Improved population prediction strategy for dynamic multi-objective optimization algorithms using transfer learning},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Solving dynamic many-objective TSP using NSGA-III equipped
with SVR-RBF kernel predictor. <em>CEC</em>, 95–102. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504966">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Dynamic multi-objective TSP (DMTSP) finds extensive applications in scheduling and routing problems. The task is challenging due to the change in problem environment (arrangement and number of cities) after certain time period. To solve this, in this manuscript a new prediction based dynamic multi-objective optimization method termed as Dynamic non-dominated sorting genetic algorithm III (DNSGA-III) is proposed. This approach reuses the information obtained from previous Pareto optimal sets (POS) to train prediction models. The prediction has been carried out with SVR-RBF, SVR-Linear, polynomial interpolation and cubic spline based prediction approaches and to determine new solutions that are closer to the reference points. This significantly promote population diversity, along with desired convergence. Performance of the proposed DNSGA-III approach has been validated on four benchmark JY test problems. Further a sixteen cities DMTSP problem with two objective functions is solved using the proposed algorithm.},
  archive   = {C_CEC},
  author    = {Rashi Gupta and Satyasai Jagannath Nanda},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504966},
  pages     = {95-102},
  title     = {Solving dynamic many-objective TSP using NSGA-III equipped with SVR-RBF kernel predictor},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A two-level genetic algorithm for inter-domain path
computation under node-defined domain uniqueness constraints.
<em>CEC</em>, 87–94. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504728">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent years have witnessed an increment in the number of network components communicating through many network scenarios such as multi-layer and multi-domain, and it may result in a negative impact on resource utilization. An urgent requirement arises for routing the packets most efficiently and economically in large multi-domain networks. In tackling this complicated area, we consider the Inter-Domain Path Computation problem under Node-defined Domain Uniqueness Constraint (IDPC-NDU), which intends to find the minimum routing cost path between two nodes that traverses every domain at most once. Owing to the NP-Hard property of the IDPC-NDU, applying metaheuristic algorithms to solve this problem usually proves more efficient. In like manner, this paper proposes a Two-level Genetic Algorithm (PGA), where the first level determines the order of the visited domains, and the second level finds the shortest path between the two given nodes. Furthermore, to facilitate the finding process, a method to minimize the search space and a new chromosome encoding that would reduce the chromosome length to the number of domains are integrated into this proposed algorithm. To evaluate the efficiency of the proposal, experiments on various instances were conducted. The results demonstrated that PGA outperforms other algorithms and gives results no more than twice the optimal values.},
  archive   = {C_CEC},
  author    = {Do Tuan Anh and Huynh Thi Thanh Binh and Nguyen Hoang Long and Ta Bao Thang and Su Simon},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504728},
  pages     = {87-94},
  title     = {A two-level genetic algorithm for inter-domain path computation under node-defined domain uniqueness constraints},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). GaCNN: Composing CNNs and GAs to build an optimized hybrid
classification architecture. <em>CEC</em>, 79–86. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504850">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Convolutional Neural Networks (CNN) are considered the gold standard for Computer Vision Problems. However, finding the best architecture for CNN often requires handcrafted design and domain knowledge. On the other hand, Genetic Algorithms (GAs) have proven to be an efficient technique to optimize a wide range of problems. Thus, in this paper, we propose the gaCNN, a hybrid classification architecture composed of a CNN and a GA. The gaCNN utilizes heterogeneous activation functions to classify images, optimizing its hyperparameters and activation functions automatically, regardless of the analyzed dataset. The results show that gaCNN is able to identify good architectures. For the Fashion MNIST dataset, the gaCNN obtained, as best accuracy, 93.73\%, better than 9 of 13 compared classifiers. For the MNIST Handwritten dataset, the gaCNN obtained, as best accuracy, 99.14\%, better than 12 of 16 classifiers.},
  archive   = {C_CEC},
  author    = {Raphael de Lima Mendes and Alexandre Henrick da Silva Alves and Matheus de Souza Gomes and Pedro Luiz Lima Bertarini and Laurence Rodrigues do Amaral},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504850},
  pages     = {79-86},
  title     = {GaCNN: Composing CNNs and GAs to build an optimized hybrid classification architecture},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A sample-efficiency comparison between evolutionary
algorithms and deep reinforcement learning for path planning in an
environmental patrolling mission. <em>CEC</em>, 71–78. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504864">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {For water environmental monitoring tasks, the use of Autonomous Surface Vehicles has been a very common option to substitute human interaction and increase the efficiency and speed in the water quality measuring process. This task requires an optimization of the trajectories of the vehicle following a non-homogeneous interest coverage criterion which is a hard optimization problem. This issue is aggravated whenever the resolution of the water resource to be monitored scales up. Since two of the preferred approaches for path planning of autonomous vehicles in the literature are Evolutionary Algorithms and Reinforcement Learning, in this paper, We compare the performance of both techniques in a simulator of Ypacarai Lake in Asunción (Paraguay). The results show that the evolutionary approach is 50\% more efficient for the lowest resolution but scales badly. Regarding the learning stability and sparsity of the trajectory optimality, the Double Deep Q-Learning algorithm has better convergence, but it appears to be less robust than the evolutionary approach. Finally, in a generalization analysis, the Deep Learning approach proves to be 35\% more effective in reacting to scenario changes.},
  archive   = {C_CEC},
  author    = {Samuel Yanes Luis and Federico Peralta Samaniego and Daniel Gutiérrez Reina and Sergio Toral Marín},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504864},
  pages     = {71-78},
  title     = {A sample-efficiency comparison between evolutionary algorithms and deep reinforcement learning for path planning in an environmental patrolling mission},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Genetic algorithm performance and the influence of its
control parameters on the optimization of optical lens design.
<em>CEC</em>, 65–70. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504778">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {One of the major challenges in optical lens design is to ascertain the lens system with the highest image quality. The image quality of the lens system, which is a measure of the performance of the lens, is a function of aberrations. This function is highly nonlinear and leads to the presence of multiple local minima in the design (optimization) landscape. Evolutionary algorithms, specifically Genetic Algorithm, are receiving attention in this field as an efficient global optimization techniques for multi variables and nonlinear objective functions. However, to the best of our knowledge, studies are as yet unavailable to provide an analysis on the performance of GA and the influence of its tuning parameters on the optimization of these systems. Our research has been conducted to supply such information and to provide a guideline on using GA, in GA-aided optical lens designs. The performance of GA has been investigated in a general group of three-lens systems. It is shown that GA is an efficient optimization technique in this field, while applying the suitable tuning parameters of GA is crucial. It has been realized that Gaussian Mutation (Scale of 0.5), combined with Heuristic Crossover, with a Crossover Fraction of 0.6, was the option which yielded good (i.e. the challengeable practically expected) results. However, any variation of these parameters may prevent the system from ever reaching an optimal configuration.},
  archive   = {C_CEC},
  author    = {N. Hesam Mahmoudi Nezhad and M. Ghaffarian Niasar},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504778},
  pages     = {65-70},
  title     = {Genetic algorithm performance and the influence of its control parameters on the optimization of optical lens design},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An ant colony optimisation inspired crossover operator for
permutation type problems. <em>CEC</em>, 57–64. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504893">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Meta-heuristic methods are commonly applied to difficult permutation type problems such as the Traveling Salesman Problem (TSP). Genetic Algorithms (GA) and Ant Colony Optimisation (ACO) are two of the most successful methods. However, a GA requires specialist crossover operators for permutation problems to avoid repetition. This paper presents a novel crossover operator, ACOX, inspired by ACO which can essentially combine both meta-heuristic methods. When applied to a range of TSP instances the ACOX crossover method demonstrates considerable improvements over standard GA crossover operators. ACOX is able to achieve solutions within 4\% of the optimal for TSP instances of several thousand cities without using any local search methodologies.},
  archive   = {C_CEC},
  author    = {Darren M. Chitty},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504893},
  pages     = {57-64},
  title     = {An ant colony optimisation inspired crossover operator for permutation type problems},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A genetic algorithm to optimize penstocks for micro-hydro
power plants. <em>CEC</em>, 49–56. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504994">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A Micro Hydropower Plant (MHPP) is a suitable and effective mean to provide electric power to rural remote communities without harming the environment. However, the lack of resources and technical training in these communities frequently leads to designs based of rules of thumb, compromising both the generation capacity and efficiency. This work makes an attempt to address this problem developing a new tool to design the layout of MHPP. The tool relies on a discrete topographic survey of the terrain and makes use of a Genetic Algorithm (GA) to optimize the installation layout, making it possible to explicitly incorporate needs and constraints such as power supply requirement, cost of the installation, available water flow, and layout feasibility in accordance with the real terrain profile. The algorithm is applied to a real scenario in a remote community in Honduras, demonstrating its capability to optimize these kind of installations.},
  archive   = {C_CEC},
  author    = {Alejadro Tapia Córdoba and Álvaro Rodríguez del Nozal and Daniel Gutiérrez Reina and Pablo Millán Gata},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504994},
  pages     = {49-56},
  title     = {A genetic algorithm to optimize penstocks for micro-hydro power plants},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive differential evolution based on exploration and
exploitation control. <em>CEC</em>, 41–48. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504876">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Search operator design and parameter tuning are essential parts of algorithm design. However, they often involve trial-and-error and are very time-consuming. A new differential evolution (DE) algorithm with adaptive exploration and exploitation control (AEEC-DE) is proposed in this work to tackle this challenge. The proposed method improves the performance of DE by automatically selecting trial vector generation strategies (both mutation and crossover operators) and dynamically generating the associated control parameter values. A probability-based exploration and exploitation measurement is introduced to estimate whether the state of each newly generated individual is in exploration or exploitation. The state of historical individuals is used to assess the exploration and exploitation capabilities of different generation strategies and parameter values. Then, the strategies and parameters of DE are adapted following the common belief that evolutionary algorithms (EAs) should start with exploration and then gradually change into exploitation. The performance of AEEC-DE is evaluated through experimental studies on a set of test problems and compared with several state-of-the-art adaptive DE variants.},
  archive   = {C_CEC},
  author    = {Hao Bai and Changwu Huang and Xin Yao},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504876},
  pages     = {41-48},
  title     = {Adaptive differential evolution based on exploration and exploitation control},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A differential evolution with multi-factor ranking based
parameter adaptation for global optimization. <em>CEC</em>, 33–40. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504838">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The performance of differential evolution (DE) algorithm depends critically on the setting of mutation factor F and crossover rate CR. In this paper, a multi-factor ranking based parameter adaptation scheme is proposed to properly set the value of F and CR. The proposed adaptation scheme includes a parameter storage and distribution mechanism. The parameter storage mechanism is used to produce a suitable value by considering the multi-factor ranking scheme, which can help the algorithm enhance its exploration ability in the early stage. The parameter distribution mechanism is a layered parameter calculation strategy, in which the individuals generate new parameters based on multi-factor ranking properties. This mechanism is helpful to improve the exploitation capability of DE. The performance of the proposed method has been evaluated on CEC2014 and CEC2015 test suites and compared with related methods. The results show our method could achieve good performance and outperform related methods.},
  archive   = {C_CEC},
  author    = {Jing Wei and Zuling Wang and Yangyan Xu and Ze Chen},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504838},
  pages     = {33-40},
  title     = {A differential evolution with multi-factor ranking based parameter adaptation for global optimization},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An integrated differential evolution-based heuristic method
for product family design problem. <em>CEC</em>, 25–32. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504926">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Increases in demand for a greater variety of products help companies gain more shares of growing competitive markets but, in contrast, lead to an increase in production processes and, therefore, higher costs and longer lead times. Although several techniques for platform formations and assembly lines have been introduced to enable more varieties of goods to be produced, this also makes a system more complex and less cost-efficient. This paper proposes a differential evolution (DE) approach that incorporates a new heuristic method, improved solution representation and enhanced crossover and mutation operators for solving the modular-based product family design problem in a reconfigurable manufacturing system. The heuristic is applied to repair some solutions in the initial population by replacing eligible components with packages to provide near-optimal solutions in the initial stage and enable DE to find the optimal solution quickly. The proposed crossover is designed to further use the repaired solutions to produce new individuals with better qualities. Finally, a case study of a kettle family is conducted to validate this heuristic method, with the experimental results showing that it saves 57.5\% of the purchasing costs of components and, on average, 41.35\% of setup costs compared with those of median-joining phylogenetic network- and non-platform-based heuristics. Moreover, the proposed DE achieves improved performances with average errors of 63.34\% and 38.52\% from those of the standard versions of DE and a genetic algorithm, respectively, in terms of the total production costs of producing the same variants.},
  archive   = {C_CEC},
  author    = {Ismail M. Ali and Hasan H. Turan and Ripon K. Chakrabortty and Sondoss Elsawah and Michael J. Ryan},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504926},
  pages     = {25-32},
  title     = {An integrated differential evolution-based heuristic method for product family design problem},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An adaptive differential evolution algorithm utilizing
failure information and success information. <em>CEC</em>, 17–24. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504715">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Differential Evolution (DE) has been successfully applied to a variety of optimization problems. The performance of DE is affected by two algorithm parameters of the scaling factor and the crossover rate. Much research has been done in order to adaptively control the parameters. One of the most successful studies on adaptive parameter control is JADE, where the two parameter values are generated according to two probability distributions which are tuned by the parameter values in success cases. In this paper, we propose a new method that utilizes not only success information but also failure information. A measure, which indicates how much the pair of generated parameter values will lead to failure, is defined. The pair is rejected probabilistically according to the measure and a new pair is regenerated until a good pair is generated. The effect of the proposed method is shown by solving various benchmark problems.},
  archive   = {C_CEC},
  author    = {Tetsuyuki Takahama and Setsuko Sakai},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504715},
  pages     = {17-24},
  title     = {An adaptive differential evolution algorithm utilizing failure information and success information},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Is algebraic differential evolution really a differential
evolution scheme? <em>CEC</em>, 9–16. (<a
href="https://doi.org/10.1109/CEC45853.2021.9504692">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Algebraic Differential Evolution (ADE) is a recently proposed combinatorial evolutionary scheme which mimics the behaviour of the classical Differential Evolution (DE) in discrete search spaces which can be represented as finitely generated groups. ADE has been successfully applied to both permutation and binary optimization problems. However, in the previous works, the relationship between ADE and the classical continuous DE has been only intuitively sketched without any theoretical or experimental proof. Here, we fill this gap by providing both theoretical and experimental justifications proving that ADE is a full-fledged generalization of DE which works across different search spaces. First, we formally prove that there exists a concrete implementation of ADE&#39;s algebraic operations converging to the classical vector operations of DE, then we propose a real-vector implementation of ADE and we experimentally prove that its behaviour is statistically equivalent to DE. As conclusion, we also pave the way for further applications of the original DE idea to mixed discrete/continuous search spaces.},
  archive   = {C_CEC},
  author    = {Valentino Santucci},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504692},
  pages     = {9-16},
  title     = {Is algebraic differential evolution really a differential evolution scheme?},
  year      = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning to mutate for differential evolution. <em>CEC</em>,
1–8. (<a href="https://doi.org/10.1109/CEC45853.2021.9504990">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Adaptive parameter control and mutation operator selection are two important research avenues in differential evolution (DE). Existing works consider the two avenues independently. In this paper, we propose to unify the two modules and develop a unified parameterized mutation operator. With different settings of the parameters, different mutation operators can be retrieved. Further, the settings of the parameters closely relate to the control parameters of the DE. By determining the parameters we can achieve adaptive parameter control and mutation operator selection simultaneously. We propose to use a neural network to output the parameters and learn the network parameter by the natural evolution strategies algorithm under the consideration of modeling the evolution process as a Markov Decision Process. Experimental results on the CEC 2018 test suite show that the proposed method performs significantly better than traditional DEs with different operators and an advanced adaptive DE. We further analyze the time complexity and population diversity of the proposed method. The analysis shows that our method can achieve a balanced exploration and exploitation with a properly learned network.},
  archive   = {C_CEC},
  author    = {Haotian Zhang and Jianyong Sun and Zongben Xu},
  booktitle = {2021 IEEE Congress on Evolutionary Computation},
  doi       = {10.1109/CEC45853.2021.9504990},
  pages     = {1-8},
  title     = {Learning to mutate for differential evolution},
  year      = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
