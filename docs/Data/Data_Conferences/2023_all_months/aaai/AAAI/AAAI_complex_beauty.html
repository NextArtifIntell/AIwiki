<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>AAAI_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="aaai---2021">AAAI - 2021</h2>
<ul>
<li><details>
<summary>
(2023). An online presentation slide assessment system using visual
and semantic segmentation features. <em>AAAI</em>, 16494–16496. (<a
href="https://doi.org/10.1609/aaai.v37i13.27090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this study, we present a new presentation slide assessment system that can extract the structural features from any slide file formats. Our previous work used a neural network to identify novice vs. well-designed presentation slides based on visual and structural features. However, the structural feature extraction was only applicable to PowerPoint files. To solve this problem, we extract the semantic segmentation from the slide images as a new format of structural features. The proposed multi-modal Transformer extracts the features from the original images and semantic segmentation results to assess the slide design. The prediction targets are the top-10 checkpoints pointed out by the professional consultants. Class-imbalanced learning and multi-task learning methods are also applied to improve the accuracy. The proposed model only requiring the slide images achieved an average accuracy of 81.67\% that is comparative to the performance of the previous work requiring the PowerPoint files.},
  archive   = {C_AAAI},
  author    = {Shengzhou Yi and Junichiro Matsugami and Hiroshi Yumoto and Toshihiko Yamasaki},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27090},
  pages     = {16494-16496},
  title     = {An online presentation slide assessment system using visual and semantic segmentation features},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CLUE-AD: A context-based method for labeling unobserved
entities in autonomous driving data. <em>AAAI</em>, 16491–16493. (<a
href="https://doi.org/10.1609/aaai.v37i13.27089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Generating high-quality annotations for object detection and recognition is a challenging and important task, especially in relation to safety-critical applications such as autonomous driving (AD). Due to the difficulty of perception in challenging situations such as occlusion, degraded weather, and sensor failure, objects can go unobserved and unlabeled. In this paper, we present CLUE-AD, a general-purpose method for detecting and labeling unobserved entities by leveraging the object continuity assumption within the context of a scene. This method is dataset-agnostic, supporting any existing and future AD datasets. Using a real-world dataset representing complex urban driving scenes, we demonstrate the applicability of CLUE-AD for detecting unobserved entities and augmenting the scene data with new labels.},
  archive   = {C_AAAI},
  author    = {Ruwan Wickramarachchi and Cory Henson and Amit Sheth},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27089},
  pages     = {16491-16493},
  title     = {CLUE-AD: A context-based method for labeling unobserved entities in autonomous driving data},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AnoViz: A visual inspection tool of anomalies in
multivariate time series. <em>AAAI</em>, 16488–16490. (<a
href="https://doi.org/10.1609/aaai.v37i13.27088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper presents AnoViz, a novel visualization tool of anomalies in multivariate time series, to support domain experts and data scientists in understanding anomalous instances in their systems. AnoViz provides an overall summary of time series as well as detailed visualizations of relevant detected anomalies in both query and stream modes, rendering near real-time visual analysis available. Here, we show that AnoViz streamlines the process of finding a potential cause of an anomaly with a deeper analysis of anomalous instances, giving explainability to any anomaly detector.},
  archive   = {C_AAAI},
  author    = {Patara Trirat and Youngeun Nam and Taeyoon Kim and Jae-Gil Lee},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27088},
  pages     = {16488-16490},
  title     = {AnoViz: A visual inspection tool of anomalies in multivariate time series},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CodeStylist: A system for performing code style transfer
using neural networks. <em>AAAI</em>, 16485–16487. (<a
href="https://doi.org/10.1609/aaai.v37i13.27087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Code style refers to attributes of computer programs that affect their readability, maintainability, and performance. Enterprises consider code style as important and enforce style requirements during code commits. Tools that assist in coding style compliance and transformations are highly valuable. However, many key aspects of programming style transfer are difficult to automate, as it can be challenging to specify the patterns required to perform the transfer algorithmically. In this paper, we describe a system called CodeStylist which uses neural methods to perform style transfer on code.},
  archive   = {C_AAAI},
  author    = {Chih-Kai Ting and Karl Munson and Serenity Wade and Anish Savla and Kiran Kate and Kavitha Srinivas},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27087},
  pages     = {16485-16487},
  title     = {CodeStylist: A system for performing code style transfer using neural networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Task2KB: A public task-oriented knowledge base.
<em>AAAI</em>, 16482–16484. (<a
href="https://doi.org/10.1609/aaai.v37i13.27086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Search engines and conversational assistants are commonly used to help users complete their every day tasks such as booking travel, cooking, etc. While there are some existing datasets that can be used for this purpose, their coverage is limited to very few domains. In this paper, we propose a novel knowledge base, ‘Task2KB’, which is constructed using data crawled from WikiHow, an online knowledge resource offering instructional articles on a wide range of tasks. Task2KB encapsulates various types of task-related information and attributes, such as requirements, detailed step description, and available methods to complete tasks. Due to its higher coverage compared to existing related knowledge graphs, Task2KB can be highly useful in the development of general purpose task completion assistants.},
  archive   = {C_AAAI},
  author    = {Procheta Sen and Xi Wang and Ruiqing Xu and Emine Yilmaz},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27086},
  pages     = {16482-16484},
  title     = {Task2KB: A public task-oriented knowledge base},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Demo alleviate: Demonstrating artificial intelligence
enabled virtual assistance for telehealth: The mental health case.
<em>AAAI</em>, 16479–16481. (<a
href="https://doi.org/10.1609/aaai.v37i13.27085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {After the pandemic, artificial intelligence (AI) powered support for mental health care has become increasingly important. The breadth and complexity of significant challenges required to provide adequate care involve: (a) Personalized patient understanding, (b) Safety-constrained and medically validated chatbot patient interactions, and (c) Support for continued feedback-based refinements in design using chatbot-patient interactions. We propose Alleviate, a chatbot designed to assist patients suffering from mental health challenges with personalized care and assist clinicians with understanding their patients better. Alleviate draws from an array of publicly available clinically valid mental-health texts and databases, allowing Alleviate to make medically sound and informed decisions. In addition, Alleviate&#39;s modular design and explainable decision-making lends itself to robust and continued feedback-based refinements to its design. In this paper, we explain the different modules of Alleviate and submit a short video demonstrating Alleviate&#39;s capabilities to help patients and clinicians understand each other better to facilitate optimal care strategies.},
  archive   = {C_AAAI},
  author    = {Kaushik Roy and Vedant Khandelwal and Raxit Goswami and Nathan Dolbir and Jinendra Malekar and Amit Sheth},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27085},
  pages     = {16479-16481},
  title     = {Demo alleviate: demonstrating artificial intelligence enabled virtual assistance for telehealth: the mental health case},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). KnowGL: Knowledge generation and linking from text.
<em>AAAI</em>, 16476–16478. (<a
href="https://doi.org/10.1609/aaai.v37i13.27084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose KnowGL, a tool that allows converting text into structured relational data represented as a set of ABox assertions compliant with the TBox of a given Knowledge Graph (KG), such as Wikidata. We address this problem as a sequence generation task by leveraging pre-trained sequence-to-sequence language models, e.g. BART. Given a sentence, we fine-tune such models to detect pairs of entity mentions and jointly generate a set of facts consisting of the full set of semantic annotations for a KG, such as entity labels, entity types, and their relationships. To showcase the capabilities of our tool, we build a web application consisting of a set of UI widgets that help users to navigate through the semantic data extracted from a given input text. We make the KnowGL model available at https://huggingface.co/ibm/knowgl-large.},
  archive   = {C_AAAI},
  author    = {Gaetano Rossiello and Md. Faisal Mahbub Chowdhury and Nandana Mihindukulasooriya and Owen Cornec and Alfio Massimiliano Gliozzo},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27084},
  pages     = {16476-16478},
  title     = {KnowGL: Knowledge generation and linking from text},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Prototyping logic-based AI services with LogicUS.
<em>AAAI</em>, 16473–16475. (<a
href="https://doi.org/10.1609/aaai.v37i13.27083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Currently, there is renewed interest in logic-related solutions for AI and Computer Science. The availability of software tools to support the realization of such studies (both as powerful and versatile prototyping tools and as teaching tools) has become a necessity. Intending to contribute to this field, we present a tool that allows the unification of different logic tasks, focused on Computer Logic but adaptable to the treatment in several subfields, contexts, and abstraction levels (LogicUS-LIB, LogicUS-NB, LogicUS-GUI). The tool provides a sound framework for two activity fields. On the one hand, in the topic of logic-based systems research, prototyping is facilitated in a relatively fast, simple, and highly adaptable way. On the other hand, in Education, by allowing the student to abstract from low-level execution of algorithms whilst preserving the conceptual structures and procedural methodologies underlying the logical foundations.},
  archive   = {C_AAAI},
  author    = {Víctor Ramos-González and Joaquín Borrego-Díaz and Fernando Sancho-Caparrini},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27083},
  pages     = {16473-16475},
  title     = {Prototyping logic-based AI services with LogicUS},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). NBIIG: A neural BI insights generation system for table
reporting. <em>AAAI</em>, 16470–16472. (<a
href="https://doi.org/10.1609/aaai.v37i13.27082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present nBIIG, a neural Business Intelligence (BI) Insights Generation system. Given a table, our system applies various analyses to create corresponding RDF representations, and then uses a neural model to generate fluent textual insights out of these representations. The generated insights can be used by an analyst, via a human-in-the-loop paradigm, to enhance the task of creating compelling table reports. The underlying generative neural model is trained over large and carefully distilled data, curated from multiple BI domains. Thus, the system can generate faithful and fluent insights over open-domain tables, making it practical and useful.},
  archive   = {C_AAAI},
  author    = {Yotam Perlitz and Dafna Sheinwald and Noam Slonim and Michal Shmueli-Scheuer},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27082},
  pages     = {16470-16472},
  title     = {NBIIG: A neural BI insights generation system for table reporting},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AI model factory: Scaling AI for industry 4.0 applications.
<em>AAAI</em>, 16467–16469. (<a
href="https://doi.org/10.1609/aaai.v37i13.27081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This demo paper discusses a scalable platform for emerging Data-Driven AI Applications targeted toward predictive maintenance solutions. We propose a common AI software architecture stack for building diverse AI Applications such as Anomaly Detection, Failure Pattern Analysis, Asset Health Forecasting, etc. for more than a 100K industrial assets of similar class. As a part of the AI system demonstration, we have identified the following three key topics for discussion: Scaling model training across multiple assets, Joint execution of multiple AI applications; and Bridge the gap between current open source software tools and the emerging need for AI Applications. To demonstrate the benefits, AI Model Factory has been tested to build the models for various industrial assets such as Wind turbines, Oil wells, etc. The system is deployed on API Hub for demonstration.},
  archive   = {C_AAAI},
  author    = {Dhaval Patel and Shuxin Lin and Dhruv Shah and Srideepika Jayaraman and Joern Ploennigs and Anuradha Bhamidipati and Jayant Kalagnanam},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27081},
  pages     = {16467-16469},
  title     = {AI model factory: Scaling AI for industry 4.0 applications},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). BiRDy: Bullying role detection in multi-party chats.
<em>AAAI</em>, 16464–16466. (<a
href="https://doi.org/10.1609/aaai.v37i13.27080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent studies have highlighted that private instant messaging platforms and channels are major media of cyber aggression, especially among teens. Due to the private nature of the verbal exchanges on these media, few studies have addressed the task of hate speech detection in this context. Moreover, the recent release of resources mimicking online aggression situations that may occur among teens on private instant messaging platforms is encouraging the development of solutions aiming at dealing with diversity in digital harassment. In this study, we present BiRDy: a fully Web-based platform performing participant role detection in multi-party chats. Leveraging the pre-trained language model mBERT (multilingual BERT), we release fine-tuned models relying on various contextual window strategies to classify exchanged messages according to the role of involvement in cyberbullying of the authors. Integrating a role scoring function, the proposed pipeline predicts a unique role for each chat participant. In addition, detailed confidence scoring are displayed. Currently, BiRDy publicly releases models for French and Italian.},
  archive   = {C_AAAI},
  author    = {Anaïs Ollagnier and Elena Cabrio and Serena Villata and Sara Tonelli},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27080},
  pages     = {16464-16466},
  title     = {BiRDy: Bullying role detection in multi-party chats},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GAAMA 2.0: An integrated system that answers boolean and
extractive questions. <em>AAAI</em>, 16461–16463. (<a
href="https://doi.org/10.1609/aaai.v37i13.27079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent machine reading comprehension datasets include extractive and boolean questions but current approaches do not offer integrated support for answering both question types. We present a front-end demo to a multilingual machine reading comprehension system that handles boolean and extractive questions. It provides a yes/no answer and highlights the supporting evidence for boolean questions. It provides an answer for extractive questions and highlights the answer in the passage. Our system, GAAMA 2.0, achieved first place on the TyDi QA leaderboard at the time of submission. We contrast two different implementations of our approach: including multiple transformer models for easy deployment, and a shared transformer model utilizing adapters to reduce GPU memory footprint for a resource-constrained environment.},
  archive   = {C_AAAI},
  author    = {Scott McCarley and Mihaela Bornea and Sara Rosenthal and Anthony Ferritto and Md Arafat Sultan and Avirup Sil and Radu Florian},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27079},
  pages     = {16461-16463},
  title     = {GAAMA 2.0: An integrated system that answers boolean and extractive questions},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust-MSA: Understanding the impact of modality noise on
multimodal sentiment analysis. <em>AAAI</em>, 16458–16460. (<a
href="https://doi.org/10.1609/aaai.v37i13.27078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Improving model robustness against potential modality noise, as an essential step for adapting multimodal models to real-world applications, has received increasing attention among researchers. For Multimodal Sentiment Analysis (MSA), there is also a debate on whether multimodal models are more effective against noisy features than unimodal ones. Stressing on intuitive illustration and in-depth analysis of these concerns, we present Robust-MSA, an interactive platform that visualizes the impact of modality noise as well as simple defence methods to help researchers know better about how their models perform with imperfect real-world data.},
  archive   = {C_AAAI},
  author    = {Huisheng Mao and Baozheng Zhang and Hua Xu and Ziqi Yuan and Yihe Liu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27078},
  pages     = {16458-16460},
  title     = {Robust-MSA: Understanding the impact of modality noise on multimodal sentiment analysis},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FC-TrackNet: Fast convergence net for 6D pose tracking in
synthetic domains. <em>AAAI</em>, 16455–16457. (<a
href="https://doi.org/10.1609/aaai.v37i13.27077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this work, we propose a fast convergence track net, or FC-TrackNet, based on a synthetic data-driven approach to maintaining long-term 6D pose tracking. Comparison experiments are performed on two different datasets, The results demonstrate that our approach can achieve a consistent tracking frequency of 90.9 Hz as well as higher accuracy than the state-of-the art approaches.},
  archive   = {C_AAAI},
  author    = {Di Jia and Qian Wang and Jun Cao and Peng Cai and Zhiyang Jin},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27077},
  pages     = {16455-16457},
  title     = {FC-TrackNet: Fast convergence net for 6D pose tracking in synthetic domains},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MARCOL: A maritime collision avoidance decision-making
testbed. <em>AAAI</em>, 16452–16454. (<a
href="https://doi.org/10.1609/aaai.v37i13.27076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Safe and efficient maritime navigation is fundamental for autonomous surface vehicles to support many applications in the blue economy, including cargo transportation that covers 90\% of the global marine industry. We developed MARCOL, a collision avoidance decision-making framework that provides safe, efficient, and explainable collision avoidance strategies and that allows for repeated experiments under diverse high-traffic scenarios.},
  archive   = {C_AAAI},
  author    = {Mingi Jeong and Alberto Quattrini Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27076},
  pages     = {16452-16454},
  title     = {MARCOL: A maritime collision avoidance decision-making testbed},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Kajibuntan: A house chore division app. <em>AAAI</em>,
16449–16451. (<a
href="https://doi.org/10.1609/aaai.v37i13.27075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Couples often encounter the challenge of sharing house chores. This raises the fundamental question of how to divide chores. In this paper, we present a new application for a fair division of household chores. Our platform, called Kajibuntan, allows couples to specify the set of chores to be shared, their preferences over them, and the current allocation. Our tool visualizes the current allocation and makes proposals according to their preferences based on the theory of fair division. The goal of our tool is to provide a systematic and transparent system to divide household chores and help creating harmony in the home.},
  archive   = {C_AAAI},
  author    = {Ayumi Igarashi and Tomohiko Yokoyama},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27075},
  pages     = {16449-16451},
  title     = {Kajibuntan: A house chore division app},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). NCTV: Neural clamping toolkit and visualization for neural
network calibration. <em>AAAI</em>, 16446–16448. (<a
href="https://doi.org/10.1609/aaai.v37i13.27074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With the advancement of deep learning technology, neural networks have demonstrated their excellent ability to provide accurate predictions in many tasks. However, a lack of consideration for neural network calibration will not gain trust from humans, even for high-accuracy models. In this regard, the gap between the confidence of the model&#39;s predictions and the actual correctness likelihood must be bridged to derive a well-calibrated model. In this paper, we introduce the Neural Clamping Toolkit, the first open-source framework designed to help developers employ state-of-the-art model-agnostic calibrated models. Furthermore, we provide animations and interactive sections in the demonstration to familiarize researchers with calibration in neural networks. A Colab tutorial on utilizing our toolkit is also introduced.},
  archive   = {C_AAAI},
  author    = {Lei Hsiung and Yung-Chen Tang and Pin-Yu Chen and Tsung-Yi Ho},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27074},
  pages     = {16446-16448},
  title     = {NCTV: Neural clamping toolkit and visualization for neural network calibration},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DFEE: Interactive DataFlow execution and evaluation kit.
<em>AAAI</em>, 16443–16445. (<a
href="https://doi.org/10.1609/aaai.v37i13.27073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {DataFlow has been emerging as a new paradigm for building task-oriented chatbots due to its expressive semantic representations of the dialogue tasks. Despite the availability of a large dataset SMCalFlow and a simplified syntax, the development and evaluation of DataFlow-based chatbots remain challenging due to the system complexity and the lack of downstream toolchains. In this demonstration, we present DFEE, an interactive DataFlow Execution and Evaluation toolkit that supports execution, visualization and benchmarking of semantic parsers given dialogue input and backend database. We demonstrate the system via a complex dialog task: event scheduling that involves temporal reasoning. It also supports diagnosing the parsing results via a friendly interface that allows developers to examine dynamic DataFlow and the corresponding execution results. To illustrate how to benchmark SoTA models, we propose a novel benchmark that covers more sophisticated event scheduling scenarios and a new metric on task success evaluation. The codes of DFEE have been released on https://github.com/amazonscience/dataflow-evaluation-toolkit.},
  archive   = {C_AAAI},
  author    = {Han He and Song Feng and Daniele Bonadiman and Yi Zhang and Saab Mansour},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27073},
  pages     = {16443-16445},
  title     = {DFEE: Interactive DataFlow execution and evaluation kit},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sudoku assistant – an AI-powered app to help solve
pen-and-paper sudokus. <em>AAAI</em>, 16440–16442. (<a
href="https://doi.org/10.1609/aaai.v37i13.27072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Sudoku Assistant app is an AI assistant that uses a combination of machine learning and constraint programming techniques, to interpret and explain a pen-and-paper Sudoku scanned with a smartphone. Although the demo is about Sudoku, the underlying techniques are equally applicable to other constraint solving problems like timetabling, scheduling, and vehicle routing.},
  archive   = {C_AAAI},
  author    = {Tias Guns and Emilio Gamba and Maxime Mulamba and Ignace Bleukx and Senne Berden and Milan Pesa},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27072},
  pages     = {16440-16442},
  title     = {Sudoku assistant – an AI-powered app to help solve pen-and-paper sudokus},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Augmenting flight training with AI to efficiently train
pilots. <em>AAAI</em>, 16437–16439. (<a
href="https://doi.org/10.1609/aaai.v37i13.27071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose an AI-based pilot trainer to help students learn how to fly aircraft. First, an AI agent uses behavioral cloning to learn flying maneuvers from qualified flight instructors. Later, the system uses the agent&#39;s decisions to detect errors made by students and provide feedback to help students correct their errors. This paper presents an instantiation of the pilot trainer. We focus on teaching straight and level flying maneuvers by automatically providing formative feedback to the human student.},
  archive   = {C_AAAI},
  author    = {Michael Guevarra and Srijita Das and Christabel Wayllace and Carrie Demmans Epp and Matthew Taylor and Alan Tay},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27071},
  pages     = {16437-16439},
  title     = {Augmenting flight training with AI to efficiently train pilots},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generating reflective questions for engaging gallery
visitors in ArtMuse. <em>AAAI</em>, 16434–16436. (<a
href="https://doi.org/10.1609/aaai.v37i13.27070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Human guides in museums and galleries are professionally trained to stimulate informal learning in visitors by asking low-risk, open-ended reflective questions that enable them to focus on specific features of artifacts, relate to prior experiences, and elicit curiosity as well as further thought. We present ArtMuse, our AI-powered chatbot for asking reflective questions in context of paintings. Our reflective question generation model in ArtMuse was trained by applying a novel combination of existing models for extractive question answering and open-domain chitchat. User evaluation studies indicate that we are able to generate fluent and specific reflective questions for paintings that are highly-engaging.},
  archive   = {C_AAAI},
  author    = {Sujatha Das Gollapalli and Mingzhe Du and See-Kiong Ng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27070},
  pages     = {16434-16436},
  title     = {Generating reflective questions for engaging gallery visitors in ArtMuse},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DISPUTool 2.0: A modular architecture for multi-layer
argumentative analysis of political debates. <em>AAAI</em>, 16431–16433.
(<a href="https://doi.org/10.1609/aaai.v37i13.27069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Political debates are one of the most salient moments of an election campaign, where candidates are challenged to discuss the main contemporary and historical issues in a country. These debates represent a natural ground for argumentative analysis, which has always been employed to investigate political discourse structure and strategy in philosophy and linguistics. In this paper, we present DISPUTool 2.0, an automated tool which relies on Argument Mining methods to analyse the political debates from the US presidential campaigns to extract argument components (i.e., premise and claim) and relations (i.e., support and attack), and highlight fallacious arguments. DISPUTool 2.0 allows also for the automatic analysis of a piece of a debate proposed by the user to identify and classify the arguments contained in the text. A REST API is provided to exploit the tool&#39;s functionalities.},
  archive   = {C_AAAI},
  author    = {Pierpaolo Goffredo and Elena Cabrio and Serena Villata and Shohreh Haddadan and Jhonatan Torres Sanchez},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27069},
  pages     = {16431-16433},
  title     = {DISPUTool 2.0: A modular architecture for multi-layer argumentative analysis of political debates},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). NL2LTL – a python package for converting natural language
(NL) instructions to linear temporal logic (LTL) formulas.
<em>AAAI</em>, 16428–16430. (<a
href="https://doi.org/10.1609/aaai.v37i13.27068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This is a demonstration of our newly released Python package NL2LTL which leverages the latest in natural language understanding (NLU) and large language models (LLMs) to translate natural language instructions to linear temporal logic (LTL) formulas. This allows direct translation to formal languages that a reasoning system can use, while at the same time, allowing the end-user to provide inputs in natural language without having to understand any details of an underlying formal language. The package comes with support for a set of default LTL patterns, corresponding to popular DECLARE templates, but is also fully extensible to new formulas and user inputs. The package is open-source and is free to use for the AI community under the MIT license. Open Source: https://github.com/IBM/nl2ltl. Video Link: https://bit.ly/3dHW5b1},
  archive   = {C_AAAI},
  author    = {Francesco Fuggitti and Tathagata Chakraborti},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27068},
  pages     = {16428-16430},
  title     = {NL2LTL – a python package for converting natural language (NL) instructions to linear temporal logic (LTL) formulas},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DUCK: A drone-urban cyber-defense framework based on
pareto-optimal deontic logic agents. <em>AAAI</em>, 16425–16427. (<a
href="https://doi.org/10.1609/aaai.v37i13.27067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Drone based terrorist attacks are increasing daily. It is not expected to be long before drones are used to carry out terror attacks in urban areas. We have developed the DUCK multi-agent testbed that security agencies can use to simulate drone-based attacks by diverse actors and develop a combination of surveillance camera, drone, and cyber defenses against them.},
  archive   = {C_AAAI},
  author    = {Tonmoay Deb and Jürgen Dix and Mingi Jeong and Cristian Molinaro and Andrea Pugliese and Alberto Quattrini Li and Eugene Santos, Jr and V.S. Subrahmanian and Shanchieh Yang and Youzhi Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27067},
  pages     = {16425-16427},
  title     = {DUCK: A drone-urban cyber-defense framework based on pareto-optimal deontic logic agents},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). EdBB-demo: Biometrics and behavior analysis for online
educational platforms. <em>AAAI</em>, 16422–16424. (<a
href="https://doi.org/10.1609/aaai.v37i13.27066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present edBB-Demo, a demonstrator of an AI-powered research platform for student monitoring in remote education. The edBB platform aims to study the challenges associated to user recognition and behavior understanding in digital platforms. This platform has been developed for data collection, acquiring signals from a variety of sensors including keyboard, mouse, webcam, microphone, smartwatch, and an Electroencephalography band. The information captured from the sensors during the student sessions is modelled in a multimodal learning framework. The demonstrator includes: i) Biometric user authentication in an unsupervised environment; ii) Human action recognition based on remote video analysis; iii) Heart rate estimation from webcam video; and iv) Attention level estimation from facial expression analysis.},
  archive   = {C_AAAI},
  author    = {Roberto Daza and Aythami Morales and Ruben Tolosana and Luis F. Gomez and Julian Fierrez and Javier Ortega-Garcia},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27066},
  pages     = {16422-16424},
  title     = {EdBB-demo: Biometrics and behavior analysis for online educational platforms},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). EasyRec: An easy-to-use, extendable and efficient framework
for building industrial recommendation systems. <em>AAAI</em>,
16419–16421. (<a
href="https://doi.org/10.1609/aaai.v37i13.27065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present EasyRec, an easy-to-use, extendable and efficient recommendation framework for building industrial recommendation systems. Our EasyRec framework is superior in the following aspects:first, EasyRec adopts a modular and pluggable design pattern to reduce the efforts to build custom models; second, EasyRec implements hyper-parameter optimization and feature selection algorithms to improve model performance automatically; third, EasyRec applies online learning to adapt to the ever-changing data distribution. The code is released: https://github.com/alibaba/EasyRec.},
  archive   = {C_AAAI},
  author    = {Mengli Cheng and Yue Gao and Guoqiang Liu and HongSheng Jin},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27065},
  pages     = {16419-16421},
  title     = {EasyRec: An easy-to-use, extendable and efficient framework for building industrial recommendation systems},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). HAPI explorer: Comprehension, discovery, and explanation on
history of ML APIs. <em>AAAI</em>, 16416–16418. (<a
href="https://doi.org/10.1609/aaai.v37i13.27064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Machine learning prediction APIs offered by Google, Microsoft, Amazon, and many other providers have been continuously adopted in a plethora of applications, such as visual object detection, natural language comprehension, and speech recognition. Despite the importance of a systematic study and comparison of different APIs over time, this topic is currently under-explored because of the lack of data and user-friendly exploration tools. To address this issue, we present HAPI Explorer (History of API Explorer), an interactive system that offers easy access to millions of instances of commercial API applications collected in three years, prioritize attention on user-defined instance regimes, and explain interesting patterns across different APIs, subpopulations, and time periods via visual and natural languages. HAPI Explorer can facilitate further comprehension and exploitation of ML prediction APIs.},
  archive   = {C_AAAI},
  author    = {Lingjiao Chen and Zhihua Jin and Sabri Eyuboglu and Huamin Qu and Christopher Ré and Matei Zaharia and James Zou},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27064},
  pages     = {16416-16418},
  title     = {HAPI explorer: Comprehension, discovery, and explanation on history of ML APIs},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TUTORING: Instruction-grounded conversational agent for
language learners. <em>AAAI</em>, 16413–16415. (<a
href="https://doi.org/10.1609/aaai.v37i13.27063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we propose Tutoring bot, a generative chatbot trained on a large scale of tutor-student conversations for English-language learning. To mimic a human tutor&#39;s behavior in language education, the tutor bot leverages diverse educational instructions and grounds to each instruction as additional input context for the tutor response generation. As a single instruction generally involves multiple dialogue turns to give the student sufficient speaking practice, the tutor bot is required to monitor and capture when the current instruction should be kept or switched to the next instruction. For that, the tutor bot is learned to not only generate responses but also infer its teaching action and progress on the current conversation simultaneously by a multi-task learning scheme. Our Tutoring bot is deployed under a non-commercial use license at https://tutoringai.com.},
  archive   = {C_AAAI},
  author    = {Hyungjoo Chae and Minjin Kim and Chaehyeong Kim and Wonseok Jeong and Hyejoong Kim and Junmyung Lee and Jinyoung Yeo},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27063},
  pages     = {16413-16415},
  title     = {TUTORING: Instruction-grounded conversational agent for language learners},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TgrApp: Anomaly detection and visualization of large-scale
call graphs. <em>AAAI</em>, 16410–16412. (<a
href="https://doi.org/10.1609/aaai.v37i13.27062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Given a million-scale dataset of who-calls-whom data containing imperfect labels, how can we detect existing and new fraud patterns? We propose TgrApp, which extracts carefully designed features and provides visualizations to assist analysts in spotting fraudsters and suspicious behavior. Our TgrApp method has the following properties: (a) Scalable, as it is linear on the input size; and (b) Effective, as it allows natural interaction with human analysts, and is applicable in both supervised and unsupervised settings.},
  archive   = {C_AAAI},
  author    = {Mirela T. Cazzolato and Saranya Vijayakumar and Xinyi Zheng and Namyong Park and Meng-Chieh Lee and Duen Horng Chau and Pedro Fidalgo and Bruno Lages and Agma J. M. Traina and Christos Faloutsos},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27062},
  pages     = {16410-16412},
  title     = {TgrApp: Anomaly detection and visualization of large-scale call graphs},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AI-SNIPS: A platform for network intelligence-based
pharmaceutical security. <em>AAAI</em>, 16407–16409. (<a
href="https://doi.org/10.1609/aaai.v37i13.27061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper presents AI-SNIPS (AI Support for Network Intelligence-based Pharmaceutical Security), a production-ready platform that enables stakeholder decision-making, secure data sharing, and interdisciplinary research in the fight against Illicit, Substandard, and Falsified Medical Products (ISFMP). AI-SNIPS takes as input cases: a case consists of one or more URLs suspected of ISFMP activity. Cases can be supplemented with ground-truth structured data (labeled keywords) such as seller PII or case notes. First, AI-SNIPS scrapes and stores relevant images and text from the provided URLs without any user intervention. Salient features for predicting case similarity are extracted from the aggregated data using a combination of rule-based and machine-learning techniques and used to construct a seller network, with the nodes representing cases (sellers) and the edges representing the similarity between two sellers. Network analysis and community detection techniques are applied to extract seller clusters ranked by profitability and their potential to harm society. Lastly, AI-SNIPS provides interpretability by distilling common word/image similarities for each cluster into signature vectors. We validate the importance of AI-SNIPS&#39;s features for distinguishing large pharmaceutical affiliate networks from small ISFMP operations using an actual ISFMP lead sheet.},
  archive   = {C_AAAI},
  author    = {Timothy A. Burt and Nikos Passas and Ioannis A. Kakadiaris},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27061},
  pages     = {16407-16409},
  title     = {AI-SNIPS: A platform for network intelligence-based pharmaceutical security},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dagster: Parallel structured search. <em>AAAI</em>,
16404–16406. (<a
href="https://doi.org/10.1609/aaai.v37i13.27060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We demonstrate Dagster, a system that implements a new approach to scheduling interdependent (Boolean) SAT search activities in high-performance computing (HPC) environments. Our system takes as input a set of disjunctive clauses (i.e., DIMACS CNF) and a labelled directed acyclic graph (DAG) structure describing how the clauses are decomposed into a set of interrelated problems. Component problems are solved using standard systematic backtracking search, which may optionally be coupled to (stochastic dynamic) local search and/or clause-strengthening processes. We demonstrate Dagster using a new Graph Maximal Determinant combinatorial case study. This demonstration paper presents a new case study, and is adjunct to the longer accepted manuscript at the Pacific Rim International Conference on Artificial Intelligence (2022).},
  archive   = {C_AAAI},
  author    = {Mark Alexander Burgess and Charles Gretton and Josh Milthorpe and Luke Croak and Thomas Willingham and Alwen Tiu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27060},
  pages     = {16404-16406},
  title     = {Dagster: Parallel structured search},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A tool for generating controllable variations of musical
themes using variational autoencoders with latent space regularisation.
<em>AAAI</em>, 16401–16403. (<a
href="https://doi.org/10.1609/aaai.v37i13.27059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A common musical composition practice is to develop musical pieces using variations of musical themes. In this study, we present an interactive tool which can generate variations of musical themes in real-time using a variational autoencoder model. Our tool is controllable using semantically meaningful musical attributes via latent space regularisation technique to increase the explainability of the model. The tool is integrated into an industry standard digital audio workstation - Ableton Live - using the Max4Live device framework and can run locally on an average personal CPU rather than requiring a costly GPU cluster. In this way we demonstrate how cutting-edge AI research can be integrated into the exiting workflows of professional and practising musicians for use in the real-world beyond the research lab.},
  archive   = {C_AAAI},
  author    = {Berker Banar and Nick Bryan-Kinns and Simon Colton},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27059},
  pages     = {16401-16403},
  title     = {A tool for generating controllable variations of musical themes using variational autoencoders with latent space regularisation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SOREO: A system for safe and autonomous drones fleet
navigation with reinforcement learning. <em>AAAI</em>, 16398–16400. (<a
href="https://doi.org/10.1609/aaai.v37i13.27058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This demonstration introduces SOREO, a system that explores the possibility of extending UAVs autonomy through machine learning. It brings a contribution to the following problem: Having a fleet of drones and a geographic area, how to learn the shortest paths between any point with regards to the base points for optimal and safe package delivery? Starting from a set of possible actions, a virtual design of a geographic location of interest, e.g., a city, and a reward value, SOREO is capable of learning not only how to prevent collisions with obstacles, e.g., walls and buildings, but also to find the shortest path between any two points, i.e., the base and the target. SOREO exploits based on the Q-learning algorithm.},
  archive   = {C_AAAI},
  author    = {Reda Alami and Hakim Hacid and Lorenzo Bellone and Michal Barcis and Enrico Natalizio},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27058},
  pages     = {16398-16400},
  title     = {SOREO: A system for safe and autonomous drones fleet navigation with reinforcement learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ConceptX: A framework for latent concept analysis.
<em>AAAI</em>, 16395–16397. (<a
href="https://doi.org/10.1609/aaai.v37i13.27057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The opacity of deep neural networks remains a challenge in deploying solutions where explanation is as important as precision. We present ConceptX, a human-in-the-loop framework for interpreting and annotating latent representational space in pre-trained Language Models (pLMs). We use an unsupervised method to discover concepts learned in these models and enable a graphical interface for humans to generate explanations for the concepts. To facilitate the process, we provide auto-annotations of the concepts (based on traditional linguistic ontologies). Such annotations enable development of a linguistic resource that directly represents latent concepts learned within deep NLP models. These include not just traditional linguistic concepts, but also task-specific or sensitive concepts (words grouped based on gender or religious connotation) that helps the annotators to mark bias in the model. The framework consists of two parts (i) concept discovery and (ii) annotation platform.},
  archive   = {C_AAAI},
  author    = {Firoj Alam and Fahim Dalvi and Nadir Durrani and Hassan Sajjad and Abdul Rafae Khan and Jia Xu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27057},
  pages     = {16395-16397},
  title     = {ConceptX: A framework for latent concept analysis},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Model-based offline weighted policy optimization (student
abstract). <em>AAAI</em>, 16392–16393. (<a
href="https://doi.org/10.1609/aaai.v37i13.27056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A promising direction for applying reinforcement learning to the real world is learning from offline datasets. Offline reinforcement learning aims to learn policies from pre-collected datasets without online interaction with the environment. Due to the lack of further interaction, offline reinforcement learning faces severe extrapolation error, leading to policy learning failure. In this paper, we investigate the weighted Bellman update in model-based offline reinforcement learning. We explore uncertainty estimation in ensemble dynamics models, then use a variational autoencoder to fit the behavioral prior, and finally propose an algorithm called Model-Based Offline Weighted Policy Optimization (MOWPO), which uses a combination of model confidence and behavioral prior as weights to reduce the impact of inaccurate samples on policy optimization. Experiment results show that MOWPO achieves better performance than state-of-the-art algorithms, and both the model confidence weight and the behavioral prior weight can play an active role in offline policy optimization.},
  archive   = {C_AAAI},
  author    = {Renzhe Zhou and Zongzhang Zhang and Yang Yu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27056},
  pages     = {16392-16393},
  title     = {Model-based offline weighted policy optimization (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feature decomposition for reducing negative transfer: A
novel multi-task learning method for recommender system (student
abstract). <em>AAAI</em>, 16390–16391. (<a
href="https://doi.org/10.1609/aaai.v37i13.27055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose a novel multi-task learning method termed Feature Decomposition Network (FDN). The key idea of the proposed FDN is to reduce the phenomenon of feature redundancy by explicitly decomposing features into task-specific features and task-shared features with carefully designed constraints. Experimental results show that our proposed FDN can outperform the state-of-the-art (SOTA) methods by a noticeable margin on Ali-CCP.},
  archive   = {C_AAAI},
  author    = {Jie Zhou and Qian Yu and Chuan Luo and Jing Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27055},
  pages     = {16390-16391},
  title     = {Feature decomposition for reducing negative transfer: A novel multi-task learning method for recommender system (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploiting high-order interaction relations to explore user
intent (student abstract). <em>AAAI</em>, 16388–16389. (<a
href="https://doi.org/10.1609/aaai.v37i13.27054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper studies the problem of exploring the user intent for session-based recommendations. Its challenges come from the uncertainty of user behavior and limited information. However, current endeavors cannot fully explore the mutual interactions among sessions and do not explicitly model the complex high-order relations among items. To circumvent these critical issues, we innovatively propose a HyperGraph Convolutional Contrastive framework (termed HGCC) that consists of two crucial tasks: 1) The session-based recommendation (SBR task) that aims to capture the beyond pair-wise relationships between items and sessions. 2) The self-supervised learning (SSL task) acted as the auxiliary task to boost the former task. By jointly optimizing the two tasks, the performance of the recommendation task achieves decent gains. Experiments on multiple real-world datasets demonstrate the superiority of the proposed approach over the state-of-the-art methods.},
  archive   = {C_AAAI},
  author    = {Xiangping Zheng and Xun Liang and Bo Wu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27054},
  pages     = {16388-16389},
  title     = {Exploiting high-order interaction relations to explore user intent (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Graph of graphs: A new knowledge representation mechanism
for graph learning (student abstract). <em>AAAI</em>, 16386–16387. (<a
href="https://doi.org/10.1609/aaai.v37i13.27053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Supervised graph classification is one of the most actively developing areas in machine learning (ML), with a broad range of domain applications, from social media to bioinformatics. Given a collection of graphs with categorical labels, the goal is to predict correct classes for unlabelled graphs. However, currently available ML tools view each such graph as a standalone entity and, as such, do not account for complex interdependencies among graphs. We propose a novel knowledge representation for graph learning called a {\it Graph of Graphs} (GoG). The key idea is to construct a new abstraction where each graph in the collection is represented by a node, while an edge then reflects similarity among the graphs. Such similarity can be assessed via a suitable graph distance. As a result, the graph classification problem can be then reformulated as a node classification problem. We show that the proposed new knowledge representation approach not only improves classification performance but substantially enhances robustness against label perturbation attacks.},
  archive   = {C_AAAI},
  author    = {Zhwiei Zhen and Yuzhou Chen and Murat Kantarcioglu and Yulia R. Gel},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27053},
  pages     = {16386-16387},
  title     = {Graph of graphs: A new knowledge representation mechanism for graph learning (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). HaPPy: Harnessing the wisdom from multi-perspective graphs
for protein-ligand binding affinity prediction (student abstract).
<em>AAAI</em>, 16384–16385. (<a
href="https://doi.org/10.1609/aaai.v37i13.27052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Gathering information from multi-perspective graphs is an essential issue for many applications especially for proteinligand binding affinity prediction. Most of traditional approaches obtained such information individually with low interpretability. In this paper, we harness the rich information from multi-perspective graphs with a general model, which abstractly represents protein-ligand complexes with better interpretability while achieving excellent predictive performance. In addition, we specially analyze the protein-ligand binding affinity problem, taking into account the heterogeneity of proteins and ligands. Experimental evaluations demonstrate the effectiveness of our data representation strategy on public datasets by fusing information from different perspectives.},
  archive   = {C_AAAI},
  author    = {Xianfeng Zhang and Yanhui Gu and Guandong Xu and Yafei Li and Jinlan Wang and Zhenglu Yang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27052},
  pages     = {16384-16385},
  title     = {HaPPy: Harnessing the wisdom from multi-perspective graphs for protein-ligand binding affinity prediction (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). DyCVAE: Learning dynamic causal factors for non-stationary
series domain generalization (student abstract). <em>AAAI</em>,
16382–16383. (<a
href="https://doi.org/10.1609/aaai.v37i13.27051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Learning domain-invariant representations is a major task of out-of-distribution generalization. To address this issue, recent efforts have taken into accounting causality, aiming at learning the causal factors with regard to tasks. However, extending existing generalization methods for adapting non-stationary time series may be ineffective, because they fail to model the underlying causal factors due to temporal-domain shifts except for source-domain shifts, as pointed out by recent studies. To this end, we propose a novel model DyCVAE to learn dynamic causal factors. The results on synthetic and real datasets demonstrate the effectiveness of our proposed model for the task of generalization in time series domain.},
  archive   = {C_AAAI},
  author    = {Weifeng Zhang and Zhiyuan Wang and Kunpeng Zhang and Ting Zhong and Fan Zhou},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27051},
  pages     = {16382-16383},
  title     = {DyCVAE: Learning dynamic causal factors for non-stationary series domain generalization (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Measuring the privacy leakage via graph reconstruction
attacks on simplicial neural networks (student abstract). <em>AAAI</em>,
16380–16381. (<a
href="https://doi.org/10.1609/aaai.v37i13.27050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we measure the privacy leakage via studying whether graph representations can be inverted to recover the graph used to generate them via graph reconstruction attack (GRA). We propose a GRA that recovers a graph&#39;s adjacency matrix from the representations via a graph decoder that minimizes the reconstruction loss between the partial graph and the reconstructed graph. We study three types of representations that are trained on the graph, i.e., representations output from graph convolutional network (GCN), graph attention network (GAT), and our proposed simplicial neural network (SNN) via a higher-order combinatorial Laplacian. Unlike the first two types of representations that only encode pairwise relationships, the third type of representation, i.e., SNN outputs, encodes higher-order interactions (e.g., homological features) between nodes. We find that the SNN outputs reveal the lowest privacy-preserving ability to defend the GRA, followed by those of GATs and GCNs, which indicates the importance of building more private representations with higher-order node information that could defend the potential threats, such as GRAs.},
  archive   = {C_AAAI},
  author    = {Huixin Zhan and Kun Zhang and Keyi Lu and Victor S. Sheng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27050},
  pages     = {16380-16381},
  title     = {Measuring the privacy leakage via graph reconstruction attacks on simplicial neural networks (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Clustered federated learning for heterogeneous data (student
abstract). <em>AAAI</em>, 16378–16379. (<a
href="https://doi.org/10.1609/aaai.v37i13.27049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Federated Learning (FL) aims to achieve a global model via aggregating models from all devices. However, it can diverge when the data on the users’ devices are heterogeneous. To address this issue, we propose a novel clustered FL method (FPFC) based on a nonconvex pairwise fusion penalty. FPFC can automatically identify clusters without prior knowledge of the number of clusters and the set of devices in each cluster. Our method is implemented in parallel, updates only a subset of devices at each communication round, and allows each participating device to perform inexact computation. We also provide convergence guarantees of FPFC for general nonconvex losses. Experiment results demonstrate the advantages of FPFC over existing methods.},
  archive   = {C_AAAI},
  author    = {Xue Yu and Ziyi Liu and Yifan Sun and Wu Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27049},
  pages     = {16378-16379},
  title     = {Clustered federated learning for heterogeneous data (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive constraint partition based optimization framework
for large-scale integer linear programming (student abstract).
<em>AAAI</em>, 16376–16377. (<a
href="https://doi.org/10.1609/aaai.v37i13.27048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Integer programming problems (IPs) are challenging to be solved efficiently due to the NP-hardness, especially for large-scale IPs. To solve this type of IPs, Large neighborhood search (LNS) uses an initial feasible solution and iteratively improves it by searching a large neighborhood around the current solution. However, LNS easily steps into local optima and ignores the correlation between variables to be optimized, leading to compromised performance. This paper presents a general adaptive constraint partition-based optimization framework (ACP) for large-scale IPs that can efficiently use any existing optimization solver as a subroutine. Specifically, ACP first randomly partitions the constraints into blocks, where the number of blocks is adaptively adjusted to avoid local optima. Then, ACP uses a subroutine solver to optimize the decision variables in a randomly selected block of constraints to enhance the variable correlation. ACP is compared with LNS framework with different subroutine solvers on four IPs and a real-world IP. The experimental results demonstrate that in specified wall-clock time ACP shows better performance than SCIP and Gurobi.},
  archive   = {C_AAAI},
  author    = {Huigen Ye and Hongyan Wang and Hua Xu and Chengming Wang and Yu Jiang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27048},
  pages     = {16376-16377},
  title     = {Adaptive constraint partition based optimization framework for large-scale integer linear programming (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mask-net: Learning context aware invariant features using
adversarial forgetting (student abstract). <em>AAAI</em>, 16374–16375.
(<a href="https://doi.org/10.1609/aaai.v37i13.27047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Training a robust system, e.g., Speech to Text (STT), requires large datasets. Variability present in the dataset, such as unwanted nuances and biases, is the reason for the need for large datasets to learn general representations. In this work, we propose a novel approach to induce invariance using adversarial forgetting (AF). Our initial experiments on learning invariant features such as accent on the STT task achieve better generalizations in terms of word error rate (WER) compared to traditional models. We observe an absolute improvement of 2.2\% and 1.3\% on out-of-distribution and in-distribution test sets, respectively.},
  archive   = {C_AAAI},
  author    = {Hemant Yadav and Rajiv Ratn Shah},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27047},
  pages     = {16374-16375},
  title     = {Mask-net: Learning context aware invariant features using adversarial forgetting (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Logic error localization and correction with machine
learning (student abstract). <em>AAAI</em>, 16372–16373. (<a
href="https://doi.org/10.1609/aaai.v37i13.27046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We aim to propose a system repairing programs with logic errors to be functionally correct among different programming languages. Logic error program repair has always been a thorny problem: First, a logic error is usually harder to repair than a syntax error in a program because it has no diagnostic feedback from compilers. Second, it requires inferring in different ranges (i.e., the distance of related code lines) and tracking symbols across its pseudocode, source code, and test cases. Third, the logic error datasets are scarce, since an ideal logic error dataset should contain lots of components during the development procedure of a program, including a program specification, pseudocode, source code, test cases, and test reports (i.e., test case failure report). In our work, we propose novel solutions to these challenges. First, we introduce pseudocode information to assist logic error localization and correction. We construct a code-pseudocode graph to connect symbols across a source code and its pseudocode and then apply a graph neural network to localize and correct logic errors. Second, we collect logic errors generated in the process of syntax error repairing via DrRepair from 500 programs in the SPoC dataset and reconstruct them to our single logic error dataset, which we leverage to train and evaluate our models. Our experimental results show that we achieve 99.39\% localization accuracy and 19.20\% full repair accuracy on logic errors with five-fold cross-validation. Based on our current work, we will replenish and construct more complete public logic error datasets and propose a novel system to comprehend different programming languages from several perspectives and correct logic errors to be functionally correct.},
  archive   = {C_AAAI},
  author    = {Zhenyu Xu and Victor S. Sheng and Keyi Lu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27046},
  pages     = {16372-16373},
  title     = {Logic error localization and correction with machine learning (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). ACCD: An adaptive clustering-based collusion detector in
crowdsourcing (student abstract). <em>AAAI</em>, 16370–16371. (<a
href="https://doi.org/10.1609/aaai.v37i13.27045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Crowdsourcing is a popular method for crowd workers to collaborate on tasks. However, workers coordinate and share answers during the crowdsourcing process. The term for this is &quot;collusion&quot;. Copies from others and repeated submissions are detrimental to the quality of the assignments. The majority of the existing research on collusion detection is limited to ground truth problems (e.g., labeling tasks) and requires a predetermined threshold to be established in advance. In this paper, we aim to detect collusion behavior of workers in an adaptive way, and propose an Adaptive Clustering Based Collusion Detection approach (ACCD) for a broad range of task types and data types solved via crowdsourcing (e.g., continuous rating with or without distributions). Extensive experiments on both real-world and synthetic datasets show the superiority of ACCD over state-of-the-art approaches.},
  archive   = {C_AAAI},
  author    = {Ruoyu Xu and Gaoxiang Li and Wei Jin and Austin Chen and Victor S. Sheng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27045},
  pages     = {16370-16371},
  title     = {ACCD: An adaptive clustering-based collusion detector in crowdsourcing (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Class incremental learning for task-oriented dialogue system
with contrastive distillation on internal representations (student
abstract). <em>AAAI</em>, 16368–16369. (<a
href="https://doi.org/10.1609/aaai.v37i13.27044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The ability to continually learn over time by grasping new knowledge and remembering previously learned experiences is essential for developing an online task-oriented dialogue system (TDS). In this paper, we work on the class incremental learning scenario where the TDS is evaluated without specifying the dialogue domain. We employ contrastive distillation on the intermediate representations of dialogues to learn transferable representations that suffer less from catastrophic forgetting. Besides, we provide a dynamic update mechanism to explicitly preserve the learned experiences by only updating the parameters related to the new task while keeping other parameters fixed. Extensive experiments demonstrate that our method significantly outperforms the strong baselines.},
  archive   = {C_AAAI},
  author    = {Qiancheng Xu and Min Yang and Binzong Geng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27044},
  pages     = {16368-16369},
  title     = {Class incremental learning for task-oriented dialogue system with contrastive distillation on internal representations (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving dialogue intent classification with a
knowledge-enhanced multifactor graph model (student abstract).
<em>AAAI</em>, 16366–16367. (<a
href="https://doi.org/10.1609/aaai.v37i13.27043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Although current Graph Neural Network (GNN) based models achieved good performances in Dialogue Intent Classification (DIC), they leaf the inherent domain-specific knowledge out of consideration, leading to the lack of ability of acquiring fine-grained semantic information. In this paper, we propose a Knowledge-Enhanced Multifactor Graph (KEMG) Model for DIC. We firstly present a knowledge-aware utterance encoder with the help of a domain-specific knowledge graph, fusing token-level and entity-level semantic information, then design a heterogeneous dialogue graph encoder by explicitly modeling several factors that matter to contextual modeling of dialogues. Experiment results show that our proposed method outperforms other GNN-based methods on a dataset collected from a real-world online customer service dialogue system on the e-commerce website, JD.},
  archive   = {C_AAAI},
  author    = {Huinan Xu and Jinhui Pang and Shuangyong Song and Bo Zou},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27043},
  pages     = {16366-16367},
  title     = {Improving dialogue intent classification with a knowledge-enhanced multifactor graph model (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Long legal article question answering via cascaded key
segment learning (student abstract). <em>AAAI</em>, 16364–16365. (<a
href="https://doi.org/10.1609/aaai.v37i13.27042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Current sentence-level evidence extraction based methods may lose the discourse coherence of legal articles since they tend to make the extracted sentences scattered over the article. To solve the problem, this paper proposes a Cascaded Answer-guided key segment learning framework for long Legal article Question Answering, namely CALQA. The framework consists of three cascaded modules: Sifter, Reader, and Responder. The Sifter transfers a long legal article into several segments and works in an answer-guided way by automatically sifting out key fact segments in a coarse-to-fine approach through multiple iterations. The Reader utilizes a set of attention mechanisms to obtain semantic representations of the question and key fact segments. Finally, considering it a multi-label classification task the Responder predicts final answers in a cascaded manner. CALQA outperforms state-of-the-art methods in CAIL 2021 Law dataset.},
  archive   = {C_AAAI},
  author    = {Shugui Xie and Lin Li and Jingling Yuan and Qing Xie and Xiaohui Tao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27042},
  pages     = {16364-16365},
  title     = {Long legal article question answering via cascaded key segment learning (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Tackling safe and efficient multi-agent reinforcement
learning via dynamic shielding (student abstract). <em>AAAI</em>,
16362–16363. (<a
href="https://doi.org/10.1609/aaai.v37i13.27041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-agent Reinforcement Learning (MARL) has been increasingly used in safety-critical applications but has no safety guarantees, especially during training. In this paper, we propose dynamic shielding, a novel decentralized MARL framework to ensure safety in both training and deployment phases. Our framework leverages Shield, a reactive system running in parallel with the reinforcement learning algorithm to monitor and correct agents&#39; behavior. In our algorithm, shields dynamically split and merge according to the environment state in order to maintain decentralization and avoid conservative behaviors while enjoying formal safety guarantees. We demonstrate the effectiveness of MARL with dynamic shielding in the mobile navigation scenario.},
  archive   = {C_AAAI},
  author    = {Wenli Xiao and Yiwei Lyu and John M. Dolan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27041},
  pages     = {16362-16363},
  title     = {Tackling safe and efficient multi-agent reinforcement learning via dynamic shielding (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Enhancing dynamic GCN for node attribute forecasting with
meta spatial-temporal learning (student abstract). <em>AAAI</em>,
16360–16361. (<a
href="https://doi.org/10.1609/aaai.v37i13.27040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Node attribute forecasting has recently attracted considerable attention. Recent attempts have thus far utilize dynamic graph convolutional network (GCN) to predict future node attributes. However, few prior works have notice that the complex spatial and temporal interaction between nodes, which will hamper the performance of dynamic GCN. In this paper, we propose a new dynamic GCN model named meta-DGCN, leveraging meta spatial-temporal tasks to enhance the ability of dynamic GCN for better capturing node attributes in the future. Experiments show that meta-DGCN effectively modeling comprehensive spatio-temporal correlations between nodes and outperforms state-of-the-art baselines on various real-world datasets.},
  archive   = {C_AAAI},
  author    = {Bo Wu and Xun Liang and Xiangping Zheng and Jun Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27040},
  pages     = {16360-16361},
  title     = {Enhancing dynamic GCN for node attribute forecasting with meta spatial-temporal learning (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning dynamic temporal relations with continuous graph
for multivariate time series forecasting (student abstract).
<em>AAAI</em>, 16358–16359. (<a
href="https://doi.org/10.1609/aaai.v37i13.27039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The recent advance in graph neural networks (GNNs) has inspired a few studies to leverage the dependencies of variables for time series prediction. Despite the promising results, existing GNN-based models cannot capture the global dynamic relations between variables owing to the inherent limitation of their graph learning module. Besides, multi-scale temporal information is usually ignored or simply concatenated in prior methods, resulting in inaccurate predictions. To overcome these limitations, we present CGMF, a Continuous Graph learning method for Multivariate time series Forecasting (CGMF). Our CGMF consists of a continuous graph module incorporating differential equations to capture the long-range intra- and inter-relations of the temporal embedding sequence. We also introduce a controlled differential equation-based fusion mechanism that efficiently exploits multi-scale representations to form continuous evolutional dynamics and learn rich relations and patterns shared across different scales. Comprehensive experiments demonstrate the effectiveness of our method for a variety of datasets.},
  archive   = {C_AAAI},
  author    = {Zhiyuan Wang and Fan Zhou and Goce Trajcevski and Kunpeng Zhang and Ting Zhong},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27039},
  pages     = {16358-16359},
  title     = {Learning dynamic temporal relations with continuous graph for multivariate time series forecasting (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Anti-drifting feature selection via deep reinforcement
learning (student abstract). <em>AAAI</em>, 16356–16357. (<a
href="https://doi.org/10.1609/aaai.v37i13.27038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Feature selection (FS) is a crucial procedure in machine learning pipelines for its significant benefits in removing data redundancy and mitigating model overfitting. Since concept drift is a widespread phenomenon in streaming data and could severely affect model performance, effective FS on concept drifting data streams is imminent. However, existing state-of-the-art FS algorithms fail to adjust their selection strategy adaptively when the effective feature subset changes, making them unsuitable for drifting streams. In this paper, we propose a dynamic FS method that selects effective features on concept drifting data streams via deep reinforcement learning. Specifically, we present two novel designs: (i) a skip-mode reinforcement learning environment that shrinks action space size for high-dimensional FS tasks; (ii) a curiosity mechanism that generates intrinsic rewards to address the long-horizon exploration problem. The experiment results show that our proposed method outperforms other FS methods and can dynamically adapt to concept drifts.},
  archive   = {C_AAAI},
  author    = {Aoran Wang and Hongyang Yang and Feng Mao and Zongzhang Zhang and Yang Yu and Xiaoyang Liu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27038},
  pages     = {16356-16357},
  title     = {Anti-drifting feature selection via deep reinforcement learning (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Quantify the political bias in news edits: Experiments with
few-shot learners (student abstract). <em>AAAI</em>, 16354–16355. (<a
href="https://doi.org/10.1609/aaai.v37i13.27037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The rapid growth of information and communication technologies in recent years, and the different forms of digital connectivity, have profoundly affected how news is generated and consumed. Digital traces and computational methods offer new opportunities to model and track the provenance of news. This project is the first study to characterize and predict how prominent news outlets make edits to news frames and their implications for geopolitical relationships and attitudes. We evaluate the feasibility of training few-shot learners on the editing patterns of articles discussing different countries, for understanding their wider implications in preserving or damaging geopolitical relationships.},
  archive   = {C_AAAI},
  author    = {Preetika Verma and Hansin Ahuja and Kokil Jaidka},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27037},
  pages     = {16354-16355},
  title     = {Quantify the political bias in news edits: Experiments with few-shot learners (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Global explanations for image classifiers (student
abstract). <em>AAAI</em>, 16352–16353. (<a
href="https://doi.org/10.1609/aaai.v37i13.27036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We hypothesize that deep network classifications of complex scenes can be explained using sets of relevant objects. We employ beam search and singular value decomposition to generate local and global explanations that summarize the deep model&#39;s interpretation of a class.},
  archive   = {C_AAAI},
  author    = {Bhavan K. Vasu and Prasad Tadepalli},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27036},
  pages     = {16352-16353},
  title     = {Global explanations for image classifiers (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploring the effectiveness of mask-guided feature
modulation as a mechanism for localized style editing of real images
(student abstract). <em>AAAI</em>, 16350–16351. (<a
href="https://doi.org/10.1609/aaai.v37i13.27035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The success of Deep Generative Models at high-resolution image generation has led to their extensive utilization for style editing of real images. Most existing methods work on the principle of inverting real images onto their latent space, followed by determining controllable directions. Both inversion of real images and determination of controllable latent directions are computationally expensive operations. Moreover, the determination of controllable latent directions requires additional human supervision. This work aims to explore the efficacy of mask-guided feature modulation in the latent space of a Deep Generative Model as a solution to these bottlenecks. To this end, we present the SemanticStyle Autoencoder (SSAE), a deep Generative Autoencoder model that leverages semantic mask-guided latent space manipulation for highly localized photorealistic style editing of real images. We present qualitative and quantitative results for the same and their analysis. This work shall serve as a guiding primer for future work.},
  archive   = {C_AAAI},
  author    = {Snehal Singh Tomar and Maitreya Suin and A. N. Rajagopalan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27035},
  pages     = {16350-16351},
  title     = {Exploring the effectiveness of mask-guided feature modulation as a mechanism for localized style editing of real images (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The naughtyformer: A transformer understands and moderates
adult humor (student abstract). <em>AAAI</em>, 16348–16349. (<a
href="https://doi.org/10.1609/aaai.v37i13.27034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Jokes are intentionally written to be funny, but not all jokes are created the same. While recent work has shown impressive results on humor detection in text, we instead investigate the more nuanced task of detecting humor subtypes, especially of the more adult variety. To that end, we introduce a novel jokes dataset filtered from Reddit and solve the subtype classification task using a finetuned Transformer dubbed the Naughtyformer. Moreover, we show that our model is significantly better at detecting offensiveness in jokes compared to state-of-the-art methods.},
  archive   = {C_AAAI},
  author    = {Leonard Tang and Alexander Cai and Jason Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27034},
  pages     = {16348-16349},
  title     = {The naughtyformer: A transformer understands and moderates adult humor (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Parallel index-based search algorithm for coalition
structure generation (student abstract). <em>AAAI</em>, 16346–16347. (<a
href="https://doi.org/10.1609/aaai.v37i13.27033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we propose a novel algorithm to address the Coalition Structure Generation (CSG) problem. Specifically, we use a novel representation of the search space that enables it to be explored in a new way. We introduce an index-based exact algorithm. Our algorithm is anytime, produces optimal solutions, and can be run on large-scale problems with hundreds of agents. Our experimental evaluation on a benchmark with several value distributions shows that our representation of the search space that we combined with the proposed algorithm provides high-quality results for the CSG problem and outperforms existing state-of-the-art algorithms.},
  archive   = {C_AAAI},
  author    = {Redha Taguelmimt and Samir Aknine and Djamila Boukredera and Narayan Changder},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27033},
  pages     = {16346-16347},
  title     = {Parallel index-based search algorithm for coalition structure generation (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploration on physics-informed neural networks on partial
differential equations (student abstract). <em>AAAI</em>, 16344–16345.
(<a href="https://doi.org/10.1609/aaai.v37i13.27032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Data-driven related solutions are dominating various scientific fields with the assistance of machine learning and data analytics. Finding effective solutions has long been discussed in the area of machine learning. The recent decade has witnessed the promising performance of the Physics-Informed Neural Networks (PINN) in bridging the gap between real-world scientific problems and machine learning models. In this paper, we explore the behavior of PINN in a particular range of different diffusion coefficients under specific boundary conditions. In addition, different initial conditions of partial differential equations are solved by applying the proposed PINN. Our paper illustrates how the effectiveness of the PINN can change under various scenarios. As a result, we demonstrate a better insight into the behaviors of the PINN and how to make the proposed method more robust while encountering different scientific and engineering problems.},
  archive   = {C_AAAI},
  author    = {Hoa Ta and Shi Wen Wong and Nathan McClanahan and Jung-Han Kimn and Kaiqun Fu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27032},
  pages     = {16344-16345},
  title     = {Exploration on physics-informed neural networks on partial differential equations (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ES-mask: Evolutionary strip mask for explaining time series
prediction (student abstract). <em>AAAI</em>, 16342–16343. (<a
href="https://doi.org/10.1609/aaai.v37i13.27031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Machine learning models are increasingly used in time series prediction with promising results. The model explanation of time series prediction falls behind the model development and makes less sense to users in understanding model decisions. This paper proposes ES-Mask, a post-hoc and model-agnostic evolutionary strip mask-based saliency approach for time series applications. ES-Mask designs the mask consisting of strips with the same salient value in consecutive time steps to produce binary and sustained feature importance scores over time for easy understanding and interpretation of time series. ES-Mask uses an evolutionary algorithm to search for the optimal mask by manipulating strips in rounds, thus is agnostic to models by involving no internal model states in the search. The initial experiments on MIMIC-III data set show that ES-Mask outperforms state-of-the-art methods.},
  archive   = {C_AAAI},
  author    = {Yifei Sun and Cheng Song and Feng Lu and Wei Li and Hai Jin and Albert Y. Zomaya},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27031},
  pages     = {16342-16343},
  title     = {ES-mask: Evolutionary strip mask for explaining time series prediction (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Two-streams: Dark and light networks with graph convolution
for action recognition from dark videos (student abstract).
<em>AAAI</em>, 16340–16341. (<a
href="https://doi.org/10.1609/aaai.v37i13.27030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this article, we propose a two-stream action recognition technique for recognizing human actions from dark videos. The proposed action recognition network consists of an image enhancement network with Self-Calibrated Illumination (SCI) module, followed by a two-stream action recognition network. We have used R(2+1)D as a feature extractor for both streams with shared weights. Graph Convolutional Network (GCN), a temporal graph encoder is utilized to enhance the obtained features which are then further fed to a classification head to recognize the actions in a video. The experimental results are presented on the recent benchmark ``ARID&quot; dark-video database.},
  archive   = {C_AAAI},
  author    = {Saurabh Suman and Nilay Naharas and Badri Narayan Subudhi and Vinit Jakhetiya},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27030},
  pages     = {16340-16341},
  title     = {Two-streams: Dark and light networks with graph convolution for action recognition from dark videos (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Backforward propagation (student abstract). <em>AAAI</em>,
16338–16339. (<a
href="https://doi.org/10.1609/aaai.v37i13.27029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper we introduce Backforward Propagation, a method of completely eliminating Internal Covariate Shift (ICS). Unlike previous methods, which only indirectly reduce the impact of ICS while introducing other biases, we are able to have a surgical view at the effects ICS has on training neural networks. Our experiments show that ICS has a weight regularizing effect on models, and completely removing it enables for faster convergence of the neural network.},
  archive   = {C_AAAI},
  author    = {George Stoica and Cristian Simionescu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27029},
  pages     = {16338-16339},
  title     = {Backforward propagation (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploring the relative value of collaborative optimisation
pathways (student abstract). <em>AAAI</em>, 16336–16337. (<a
href="https://doi.org/10.1609/aaai.v37i13.27028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Compression techniques in machine learning (ML) independently improve a model’s inference efficiency by reducing its memory footprint while aiming to maintain its quality. This paper lays groundwork in questioning the merit of a compression pipeline involving all techniques as opposed to skipping a few by considering a case study on a keyword spotting model: DS-CNN-S. In addition, it documents improvements to the model’s training and dataset infrastructure. For this model, preliminary findings suggest that a full-scale pipeline isn’t required to achieve a competent memory footprint and accuracy, but a more comprehensive study is required.},
  archive   = {C_AAAI},
  author    = {Sudarshan Sreeram},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27028},
  pages     = {16336-16337},
  title     = {Exploring the relative value of collaborative optimisation pathways (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TA-DA: Topic-aware domain adaptation for scientific
keyphrase identification and classification (student abstract).
<em>AAAI</em>, 16334–16335. (<a
href="https://doi.org/10.1609/aaai.v37i13.27027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Keyphrase identification and classification is a Natural Language Processing and Information Retrieval task that involves extracting relevant groups of words from a given text related to the main topic. In this work, we focus on extracting keyphrases from scientific documents. We introduce TA-DA, a Topic-Aware Domain Adaptation framework for keyphrase extraction that integrates Multi-Task Learning with Adversarial Training and Domain Adaptation. Our approach improves performance over baseline models by up to 5\% in the exact match of the F1-score.},
  archive   = {C_AAAI},
  author    = {Răzvan-Alexandru Smădu and George-Eduard Zaharia and Andrei-Marius Avram and Dumitru-Clementin Cercel and Mihai Dascalu and Florin Pop},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27027},
  pages     = {16334-16335},
  title     = {TA-DA: Topic-aware domain adaptation for scientific keyphrase identification and classification (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Persistent homology through image segmentation (student
abstract). <em>AAAI</em>, 16332–16333. (<a
href="https://doi.org/10.1609/aaai.v37i13.27026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The efficacy of topological data analysis (TDA) has been demonstrated in many different machine learning pipelines, particularly those in which structural characteristics of data are highly relevant. However, TDA&#39;s usability in large scale machine learning applications is hindered by the significant computational cost of generating persistence diagrams. In this work, a method that allows this computationally expensive process to be approximated by deep neural networks is proposed. Moreover, the method&#39;s practicality in estimating 0-dimensional persistence diagrams across a diverse range of images is shown.},
  archive   = {C_AAAI},
  author    = {Joshua Slater and Thomas Weighill},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27026},
  pages     = {16332-16333},
  title     = {Persistent homology through image segmentation (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Development of a human-agent interaction system including
norm and emotion in an evacuation situation (student abstract).
<em>AAAI</em>, 16330–16331. (<a
href="https://doi.org/10.1609/aaai.v37i13.27025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Agent-based modeling and simulation can provide a powerful test environment for crisis management scenarios. Human agent interaction has limitations in representing norms issued by an agent to a human agent that has emotions. In this study, we present an approach to the interaction between a virtual normative agent and a human agent in an evacuation scenario. Through simulation comparisons, it is shown that the method used in this study can more fully simulate the real-life out come of an emergency situation and also improves the au thenticity of the agent interaction.},
  archive   = {C_AAAI},
  author    = {Ephraim Sinyabe Pagou and Vivient Corneille Kamla and Igor Tchappi and Amro Najjar},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27025},
  pages     = {16330-16331},
  title     = {Development of a human-agent interaction system including norm and emotion in an evacuation situation (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient dynamic batch adaptation (student abstract).
<em>AAAI</em>, 16328–16329. (<a
href="https://doi.org/10.1609/aaai.v37i13.27024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper we introduce Efficient Dynamic Batch Adaptation (EDBA), which improves on a previous method that works by adjusting the composition and the size of the current batch. Our improvements allow for Dynamic Batch Adaptation to feasibly scale up for bigger models and datasets, drastically improving model convergence and generalization. We show how the method is still able to perform especially well in data-scarce scenarios, managing to obtain a test accuracy on 100 samples of CIFAR-10 of 90.68\%, while the baseline only reaches 23.79\%. On the full CIFAR-10 dataset, EDBA reaches convergence in ∼120 epochs while the baseline requires ∼300 epochs.},
  archive   = {C_AAAI},
  author    = {Cristian Simionescu and George Stoica},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27024},
  pages     = {16328-16329},
  title     = {Efficient dynamic batch adaptation (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Scalable negotiating agent strategy via multi-issue policy
network (student abstract). <em>AAAI</em>, 16326–16327. (<a
href="https://doi.org/10.1609/aaai.v37i13.27023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Previous research on the comprehensive negotiation strategy using deep reinforcement learning (RL) has scalability issues of not performing effectively in the large-sized domains. We improve negotiation strategy via deep RL by considering an issue-based represented deep policy network to deal with multi-issue negotiation. The architecture of the proposed learning agent considers the characteristics of multi-issue negotiation domains and policy-based learning. We demonstrate that proposed method achieve equivalent or higher utility than existing negotiation agents in the large-sized domains.},
  archive   = {C_AAAI},
  author    = {Takumu Shimizu and Ryota Higa and Toki Takahashi and Katsuhide Fujita and Shinji Nakadai},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27023},
  pages     = {16326-16327},
  title     = {Scalable negotiating agent strategy via multi-issue policy network (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bayesian models for targeted cyber deception strategies
(student abstract). <em>AAAI</em>, 16324–16325. (<a
href="https://doi.org/10.1609/aaai.v37i13.27022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose a model-driven decision support system (DSS) based on a Bayesian belief network (BBN) to support cyber deception based on a detailed model of attacker beliefs. We discuss this approach using a case study based on passively observed operating system (OS) fingerprinting data. In passive reconnaissance attackers can remain undetected while collecting information to identify systems and plan attacks. Our DSS is intended to support preventative measures to protect the network from successful reconnaissance, such as by modifying features using deception. We validate the prediction accuracy of the model in comparison with a sequential artificial neural network (ANN). We then introduce a deceptive algorithm to select a minimal set of features for OS obfuscation. We show the effectiveness of feature-modification strategies based on our methods using passively collected data to decide what features from a real operating system (OS) to modify to appear as a fake [different] OS.},
  archive   = {C_AAAI},
  author    = {Nazia Sharmin},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27022},
  pages     = {16324-16325},
  title     = {Bayesian models for targeted cyber deception strategies (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Can adversarial networks make uninformative colonoscopy
video frames clinically informative? (Student abstract). <em>AAAI</em>,
16322–16323. (<a
href="https://doi.org/10.1609/aaai.v37i13.27021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Various artifacts, such as ghost colors, interlacing, and motion blur, hinder diagnosing colorectal cancer (CRC) from videos acquired during colonoscopy. The frames containing these artifacts are called uninformative frames and are present in large proportions in colonoscopy videos. To alleviate the impact of artifacts, we propose an adversarial network based framework to convert uninformative frames to clinically relevant frames. We examine the effectiveness of the proposed approach by evaluating the translated frames for polyp detection using YOLOv5. Preliminary results present improved detection performance along with elegant qualitative outcomes. We also examine the failure cases to determine the directions for future work.},
  archive   = {C_AAAI},
  author    = {Vanshali Sharma and M.K. Bhuyan and Pradip K. Das},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27021},
  pages     = {16322-16323},
  title     = {Can adversarial networks make uninformative colonoscopy video frames clinically informative? (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FakeKG: A knowledge graph of fake claims for improving
automated fact-checking (student abstract). <em>AAAI</em>, 16320–16321.
(<a href="https://doi.org/10.1609/aaai.v37i13.27020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {False information could be dangerous if the claim is not debunked timely. Fact-checking organisations get a high volume of claims on different topics with immense velocity. The efficiency of the fact-checkers decreases due to 3V problems volume, velocity and variety. Especially during crises or elections, fact-checkers cannot handle user requests to verify the claim. Until now, no real-time curable centralised corpus of fact-checked articles is available. Also, the same claim is fact-checked by multiple fact-checking organisations with or without judgement. To fill this gap, we introduce FakeKG: A Knowledge Graph-Based approach for improving Automated Fact-checking. FakeKG is a centralised knowledge graph containing fact-checked articles from different sources that can be queried using the SPARQL endpoint. The proposed FakeKG can prescreen claim requests and filter them if the claim is already fact-checked and provide a judgement to the claim. It will also categorise the claim&#39;s domain so that the fact-checker can prioritise checking the incoming claims into different groups like health and election. This study proposes an approach for creating FakeKG and its future application for mitigating misinformation.},
  archive   = {C_AAAI},
  author    = {Gautam Kishore Shahi},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27020},
  pages     = {16320-16321},
  title     = {FakeKG: A knowledge graph of fake claims for improving automated fact-checking (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Can you answer this? – exploring zero-shot QA generalization
capabilities in large language models (student abstract). <em>AAAI</em>,
16318–16319. (<a
href="https://doi.org/10.1609/aaai.v37i13.27019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The buzz around Transformer-based language models (TLM) such as BERT, RoBERTa, etc. is well-founded owing to their impressive results on an array of tasks. However, when applied to areas needing specialized knowledge (closed-domain), such as medical, finance, etc. their performance takes drastic hits, sometimes more than their older recurrent/convolutional counterparts. In this paper, we explore zero-shot capabilities of large LMs for extractive QA. Our objective is to examine performance change in the face of domain drift i.e. when the target domain data is vastly different in semantic and statistical properties from the source domain and attempt to explain the subsequent behavior. To this end, we present two studies in this paper while planning further experiments later down the road. Our findings indicate flaws in the current generation of TLM limiting their performance on closed-domain tasks.},
  archive   = {C_AAAI},
  author    = {Saptarshi Sengupta and Shreya Ghosh and Preslav Nakov and Prasenjit Mitra},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27019},
  pages     = {16318-16319},
  title     = {Can you answer this? – exploring zero-shot QA generalization capabilities in large language models (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Maximizing influence spread through a dynamic social network
(student abstract). <em>AAAI</em>, 16316–16317. (<a
href="https://doi.org/10.1609/aaai.v37i13.27018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Modern social networks are dynamic in their nature; a new connections are appearing and old connections are disappearing all the time. However, in our algorithmic and complexity studies, we usually model social networks as static graphs. In this paper, we propose a new paradigm for the study of the well-known Target Set Selection problem, which is a fundamental problem in viral marketing and the spread of opinion through social networks. In particular, we use temporal graphs to capture the dynamic nature of social networks. We show that the temporal interpretation is, unsurprisingly, NP-complete in general. Then, we study computational complexity of this problem for multiple restrictions of both the threshold function and the underlying graph structure and provide multiple hardness lower-bounds.},
  archive   = {C_AAAI},
  author    = {Šimon Schierreich},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27018},
  pages     = {16316-16317},
  title     = {Maximizing influence spread through a dynamic social network (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RFC-net: Learning high resolution global features for
medical image segmentation on a computational budget (student abstract).
<em>AAAI</em>, 16314–16315. (<a
href="https://doi.org/10.1609/aaai.v37i13.27017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Learning High-Resolution representations is essential for semantic segmentation. Convolutional neural network (CNN) architectures with downstream and upstream propagation flow are popular for segmentation in medical diagnosis. However, due to performing spatial downsampling and upsampling in multiple stages, information loss is inexorable. On the contrary, connecting layers densely on high spatial resolution is computationally expensive. In this work, we devise a Loose Dense Connection Strategy to connect neurons in subsequent layers with reduced parameters. On top of that, using a m-way Tree structure for feature propagation we propose Receptive Field Chain Network (RFC-Net) that learns high-resolution global features on a compressed computational space. Our experiments demonstrates that RFC Net achieves state-of-the-art performance on Kvasir and CVC-ClinicDB benchmarks for Polyp segmentation. Our code is publicly available at github.com/sourajitcs/RFC-NetAAAI23.},
  archive   = {C_AAAI},
  author    = {Sourajit Saha and Shaswati Saha and Md Osman Gani and Tim Oates and David Chapman},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27017},
  pages     = {16314-16315},
  title     = {RFC-net: Learning high resolution global features for medical image segmentation on a computational budget (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Photogrammetry and VR for comparing 2D and immersive
linguistic data collection (student abstract). <em>AAAI</em>,
16312–16313. (<a
href="https://doi.org/10.1609/aaai.v37i13.27016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The overarching goal of this work is to enable the collection of language describing a wide variety of objects viewed in virtual reality. We aim to create full 3D models from a small number of ‘keyframe’ images of objects found in the publicly available Grounded Language Dataset (GoLD) using photogrammetry. We will then collect linguistic descriptions by placing our models in virtual reality and having volunteers describe them. To evaluate the impact of virtual reality immersion on linguistic descriptions of the objects, we intend to apply contrastive learning to perform grounded language learning, then compare the descriptions collected from images (in GoLD) versus our models.},
  archive   = {C_AAAI},
  author    = {Jacob Rubinstein and Cynthia Matuszek and Don Engel},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27016},
  pages     = {16312-16313},
  title     = {Photogrammetry and VR for comparing 2D and immersive linguistic data collection (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fuzzy c-means: Differences on clustering behavior between
high dimensional and functional data (student abstract). <em>AAAI</em>,
16310–16311. (<a
href="https://doi.org/10.1609/aaai.v37i13.27015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Fuzzy c-means (FCM) is a generalization of the classical k-means clustering algorithm to the case where an observation can belong to several clusters at the same time. The algorithm was previously observed to have initialization problems when the number of desired clusters or the number of dimensions of the data are high. We have tested FCM against clustering problems with functional data, generated from stationary Gaussian processes, and thus in principle infinite-dimensional. We observed that when the data is more functional in nature, which can be obtained by tuning the length-scale parameter of the Gaussian process, the aforementioned problems do not appear. This not only indicates that FCM is suitable as a clustering method for functional data, but also illustrates how functional data differs from traditional multivariate data. In addition this seems to suggest a qualitative way to measure the latent dimensionality of the functional distribution itself.},
  archive   = {C_AAAI},
  author    = {Carlos Ramos-Carreño},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27015},
  pages     = {16310-16311},
  title     = {Fuzzy C-means: Differences on clustering behavior between high dimensional and functional data (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Explaining large language model-based neural semantic
parsers (student abstract). <em>AAAI</em>, 16308–16309. (<a
href="https://doi.org/10.1609/aaai.v37i13.27014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {While large language models (LLMs) have demonstrated strong capability in structured prediction tasks such as semantic parsing, few amounts of research have explored the underlying mechanisms of their success. Our work studies different methods for explaining an LLM-based semantic parser and qualitatively discusses the explained model behaviors, hoping to inspire future research toward better understanding them.},
  archive   = {C_AAAI},
  author    = {Daking Rai and Yilun Zhou and Bailin Wang and Ziyu Yao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27014},
  pages     = {16308-16309},
  title     = {Explaining large language model-based neural semantic parsers (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A probabilistic graph diffusion model for source
localization (student abstract). <em>AAAI</em>, 16306–16307. (<a
href="https://doi.org/10.1609/aaai.v37i13.27013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Source localization, as a reverse problem of graph diffusion, is important for many applications such as rumor tracking, detecting computer viruses, and finding epidemic spreaders. However, it is still under-explored due to the inherent uncertainty of the diffusion process: after a long period of propagation, the same diffusion process may start with diverse sources. Most existing solutions utilize deterministic models and therefore cannot describe the diffusion uncertainty of sources. Moreover, current probabilistic approaches are hard to conduct smooth transformations with variational inference. To overcome the limitations, we propose a probabilistic framework using continuous normalizing flows with invertible transformations and graph neural networks to explicitly model the uncertainty of the diffusion source. Experimental results on two real-world datasets demonstrate the effectiveness of our model over strong baselines.},
  archive   = {C_AAAI},
  author    = {Tangjiang Qian and Xovee Xu and Zhe Xiao and Ting Zhong and Fan Zhou},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27013},
  pages     = {16306-16307},
  title     = {A probabilistic graph diffusion model for source localization (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Ordinal programmatic weak supervision and crowdsourcing for
estimating cognitive states (student abstract). <em>AAAI</em>,
16304–16305. (<a
href="https://doi.org/10.1609/aaai.v37i13.27012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Crowdsourcing and weak supervision offer methods to efficiently label large datasets. Our work builds on existing weak supervision models to accommodate ordinal target classes, in an effort to recover ground truth from weak, external labels. We define a parameterized factor function and show that our approach improves over other baselines.},
  archive   = {C_AAAI},
  author    = {Prakruthi Pradeep and Benedikt Boecking and Nicholas Gisolfi and Jacob R. Kintz and Torin K. Clark and Artur Dubrawski},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27012},
  pages     = {16304-16305},
  title     = {Ordinal programmatic weak supervision and crowdsourcing for estimating cognitive states (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evaluating factors influencing COVID-19 outcomes across
countries using decision trees (student abstract). <em>AAAI</em>,
16302–16303. (<a
href="https://doi.org/10.1609/aaai.v37i13.27011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {While humanity prepares for a post-pandemic world and a return to normality through worldwide vaccination campaigns, each country experienced different levels of impact based on natural, political, regulatory, and socio-economic factors. To prepare for a possible future with COVID-19 and similar outbreaks, it is imperative to understand how each of these factors impacted spread and mortality. We train and tune two decision tree regression models to predict COVID-related cases and deaths using a multitude of features. Our findings suggest that, at the country-level, GDP per capita and comorbidity mortality rate are best predictors for both outcomes. Furthermore, latitude and smoking prevalence are also significantly related to COVID-related spread and mortality.},
  archive   = {C_AAAI},
  author    = {Aniruddha Pokhrel and Nikesh Subedi and Saurav Keshari Aryal},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27011},
  pages     = {16302-16303},
  title     = {Evaluating factors influencing COVID-19 outcomes across countries using decision trees (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural language model based attentive term dependence model
for verbose query (student abstract). <em>AAAI</em>, 16300–16301. (<a
href="https://doi.org/10.1609/aaai.v37i13.27010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The query-document term matching plays an important role in information retrieval. However, the retrieval performance degrades when the documents get matched with the extraneous terms of the query which frequently arises in verbose queries. To address this problem, we generate the dense vector of the entire query and individual query terms using the pre-trained BERT (Bidirectional Encoder Representations from Transformers) model and subsequently analyze their relation to focus on the central terms. We then propose a context-aware attentive extension of unsupervised Markov Random Field-based sequential term dependence model that explicitly pays more attention to those contextually central terms. The proposed model utilizes the strengths of the pre-trained large language model for estimating the attention weight of terms and rank the documents in a single pass without any supervision.},
  archive   = {C_AAAI},
  author    = {Dipannita Podder and Jiaul H. Paik and Pabitra Mitra},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27010},
  pages     = {16300-16301},
  title     = {Neural language model based attentive term dependence model for verbose query (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generative pipeline for data augmentation of unconstrained
document images with structural and textural degradation (student
abstract). <em>AAAI</em>, 16298–16299. (<a
href="https://doi.org/10.1609/aaai.v37i13.27009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Computer vision applications for document image understanding (DIU) such as optical character recognition, word spotting, enhancement etc. suffer from structural deformations like strike-outs and unconstrained strokes, to name a few. They also suffer from texture degradation due to blurring, aging, or blotting-spots etc. The DIU applications with deep networks are limited to constrained environment and lack diverse data with text-level and pixel-level annotation simultaneously. In this work, we propose a generative framework to produce realistic synthetic handwritten document images with simultaneous annotation of text and corresponding pixel-level spatial foreground information. The proposed approach generates realistic backgrounds with artificial handwritten texts which supplements data-augmentation in multiple unconstrained DIU systems. The proposed framework is an early work to facilitate DIU system-evaluation in both image quality and recognition performance at a go.},
  archive   = {C_AAAI},
  author    = {Arnab Poddar and Abhishek Kumar Sah and Soumyadeep Dey and Pratik Jawanpuria and Jayanta Mukhopadhyay and Prabir Kumar Biswas},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27009},
  pages     = {16298-16299},
  title     = {Generative pipeline for data augmentation of unconstrained document images with structural and textural degradation (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hardness of learning AES key (student abstract).
<em>AAAI</em>, 16296–16297. (<a
href="https://doi.org/10.1609/aaai.v37i13.27008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We show hardness of learning AES key from pairs of ciphertexts under the assumption of computational closeness of AES to pairwise independence. The latter is motivated by a recent result on statistical closeness of AES to pairwise independence.},
  archive   = {C_AAAI},
  author    = {Artur Pak and Sultan Nurmukhamedov and Rustem Takhanov and Zhenisbek Assylbekov},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27008},
  pages     = {16296-16297},
  title     = {Hardness of learning AES key (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). LVRNet: Lightweight image restoration for aerial images
under low visibility (student abstract). <em>AAAI</em>, 16294–16295. (<a
href="https://doi.org/10.1609/aaai.v37i13.27007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Learning to recover clear images from images having a combination of degrading factors is a challenging task. That being said, autonomous surveillance in low visibility conditions caused by high pollution/smoke, poor air quality index, low light, atmospheric scattering, and haze during a blizzard, etc, becomes even more important to prevent accidents. It is thus crucial to form a solution that can not only result in a high-quality image but also which is efficient enough to be deployed for everyday use. However, the lack of proper datasets available to tackle this task limits the performance of the previous methods proposed. To this end, we generate the LowVis-AFO dataset, containing 3647 paired dark-hazy and clear images. We also introduce a new lightweight deep learning model called Low-Visibility Restoration Network (LVRNet). It outperforms previous image restoration methods with low latency, achieving a PSNR value of 25.744 and an SSIM of 0.905, hence making our approach scalable and ready for practical use.},
  archive   = {C_AAAI},
  author    = {Esha Pahwa and Achleshwar Luthra and Pratik Narang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27007},
  pages     = {16294-16295},
  title     = {LVRNet: Lightweight image restoration for aerial images under low visibility (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving adversarial robustness to sensitivity and
invariance attacks with deep metric learning (student abstract).
<em>AAAI</em>, 16292–16293. (<a
href="https://doi.org/10.1609/aaai.v37i13.27006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Intentionally crafted adversarial samples have effectively exploited weaknesses in deep neural networks. A standard method in adversarial robustness assumes a framework to defend against samples crafted by minimally perturbing a sample such that its corresponding model output changes. These sensitivity attacks exploit the model&#39;s sensitivity toward task-irrelevant features. Another form of adversarial sample can be crafted via invariance attacks, which exploit the model underestimating the importance of relevant features. Previous literature has indicated a tradeoff in defending against both attack types within a strictly L-p bounded defense. To promote robustness toward both types of attacks beyond Euclidean distance metrics, we use metric learning to frame adversarial regularization as an optimal transport problem. Our preliminary results indicate that regularizing over invariant perturbations in our framework improves both invariant and sensitivity defense.},
  archive   = {C_AAAI},
  author    = {Anaelia Ovalle and Evan Czyzycki and Cho-Jui Hsieh},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27006},
  pages     = {16292-16293},
  title     = {Improving adversarial robustness to sensitivity and invariance attacks with deep metric learning (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fraud’s bargain attacks to textual classifiers via
metropolis-hasting sampling (student abstract). <em>AAAI</em>,
16290–16291. (<a
href="https://doi.org/10.1609/aaai.v37i13.27005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent studies on adversarial examples expose vulnerabilities of natural language processing (NLP) models. Existing techniques for generating adversarial examples are typically driven by deterministic heuristic rules that are agnostic to the optimal adversarial examples, a strategy that often results in attack failures. To this end, this research proposes Fraud&#39;s Bargain Attack (FBA), which utilizes a novel randomization mechanism to enlarge the searching space and enables high-quality adversarial examples to be generated with high probabilities. FBA applies the Metropolis-Hasting algorithm to enhance the selection of adversarial examples from all candidates proposed by a customized Word Manipulation Process (WMP). WMP perturbs one word at a time via insertion, removal, or substitution in a contextual-aware manner. Extensive experiments demonstrate that FBA outperforms the baselines in terms of attack success rate and imperceptibility.},
  archive   = {C_AAAI},
  author    = {Mingze Ni and Zhensu Sun and Wei Liu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27005},
  pages     = {16290-16291},
  title     = {Fraud’s bargain attacks to textual classifiers via metropolis-hasting sampling (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Pre-training with scientific text improves educational
question generation (student abstract). <em>AAAI</em>, 16288–16289. (<a
href="https://doi.org/10.1609/aaai.v37i13.27004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With the boom of digital educational materials and scalable e-learning systems, the potential for realising AI-assisted personalised learning has skyrocketed. In this landscape, the automatic generation of educational questions will play a key role, enabling scalable self-assessment when a global population is manoeuvring their personalised learning journeys. We develop EduQG, a novel educational question generation model built by adapting a large language model. Our initial experiments demonstrate that EduQG can produce superior educational questions by pre-training on scientific text.},
  archive   = {C_AAAI},
  author    = {Hamze Muse and Sahan Bulathwela and Emine Yilmaz},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27004},
  pages     = {16288-16289},
  title     = {Pre-training with scientific text improves educational question generation (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Novel intent detection and active learning based
classification (student abstract). <em>AAAI</em>, 16286–16287. (<a
href="https://doi.org/10.1609/aaai.v37i13.27003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Novel intent class detection is an important problem in real world scenario for conversational agents for continuous interaction. Several research works have been done to detect novel intents in a mono-lingual (primarily English) texts and images. But, current systems lack an end-to-end universal framework to detect novel intents across various different languages with less human annotation effort for mis-classified and system rejected samples. This paper proposes NIDAL (Novel Intent Detection and Active Learning based classification), a semi-supervised framework to detect novel intents while reducing human annotation cost. Empirical results on various benchmark datasets demonstrate that this system outperforms the baseline methods by more than 10\% margin for accuracy and macro-F1. The system achieves this while maintaining overall annotation cost to be just ~6-10\% of the unlabeled data available to the system.},
  archive   = {C_AAAI},
  author    = {Ankan Mullick},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27003},
  pages     = {16286-16287},
  title     = {Novel intent detection and active learning based classification (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Counting knot mosaics with ALLSAT (student abstract).
<em>AAAI</em>, 16284–16285. (<a
href="https://doi.org/10.1609/aaai.v37i13.27002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Knot mosaics are a model of a quantum knot system. A knot mosaic is a m-by-n grid where each location on the grid may contain any of 11 possible tiles such that the final layout has closed loops. Oh et al. proved a recurrence relation of state matrices to count the number of m-by-n knot mosaics. Our contribution is to use ALLSAT solvers to count knot mosaics and to experimentally try different ways to encode the AT MOST ONE constraint in SAT. We plan to use our SAT method as a tool to list knot mosaics of interest for specific classes of knots.},
  archive   = {C_AAAI},
  author    = {Hannah Miller},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27002},
  pages     = {16284-16285},
  title     = {Counting knot mosaics with ALLSAT (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Label smoothing for emotion detection (student abstract).
<em>AAAI</em>, 16282–16283. (<a
href="https://doi.org/10.1609/aaai.v37i13.27001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Automatically detecting emotions from text has countless applications, ranging from large scale opinion mining to social robots in healthcare and education. However, emotions are subjective in nature and are often expressed in ambiguous ways. At the same time, detecting emotions can also require implicit reasoning, which may not be available as surface- level, lexical information. In this work, we conjecture that the overconfidence of pre-trained language models such as BERT is a critical problem in emotion detection and show that alleviating this problem can considerably improve the generalization performance. We carry out comprehensive experiments on four emotion detection benchmark datasets and show that calibrating our model predictions leads to an average improvement of 1.35\% in weighted F1 score.},
  archive   = {C_AAAI},
  author    = {George Maratos and Tiberiu Sosea and Cornelia Caragea},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27001},
  pages     = {16282-16283},
  title     = {Label smoothing for emotion detection (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Debiasing intrinsic bias and application bias jointly via
invariant risk minimization (student abstract). <em>AAAI</em>,
16280–16281. (<a
href="https://doi.org/10.1609/aaai.v37i13.27000">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Demographic biases and social stereotypes are common in pretrained language models (PLMs), while the fine-tuning in downstream applications can also produce new biases or amplify the impact of the original biases. Existing works separate the debiasing from the fine-tuning procedure, which results in a gap between intrinsic bias and application bias. In this work, we propose a debiasing framework CauDebias to eliminate both biases, which directly combines debiasing with fine-tuning and can be applied for any PLMs in downstream tasks. We distinguish the bias-relevant (non-causal factors) and label-relevant (causal factors) parts in sentences from a causal invariant perspective. Specifically, we perform intervention on non-causal factors in different demographic groups, and then devise an invariant risk minimization loss to trade-off performance between bias mitigation and task accuracy. Experimental results on three downstream tasks show that our CauDebias can remarkably reduce biases in PLMs while minimizing the impact on downstream tasks.},
  archive   = {C_AAAI},
  author    = {Yuzhou Mao and Liu Yu and Yi Yang and Fan Zhou and Ting Zhong},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27000},
  pages     = {16280-16281},
  title     = {Debiasing intrinsic bias and application bias jointly via invariant risk minimization (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A mutually enhanced bidirectional approach for jointly
mining user demand and sentiment (student abstract). <em>AAAI</em>,
16278–16279. (<a
href="https://doi.org/10.1609/aaai.v37i13.26999">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {User demand mining aims to identify the implicit demand from the e-commerce reviews, which are always irregular, vague and diverse. Existing sentiment analysis research mainly focuses on aspect-opinion-sentiment triplet extraction, while the deeper user demands remain unexplored. In this paper, we formulate a novel research question of jointly mining aspect-opinion-sentiment-demand, and propose a Mutually Enhanced Bidirectional Extraction (MEMB) framework for capturing the dynamic interaction among different types of information. Finally, experiments on Chinese e-commerce data demonstrate the efficacy of the proposed model.},
  archive   = {C_AAAI},
  author    = {Xue Mao and Haoda Qian and Minjie Yuan and Qiudan Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26999},
  pages     = {16278-16279},
  title     = {A mutually enhanced bidirectional approach for jointly mining user demand and sentiment (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Risk-aware decentralized safe control via dynamic
responsibility allocation (student abstract). <em>AAAI</em>,
16276–16277. (<a
href="https://doi.org/10.1609/aaai.v37i13.26998">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this work, we present a novel risk-aware decentralized Control Barrier Function (CBF)-based controller for multi-agent systems. The proposed decentralized controller is composed based on pairwise agent responsibility shares (a percentage), calculated from the risk evaluation of each individual agent faces in a multi-agent interaction environment. With our proposed CBF-inspired risk evaluation framework, the responsibility portions between pairwise agents are dynamically updated based on the relative risk they face. Our method allows agents with lower risk to enjoy a higher level of freedom in terms of a wider action space, and the agents exposed to higher risk are constrained more tightly on action spaces, and are therefore forced to proceed with caution.},
  archive   = {C_AAAI},
  author    = {Yiwei Lyu and Wenhao Luo and John M. Dolan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26998},
  pages     = {16276-16277},
  title     = {Risk-aware decentralized safe control via dynamic responsibility allocation (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Toplogical data analysis detects and classifies sunspots
(student abstract). <em>AAAI</em>, 16274–16275. (<a
href="https://doi.org/10.1609/aaai.v37i13.26997">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In our technology-dependent modern world, it is imperative to monitor the Sun for space weather threats to critical infrastructure. Topological data analysis (TDA) is a new set of mathematical techniques used in data analysis and machine learning. We demonstrate that TDA can robustly detect and classify solar surface and coronal activity. This technique is a promising step toward future application in predictive space weather modeling.},
  archive   = {C_AAAI},
  author    = {Aidan Lytle and Neil Pritchard and Alicia Aarnio and Thomas Weighill},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26997},
  pages     = {16274-16275},
  title     = {Toplogical data analysis detects and classifies sunspots (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Semi-supervised review-aware rating regression (student
abstract). <em>AAAI</em>, 16272–16273. (<a
href="https://doi.org/10.1609/aaai.v37i13.26996">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Semi-supervised learning is a promising solution to mitigate data sparsity in review-aware rating regression (RaRR), but it bears the risk of learning with noisy pseudo-labelled data. In this paper, we propose a paradigm called co-training-teaching (CoT2), which integrates the merits of both co-training and co-teaching towards the robust semi-supervised RaRR. Concretely, CoT2 employs two predictors and each of them alternately plays the roles of &quot;labeler&quot; and &quot;validator&quot; to generate and validate pseudo-labelled instances. Extensive experiments show that CoT2 considerably outperforms state-of-the-art RaRR techniques, especially when training data is severely insufficient.},
  archive   = {C_AAAI},
  author    = {Xiangkui Lu and Jun Wu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26996},
  pages     = {16272-16273},
  title     = {Semi-supervised review-aware rating regression (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MGIA: Mutual gradient inversion attack in multi-modal
federated learning (student abstract). <em>AAAI</em>, 16270–16271. (<a
href="https://doi.org/10.1609/aaai.v37i13.26995">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent studies have demonstrated that local training data in Federated Learning can be recovered from gradients, which are called gradient inversion attacks. These attacks display powerful effects on either computer vision or natural language processing tasks. As it is known that there are certain correlations between multi-modality data, we argue that the threat of such attacks combined with Multi-modal Learning may cause more severe effects. Different modalities may communicate through gradients to provide richer information for the attackers, thus improving the strength and efficiency of the gradient inversion attacks. In this paper, we propose the Mutual Gradient Inversion Attack (MGIA), by utilizing the shared labels between image and text modalities combined with the idea of knowledge distillation. Our experimental results show that MGIA achieves the best quality of both modality data and label recoveries in comparison with other methods. In the meanwhile, MGIA verifies that multi-modality gradient inversion attacks are more likely to disclose private information than the existing single-modality attacks.},
  archive   = {C_AAAI},
  author    = {Xuan Liu and Siqi Cai and Lin Li and Rui Zhang and Song Guo},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26995},
  pages     = {16270-16271},
  title     = {MGIA: Mutual gradient inversion attack in multi-modal federated learning (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A highly efficient marine mammals classifier based on a
cross-covariance attended compact feed-forward sequential memory network
(student abstract). <em>AAAI</em>, 16268–16269. (<a
href="https://doi.org/10.1609/aaai.v37i13.26994">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Military active sonar and marine transportation are detrimental to the livelihood of marine mammals and the ecosystem. Early detection and classification of marine mammals using machine learning can help humans to mitigate the harm to marine mammals. This paper proposes a cross-covariance attended compact Feed-Forward Sequential Memory Network (CC-FSMN). The proposed framework shows improved efficiency over multiple convolutional neural network (CNN) backbones. It also maintains a relatively decent performance.},
  archive   = {C_AAAI},
  author    = {Xiangrui Liu and Julian Cheng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26994},
  pages     = {16268-16269},
  title     = {A highly efficient marine mammals classifier based on a cross-covariance attended compact feed-forward sequential memory network (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Flaky performances when pretraining on relational databases
(student abstract). <em>AAAI</em>, 16266–16267. (<a
href="https://doi.org/10.1609/aaai.v37i13.26993">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We explore the downstream task performances for graph neural network (GNN) self-supervised learning (SSL) methods trained on subgraphs extracted from relational databases (RDBs). Intuitively, this joint use of SSL and GNNs should allow to leverage more of the available data, which could translate to better results. However, we found that naively porting contrastive SSL techniques can cause ``negative transfer&#39;&#39;: linear evaluation on fixed representation from a pretrained model performs worse than on representations from the randomly-initialized model. Based on the conjecture that contrastive SSL conflicts with the message passing layers of the GNN, we propose InfoNode: a contrastive loss aiming to maximize the mutual information between a node&#39;s initial- and final-layer representation. The primary empirical results support our conjecture and the effectiveness of InfoNode.},
  archive   = {C_AAAI},
  author    = {Shengchao Liu and David Vazquez and Jian Tang and Pierre-André Noël},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26993},
  pages     = {16266-16267},
  title     = {Flaky performances when pretraining on relational databases (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Can graph neural networks learn to solve the MaxSAT
problem? (Student abstract). <em>AAAI</em>, 16264–16265. (<a
href="https://doi.org/10.1609/aaai.v37i13.26992">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The paper presents an attempt to bridge the gap between machine learning and symbolic reasoning. We build graph neural networks (GNNs) to predict the solution of the Maximum Satisfiability (MaxSAT) problem, an optimization variant of SAT. Two closely related graph representations are adopted, and we prove their theoretical equivalence. We also show that GNNs can achieve attractive performance to solve hard MaxSAT problems in certain distributions even compared with state-of-the-art solvers through experimental evaluation.},
  archive   = {C_AAAI},
  author    = {Minghao Liu and Pei Huang and Fuqi Jia and Fan Zhang and Yuchen Sun and Shaowei Cai and Feifei Ma and Jian Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26992},
  pages     = {16264-16265},
  title     = {Can graph neural networks learn to solve the MaxSAT problem? (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Category-guided visual question generation (student
abstract). <em>AAAI</em>, 16262–16263. (<a
href="https://doi.org/10.1609/aaai.v37i13.26991">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Visual question generation aims to generate high-quality questions related to images. Generating questions based only on images can better reduce labor costs and thus be easily applied. However, their methods tend to generate similar general questions that fail to ask questions about the specific content of each image scene. In this paper, we propose a category-guided visual question generation model that can generate questions with multiple categories that focus on different objects in an image. Specifically, our model first selects the appropriate question category based on the objects in the image and the relationships among objects. Then, we generate corresponding questions based on the selected question categories. Experiments conducted on the TDIUC dataset show that our proposed model outperforms existing models in terms of diversity and quality.},
  archive   = {C_AAAI},
  author    = {Hongfei Liu and Jiali Chen and Wenhao Fang and Jiayuan Xie and Yi Cai},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26991},
  pages     = {16262-16263},
  title     = {Category-guided visual question generation (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cross-regional fraud detection via continual learning
(student abstract). <em>AAAI</em>, 16260–16261. (<a
href="https://doi.org/10.1609/aaai.v37i13.26990">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Detecting fraud is an urgent task to avoid transaction risks. Especially when expanding a business to new cities or new countries, developing a totally new model will bring the cost issue and result in forgetting previous knowledge. This study proposes a novel solution based on heterogeneous trade graphs, namely HTG-CFD, to prevent knowledge forgetting of cross-regional fraud detection. Specifically, a novel heterogeneous trade graph is meticulously constructed from original transactions to explore the complex semantics among different types of entities and relationships. Motivated by continual learning, we present a practical and task-oriented forgetting prevention method to alleviate knowledge forgetting in the context of cross-regional detection. Extensive experiments demonstrate that HTG-CFD promotes performance in both cross-regional and single-regional scenarios.},
  archive   = {C_AAAI},
  author    = {Yujie Li and Yuxuan Yang and Qiang Gao and Xin Yang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26990},
  pages     = {16260-16261},
  title     = {Cross-regional fraud detection via continual learning (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning generalizable batch active learning strategies via
deep q-networks (student abstract). <em>AAAI</em>, 16258–16259. (<a
href="https://doi.org/10.1609/aaai.v37i13.26989">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {To handle a large amount of unlabeled data, batch active learning (BAL) queries humans for the labels of a batch of the most valuable data points at every round. Most current BAL strategies are based on human-designed heuristics, such as uncertainty sampling or mutual information maximization. However, there exists a disagreement between these heuristics and the ultimate goal of BAL, i.e., optimizing the model&#39;s final performance within the query budgets. This disagreement leads to a limited generality of these heuristics. To this end, we formulate BAL as an MDP and propose a data-driven approach based on deep reinforcement learning. Our method learns the BAL strategy by maximizing the model&#39;s final performance. Experiments on the UCI benchmark show that our method can achieve competitive performance compared to existing heuristics-based approaches.},
  archive   = {C_AAAI},
  author    = {Yi-Chen Li and Wen-Jie Shen and Boyu Zhang and Feng Mao and Zongzhang Zhang and Yang Yu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26989},
  pages     = {16258-16259},
  title     = {Learning generalizable batch active learning strategies via deep Q-networks (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Double policy network for aspect sentiment triplet
extraction (student abstract). <em>AAAI</em>, 16256–16257. (<a
href="https://doi.org/10.1609/aaai.v37i13.26988">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Aspect Sentiment Triplet Extraction (ASTE) is the task to extract aspects, opinions and associated sentiments from sentences. Previous studies do not adequately consider the complicated interactions between aspect and opinion terms in both extraction logic and strategy. We present a novel Double Policy Network with Multi-Tag based Reward model (DPN-MTR), which adopts two networks ATE, TSOTE and a Trigger Mechanism to execute ASTE task following a more logical framework. A Multi-Tag based reward is also proposed to solve the limitations of existing studies for identifying aspect/opinion terms with multiple tokens (one term may consist of two or more tokens) to a certain extent. Extensive experiments are conducted on four widely-used benchmark datasets, and demonstrate the effectiveness of our model in generally improving the performance on ASTE significantly.},
  archive   = {C_AAAI},
  author    = {Xuting Li and Daifeng Li and Ruo Du and Dingquan Chen and Andrew Madden},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26988},
  pages     = {16256-16257},
  title     = {Double policy network for aspect sentiment triplet extraction (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). On analyzing the role of image for visual-enhanced relation
extraction (student abstract). <em>AAAI</em>, 16254–16255. (<a
href="https://doi.org/10.1609/aaai.v37i13.26987">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multimodal relation extraction is an essential task for knowledge graph construction. In this paper, we take an in-depth empirical analysis that indicates the inaccurate information in the visual scene graph leads to poor modal alignment weights, further degrading performance. Moreover, the visual shuffle experiments illustrate that the current approaches may not take full advantage of visual information. Based on the above observation, we further propose a strong baseline with an implicit fine-grained multimodal alignment based on Transformer for multimodal relation extraction. Experimental results demonstrate the better performance of our method. Codes are available at https://github.com/zjunlp/DeepKE/tree/main/example/re/multimodal.},
  archive   = {C_AAAI},
  author    = {Lei Li and Xiang Chen and Shuofei Qiao and Feiyu Xiong and Huajun Chen and Ningyu Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26987},
  pages     = {16254-16255},
  title     = {On analyzing the role of image for visual-enhanced relation extraction (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evaluating robustness of vision transformers on imbalanced
datasets (student abstract). <em>AAAI</em>, 16252–16253. (<a
href="https://doi.org/10.1609/aaai.v37i13.26986">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Data in the real world is commonly imbalanced across classes. Training neural networks on imbalanced datasets often leads to poor performance on rare classes. Existing work in this area has primarily focused on Convolution Neural Networks (CNN), which are increasingly being replaced by Self-Attention-based Vision Transformers (ViT). Fundamentally, ViTs differ from CNNs in that they offer the flexibility in learning the appropriate inductive bias conducive to improving performance. This work is among the first to evaluate the performance of ViTs under class imbalance. We find that accuracy degradation in the presence of class imbalance is much more prominent in ViTs compared to CNNs. This degradation can be partially mitigated through loss reweighting - a popular strategy that increases the loss contributed by rare classes. We investigate the impact of loss reweighting on different components of a ViT, namely, the patch embedding, self-attention backbone, and linear classifier. Our ongoing investigations reveal that loss reweighting impacts mostly the linear classifier and self-attention backbone while having a small and negligible effect on the embedding layer.},
  archive   = {C_AAAI},
  author    = {Kevin Li and Rahul Duggal and Duen Horng Chau},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26986},
  pages     = {16252-16253},
  title     = {Evaluating robustness of vision transformers on imbalanced datasets (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Summarization attack via paraphrasing (student abstract).
<em>AAAI</em>, 16250–16251. (<a
href="https://doi.org/10.1609/aaai.v37i13.26985">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Many natural language processing models are perceived to be fragile on adversarial attacks. Recent work on adversarial attack has demonstrated a high success rate on sentiment analysis as well as classification models. However, attacks to summarization models have not been well studied. Summarization tasks are rarely influenced by word substitution, since advanced abstractive summary models utilize sentence level information. In this paper, we propose a paraphrasing-based attack method to attack summarization models. We first rank the sentences in the document according to their impacts to summarization. Then, we apply paraphrasing procedure to generate adversarial samples. Finally, we test our algorithm on benchmarks datasets against others methods. Our approach achieved the highest success rate and the lowest sentence substitution rate. In addition, the adversarial samples have high semantic similarity with the original sentences.},
  archive   = {C_AAAI},
  author    = {Jiyao Li and Wei Liu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26985},
  pages     = {16250-16251},
  title     = {Summarization attack via paraphrasing (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A federated learning monitoring tool for self-driving car
simulation (student abstract). <em>AAAI</em>, 16248–16249. (<a
href="https://doi.org/10.1609/aaai.v37i13.26984">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose CARLA-FLMon, which can monitor the progress of running federated learning (FL) training in the open-source autonomous driving simulation software, CARLA. The purpose of CARLA-FLMon is to visually present the status and results of federated learning training, and to provide an extensible FL training environment with which FL training can be performed repeatedly with updated learning strategies through analysis. With CARLA-FLMon, we can determine what factors have positive or negative influences on learning by visualizing training data. Then, we can optimize the parameters of the FL training model to improve the accuracy of FL. With preliminary experiments of CARLA-FLMon on lane recognition, we demonstrate that CARLA-FLmon can increase the overall accuracy from 80.33\% to 93.82\% by identifying lowly-contributing clients and excluding them.},
  archive   = {C_AAAI},
  author    = {Taejoon Lee and Hyunsu Mun and Youngseok Lee},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26984},
  pages     = {16248-16249},
  title     = {A federated learning monitoring tool for self-driving car simulation (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mitigating negative transfer in multi-task learning with
exponential moving average loss weighting strategies (student abstract).
<em>AAAI</em>, 16246–16247. (<a
href="https://doi.org/10.1609/aaai.v37i13.26983">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-Task Learning (MTL) is a growing subject of interest in deep learning, due to its ability to train models more efficiently on multiple tasks compared to using a group of conventional single-task models. However, MTL can be impractical as certain tasks can dominate training and hurt performance in others, thus making some tasks perform better in a single-task model compared to a multi-task one. Such problems are broadly classified as negative transfer, and many prior approaches in the literature have been made to mitigate these issues. One such current approach to alleviate negative transfer is to weight each of the losses so that they are on the same scale. Whereas current loss balancing approaches rely on either optimization or complex numerical analysis, none directly scale the losses based on their observed magnitudes. We propose multiple techniques for loss balancing based on scaling by the exponential moving average and benchmark them against current best-performing methods on three established datasets. On these datasets, they achieve comparable, if not higher, performance compared to current best-performing methods.},
  archive   = {C_AAAI},
  author    = {Anish Lakkapragada and Essam Sleiman and Saimourya Surabhi and Dennis P. Wall},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26983},
  pages     = {16246-16247},
  title     = {Mitigating negative transfer in multi-task learning with exponential moving average loss weighting strategies (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sequential graph attention learning for predicting dynamic
stock trends (student abstract). <em>AAAI</em>, 16244–16245. (<a
href="https://doi.org/10.1609/aaai.v37i13.26982">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The stock market is characterized by a complex relationship between companies and the market. This study combines a sequential graph structure with attention mechanisms to learn global and local information within temporal time. Specifically, our proposed “GAT-AGNN” module compares model performance across multiple industries as well as within single industries. The results show that the proposed framework outperforms the state-of-the-art methods in predicting stock trends across multiple industries on Taiwan Stock datasets.},
  archive   = {C_AAAI},
  author    = {Tzu-Ya Lai and Wen Jung Cheng and Jun-En Ding},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26982},
  pages     = {16244-16245},
  title     = {Sequential graph attention learning for predicting dynamic stock trends (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Incremental density-based clustering with grid partitioning
(student abstract). <em>AAAI</em>, 16242–16243. (<a
href="https://doi.org/10.1609/aaai.v37i13.26981">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {DBSCAN is widely used in various fields, but it requires computational costs similar to those of re-clustering from scratch to update clusters when new data is inserted. To solve this, we propose an incremental density-based clustering method that rapidly updates clusters by identifying in advance regions where cluster updates will occur. Also, through extensive experiments, we show that our method provides clustering results similar to those of DBSCAN.},
  archive   = {C_AAAI},
  author    = {Jeong-Hun Kim and Tserenpurev Chuluunsaikhan and Jong-Hyeok Choi and Aziz Nasridinov},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26981},
  pages     = {16242-16243},
  title     = {Incremental density-based clustering with grid partitioning (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CKS: A community-based k-shell decomposition approach using
community bridge nodes for influence maximization (student abstract).
<em>AAAI</em>, 16240–16241. (<a
href="https://doi.org/10.1609/aaai.v37i13.26980">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Social networks have enabled user-specific advertisements and recommendations on their platforms, which puts a significant focus on Influence Maximisation (IM) for target advertising and related tasks. The aim is to identify nodes in the network which can maximize the spread of information through a diffusion cascade. We propose a community structures-based approach that employs K-Shell algorithm with community structures to generate a score for the connections between seed nodes and communities. Further, our approach employs entropy within communities to ensure the proper spread of information within the communities. We validate our approach on four publicly available networks and show its superiority to four state-of-the-art approaches while still being relatively efficient.},
  archive   = {C_AAAI},
  author    = {Inder Khatri and Aaryan Gupta and Arjun Choudhry and Aryan Tyagi and Dinesh Kumar Vishwakarma and Mukesh Prasad},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26980},
  pages     = {16240-16241},
  title     = {CKS: A community-based K-shell decomposition approach using community bridge nodes for influence maximization (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). In-game toxic language detection: Shared task and attention
residuals (student abstract). <em>AAAI</em>, 16238–16239. (<a
href="https://doi.org/10.1609/aaai.v37i13.26979">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In-game toxic language becomes the hot potato in the gaming industry and community. There have been several online game toxicity analysis frameworks and models proposed. However, it is still challenging to detect toxicity due to the nature of in-game chat, which has extremely short length. In this paper, we describe how the in-game toxic language shared task has been established using the real-world in-game chat data. In addition, we propose and introduce the model/framework for toxic language token tagging (slot filling) from the in-game chat. The data and code will be released.},
  archive   = {C_AAAI},
  author    = {Yuanzhe Jia and Weixuan Wu and Feiqi Cao and Soyeon Caren Han},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26979},
  pages     = {16238-16239},
  title     = {In-game toxic language detection: Shared task and attention residuals (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Understand restart of SAT solver using search similarity
index (student abstract). <em>AAAI</em>, 16236–16237. (<a
href="https://doi.org/10.1609/aaai.v37i13.26978">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {SAT solvers are widely used to solve many industrial problems because of their high performance, which is achieved by various heuristic methods. Understanding why these methods are effective is essential to improving them. One approach to this is analyzing them using qualitative measurements. In our previous study, we proposed search similarity index (SSI), a metric to quantify the similarity between searches. SSI significantly improved the performance of the parallel SAT solver. Here, we apply SSI to analyze the effect of restart, a key SAT solver technique. Experiments using SSI reveal the correlation between the difficulty of instances and the search change effect by restart, and the reason behind the effectiveness of the state-of-the-art restart method is also explained.},
  archive   = {C_AAAI},
  author    = {Yoichiro Iida and Tomohiro Sonobe and Mary Inaba},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26978},
  pages     = {16236-16237},
  title     = {Understand restart of SAT solver using search similarity index (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Less is more: Volatility forecasting with contrastive
representation learning (student abstract). <em>AAAI</em>, 16234–16235.
(<a href="https://doi.org/10.1609/aaai.v37i13.26977">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Earnings conference calls are indicative information events for volatility forecasting, which is essential for financial risk management and asset pricing. Although recent volatility forecasting models have explored the textual content of conference calls for prediction, they suffer from modeling the long-text and representing the risk-relevant information. This work proposes to identify key sentences for robust and interpretable transcript representation learning based on the cognitive theory. Specifically, we introduce TextRank to find key sentences and leverage attention mechanism to screen out the candidates by modeling the semantic correlations. Upon on the structural information of earning conference calls, we propose a structure-based contrastive learning method to facilitate the effective transcript representation. Empirical results on the benchmark dataset demonstrate the superiority of our model over competitive baselines in volatility forecasting.},
  archive   = {C_AAAI},
  author    = {Yanlong Huang and Wenxin Tai and Ting Zhong and Kunpeng Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26977},
  pages     = {16234-16235},
  title     = {Less is more: Volatility forecasting with contrastive representation learning (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A reinforcement learning badminton environment for
simulating player tactics (student abstract). <em>AAAI</em>,
16232–16233. (<a
href="https://doi.org/10.1609/aaai.v37i13.26976">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent techniques for analyzing sports precisely has stimulated various approaches to improve player performance and fan engagement. However, existing approaches are only able to evaluate offline performance since testing in real-time matches requires exhaustive costs and cannot be replicated. To test in a safe and reproducible simulator, we focus on turn-based sports and introduce a badminton environment by simulating rallies with different angles of view and designing the states, actions, and training procedures. This benefits not only coaches and players by simulating past matches for tactic investigation, but also researchers from rapidly evaluating their novel algorithms. Our code is available at https://github.com/wywyWang/CoachAI-Projects/tree/main/Strategic\%20Environment.},
  archive   = {C_AAAI},
  author    = {Li-Chun Huang and Nai-Zen Hsueh and Yen-Che Chien and Wei-Yao Wang and Kuang-Da Wang and Wen-Chih Peng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26976},
  pages     = {16232-16233},
  title     = {A reinforcement learning badminton environment for simulating player tactics (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mobility prediction via sequential trajectory
disentanglement (student abstract). <em>AAAI</em>, 16230–16231. (<a
href="https://doi.org/10.1609/aaai.v37i13.26975">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Accurately predicting human mobility is a critical task in location-based recommendation. Most prior approaches focus on fusing multiple semantics trajectories to forecast the future movement of people, and fail to consider the distinct relations in underlying context of human mobility, resulting in a narrow perspective to comprehend human motions. Inspired by recent advances in disentanglement learning, we propose a novel self-supervised method called SelfMove for next POI prediction. SelfMove seeks to disentangle the potential time-invariant and time-varying factors from massive trajectories, which provides an interpretable view to understand the complex semantics underlying human mobility representations. To address the data sparsity issue, we present two realistic trajectory augmentation approaches to help understand the intrinsic periodicity and constantly changing intents of humans. In addition, a POI-centric graph structure is proposed to explore both homogeneous and heterogeneous collaborative signals behind historical trajectories. Experiments on two real-world datasets demonstrate the superiority of SelfMove compared to the state-of-the-art baselines.},
  archive   = {C_AAAI},
  author    = {Jinyu Hong and Fan Zhou and Qiang Gao and Ping Kuang and Kunpeng Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26975},
  pages     = {16230-16231},
  title     = {Mobility prediction via sequential trajectory disentanglement (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An analysis of the deliberation and task performance of an
active logic based agent (student abstract). <em>AAAI</em>, 16228–16229.
(<a href="https://doi.org/10.1609/aaai.v37i13.26974">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Active logic is a time-situated reasoner that can track the history of inferences, detect contradictions, and make parallel inferences in time. In this paper, we explore the behavior of an active-logic based agent on different sets of action selection axioms for a time-constrained target search task. We compare the performance of a baseline set of axioms that does not avoid redundant actions with five other axiom sets that avoid repeated actions but vary in their knowledge content. The results of these experiments show the importance of balancing boldness and caution for target search.},
  archive   = {C_AAAI},
  author    = {Anthony Herron and Darsana P. Josyula},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26974},
  pages     = {16228-16229},
  title     = {An analysis of the deliberation and task performance of an active logic based agent (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploring hypergraph of earnings call for risk prediction
(student abstract). <em>AAAI</em>, 16226–16227. (<a
href="https://doi.org/10.1609/aaai.v37i13.26973">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In financial economics, studies have shown that the textual content in the earnings conference call transcript has predictive power for a firm&#39;s future risk. However, the conference call transcript is very long and contains diverse non-relevant content, which poses challenges for the text-based risk forecast. This study investigates the structural dependency within a conference call transcript by explicitly modeling the dialogue between managers and analysts. Specifically, we utilize TextRank to extract information and exploit the semantic correlation within a discussion using hypergraph learning. This novel design can improve the transcript representation performance and reduce the risk of forecast errors. Experimental results on a large-scale dataset show that our approach can significantly improve prediction performance compared to state-of-the-art text-based models.},
  archive   = {C_AAAI},
  author    = {Yi He and Wenxin Tai and Fan Zhou and Yi Yang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26973},
  pages     = {16226-16227},
  title     = {Exploring hypergraph of earnings call for risk prediction (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Invertible conditional GAN revisited: Photo-to-manga face
translation with modern architectures (student abstract). <em>AAAI</em>,
16224–16225. (<a
href="https://doi.org/10.1609/aaai.v37i13.26972">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent style translation methods have extended their transferability from texture to geometry. However, performing translation while preserving image content when there is a significant style difference is still an open problem. To overcome this problem, we propose Invertible Conditional Fast GAN (IcFGAN) based on GAN inversion and cFGAN. It allows for unpaired photo-to-manga face translation. Experimental results show that our method could translate styles under significant style gaps, while the state-of-the-art methods could hardly preserve image content.},
  archive   = {C_AAAI},
  author    = {Taro Hatakeyama and Ryusuke Saito and Komei Hiruta and Atsushi Hashimoto and Satoshi Kurihara},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26972},
  pages     = {16224-16225},
  title     = {Invertible conditional GAN revisited: Photo-to-manga face translation with modern architectures (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unsupervised contrastive representation learning for 3D mesh
segmentation (student abstract). <em>AAAI</em>, 16222–16223. (<a
href="https://doi.org/10.1609/aaai.v37i13.26971">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {3D deep learning is a growing field of interest due to the vast amount of information stored in 3D formats. Triangular meshes are an efficient representation for irregular, non-uniform 3D objects. However, meshes are often challenging to annotate due to their high computational complexity. Therefore, it is desirable to train segmentation networks with limited-labeled data. Self-supervised learning (SSL), a form of unsupervised representation learning, is a growing alternative to fully-supervised learning which can decrease the burden of supervision for training. Specifically, contrastive learning (CL), a form of SSL, has recently been explored to solve limited-labeled data tasks. We propose SSL-MeshCNN, a CL method for pre-training CNNs for mesh segmentation. We take inspiration from prior CL frameworks to design a novel CL algorithm specialized for meshes. Our preliminary experiments show promising results in reducing the heavy labeled data requirement needed for mesh segmentation by at least 33\%.},
  archive   = {C_AAAI},
  author    = {Ayaan Haque and Hankyu Moon and Heng Hao and Sima Didari and Jae Oh Woo and Patrick Bangert},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26971},
  pages     = {16222-16223},
  title     = {Unsupervised contrastive representation learning for 3D mesh segmentation (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Expert data augmentation in imitation learning (student
abstract). <em>AAAI</em>, 16220–16221. (<a
href="https://doi.org/10.1609/aaai.v37i13.26970">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Behavioral Cloning (BC) is a simple and effective imitation learning algorithm, which suffers from compounding error due to covariate shift. One solution is to use enough data for training. However, the amount of expert demonstrations available is usually limited. So we propose an effective method to augment expert demonstrations to alleviate the problem of compounding error in BC. It operates by estimating the similarity of states and filtering out transitions that can go back to the states similar to ones in expert demonstrations during the process of sampling. The data filtered out along with original expert demonstrations are used for training. We evaluate the performance of our method on several Atari tasks and continuous MuJoCo control tasks. Empirically, BC trained with the augmented data significantly outperform BC trained with the original expert demonstrations.},
  archive   = {C_AAAI},
  author    = {Fuguang Han and Zongzhang Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26970},
  pages     = {16220-16221},
  title     = {Expert data augmentation in imitation learning (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural implicit surface reconstruction from noisy camera
observations (student abstract). <em>AAAI</em>, 16218–16219. (<a
href="https://doi.org/10.1609/aaai.v37i13.26969">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Representing 3D objects and scenes with neural radiance fields has become very popular over the last years. Recently, surface-based representations have been proposed, that allow to reconstruct 3D objects from simple photographs. However, most current techniques require an accurate camera calibration, i.e. camera parameters corresponding to each image, which is often a difficult task to do in real-life situations. To this end, we propose a method for learning 3D surfaces from noisy camera parameters. We show that we can learn camera parameters together with learning the surface representation, and demonstrate good quality 3D surface reconstruction even with noisy camera observations.},
  archive   = {C_AAAI},
  author    = {Sarthak Gupta and Patrik Huber},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26969},
  pages     = {16218-16219},
  title     = {Neural implicit surface reconstruction from noisy camera observations (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards safe reinforcement learning via OOD dynamics
detection in autonomous driving system (student abstract).
<em>AAAI</em>, 16216–16217. (<a
href="https://doi.org/10.1609/aaai.v37i13.26968">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep reinforcement learning (DRL) has proven effective in training agents to achieve goals in complex environments. However, a trained RL agent may exhibit, during deployment, unexpected behavior when faced with a situation where its state transitions differ even slightly from the training environment. Such a situation can arise for a variety of reasons. Rapid and accurate detection of anomalous behavior appears to be a prerequisite for using DRL in safety-critical systems, such as autonomous driving. We propose a novel OOD detection algorithm based on modeling the transition function of the training environment. Our method captures the bias of model behavior when encountering subtle changes of dynamics while maintaining a low false positive rate. Preliminary evaluations on the realistic simulator CARLA corroborate the relevance of our proposed method.},
  archive   = {C_AAAI},
  author    = {Arnaud Gardille and Ola Ahmad},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26968},
  pages     = {16216-16217},
  title     = {Towards safe reinforcement learning via OOD dynamics detection in autonomous driving system (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards fair and selectively privacy-preserving models using
negative multi-task learning (student abstract). <em>AAAI</em>,
16214–16215. (<a
href="https://doi.org/10.1609/aaai.v37i13.26967">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep learning models have shown great performances in natural language processing tasks. While much attention has been paid to improvements in utility, privacy leakage and social bias are two major concerns arising in trained models. In order to tackle these problems, we protect individuals&#39; sensitive information and mitigate gender bias simultaneously. First, we propose a selective privacy-preserving method that only obscures individuals&#39; sensitive information. Then we propose a negative multi-task learning framework to mitigate the gender bias which contains a main task and a gender prediction task. We analyze two existing word embeddings and evaluate them on sentiment analysis and a medical text classification task. Our experimental results show that our negative multi-task learning framework can mitigate the gender bias while keeping models’ utility.},
  archive   = {C_AAAI},
  author    = {Liyuan Gao and Huixin Zhan and Austin Chen and Victor S. Sheng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26967},
  pages     = {16214-16215},
  title     = {Towards fair and selectively privacy-preserving models using negative multi-task learning (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Safety aware neural pruning for deep reinforcement learning
(student abstract). <em>AAAI</em>, 16212–16213. (<a
href="https://doi.org/10.1609/aaai.v37i13.26966">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Neural network pruning is a technique of network compression by removing weights of lower importance from an optimized neural network. Often, pruned networks are compared in terms of accuracy, which is realized in terms of rewards for Deep Reinforcement Learning (DRL) networks. However, networks that estimate control actions for safety-critical tasks, must also adhere to safety requirements along with obtaining rewards. We propose a methodology to iteratively refine the weights of a pruned neural network such that we get a sparse high-performance network without significant side effects on safety.},
  archive   = {C_AAAI},
  author    = {Briti Gangopadhyay and Pallab Dasgupta and Soumyajit Dey},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26966},
  pages     = {16212-16213},
  title     = {Safety aware neural pruning for deep reinforcement learning (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). LEAN-DMKDE: Quantum latent density estimation for anomaly
detection (student abstract). <em>AAAI</em>, 16210–16211. (<a
href="https://doi.org/10.1609/aaai.v37i13.26965">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper presents an anomaly detection model that combines the strong statistical foundation of density-estimation-based anomaly detection methods with the representation-learning ability of deep-learning models. The method combines an autoencoder, that learns a low-dimensional representation of the data, with a density-estimation model based on density matrices in an end-to-end architecture that can be trained using gradient-based optimization techniques. A systematic experimental evaluation was performed on different benchmark datasets. The experimental results show that the method is able to outperform other state-of-the-art methods.},
  archive   = {C_AAAI},
  author    = {Joseph A. Gallego-Mejia and Oscar A. Bustos-Brinez and Fabio A. González},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26965},
  pages     = {16210-16211},
  title     = {LEAN-DMKDE: Quantum latent density estimation for anomaly detection (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ECDANs: Efficient temporal causal discovery from
autocorrelated and non-stationary data (student abstract).
<em>AAAI</em>, 16208–16209. (<a
href="https://doi.org/10.1609/aaai.v37i13.26964">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Conventional temporal causal discovery (CD) methods suffer from high dimensionality, fail to identify lagged causal relationships, and often ignore dynamics in relations. In this study, we present a novel constraint-based CD approach for autocorrelated and non-stationary time series data (eCDANs) capable of detecting lagged and contemporaneous causal relationships along with temporal changes. eCDANs addresses high dimensionality by optimizing the conditioning sets while conducting conditional independence (CI) tests and identifies the changes in causal relations by introducing a surrogate variable to represent time dependency. Experiments on synthetic and real-world data show that eCDANs can identify time influence and outperform the baselines.},
  archive   = {C_AAAI},
  author    = {Muhammad Hasan Ferdous and Uzma Hasan and Md Osman Gani},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26964},
  pages     = {16208-16209},
  title     = {ECDANs: Efficient temporal causal discovery from autocorrelated and non-stationary data (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Transformer-based multi-hop question generation (student
abstract). <em>AAAI</em>, 16206–16207. (<a
href="https://doi.org/10.1609/aaai.v37i13.26963">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Question generation is the parallel task of question answering, where given an input context and, optionally, an answer, the goal is to generate a relevant and fluent natural language question. Although recent works on question generation have experienced success by utilizing sequence-to-sequence models, there is a need for question generation models to handle increasingly complex input contexts to produce increasingly detailed questions. Multi-hop question generation is a more challenging task that aims to generate questions by connecting multiple facts from multiple input contexts. In this work, we apply a transformer model to the task of multi-hop question generation without utilizing any sentence-level supporting fact information. We utilize concepts that have proven effective in single-hop question generation, including a copy mechanism and placeholder tokens. We evaluate our model’s performance on the HotpotQA dataset using automated evaluation metrics, including BLEU, ROUGE and METEOR and show an improvement over the previous work.},
  archive   = {C_AAAI},
  author    = {John Emerson and Yllias Chali},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26963},
  pages     = {16206-16207},
  title     = {Transformer-based multi-hop question generation (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AlphaSnake: Policy iteration on a nondeterministic NP-hard
markov decision process (student abstract). <em>AAAI</em>, 16204–16205.
(<a href="https://doi.org/10.1609/aaai.v37i13.26962">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Reinforcement learning has been used to approach well-known NP-hard combinatorial problems in graph theory. Among these, Hamiltonian cycle problems are exceptionally difficult to analyze, even when restricted to individual instances of structurally complex graphs. In this paper, we use Monte Carlo Tree Search (MCTS), the search algorithm behind many state-of-the-art reinforcement learning algorithms such as AlphaZero, to create autonomous agents that learn to play the game of Snake, a game centered on properties of Hamiltonian cycles on grid graphs. The game of Snake can be formulated as a single-player discounted Markov Decision Process (MDP), where the agent must behave optimally in a stochastic environment. Determining the optimal policy for Snake, defined as the policy that maximizes the probability of winning -- or win rate -- with higher priority and minimizes the expected number of time steps to win with lower priority, is conjectured to be NP-hard. Performance-wise, compared to prior work in the Snake game, our algorithm is the first to achieve a win rate over 0.5 (a uniform random policy achieves a win rate &lt; 2.57 x 10^{-15}), demonstrating the versatility of AlphaZero in tackling NP-hard problems.},
  archive   = {C_AAAI},
  author    = {Kevin Du and Ian Gemp and Yi Wu and Yingying Wu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26962},
  pages     = {16204-16205},
  title     = {AlphaSnake: Policy iteration on a nondeterministic NP-hard markov decision process (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Demystify the gravity well in the optimization landscape
(student abstract). <em>AAAI</em>, 16202–16203. (<a
href="https://doi.org/10.1609/aaai.v37i13.26961">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We provide both empirical and theoretical insights to demystify the gravity well phenomenon in the optimization landscape. We start from describe the problem setup and theoretical results (an escape time lower bound) of the Softmax Gravity Well (SGW) in the literature. Then we move toward the understanding of a recent observation called ASR gravity well. We provide an explanation of why normal distribution with high variance can lead to suboptimal plateaus from an energy function point of view. We also contribute to the empirical insights of curriculum learning by comparison of policy initialization by different normal distributions. Furthermore, we provide the ASR escape time lower bound to understand the ASR gravity well theoretically. Future work includes more specific modeling of the reward as a function of time and quantitative evaluation of normal distribution’s influence on policy initialization.},
  archive   = {C_AAAI},
  author    = {Jason Xiaotian Dou and Runxue Bao and Susan Song and Shuran Yang and Yanfu Zhang and Paul Pu Liang and Haiyi Harry Mao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26961},
  pages     = {16202-16203},
  title     = {Demystify the gravity well in the optimization landscape (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Performance disparities between accents in automatic speech
recognition (student abstract). <em>AAAI</em>, 16200–16201. (<a
href="https://doi.org/10.1609/aaai.v37i13.26960">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this work, we expand the discussion of bias in Automatic Speech Recognition (ASR) through a large-scale audit. Using a large and global data set of speech, we perform an audit of some of the most popular English ASR services. We show that, even when controlling for multiple linguistic covariates, ASR service performance has a statistically significant relationship to the political alignment of the speaker&#39;s birth country with respect to the United States&#39; geopolitical power.},
  archive   = {C_AAAI},
  author    = {Alex DiChristofano and Henry Shuster and Shefali Chandra and Neal Patwari},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26960},
  pages     = {16200-16201},
  title     = {Performance disparities between accents in automatic speech recognition (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Disentangling the benefits of self-supervised learning to
deployment-driven downstream tasks of satellite images (student
abstract). <em>AAAI</em>, 16198–16199. (<a
href="https://doi.org/10.1609/aaai.v37i13.26959">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we investigate the benefits of self-supervised learning (SSL) to downstream tasks of satellite images. Unlike common student academic projects, this work focuses on the advantages of the SSL for deployment-driven tasks which have specific scenarios with low or high-spatial resolution images. Our preliminary experiments demonstrate the robust benefits of the SSL trained by medium-resolution (10m) images to both low-resolution (100m) scene classification case (4.25\%↑) and very high-resolution (5cm) aerial image segmentation case (1.96\%↑), respectively.},
  archive   = {C_AAAI},
  author    = {Zhuo Deng and Yibing Wei and Mingye Zhu and Xueliang Wang and Junchi Zhou and Zhicheng Yang and Hang Zhou and Zhenjie Cao and Lan Ma and Mei Han and Jui-Hsin Lai},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26959},
  pages     = {16198-16199},
  title     = {Disentangling the benefits of self-supervised learning to deployment-driven downstream tasks of satellite images (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Transformer-based named entity recognition for french using
adversarial adaptation to similar domain corpora (student abstract).
<em>AAAI</em>, 16196–16197. (<a
href="https://doi.org/10.1609/aaai.v37i13.26958">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Named Entity Recognition (NER) involves the identification and classification of named entities in unstructured text into predefined classes. NER in languages with limited resources, like French, is still an open problem due to the lack of large, robust, labelled datasets. In this paper, we propose a transformer-based NER approach for French using adversarial adaptation to similar domain or general corpora for improved feature extraction and better generalization. We evaluate our approach on three labelled datasets and show that our adaptation framework outperforms the corresponding non-adaptive models for various combinations of transformer models, source datasets and target corpora.},
  archive   = {C_AAAI},
  author    = {Arjun Choudhry and Pankaj Gupta and Inder Khatri and Aaryan Gupta and Maxime Nicol and Marie-Jean Meurs and Dinesh Kumar Vishwakarma},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26958},
  pages     = {16196-16197},
  title     = {Transformer-based named entity recognition for french using adversarial adaptation to similar domain corpora (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SR-AnoGAN: You never detect alone. Super resolution in
anomaly detection (student abstract). <em>AAAI</em>, 16194–16195. (<a
href="https://doi.org/10.1609/aaai.v37i13.26957">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Despite the advance in deep learning algorithms, implementing supervised learning algorithms in medical datasets is difficult owing to the medical data&#39;s properties. This paper proposes SR-AnoGAN, which could generate higher resolution images and conduct anomaly detection more efficiently than AnoGAN. The most distinctive part of the proposed model is incorporating CNN and SRGAN into AnoGAN for reconstructing high-resolution images. Experimental results from X-ray datasets(pneumonia, covid-19) verify that the SR-AnoGAN outperforms the previous AnoGAN model through qualitative and quantitative approaches. Therefore, this paper shows the possibility of resolving data imbalance problems prevalent in the medical field, and proposing more precise diagnosis.},
  archive   = {C_AAAI},
  author    = {Minjong Cheon},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26957},
  pages     = {16194-16195},
  title     = {SR-AnoGAN: You never detect alone. super resolution in anomaly detection (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). CasODE: Modeling irregular information cascade via neural
ordinary differential equations (student abstract). <em>AAAI</em>,
16192–16193. (<a
href="https://doi.org/10.1609/aaai.v37i13.26956">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Predicting information cascade popularity is a fundamental problem for understanding the nature of information propagation on social media. However, existing works fail to capture an essential aspect of information propagation: the temporal irregularity of cascade event -- i.e., users&#39; re-tweetings at random and non-periodic time instants. In this work, we present a novel framework CasODE for information cascade prediction with neural ordinary differential equations (ODEs). CasODE generalizes the discrete state transitions in RNNs to continuous-time dynamics for modeling the irregular-sampled events in information cascades. Experimental evaluations on real-world datasets demonstrate the advantages of the CasODE over baseline approaches.},
  archive   = {C_AAAI},
  author    = {Zhangtao Cheng and Xovee Xu and Ting Zhong and Fan Zhou and Goce Trajcevski},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26956},
  pages     = {16192-16193},
  title     = {CasODE: Modeling irregular information cascade via neural ordinary differential equations (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-modal protein knowledge graph construction and
applications (student abstract). <em>AAAI</em>, 16190–16191. (<a
href="https://doi.org/10.1609/aaai.v37i13.26955">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Existing data-centric methods for protein science generally cannot sufficiently capture and leverage biology knowledge, which may be crucial for many protein tasks. To facilitate research in this field, we create ProteinKG65, a knowledge graph for protein science. Using gene ontology and Uniprot knowledge base as a basis, we transform and integrate various kinds of knowledge with aligned descriptions and protein sequences, respectively, to GO terms and protein entities. ProteinKG65 is mainly dedicated to providing a specialized protein knowledge graph, bringing the knowledge of Gene Ontology to protein function and structure prediction. We also illustrate the potential applications of ProteinKG65 with a prototype. Our dataset can be downloaded at https://w3id.org/proteinkg65.},
  archive   = {C_AAAI},
  author    = {Siyuan Cheng and Xiaozhuan Liang and Zhen Bi and Huajun Chen and Ningyu Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26955},
  pages     = {16190-16191},
  title     = {Multi-modal protein knowledge graph construction and applications (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Self-paced learning based graph convolutional neural
network for mixed integer programming (student abstract). <em>AAAI</em>,
16188–16189. (<a
href="https://doi.org/10.1609/aaai.v37i13.26954">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph convolutional neural network (GCN) based methods have achieved noticeable performance in solving mixed integer programming problems (MIPs). However, the generalization of existing work is limited due to the problem structure. This paper proposes a self-paced learning (SPL) based GCN network (SPGCN) with curriculum learning (CL) to make the utmost of samples. SPGCN employs a GCN model to imitate the branching variable selection during the branch and bound process, while the training process is conducted in a self-paced fashion. Specifically, SPGCN contains a loss-based automatic difficulty measurer, where the training loss of the sample represents the difficulty level. In each iteration, a dynamic training dataset is constructed according to the difficulty level for GCN model training. Experiments on four NP-hard datasets verify that CL can lead to generalization improvement and convergence speedup in solving MIPs, where SPL performs better than predefined CL methods.},
  archive   = {C_AAAI},
  author    = {Li Chen and Hua Xu and Ziteng Wang and Chengming Wang and Yu Jiang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26954},
  pages     = {16188-16189},
  title     = {Self-paced learning based graph convolutional neural network for mixed integer programming (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). AsT: An asymmetric-sensitive transformer for osteonecrosis
of the femoral head detection (student abstract). <em>AAAI</em>,
16186–16187. (<a
href="https://doi.org/10.1609/aaai.v37i13.26953">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Early diagnosis of osteonecrosis of the femoral head (ONFH) can inhibit the progression and improve femoral head preservation. The radiograph difference between early ONFH and healthy ones is not apparent to the naked eye. It is also hard to produce a large dataset to train the classification model. In this paper, we propose Asymmetric-Sensitive Transformer (AsT) to capture the uneven development of the bilateral femoral head to enable robust ONFH detection. Our ONFH detection is realized using the self-attention mechanism to femoral head regions while conferring sensitivity to the uneven development by the attention-shared transformer. The real-world experiment studies show that AsT achieves the best performance of AUC 0.9313 in the early diagnosis of ONFH and can find out misdiagnosis cases firmly.},
  archive   = {C_AAAI},
  author    = {Haoyang Chen and Shuai Liu and Feng Lu and Wei Li and Bin Sheng and Mi Li and Hai Jin and Albert Y. Zomaya},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26953},
  pages     = {16186-16187},
  title     = {AsT: An asymmetric-sensitive transformer for osteonecrosis of the femoral head detection (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SkateboardAI: The coolest video action recognition for
skateboarding (student abstract). <em>AAAI</em>, 16184–16185. (<a
href="https://doi.org/10.1609/aaai.v37i13.26952">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Impressed by the coolest skateboarding sports program from 2021 Tokyo Olympic Games, we are the first to curate the original real-world video datasets &quot;SkateboardAI&quot; in the wild, even self-design and implement diverse uni-modal and multi-modal video action recognition approaches to recognize different tricks accurately. For uni-modal methods, we separately apply (1)CNN and LSTM; (2)CNN and BiLSTM; (3)CNN and BiLSTM with effective attention mechanisms; (4)Transformer-based action recognition pipeline. Transferred to the multi-modal conditions, we investigated the two-stream Inflated-3D architecture on &quot;SkateboardAI&quot; datasets to compare its performance with uni-modal cases. In sum, our objective is developing an excellent AI sport referee for the coolest skateboarding competitions.},
  archive   = {C_AAAI},
  author    = {Hanxiao Chen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26952},
  pages     = {16184-16185},
  title     = {SkateboardAI: The coolest video action recognition for skateboarding (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Towards deployment-efficient and collision-free multi-agent
path finding (student abstract). <em>AAAI</em>, 16182–16183. (<a
href="https://doi.org/10.1609/aaai.v37i13.26951">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-agent pathfinding (MAPF) is essential to large-scale robotic coordination tasks. Planning-based algorithms show their advantages in collision avoidance while avoiding exponential growth in the number of agents. Reinforcement-learning (RL)-based algorithms can be deployed efficiently but cannot prevent collisions entirely due to the lack of hard constraints. This paper combines the merits of planning-based and RL-based MAPF methods to propose a deployment-efficient and collision-free MAPF algorithm. The experiments show the effectiveness of our approach.},
  archive   = {C_AAAI},
  author    = {Feng Chen and Chenghe Wang and Fuxiang Zhang and Hao Ding and Qiaoyong Zhong and Shiliang Pu and Zongzhang Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26951},
  pages     = {16182-16183},
  title     = {Towards deployment-efficient and collision-free multi-agent path finding (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Deep anomaly detection and search via reinforcement
learning (student abstract). <em>AAAI</em>, 16180–16181. (<a
href="https://doi.org/10.1609/aaai.v37i13.26950">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Semi-supervised anomaly detection is a data mining task which aims at learning features from partially-labeled datasets. We propose Deep Anomaly Detection and Search (DADS) with reinforcement learning. During the training process, the agent searches for possible anomalies in unlabeled dataset to enhance performance. Empirically, we compare DADS with several methods in the settings of leveraging known anomalies to detect both other known and unknown anomalies. Results show that DADS achieves good performance.},
  archive   = {C_AAAI},
  author    = {Chao Chen and Dawei Wang and Feng Mao and Zongzhang Zhang and Yang Yu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26950},
  pages     = {16180-16181},
  title     = {Deep anomaly detection and search via reinforcement learning (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An emotion-guided approach to domain adaptive fake news
detection using adversarial learning (student abstract). <em>AAAI</em>,
16178–16179. (<a
href="https://doi.org/10.1609/aaai.v37i13.26949">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent works on fake news detection have shown the efficacy of using emotions as a feature for improved performance. However, the cross-domain impact of emotion-guided features for fake news detection still remains an open problem. In this work, we propose an emotion-guided, domain-adaptive, multi-task approach for cross-domain fake news detection, proving the efficacy of emotion-guided models in cross-domain settings for various datasets.},
  archive   = {C_AAAI},
  author    = {Arkajyoti Chakraborty and Inder Khatri and Arjun Choudhry and Pankaj Gupta and Dinesh Kumar Vishwakarma and Mukesh Prasad},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26949},
  pages     = {16178-16179},
  title     = {An emotion-guided approach to domain adaptive fake news detection using adversarial learning (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Know your enemy: Identifying adversarial behaviours in deep
reinforcement learning agents (student abstract). <em>AAAI</em>,
16176–16177. (<a
href="https://doi.org/10.1609/aaai.v37i13.26948">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {It has been shown that an agent can be trained with an adversarial policy which achieves high degrees of success against a state-of-the-art DRL victim despite taking unintuitive actions. This prompts the question: is this adversarial behaviour detectable through the observations of the victim alone? We find that widely used classification methods such as random forests are only able to achieve a maximum of ≈71\% test set accuracy when classifying an agent for a single timestep. However, when the classifier inputs are treated as time-series data, test set classification accuracy is increased significantly to ≈98\%. This is true for both classification of episodes as a whole, and for “live” classification at each timestep in an episode. These classifications can then be used to “react” to incoming attacks and increase the overall win rate against Adversarial opponents by approximately 17\%. Classification of the victim’s own internal activations in response to the adversary is shown to achieve similarly impressive accuracy while also offering advantages like increased transferability to other domains.},
  archive   = {C_AAAI},
  author    = {Seán Caulfield Curley and Karl Mason and Patrick Mannion},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26948},
  pages     = {16176-16177},
  title     = {Know your enemy: Identifying adversarial behaviours in deep reinforcement learning agents (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reconsidering deception in social robotics: The role of
human vulnerability (student abstract). <em>AAAI</em>, 16174–16175. (<a
href="https://doi.org/10.1609/aaai.v37i13.26947">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The literature on deception in human-robot interaction (henceforth HRI) could be divided between: (i) those who consider it essential to maximise users&#39; end utility and robotic performance; (ii) those who consider it unethical, because it is potentially dangerous for individuals&#39; psychological integrity. However, it has now been proven that humans are naturally prone to anthropomorphism and emotional attachment to inanimate objects. Consequently, despite ethical concerns, the argument for the total elimination of deception could reveal to be a pointless exercise. Rather, it is suggested here to conceive deception in HRI as a dynamic to be modulated and graded, in order to both promote innovation and protect fundamental human rights. To this end, the concept of vulnerability could serve as an objective balancing criterion.},
  archive   = {C_AAAI},
  author    = {Rachele Carli and Amro Najjar},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26947},
  pages     = {16174-16175},
  title     = {Reconsidering deception in social robotics: The role of human vulnerability (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Lightweight transformer for multi-modal object detection
(student abstract). <em>AAAI</em>, 16172–16173. (<a
href="https://doi.org/10.1609/aaai.v37i13.26946">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {It has become a common practice for many perceptual systems to integrate information from multiple sensors to improve the accuracy of object detection. For example, autonomous vehicles use visible light, and infrared (IR) information to ensure that the car can cope with complex weather conditions. However, the accuracy of the algorithm is usually a trade-off between the computational complexity and memory consumption. In this study, we evaluate the performance and complexity of different fusion operators in multi-modal object detection tasks. On top of that, a Poolformer-based fusion operator (PoolFuser) is proposed to enhance the accuracy of detecting targets without compromising the efficiency of the detection framework.},
  archive   = {C_AAAI},
  author    = {Yue Cao and Yanshuo Fan and Junchi Bin and Zheng Liu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26946},
  pages     = {16172-16173},
  title     = {Lightweight transformer for multi-modal object detection (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal execution via multi-objective multi-armed bandits
(student abstract). <em>AAAI</em>, 16170–16171. (<a
href="https://doi.org/10.1609/aaai.v37i13.26945">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {When trying to liquidate a large quantity of a particular stock, the price of that stock is likely to be affected by trades, thus leading to a reduced expected return if we were to sell the entire quantity at once. This leads to the problem of optimal execution, where the aim is to split the sell order into several smaller sell orders over the course of a period of time, to optimally balance stock price with market risk. This problem can be defined in terms of difference equations. Here, we show how we can reformulate this as a multi-objective problem, which we solve with a novel multi-armed bandit algorithm.},
  archive   = {C_AAAI},
  author    = {Francois Buet-Golfouse and Peter Hill},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26945},
  pages     = {16170-16171},
  title     = {Optimal execution via multi-objective multi-armed bandits (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Model selection of graph signage models using maximum
likelihood (student abstract). <em>AAAI</em>, 16168–16169. (<a
href="https://doi.org/10.1609/aaai.v37i13.26944">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Complex systems across various domains can be naturally modeled as signed networks with positive and negative edges. In this work, we design a new class of signage models and show how to select the model parameters that best fit real-world datasets using maximum likelihood.},
  archive   = {C_AAAI},
  author    = {Angelina Brilliantova and Ivona Bezáková},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26944},
  pages     = {16168-16169},
  title     = {Model selection of graph signage models using maximum likelihood (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Latent space evolution under incremental learning with
concept drift (student abstract). <em>AAAI</em>, 16166–16167. (<a
href="https://doi.org/10.1609/aaai.v37i13.26943">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This work investigates the evolution of latent space when deep learning models are trained incrementally in non-stationary environments that stem from concept drift. We propose a methodology for visualizing the incurred change in latent representations. We further show that classes not targeted by concept drift can be negatively affected, suggesting that the observation of all classes during learning may regularize the latent space.},
  archive   = {C_AAAI},
  author    = {Charles Bourbeau and Audrey Durand},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26943},
  pages     = {16166-16167},
  title     = {Latent space evolution under incremental learning with concept drift (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). IdProv: Identity-based provenance for synthetic image
generation (student abstract). <em>AAAI</em>, 16164–16165. (<a
href="https://doi.org/10.1609/aaai.v37i13.26942">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent advancements in Generative Adversarial Networks (GANs) have made it possible to obtain high-quality face images of synthetic identities. These networks see large amounts of real faces in order to learn to generate realistic looking synthetic images. However, the concept of a synthetic identity for these images is not very well-defined. In this work, we verify identity leakage from the training set containing real images into the latent space and propose a novel method, IdProv, that uses image composition to trace the source of identity signals in the generated image.},
  archive   = {C_AAAI},
  author    = {Harshil Bhatia and Jaisidh Singh and Gaurav Sangwan and Aparna Bharati and Richa Singh and Mayank Vatsa},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26942},
  pages     = {16164-16165},
  title     = {IdProv: Identity-based provenance for synthetic image generation (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust training for AC-OPF (student abstract).
<em>AAAI</em>, 16162–16163. (<a
href="https://doi.org/10.1609/aaai.v37i13.26941">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Electricity network operators use computationally demanding mathematical models to optimize AC power flow (AC-OPF). Recent work applies neural networks (NN) rather than optimization methods to estimate locally optimal solutions. However, NN training data is costly and current models cannot guarantee optimal or feasible solutions. This study proposes a robust NN training approach, which starts with a small amount of seed training data and uses iterative feedback to generate additional data in regions where the model makes poor predictions. The method is applied to non-linear univariate and multivariate test functions, and an IEEE 6-bus AC-OPF system. Results suggest robust training can achieve NN prediction performance similar to, or better than, regular NN training, while using significantly less data.},
  archive   = {C_AAAI},
  author    = {Fuat Can Beylunioglu and Mehrdad Pirnia and P. Robert Duimering and Vijay Ganesh},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26941},
  pages     = {16162-16163},
  title     = {Robust training for AC-OPF (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Social intelligence towards human-AI teambuilding (student
abstract). <em>AAAI</em>, 16160–16161. (<a
href="https://doi.org/10.1609/aaai.v37i13.26940">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As Artificial Intelligence (AI) continues to develop, it becomes vital to understand more of the nuances of Human-AI interactions. This study aims to uncover how developers can design AI to feel more human in a work environment where only written feedback is possible. Participants will identify a location from Google Maps. To do this successfully, participants must rely on the answers provided by their teammates, one AI and one human. The experiment will run a 2x4 de-sign where AI&#39;s responses will either be designed in a human style (high humanness) or state a one-word answer (low humanness), the latter of which is more typical in machines and AI. The reliability of the AI will either be 60\% or 90\%, and the human will be 30\%. Participants will be given a series of questionnaires to rate their opinions of the AI and rate feelings of trust, confidence and performance throughout the study. Following this study, the aim is to identify specific design elements that allow AI to feel human and successfully appear to have social intelligence in more interactive settings.},
  archive   = {C_AAAI},
  author    = {Morgan E Bailey and Frank E Pollick},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26940},
  pages     = {16160-16161},
  title     = {Social intelligence towards human-AI teambuilding (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PanTop: Pandemic topic detection and monitoring system
(student abstract). <em>AAAI</em>, 16158–16159. (<a
href="https://doi.org/10.1609/aaai.v37i13.26939">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Diverse efforts to combat the COVID-19 pandemic have continued throughout the past two years. Governments have announced plans for unprecedentedly rapid vaccine development, quarantine measures, and economic revitalization. They contribute to a more effective pandemic response by determining the precise opinions of individuals regarding these mitigation measures. In this paper, we propose a deep learning-based topic monitoring and storyline extraction system for COVID-19 that is capable of analyzing public sentiment and pandemic trends. The proposed method is able to retrieve Twitter data related to COVID-19 and conduct spatiotemporal analysis. Furthermore, a deep learning component of the system provides monitoring and modeling capabilities for topics based on advanced natural language processing models. A variety of visualization methods are applied to the project to show the distribution of each topic. Our proposed system accurately reflects how public reactions change over time along with pandemic topics.},
  archive   = {C_AAAI},
  author    = {Yangxiao Bai and Kaiqun Fu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26939},
  pages     = {16158-16159},
  title     = {PanTop: Pandemic topic detection and monitoring system (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FV-train: Quantum convolutional neural network training with
a finite number of qubits by extracting diverse features (student
abstract). <em>AAAI</em>, 16156–16157. (<a
href="https://doi.org/10.1609/aaai.v37i13.26938">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Quantum convolutional neural network (QCNN) has just become as an emerging research topic as we experience the noisy intermediate-scale quantum (NISQ) era and beyond. As convolutional filters in QCNN extract intrinsic feature using quantum-based ansatz, it should use only finite number of qubits to prevent barren plateaus, and it introduces the lack of the feature information. In this paper, we propose a novel QCNN training algorithm to optimize feature extraction while using only a finite number of qubits, which is called fidelity-variation training (FV-Training).},
  archive   = {C_AAAI},
  author    = {Hankyul Baek and Won Joon Yun and Joongheon Kim},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26938},
  pages     = {16156-16157},
  title     = {FV-train: Quantum convolutional neural network training with a finite number of qubits by extracting diverse features (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hey, siri! Why are you biased against women? (Student
abstract). <em>AAAI</em>, 16154–16155. (<a
href="https://doi.org/10.1609/aaai.v37i13.26937">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The intersection of pervasive technology and verbal communication has resulted in the creation of Automatic Speech Recognition Systems (ASRs), which automate the conversion of spontaneous speech into texts. ASR enables human-computer interactions through speech and is rapidly integrated into our daily lives. However, the research studies on current ASR technologies have reported unfulfilled social inclusivity and accentuated biases and stereotypes towards minorities. In this work, we provide a review of examples and evidence to demonstrate preexisting sexist behavior in ASR systems through a systematic review of research literature over the past five years. For each article, we also provide the ASR technology used, highlight specific instances of reported bias, discuss the impact of this bias on the female community, and suggest possible methods of mitigation. We believe this paper will provide insights into the harm that unchecked AI-powered technologies can have on a community by contributing to the growing body of research on this topic and underscoring the need for technological inclusivity for all demographics, especially women.},
  archive   = {C_AAAI},
  author    = {Surakshya Aryal and Mikel K. Ngueajio and Saurav Keshari Aryal and Gloria Washington},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26937},
  pages     = {16154-16155},
  title     = {Hey, siri! why are you biased against women? (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Modeling metacognitive and cognitive processes in data
science problem solving (student abstract). <em>AAAI</em>, 16152–16153.
(<a href="https://doi.org/10.1609/aaai.v37i13.26936">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Data Science (DS) is an interdisciplinary topic that is applicable to many domains. In this preliminary investigation, we use caselet, a mini-version of a case study, as a learning tool to allow students to practice data science problem solving (DSPS). Using a dataset collected from a real-world classroom, we performed correlation analysis to reveal the structure of cognition and metacognition processes. We also explored the similarity of different DS knowledge components based on students’ performance. In addition, we built a predictive model to characterize the relationship between metacognition, cognition, and learning gain.},
  archive   = {C_AAAI},
  author    = {Maryam Alomair and Shimei Pan and Lujie Karen Chen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26936},
  pages     = {16152-16153},
  title     = {Modeling metacognitive and cognitive processes in data science problem solving (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-horizon learning in procedurally-generated
environments for off-policy reinforcement learning (student abstract).
<em>AAAI</em>, 16150–16151. (<a
href="https://doi.org/10.1609/aaai.v37i13.26935">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Value estimates at multiple timescales can help create advanced discounting functions and allow agents to form more effective predictive models of their environment. In this work, we investigate learning over multiple horizons concurrently for off-policy reinforcement learning by using an advantage-based action selection method and introducing architectural improvements. Our proposed agent learns over multiple horizons simultaneously, while using either exponential or hyperbolic discounting functions. We implement our approach on Rainbow, a value-based off-policy algorithm, and test on Procgen, a collection of procedurally-generated environments, to demonstrate the effectiveness of this approach, specifically to evaluate the agent&#39;s performance in previously unseen scenarios.},
  archive   = {C_AAAI},
  author    = {Raja Farrukh Ali and Kevin Duong and Nasik Muhammad Nafi and William Hsu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26935},
  pages     = {16150-16151},
  title     = {Multi-horizon learning in procedurally-generated environments for off-policy reinforcement learning (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient algorithms for regret minimization in billboard
advertisement (student abstract). <em>AAAI</em>, 16148–16149. (<a
href="https://doi.org/10.1609/aaai.v37i13.26934">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Now-a-days, billboard advertisement has emerged as an effective outdoor advertisement technique. In this case, a commercial house approaches an influence provider for a specific number of views of their advertisement content on a payment basis. If the influence provider can satisfy this then they will receive the full payment else a partial payment. If the influence provider provides more or less than the demand then certainly this is a loss to them. This is formalized as ‘Regret’ and the goal of the influence provider will be to minimize the ‘Regret’. In this paper, we propose simple and efficient solution methodologies to solve this problem. Efficiency and effectiveness have been demonstrated by experimentation.},
  archive   = {C_AAAI},
  author    = {Dildar Ali and Ankit Kumar Bhagat and Suman Banerjee and Yamuna Prasad},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26934},
  pages     = {16148-16149},
  title     = {Efficient algorithms for regret minimization in billboard advertisement (Student abstract)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). Deep learning for medical prediction in electronic health
records. <em>AAAI</em>, 16145–16146. (<a
href="https://doi.org/10.1609/aaai.v37i13.26933">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The widespread adoption of electronic health records (EHRs) has opened up new opportunities for using deep neural networks to enhance healthcare. However, modeling EHR data can be challenging due to its complex properties, such as missing values, data scarcity in multi-hospital systems, and multimodal irregularity. How to tackle various issues in EHRs for improving medical prediction is challenging and under exploration. I separately illustrate my works to address these issues in EHRs and discuss potential future directions.},
  archive   = {C_AAAI},
  author    = {Xinlu Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26933},
  pages     = {16145-16146},
  title     = {Deep learning for medical prediction in electronic health records},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Privacy-preserving representation learning for
text-attributed networks with simplicial complexes. <em>AAAI</em>,
16143–16144. (<a
href="https://doi.org/10.1609/aaai.v37i13.26932">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Although recent network representation learning (NRL) works in text-attributed networks demonstrated superior performance for various graph inference tasks, learning network representations could always raise privacy concerns when nodes represent people or human-related variables. Moreover, standard NRLs that leverage structural information from a graph proceed by first encoding pairwise relationships into learned representations and then analysing its properties. This approach is fundamentally misaligned with problems where the relationships involve multiple points, and topological structure must be encoded beyond pairwise interactions. Fortunately, the machinery of topological data analysis (TDA) and, in particular, simplicial neural networks (SNNs) offer a mathematically rigorous framework to evaluate not only higher-order interactions, but also global invariant features of the observed graph to systematically learn topological structures. It is critical to investigate if the representation outputs from SNNs are more vulnerable compared to regular representation outputs from graph neural networks (GNNs) via pairwise interactions. In my dissertation, I will first study learning the representations with text attributes for simplicial complexes (RT4SC) via SNNs. Then, I will conduct research on two potential attacks on the representation outputs from SNNs: (1) membership inference attack, which infers whether a certain node of a graph is inside the training data of the GNN model; and (2) graph reconstruction attacks, which infer the confidential edges of a text-attributed network. Finally, I will study a privacy-preserving deterministic differentially private alternating direction method of multiplier to learn secure representation outputs from SNNs that capture multi-scale relationships and facilitate the passage from local structure to global invariant features on text-attributed networks.},
  archive   = {C_AAAI},
  author    = {Huixin Zhan and Victor S. Sheng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26932},
  pages     = {16143-16144},
  title     = {Privacy-preserving representation learning for text-attributed networks with simplicial complexes},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Failure-resistant intelligent interaction for reliable
human-AI collaboration. <em>AAAI</em>, 16141–16142. (<a
href="https://doi.org/10.1609/aaai.v37i13.26931">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {My thesis is focusing on how we can overcome the gap people have against machine learning techniques that require a well-defined application scheme and can produce wrong results. I am planning to discuss the principle of the interaction design that fills such a gap based on my past projects that have explored better interactions for applying machine learning in various fields, such as malware analysis, executive coaching, photo editing, and so on. To this aim, my thesis also shed a light on the limitations of machine learning techniques, like adversarial examples, to highlight the importance of &quot;failure-resistant intelligent interaction.&quot;},
  archive   = {C_AAAI},
  author    = {Hiromu Yakura},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26931},
  pages     = {16141-16142},
  title     = {Failure-resistant intelligent interaction for reliable human-AI collaboration},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning and planning under uncertainty for conservation
decisions. <em>AAAI</em>, 16139–16140. (<a
href="https://doi.org/10.1609/aaai.v37i13.26930">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {My research focuses on new techniques in machine learning and game theory to optimally allocate our scarce resources in multi-agent settings to maximize environmental sustainability. Drawing scientific questions from my close partnership with conservation organizations, I have advanced new lines of research in learning and planning under uncertainty, inspired by the low-data, noisy, and dynamic settings faced by rangers on the frontlines of protected areas.},
  archive   = {C_AAAI},
  author    = {Lily Xu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26930},
  pages     = {16139-16140},
  title     = {Learning and planning under uncertainty for conservation decisions},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Meta learning in decentralized neural networks: Towards more
general AI. <em>AAAI</em>, 16137–16138. (<a
href="https://doi.org/10.1609/aaai.v37i13.26929">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Meta-learning usually refers to a learning algorithm that learns from other learning algorithms. The problem of uncertainty in the predictions of neural networks shows that the world is only partially predictable and a learned neural network cannot generalize to its ever-changing surrounding environments. Therefore, the question is how a predictive model can represent multiple predictions simultaneously. We aim to provide a fundamental understanding of learning to learn in the contents of Decentralized Neural Networks (Decentralized NNs) and we believe this is one of the most important questions and prerequisites to building an autonomous intelligence machine. To this end, we shall demonstrate several pieces of evidence for tackling the problems above with Meta Learning in Decentralized NNs. In particular, we will present three different approaches to building such a decentralized learning system: (1) learning from many replica neural networks, (2) building the hierarchy of neural networks for different functions, and (3) leveraging different modality experts to learn cross-modal representations.},
  archive   = {C_AAAI},
  author    = {Yuwei Sun},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26929},
  pages     = {16137-16138},
  title     = {Meta learning in decentralized neural networks: Towards more general AI},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Embodied, intelligent communication for multi-agent
cooperation. <em>AAAI</em>, 16135–16136. (<a
href="https://doi.org/10.1609/aaai.v37i13.26928">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {High-performing human teams leverage intelligent and efficient communication and coordination strategies to collaboratively maximize their joint utility. Inspired by teaming behaviors among humans, I seek to develop computational methods for synthesizing intelligent communication and coordination strategies for collaborative multi-robot systems. I leverage both classical model-based control and planning approaches as well as data-driven methods such as Multi-Agent Reinforcement Learning (MARL) to provide several contributions towards enabling emergent cooperative teaming behavior across both homogeneous and heterogeneous (including agents with different capabilities) robot teams.},
  archive   = {C_AAAI},
  author    = {Esmaeil Seraj},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26928},
  pages     = {16135-16136},
  title     = {Embodied, intelligent communication for multi-agent cooperation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning better representations using auxiliary knowledge.
<em>AAAI</em>, 16133–16134. (<a
href="https://doi.org/10.1609/aaai.v37i13.26927">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Representation Learning is the core of Machine Learning and Artificial Intelligence as it summarizes input data points into low dimensional vectors. This low dimensional vectors should be accurate portrayals of the input data, thus it is crucial to find the most effective and robust representation possible for given input as the performance of the ML task is dependent on the resulting representations. In this summary, we discuss an approach to augment representation learning which relies on external knowledge. We briefly describe the shortcoming of the existing techniques and describe how an auxiliary knowledge source could result in obtaining improved representations.},
  archive   = {C_AAAI},
  author    = {Saed Rezayi},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26927},
  pages     = {16133-16134},
  title     = {Learning better representations using auxiliary knowledge},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Knowledge-embedded narrative construction from open source
intelligence. <em>AAAI</em>, 16131–16132. (<a
href="https://doi.org/10.1609/aaai.v37i13.26926">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Storytelling is an innate part of language-based communication. Today, current events are reported via Open Source Intelligence (OSINT) sources like news websites, blogs, and discussion forums. Scattered and fragmented sources such as these can be better understood when organized as chains of event plot points, or narratives, that have the ability to communicate end-end stories. Though search engines can retrieve aggregated event information, they lack the ability to sequence relevant events together to form narratives about different topics. I propose an AI system inspired by Gustav Freytag’s narrative theory called the Plot Element Pyramid and use knowledge graphs to represent, chain, and reason over narratives from disparately sourced event details to better comprehend convoluted, noisy information about critical events during intelligence analysis.},
  archive   = {C_AAAI},
  author    = {Priyanka Ranade},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26926},
  pages     = {16131-16132},
  title     = {Knowledge-embedded narrative construction from open source intelligence},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Topics in selective classification. <em>AAAI</em>,
16129–16130. (<a
href="https://doi.org/10.1609/aaai.v37i13.26925">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In recent decades, advancements in information technology allowed Artificial Intelligence (AI) systems to predict future outcomes with unprecedented success. This brought the widespread deployment of these methods in many fields, intending to support decision-making. A pressing question is how to make AI systems robust to common challenges in real-life scenarios and trustworthy. In my work, I plan to explore ways to enhance the trustworthiness of AI through the selective classification framework. In this setting, the AI system can refrain from predicting whenever it is not confident enough, allowing it to trade off coverage, i.e. the percentage of instances that receive a prediction, for performance.},
  archive   = {C_AAAI},
  author    = {Andrea Pugnana},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26925},
  pages     = {16129-16130},
  title     = {Topics in selective classification},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multimodal deep generative models for remote medical
applications. <em>AAAI</em>, 16127–16128. (<a
href="https://doi.org/10.1609/aaai.v37i13.26924">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Visible-to-Thermal (VT) face translation is an under-studied problem of image-to-image translation that offers an AI-enabled alternative to traditional thermal sensors. Over three phases, my Doctoral Proposal explores developing multimodal deep generative solutions that can be applied towards telemedicine applications. These include the contribution of a novel Thermal Face Contrastive GAN (TFC-GAN), exploration of hybridized diffusion-GAN models, application on real clinical thermal data at the National Institutes of Health, and exploration of strategies for Federated Learning (FL) in heterogenous data settings.},
  archive   = {C_AAAI},
  author    = {Catherine Ordun},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26924},
  pages     = {16127-16128},
  title     = {Multimodal deep generative models for remote medical applications},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Theory of mind: A familiar aspect of humanity to give
machines. <em>AAAI</em>, 16125–16126. (<a
href="https://doi.org/10.1609/aaai.v37i13.26923">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {My research focuses on machine models of theory of mind, a set of skills that helps humans cooperate with each other. Because these skills present themselves in behavior, inference-based measurements must be carefully designed to rule out alternate hypotheses. Producing models that display these skills requires an extensive understanding of experiences and mechanisms sufficient for learning, and the models must have robust generalization to be effective in varied domains. To address these problems, I intend to evaluate computational models of ToM using a variety of tests.},
  archive   = {C_AAAI},
  author    = {Joel Michelson},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26923},
  pages     = {16125-16126},
  title     = {Theory of mind: A familiar aspect of humanity to give machines},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Safe interactive autonomy for multi-agent systems.
<em>AAAI</em>, 16123–16124. (<a
href="https://doi.org/10.1609/aaai.v37i13.26922">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {It is envisioned that in the near future autonomous systems such as multi-agent systems, will co-exist with humans, e.g., autonomous vehicles will share roads with human drivers. These safety-critical scenarios require formally provable safety guarantees so that the robots will never collide with humans or with each other. It is challenging to provide such guarantees in the real world due to the stochastic environments and inaccurate models of heterogeneous agents including robots and humans. My PhD research investigates decision-making algorithm design for provably-correct safety guarantees in mixed multi-agent systems.},
  archive   = {C_AAAI},
  author    = {Yiwei Lyu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26922},
  pages     = {16123-16124},
  title     = {Safe interactive autonomy for multi-agent systems},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Poisoning-based backdoor attacks in computer vision.
<em>AAAI</em>, 16121–16122. (<a
href="https://doi.org/10.1609/aaai.v37i13.26921">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent studies demonstrated that the training process of deep neural networks (DNNs) is vulnerable to backdoor attacks if third-party training resources (e.g., samples) are adopted. Specifically, the adversaries intend to embed hidden backdoors into DNNs, where the backdoor can be activated by pre-defined trigger patterns and leading malicious model predictions. My dissertation focuses on poisoning-based backdoor attacks in computer vision. Firstly, I study and propose more stealthy and effective attacks against image classification tasks in both physical and digital spaces. Secondly, I reveal the backdoor threats in visual object tracking, which is representative of critical video-related tasks. Thirdly, I explore how to exploit backdoor attacks as watermark techniques for positive purposes. I design a Python toolbox (i.e., BackdoorBox) that implements representative and advanced backdoor attacks and defenses under a unified and flexible framework, based on which to provide a comprehensive benchmark of existing methods at the end.},
  archive   = {C_AAAI},
  author    = {Yiming Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26921},
  pages     = {16121-16122},
  title     = {Poisoning-based backdoor attacks in computer vision},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Explaining the uncertainty in AI-assisted decision making.
<em>AAAI</em>, 16119–16120. (<a
href="https://doi.org/10.1609/aaai.v37i13.26920">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The aim of this project is to improve human decision-making using explainability; specifically, how to explain the (un)certainty of machine learning models. Prior research has used uncertainty measures to promote trust and decision-making. However, the direction of explaining why the AI prediction is confident (or not confident) in its prediction needs to be addressed. By explaining the model uncertainty, we can promote trust, improve understanding and improve decision-making for users.},
  archive   = {C_AAAI},
  author    = {Thao Le},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26920},
  pages     = {16119-16120},
  title     = {Explaining the uncertainty in AI-assisted decision making},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient non-parametric neural density estimation and its
application to outlier and anomaly detection. <em>AAAI</em>,
16117–16118. (<a
href="https://doi.org/10.1609/aaai.v37i13.26919">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The main goal of this thesis is to develop efficient non-parametric density estimation methods that can be integrated with deep learning architectures, for instance, convolutional neural networks and transformers. Density estimation methods can be applied to different problems in statistics and machine learning. They may be used to solve tasks such as anomaly detection, generative models, semi-supervised learning, compression, text-to-speech, among others. The present work will mainly focus on the application of the method in anomaly and outlier detection tasks such as medical anomaly detection, fraud detection, video surveillance, time series anomaly detection, industrial damage detection, among others. A recent approach to non-parametric density estimation is neural density estimation. One advantage of these methods is that they can be integrated with deep learning architectures and trained using gradient descent. Most of these methods are based on neural network implementations of normalizing flows which transform an original simpler distribution to a more complex one. The approach of this thesis is based on a different idea that combines random Fourier features with density matrices to estimate the underlying distribution function. The method can be seen as an approximation of the popular kernel density estimation method but without the inherent computational cost.},
  archive   = {C_AAAI},
  author    = {Joseph A. Gallego-Mejia},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26919},
  pages     = {16117-16118},
  title     = {Efficient non-parametric neural density estimation and its application to outlier and anomaly detection},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Assessing learned representations under open-world novelty.
<em>AAAI</em>, 16115–16116. (<a
href="https://doi.org/10.1609/aaai.v37i13.26918">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {My dissertation research focuses on sequential decision-making (SDM) in complex environments, and how agents can perform well even when novelty is introduced to those environments. The problem of how agents can respond intelligently to novelty has been a long-standing challenge in AI, and poses unique problems across approaches to SDM. This question has been studied in various formulations, including open-world learning and reasoning, transfer learning, concept drift, and statistical relational learning. Classical and modern approaches in agent design offer tradeoffs in human effort for feature encoding, ease of deployment in new domains, and the development of both provably and empirically reliable policies. I propose a formalism for studying open-world novelty in SDM processes with feature-rich observations. I study the conditions under which causal-relational queries can be estimated from non-novel observations, and empirically examine the effects of open-world novelty on agent behavior.},
  archive   = {C_AAAI},
  author    = {Kaleigh Clary},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26918},
  pages     = {16115-16116},
  title     = {Assessing learned representations under open-world novelty},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enhancing smart, sustainable mobility with game theory and
multi-agent reinforcement learning with applications to ridesharing.
<em>AAAI</em>, 16113–16114. (<a
href="https://doi.org/10.1609/aaai.v37i13.26917">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose the use of game-theoretic solutions and multi- agent Reinforcement Learning in the mechanism design of smart, sustainable mobility services. In particular, we present applications to ridesharing as an example of a cost game.},
  archive   = {C_AAAI},
  author    = {Lucia Cipolina-Kun},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26917},
  pages     = {16113-16114},
  title     = {Enhancing smart, sustainable mobility with game theory and multi-agent reinforcement learning with applications to ridesharing},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Non-exponential reward discounting in reinforcement
learning. <em>AAAI</em>, 16111–16112. (<a
href="https://doi.org/10.1609/aaai.v37i13.26916">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Reinforcement learning methods typically discount future rewards using an exponential scheme to achieve theoretical convergence guarantees. Studies from neuroscience, psychology, and economics suggest that human and animal behavior is better captured by the hyperbolic discounting model. Hyperbolic discounting has recently been studied in deep reinforcement learning and has shown promising results. However, this area of research is seemingly understudied, with most extant and continuing research using the standard exponential discounting formulation. My dissertation examines the effects of non-exponential discounting functions (such as hyperbolic) on an agent&#39;s learning and aims to investigate their impact on multi-agent systems and generalization tasks. A key objective of this study is to link the discounting rate to an agent&#39;s approximation of the underlying hazard rate of its environment through survival analysis.},
  archive   = {C_AAAI},
  author    = {Raja Farrukh Ali},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26916},
  pages     = {16111-16112},
  title     = {Non-exponential reward discounting in reinforcement learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Modeling strategies as programs: How to study strategy
differences in intelligent systems with program synthesis.
<em>AAAI</em>, 16109–16110. (<a
href="https://doi.org/10.1609/aaai.v37i13.26915">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {When faced with novel tasks, humans have the ability to form successful strategies, seemingly without much effort. Artificial systems, on the other, hand cannot, at least when the flexibility at which humans perform is considered. For my dissertation, I am using program synthesis as a tool to study the factors that affect strategy choices in intelligent systems. I am evaluating my work through agents that reason through problems from the Abstract Reasoning Corpus and The Block Design Task.},
  archive   = {C_AAAI},
  author    = {James Ainooson},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26915},
  pages     = {16109-16110},
  title     = {Modeling strategies as programs: How to study strategy differences in intelligent systems with program synthesis},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Probabilistic shape models of anatomy directly from images.
<em>AAAI</em>, 16107–16108. (<a
href="https://doi.org/10.1609/aaai.v37i13.26914">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Statistical shape modeling (SSM) is an enabling tool in medical image analysis as it allows for population-based quantitative analysis. The traditional pipeline for landmark-based SSM from images requires painstaking and cost-prohibitive steps. My thesis aims to leverage probabilistic deep learning frameworks to streamline the adoption of SSM in biomedical research and practice. The expected outcomes of this work will be new frameworks for SSM that (1) provide reliable and calibrated uncertainty quantification, (2) are effective given limited or sparsely annotated/incomplete data, and (3) can make predictions from incomplete 4D spatiotemporal data. These efforts will reduce required costs and manual labor for anatomical SSM, helping SSM become a more viable clinical tool and advancing medical practice.},
  archive   = {C_AAAI},
  author    = {Jadie Adams},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26914},
  pages     = {16107-16108},
  title     = {Probabilistic shape models of anatomy directly from images},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Model AI assignments 2023. <em>AAAI</em>, 16104–16105. (<a
href="https://doi.org/10.1609/aaai.v37i13.26913">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Model AI Assignments session seeks to gather and disseminate the best assignment designs of the Artificial Intelligence (AI) Education community. Recognizing that assignments form the core of student learning experience, we here present abstracts of six AI assignments from the 2023 session that are easily adoptable, playfully engaging, and flexible for a variety of instructor needs. Assignment specifications and supporting resources may be found at http://modelai.gettysburg.edu .},
  archive   = {C_AAAI},
  author    = {Todd W. Neller and Raechel Walker and Olivia Dias and Zeynep Yalçın and Cynthia Breazeal and Matt Taylor and Michele Donini and Erin J. Talvitie and Charlie Pilgrim and Paolo Turrini and James Maher and Matthew Boutell and Justin Wilson and Narges Norouzi and Jonathan Scott},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26913},
  pages     = {16104-16105},
  title     = {Model AI assignments 2023},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Music-to-facial expressions: Emotion-based music
visualization for the hearing impaired. <em>AAAI</em>, 16096–16102. (<a
href="https://doi.org/10.1609/aaai.v37i13.26912">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {While music is made to convey messages and emotions, auditory music is not equally accessible to everyone. Music visualization is a common approach to augment the listening experiences of the hearing users and to provide music experiences for the hearing-impaired. In this paper, we present a music visualization system that can turn the input of a piece of music into a series of facial expressions representative of the continuously changing sentiments in the music. The resulting facial expressions, recorded as action units, can later animate a static virtual avatar to be emotive synchronously with the music.},
  archive   = {C_AAAI},
  author    = {Yubo Wang and Fengzhou Pan and Danni Liu and Jiaxiong Hu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26912},
  pages     = {16096-16102},
  title     = {Music-to-facial expressions: Emotion-based music visualization for the hearing impaired},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Emotion-aware music recommendation. <em>AAAI</em>,
16087–16095. (<a
href="https://doi.org/10.1609/aaai.v37i13.26911">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {It is common to listen to songs that match one&#39;s mood. Thus, an AI music recommendation system that is aware of the user&#39;s emotions is likely to provide a superior user experience to one that is unaware. In this paper, we present an emotion-aware music recommendation system. Multiple models are discussed and evaluated for affect identification from a live image of the user. We propose two models: DRViT, which applies dynamic routing to vision transformers, and InvNet50, which uses involution. All considered models are trained and evaluated on the AffectNet dataset. Each model outputs the user&#39;s estimated valence and arousal under the circumplex model of affect. These values are compared to the valence and arousal values for songs in a Spotify dataset, and the top-five closest-matching songs are presented to the user. Experimental results of the models and user testing are presented.},
  archive   = {C_AAAI},
  author    = {Hieu Tran and Tuan Le and Anh Do and Tram Vu and Steven Bogaerts and Brian Howard},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26911},
  pages     = {16087-16095},
  title     = {Emotion-aware music recommendation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Predicting perceived music emotions with respect to
instrument combinations. <em>AAAI</em>, 16078–16086. (<a
href="https://doi.org/10.1609/aaai.v37i13.26910">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Music Emotion Recognition has attracted a lot of academic research work in recent years because it has a wide range of applications, including song recommendation and music visualization. As music is a way for humans to express emotion, there is a need for a machine to automatically infer the perceived emotion of pieces of music. In this paper, we compare the accuracy difference between music emotion recognition models given music pieces as a whole versus music pieces separated by instruments. To compare the models&#39; emotion predictions, which are distributions over valence and arousal values, we provide a metric that compares two distribution curves. Using this metric, we provide empirical evidence that training Random Forest and Convolution Recurrent Neural Network with mixed instrumental music data conveys a better understanding of emotion than training the same models with music that are separated into each instrumental source.},
  archive   = {C_AAAI},
  author    = {Viet Dung Nguyen and Quan H. Nguyen and Richard G. Freedman},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26910},
  pages     = {16078-16086},
  title     = {Predicting perceived music emotions with respect to instrument combinations},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning adaptive game soundtrack control. <em>AAAI</em>,
16070–16077. (<a
href="https://doi.org/10.1609/aaai.v37i13.26909">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we demonstrate a novel technique for dynamically generating an emotionally-directed video game soundtrack. We begin with a human Conductor observing gameplay and directing associated emotions that would enhance the observed gameplay experience. We apply supervised learning to data sampled from synchronized input gameplay features and Conductor output emotional direction features in order to fit a mathematical model to the Conductor&#39;s emotional direction. Then, during gameplay, the emotional direction model maps gameplay state input to emotional direction output, which is then input to a music generation module that dynamically generates emotionally-relevant music during gameplay. Our empirical study suggests that random forests serve well for modeling the Conductor for our two experimental game genres.},
  archive   = {C_AAAI},
  author    = {Aaron Dorsey and Todd W. Neller and Hien G. Tran and Veysel Yilmaz},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26909},
  pages     = {16070-16077},
  title     = {Learning adaptive game soundtrack control},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A multi-user virtual world with music recommendations and
mood-based virtual effects. <em>AAAI</em>, 16063–16069. (<a
href="https://doi.org/10.1609/aaai.v37i13.26908">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The SEND/RETURN (S/R) project is created to explore the efficacy of content-based music recommendations alongside a uniquely generated Unreal Engine 5 (UE5) virtual environment based on audio features. S/R employs both a k-means clustering algorithm using audio features and a fast pattern matching (FPM) algorithm using 30-second audio signals to find similar-sounding songs to recommend to users. The feature values of the recommended song are then communicated via HTTP to the UE5 virtual environment, which changes a number of effects in real-time. All of this is being replicated from a listen-server to other clients to create a multiplayer audio session. S/R successfully creates a lightweight online environment that replicates song information to all clients and suggests new songs that alter the world around you. In this work, we extend S/R by training a convolutional neural network using Mel-spectrograms of 30-second audio samples to predict the mood of a song. This model can then orchestrate the post-processing effect in the UE5 virtual environment. The developed convolutional model had a validation accuracy of 67.5\% in predicting 4 moods (&#39;calm&#39;, &#39;energetic&#39;, &#39;happy&#39;, &#39;sad&#39;).},
  archive   = {C_AAAI},
  author    = {Charats Burch and Robert Sprowl and Mehmet Ergezer},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26908},
  pages     = {16063-16069},
  title     = {A multi-user virtual world with music recommendations and mood-based virtual effects},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MoMusic: A motion-driven human-AI collaborative music
composition and performing system. <em>AAAI</em>, 16057–16062. (<a
href="https://doi.org/10.1609/aaai.v37i13.26907">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The significant development of artificial neural network architectures has facilitated the increasing adoption of automated music composition models over the past few years. However, most existing systems feature algorithmic generative structures based on hard code and predefined rules, generally excluding interactive or improvised behaviors. We propose a motion based music system, MoMusic, as a AI real time music generation system. MoMusic features a partially randomized harmonic sequencing model based on a probabilistic analysis of tonal chord progressions, mathematically abstracted through musical set theory. This model is presented against a dual dimension grid that produces resulting sounds through a posture recognition mechanism. A camera captures the users&#39; fingers&#39; movement and trajectories, creating coherent, partially improvised harmonic progressions. MoMusic integrates several timbrical registers, from traditional classical instruments such as the piano to a new &#39;&#39;human voice instrument&#39;&#39; created using a voice conversion technique. Our research demonstrates MoMusic&#39;s interactiveness, ability to inspire musicians, and ability to generate coherent musical material with various timbrical registers. MoMusic&#39;s capabilities could be easily expanded to incorporate different forms of posture controlled timbrical transformation, rhythmic transformation, dynamic transformation, or even digital sound processing techniques.},
  archive   = {C_AAAI},
  author    = {Weizhen Bian and Yijin Song and Nianzhen Gu and Tin Yan Chan and Tsz To Lo and Tsun Sun Li and King Chak Wong and Wei Xue and Roberto Alonso Trillo},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26907},
  pages     = {16057-16062},
  title     = {MoMusic: A motion-driven human-AI collaborative music composition and performing system},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Literacy and STEM teachers adapt AI ethics curriculum.
<em>AAAI</em>, 16048–16055. (<a
href="https://doi.org/10.1609/aaai.v37i13.26906">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This article examines the ways secondary computer science and English Language Arts teachers in urban, suburban, and semi-rural schools adapted a project-based AI ethics curriculum to make it better fit their local contexts. AI ethics is an urgent topic with tangible consequences for youths’ current and future lives, but one that is rarely taught in schools. Few teachers have formal training in this area as it is an emerging field even at the university level. Exploring AI ethics involves examining biases related to race, gender, and social class, a challenging task for all teachers, and an unfamiliar one for most computer science teachers. It also requires teaching technical content which falls outside the comfort zone of most humanities teachers. Although none of our partner teachers had previously taught an AI ethics project, this study demonstrates that their expertise and experience in other domains played an essential role in providing high quality instruction. Teachers designed and redesigned tasks and incorporated texts and apps to ensure the AI ethics project would adhere to district and department level requirements; they led equity-focused inquiry in a way that both protected vulnerable students and accounted for local cultures and politics; and they adjusted technical content and developed hands-on computer science experiences to better challenge and engage their students. We use Mishra and Kohler’s TPACK framework to highlight the ways teachers leveraged their own expertise in some areas, while relying on materials and support from our research team in others, to create stronger learning experiences.},
  archive   = {C_AAAI},
  author    = {Benjamin Walsh and Bridget Dalton and Stacey Forsyth and Tom Yeh},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26906},
  pages     = {16048-16055},
  title     = {Literacy and STEM teachers adapt AI ethics curriculum},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Guiding students to investigate what google speech
recognition knows about language. <em>AAAI</em>, 16040–16047. (<a
href="https://doi.org/10.1609/aaai.v37i13.26905">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Today, children of all ages interact with speech recognition systems but are largely unaware of how they work. Teaching K-12 students to investigate how these systems employ phonological, syntactic, semantic, and cultural knowledge to resolve ambiguities in the audio signal can provide them a window on complex AI decision-making and also help them appreciate the richness and complexity of human language. We describe a browser-based tool for exploring the Google Web Speech API and a series of experiments students can engage in to measure what the service knows about language and the types of biases it exhibits. Middle school students taking an introductory AI elective were able to use the tool to explore Google’s knowledge of homophones and its ability to exploit context to disambiguate them. Older students could potentially conduct more comprehensive investigations, which we lay out here. This approach to investigating the power and limitations of speech technology through carefully designed experiments can also be applied to other AI application areas, such as face detection, object recognition, machine translation, or question answering.},
  archive   = {C_AAAI},
  author    = {David S. Touretzky and Christina Gardner-McCune},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26905},
  pages     = {16040-16047},
  title     = {Guiding students to investigate what google speech recognition knows about language},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Develop AI teaching and learning resources for compulsory
education in china. <em>AAAI</em>, 16033–16039. (<a
href="https://doi.org/10.1609/aaai.v37i13.26904">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Artificial intelligence course has been required to take for compulsory education students in China. However, not all teachers and schools are fully prepared and ready. This is partially because of the lack of adequate teaching and learning resources, which requires a major expenditure of time and effort for schools and teachers to design and develop. To meet the challenge of lacking appropriate resources in teaching and learning AI from grade 1 to grade 9, we developed AI knowledge structure and instructional resources based on Chinese national curriculum for information science and technology. Our comprehensive AI syllabus contains 90 core concepts, 63 learning indicators, and 27 teaching and learning resources, which have been implemented. The resources have been taken as model courses in teacher training programs and an exemplary course has been implemented in primary schools that verified the effectiveness of our resources.},
  archive   = {C_AAAI},
  author    = {Jiachen Song and Jinglei Yu and Li Yan and Linan Zhang and Bei Liu and Yujin Zhang and Yu Lu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26904},
  pages     = {16033-16039},
  title     = {Develop AI teaching and learning resources for compulsory education in china},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Build-a-bot: Teaching conversational AI using a
transformer-based intent recognition and question answering
architecture. <em>AAAI</em>, 16025–16032. (<a
href="https://doi.org/10.1609/aaai.v37i13.26903">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As artificial intelligence (AI) becomes a prominent part of modern life, AI literacy is becoming important for all citizens, not just those in technology careers. Previous research in AI education materials has largely focused on the introduction of terminology as well as AI use cases and ethics, but few allow students to learn by creating their own machine learning models. Therefore, there is a need for enriching AI educational tools with more adaptable and flexible platforms for interested educators with any level of technical experience to utilize within their teaching material. As such, we propose the development of an open-source tool (Build-A-Bot) for students and teachers to not only create their own transformer-based chatbots based on their own course material but also learn the fundamentals of AI through the model creation process. The primary concern of this paper is the creation of an interface for students to learn the principles of artificial intelligence by using a natural language pipeline to train a customized model to answer questions based on their own school curriculums. The model uses contexts given by their instructor, such as chapters of a textbook, to answer questions and is deployed on an interactive chatbot/voice agent. The pipeline teaches students data collection, data augmentation, intent recognition, and question answering by having them work through each of these processes while creating their AI agent, diverging from previous chatbot work where students and teachers use the bots as black-boxes with no abilities for customization or the bots lack AI capabilities, with the majority of dialogue scripts being rule-based. In addition, our tool is designed to make each step of this pipeline intuitive for students at a middle-school level. Further work primarily lies in providing our tool to schools and seeking student and teacher evaluations.},
  archive   = {C_AAAI},
  author    = {Kate Pearce and Sharifa Alghowinem and Cynthia Breazeal},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26903},
  pages     = {16025-16032},
  title     = {Build-a-bot: Teaching conversational AI using a transformer-based intent recognition and question answering architecture},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). “How can i code a.i. Responsibly?”: The effect of
computational action on k-12 students learning and creating socially
responsible a.i. <em>AAAI</em>, 16017–16024. (<a
href="https://doi.org/10.1609/aaai.v37i13.26902">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Teaching young people about artificial intelligence (A.I.) is recognized globally as an important education effort by organizations and programs such as UNICEF, OECD, Elements of A.I., and AI4K12. A common theme among K-12 A.I. education programs is teaching how A.I. can impact society in both positive and negative ways. We present an effective tool that teaches young people about the societal impact of A.I. that goes one step further: empowering K-12 students to use tools and frameworks to create socially responsible A.I. The computational action process is a curriculum and toolkit that gives students the lessons and tools to evaluate positive and negative impacts of A.I. and consider how they can create beneficial solutions that involve A.I. and computing technology. In a human-subject research study, 101 U.S. and international students between ages 9 and 18 participated in a one-day workshop to learn and practice the computational action process. Pre-post questionnaires measured on the Likert scale students’ perception of A.I. in society and students&#39; desire to use A.I. in their projects. Analysis of the results shows that students who identified as female agreed more strongly with having a concern about the impacts of A.I. than those who identified as male. Students also wrote open-ended responses to questions about what socially responsible technology means to them pre- and post-study. Analysis shows that post-intervention, students were more aware of ethical considerations and what tools they can use to code A.I. responsibly. In addition, students engaged actively with tools in the computational action toolkit, specifically the novel impact matrix, to describe the positive and negative impacts of A.I. technologies like facial recognition. Students demonstrated breadth and depth of discussion of various A.I. technologies&#39; far-reaching positive and negative impacts. These promising results indicate that the computational action process can be a helpful addition to A.I. education programs in furnishing tools for students to analyze the effects of A.I. on society and plan how they can create and use socially responsible A.I.},
  archive   = {C_AAAI},
  author    = {H. Nicole Pang and Robert Parks and Cynthia Breazeal and Hal Abelson},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26902},
  pages     = {16017-16024},
  title     = {“How can i code A.I. responsibly?”: The effect of computational action on K-12 students learning and creating socially responsible A.I.},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Scratch for sports: Athletic drills as a platform for
experiencing, understanding, and developing AI-driven apps.
<em>AAAI</em>, 16011–16016. (<a
href="https://doi.org/10.1609/aaai.v37i13.26901">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Culturally relevant and sustaining implementations of computing education are increasingly leveraging young learners&#39; passion for sports as a platform for building interest in different STEM (Science, Technology, Engineering, and Math) concepts. Numerous disciplines spanning physics, engineering, data science, and especially AI based computing are not only authentically used in professional sports in today&#39;s world, but can also be productively introduced to introduce young learnres to these disciplines and facilitate deep engagement with the same in the context of sports. In this work, we present a curriculum that includes a constellation of proprietary apps and tools we show student athletes learning sports like basketball and soccer that use AI methods like pose detection and IMU-based gesture detection to track activity and provide feedback. We also share Scratch extensions which enable rich access to sports related pose, object, and gesture detection algorithms that youth can then tinker around with and develop their own sports drill applications. We present early findings from pilot implementations of portions of these tools and curricula, which also fostered discussion relating to the failings, risks, and social harms associated with many of these different AI methods – noticeable in professional sports contexts, and relevant to youths&#39; lives as active users of AI technologies as well as potential future creators of the same.},
  archive   = {C_AAAI},
  author    = {Vishesh Kumar and Marcelo Worsley},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26901},
  pages     = {16011-16016},
  title     = {Scratch for sports: Athletic drills as a platform for experiencing, understanding, and developing AI-driven apps},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An introduction to rule-based feature and object perception
for middle school students. <em>AAAI</em>, 16004–16010. (<a
href="https://doi.org/10.1609/aaai.v37i13.26900">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Feature Detection tool is a web-based activity that allows students to detect features in images and build their own rule-based classification algorithms. In this paper, we introduce the tool and share how it is incorporated into two, 45-minute lessons. The objective of the first lesson is to introduce students to the concept of feature detection, or how a computer can break down visual input into lower-level features. The second lesson aims to show students how these lower-level features can be incorporated into rule-based models to classify higher-order objects. We discuss how this tool can be used as a &quot;first step&quot; to the more complex concept ideas of data representation and neural networks.},
  archive   = {C_AAAI},
  author    = {Daniella DiPaola and Parker Malachowsky and Nancye Blair Black and Sharifa Alghowinem and Xiaoxue Du and Cynthia Breazeal},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26900},
  pages     = {16004-16010},
  title     = {An introduction to rule-based feature and object perception for middle school students},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploring artificial intelligence in english language arts
with StoryQ. <em>AAAI</em>, 15999–16003. (<a
href="https://doi.org/10.1609/aaai.v37i13.26899">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Exploring Artificial Intelligence (AI) in English Language Arts (ELA) with StoryQ is a 10-hour curriculum module designed for high school ELA classes. The module introduces students to fundamental AI concepts and essential machine learning workflow using StoryQ, a web-based GUI environment for Grades 6-12 learners. In this module, students work with unstructured text data and learn to train, test, and improve text classification models such as intent recognition, clickbait filter, and sentiment analysis. As they interact with machine-learning language models deeply, students also gain a nuanced understanding of language and how to wield it, not just as a data structure, but as a tool in our human-human encounters as well. The current version contains eight lessons, all delivered through a full-featured online learning and teaching platform. Computers and Internet access are required to implement the module. The module was piloted in an ELA class in the Spring of 2022, and the student learning outcomes were positive. The module is currently undergoing revision and will be further tested and improved in Fall 2022.},
  archive   = {C_AAAI},
  author    = {Jie Chao and Rebecca Ellis and Shiyan Jiang and Carolyn Rosé and William Finzer and Cansu Tatar and James Fiacco and Kenia Wiedemann},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26899},
  pages     = {15999-16003},
  title     = {Exploring artificial intelligence in english language arts with StoryQ},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Beyond black-boxes: Teaching complex machine learning ideas
through scaffolded interactive activities. <em>AAAI</em>, 15990–15998.
(<a href="https://doi.org/10.1609/aaai.v37i13.26898">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Existing approaches to teaching artificial intelligence and machine learning (ML) often focus on the use of pre-trained models or fine-tuning an existing black-box architecture. We believe ML techniques and core ML topics, such as optimization and adversarial examples, can be designed for high school age students given appropriate support. Our curricular approach focuses on teaching ML ideas by enabling students to develop deep intuition about these complex concepts by first making them accessible to novices through interactive tools, pre-programmed games, and carefully designed programming activities. Then, students are able to engage with the concepts via meaningful, hands-on experiences that span the entire ML process from data collection to model optimization and inspection. This paper describes our &#39;AI &amp; Cybersecurity for Teens&#39; suite of curricular activities aimed at high school students and teachers.},
  archive   = {C_AAAI},
  author    = {Brian Broll and Shuchi Grover},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26898},
  pages     = {15990-15998},
  title     = {Beyond black-boxes: Teaching complex machine learning ideas through scaffolded interactive activities},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AI audit: A card game to reflect on everyday AI systems.
<em>AAAI</em>, 15981–15989. (<a
href="https://doi.org/10.1609/aaai.v37i13.26897">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {An essential element of K-12 AI literacy is educating learners about the ethical and societal implications of AI systems. Previous work in AI ethics literacy have developed curriculum and classroom activities that engage learners in reflecting on the ethical implications of AI systems and developing responsible AI. There is little work in using game-based learning methods in AI literacy. Games are known to be compelling media to teach children about complex STEM concepts. In this work, we developed a competitive card game for middle and high school students called “AI Audit” where they play as AI start-up founders building novel AI-powered technology. Players can challenge other players with potential harms of their technology or defend their own businesses by features that mitigate these harms. The game mechanics reward systems that are ethically developed or that take steps to mitigate potential harms. In this paper, we present the game design, teacher resources for classroom deployment and early playtesting results. We discuss our reflections about using games as teaching tools for AI literacy in K-12 classrooms.},
  archive   = {C_AAAI},
  author    = {Safinah Ali and Vishesh Kumar and Cynthia Breazeal},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26897},
  pages     = {15981-15989},
  title     = {AI audit: A card game to reflect on everyday AI systems},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Solving math word problems concerning systems of equations
with GPT-3. <em>AAAI</em>, 15972–15979. (<a
href="https://doi.org/10.1609/aaai.v37i13.26896">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Researchers have been interested in developing AI tools to help students learn various mathematical subjects. One challenging set of tasks for school students is learning to solve math word problems. We explore how recent advances in natural language processing, specifically the rise of powerful transformer based models, can be applied to help math learners with such problems. Concretely, we evaluate the use of GPT-3, a 1.75B parameter transformer model recently released by OpenAI, for three related challenges pertaining to math word problems corresponding to systems of two linear equations. The three challenges are classifying word problems, extracting equations from word problems, and generating word problems. For the first challenge, we define a set of problem classes and find that GPT-3 has generally very high accuracy in classifying word problems (80\%-100\%), for all but one of these classes. For the second challenge, we find the accuracy for extracting equations improves with number of examples provided to the model, ranging from an accuracy of 31\% for zero-shot learning to about 69\% using 3-shot learning, which is further improved to a high value of 80\% with fine-tuning. For the third challenge, we find that GPT-3 is able to generate problems with accuracy ranging from 33\% to 93\%, depending on the problem type.},
  archive   = {C_AAAI},
  author    = {Mingyu Zong and Bhaskar Krishnamachari},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26896},
  pages     = {15972-15979},
  title     = {Solving math word problems concerning systems of equations with GPT-3},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Detecting exclusive language during pair programming.
<em>AAAI</em>, 15964–15971. (<a
href="https://doi.org/10.1609/aaai.v37i13.26895">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Inclusive team participation is one of the most important factors that aids effective collaboration and pair programming. In this paper, we investigated the ability of linguistic features and a transformer-based language model to detect exclusive and inclusive language. The task of detecting exclusive language was approached as a text classification problem. We created a research community resource consisting of a dataset of 40,490 labeled utterances obtained from three programming assignments involving 34 students pair programming in a remote environment. This research involves the first successful automated detection of exclusive language during pair programming. Additionally, this is the first work to perform a computational linguistic analysis on the verbal interaction common in the context of inclusive and exclusive language during pair programming.},
  archive   = {C_AAAI},
  author    = {Solomon Ubani and Rodney Nielsen and Helen Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26895},
  pages     = {15964-15971},
  title     = {Detecting exclusive language during pair programming},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). H-AES: Towards automated essay scoring for hindi.
<em>AAAI</em>, 15955–15963. (<a
href="https://doi.org/10.1609/aaai.v37i13.26894">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The use of Natural Language Processing (NLP) for Automated Essay Scoring (AES) has been well explored in the English language, with benchmark models exhibiting performance comparable to human scorers. However, AES in Hindi and other low-resource languages remains unexplored. In this study, we reproduce and compare state-of-the-art methods for AES in the Hindi domain. We employ classical feature-based Machine Learning (ML) and advanced end-to-end models, including LSTM Networks and Fine-Tuned Transformer Architecture, in our approach and derive results comparable to those in the English language domain. Hindi being a low-resource language, lacks a dedicated essay-scoring corpus. We train and evaluate our models using translated English essays and empirically measure their performance on our own small-scale, real-world Hindi corpus. We follow this up with an in-depth analysis discussing prompt-specific behavior of different language models implemented.},
  archive   = {C_AAAI},
  author    = {Shubhankar Singh and Anirudh Pupneja and Shivaansh Mital and Cheril Shah and Manish Bawkar and Lakshman Prasad Gupta and Ajit Kumar and Yaman Kumar and Rushali Gupta and Rajiv Ratn Shah},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26894},
  pages     = {15955-15963},
  title     = {H-AES: Towards automated essay scoring for hindi},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CLGT: A graph transformer for student performance prediction
in collaborative learning. <em>AAAI</em>, 15947–15954. (<a
href="https://doi.org/10.1609/aaai.v37i13.26893">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Modeling and predicting the performance of students in collaborative learning paradigms is an important task. Most of the research presented in literature regarding collaborative learning focuses on the discussion forums and social learning networks. There are only a few works that investigate how students interact with each other in team projects and how such interactions affect their academic performance. In order to bridge this gap, we choose a software engineering course as the study subject. The students who participate in a software engineering course are required to team up and complete a software project together. In this work, we construct an interaction graph based on the activities of students grouped in various teams. Based on this student interaction graph, we present an extended graph transformer framework for collaborative learning (CLGT) for evaluating and predicting the performance of students. Moreover, the proposed CLGT contains an interpretation module that explains the prediction results and visualizes the student interaction patterns. The experimental results confirm that the proposed CLGT outperforms the baseline models in terms of performing predictions based on the real-world datasets. Moreover, the proposed CLGT differentiates the students with poor performance in the collaborative learning paradigm and gives teachers early warnings, so that appropriate assistance can be provided.},
  archive   = {C_AAAI},
  author    = {Tianhao Peng and Yu Liang and Wenjun Wu and Jian Ren and Zhao Pengrui and Yanjun Pu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26893},
  pages     = {15947-15954},
  title     = {CLGT: A graph transformer for student performance prediction in collaborative learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Context-aware analysis of group submissions for group
anomaly detection and performance prediction. <em>AAAI</em>,
15938–15946. (<a
href="https://doi.org/10.1609/aaai.v37i13.26892">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Learning exercises that activate students’ additional cognitive understanding of course concepts facilitate contextualizing the content knowledge and developing higher-order thinking and problem-solving skills. Student-generated instructional materials such as course summaries and problem sets are amongst the instructional strategies that reflect active learning and constructivist philosophy. The contributions of this work are twofold: 1) We introduce a practical implementation of inside-outside learning strategy in an undergraduate deep learning course and will share our experiences in incorporating student-generated instructional materials learning strategy in course design, and 2) We develop a context-aware deep learning framework to draw insights from the student-generated materials for (i) Detecting anomalies in group activities and (ii) Predicting the median quiz performance of students in each group. This work opens up an avenue for effectively implementing a constructivism learning strategy in large-scale and online courses to build a sense of community between learners while providing an automated tool for instructors to identify at-risk groups.},
  archive   = {C_AAAI},
  author    = {Narges Norouzi and Amir Mazaheri},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26892},
  pages     = {15938-15946},
  title     = {Context-aware analysis of group submissions for group anomaly detection and performance prediction},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning logical reasoning using an intelligent tutoring
system: A hybrid approach to student modeling. <em>AAAI</em>,
15930–15937. (<a
href="https://doi.org/10.1609/aaai.v37i13.26891">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In our previous works, we presented Logic-Muse as an Intelligent Tutoring System that helps learners improve logical reasoning skills in multiple contexts. Logic-Muse components were validated and argued by experts throughout the designing process (ITS researchers, logicians, and reasoning psychologists). A catalog of reasoning errors (syntactic and semantic) has been established, in addition to an explicit representation of semantic knowledge and the structures and meta-structures underlying conditional reasoning. A Bayesian network with expert validation has been developed and used in a Bayesian Knowledge Tracing (BKT) process that allows the inference of the learner skills. This paper presents an evaluation of the learner-model components in Logic-Muse (a bayesian learner model). We conducted a study and collected data from nearly 300 students who processed 48 reasoning activities. These data were used to develop a psychometric model for initializing the learner&#39;s model and validating the structure of the initial Bayesian network. We have also developed a neural architecture on which a model was trained to support a deep knowledge tracing (DKT) process. The proposed neural architecture improves the initial version of DKT by allowing the integration of expert knowledge (through the Bayesian Expert Validation Network) and allowing better generalization of knowledge with few samples. The results show a significant improvement in the predictive power of the learner model. The analysis of the results of the psychometric model also illustrates an excellent potential for improving the Bayesian network&#39;s structure and the learner model&#39;s initialization process.},
  archive   = {C_AAAI},
  author    = {Roger Nkambou and Janie Brisson and Ange Tato and Serge Robert},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26891},
  pages     = {15930-15937},
  title     = {Learning logical reasoning using an intelligent tutoring system: A hybrid approach to student modeling},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A dataset for learning university STEM courses at scale and
generating questions at a human level. <em>AAAI</em>, 15921–15929. (<a
href="https://doi.org/10.1609/aaai.v37i13.27091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present a new dataset for learning to solve, explain, and generate university-level STEM questions from 27 courses across a dozen departments in seven universities. We scale up previous approaches to questions from courses in the departments of Mechanical Engineering, Materials Science and Engineering, Chemistry, Electrical Engineering, Computer Science, Physics, Earth Atmospheric and Planetary Sciences, Economics, Mathematics, Biological Engineering, Data Systems, and Society, and Statistics. We visualize similarities and differences between questions across courses. We demonstrate that a large foundation model is able to generate questions that are as appropriate and at the same difficulty level as human-written questions.},
  archive   = {C_AAAI},
  author    = {Iddo Drori and Sarah Zhang and Zad Chin and Reece Shuttleworth and Albert Lu and Linda Chen and Bereket Birbo and Michele He and Pedro Lantigua and Sunny Tran and Gregory Hunter and Bo Feng and Newman Cheng and Roman Wang and Yann Hicke and Saisamrit Surbehera and Arvind Raghavan and Alexander Siemenn and Nikhil Singh and Jayson Lynch and Avi Shporer and Nakul Verma and Tonio Buonassisi and Armando Solar-Lezama},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.27091},
  pages     = {15921-15929},
  title     = {A dataset for learning university STEM courses at scale and generating questions at a human level},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploring tradeoffs in automated school redistricting:
Computational and ethical perspectives. <em>AAAI</em>, 15912–15920. (<a
href="https://doi.org/10.1609/aaai.v37i13.26889">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The US public school system is administered by local school districts. Each district comprises a set of schools mapped to attendance zones which are annually assessed to meet enrollment objectives. To support school officials in redrawing attendance boundaries, existing approaches have proven promising but still suffer from several challenges, including: 1) inability to scale to large school districts, 2) high computational cost of obtaining compact school attendance zones, and 3) lack of discussion on quantifying ethical considerations underlying the redrawing of school boundaries. Motivated by these challenges, this paper approaches the school redistricting problem from both computational and ethical standpoints. First, we introduce a practical framework based on sampling methods to solve school redistricting as a graph partitioning problem. Next, the advantages of adopting a modified objective function for optimizing discrete geometry to obtain compact boundaries are examined. Lastly, alternative metrics to address ethical considerations in real-world scenarios are formally defined and thoroughly discussed. Our findings highlight the inclusiveness and efficiency advantages of the designed framework and depict how tradeoffs need to be made to obtain qualitatively different school redistricting plans.},
  archive   = {C_AAAI},
  author    = {Fanglan Chen and Subhodip Biswas and Zhiqian Chen and Shuo Lei and Naren Ramakrishnan and Chang-Tien Lu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26889},
  pages     = {15912-15920},
  title     = {Exploring tradeoffs in automated school redistricting: Computational and ethical perspectives},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Ripple: Concept-based interpretation for raw time series
models in education. <em>AAAI</em>, 15903–15911. (<a
href="https://doi.org/10.1609/aaai.v37i13.26888">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Time series is the most prevalent form of input data for educational prediction tasks. The vast majority of research using time series data focuses on hand-crafted features, designed by experts for predictive performance and interpretability. However, extracting these features is labor-intensive for humans and computers. In this paper, we propose an approach that utilizes irregular multivariate time series modeling with graph neural networks to achieve comparable or better accuracy with raw time series clickstreams in comparison to hand-crafted features. Furthermore, we extend concept activation vectors for interpretability in raw time series models. We analyze these advances in the education domain, addressing the task of early student performance prediction for downstream targeted interventions and instructional support. Our experimental analysis on 23 MOOCs with millions of combined interactions over six behavioral dimensions show that models designed with our approach can (i) beat state-of-the-art educational time series baselines with no feature extraction and (ii) provide interpretable insights for personalized interventions. Source code: https://github.com/epfl-ml4ed/ripple/.},
  archive   = {C_AAAI},
  author    = {Mohammad Asadi and Vinitra Swamy and Jibril Frej and Julien Vignoud and Mirko Marras and Tanja Käser},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26888},
  pages     = {15903-15911},
  title     = {Ripple: Concept-based interpretation for raw time series models in education},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Does knowing when help is needed improve subgoal hint
performance in an intelligent data-driven logic tutor? <em>AAAI</em>,
15895–15902. (<a
href="https://doi.org/10.1609/aaai.v37i13.26887">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The assistance dilemma is a well-recognized challenge to determine when and how to provide help during problem solving in intelligent tutoring systems. This dilemma is particularly challenging to address in domains such as logic proofs, where problems can be solved in a variety of ways. In this study, we investigate two data-driven techniques to address the when and how of the assistance dilemma, combining a model that predicts when students need help learning efficient strategies, and hints that suggest what subgoal to achieve. We conduct a study assessing the impact of the new pedagogical policy against a control policy without these adaptive components. We found empirical evidence which suggests that showing subgoals in training problems upon predictions of the model helped the students who needed it most and improved test performance when compared to their control peers. Our key findings include significantly fewer steps in posttest problem solutions for students with low prior proficiency and significantly reduced help avoidance for all students in training.},
  archive   = {C_AAAI},
  author    = {Nazia Alam and Mehak Maniktala and Behrooz Mostafavi and Min Chi and Tiffany Barnes},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26887},
  pages     = {15895-15902},
  title     = {Does knowing when help is needed improve subgoal hint performance in an intelligent data-driven logic tutor?},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data labeling for machine learning engineers: Project-based
curriculum and data-centric competitions. <em>AAAI</em>, 15886–15893.
(<a href="https://doi.org/10.1609/aaai.v37i13.26886">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The process of training and evaluating machine learning (ML) models relies on high-quality and timely annotated datasets. While a significant portion of academic and industrial research is focused on creating new ML methods, these communities rely on open datasets and benchmarks. However, practitioners often face issues with unlabeled and unavailable data specific to their domain. We believe that building scalable and sustainable processes for collecting data of high quality for ML is a complex skill that needs focused development. To fill the need for this competency, we created a semester course on Data Collection and Labeling for Machine Learning, integrated into a bachelor program that trains data analysts and ML engineers. The course design and delivery illustrate how to overcome the challenge of putting university students with a theoretical background in mathematics, computer science, and physics through a program that is substantially different from their educational habits. Our goal was to motivate students to focus on practicing and mastering a skill that was considered unnecessary to their work. We created a system of inverse ML competitions that showed the students how high-quality and relevant data affect their work with ML models, and their mindset changed completely in the end. Project-based learning with increasing complexity of conditions at each stage helped to raise the satisfaction index of students accustomed to difficult challenges. During the course, our invited industry practitioners drew on their first-hand experience with data, which helped us avoid overtheorizing and made the course highly applicable to the students’ future career paths.},
  archive   = {C_AAAI},
  author    = {Anastasia Zhdanovskaya and Daria Baidakova and Dmitry Ustalov},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26886},
  pages     = {15886-15893},
  title     = {Data labeling for machine learning engineers: Project-based curriculum and data-centric competitions},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Responsible robotics: A socio-ethical addition to robotics
courses. <em>AAAI</em>, 15877–15885. (<a
href="https://doi.org/10.1609/aaai.v37i13.26885">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We are witnessing a rapid increase in real-world autonomous robotic deployments in environments ranging from indoor homes and commercial establishments to large-scale urban areas, with applications ranging from domestic assistance to urban last-mile delivery. The developers of these robots inevitably have to make impactful design decisions to ensure commercially viability, but such decisions have serious real-world consequences. Unfortunately it is not uncommon for such projects to face intense bouts of social backlash, which can be attributed to a wide variety of causes, ranging from inappropriate technical design choices to transgressions of social norms and lack of community engagement. To better prepare students for the rigors of developing and deploying real-world robotics systems, we developed a Responsible Robotics teaching module, intended to be included in upper-division and graduate level robotics courses. Our module is structured as a role playing exercise which aims to equip students with a framework for navigating the conflicting goals of human actors which govern robots in the field. We report on instructor reflections and anonymous survey responses from offering our responsible robotics module in both a graduate-level, and an upper-division undergraduate robotics course at UT Austin. The responses indicate that students gained a deeper understanding of the socio-technical factors of real-world robotics deployments than they might have using self-study methods, and the students proactively suggested that such modules should be more broadly included in CS courses.},
  archive   = {C_AAAI},
  author    = {Joshua Vekhter and Joydeep Biswas},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26885},
  pages     = {15877-15885},
  title     = {Responsible robotics: A socio-ethical addition to robotics courses},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FOLL-e: Teaching first order logic to children.
<em>AAAI</em>, 15869–15876. (<a
href="https://doi.org/10.1609/aaai.v37i13.26884">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {First-order logic (FO) is an important foundation of many domains, including computer science and artificial intelligence. In recent efforts to teach basic CS and AI concepts to children, FO has so far remained absent. In this paper, we examine whether it is possible to design a learning environment that both motivates and enables children to learn the basics of FO. The key components of the learning environment are a syntax-free blocks-based notation for FO, graphics-based puzzles to solve, and a tactile environment which uses computer vision to allow the children to work with wooden blocks. The resulting FOLL-E system is intended to sharpen childrens&#39; reasoning skills, encourage critical thinking and make them aware of the ambiguities of natural language. During preliminary testing with children, they reported that they found the notation intuitive and inviting, and that they enjoyed interacting with the application.},
  archive   = {C_AAAI},
  author    = {Simon Vandevelde and Joost Vennekens},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26884},
  pages     = {15869-15876},
  title     = {FOLL-E: Teaching first order logic to children},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning affects trust: Design recommendations and concepts
for teaching children—and nearly anyone—about conversational agents.
<em>AAAI</em>, 15860–15868. (<a
href="https://doi.org/10.1609/aaai.v37i13.26883">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Conversational agents are rapidly becoming commonplace. However, since these systems are typically blackboxed, users—including vulnerable populations, like children—often do not understand them deeply. For example, they might assume agents are overly intelligent, leading to frustration and distrust. Users may also overtrust agents, and thus overshare personal information or rely heavily on agents&#39; advice. Despite this, little research investigates users&#39; perceptions of conversational agents in-depth, and even less investigates how education might change these perceptions to be more healthy. We present workshops with associated educational conversational AI concepts to encourage healthier understanding of agents. Through studies with the curriculum with children and parents from various countries, we found participants&#39; perceptions of agents—specifically their partner models and trust—changed. When participants discussed changes in trust of agents, we found they most often mentioned learning something. For example, they frequently mentioned learning where agents obtained information, what agents do with this information and how agents are programmed. Based on the results, we developed recommendations for teaching conversational agent concepts, including emphasizing the concepts students found most challenging, like training, turn-taking and terminology; supplementing agent development activities with related learning activities; fostering appropriate levels of trust towards agents; and fostering accurate partner models of agents. Through such pedagogy, students can learn to better understand conversational AI and what it means to have it in the world.},
  archive   = {C_AAAI},
  author    = {Jessica Van Brummelen and Mingyan Claire Tian and Maura Kelleher and Nghi Hoang Nguyen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26883},
  pages     = {15860-15868},
  title     = {Learning affects trust: Design recommendations and concepts for teaching children—and nearly anyone—about conversational agents},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AI made by youth: A conversational AI curriculum for middle
school summer camps. <em>AAAI</em>, 15851–15859. (<a
href="https://doi.org/10.1609/aaai.v37i13.26882">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As artificial intelligence permeates our lives through various tools and services, there is an increasing need to consider how to teach young learners about AI in a relevant and engaging way. One way to do so is to leverage familiar and pervasive technologies such as conversational AIs. By learning about conversational AIs, learners are introduced to AI concepts such as computers’ perception of natural language, the need for training datasets, and the design of AI-human interactions. In this experience report, we describe a summer camp curriculum designed for middle school learners composed of general AI lessons, unplugged activities, conversational AI lessons, and project activities in which the campers develop their own conversational agents. The results show that this summer camp experience fostered significant increases in learners’ ability beliefs, willingness to share their learning experience, and intent to persist in AI learning. We conclude with a discussion of how conversational AI can be used as an entry point to K-12 AI education.},
  archive   = {C_AAAI},
  author    = {Yukyeong Song and Gloria Ashiya Katuka and Joanne Barrett and Xiaoyi Tian and Amit Kumar and Tom McKlin and Mehmet Celepkolu and Kristy Elizabeth Boyer and Maya Israel},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26882},
  pages     = {15851-15859},
  title     = {AI made by youth: A conversational AI curriculum for middle school summer camps},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Autonomous agents: An advanced course on AI integration and
deployment. <em>AAAI</em>, 15843–15850. (<a
href="https://doi.org/10.1609/aaai.v37i13.26881">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A majority of the courses on autonomous systems focus on robotics, despite the growing use of autonomous agents in a wide spectrum of applications, from smart homes to intelligent traffic control. Our goal in designing a new senior-level undergraduate course is to teach the integration of a variety of AI techniques in uncertain environments, without the dependence on topics such as robotic control and localization. We chose the application of an autonomous greenhouse to frame our discussions and our student projects because of the greenhouse&#39;s self-contained nature and objective metrics for successfully growing plants. We detail our curriculum design, including lecture topics and assignments, and our iterative process for updating the course over the last four years. Finally, we present some student feedback about the course and opportunities for future improvement.},
  archive   = {C_AAAI},
  author    = {Stephanie Rosenthal and Reid Simmons},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26881},
  pages     = {15843-15850},
  title     = {Autonomous agents: An advanced course on AI integration and deployment},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An analysis of engineering students’ responses to an AI
ethics scenario. <em>AAAI</em>, 15834–15842. (<a
href="https://doi.org/10.1609/aaai.v37i13.26880">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In light of significant issues in the technology industry, such as algorithms that worsen racial biases, the spread of online misinformation, and the expansion of mass surveillance, it is increasingly important to teach the ethics and sociotechnical implications of developing and using artificial intelligence (AI). Using 53 survey responses from engineering undergraduates, this paper measures students&#39; abilities to identify, mitigate, and reflect on a hypothetical AI ethics scenario. We engage with prior research on pedagogical approaches to and considerations for teaching AI ethics and highlight some of the obstacles that engineering undergraduate students experience in learning and applying AI ethics concepts.},
  archive   = {C_AAAI},
  author    = {Alexi Orchard and David Radke},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26880},
  pages     = {15834-15842},
  title     = {An analysis of engineering students’ responses to an AI ethics scenario},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploring social biases of large language models in a
college artificial intelligence course. <em>AAAI</em>, 15825–15833. (<a
href="https://doi.org/10.1609/aaai.v37i13.26879">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Large neural network-based language models play an increasingly important role in contemporary AI. Although these models demonstrate sophisticated text generation capabilities, they have also been shown to reproduce harmful social biases contained in their training data. This paper presents a project that guides students through an exploration of social biases in large language models. As a final project for an intermediate college course in Artificial Intelligence, students developed a bias probe task for a previously-unstudied aspect of sociolinguistic or sociocultural bias they were interested in exploring. Through the process of constructing a dataset and evaluation metric to measure bias, students mastered key technical concepts, including how to run contemporary neural networks for natural language processing tasks; construct datasets and evaluation metrics; and analyze experimental results. Students reported their findings in an in-class presentation and a final report, recounting patterns of predictions that surprised, unsettled, and sparked interest in advocating for technology that reflects a more diverse set of backgrounds and experiences. Through this project, students engage with and even contribute to a growing body of scholarly work on social biases in large language models.},
  archive   = {C_AAAI},
  author    = {Skylar Kolisko and Carolyn Jane Anderson},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26879},
  pages     = {15825-15833},
  title     = {Exploring social biases of large language models in a college artificial intelligence course},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Maestro: A gamified platform for teaching AI robustness.
<em>AAAI</em>, 15816–15824. (<a
href="https://doi.org/10.1609/aaai.v37i13.26878">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Although the prevention of AI vulnerabilities is critical to preserve the safety and privacy of users and businesses, educational tools for robust AI are still underdeveloped worldwide. We present the design, implementation, and assessment of Maestro. Maestro is an effective open-source game-based platform that contributes to the advancement of robust AI education. Maestro provides &quot;goal-based scenarios&quot; where college students are exposed to challenging life-inspired assignments in a &quot;competitive programming&quot; environment. We assessed Maestro&#39;s influence on students&#39; engagement, motivation, and learning success in robust AI. This work also provides insights into the design features of online learning tools that promote active learning opportunities in the robust AI domain. We analyzed the reflection responses (measured with Likert scales) of 147 undergraduate students using Maestro in two quarterly college courses in AI. According to the results, students who felt the acquisition of new skills in robust AI tended to appreciate highly Maestro and scored highly on material consolidation, curiosity, and maestry in robust AI. Moreover, the leaderboard, our key gamification element in Maestro, has effectively contributed to students&#39; engagement and learning. Results also indicate that Maestro can be effectively adapted to any course length and depth without losing its educational quality.},
  archive   = {C_AAAI},
  author    = {Margarita Geleta and Jiacen Xu and Manikanta Loya and Junlin Wang and Sameer Singh and Zhou Li and Sergio Gago-Masague},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26878},
  pages     = {15816-15824},
  title     = {Maestro: A gamified platform for teaching AI robustness},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Shared tasks as tutorials: A methodical approach.
<em>AAAI</em>, 15807–15815. (<a
href="https://doi.org/10.1609/aaai.v37i13.26877">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we discuss the benefits and challenges of shared tasks as a teaching method. A shared task is a scientific event and a friendly competition to solve a research problem, the task. In terms of linking research and teaching, shared-task-based tutorials fulfill several faculty desires: they leverage students&#39; interdisciplinary and heterogeneous skills, foster teamwork, and engage them in creative work that has the potential to produce original research contributions. Based on ten information retrieval (IR) courses at two universities since 2019 with shared tasks as tutorials, we derive a domain-neutral process model to capture the respective tutorial structure. Meanwhile, our teaching method has been adopted by other universities in IR courses, but also in other areas of AI such as natural language processing and robotics.},
  archive   = {C_AAAI},
  author    = {Theresa Elstner and Frank Loebe and Yamen Ajjour and Christopher Akiki and Alexander Bondarenko and Maik Fröbe and Lukas Gienapp and Nikolay Kolyada and Janis Mohr and Stephan Sandfuchs and Matti Wiegmann and Jörg Frochte and Nicola Ferro and Sven Hofmann and Benno Stein and Matthias Hagen and Martin Potthast},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26877},
  pages     = {15807-15815},
  title     = {Shared tasks as tutorials: A methodical approach},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AI and parallelism in CS1: Experiences and analysis.
<em>AAAI</em>, 15798–15806. (<a
href="https://doi.org/10.1609/aaai.v37i13.26876">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This work considers the use of AI and parallelism as a context for learning typical programming concepts in an introductory programming course (CS1). The course includes exercises in decision trees, a novel game called Find the Gnomes to introduce supervised learning, the construction and application of a vectorized neural network unit class, and obtaining speedup in training through parallelism. The exercises are designed to teach students typical introductory programming concepts while also providing a preview and motivating example of advanced CS topics. Students&#39; understanding and motivation are considered through a detailed analysis of pre- and post-survey data gathered in several sections of the course each taught by one of four instructors across five semesters.},
  archive   = {C_AAAI},
  author    = {Steven Bogaerts},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26876},
  pages     = {15798-15806},
  title     = {AI and parallelism in CS1: Experiences and analysis},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A study of students’ learning of computing through an
LP-based integrated curriculum for middle schools. <em>AAAI</em>,
15790–15797. (<a
href="https://doi.org/10.1609/aaai.v37i13.26875">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {There has been a consensus on integrating Computing into the teaching and learning of STEM (Science, Technology, Engineering and Math) subjects in K-12 (Kindergarten to 12th grade in the US education system). However, rigorous study on the impact of an integrated curriculum on students&#39; learning in computing and/or the STEM subject(s) is still rare. In this paper, we report our research on how well an integrated curriculum helps middle school students learn Computing through the microgenetic analysis methods.},
  archive   = {C_AAAI},
  author    = {Joshua Archer and Rory Eckel and Joshua Hawkins and Jianlan Wang and Darrel Musslewhite and Yuanlin Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26875},
  pages     = {15790-15797},
  title     = {A study of students’ learning of computing through an LP-based integrated curriculum for middle schools},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive temporal planning for multi-robot systems in
operations and maintenance of offshore wind farms. <em>AAAI</em>,
15782–15788. (<a
href="https://doi.org/10.1609/aaai.v37i13.26874">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With the fast development of offshore wind farms as renewable energy sources, maintaining them efficiently and safely becomes necessary. The high costs of operation and maintenance (O&amp;M) are due to the length of turbine downtime and the logistics for human technician transfer. To reduce such costs, we propose a comprehensive multi-robot system that includes unmanned aerial vehicles (UAV), autonomous surface vessels (ASV), and inspection-and-repair robots (IRR). Our system, which is capable of co-managing the farms with human operators located onshore, brings down costs and significantly reduces the Health and Safety (H&amp;S) risks of O&amp;M by assisting human operators in performing dangerous tasks. In this paper, we focus on using AI temporal planning to coordinate the actions of the different autonomous robots that form the multi-robot system. We devise a new, adaptive planning approach that reduces failures and replanning by performing data-driven goal and domain refinement. Our experiments in both simulated and real-world scenarios prove the effectiveness and robustness of our technique. The success of our system marks the first-step towards a large-scale, multirobot solution for wind farm O&amp;M.},
  archive   = {C_AAAI},
  author    = {Ferdian Jovan and Sara Bernardini},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26874},
  pages     = {15782-15788},
  title     = {Adaptive temporal planning for multi-robot systems in operations and maintenance of offshore wind farms},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PARCS: A deployment-oriented AI system for robust
parcel-level cropland segmentation of satellite images. <em>AAAI</em>,
15775–15781. (<a
href="https://doi.org/10.1609/aaai.v37i13.26873">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Cropland segmentation of satellite images is an essential basis for crop area and yield estimation tasks in the remote sensing and computer vision interdisciplinary community. Instead of common pixel-level segmentation results with salt-and-pepper effects, a parcel-level output conforming to human recognition is required according to the clients&#39; needs during the model deployment. However, leveraging CNN-based models requires fine-grained parcel-level labels, which is an unacceptable annotation burden. To cure these practical pain points, in this paper, we present PARCS, a holistic deployment-oriented AI system for PARcel-level Cropland Segmentation. By consolidating multi-disciplinary knowledge, PARCS has two algorithm branches. The first branch performs pixel-level crop segmentation by learning from limited labeled pixel samples with an active learning strategy to avoid parcel-level annotation costs. The second branch aims at generating the parcel regions without a learning procedure. The final parcel-level segmentation result is achieved by integrating the outputs of these two branches in tandem. The robust effectiveness of PARCS is demonstrated by its outstanding performance on public and in-house datasets (an overall accuracy of 85.3\% and an mIoU of 61.7\% on the public PASTIS dataset, and an mIoU of 65.16\% on the in-house dataset). We also include subjective feedback from clients and discuss the lessons learned from deployment.},
  archive   = {C_AAAI},
  author    = {Chen Du and Yiwei Wang and Zhicheng Yang and Hang Zhou and Mei Han and Jui-Hsin Lai},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26873},
  pages     = {15775-15781},
  title     = {PARCS: A deployment-oriented AI system for robust parcel-level cropland segmentation of satellite images},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DetAIL: A tool to automatically detect and analyze drift in
language. <em>AAAI</em>, 15767–15773. (<a
href="https://doi.org/10.1609/aaai.v37i13.26872">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Machine learning and deep learning-based decision making has become part of today&#39;s software. The goal of this work is to ensure that machine learning and deep learning-based systems are as trusted as traditional software. Traditional software is made dependable by following rigorous practice like static analysis, testing, debugging, verifying, and repairing throughout the development and maintenance life-cycle. Similarly for machine learning systems, we need to keep these models up to date so that their performance is not compromised. For this, current systems rely on scheduled re-training of these models as new data kicks in. In this work, we propose DetAIL, a tool to measure the data drift that takes place when new data kicks in so that one can adaptively re-train the models whenever re-training is actually required irrespective of schedules. In addition to that, we generate various explanations at sentence level and dataset level to capture why a given payload text has drifted.},
  archive   = {C_AAAI},
  author    = {Nishtha Madaan and Adithya Manjunatha and Hrithik Nambiar and Aviral Goel and Harivansh Kumar and Diptikalyan Saha and Srikanta Bedathur},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26872},
  pages     = {15767-15773},
  title     = {DetAIL: A tool to automatically detect and analyze drift in language},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Xaitk-saliency: An open source explainable AI toolkit for
saliency. <em>AAAI</em>, 15760–15766. (<a
href="https://doi.org/10.1609/aaai.v37i13.26871">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Advances in artificial intelligence (AI) using techniques such as deep learning have fueled the recent progress in fields such as computer vision. However, these algorithms are still often viewed as &quot;black boxes&quot;, which cannot easily explain how they arrived at their final output decisions. Saliency maps are one commonly used form of explainable AI (XAI), which indicate the input features an algorithm paid attention to during its decision process. Here, we introduce the open source xaitk-saliency package, an XAI framework and toolkit for saliency. We demonstrate its modular and flexible nature by highlighting two example use cases for saliency maps: (1) object detection model comparison and (2) doppelganger saliency for person re-identification. We also show how the xaitk-saliency package can be paired with visualization tools to support the interactive exploration of saliency maps. Our results suggest that saliency maps may play a critical role in the verification and validation of AI models, ensuring their trusted use and deployment. The code is publicly available at: https://github.com/xaitk/xaitk-saliency.},
  archive   = {C_AAAI},
  author    = {Brian Hu and Paul Tunison and Brandon RichardWebster and Anthony Hoogs},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26871},
  pages     = {15760-15766},
  title     = {Xaitk-saliency: An open source explainable AI toolkit for saliency},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). End-to-end pipeline for trigger detection on hit and track
graphs. <em>AAAI</em>, 15752–15758. (<a
href="https://doi.org/10.1609/aaai.v37i13.26870">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {There has been a surge of interest in applying deep learning in particle and nuclear physics to replace labor-intensive offline data analysis with automated online machine learning tasks. This paper details a novel AI-enabled triggering solution for physics experiments in Relativistic Heavy Ion Collider and future Electron-Ion Collider. The triggering system consists of a comprehensive end-to-end pipeline based on Graph Neural Networks that classifies trigger events versus background events, makes online decisions to retain signal data, and enables efficient data acquisition. The triggering system first starts with the coordinates of pixel hits lit up by passing particles in the detector, applies three stages of event processing (hits clustering, track reconstruction, and trigger detection), and labels all processed events with the binary tag of trigger versus background events. By switching among different objective functions, we train the Graph Neural Networks in the pipeline to solve multiple tasks: the edge-level track reconstruction problem, the edge-level track adjacency matrix prediction, and the graph-level trigger detection problem. We propose a novel method to treat the events as track-graphs instead of hit-graphs. This method focuses on intertrack relations and is driven by underlying physics processing. As a result, it attains a solid performance (around 72\% accuracy) for trigger detection and outperforms the baseline method using hit-graphs by 2\% higher accuracy.},
  archive   = {C_AAAI},
  author    = {Tingting Xuan and Yimin Zhu and Giorgian Borca-Tasciuc and Ming Xiong Liu and Yu Sun and Cameron Dean and Yasser Corrales Morales and Zhaozhong Shi and Dantong Yu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26870},
  pages     = {15752-15758},
  title     = {End-to-end pipeline for trigger detection on hit and track graphs},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). High-throughput, high-performance deep learning-driven light
guide plate surface visual quality inspection tailored for real-world
manufacturing environments. <em>AAAI</em>, 15745–15751. (<a
href="https://doi.org/10.1609/aaai.v37i13.26869">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Light guide plates are essential optical components widely used in a diverse range of applications ranging from medical lighting fixtures to back-lit TV displays. An essential step in the manufacturing of light guide plates is the quality inspection of defects such as scratches, bright/dark spots, and impurities. This is mainly done in industry through manual visual inspection for plate pattern irregularities, which is time-consuming and prone to human error and thus act as a significant barrier to high-throughput production. Advances in deep learning-driven computer vision has led to the exploration of automated visual quality inspection of light guide plates to improve inspection consistency, accuracy, and efficiency. However, given the computational constraints and high-throughput nature of real-world manufacturing environments, the widespread adoption of deep learning-driven visual inspection systems for inspecting light guide plates in real-world manufacturing environments has been greatly limited due to high computational requirements and integration challenges of existing deep learning approaches in research literature. In this work, we introduce a fully-integrated, high-throughput, high-performance deep learning-driven workflow for light guide plate surface visual quality inspection (VQI) tailored for real-world manufacturing environments. To enable automated VQI on the edge computing within the fully-integrated VQI system, a highly compact deep anti-aliased attention condenser neural network (which we name Light-DefectNet) tailored specifically for light guide plate surface defect detection in resource-constrained scenarios was created via machine-driven design exploration with computational and “best-practices” constraints as well as L1 paired classification discrepancy loss. Experiments show that Light-DetectNet achieves a detection accuracy of ∼98.2\% on the LGPSDD benchmark while having just 770K parameters (∼33× and ∼6.9× lower than ResNet-50 and EfficientNet-B0, respectively) and ∼93M FLOPs (∼88× and ∼8.4× lower than ResNet-50 and EfficientNet-B0, respectively) and ∼8.8× faster inference speed than EfficientNet-B0 on an embedded ARM processor. As such, the proposed deep learning-driven workflow, integrated with the aforementioned LightDefectNet neural network, is highly suited for high-throughput, high-performance light plate surface VQI within real-world manufacturing environments.},
  archive   = {C_AAAI},
  author    = {Carol Xu and Mahmoud Famouri and Gautam Bathla and Mohammad Javad Shafiee and Alexander Wong},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26869},
  pages     = {15745-15751},
  title     = {High-throughput, high-performance deep learning-driven light guide plate surface visual quality inspection tailored for real-world manufacturing environments},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fault injection based interventional causal learning for
distributed applications. <em>AAAI</em>, 15738–15744. (<a
href="https://doi.org/10.1609/aaai.v37i13.26868">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We apply the machinery of interventional causal learning with programmable interventions to the domain of applications management. Modern applications are modularized into interdependent components or services (e.g. microservices) for ease of development and management. The communication graph among such components is a function of application code and is not always known to the platform provider. In our solution we learn this unknown communication graph solely using application logs observed during the execution of the application by using fault injections in a staging environment. Specifically, we have developed an active (or interventional) causal learning algorithm that uses the observations obtained during fault injections to learn a model of error propagation in the communication among the components. The “power of intervention” additionally allows us to address the presence of confounders in unobserved user interactions. We demonstrate the effectiveness of our solution in learning the communication graph of well-known microservice application benchmarks. We also show the efficacy of the solution on a downstream task of fault localization in which the learned graph indeed helps to localize faults at runtime in a production environment (in which the location of the fault is unknown). Additionally, we briefly discuss the implementation and deployment status of a fault injection framework which incorporates the developed technology.},
  archive   = {C_AAAI},
  author    = {Qing Wang and Jesus Rios and Saurabh Jha and Karthikeyan Shanmugam and Frank Bagehorn and Xi Yang and Robert Filepp and Naoki Abe and Larisa Shwartz},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26868},
  pages     = {15738-15744},
  title     = {Fault injection based interventional causal learning for distributed applications},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Embedding a long short-term memory network in a constraint
programming framework for tomato greenhouse optimisation. <em>AAAI</em>,
15731–15737. (<a
href="https://doi.org/10.1609/aaai.v37i13.26867">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Increasing global food demand, accompanied by the limited number of expert growers, brings the need for more sustainable and efficient horticulture. The controlled environment of greenhouses enable data collection and precise control. For optimally controlling the greenhouse climate, a grower not only looks at crop production, but rather aims at maximising the profit. However this is a complex, long term optimisation task. In this paper, Constraint Programming (CP) is applied to task of optimal greenhouse economic control, by leveraging a learned greenhouse climate model through a CP embedding. In collaboration with an industrial partner, we demonstrate how to model the greenhouse climate with an LSTM model, embed this LSTM into a CP optimisation framework, and optimise the expected profit of the grower. This data-to-decision pipeline is being integrated into a decision support system for multiple greenhouses in the Netherlands.},
  archive   = {C_AAAI},
  author    = {Dirk van Bokkem and Max van den Hemel and Sebastijan Dumančić and Neil Yorke-Smith},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26867},
  pages     = {15731-15737},
  title     = {Embedding a long short-term memory network in a constraint programming framework for tomato greenhouse optimisation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reward design for an online reinforcement learning algorithm
supporting oral self-care. <em>AAAI</em>, 15724–15730. (<a
href="https://doi.org/10.1609/aaai.v37i13.26866">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {While dental disease is largely preventable, professional advice on optimal oral hygiene practices is often forgotten or abandoned by patients. Therefore patients may benefit from timely and personalized encouragement to engage in oral self-care behaviors. In this paper, we develop an online reinforcement learning (RL) algorithm for use in optimizing the delivery of mobile-based prompts to encourage oral hygiene behaviors. One of the main challenges in developing such an algorithm is ensuring that the algorithm considers the impact of current actions on the effectiveness of future actions (i.e., delayed effects), especially when the algorithm has been designed to run stably and autonomously in a constrained, real-world setting characterized by highly noisy, sparse data. We address this challenge by designing a quality reward that maximizes the desired health outcome (i.e., high-quality brushing) while minimizing user burden. We also highlight a procedure for optimizing the hyperparameters of the reward by building a simulation environment test bed and evaluating candidates using the test bed. The RL algorithm discussed in this paper will be deployed in Oralytics. To the best of our knowledge, Oralytics is the first mobile health study utilizing an RL algorithm designed to prevent dental disease by optimizing the delivery of motivational messages supporting oral self-care behaviors.},
  archive   = {C_AAAI},
  author    = {Anna L. Trella and Kelly W. Zhang and Inbal Nahum-Shani and Vivek Shetty and Finale Doshi-Velez and Susan A. Murphy},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26866},
  pages     = {15724-15730},
  title     = {Reward design for an online reinforcement learning algorithm supporting oral self-care},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Grape cold hardiness prediction via multi-task learning.
<em>AAAI</em>, 15717–15723. (<a
href="https://doi.org/10.1609/aaai.v37i13.26865">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Cold temperatures during fall and spring have the potential to cause frost damage to grapevines and other fruit plants, which can significantly decrease harvest yields. To help prevent these losses, farmers deploy expensive frost mitigation measures, such as, sprinklers, heaters, and wind machines, when they judge that damage may occur. This judgment, however, is challenging because the cold hardiness of plants changes throughout the dormancy period and it is difficult to directly measure. This has led scientists to develop cold hardiness prediction models that can be tuned to different grape cultivars based on laborious field measurement data. In this paper, we study whether deep-learning models can improve cold hardiness prediction for grapes based on data that has been collected over a 30-year time period. A key challenge is that the amount of data per cultivar is highly variable, with some cultivars having only a small amount. For this purpose, we investigate the use of multi-task learning to leverage data across cultivars in order to improve prediction performance for individual cultivars. We evaluate a number of multi-task learning approaches and show that the highest performing approach is able to significantly improve over learning for single cultivars and outperforms the current state-of-the-art scientific model for most cultivars.},
  archive   = {C_AAAI},
  author    = {Aseem Saxena and Paola Pesantez-Cabrera and Rohan Ballapragada and Kin-Ho Lam and Markus Keller and Alan Fern},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26865},
  pages     = {15717-15723},
  title     = {Grape cold hardiness prediction via multi-task learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AnimateSVG: Autonomous creation and aesthetics evaluation of
scalable vector graphics animations for the case of brand logos.
<em>AAAI</em>, 15710–15716. (<a
href="https://doi.org/10.1609/aaai.v37i13.26864">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the light of the constant battle for attention on digital media, animating digital content plays an increasing role in modern graphic design. In this study, we use artificial intelligence methods to create aesthetic animations along the case of brand logos. With scalable vector graphics as the standard format in modern graphic design, we develop an autonomous end-to-end method using complex machine learning techniques to create brand logo animations as scalable vector graphics from scratch. We acquire data and setup a comprehensive animation space to create novel animations and evaluate them based on their aesthetics. We propose and compare two alternative computational models for automated logo animation and carefully weigh up their idiosyncrasies: on the one hand, we set up an aesthetics evaluation model to train an animation generator and, on the other hand, we combine tree ensembles with global optimization. Indeed, our proposed methods are capable of creating aesthetic logo animations, receiving an average rating of ‘good’ from observers.},
  archive   = {C_AAAI},
  author    = {Deborah Mateja and Rebecca Armbruster and Jonathan Baumert and Tim Bleil and Jakob Langenbahn and Jan Christian Schwedhelm and Sarah Sester and Armin Heinzl},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26864},
  pages     = {15710-15716},
  title     = {AnimateSVG: Autonomous creation and aesthetics evaluation of scalable vector graphics animations for the case of brand logos},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data-driven machine learning models for a multi-objective
flapping fin unmanned underwater vehicle control system. <em>AAAI</em>,
15703–15709. (<a
href="https://doi.org/10.1609/aaai.v37i13.26863">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Flapping-fin unmanned underwater vehicle (UUV) propulsion systems provide high maneuverability for naval tasks such as surveillance and terrain exploration. Recent work has explored the use of time-series neural network surrogate models to predict thrust from vehicle design and fin kinematics. We develop a search-based inverse model that leverages a kinematics-to-thrust neural network model for control system design. Our inverse model finds a set of fin kinematics with the multi-objective goal of reaching a target thrust and creating a smooth kinematic transition between flapping cycles. We demonstrate how a control system integrating this inverse model can make online, cycle-to-cycle adjustments to prioritize different system objectives.},
  archive   = {C_AAAI},
  author    = {Julian Lee and Kamal Viswanath and Alisha Sharma and Jason Geder and Marius Pruessner and Brian Zhou},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26863},
  pages     = {15703-15709},
  title     = {Data-driven machine learning models for a multi-objective flapping fin unmanned underwater vehicle control system},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards safe mechanical ventilation treatment using deep
offline reinforcement learning. <em>AAAI</em>, 15696–15702. (<a
href="https://doi.org/10.1609/aaai.v37i13.26862">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Mechanical ventilation is a key form of life support for patients with pulmonary impairment. Healthcare workers are required to continuously adjust ventilator settings for each patient, a challenging and time consuming task. Hence, it would be beneficial to develop an automated decision support tool to optimize ventilation treatment. We present DeepVent, a Conservative Q-Learning (CQL) based offline Deep Reinforcement Learning (DRL) agent that learns to predict the optimal ventilator parameters for a patient to promote 90 day survival. We design a clinically relevant intermediate reward that encourages continuous improvement of the patient vitals as well as addresses the challenge of sparse reward in RL. We find that DeepVent recommends ventilation parameters within safe ranges, as outlined in recent clinical trials. The CQL algorithm offers additional safety by mitigating the overestimation of the value estimates of out-of-distribution states/actions. We evaluate our agent using Fitted Q Evaluation (FQE) and demonstrate that it outperforms physicians from the MIMIC-III dataset.},
  archive   = {C_AAAI},
  author    = {Flemming Kondrup and Thomas Jiralerspong and Elaine Lau and Nathan de Lara and Jacob Shkrob and My Duc Tran and Doina Precup and Sumana Basu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26862},
  pages     = {15696-15702},
  title     = {Towards safe mechanical ventilation treatment using deep offline reinforcement learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Intuitive access to smartphone settings using relevance
model trained by contrastive learning. <em>AAAI</em>, 15689–15695. (<a
href="https://doi.org/10.1609/aaai.v37i13.26861">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The more new features that are being added to smartphones, the harder it becomes for users to find them. This is because the feature names are usually short and there are just too many of them for the users to remember the exact words. The users are more comfortable asking contextual queries that describe the features they are looking for, but the standard term frequency-based search cannot process them. This paper presents a novel retrieval system for mobile features that accepts intuitive and contextual search queries. We trained a relevance model via contrastive learning from a pre-trained language model to perceive the contextual relevance between a query embedding and indexed mobile features. Also, to make it efficiently run on-device using minimal resources, we applied knowledge distillation to compress the model without degrading much performance. To verify the feasibility of our method, we collected test queries and conducted comparative experiments with the currently deployed search baselines. The results show that our system outperforms the others on contextual sentence queries and even on usual keyword-based queries.},
  archive   = {C_AAAI},
  author    = {Joonyoung Kim and Kangwook Lee and Haebin Shin and Hurnjoo Lee and Sechun Kang and Byunguk Choi and Dong Shin and Joohyung Lee},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26861},
  pages     = {15689-15695},
  title     = {Intuitive access to smartphone settings using relevance model trained by contrastive learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Vessel-to-vessel motion compensation with reinforcement
learning. <em>AAAI</em>, 15682–15688. (<a
href="https://doi.org/10.1609/aaai.v37i13.26860">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Actuation delay poses a challenge for robotic arms and cranes. This is especially the case in dynamic environments where the robot arm or the objects it is trying to manipulate are moved by exogenous forces. In this paper, we consider the task of using a robotic arm to compensate for relative motion between two vessels at sea. We construct a hybrid controller that combines an Inverse Kinematic (IK) solver with a Reinforcement Learning (RL) agent that issues small corrections to the IK input. The solution is empirically evaluated in a simulated environment under several sea states and actuation delays. We observe that more intense waves and larger actuation delays have an adverse effect on the IK controller&#39;s ability to compensate for vessel motion. The RL agent is shown to be effective at mitigating large parts of these errors, both in the average case and in the worst case. Its modest requirement for sensory information, combined with the inherent safety in only making small adjustments, also makes it a promising approach for real-world deployment.},
  archive   = {C_AAAI},
  author    = {Sverre Herland and Kerstin Bach},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26860},
  pages     = {15682-15688},
  title     = {Vessel-to-vessel motion compensation with reinforcement learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MobilePTX: Sparse coding for pneumothorax detection given
limited training examples. <em>AAAI</em>, 15675–15681. (<a
href="https://doi.org/10.1609/aaai.v37i13.26859">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Point-of-Care Ultrasound (POCUS) refers to clinician-performed and interpreted ultrasonography at the patient&#39;s bedside. Interpreting these images requires a high level of expertise, which may not be available during emergencies. In this paper, we support POCUS by developing classifiers that can aid medical professionals by diagnosing whether or not a patient has pneumothorax. We decomposed the task into multiple steps, using YOLOv4 to extract relevant regions of the video and a 3D sparse coding model to represent video features. Given the difficulty in acquiring positive training videos, we trained a small-data classifier with a maximum of 15 positive and 32 negative examples. To counteract this limitation, we leveraged subject matter expert (SME) knowledge to limit the hypothesis space, thus reducing the cost of data collection. We present results using two lung ultrasound datasets and demonstrate that our model is capable of achieving performance on par with SMEs in pneumothorax identification. We then developed an iOS application that runs our full system in less than 4 seconds on an iPad Pro, and less than 8 seconds on an iPhone 13 Pro, labeling key regions in the lung sonogram to provide interpretable diagnoses.},
  archive   = {C_AAAI},
  author    = {Darryl Hannan and Steven C. Nesbit and Ximing Wen and Glen Smith and Qiao Zhang and Alberto Goffi and Vincent Chan and Michael J. Morris and John C. Hunninghake and Nicholas E. Villalobos and Edward Kim and Rosina O. Weber and Christopher J. MacLellan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26859},
  pages     = {15675-15681},
  title     = {MobilePTX: Sparse coding for pneumothorax detection given limited training examples},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SolderNet: Towards trustworthy visual inspection of solder
joints in electronics manufacturing using explainable artificial
intelligence. <em>AAAI</em>, 15668–15674. (<a
href="https://doi.org/10.1609/aaai.v37i13.26858">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In electronics manufacturing, solder joint defects are a common problem affecting a variety of printed circuit board components. To identify and correct solder joint defects, the solder joints on a circuit board are typically inspected manually by trained human inspectors, which is a very time-consuming and error-prone process. To improve both inspection efficiency and accuracy, in this work we describe an explainable deep learning-based visual quality inspection system tailored for visual inspection of solder joints in electronics manufacturing environments. At the core of this system is an explainable solder joint defect identification system called SolderNet which we design and implement with trust and transparency in mind. While several challenges remain before the full system can be developed and deployed, this study presents important progress towards trustworthy visual inspection of solder joints in electronics manufacturing.},
  archive   = {C_AAAI},
  author    = {Hayden Gunraj and Paul Guerrier and Sheldon Fernandez and Alexander Wong},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26858},
  pages     = {15668-15674},
  title     = {SolderNet: Towards trustworthy visual inspection of solder joints in electronics manufacturing using explainable artificial intelligence},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Compressing cross-lingual multi-task models at qualtrics.
<em>AAAI</em>, 15661–15667. (<a
href="https://doi.org/10.1609/aaai.v37i13.26857">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Experience management is an emerging business area where organizations focus on understanding the feedback of customers and employees in order to improve their end-to-end experiences. This results in a unique set of machine learning problems to help understand how people feel, discover issues they care about, and find which actions need to be taken on data that are different in content and distribution from traditional NLP domains. In this paper, we present a case study of building text analysis applications that perform multiple classification tasks efficiently in 12 languages in the nascent business area of experience management. In order to scale up modern ML methods on experience data, we leverage cross lingual and multi-task modeling techniques to consolidate our models into a single deployment to avoid overhead. We also make use of model compression and model distillation to reduce overall inference latency and hardware cost to the level acceptable for business needs while maintaining model prediction quality. Our findings show that multi-task modeling improves task performance for a subset of experience management tasks in both XLM-R and mBert architectures. Among the compressed architectures we explored, we found that MiniLM achieved the best compression/performance tradeoff. Our case study demonstrates a speedup of up to 15.61x with 2.60\% average task degradation (or 3.29x speedup with 1.71\% degradation) and estimated savings of 44\% over using the original full-size model. These results demonstrate a successful scaling up of text classification for the challenging new area of ML for experience management.},
  archive   = {C_AAAI},
  author    = {Daniel Campos and Daniel Perry and Samir Joshi and Yashmeet Gambhir and Wei Du and Zhengzheng Xing and Aaron Colak},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26857},
  pages     = {15661-15667},
  title     = {Compressing cross-lingual multi-task models at qualtrics},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards hybrid automation by bootstrapping conversational
interfaces for IT operation tasks. <em>AAAI</em>, 15654–15660. (<a
href="https://doi.org/10.1609/aaai.v37i13.26856">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Process automation has evolved from end-to-end automation of repetitive process branches to hybrid automation where bots perform some activities and humans serve other activities. In the context of knowledge-intensive processes such as IT operations, implementing hybrid automation is a natural choice where robots can perform certain mundane functions, with humans taking over the decision of when and which IT systems need to act. Recently, ChatOps, which refers to conversation-driven collaboration for IT operations, has rapidly accelerated efficiency by providing a cross-organization and cross-domain platform to resolve and manage issues as soon as possible. Hence, providing a natural language interface to bots is a logical progression to enable collaboration between humans and bots. This work presents a no-code approach to provide a conversational interface that enables human workers to collaborate with bots executing automation scripts. The bots identify the intent of users&#39; requests and automatically orchestrate one or more relevant automation tasks to serve the request. We further detail our process of mining the conversations between humans and bots to monitor performance and identify the scope for improvement in service quality.},
  archive   = {C_AAAI},
  author    = {Jayachandu Bandlamudi and Kushal Mukherjee and Prerna Agarwal and Sampath Dechu and Siyu Huo and Vatche Isahagian and Vinod Muthusamy and Naveen Purushothaman and Renuka Sindhgatta},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26856},
  pages     = {15654-15660},
  title     = {Towards hybrid automation by bootstrapping conversational interfaces for IT operation tasks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Phase-informed bayesian ensemble models improve performance
of COVID-19 forecasts. <em>AAAI</em>, 15647–15653. (<a
href="https://doi.org/10.1609/aaai.v37i13.26855">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Despite hundreds of methods published in the literature, forecasting epidemic dynamics remains challenging yet important. The challenges stem from multiple sources, including: the need for timely data, co-evolution of epidemic dynamics with behavioral and immunological adaptations, and the evolution of new pathogen strains. The ongoing COVID-19 pandemic highlighted these challenges; in an important article, Reich et al. did a comprehensive analysis highlighting many of these challenges. In this paper, we take another step in critically evaluating existing epidemic forecasting methods. Our methods are based on a simple yet crucial observation - epidemic dynamics go through a number of phases (waves). Armed with this understanding, we propose a modification to our deployed Bayesian ensembling case time series forecasting framework. We show that ensembling methods employing the phase information and using different weighting schemes for each phase can produce improved forecasts. We evaluate our proposed method with both the currently deployed model and the COVID-19 forecasthub models. The overall performance of the proposed model is consistent across the pandemic but more importantly, it is ranked third and first during two critical rapid growth phases in cases, regimes where the performance of most models from the CDC forecasting hub dropped significantly.},
  archive   = {C_AAAI},
  author    = {Aniruddha Adiga and Gursharn Kaur and Lijing Wang and Benjamin Hurt and Przemyslaw Porebski and Srinivasan Venkatramanan and Bryan Lewis and Madhav V. Marathe},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26855},
  pages     = {15647-15653},
  title     = {Phase-informed bayesian ensemble models improve performance of COVID-19 forecasts},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cosmic microwave background recovery: A graph-based bayesian
convolutional network approach. <em>AAAI</em>, 15640–15646. (<a
href="https://doi.org/10.1609/aaai.v37i13.26854">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The cosmic microwave background (CMB) is a significant source of knowledge about the origin and evolution of our universe. However, observations of the CMB are contaminated by foreground emissions, obscuring the CMB signal and reducing its efficacy in constraining cosmological parameters. We employ deep learning as a data-driven approach to CMB cleaning from multi-frequency full-sky maps. In particular, we develop a graph-based Bayesian convolutional neural network based on the U-Net architecture that predicts cleaned CMB with pixel-wise uncertainty estimates. We demonstrate the potential of this technique on realistic simulated data based on the Planck mission. We show that our model ac- accurately recovers the cleaned CMB sky map and resulting angular power spectrum while identifying regions of uncertainty. Finally, we discuss the current challenges and the path forward for deploying our model for CMB recovery on real observations.},
  archive   = {C_AAAI},
  author    = {Jadie Adams and Steven Lu and Krzysztof M. Gorski and Graca Rocha and Kiri L. Wagstaff},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26854},
  pages     = {15640-15646},
  title     = {Cosmic microwave background recovery: A graph-based bayesian convolutional network approach},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). EForecaster: Unifying electricity forecasting with robust,
flexible, and explainable machine learning algorithms. <em>AAAI</em>,
15630–15638. (<a
href="https://doi.org/10.1609/aaai.v37i13.26853">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Electricity forecasting is crucial in scheduling and planning of future electric load, so as to improve the reliability and safeness of the power grid. Despite recent developments of forecasting algorithms in the machine learning community, there is a lack of general and advanced algorithms specifically considering requirements from the power industry perspective. In this paper, we present eForecaster, a unified AI platform including robust, flexible, and explainable machine learning algorithms for diversified electricity forecasting applications. Since Oct. 2021, multiple commercial bus load, system load, and renewable energy forecasting systems built upon eForecaster have been deployed in seven provinces of China. The deployed systems consistently reduce the average Mean Absolute Error (MAE) by 39.8\% to 77.0\%, with reduced manual work and explainable guidance. In particular, eForecaster also integrates multiple interpretation methods to uncover the working mechanism of the predictive models, which significantly improves forecasts adoption and user satisfaction.},
  archive   = {C_AAAI},
  author    = {Zhaoyang Zhu and Weiqi Chen and Rui Xia and Tian Zhou and Peisong Niu and Bingqing Peng and Wenwei Wang and Hengbo Liu and Ziqing Ma and Qingsong Wen and Liang Sun},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26853},
  pages     = {15630-15638},
  title     = {EForecaster: Unifying electricity forecasting with robust, flexible, and explainable machine learning algorithms},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AHPA: Adaptive horizontal pod autoscaling systems on alibaba
cloud container service for kubernetes. <em>AAAI</em>, 15621–15629. (<a
href="https://doi.org/10.1609/aaai.v37i13.26852">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The existing resource allocation policy for application instances in Kubernetes cannot dynamically adjust according to the requirement of business, which would cause an enormous waste of resources during fluctuations. Moreover, the emergence of new cloud services puts higher resource management requirements. This paper discusses horizontal POD resources management in Alibaba Cloud Container Services with a newly deployed AI algorithm framework named AHPA - the adaptive horizontal pod auto-scaling system. Based on a robust decomposition forecasting algorithm and performance training model, AHPA offers an optimal pod number adjustment plan that could reduce POD resources and maintain business stability. Since being deployed in April 2021, this system has expanded to multiple customer scenarios, including logistics, social networks, AI audio and video, e-commerce, etc. Compared with the previous algorithms, AHPA solves the elastic lag problem, increasing CPU usage by 10\% and reducing resource cost by more than 20\%. In addition, AHPA can automatically perform flexible planning according to the predicted business volume without manual intervention, significantly saving operation and maintenance costs.},
  archive   = {C_AAAI},
  author    = {Zhiqiang Zhou and Chaoli Zhang and Lingna Ma and Jing Gu and Huajie Qian and Qingsong Wen and Liang Sun and Peng Li and Zhimin Tang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26852},
  pages     = {15621-15629},
  title     = {AHPA: Adaptive horizontal pod autoscaling systems on alibaba cloud container service for kubernetes},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). OPRADI: Applying security game to fight drive under the
influence in real-world. <em>AAAI</em>, 15612–15620. (<a
href="https://doi.org/10.1609/aaai.v37i13.26851">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Driving under the influence (DUI) is one of the main causes of traffic accidents, often leading to severe life and property losses. Setting up sobriety checkpoints on certain roads is the most commonly used practice to identify DUI-drivers in many countries worldwide. However, setting up checkpoints according to the police&#39;s experiences may not be effective for ignoring the strategic interactions between the police and DUI-drivers, particularly when inspecting resources are limited. To remedy this situation, we adapt the classic Stackelberg security game (SSG) to a new SSG-DUI game to describe the strategic interactions in catching DUI-drivers. SSG-DUI features drivers&#39; bounded rationality and social knowledge sharing among them, thus realizing improved real-world fidelity. With SSG-DUI, we propose OPRADI, a systematic approach for advising better strategies in setting up checkpoints. We perform extensive experiments to evaluate it in both simulated environments and real-world contexts, in collaborating with a Chinese city&#39;s police bureau. The results reveal its effectiveness in improving police&#39;s real-world operations, thus having significant practical potentials.},
  archive   = {C_AAAI},
  author    = {Luzhan Yuan and Wei Wang and Gaowei Zhang and Yi Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26851},
  pages     = {15612-15620},
  title     = {OPRADI: Applying security game to fight drive under the influence in real-world},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MuMIC – multimodal embedding for multi-label image
classification with tempered sigmoid. <em>AAAI</em>, 15603–15611. (<a
href="https://doi.org/10.1609/aaai.v37i13.26850">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-label image classification is a foundational topic in various domains. Multimodal learning approaches have recently achieved outstanding results in image representation and single-label image classification. For instance, Contrastive Language-Image Pretraining (CLIP) demonstrates impressive image-text representation learning abilities and is robust to natural distribution shifts. This success inspires us to leverage multimodal learning for multi-label classification tasks, and benefit from contrastively learnt pretrained models. We propose the Multimodal Multi-label Image Classification (MuMIC) framework, which utilizes a hardness-aware tempered sigmoid based Binary Cross Entropy loss function, thus enables the optimization on multi-label objectives and transfer learning on CLIP. MuMIC is capable of providing high classification performance, handling real-world noisy data, supporting zero-shot predictions, and producing domain-specific image embeddings. In this study, a total of 120 image classes are defined, and more than 140K positive annotations are collected on approximately 60K Booking.com images. The final MuMIC model is deployed on Booking.com Content Intelligence Platform, and it outperforms other state-of-the-art models with 85.6\% GAP@10 and 83.8\% GAP on all 120 classes, as well as a 90.1\% macro mAP score across 32 majority classes. We summarize the modelling choices which are extensively tested through ablation studies. To the best of our knowledge, we are the first to adapt contrastively learnt multimodal pretraining for real-world multi-label image classification problems, and the innovation can be transferred to other domains.},
  archive   = {C_AAAI},
  author    = {Fengjun Wang and Sarai Mizrachi and Moran Beladev and Guy Nadav and Gil Amsalem and Karen Lastmann Assaraf and Hadas Harush Boker},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26850},
  pages     = {15603-15611},
  title     = {MuMIC – multimodal embedding for multi-label image classification with tempered sigmoid},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Increasing impact of mobile health programs: SAHELI for
maternal and child care. <em>AAAI</em>, 15594–15602. (<a
href="https://doi.org/10.1609/aaai.v37i13.26849">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Underserved communities face critical health challenges due to lack of access to timely and reliable information. Nongovernmental organizations are leveraging the widespread use of cellphones to combat these healthcare challenges and spread preventative awareness. The health workers at these organizations reach out individually to beneficiaries; however such programs still suffer from declining engagement. We have deployed SAHELI, a system to efficiently utilize the limited availability of health workers for improving maternal and child health in India. SAHELI uses the Restless Multiarmed Bandit (RMAB) framework to identify beneficiaries for outreach. It is the first deployed application for RMABs in public health, and is already in continuous use by our partner NGO, ARMMAN. We have already reached ~100K beneficiaries with SAHELI, and are on track to serve 1 million beneficiaries by the end of 2023. This scale and impact has been achieved through multiple innovations in the RMAB model and its development, in preparation of real world data, and in deployment practices; and through careful consideration of responsible AI practices. Specifically, in this paper, we describe our approach to learn from past data to improve the performance of SAHELI’s RMAB model, the real-world challenges faced during deployment and adoption of SAHELI, and the end-to-end pipeline.},
  archive   = {C_AAAI},
  author    = {Shresth Verma and Gargi Singh and Aditya Mate and Paritosh Verma and Sruthi Gorantla and Neha Madhiwalla and Aparna Hegde and Divy Thakkar and Manish Jain and Milind Tambe and Aparna Taneja},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26849},
  pages     = {15594-15602},
  title     = {Increasing impact of mobile health programs: SAHELI for maternal and child care},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). THMA: Tencent HD map AI system for creating HD map
annotations. <em>AAAI</em>, 15585–15593. (<a
href="https://doi.org/10.1609/aaai.v37i13.26848">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Nowadays, autonomous vehicle technology is becoming more and more mature. Critical to progress and safety, high-definition (HD) maps, a type of centimeter-level map collected using a laser sensor, provide accurate descriptions of the surrounding environment. The key challenge of HD map production is efficient, high-quality collection and annotation of large-volume datasets. Due to the demand for high quality, HD map production requires significant manual human effort to create annotations, a very time-consuming and costly process for the map industry. In order to reduce manual annotation burdens, many artificial intelligence (AI) algorithms have been developed to pre-label the HD maps. However, there still exists a large gap between AI algorithms and the traditional manual HD map production pipelines in accuracy and robustness. Furthermore, it is also very resource-costly to build large-scale annotated datasets and advanced machine learning algorithms for AI-based HD map automatic labeling systems. In this paper, we introduce the Tencent HD Map AI (THMA) system, an innovative end-to-end, AI-based, active learning HD map labeling system capable of producing and labeling HD maps with a scale of hundreds of thousands of kilometers. In THMA, we train AI models directly from massive HD map datasets via supervised, self-supervised, and weakly supervised learning to achieve high accuracy and efficiency required by downstream users. THMA has been deployed by the Tencent Map team to provide services to downstream companies and users, serving over 1,000 labeling workers and producing more than 30,000 kilometers of HD map data per day at most. More than 90 percent of the HD map data in Tencent Map is labeled automatically by THMA, accelerating the traditional HD map labeling process by more than ten times.},
  archive   = {C_AAAI},
  author    = {Kun Tang and Xu Cao and Zhipeng Cao and Tong Zhou and Erlong Li and Ao Liu and Shengtao Zou and Chang Liu and Shuqi Mei and Elena Sizikova and Chao Zheng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26848},
  pages     = {15585-15593},
  title     = {THMA: Tencent HD map AI system for creating HD map annotations},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Industry-scale orchestrated federated learning for drug
discovery. <em>AAAI</em>, 15576–15584. (<a
href="https://doi.org/10.1609/aaai.v37i13.26847">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {To apply federated learning to drug discovery we developed a novel platform in the context of European Innovative Medicines Initiative (IMI) project MELLODDY (grant n°831472), which was comprised of 10 pharmaceutical companies, academic research labs, large industrial companies and startups. The MELLODDY platform was the first industry-scale platform to enable the creation of a global federated model for drug discovery without sharing the confidential data sets of the individual partners. The federated model was trained on the platform by aggregating the gradients of all contributing partners in a cryptographic, secure way following each training iteration. The platform was deployed on an Amazon Web Services (AWS) multi-account architecture running Kubernetes clusters in private subnets. Organisationally, the roles of the different partners were codified as different rights and permissions on the platform and administrated in a decentralized way. The MELLODDY platform generated new scientific discoveries which are described in a companion paper.},
  archive   = {C_AAAI},
  author    = {Martijn Oldenhof and Gergely Ács and Balázs Pejó and Ansgar Schuffenhauer and Nicholas Holway and Noé Sturm and Arne Dieckmann and Oliver Fortmeier and Eric Boniface and Clément Mayer and Arnaud Gohier and Peter Schmidtke and Ritsuya Niwayama and Dieter Kopecky and Lewis Mervin and Prakash Chandra Rathi and Lukas Friedrich and András Formanek and Peter Antal and Jordon Rahaman and Adam Zalewski and Wouter Heyndrickx and Ezron Oluoch and Manuel Stößel and Michal Vančo and David Endico and Fabien Gelus and Thaïs de Boisfossé and Adrien Darbier and Ashley Nicollet and Matthieu Blottière and Maria Telenczuk and Van Tien Nguyen and Thibaud Martinez and Camille Boillet and Kelvin Moutet and Alexandre Picosson and Aurélien Gasser and Inal Djafar and Antoine Simon and Ádám Arany and Jaak Simm and Yves Moreau and Ola Engkvist and Hugo Ceulemans and Camille Marini and Mathieu Galtier},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26847},
  pages     = {15576-15584},
  title     = {Industry-scale orchestrated federated learning for drug discovery},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An explainable forecasting system for humanitarian needs
assessment. <em>AAAI</em>, 15569–15575. (<a
href="https://doi.org/10.1609/aaai.v37i13.26846">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present a machine learning system for forecasting forced displacement populations deployed at the Danish Refugee Council (DRC). The system, named Foresight, supports long term forecasts aimed at humanitarian response planning. It is explainable, providing evidence and context supporting the forecast. Additionally, it supports scenarios, whereby analysts are able to generate forecasts under alternative conditions. The system has been in deployment since early 2020 and powers several downstream business functions within DRC. It is central to our annual Global Displacement Report which informs our response planning. We describe the system, key outcomes, lessons learnt, along with technical limitations and challenges in deploying machine learning systems in the humanitarian sector.},
  archive   = {C_AAAI},
  author    = {Rahul Nair and Bo Madsen and Alexander Kjærum},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26846},
  pages     = {15569-15575},
  title     = {An explainable forecasting system for humanitarian needs assessment},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynamic pricing with volume discounts in online settings.
<em>AAAI</em>, 15560–15568. (<a
href="https://doi.org/10.1609/aaai.v37i13.26845">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {According to the main international reports, more pervasive industrial and business-process automation, thanks to machine learning and advanced analytic tools, will unlock more than 14 trillion USD worldwide annually by 2030. In the specific case of pricing problems, which constitute the class of problems we investigate in this paper, the estimated unlocked value will be about 0.5 trillion USD per year. In particular, this paper focuses on pricing in e-commerce when the objective function is profit maximization and only transaction data are available. This setting is one of the most common in real-world applications. Our work aims to find a pricing strategy that allows defining optimal prices at different volume thresholds to serve different classes of users. Furthermore, we face the major challenge, common in real-world settings, of dealing with limited data available. We design a two-phase online learning algorithm, namely PVD-B, capable of exploiting the data incrementally in an online fashion. The algorithm first estimates the demand curve and retrieves the optimal average price, and subsequently it offers discounts to differentiate the prices for each volume threshold. We ran a real-world 4-month-long A/B testing experiment in collaboration with an Italian e-commerce company, in which our algorithm PVD-B - corresponding to A configuration - has been compared with human pricing specialists - corresponding to B configuration. At the end of the experiment, our algorithm produced a total turnover of about 300 KEuros, outperforming the B configuration performance by about 55\%. The Italian company we collaborated with decided to adopt our algorithm for more than 1,200 products since January 2022.},
  archive   = {C_AAAI},
  author    = {Marco Mussi and Gianmarco Genalti and Alessandro Nuara and Francesco Trovó and Marcello Restelli and Nicola Gatti},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26845},
  pages     = {15560-15568},
  title     = {Dynamic pricing with volume discounts in online settings},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Real-time detection of robotic traffic in online
advertising. <em>AAAI</em>, 15551–15559. (<a
href="https://doi.org/10.1609/aaai.v37i13.26844">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Detecting robotic traffic at scale on online ads needs an approach that is scalable, comprehensive, precise, and can rapidly respond to changing traffic patterns. In this paper we describe SLIDR or SLIce-Level Detection of Robots, a real-time deep neural network model trained with weak supervision to identify invalid clicks on online ads. We ensure fairness across different traffic slices by formulating a convex optimization problem that allows SLIDR to achieve optimal performance on individual traffic slices with a budget on overall false positives. SLIDR has been deployed since 2021 and safeguards advertiser campaigns on Amazon against robots clicking on ads on the e-commerce site. We describe some of the important lessons learned by deploying SLIDR that include guardrails that prevent updates of anomalous models and disaster recovery mechanisms to mitigate or correct decisions made by a faulty model.},
  archive   = {C_AAAI},
  author    = {Anand Muralidhar and Sharad Chitlangia and Rajat Agarwal and Muneeb Ahmed},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26844},
  pages     = {15551-15559},
  title     = {Real-time detection of robotic traffic in online advertising},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A dataset and baseline approach for identifying usage states
from non-intrusive power sensing with MiDAS IoT-based sensors.
<em>AAAI</em>, 15545–15550. (<a
href="https://doi.org/10.1609/aaai.v37i13.26843">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The state identification problem seeks to identify power usage patterns of any system, like buildings or factories, of interest. In this challenge paper, we make power usage dataset available from 8 institutions in manufacturing, education and medical institutions from the US and India, and an initial unsupervised machine learning based solution as a baseline for the community to accelerate research in this area.},
  archive   = {C_AAAI},
  author    = {Bharath Muppasani and Cheyyur Jaya Anand and Chinmayi Appajigowda and Biplav Srivastava and Lokesh Johri},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26843},
  pages     = {15545-15550},
  title     = {A dataset and baseline approach for identifying usage states from non-intrusive power sensing with MiDAS IoT-based sensors},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Trustworthy residual vehicle value prediction for auto
finance. <em>AAAI</em>, 15537–15544. (<a
href="https://doi.org/10.1609/aaai.v37i13.26842">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The residual value (RV) of a vehicle refers to its estimated worth at some point in the future. It is a core component in every auto financial product, used to determine the credit lines and the leasing rates. As such, an accurate prediction of RV is critical for the auto finance industry, since it can pose a risk of revenue loss by over-prediction or make the financial product incompetent by under-prediction. Although there are a number of prior studies on training machine learning models on a large amount of used car sales data, we had to cope with real-world operational requirements such as compliance with regulations (i.e. monotonicity of output with respect to a subset of features) and generalization to unseen input (i.e. new and rare car models). In this paper, we describe how we coped with these practical challenges and created value for our business at Hyundai Capital Services, the top auto financial service provider in Korea.},
  archive   = {C_AAAI},
  author    = {Mihye Kim and Jimyung Choi and Jaehyun Kim and Wooyoung Kim and Yeonung Baek and Gisuk Bang and Kwangwoon Son and Yeonman Ryou and Kee-Eung Kim},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26842},
  pages     = {15537-15544},
  title     = {Trustworthy residual vehicle value prediction for auto finance},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). NewsPanda: Media monitoring for timely conservation action.
<em>AAAI</em>, 15528–15536. (<a
href="https://doi.org/10.1609/aaai.v37i13.26841">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Non-governmental organizations for environmental conservation have a significant interest in monitoring conservation-related media and getting timely updates about infrastructure construction projects as they may cause massive impact to key conservation areas. Such monitoring, however, is difficult and time-consuming. We introduce NewsPanda, a toolkit which automatically detects and analyzes online articles related to environmental conservation and infrastructure construction. We fine-tune a BERT-based model using active learning methods and noise correction algorithms to identify articles that are relevant to conservation and infrastructure construction. For the identified articles, we perform further analysis, extracting keywords and finding potentially related sources. NewsPanda has been successfully deployed by the World Wide Fund for Nature teams in the UK, India, and Nepal since February 2022. It currently monitors over 80,000 websites and 1,074 conservation sites across India and Nepal, saving more than 30 hours of human efforts weekly. We have now scaled it up to cover 60,000 conservation sites globally.},
  archive   = {C_AAAI},
  author    = {Sedrick Scott Keh and Zheyuan Ryan Shi and David J. Patterson and Nirmal Bhagabati and Karun Dewan and Areendran Gopala and Pablo Izquierdo and Debojyoti Mallick and Ambika Sharma and Pooja Shrestha and Fei Fang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26841},
  pages     = {15528-15536},
  title     = {NewsPanda: Media monitoring for timely conservation action},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Detecting VoIP data streams: Approaches using hidden
representation learning. <em>AAAI</em>, 15519–15527. (<a
href="https://doi.org/10.1609/aaai.v37i13.26840">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The use of voice-over-IP technology has rapidly expanded over the past several years, and has thus become a significant portion of traffic in the real, complex network environment. Deep packet inspection and middlebox technologies need to analyze call flows in order to perform network management, load-balancing, content monitoring, forensic analysis, and intelligence gathering. Because the session setup and management data can be sent on different ports or out of sync with VoIP call data over the Real-time Transport Protocol (RTP) with low latency, inspection software may miss calls or parts of calls. To solve this problem, we engineered two different deep learning models based on hidden representation learning. MAPLE, a matrix-based encoder which transforms packets into an image representation, uses convolutional neural networks to determine RTP packets from data flow. DATE is a density-analysis based tensor encoder which transforms packet data into a three-dimensional point cloud representation. We then perform density-based clustering over the point clouds as latent representations of the data, and classify packets as RTP or non-RTP based on their statistical clustering features. In this research, we show that these tools may allow a data collection and analysis pipeline to begin detecting and buffering RTP streams for later session association, solving the initial drop problem. MAPLE achieves over ninety-nine percent accuracy in RTP/non-RTP detection. The results of our experiments show that both models can not only classify RTP versus non-RTP packet streams, but could extend to other network traffic classification problems in real deployments of network analysis pipelines.},
  archive   = {C_AAAI},
  author    = {Maya Kapoor and Michael Napolitano and Jonathan Quance and Thomas Moyer and Siddharth Krishnan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26840},
  pages     = {15519-15527},
  title     = {Detecting VoIP data streams: Approaches using hidden representation learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Developing the wheel image similarity application with deep
metric learning: Hyundai motor company case. <em>AAAI</em>, 15512–15518.
(<a href="https://doi.org/10.1609/aaai.v37i13.26839">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The global automobile market experiences quick changes in design preferences. In response to the demand shifts, manufacturers now try to apply new technologies to bring a novel design to market faster. In this paper, we introduce a novel application that performs a similarity verification task of wheel designs using an AI model and cloud computing technology. At Jan 2022, we successfully implemented the application to the wheel design process of Hyundai Motor Company’s design team and shortened the similarity verification time by 90\% to a maximum of 10 minutes. We believe that this study is the first to build a wheel image database and empirically prove that the cross-entropy loss does similar tasks as the pairwise losses do in the embedding space. As a result, we successfully automated Hyundai Motor’s verification task of wheel design similarity. With a few clicks, the end-users in Hyundai Motor could take advantage of our application.},
  archive   = {C_AAAI},
  author    = {Kyung Pyo Kang and Ga Hyeon Jeong and Jeong Hoon Eom and Soon Beom Kwon and Jae Hong Park},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26839},
  pages     = {15512-15518},
  title     = {Developing the wheel image similarity application with deep metric learning: Hyundai motor company case},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A robust and scalable stacked ensemble for day-ahead
forecasting of distribution network losses. <em>AAAI</em>, 15503–15511.
(<a href="https://doi.org/10.1609/aaai.v37i13.26838">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Accurate day-ahead nominations of grid losses in electrical distribution networks are important to reduce the societal cost of these losses. We present a modification of the CatBoost ensemble-based system for day-ahead grid loss prediction detailed in Dalal et al. (2020), making four main changes. Base models predict on the log-space of the target, to ensure non-negative predictions. The model ensemble is changed to include different model types, for increased ensemble variance. Feature engineering is applied to consumption and weather forecasts, to improve base model performance. Finally, a non-negative least squares-based stacking method that uses as many available models as possible for each prediction is introduced, to achieve an improved model selection that is robust to missing data. When deployed for over three months in 2022, the resulting system reduced mean absolute error by 10.7\% compared to the system from Dalal et al. (2020), a reduction from 5.05 to 4.51 MW. With no tuning of machine learning parameters, the system was also extended to three new grids, where it achieved similar relative error as on the old grids. Our system is robust and easily scalable, and our proposed stacking method could provide improved performance in applications outside grid loss.},
  archive   = {C_AAAI},
  author    = {Gunnar Grotmol and Eivind Hovdegård Furdal and Nisha Dalal and Are Løkken Ottesen and Ella-Lovise Hammervold Rørvik and Martin Mølnå and Gleb Sizov and Odd Erik Gundersen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26838},
  pages     = {15503-15511},
  title     = {A robust and scalable stacked ensemble for day-ahead forecasting of distribution network losses},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AmnioML: Amniotic fluid segmentation and volume prediction
with uncertainty quantification. <em>AAAI</em>, 15494–15502. (<a
href="https://doi.org/10.1609/aaai.v37i13.26837">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Accurately predicting the volume of amniotic fluid is fundamental to assessing pregnancy risks, though the task usually requires many hours of laborious work by medical experts. In this paper, we present AmnioML, a machine learning solution that leverages deep learning and conformal prediction to output fast and accurate volume estimates and segmentation masks from fetal MRIs with Dice coefficient over 0.9. Also, we make available a novel, curated dataset for fetal MRIs with 853 exams and benchmark the performance of many recent deep learning architectures. In addition, we introduce a conformal prediction tool that yields narrow predictive intervals with theoretically guaranteed coverage, thus aiding doctors in detecting pregnancy risks and saving lives. A successful case study of AmnioML deployed in a medical setting is also reported. Real-world clinical benefits include up to 20x segmentation time reduction, with most segmentations deemed by doctors as not needing any further manual refinement. Furthermore, AmnioML&#39;s volume predictions were found to be highly accurate in practice, with mean absolute error below 56mL and tight predictive intervals, showcasing its impact in reducing pregnancy complications.},
  archive   = {C_AAAI},
  author    = {Daniel Csillag and Lucas Monteiro Paes and Thiago Ramos and João Vitor Romano and Rodrigo Schuller and Roberto B. Seixas and Roberto I. Oliveira and Paulo Orenstein},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26837},
  pages     = {15494-15502},
  title     = {AmnioML: Amniotic fluid segmentation and volume prediction with uncertainty quantification},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Efficient training of large-scale industrial fault
diagnostic models through federated opportunistic block dropout.
<em>AAAI</em>, 15485–15493. (<a
href="https://doi.org/10.1609/aaai.v37i13.26836">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Artificial intelligence (AI)-empowered industrial fault diagnostics is important in ensuring the safe operation of industrial applications. Since complex industrial systems often involve multiple industrial plants (possibly belonging to different companies or subsidiaries) with sensitive data collected and stored in a distributed manner, collaborative fault diagnostic model training often needs to leverage federated learning (FL). As the scale of the industrial fault diagnostic models are often large and communication channels in such systems are often not exclusively used for FL model training, existing deployed FL model training frameworks cannot train such models efficiently across multiple institutions. In this paper, we report our experience developing and deploying the Federated Opportunistic Block Dropout (FedOBD) approach for industrial fault diagnostic model training. By decomposing large-scale models into semantic blocks and enabling FL participants to opportunistically upload selected important blocks in a quantized manner, it significantly reduces the communication overhead while maintaining model performance. Since its deployment in ENN Group in February 2022, FedOBD has served two coal chemical plants across two cities in China to build industrial fault prediction models. It helped the company reduce the training communication overhead by over 70\% compared to its previous AI Engine, while maintaining model performance at over 85\% test F1 score. To our knowledge, it is the first successfully deployed dropout-based FL approach.},
  archive   = {C_AAAI},
  author    = {Yuanyuan Chen and Zichen Chen and Sheng Guo and Yansong Zhao and Zelei Liu and Pengcheng Wu and Chengyi Yang and Zengxiang Li and Han Yu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26836},
  pages     = {15485-15493},
  title     = {Efficient training of large-scale industrial fault diagnostic models through federated opportunistic block dropout},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Blending advertising with organic content in e-commerce via
virtual bids. <em>AAAI</em>, 15476–15484. (<a
href="https://doi.org/10.1609/aaai.v37i13.26835">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {It has become increasingly common that sponsored content (i.e., paid ads) and non-sponsored content are jointly displayed to users, especially on e-commerce platforms. Thus, both of these contents may interact together to influence their engagement behaviors. In general, sponsored content helps brands achieve their marketing goals and provides ad revenue to the platforms. In contrast, non-sponsored content contributes to the long-term health of the platform through increasing users&#39; engagement. A key conundrum to platforms is learning how to blend both of these contents allowing their interactions to be considered and balancing these business objectives. This paper proposes a system built for this purpose and applied to product detail pages of JD.COM, an e-commerce company. This system achieves three objectives: (a) Optimization of competing business objectives via Virtual Bids allowing the expressiveness of the valuation of the platform for these objectives. (b) Modeling the users&#39; click behaviors considering explicitly the influence exerted by the sponsored and non-sponsored content displayed alongside through a deep learning approach. (c) Consideration of a Vickrey-Clarke-Groves (VCG) Auction design compatible with the allocation of ads and its induced externalities. Experiments are presented demonstrating the performance of the proposed system. Moreover, our approach is fully deployed and serves all traffic through JD.COM&#39;s mobile application.},
  archive   = {C_AAAI},
  author    = {Carlos Carrion and Zenan Wang and Harikesh Nair and Xianghong Luo and Yulin Lei and Peiqin Gu and Xiliang Lin and Wenlong Chen and Junsheng Jin and Fanan Zhu and Changping Peng and Yongjun Bao and Zhangang Lin and Weipeng Yan and Jingping Shao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26835},
  pages     = {15476-15484},
  title     = {Blending advertising with organic content in E-commerce via virtual bids},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Accurate detection of weld seams for laser welding in
real-world manufacturing. <em>AAAI</em>, 15468–15475. (<a
href="https://doi.org/10.1609/aaai.v37i13.26834">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Welding is a fabrication process used to join or fuse two mechanical parts. Modern welding machines have automated lasers that follow a pre-defined weld seam path between the two parts to create a bond. Previous efforts have used simple computer vision edge detectors to automatically detect the weld seam edge on an image at the junction of two metals to be welded. However, these systems lack reliability and accuracy resulting in manual human verification of the detected edges. This paper presents a neural network architecture that automatically detects the weld seam edge between two metals with high accuracy. We augment this system with a pre-classifier that filters out anomalous workpieces (e.g., incorrect placement). Finally, we justify our design choices by evaluating against several existing deep network pipelines as well as proof through real-world use. We also describe in detail the process of deploying this system in a real-world shop floor including evaluation and monitoring. We make public a large, well-labeled laser seam dataset to perform deep learning-based edge detection in industrial settings.},
  archive   = {C_AAAI},
  author    = {Rabia Ali and Muhammad Sarmad and Jawad Tayyub and Alexander Vogel},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26834},
  pages     = {15468-15475},
  title     = {Accurate detection of weld seams for laser welding in real-world manufacturing},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Building compositional robot autonomy with modularity and
abstraction. <em>AAAI</em>, 15466. (<a
href="https://doi.org/10.1609/aaai.v37i13.26833">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper summarizes my research roadmap for building compositional robot autonomy with the principles of modularity and abstraction.},
  archive   = {C_AAAI},
  author    = {Yuke Zhu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26833},
  pages     = {15466},
  title     = {Building compositional robot autonomy with modularity and abstraction},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). A new challenge in policy evaluation. <em>AAAI</em>, 15465.
(<a href="https://doi.org/10.1609/aaai.v37i13.26832">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper proposes a new challenge in policy evaluation: to improve the online data efficiency of Monte Carlo methods via information extracted from offline data while maintaining the unbiasedness of Monte Carlo methods.},
  archive   = {C_AAAI},
  author    = {Shangtong Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26832},
  pages     = {15465},
  title     = {A new challenge in policy evaluation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Information transfer in multitask learning, data
augmentation, and beyond. <em>AAAI</em>, 15464. (<a
href="https://doi.org/10.1609/aaai.v37i13.26831">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A hallmark of human intelligence is that we continue to learn new information and then extrapolate the learned information onto new tasks and domains (see, e.g., Thrun and Pratt (1998)). While this is a fairly intuitive observation, formulating such ideas has proved to be a challenging research problem and continues to inspire new studies. Recently, there has been increasing interest in AI/ML about building models that generalize across tasks, even when they have some form of distribution shifts. How can we ground this research in a solid framework to develop principled methods for better practice? This talk will present my recent works addressing this research question. My talk will involve three parts: revisiting multitask learning from the lens of deep learning theory, designing principled methods for robust transfer, and algorithmic implications for data augmentation.},
  archive   = {C_AAAI},
  author    = {Hongyang R. Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26831},
  pages     = {15464},
  title     = {Information transfer in multitask learning, data augmentation, and beyond},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Towards societal impact of AI. <em>AAAI</em>, 15463. (<a
href="https://doi.org/10.1609/aaai.v37i13.26830">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Artificial intelligence (AI) and Machine Learning (ML) have shown great success in many areas such as computer vision, natural language processing, and knowledge discovery. However, AI research to deliver social benefits and impacts is less explored while imminent needed. Guided by the United Nations’ Sustainable Development Goals, my research involves the development of advanced AI techniques, in particular Deep Graph Learning (DGL), to address the grand societal challenges and further apply them to various social good applications for improving our society and people’s daily life, namely DGL for Social Good (DGL4SG). Achieving the goal is not easy since challenges come from the increasing complexity of many factors including problems, data, and techniques, which require long-term and concentrated effort. DGL presents a good opportunity to build better solutions and tools due to its strong capability in learning and inferring graph data which is ideal for modeling many real-world social good systems. Fortunately, I have been working on DGL with continued contributions and impacts since my graduate study. The special research experience lifts me up to a unique position for conducting research that intersects AI, DGL, and social good, and pushing the field of DGL4SG forward.},
  archive   = {C_AAAI},
  author    = {Chuxu Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26830},
  pages     = {15463},
  title     = {Towards societal impact of AI},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The analysis of deep neural networks by information theory:
From explainability to generalization. <em>AAAI</em>, 15462. (<a
href="https://doi.org/10.1609/aaai.v37i13.26829">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Despite their great success in many artificial intelligence tasks, deep neural networks (DNNs) still suffer from a few limitations, such as poor generalization behavior for out-of-distribution (OOD) data and the &quot;black-box&quot; nature. Information theory offers fresh insights to solve these challenges. In this short paper, we briefly review the recent developments in this area, and highlight our contributions.},
  archive   = {C_AAAI},
  author    = {Shujian Yu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26829},
  pages     = {15462},
  title     = {The analysis of deep neural networks by information theory: From explainability to generalization},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enhance robustness of machine learning with improved
efficiency. <em>AAAI</em>, 15461. (<a
href="https://doi.org/10.1609/aaai.v37i13.26828">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Robustness of machine learning, often referring to securing performance on different data, is always an active field due to the ubiquitous variety and diversity of data in practice. Many studies have been investigated to enhance the learning process robust in recent years. To this end, there is usually a trade-off that results in somewhat extra cost, e.g., more data samples, more complicated objective functions, more iterations to converge in optimization, etc. Then this problem boils down to finding a better trade-off under some conditions. My recent research focuses on robust machine learning with improved efficiency. Particularly, the efficiency here represents learning speed to find a model, and the number of data required to secure the robustness. In the talk, I will survey three pieces of my recent research by elaborating the algorithmic idea and theoretical analysis as technical contributions --- (i) epoch stochastic gradient descent ascent for min-max problems, (ii) stochastic optimization algorithm for non-convex inf-projection problems, and (iii) neighborhood conformal prediction. In the first two pieces of work, the proposed optimization algorithms are general and cover objective functions for robust machine learning. In the third one, I will elaborate an efficient conformal prediction algorithm that guarantee the robustness of prediction after model is trained. Particularly, the efficiency of conformal prediction is measured by its bandwidth.},
  archive   = {C_AAAI},
  author    = {Yan Yan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26828},
  pages     = {15461},
  title     = {Enhance robustness of machine learning with improved efficiency},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning to see the physical world. <em>AAAI</em>, 15460.
(<a href="https://doi.org/10.1609/aaai.v37i13.26827">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper is part of the AAAI-23 New Faculty Highlights. In my presentation, I will introduce my research goal, which is to build machines that see, interact with, and reason about the physical world just like humans. This problem, which we call physical scene understanding, involves three key topics that bridge research in computer science, AI, robotics, cognitive science, and neuroscience: Perception, Physical Interaction, and Reasoning.},
  archive   = {C_AAAI},
  author    = {Jiajun Wu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26827},
  pages     = {15460},
  title     = {Learning to see the physical world},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AI for equitable, data-driven decisions in public health.
<em>AAAI</em>, 15459. (<a
href="https://doi.org/10.1609/aaai.v37i13.26826">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As exemplified by the COVID-19 pandemic, our health and wellbeing depend on a difficult-to-measure web of societal factors and individual behaviors. This effort requires new algorithmic and data-driven paradigms which span the full process of gathering costly data, learning models to understand and predict such interactions, and optimizing the use of limited resources in interventions. In response to these needs, I present methodological developments at the intersection of machine learning, optimization, and social networks which are motivated by on-the-ground collaborations on HIV prevention, tuberculosis treatment, and the COVID-19 response. Here, I give an overview of two lines of work.},
  archive   = {C_AAAI},
  author    = {Bryan Wilder},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26826},
  pages     = {15459},
  title     = {AI for equitable, data-driven decisions in public health},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Artificial intelligence at the service of society to analyse
human arguments. <em>AAAI</em>, 15458. (<a
href="https://doi.org/10.1609/aaai.v37i13.26825">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Argument(ation) mining (AM) is an area of research in Artificial Intelligence (AI) that aims to identify, analyse and automatically generate arguments in natural language. In a pipeline, the identification and analysis of the arguments and their components (i.e. premises and claims) in texts and the prediction of their relations (i.e. attack and support) are then handled by argument-based reasoning frameworks so that, for example, fallacies and inconsistencies can be automatically identified. Recently, the field of argument mining has tackled new challenges, namely the evaluation of argument quality (e.g. strength, persuasiveness), natural language argument summarisation and retrieval, and natural language argument generation. In this paper, I discuss my main contributions in this area as well as some lines of future research. This paper is part of the AAAI-23 New Faculty Highlights.},
  archive   = {C_AAAI},
  author    = {Serena Villata},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26825},
  pages     = {15458},
  title     = {Artificial intelligence at the service of society to analyse human arguments},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reshaping state-space search: From dominance to contrastive
analysis. <em>AAAI</em>, 15457. (<a
href="https://doi.org/10.1609/aaai.v37i13.26824">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {State-space search is paramount for intelligent decision making when long-term thinking is needed. We introduce dominance and contrastive analysis methods, which enable reasoning about the relative advantages among different courses of action. This re-shapes how agents reason and leads to new families of state-space search algorithms.},
  archive   = {C_AAAI},
  author    = {Alvaro Torralba},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26824},
  pages     = {15457},
  title     = {Reshaping state-space search: From dominance to contrastive analysis},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards unified, explainable, and robust multisensory
perception. <em>AAAI</em>, 15456. (<a
href="https://doi.org/10.1609/aaai.v37i13.26823">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Humans perceive surrounding scenes through multiple senses with multisensory integration. For example, hearing helps capture the spatial location of a racing car behind us; seeing peoples&#39; talking faces can strengthen our perception of their speech. However, today&#39;s state-of-the-art scene understanding systems are usually designed to rely on a single audio or visual modality. Ignoring multisensory cooperation has become one of the key bottlenecks in creating intelligent systems with human-level perception capability, which impedes the real-world applications of existing scene understanding models. To address this limitation, my research has pioneered marrying computer vision with computer audition to create multimodal systems that can learn to understand audio and visual data. In particular, my current research focuses on asking and solving fundamental problems in a fresh research area: audio-visual scene understanding and strives to develop unified, explainable, and robust multisensory perception machines. The three themes are distinct yet interconnected, and all of them are essential for designing powerful and trustworthy perception systems. In my talk, I will give a brief overview about this new research area and then introduce my works in the three research thrusts.},
  archive   = {C_AAAI},
  author    = {Yapeng Tian},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26823},
  pages     = {15456},
  title     = {Towards unified, explainable, and robust multisensory perception},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Human-aware AI – a foundational framework for human-AI
interaction. <em>AAAI</em>, 15455. (<a
href="https://doi.org/10.1609/aaai.v37i13.26822">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We are living through a revolutionary moment in AI history. We are seeing the development of impressive new AI systems at a rate that was unimaginable just a few years ago. However, AI&#39;s true potential to transform society remains unrealized, in no small part due to the inability of current systems to work effectively with people. A major hurdle to achieving such coordination is the inherent asymmetry between the AI system and its users. In this talk, I will discuss how the framework of Human-Aware AI (HAAI) provides us with the tools required to bridge this gap and support fluent and intuitive coordination between the AI system and its users.},
  archive   = {C_AAAI},
  author    = {Sarath Sreedharan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26822},
  pages     = {15455},
  title     = {Human-aware AI – a foundational framework for human-AI interaction},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Combating disinformation on social media and its challenges:
A computational perspective. <em>AAAI</em>, 15454. (<a
href="https://doi.org/10.1609/aaai.v37i13.26821">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The use of social media has accelerated information sharing and instantaneous communications. The low barrier to entering social media enables more users to participate and keeps them engaged longer, incentivizing individuals with a hidden agenda to spread disinformation online to manipulate information and sway opinion. Disinformation, such as fake news, hoaxes, and conspiracy theories, has increasingly become a hindrance to the functioning of online social media as an effective channel for trustworthy information. Therefore, it is imperative to understand disinformation and systematically investigate how to improve resistance against it. This article highlights relevant theories and recent advancements of detecting disinformation from a computational perspective, and urges the need for future interdisciplinary research.},
  archive   = {C_AAAI},
  author    = {Kai Shu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26821},
  pages     = {15454},
  title     = {Combating disinformation on social media and its challenges: A computational perspective},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynamics of cooperation and conflict in multiagent systems.
<em>AAAI</em>, 15453. (<a
href="https://doi.org/10.1609/aaai.v37i13.26820">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Meeting today’s major scientific and societal challenges requires understanding the dynamics of cooperation, coordination, and conflict in complex adaptive systems (CAS). Artificial Intelligence (AI) is intimately connected with these challenges, both as an application domain and as a source of new computational techniques: On the one hand, AI suggests new algorithmic recommendations and interaction paradigms, offering novel possibilities to engineer cooperation and alleviate conflict in multiagent (hybrid) systems; on the other hand, new learning algorithms provide improved techniques to simulate sophisticated agents and increasingly realistic CAS. My research lies at the interface between CAS and AI: I develop computational methods to understand cooperation and conflict in multiagent systems, and how these depend on systems’ design and incentives. I focus on mapping interaction rules and incentives onto emerging macroscopic patterns and long-term dynamics. Examples of this research agenda, that I will survey in this talk, include modelling (1) the connection between reputation systems and cooperation dynamics, (2) the role of agents with hard-coded strategies in stabilizing fair behaviors in a population, or (3) the impact of recommendation algorithms on potential sources of conflict (e.g., radicalization and polarization) in a system composed of adaptive agents influencing each other over time.},
  archive   = {C_AAAI},
  author    = {Fernando P. Santos},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26820},
  pages     = {15453},
  title     = {Dynamics of cooperation and conflict in multiagent systems},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Planning and learning for reliable autonomy in the open
world. <em>AAAI</em>, 15452. (<a
href="https://doi.org/10.1609/aaai.v37i13.26819">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Safe and reliable decision-making is critical for long-term deployment of autonomous systems. Despite the recent advances in artificial intelligence, ensuring safe and reliable operation of human-aligned autonomous systems in open-world environments remains a challenge. My research focuses on developing planning and learning algorithms that support reliable autonomy in fully and partially observable environments, in the presence of uncertainty, limited information, and limited resources. This talk covers a summary of my recent research towards reliable autonomy.},
  archive   = {C_AAAI},
  author    = {Sandhya Saisubramanian},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26819},
  pages     = {15452},
  title     = {Planning and learning for reliable autonomy in the open world},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Internal robust representations for domain generalization.
<em>AAAI</em>, 15451. (<a
href="https://doi.org/10.1609/aaai.v37i13.26818">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Model generalization under distributional changes remains a significant challenge for machine learning. We present consolidating the internal representation of the training data in a model as a strategy of improving model generalization.},
  archive   = {C_AAAI},
  author    = {Mohammad Rostami},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26818},
  pages     = {15451},
  title     = {Internal robust representations for domain generalization},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Monitoring and intervening on large populations of weakly
coupled processes with social impact applications. <em>AAAI</em>, 15450.
(<a href="https://doi.org/10.1609/aaai.v37i13.26817">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Many real-world sequential decision problems can be decomposed into processes with independent dynamics that are coupled via the action structure. We discuss recent work on such problems and future directions.},
  archive   = {C_AAAI},
  author    = {Andrew Perrault},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26817},
  pages     = {15450},
  title     = {Monitoring and intervening on large populations of weakly coupled processes with social impact applications},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards safe and resilient autonomy in multi-robot systems.
<em>AAAI</em>, 15449. (<a
href="https://doi.org/10.1609/aaai.v37i13.26816">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the near future, autonomous systems such as multi-robot systems are envisioned to increasingly co-exist with hu- mans in our daily lives, from household service to large- scale warehouse logistics, agriculture environment sampling, and smart city. In these applications, robots and humans as networked heterogeneous components will frequently inter- act with each other in a variety of scenarios under uncer- tain, rapidly-changing, and possibly hostile environment. On one hand, harmonious interactions among robots, as well as between robots and humans, would require safe integration (e.g. collision-free close-proximity interactions) of heteroge- neous robots, human, and human-robot autonomy. On the other hand, reliable interactions among autonomous multi- robot systems often call for resilient system integrity (e.g. communication capability with potential robot failures) to re- tain its capability of accomplishing complex tasks through coordinated behaviors. In the proposed talk, I will discuss our recent works towards safe autonomy and resilient autonomy that aim to facilitate correct-by-design robotic behaviors in a variety of applications.},
  archive   = {C_AAAI},
  author    = {Wenhao Luo},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26816},
  pages     = {15449},
  title     = {Towards safe and resilient autonomy in multi-robot systems},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Combining runtime monitoring and machine learning with human
feedback. <em>AAAI</em>, 15448. (<a
href="https://doi.org/10.1609/aaai.v37i13.26815">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {State-of-the-art machine-learned controllers for autonomous systems demonstrate unbeatable performance in scenarios known from training. However, in evolving environments---changing weather or unexpected anomalies---, safety and interpretability remain the greatest challenges for autonomous systems to be reliable and are the urgent scientific challenges. Existing machine-learning approaches focus on recovering lost performance but leave the system open to potential safety violations. Formal methods address this problem by rigorously analysing a smaller representation of the system but they rarely prioritize performance of the controller. We propose to combine insights from formal verification and runtime monitoring with interpretable machine-learning design for guaranteeing reliability of autonomous systems.},
  archive   = {C_AAAI},
  author    = {Anna Lukina},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26815},
  pages     = {15448},
  title     = {Combining runtime monitoring and machine learning with human feedback},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AAAI new faculty highlights: General and scalable
optimization for robust AI. <em>AAAI</em>, 15447. (<a
href="https://doi.org/10.1609/aaai.v37i13.26814">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep neural networks (DNNs) can easily be manipulated (by an adversary) to output drastically different predictions and can be done so in a controlled and directed way. This process is known as adversarial attack and is considered one of the major hurdles in using DNNs in high-stakes and real-world applications. Although developing methods to secure DNNs against adversaries is now a primary research focus, it suffers from limitations such as lack of optimization generality and lack of optimization scalability. My research highlights will offer a holistic understanding of optimization foundations for robust AI, peer into their emerging challenges, and present recent solutions developed by my research group.},
  archive   = {C_AAAI},
  author    = {Sijia Liu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26814},
  pages     = {15447},
  title     = {AAAI new faculty highlights: General and scalable optimization for robust AI},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). Robust and adaptive deep learning via bayesian principles.
<em>AAAI</em>, 15446. (<a
href="https://doi.org/10.1609/aaai.v37i13.26813">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep learning models have achieved tremendous successes in accurate predictions for computer vision, natural language processing and speech recognition applications. However, to succeed in high-risk and safety-critical domains such as healthcare and finance, these deep learning models need to be made reliable and trustworthy. Specifically, they need to be robust and adaptive to real-world environments which can be drastically different from the training settings. In this talk, I will advocate for Bayesian principles to achieve the goal of building robust and adaptive deep learning models. I will introduce a suite of uncertainty quantification methods for Bayesian deep learning, and demonstrate applications en- abled by accurate uncertainty estimates, e.g., robust predic- tion, continual learning and repairing model failures. I will conclude by discussing the research challenges and potential impact for robust and adaptive deep learning models. This paper is part of the AAAI-23 New Faculty Highlights.},
  archive   = {C_AAAI},
  author    = {Yingzhen Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26813},
  pages     = {15446},
  title     = {Robust and adaptive deep learning via bayesian principles},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Intelligent planning for large-scale multi-robot
coordination. <em>AAAI</em>, 15445. (<a
href="https://doi.org/10.1609/aaai.v37i13.26812">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Robots will play a crucial role in the future and need to work as a team in increasingly more complex applications. Advances in robotics have laid the hardware foundations for building large-scale multi-robot systems. But how to coordinate robots intelligently is a difficult problem. We believe that graph-search-based planning can systematically exploit the combinatorial structure of multi-robot coordination problems and efficiently generate solutions with rigorous guarantees on correctness, completeness, and solution quality. We started with one problem that is central to many multi-robot applications. Multi-Agent Path Finding (MAPF) is an NP-hard problem of planning collision-free paths for a team of agents while minimizing their travel times. We addressed the MAPF problem from both (1) a theoretical perspective by developing efficient algorithms to solve large MAPF instances with completeness and optimality guarantees via a variety of AI and optimization technologies, such as constraint reasoning, heuristic search, stochastic local search, and machine learning, and (2) an applicational perspective by developing algorithmic techniques for integrating MAPF with task planning and execution for various multi-robot systems, such as mobile robot coordination, traffic management, drone swarm control, multi-arm assembly, and character control in video games. This paper is part of the AAAI-23 New Faculty Highlights.},
  archive   = {C_AAAI},
  author    = {Jiaoyang Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26812},
  pages     = {15445},
  title     = {Intelligent planning for large-scale multi-robot coordination},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Advances in AI for safety, equity, and well-being on web and
social media: Detection, robustness, attribution, and mitigation.
<em>AAAI</em>, 15444. (<a
href="https://doi.org/10.1609/aaai.v37i13.26811">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the talk, I shall describe my lab’s recent advances in AI, applied machine learning, and data mining to combat malicious actors (sockpuppets, ban evaders, etc.) and dangerous content (misinformation, hate, etc.) on web and social media platforms. My vision is to create a trustworthy online ecosystem for everyone and create the next generation of socially-aware methods that promote health, equity, and safety. Broadly, in my research, I have created novel graph, content (NLP, multimodality), and adversarial machine learning methods leveraging terabytes of data to detect, predict, and mitigate online threats. I shall describe the advancements made in my group across four key thrusts: (1) Detection of harmful content and malicious actors across platforms, languages, and modalities, (2) Robustifying detection models against adversarial actors by predicting future malicious activities, (3) Attributing the impact of harmful content and the role of recommender systems, and (4) Developing mitigation techniques to counter misinformation by professionals and the crowd.},
  archive   = {C_AAAI},
  author    = {Srijan Kumar},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26811},
  pages     = {15444},
  title     = {Advances in AI for safety, equity, and well-being on web and social media: Detection, robustness, attribution, and mitigation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Recent developments in data-driven algorithms for discrete
optimization. <em>AAAI</em>, 15443. (<a
href="https://doi.org/10.1609/aaai.v37i13.26810">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The last few years have witnessed a renewed interest in “data-driven algorithm design” (Balcan 2020), the use of Machine Learning (ML) to tailor an algorithm to a distribution of instances. More than a decade ago, advances in algorithm configuration (Hoos 2011) paved the way for the use of historical data to modify an algorithm’s (typically fixed, static) parameters. In discrete optimization (e.g., satisfiability, integer programming, etc.), exact and inexact algorithms for NP-Hard problems often involve heuristic search decisions (Lodi 2013), abstracted as parameters, that can demonstrably benefit from tuning on historical instances from the application of interest. While useful, algorithm configuration may be insufficient: setting the parameters of an algorithm upfront of solving the input instance is still a static, high-level decision. In contrast, we have been exploring a suite of ML and Reinforcement Learning (RL) approaches that tune iterative optimization algorithms, such as branch-and-bound for integer programming or construction heuristics, at the iteration-level (Khalil et al. 2016, 2017; Dai et al. 2017; Chmiela et al. 2021; Gupta et al. 2022; Chi et al. 2022; Khalil, Vaezipoor, and Dilkina 2022; Khalil, Morris, and Lodi 2022; Alomrani, Moravej, and Khalil 2022; Cappart et al. 2021; Gupta et al. 2020). We will survey our most recent work in this area: 1. New methods for learning in MILP branch-and-bound (Gupta et al. 2020, 2022; Chmiela et al. 2021; Khalil, Vaezipoor, and Dilkina 2022; Khalil, Morris, and Lodi 2022); 2. RL for online combinatorial optimization and largescale linear programming (Alomrani, Moravej, and Khalil 2022; Chi et al. 2022); 3. Neural network approximations for stochastic programming (Dumouchelle et al. 2022).},
  archive   = {C_AAAI},
  author    = {Elias B. Khalil},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26810},
  pages     = {15443},
  title     = {Recent developments in data-driven algorithms for discrete optimization},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Better environments for better AI. <em>AAAI</em>, 15442. (<a
href="https://doi.org/10.1609/aaai.v37i13.26809">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Most past research aimed at increasing the capabilities of AI methods has focused exclusively on the AI agent itself, i.e., given some input, what are the improvements to the agent’s reasoning that will yield the best possible output. In my research, I take a novel approach to increasing the capabilities of AI agents via the design of the environments in which they are intended to act. My methods for automated design identify the inherent capabilities and limitations of AI agents with respect to their environment and find the best way to modify the environment to account for those limitations and maximize the agents’ performance. The future will bring an ever increasing set of interactions between people and automated agents, whether at home, at the workplace, on the road, or across many other everyday settings. Autonomous vehicles, robotic tools, medical devices, and smart homes, all allow ample opportunity for human-robot and multi-agent interactions. In these settings, recognizing what agents are trying to achieve, providing relevant assistance, and supporting an effective collaboration are essential tasks, and tasks that can all be enhanced via careful environment design. However, the increasing complexity of the systems we use and the environments in which we operate makes devising good design solutions extremely challenging. This stresses the importance of developing automated design tools to help determine the most effective ways to apply change and enable robust AI systems. My long-term goal is to provide theoretical foundations for designing AI systems that are capable of effective partnership in sustainable and efficient collaborations of automated agents as well as of automated agents and people.},
  archive   = {C_AAAI},
  author    = {Sarah Keren},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26809},
  pages     = {15442},
  title     = {Better environments for better AI},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Food information engineering: A systematic literature
review. <em>AAAI</em>, 15441. (<a
href="https://doi.org/10.1609/aaai.v37i13.26808">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In recent years, the research on food information gave rise to the food information engineering domain. The goal of this paper is to provide to the research community with a systematic literature review of methodologies, methods and tools used in this domain.},
  archive   = {C_AAAI},
  author    = {Azanzi Jiomekong},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26808},
  pages     = {15441},
  title     = {Food information engineering: A systematic literature review},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generative decision making under uncertainty. <em>AAAI</em>,
15440. (<a href="https://doi.org/10.1609/aaai.v37i13.26807">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the fields of natural language processing (NLP) and computer vision (CV), recent advances in generative modeling have led to powerful machine learning systems that can effectively learn from large labeled and unlabeled datasets. These systems, by and large, apply a uniform pretrain-finetune pipeline on sequential data streams and have achieved state-of-the-art-performance across many tasks and benchmarks. In this talk, we will present recent algorithms that extend this paradigm to sequential decision making, by casting it as an inverse problem that can be solved via deep generative models. These generative approaches are stable to train, provide a flexible interface for single- and multi-task inference, and generalize exceedingly well outside their training datasets. We instantiate these algorithms in the context of reinforcement learning and black-box optimization. Empirically, we demonstrate that these approaches perform exceedingly well on high-dimensional benchmarks outperforming the current state-of-the-art approaches based on forward models.},
  archive   = {C_AAAI},
  author    = {Aditya Grover},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26807},
  pages     = {15440},
  title     = {Generative decision making under uncertainty},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Accountability layers: Explaining complex system failures by
parts. <em>AAAI</em>, 15439. (<a
href="https://doi.org/10.1609/aaai.v37i13.26806">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With the rise of AI used for critical decision-making, many important predictions are made by complex and opaque AI algorithms. The aim of eXplainable Artificial Intelligence (XAI) is to make these opaque decision-making algorithms more transparent and trustworthy. This is often done by constructing an ``explainable model&#39;&#39; for a single modality or subsystem. However, this approach fails for complex systems that are made out of multiple parts. In this paper, I discuss how to explain complex system failures. I represent a complex machine as a hierarchical model of introspective sub-systems working together towards a common goal. The subsystems communicate in a common symbolic language. This work creates a set of explanatory accountability layers for trustworthy AI.},
  archive   = {C_AAAI},
  author    = {Leilani H. Gilpin},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26806},
  pages     = {15439},
  title     = {Accountability layers: Explaining complex system failures by parts},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Targeted knowledge infusion to make conversational AI
explainable and safe. <em>AAAI</em>, 15438. (<a
href="https://doi.org/10.1609/aaai.v37i13.26805">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Conversational Systems (CSys) represent practical and tangible outcomes of advances in NLP and AI. CSys see continuous improvements through unsupervised training of large language models (LLMs) on a humongous amount of generic training data. However, when these CSys are suggested for use in domains like Mental Health, they fail to match the acceptable standards of clinical care, such as the clinical process in Patient Health Questionnaire (PHQ-9). The talk will present, Knowledge-infused Learning (KiL), a paradigm within NeuroSymbolic AI that focuses on making machine/deep learning models (i) learn over knowledge-enriched data, (ii) learn to follow guidelines in process-oriented tasks for safe and reasonable generation, and (iii) learn to leverage multiple contexts and stratified knowledge to yield user-level explanations. KiL established Knowledge-Intensive Language Understanding, a set of tasks for assessing safety, explainability, and conceptual flow in CSys.},
  archive   = {C_AAAI},
  author    = {Manas Gaur},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26805},
  pages     = {15438},
  title     = {Targeted knowledge infusion to make conversational AI explainable and safe},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distributed stochastic nested optimization for emerging
machine learning models: Algorithm and theory. <em>AAAI</em>, 15437. (<a
href="https://doi.org/10.1609/aaai.v37i13.26804">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Traditional machine learning models can be formulated as the expected risk minimization (ERM) problem: minw∈Rd Eξ [l(w; ξ)], where w ∈ Rd denotes the model parameter, ξ represents training samples, l(·) is the loss function. Numerous optimization algorithms, such as stochastic gradient descent (SGD), have been developed to solve the ERM problem. However, a wide range of emerging machine learning models are beyond this class of optimization problems, such as model-agnostic meta-learning (Finn, Abbeel, and Levine 2017). Of particular interest of my research is the stochastic nested optimization (SNO) problem, whose objective function has a nested structure. Specifically, I have been focusing on two instances of this kind of problem: stochastic compositional optimization (SCO) problems, which cover meta-learning, area-under-the-precision recall-curve optimization, contrastive self-supervised learning, etc., and stochastic bilevel optimization (SBO) problems, which can be applied to meta-learning, hyperparameter optimization, neural network architecture search, etc. With the emergence of large-scale distributed data, such as the user data generated on mobile devices or intelligent hardware, it is imperative to develop distributed optimization algorithms for SNO (Distributed SNO). A significant challenge for optimizing distributed SNO problems lies in that the stochastic (hyper-)gradient is a biased estimation of the full gradient. Thus, existing distributed optimization algorithms when applied to them suffer from slow convergence rates. In this talk, I will discuss my recent works about distributed SCO (Gao and Huang 2021; Gao, Li, and Huang 2022) and distributed SBO (Gao, Gu, and Thai 2022; Gao 2022) under both centralized and decentralized settings, including algorithmic details about reducing the bias of stochastic gradient, theoretical convergence rate, and practical machine learning applications, and then highlight challenges for future research.},
  archive   = {C_AAAI},
  author    = {Hongchang Gao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26804},
  pages     = {15437},
  title     = {Distributed stochastic nested optimization for emerging machine learning models: Algorithm and theory},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cooperative multi-agent learning in a complex world:
Challenges and solutions. <em>AAAI</em>, 15436. (<a
href="https://doi.org/10.1609/aaai.v37i13.26803">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Over the past few years, artificial intelligence (AI) has achieved great success in a variety of applications, such as image classification and recommendation systems. This success has often been achieved by training machine learning models on static datasets, where inputs and desired outputs are provided. However, we are now seeing a shift in this paradigm. Instead of learning from static datasets, machine learning models are increasingly being trained through feedback from their interactions with the world. This is particularly important when machine learning models are deployed in the real world, as their decisions can often have an impact on other agents, turning the decision-making process into a multi-agent problem. As a result, multi-agent learning in complex environments is a critical area of research for the next generation of AI, particularly in the context of cooperative tasks. Cooperative multi-agent learning is an essential problem for practitioners to consider as it has the potential to enable a wide range of multi-agent tasks. In this presentation, we will review the background and challenges of cooperative multi-agent learning, and survey our research that aims to address these challenges.},
  archive   = {C_AAAI},
  author    = {Yali Du},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26803},
  pages     = {15436},
  title     = {Cooperative multi-agent learning in a complex world: Challenges and solutions},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Perception for general-purpose robot manipulation.
<em>AAAI</em>, 15435. (<a
href="https://doi.org/10.1609/aaai.v37i13.26802">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {To autonomously perform tasks, a robot should continually perceive the state of its environment, reason with the task at hand, plan and execute appropriate actions. In this pipeline, perception is largely unsolved and one of the more challenging problems. Common indoor environments typically pose two main problems: 1) inherent occlusions leading to unreliable observations of objects, and 2) the presence and involvement of a wide range of objects with varying physical and visual attributes (i.e., rigid, articulated, deformable, granular, transparent, etc.). Thus, we need algorithms that can accommodate perceptual uncertainty in the state estimation and generalize to a wide range of objects. Probabilistic inference methods have been highly suitable for modeling perceptual uncertainty, and data-driven approaches using deep learning techniques have shown promising advancements toward generalization. Perception for manipulation is a more intricate setting requiring the best from both worlds. My research aims to develop robot perception algorithms that can generalize over objects and tasks while accommodating perceptual uncertainty to support robust task execution in the real world. In this presentation, I will briefly highlight my research in these two research threads.},
  archive   = {C_AAAI},
  author    = {Karthik Desingh},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26802},
  pages     = {15435},
  title     = {Perception for general-purpose robot manipulation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The automatic computer scientist. <em>AAAI</em>, 15434. (<a
href="https://doi.org/10.1609/aaai.v37i13.26801">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Algorithms are ubiquitous: they track our sleep, help us find cheap flights, and even help us see black holes. However, designing novel algorithms is extremely difficult, and we do not have efficient algorithms for many fundamental problems. The goal of my research is to accelerate algorithm discovery by building an automatic computer scientist. To work towards this goal, my research focuses on inductive logic programming, a form of machine learning in which my collaborators and I have demonstrated major advances in automated algorithm discovery over the past five years. In this talk and paper, I survey these advances.},
  archive   = {C_AAAI},
  author    = {Andrew Cropper},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26801},
  pages     = {15434},
  title     = {The automatic computer scientist},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Probabilistic reasoning and learning for trustworthy AI.
<em>AAAI</em>, 15433. (<a
href="https://doi.org/10.1609/aaai.v37i13.26800">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As automated decision-making systems are increasingly deployed in areas with personal and societal impacts, there is a growing demand for artificial intelligence and machine learning systems that are fair, robust, interpretable, and generally trustworthy. Ideally we would wish to answer questions regarding these properties and provide guarantees about any automated system to be deployed in the real world. This raises the need for a unified language and framework under which we can reason about and develop trustworthy AI systems. This talk will discuss how tractable probabilistic reasoning and learning provides such framework. It is important to note that guarantees regarding fairness, robustness, etc., hold with respect to the distribution of the world in which the decision-making system operates. For example, to see whether automated loan decisions are biased against certain gender, one may compare the average decision for each gender; this requires knowledge of how the features used in the decision are distributed for each gender. Moreover, there are inherent uncertainties in modeling this distribution, in addition to the uncertainties when deploying a system in the real world, such as missing or noisy information. We can handle such uncertainties in a principled way through probabilistic reasoning. Taking fairness-aware learning as an example, we can deal with biased labels in the training data by explicitly modeling the observed labels as being generated from some probabilistic process that injects bias/noise to hidden, fair labels, particularly in a way that best explains the observed data. A key challenge that still needs to be addressed is that: we need models that can closely fit complex real-world distributions—i.e. expressive—while also being amenable to exact and efficient inference of probabilistic queries—i.e. tractable. I will show that probabilistic circuits, a family of tractable probabilistic models, offer both such benefits. In order to ultimately develop a common framework to study various areas of trustworthy AI (e.g., privacy, fairness, explanations, etc.), we need models that can flexibly answer different questions, even the ones it did not foresee. This talk will thus survey the efforts to expand the horizon of complex reasoning capabilities of probabilistic circuits, especially highlighted by a modular approach that answers various queries via a pipeline of a handful of simple tractable operations.},
  archive   = {C_AAAI},
  author    = {YooJung Choi},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26800},
  pages     = {15433},
  title     = {Probabilistic reasoning and learning for trustworthy AI},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Safety validation of learning-based autonomous systems: A
multi-fidelity approach. <em>AAAI</em>, 15432. (<a
href="https://doi.org/10.1609/aaai.v37i13.26799">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In recent years, learning-based autonomous systems have emerged as a promising tool for automating many crucial tasks. The key question is how we can build trust in such systems for safety-critical applications. My research aims to focus on the creation and validation of safety frameworks that leverage multiple sources of information. The ultimate goal is to establish a solid foundation for a long-term research program aimed at understanding the role of fidelity in simulators for safety validation and robot learning.},
  archive   = {C_AAAI},
  author    = {Ali Baheri},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26799},
  pages     = {15432},
  title     = {Safety validation of learning-based autonomous systems: A multi-fidelity approach},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Can we trust fair-AI? <em>AAAI</em>, 15421–15430. (<a
href="https://doi.org/10.1609/aaai.v37i13.26798">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {There is a fast-growing literature in addressing the fairness of AI models (fair-AI), with a continuous stream of new conceptual frameworks, methods, and tools. How much can we trust them? How much do they actually impact society? We take a critical focus on fair-AI and survey issues, simplifications, and mistakes that researchers and practitioners often underestimate, which in turn can undermine the trust on fair-AI and limit its contribution to society. In particular, we discuss the hyper-focus on fairness metrics and on optimizing their average performances. We instantiate this observation by discussing the Yule&#39;s effect of fair-AI tools: being fair on average does not imply being fair in contexts that matter. We conclude that the use of fair-AI methods should be complemented with the design, development, and verification practices that are commonly summarized under the umbrella of trustworthy AI.},
  archive   = {C_AAAI},
  author    = {Salvatore Ruggieri and Jose M. Alvarez and Andrea Pugnana and Laura State and Franco Turini},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26798},
  pages     = {15421-15430},
  title     = {Can we trust fair-AI?},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Holistic adversarial robustness of deep learning models.
<em>AAAI</em>, 15411–15420. (<a
href="https://doi.org/10.1609/aaai.v37i13.26797">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Adversarial robustness studies the worst-case performance of a machine learning model to ensure safety and reliability. With the proliferation of deep-learning-based technology, the potential risks associated with model development and deployment can be amplified and become dreadful vulnerabilities. This paper provides a comprehensive overview of research topics and foundational principles of research methods for adversarial robustness of deep learning models, including attacks, defenses, verification, and novel applications.},
  archive   = {C_AAAI},
  author    = {Pin-Yu Chen and Sijia Liu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26797},
  pages     = {15411-15420},
  title     = {Holistic adversarial robustness of deep learning models},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The many faces of adversarial machine learning.
<em>AAAI</em>, 15402–15409. (<a
href="https://doi.org/10.1609/aaai.v37i13.26796">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Adversarial machine learning (AML) research is concerned with robustness of machine learning models and algorithms to malicious tampering. Originating at the intersection between machine learning and cybersecurity, AML has come to have broader research appeal, stretching traditional notions of security to include applications of computer vision, natural language processing, and network science. In addition, the problems of strategic classification, algorithmic recourse, and counterfactual explanations have essentially the same core mathematical structure as AML, despite distinct motivations. I give a simplified overview of the central problems in AML, and then discuss both the security-motivated AML domains, and the problems above unrelated to security. These together span a number of important AI subdisciplines, but can all broadly be viewed as concerned with trustworthy AI. My goal is to clarify both the technical connections among these, as well as the substantive differences, suggesting directions for future research.},
  archive   = {C_AAAI},
  author    = {Yevgeniy Vorobeychik},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26796},
  pages     = {15402-15409},
  title     = {The many faces of adversarial machine learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Customer service combining human operators and virtual
agents: A call for multidisciplinary AI research. <em>AAAI</em>,
15393–15401. (<a
href="https://doi.org/10.1609/aaai.v37i13.26795">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The use of virtual agents (bots) has become essential for providing online assistance to customers. However, even though a lot of effort has been dedicated to the research, development, and deployment of such virtual agents, customers are frequently frustrated with the interaction with the virtual agent and require a human instead. We suggest that a holistic approach, combining virtual agents and human operators working together, is the path to providing satisfactory service. However, implementing such a holistic customer service system will not, and cannot, be achieved using any single AI technology or branch. Rather, such a system will inevitably require the integration of multiple and diverse AI technologies, including natural language processing, multi-agent systems, machine learning, reinforcement learning, and behavioral cloning; in addition to integration with other disciplines such as psychology, business, sociology, economics, operation research, informatics, computer-human interaction, and more. As such, we believe this customer service application offers a rich domain for experimentation and application of multidisciplinary AI. In this paper, we introduce the holistic customer service application and discuss the key AI technologies and disciplines required for a successful AI solution for this setting. For each of these AI technologies, we outline the key scientific questions and research avenues stemming from this setting. We demonstrate that integrating technologies from different fields can lead to a cost-effective successful customer service center. The challenge is that there is a need for several communities, each with its own language and modeling techniques, different problem-solving methods, and different evaluation methodologies, all of which need to work together. Real cooperation will require the formation of joint methodologies and techniques that could improve the service to customers, but, more importantly, open new directions in cooperation of diverse communities toward solving joint difficult tasks.},
  archive   = {C_AAAI},
  author    = {Sarit Kraus and Yaniv Oshrat and Yonatan Aumann and Tal Hollander and Oleg Maksimov and Anita Ostroumov and Natali Shechtman},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26795},
  pages     = {15393-15401},
  title     = {Customer service combining human operators and virtual agents: A call for multidisciplinary AI research},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). QA is the new KR: Question-answer pairs as knowledge bases.
<em>AAAI</em>, 15385–15392. (<a
href="https://doi.org/10.1609/aaai.v37i13.26794">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose a new knowledge representation (KR) based on knowledge bases (KBs) derived from text, based on question generation and entity linking. We argue that the proposed type of KB has many of the key advantages of a traditional symbolic KB: in particular, it consists of small modular components, which can be combined compositionally to answer complex queries, including relational queries and queries involving ``multi-hop&#39;&#39; inferences. However, unlike a traditional KB, this information store is well-aligned with common user information needs. We present one such KB, called a QEDB, and give qualitative evidence that the atomic components are high-quality and meaningful, and that atomic components can be combined in ways similar to the triples in a symbolic KB. We also show experimentally that questions reflective of typical user questions are more easily answered with a QEDB than a symbolic KB.},
  archive   = {C_AAAI},
  author    = {William W. Cohen and Wenhu Chen and Michiel De Jong and Nitish Gupta and Alessandro Presta and Pat Verga and John Wieting},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26794},
  pages     = {15385-15392},
  title     = {QA is the new KR: Question-answer pairs as knowledge bases},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Foundation model for material science. <em>AAAI</em>,
15376–15383. (<a
href="https://doi.org/10.1609/aaai.v37i13.26793">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Foundation models (FMs) are achieving remarkable successes to realize complex downstream tasks in domains including natural language and visions. In this paper, we propose building an FM for material science, which is trained with massive data across a wide variety of material domains and data modalities. Nowadays machine learning models play key roles in material discovery, particularly for property prediction and structure generation. However, those models have been independently developed to address only specific tasks without sharing more global knowledge. Development of an FM for material science will enable overarching modeling across material domains and data modalities by sharing their feature representations. We discuss fundamental challenges and required technologies to build an FM from the aspects of data preparation, model development, and downstream tasks.},
  archive   = {C_AAAI},
  author    = {Seiji Takeda and Akihiro Kishimoto and Lisa Hamada and Daiju Nakano and John R. Smith},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26793},
  pages     = {15376-15383},
  title     = {Foundation model for material science},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multimodal propaganda processing. <em>AAAI</em>,
15368–15375. (<a
href="https://doi.org/10.1609/aaai.v37i13.26792">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Propaganda campaigns have long been used to influence public opinion via disseminating biased and/or misleading information. Despite the increasing prevalence of propaganda content on the Internet, few attempts have been made by AI researchers to analyze such content. We introduce the task of multimodal propaganda processing, where the goal is to automatically analyze propaganda content. We believe that this task presents a long-term challenge to AI researchers and that successful processing of propaganda could bring machine understanding one important step closer to human understanding. We discuss the technical challenges associated with this task and outline the steps that need to be taken to address it.},
  archive   = {C_AAAI},
  author    = {Vincent Ng and Shengjie Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26792},
  pages     = {15368-15375},
  title     = {Multimodal propaganda processing},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Foundations of cooperative AI. <em>AAAI</em>, 15359–15367.
(<a href="https://doi.org/10.1609/aaai.v37i13.26791">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {AI systems can interact in unexpected ways, sometimes with disastrous consequences. As AI gets to control more of our world, these interactions will become more common and have higher stakes. As AI becomes more advanced, these interactions will become more sophisticated, and game theory will provide the tools for analyzing these interactions. However, AI agents are in some ways unlike the agents traditionally studied in game theory, introducing new challenges as well as opportunities. We propose a research agenda to develop the game theory of highly advanced AI agents, with a focus on achieving cooperation.},
  archive   = {C_AAAI},
  author    = {Vincent Conitzer and Caspar Oesterheld},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26791},
  pages     = {15359-15367},
  title     = {Foundations of cooperative AI},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Probabilistic programs as an action description language.
<em>AAAI</em>, 15351–15358. (<a
href="https://doi.org/10.1609/aaai.v37i13.26790">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Actions description languages (ADLs), such as STRIPS, PDDL, and RDDL specify the input format for planning algorithms. Unfortunately, their syntax is familiar to planning experts only, and not to potential users of planning technology. Moreover, this syntax limits the ability to describe complex and large domains. We argue that programming languages (PLs), and more specifically, probabilistic programming languages (PPLs), provide a more suitable alternative. PLs are familiar to all programmers, support complex data types and rich libraries for their manipulation, and have powerful constructs, such as loops, sub-routines, and local variables with which complex, realistic models and complex objectives can be simply and naturally specified. PPLs, specifically, make it easy to specify distributions, which is essential for stochastic models. The natural objection to this proposal is that PLs are opaque and too expressive, making reasoning about them difficult. However, PPLs also come with efficient inference algorithms, which, coupled with a growing body of work on sampling-based and gradient-based planning, imply that planning and execution monitoring can be carried out efficiently in practice. In this paper, we expand on this proposal, illustrating its potential with examples.},
  archive   = {C_AAAI},
  author    = {Ronen I. Brafman and David Tolpin and Or Wertheim},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i13.26790},
  pages     = {15351-15358},
  title     = {Probabilistic programs as an action description language},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards safe AI: Sandboxing DNNs-based controllers in
stochastic games. <em>AAAI</em>, 15340–15349. (<a
href="https://doi.org/10.1609/aaai.v37i12.26789">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Nowadays, AI-based techniques, such as deep neural networks (DNNs), are widely deployed in autonomous systems for complex mission requirements (e.g., motion planning in robotics). However, DNNs-based controllers are typically very complex, and it is very hard to formally verify their correctness, potentially causing severe risks for safety-critical autonomous systems. In this paper, we propose a construction scheme for a so-called Safe-visor architecture to sandbox DNNs-based controllers. Particularly, we consider the construction under a stochastic game framework to provide a system-level safety guarantee which is robust to noises and disturbances. A supervisor is built to check the control inputs provided by a DNNs-based controller and decide whether to accept them. Meanwhile, a safety advisor is running in parallel to provide fallback control inputs in case the DNN-based controller is rejected. We demonstrate the proposed approaches on a quadrotor employing an unverified DNNs-based controller.},
  archive   = {C_AAAI},
  author    = {Bingzhuo Zhong and Hongpeng Cao and Majid Zamani and Marco Caccamo},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26789},
  pages     = {15340-15349},
  title     = {Towards safe AI: Sandboxing DNNs-based controllers in stochastic games},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Rethinking safe control in the presence of self-seeking
humans. <em>AAAI</em>, 15331–15339. (<a
href="https://doi.org/10.1609/aaai.v37i12.26788">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Safe control methods are often designed to behave safely even in worst-case human uncertainties. Such design can cause more aggressive human behaviors that exploit its conservatism and result in greater risk for everyone. However, this issue has not been systematically investigated previously. This paper uses an interaction-based payoff structure from evolutionary game theory to model humans’ short-sighted, self-seeking behaviors. The model captures how prior human-machine interaction experience causes behavioral and strategic changes in humans in the long term. We then show that deterministic worst-case safe control techniques and equilibrium-based stochastic methods can have worse safety and performance trade-offs than a basic method that mediates human strategic changes. This finding suggests an urgent need to fundamentally rethink the safe control framework used in human-technology interaction in pursuit of greater safety for all.},
  archive   = {C_AAAI},
  author    = {Zixuan Zhang and Maitham AL-Sunni and Haoming Jing and Hirokazu Shirado and Yorie Nakahira},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26788},
  pages     = {15331-15339},
  title     = {Rethinking safe control in the presence of self-seeking humans},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Video-audio domain generalization via confounder
disentanglement. <em>AAAI</em>, 15322–15330. (<a
href="https://doi.org/10.1609/aaai.v37i12.26787">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Existing video-audio understanding models are trained and evaluated in an intra-domain setting, facing performance degeneration in real-world applications where multiple domains and distribution shifts naturally exist. The key to video-audio domain generalization (VADG) lies in alleviating spurious correlations over multi-modal features. To achieve this goal, we resort to causal theory and attribute such correlation to confounders affecting both video-audio features and labels. We propose a DeVADG framework that conducts uni-modal and cross-modal deconfounding through back-door adjustment. DeVADG performs cross-modal disentanglement and obtains fine-grained confounders at both class-level and domain-level using half-sibling regression and unpaired domain transformation, which essentially identifies domain-variant factors and class-shared factors that cause spurious correlations between features and false labels. To promote VADG research, we collect a VADG-Action dataset for video-audio action recognition with over 5,000 video clips across four domains (e.g., cartoon and game) and ten action classes (e.g., cooking and riding). We conduct extensive experiments, i.e., multi-source DG, single-source DG, and qualitative analysis, validating the rationality of our causal analysis and the effectiveness of the DeVADG framework.},
  archive   = {C_AAAI},
  author    = {Shengyu Zhang and Xusheng Feng and Wenyan Fan and Wenjing Fang and Fuli Feng and Wei Ji and Shuo Li and Li Wang and Shanshan Zhao and Zhou Zhao and Tat-Seng Chua and Fei Wu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26787},
  pages     = {15322-15330},
  title     = {Video-audio domain generalization via confounder disentanglement},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Evaluating model-free reinforcement learning toward
safety-critical tasks. <em>AAAI</em>, 15313–15321. (<a
href="https://doi.org/10.1609/aaai.v37i12.26786">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Safety comes first in many real-world applications involving autonomous agents. Despite a large number of reinforcement learning (RL) methods focusing on safety-critical tasks, there is still a lack of high-quality evaluation of those algorithms that adheres to safety constraints at each decision step under complex and unknown dynamics. In this paper, we revisit prior work in this scope from the perspective of state-wise safe RL and categorize them as projection-based, recovery-based, and optimization-based approaches, respectively. Furthermore, we propose Unrolling Safety Layer (USL), a joint method that combines safety optimization and safety projection. This novel technique explicitly enforces hard constraints via the deep unrolling architecture and enjoys structural advantages in navigating the trade-off between reward improvement and constraint satisfaction. To facilitate further research in this area, we reproduce related algorithms in a unified pipeline and incorporate them into SafeRL-Kit, a toolkit that provides off-the-shelf interfaces and evaluation utilities for safety-critical tasks. We then perform a comparative study of the involved algorithms on six benchmarks ranging from robotic control to autonomous driving. The empirical results provide an insight into their applicability and robustness in learning zero-cost-return policies without task-dependent handcrafting. The project page is available at https://sites.google.com/view/saferlkit.},
  archive   = {C_AAAI},
  author    = {Linrui Zhang and Qin Zhang and Li Shen and Bo Yuan and Xueqian Wang and Dacheng Tao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26786},
  pages     = {15313-15321},
  title     = {Evaluating model-free reinforcement learning toward safety-critical tasks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robustness to spurious correlations improves semantic
out-of-distribution detection. <em>AAAI</em>, 15305–15312. (<a
href="https://doi.org/10.1609/aaai.v37i12.26785">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Methods which utilize the outputs or feature representations of predictive models have emerged as promising approaches for out-of-distribution (OOD) detection of image inputs. However, as demonstrated in previous work, these methods struggle to detect OOD inputs that share nuisance values (e.g. background) with in-distribution inputs. The detection of shared-nuisance OOD (SN-OOD) inputs is particularly relevant in real-world applications, as anomalies and in-distribution inputs tend to be captured in the same settings during deployment. In this work, we provide a possible explanation for these failures and propose nuisance-aware OOD detection to address them. Nuisance-aware OOD detection substitutes a classifier trained via Empirical Risk Minimization (ERM) with one that 1. approximates a distribution where the nuisance-label relationship is broken and 2. yields representations that are independent of the nuisance under this distribution, both marginally and conditioned on the label. We can train a classifier to achieve these objectives using Nuisance-Randomized Distillation (NuRD), an algorithm developed for OOD generalization under spurious correlations. Output- and feature-based nuisance-aware OOD detection perform substantially better than their original counterparts, succeeding even when detection based on domain generalization algorithms fails to improve performance.},
  archive   = {C_AAAI},
  author    = {Lily H. Zhang and Rajesh Ranganath},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26785},
  pages     = {15305-15312},
  title     = {Robustness to spurious correlations improves semantic out-of-distribution detection},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). BIFRNet: A brain-inspired feature restoration DNN for
partially occluded image recognition. <em>AAAI</em>, 15296–15304. (<a
href="https://doi.org/10.1609/aaai.v37i12.26784">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The partially occluded image recognition (POIR) problem has been a challenge for artificial intelligence for a long time. A common strategy to handle the POIR problem is using the non-occluded features for classification. Unfortunately, this strategy will lose effectiveness when the image is severely occluded, since the visible parts can only provide limited information. Several studies in neuroscience reveal that feature restoration which fills in the occluded information and is called amodal completion is essential for human brains to recognize partially occluded images. However, feature restoration is commonly ignored by CNNs, which may be the reason why CNNs are ineffective for the POIR problem. Inspired by this, we propose a novel brain-inspired feature restoration network (BIFRNet) to solve the POIR problem. It mimics a ventral visual pathway to extract image features and a dorsal visual pathway to distinguish occluded and visible image regions. In addition, it also uses a knowledge module to store classification prior knowledge and uses a completion module to restore occluded features based on visible features and prior knowledge. Thorough experiments on synthetic and real-world occluded image datasets show that BIFRNet outperforms the existing methods in solving the POIR problem. Especially for severely occluded images, BIRFRNet surpasses other methods by a large margin and is close to the human brain performance. Furthermore, the brain-inspired design makes BIFRNet more interpretable.},
  archive   = {C_AAAI},
  author    = {Jiahong Zhang and Lihong Cao and Qiuxia Lai and Bingyao Li and Yunxiao Qin},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26784},
  pages     = {15296-15304},
  title     = {BIFRNet: A brain-inspired feature restoration DNN for partially occluded image recognition},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reachability analysis of neural network control systems.
<em>AAAI</em>, 15287–15295. (<a
href="https://doi.org/10.1609/aaai.v37i12.26783">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Neural network controllers (NNCs) have shown great promise in autonomous and cyber-physical systems. Despite the various verification approaches for neural networks, the safety analysis of NNCs remains an open problem. Existing verification approaches for neural network control systems (NNCSs) either can only work on a limited type of activation functions, or result in non-trivial over-approximation errors with time evolving. This paper proposes a verification framework for NNCS based on Lipschitzian optimisation, called DeepNNC. We first prove the Lipschitz continuity of closed-loop NNCSs by unrolling and eliminating the loops. We then reveal the working principles of applying Lipschitzian optimisation on NNCS verification and illustrate it by verifying an adaptive cruise control model. Compared to state-of-the-art verification approaches, DeepNNC shows superior performance in terms of efficiency and accuracy over a wide range of NNCs. We also provide a case study to demonstrate the capability of DeepNNC to handle a real-world, practical, and complex system. Our tool DeepNNC is available at https://github.com/TrustAI/DeepNNC.},
  archive   = {C_AAAI},
  author    = {Chi Zhang and Wenjie Ruan and Peipei Xu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26783},
  pages     = {15287-15295},
  title     = {Reachability analysis of neural network control systems},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Safety verification of nonlinear systems with bayesian
neural network controllers. <em>AAAI</em>, 15278–15286. (<a
href="https://doi.org/10.1609/aaai.v37i12.26782">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Bayesian neural networks (BNNs) retain NN structures with a probability distribution placed over their weights. With the introduced uncertainties and redundancies, BNNs are proper choices of robust controllers for safety-critical control systems. This paper considers the problem of verifying the safety of nonlinear closed-loop systems with BNN controllers over unbounded-time horizon. In essence, we compute a safe weight set such that as long as the BNN controller is always applied with weights sampled from the safe weight set, the controlled system is guaranteed to be safe. We propose a novel two-phase method for the safe weight set computation. First, we construct a reference safe control set that constraints the control inputs, through polynomial approximation to the BNN controller followed by polynomial-optimization-based barrier certificate generation. Then, the computation of safe weight set is reduced to a range inclusion problem of the BNN on the system domain w.r.t. the safe control set, which can be solved incrementally and the set of safe weights can be extracted. Compared with the existing method based on invariant learning and mixed-integer linear programming, we could compute safe weight sets with larger radii on a series of linear benchmarks. Moreover, experiments on a series of widely used nonlinear control tasks show that our method can synthesize large safe weight sets with probability measure as high as 95\% even for a large-scale system of dimension 7.},
  archive   = {C_AAAI},
  author    = {Xia Zeng and Zhengfeng Yang and Li Zhang and Xiaochao Tang and Zhenbing Zeng and Zhiming Liu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26782},
  pages     = {15278-15286},
  title     = {Safety verification of nonlinear systems with bayesian neural network controllers},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). User-oriented robust reinforcement learning. <em>AAAI</em>,
15269–15277. (<a
href="https://doi.org/10.1609/aaai.v37i12.26781">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, improving the robustness of policies across different environments attracts increasing attention in the reinforcement learning (RL) community. Existing robust RL methods mostly aim to achieve the max-min robustness by optimizing the policy’s performance in the worst-case environment. However, in practice, a user that uses an RL policy may have different preferences over its performance across environments. Clearly, the aforementioned max-min robustness is oftentimes too conservative to satisfy user preference. Therefore, in this paper, we integrate user preference into policy learning in robust RL, and propose a novel User-Oriented Robust RL (UOR-RL) framework. Specifically, we define a new User-Oriented Robustness (UOR) metric for RL, which allocates different weights to the environments according to user preference and generalizes the max-min robustness metric. To optimize the UOR metric, we develop two different UOR-RL training algorithms for the scenarios with or without a priori known environment distribution, respectively. Theoretically, we prove that our UOR-RL training algorithms converge to near-optimal policies even with inaccurate or completely no knowledge about the environment distribution. Furthermore, we carry out extensive experimental evaluations in 6 MuJoCo tasks. The experimental results demonstrate that UOR-RL is comparable to the state-of-the-art baselines under the average-case and worst-case performance metrics, and more importantly establishes new state-of-the-art performance under the UOR metric.},
  archive   = {C_AAAI},
  author    = {Haoyi You and Beichen Yu and Haiming Jin and Zhaoxing Yang and Jiahui Sun},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26781},
  pages     = {15269-15277},
  title     = {User-oriented robust reinforcement learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Auditing and robustifying COVID-19 misinformation datasets
via anticontent sampling. <em>AAAI</em>, 15260–15268. (<a
href="https://doi.org/10.1609/aaai.v37i12.26780">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper makes two key contributions. First, it argues that highly specialized rare content classifiers trained on small data typically have limited exposure to the richness and topical diversity of the negative class (dubbed anticontent) as observed in the wild. As a result, these classifiers&#39; strong performance observed on the test set may not translate into real-world settings. In the context of COVID-19 misinformation detection, we conduct an in-the-wild audit of multiple datasets and demonstrate that models trained with several prominently cited recent datasets are vulnerable to anticontent when evaluated in the wild. Second, we present a novel active learning pipeline that requires zero manual annotation and iteratively augments the training data with challenging anticontent, robustifying these classifiers.},
  archive   = {C_AAAI},
  author    = {Clay H. Yoo and Ashiqur R. KhudaBukhsh},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26780},
  pages     = {15260-15268},
  title     = {Auditing and robustifying COVID-19 misinformation datasets via anticontent sampling},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DeepGemini: Verifying dependency fairness for deep neural
network. <em>AAAI</em>, 15251–15259. (<a
href="https://doi.org/10.1609/aaai.v37i12.26779">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep neural networks (DNNs) have been widely adopted in many decision-making industrial applications. Their fairness issues, i.e., whether there exist unintended biases in the DNN, receive much attention and become critical concerns, which can directly cause negative impacts in our daily life and potentially undermine the fairness of our society, especially with their increasing deployment at an unprecedented speed. Recently, some early attempts have been made to provide fairness assurance of DNNs, such as fairness testing, which aims at finding discriminatory samples empirically, and fairness certification, which develops sound but not complete analysis to certify the fairness of DNNs. Nevertheless, how to formally compute discriminatory samples and fairness scores (i.e., the percentage of fair input space), is still largely uninvestigated. In this paper, we propose DeepGemini, a novel fairness formal analysis technique for DNNs, which contains two key components: discriminatory sample discovery and fairness score computation. To uncover discriminatory samples, we encode the fairness of DNNs as safety properties and search for discriminatory samples by means of state-of-the-art verification techniques for DNNs. This reduction enables us to be the first to formally compute discriminatory samples. To compute the fairness score, we develop counterexample guided fairness analysis, which utilizes four heuristics to efficiently approximate a lower bound of fairness score. Extensive experimental evaluations demonstrate the effectiveness and efficiency of DeepGemini on commonly-used benchmarks, and DeepGemini outperforms state-of-the-art DNN fairness certification approaches in terms of both efficiency and scalability.},
  archive   = {C_AAAI},
  author    = {Xuan Xie and Fuyuan Zhang and Xinwen Hu and Lei Ma},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26779},
  pages     = {15251-15259},
  title     = {DeepGemini: Verifying dependency fairness for deep neural network},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Beyond NaN: Resiliency of optimization layers in the face of
infeasibility. <em>AAAI</em>, 15242–15250. (<a
href="https://doi.org/10.1609/aaai.v37i12.26778">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Prior work has successfully incorporated optimization layers as the last layer in neural networks for various problems, thereby allowing joint learning and planning in one neural network forward pass. In this work, we identify a weakness in such a set-up where inputs to the optimization layer lead to undefined output of the neural network. Such undefined decision outputs can lead to possible catastrophic outcomes in critical real time applications. We show that an adversary can cause such failures by forcing rank deficiency on the matrix fed to the optimization layer which results in the optimization failing to produce a solution. We provide a defense for the failure cases by controlling the condition number of the input matrix. We study the problem in the settings of synthetic data, Jigsaw Sudoku, and in speed planning for autonomous driving. We show that our proposed defense effectively prevents the framework from failing with undefined output. Finally, we surface a number of edge cases which lead to serious bugs in popular optimization solvers which can be abused as well.},
  archive   = {C_AAAI},
  author    = {Wai Tuck Wong and Sarah Kinsey and Ramesha Karunasena and Thanh H. Nguyen and Arunesh Sinha},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26778},
  pages     = {15242-15250},
  title     = {Beyond NaN: Resiliency of optimization layers in the face of infeasibility},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). HOTCOLD block: Fooling thermal infrared detectors with a
novel wearable design. <em>AAAI</em>, 15233–15241. (<a
href="https://doi.org/10.1609/aaai.v37i12.26777">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Adversarial attacks on thermal infrared imaging expose the risk of related applications. Estimating the security of these systems is essential for safely deploying them in the real world. In many cases, realizing the attacks in the physical space requires elaborate special perturbations. These solutions are often impractical and attention-grabbing. To address the need for a physically practical and stealthy adversarial attack, we introduce HotCold Block, a novel physical attack for infrared detectors that hide persons utilizing the wearable Warming Paste and Cooling Paste. By attaching these readily available temperature-controlled materials to the body, HotCold Block evades human eyes efficiently. Moreover, unlike existing methods that build adversarial patches with complex texture and structure features, HotCold Block utilizes an SSP-oriented adversarial optimization algorithm that enables attacks with pure color blocks and explores the influence of size, shape, and position on attack performance. Extensive experimental results in both digital and physical environments demonstrate the performance of our proposed HotCold Block. Code is available: https://github.com/weihui1308/HOTCOLDBlock.},
  archive   = {C_AAAI},
  author    = {Hui Wei and Zhixiang Wang and Xuemei Jia and Yinqiang Zheng and Hao Tang and Shin&#39;ichi Satoh and Zheng Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26777},
  pages     = {15233-15241},
  title     = {HOTCOLD block: Fooling thermal infrared detectors with a novel wearable design},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust graph meta-learning via manifold calibration with
proxy subgraphs. <em>AAAI</em>, 15224–15232. (<a
href="https://doi.org/10.1609/aaai.v37i12.26776">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph meta-learning has become a preferable paradigm for graph-based node classification with long-tail distribution, owing to its capability of capturing the intrinsic manifold of support and query nodes. Despite the remarkable success, graph meta-learning suffers from severe performance degradation when training on graph data with structural noise. In this work, we observe that the structural noise may impair the smoothness of the intrinsic manifold supporting the support and query nodes, leading to the poor transferable priori of the meta-learner. To address the issue, we propose a new approach for graph meta-learning that is robust against structural noise, called Proxy subgraph-based Manifold Calibration method (Pro-MC). Concretely, a subgraph generator is designed to generate proxy subgraphs that can calibrate the smoothness of the manifold. The proxy subgraph compromises two types of subgraphs with two biases, thus preventing the manifold from being rugged and straightforward. By doing so, our proposed meta-learner can obtain generalizable and transferable prior knowledge. In addition, we provide a theoretical analysis to illustrate the effectiveness of Pro-MC. Experimental results have demonstrated that our approach can achieve state-of-the-art performance under various structural noises.},
  archive   = {C_AAAI},
  author    = {Zhenzhong Wang and Lulu Cao and Wanyu Lin and Min Jiang and Kay Chen Tan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26776},
  pages     = {15224-15232},
  title     = {Robust graph meta-learning via manifold calibration with proxy subgraphs},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust average-reward markov decision processes.
<em>AAAI</em>, 15215–15223. (<a
href="https://doi.org/10.1609/aaai.v37i12.26775">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In robust Markov decision processes (MDPs), the uncertainty in the transition kernel is addressed by finding a policy that optimizes the worst-case performance over an uncertainty set of MDPs. While much of the literature has focused on discounted MDPs, robust average-reward MDPs remain largely unexplored. In this paper, we focus on robust average-reward MDPs, where the goal is to find a policy that optimizes the worst-case average reward over an uncertainty set. We first take an approach that approximates average-reward MDPs using discounted MDPs. We prove that the robust discounted value function converges to the robust average-reward as the discount factor goes to 1, and moreover when it is large, any optimal policy of the robust discounted MDP is also an optimal policy of the robust average-reward. We further design a robust dynamic programming approach, and theoretically characterize its convergence to the optimum. Then, we investigate robust average-reward MDPs directly without using discounted MDPs as an intermediate step. We derive the robust Bellman equation for robust average-reward MDPs, prove that the optimal policy can be derived from its solution, and further design a robust relative value iteration algorithm that provably finds its solution, or equivalently, the optimal robust policy.},
  archive   = {C_AAAI},
  author    = {Yue Wang and Alvaro Velasquez and George Atia and Ashley Prater-Bennette and Shaofeng Zou},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26775},
  pages     = {15215-15223},
  title     = {Robust average-reward markov decision processes},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Revisiting item promotion in GNN-based collaborative
filtering: A masked targeted topological attack perspective.
<em>AAAI</em>, 15206–15214. (<a
href="https://doi.org/10.1609/aaai.v37i12.26774">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph neural networks (GNN) based collaborative filtering (CF) has attracted increasing attention in e-commerce and financial marketing platforms. However, there still lack efforts to evaluate the robustness of such CF systems in deployment. Fundamentally different from existing attacks, this work revisits the item promotion task and reformulates it from a targeted topological attack perspective for the first time. Specifically, we first develop a targeted attack formulation to maximally increase a target item&#39;s popularity. We then leverage gradient-based optimizations to find a solution. However, we observe the gradient estimates often appear noisy due to the discrete nature of a graph, which leads to a degradation of attack ability. To resolve noisy gradient effects, we then propose a masked attack objective that can remarkably enhance the topological attack ability. Furthermore, we design a computationally efficient approach to the proposed attack, thus making it feasible to evaluate large-large CF systems. Experiments on two real-world datasets show the effectiveness of our attack in analyzing the robustness of GNN-based CF more practically.},
  archive   = {C_AAAI},
  author    = {Yongwei Wang and Yong Liu and Zhiqi Shen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26774},
  pages     = {15206-15214},
  title     = {Revisiting item promotion in GNN-based collaborative filtering: A masked targeted topological attack perspective},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Towards verifying the geometric robustness of large-scale
neural networks. <em>AAAI</em>, 15197–15205. (<a
href="https://doi.org/10.1609/aaai.v37i12.26773">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep neural networks (DNNs) are known to be vulnerable to adversarial geometric transformation. This paper aims to verify the robustness of large-scale DNNs against the combination of multiple geometric transformations with a provable guarantee. Given a set of transformations (e.g., rotation, scaling, etc.), we develop GeoRobust, a black-box robustness analyser built upon a novel global optimisation strategy, for locating the worst-case combination of transformations that affect and even alter a network&#39;s output. GeoRobust can provide provable guarantees on finding the worst-case combination based on recent advances in Lipschitzian theory. Due to its black-box nature, GeoRobust can be deployed on large-scale DNNs regardless of their architectures, activation functions, and the number of neurons. In practice, GeoRobust can locate the worst-case geometric transformation with high precision for the ResNet50 model on ImageNet in a few seconds on average. We examined 18 ImageNet classifiers, including the ResNet family and vision transformers, and found a positive correlation between the geometric robustness of the networks and the parameter numbers. We also observe that increasing the depth of DNN is more beneficial than increasing its width in terms of improving its geometric robustness. Our tool GeoRobust is available at https://github.com/TrustAI/GeoRobust.},
  archive   = {C_AAAI},
  author    = {Fu Wang and Peipei Xu and Wenjie Ruan and Xiaowei Huang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26773},
  pages     = {15197-15205},
  title     = {Towards verifying the geometric robustness of large-scale neural networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural policy safety verification via predicate abstraction:
CEGAR. <em>AAAI</em>, 15188–15196. (<a
href="https://doi.org/10.1609/aaai.v37i12.26772">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Neural networks (NN) are an increasingly important representation of action policies pi. Recent work has extended predicate abstraction to prove safety of such pi, through policy predicate abstraction (PPA) which over-approximates the state space subgraph induced by pi. The advantage of PPA is that reasoning about the NN – calls to SMT solvers – is required only locally, at individual abstract state transitions, in contrast to bounded model checking (BMC) where SMT must reason globally about sequences of NN decisions. Indeed, it has been shown that PPA can outperform a simple BMC implementation. However, the abstractions underlying these results (i.e., the abstraction predicates) were supplied manually. Here we automate this step. We extend counterexample guided abstraction refinement (CEGAR) to PPA. This involves dealing with a new source of spuriousness in abstract unsafe paths, pertaining not to transition behavior but to the decisions of the neural network pi. We introduce two methods tackling this issue based on the states involved, and we show that global SMT calls deciding spuriousness exactly can be avoided. We devise algorithmic enhancements leveraging incremental computation and heuristic search. We show empirically that the resulting verification tool has significant advantages over an encoding into the state-of-the-art model checker nuXmv. In particular, ours is the only approach in our experiments that succeeds in proving policies safe.},
  archive   = {C_AAAI},
  author    = {Marcel Vinzent and Siddhant Sharma and Jöerg Hoffmann},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26772},
  pages     = {15188-15196},
  title     = {Neural policy safety verification via predicate abstraction: CEGAR},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Conflicting interactions among protection mechanisms for
machine learning models. <em>AAAI</em>, 15179–15187. (<a
href="https://doi.org/10.1609/aaai.v37i12.26771">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Nowadays, systems based on machine learning (ML) are widely used in different domains. Given their popularity, ML models have become targets for various attacks. As a result, research at the intersection of security/privacy and ML has flourished. Typically such work has focused on individual types of security/privacy concerns and mitigations thereof. However, in real-life deployments, an ML model will need to be protected against several concerns simultaneously. A protection mechanism optimal for a specific security or privacy concern may interact negatively with mechanisms intended to address other concerns. Despite its practical relevance, the potential for such conflicts has not been studied adequately. In this work, we first provide a framework for analyzing such conflicting interactions. We then focus on systematically analyzing pairwise interactions between protection mechanisms for one concern, model and data ownership verification, with two other classes of ML protection mechanisms: differentially private training, and robustness against model evasion. We find that several pairwise interactions result in conflicts. We also explore potential approaches for avoiding such conflicts. First, we study the effect of hyperparameter relaxations, finding that there is no sweet spot balancing the performance of both protection mechanisms. Second, we explore whether modifying one type of protection mechanism (ownership verification) so as to decouple it from factors that may be impacted by a conflicting mechanism (differentially private training or robustness to model evasion) can avoid conflict. We show that this approach can indeed avoid the conflict between ownership verification mechanisms when combined with differentially private training, but has no effect on robustness to model evasion. We conclude by identifying the gaps in the landscape of studying interactions between other types of ML protection mechanisms.},
  archive   = {C_AAAI},
  author    = {Sebastian Szyller and N. Asokan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26771},
  pages     = {15179-15187},
  title     = {Conflicting interactions among protection mechanisms for machine learning models},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DPAUC: Differentially private AUC computation in federated
learning. <em>AAAI</em>, 15170–15178. (<a
href="https://doi.org/10.1609/aaai.v37i12.26770">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Federated learning (FL) has gained significant attention recently as a privacy-enhancing tool to jointly train a machine learning model by multiple participants. The prior work on FL has mostly studied how to protect label privacy during model training. However, model evaluation in FL might also lead to the potential leakage of private label information. In this work, we propose an evaluation algorithm that can accurately compute the widely used AUC (area under the curve) metric when using the label differential privacy (DP) in FL. Through extensive experiments, we show our algorithms can compute accurate AUCs compared to the ground truth. The code is available at https://github.com/bytedance/fedlearner/tree/master/example/privacy/DPAUC},
  archive   = {C_AAAI},
  author    = {Jiankai Sun and Xin Yang and Yuanshun Yao and Junyuan Xie and Di Wu and Chong Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26770},
  pages     = {15170-15178},
  title     = {DPAUC: Differentially private AUC computation in federated learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving robust fariness via balance adversarial training.
<em>AAAI</em>, 15161–15169. (<a
href="https://doi.org/10.1609/aaai.v37i12.26769">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Adversarial training (AT) methods are effective against adversarial attacks, yet they introduce severe disparity of accuracy and robustness between different classes, known as the robust fairness problem. Previously proposed Fair Robust Learning (FRL) adaptively reweights different classes to improve fairness. However, the performance of the better-performed classes decreases, leading to a strong performance drop. In this paper, we observed two unfair phenomena during adversarial training: different difficulties in generating adversarial examples from each class (source-class fairness) and disparate target class tendencies when generating adversarial examples (target-class fairness). From the observations, we propose Balance Adversarial Training (BAT) to address the robust fairness problem. Regarding source-class fairness, we adjust the attack strength and difficulties of each class to generate samples near the decision boundary for easier and fairer model learning; considering target-class fairness, by introducing a uniform distribution constraint, we encourage the adversarial example generation process for each class with a fair tendency. Extensive experiments conducted on multiple datasets (CIFAR-10, CIFAR-100, and ImageNette) demonstrate that our BAT can significantly outperform other baselines in mitigating the robust fairness problem (+5-10\% on the worst class accuracy)(Our codes can be found at https://github.com/silvercherry/Improving-Robust-Fairness-via-Balance-Adversarial-Training).},
  archive   = {C_AAAI},
  author    = {Chunyu Sun and Chenye Xu and Chengyuan Yao and Siyuan Liang and Yichao Wu and Ding Liang and Xianglong Liu and Aishan Liu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26769},
  pages     = {15161-15169},
  title     = {Improving robust fariness via balance adversarial training},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Toward robust uncertainty estimation with random activation
functions. <em>AAAI</em>, 15152–15160. (<a
href="https://doi.org/10.1609/aaai.v37i12.26768">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep neural networks are in the limelight of machine learning with their excellent performance in many data-driven applications. However, they can lead to inaccurate predictions when queried in out-of-distribution data points, which can have detrimental effects especially in sensitive domains, such as healthcare and transportation, where erroneous predictions can be very costly and/or dangerous. Subsequently, quantifying the uncertainty of the output of a neural network is often leveraged to evaluate the confidence of its predictions, and ensemble models have proved to be effective in measuring the uncertainty by utilizing the variance of predictions over a pool of models. In this paper, we propose a novel approach for uncertainty quantification via ensembles, called Random Activation Functions (RAFs) Ensemble, that aims at improving the ensemble diversity toward a more robust estimation, by accommodating each neural network with a different (random) activation function. Extensive empirical study demonstrates that RAFs Ensemble outperforms state-of-the-art ensemble uncertainty quantification methods on both synthetic and real-world datasets in a series of regression tasks.},
  archive   = {C_AAAI},
  author    = {Yana Stoyanova and Soroush Ghandi and Maryam Tavakol},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26768},
  pages     = {15152-15160},
  title     = {Toward robust uncertainty estimation with random activation functions},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Planning and learning for non-markovian negative side
effects using finite state controllers. <em>AAAI</em>, 15144–15151. (<a
href="https://doi.org/10.1609/aaai.v37i12.26767">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Autonomous systems are often deployed in the open world where it is hard to obtain complete specifications of objectives and constraints. Operating based on an incomplete model can produce negative side effects (NSEs), which affect the safety and reliability of the system. We focus on mitigating NSEs in environments modeled as Markov decision processes (MDPs). First, we learn a model of NSEs using observed data that contains state-action trajectories and severity of associated NSEs. Unlike previous works that associate NSEs with state-action pairs, our framework associates NSEs with entire trajectories, which is more general and captures non-Markovian dependence on states and actions. Second, we learn finite state controllers (FSCs) that predict NSE severity for a given trajectory and generalize well to unseen data. Finally, we develop a constrained MDP model that uses information from the underlying MDP and the learned FSC for planning while avoiding NSEs. Our empirical evaluation demonstrates the effectiveness of our approach in learning and mitigating Markovian and non-Markovian NSEs.},
  archive   = {C_AAAI},
  author    = {Aishwarya Srivastava and Sandhya Saisubramanian and Praveen Paruchuri and Akshat Kumar and Shlomo Zilberstein},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26767},
  pages     = {15144-15151},
  title     = {Planning and learning for non-markovian negative side effects using finite state controllers},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Misspecification in inverse reinforcement learning.
<em>AAAI</em>, 15136–15143. (<a
href="https://doi.org/10.1609/aaai.v37i12.26766">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The aim of Inverse Reinforcement Learning (IRL) is to infer a reward function R from a policy pi. To do this, we need a model of how pi relates to R. In the current literature, the most common models are optimality, Boltzmann rationality, and causal entropy maximisation. One of the primary motivations behind IRL is to infer human preferences from human behaviour. However, the true relationship between human preferences and human behaviour is much more complex than any of the models currently used in IRL. This means that they are misspecified, which raises the worry that they might lead to unsound inferences if applied to real-world data. In this paper, we provide a mathematical analysis of how robust different IRL models are to misspecification, and answer precisely how the demonstrator policy may differ from each of the standard models before that model leads to faulty inferences about the reward function R. We also introduce a framework for reasoning about misspecification in IRL, together with formal tools that can be used to easily derive the misspecification robustness of new IRL models.},
  archive   = {C_AAAI},
  author    = {Joar Skalse and Alessandro Abate},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26766},
  pages     = {15136-15143},
  title     = {Misspecification in inverse reinforcement learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Understanding and enhancing robustness of concept-based
models. <em>AAAI</em>, 15127–15135. (<a
href="https://doi.org/10.1609/aaai.v37i12.26765">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Rising usage of deep neural networks to perform decision making in critical applications like medical diagnosis and fi- nancial analysis have raised concerns regarding their reliability and trustworthiness. As automated systems become more mainstream, it is important their decisions be transparent, reliable and understandable by humans for better trust and confidence. To this effect, concept-based models such as Concept Bottleneck Models (CBMs) and Self-Explaining Neural Networks (SENN) have been proposed which constrain the latent space of a model to represent high level concepts easily understood by domain experts in the field. Although concept-based models promise a good approach to both increasing explainability and reliability, it is yet to be shown if they demonstrate robustness and output consistent concepts under systematic perturbations to their inputs. To better understand performance of concept-based models on curated malicious samples, in this paper, we aim to study their robustness to adversarial perturbations, which are also known as the imperceptible changes to the input data that are crafted by an attacker to fool a well-learned concept-based model. Specifically, we first propose and analyze different malicious attacks to evaluate the security vulnerability of concept based models. Subsequently, we propose a potential general adversarial training-based defense mechanism to increase robustness of these systems to the proposed malicious attacks. Extensive experiments on one synthetic and two real-world datasets demonstrate the effectiveness of the proposed attacks and the defense approach. An appendix of the paper with more comprehensive results can also be viewed at https://arxiv.org/abs/2211.16080.},
  archive   = {C_AAAI},
  author    = {Sanchit Sinha and Mengdi Huai and Jianhui Sun and Aidong Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26765},
  pages     = {15127-15135},
  title     = {Understanding and enhancing robustness of concept-based models},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). STL-based synthesis of feedback controllers using
reinforcement learning. <em>AAAI</em>, 15118–15126. (<a
href="https://doi.org/10.1609/aaai.v37i12.26764">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep Reinforcement Learning (DRL) has the potential to be used for synthesizing feedback controllers (agents) for various complex systems with unknown dynamics. These systems are expected to satisfy diverse safety and liveness properties best captured using temporal logic. In RL, the reward function plays a crucial role in specifying the desired behaviour of these agents. However, the problem of designing the reward function for an RL agent to satisfy complex temporal logic specifications has received limited attention in the literature. To address this, we provide a systematic way of generating rewards in real-time by using the quantitative semantics of Signal Temporal Logic (STL), a widely used temporal logic to specify the behaviour of cyber-physical systems. We propose a new quantitative semantics for STL having several desirable properties, making it suitable for reward generation. We evaluate our STL-based reinforcement learning mechanism on several complex continuous control benchmarks and compare our STL semantics with those available in the literature in terms of their efficacy in synthesizing the controller agent. Experimental results establish our new semantics to be the most suitable for synthesizing feedback controllers for complex continuous dynamical systems through reinforcement learning.},
  archive   = {C_AAAI},
  author    = {Nikhil Kumar Singh and Indranil Saha},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26764},
  pages     = {15118-15126},
  title     = {STL-based synthesis of feedback controllers using reinforcement learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Safe policy improvement for POMDPs via finite-state
controllers. <em>AAAI</em>, 15109–15117. (<a
href="https://doi.org/10.1609/aaai.v37i12.26763">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study safe policy improvement (SPI) for partially observable Markov decision processes (POMDPs). SPI is an offline reinforcement learning (RL) problem that assumes access to (1) historical data about an environment, and (2) the so-called behavior policy that previously generated this data by interacting with the environment. SPI methods neither require access to a model nor the environment itself, and aim to reliably improve upon the behavior policy in an offline manner. Existing methods make the strong assumption that the environment is fully observable. In our novel approach to the SPI problem for POMDPs, we assume that a finite-state controller (FSC) represents the behavior policy and that finite memory is sufficient to derive optimal policies. This assumption allows us to map the POMDP to a finite-state fully observable MDP, the history MDP. We estimate this MDP by combining the historical data and the memory of the FSC, and compute an improved policy using an off-the-shelf SPI algorithm. The underlying SPI method constrains the policy space according to the available data, such that the newly computed policy only differs from the behavior policy when sufficient data is available. We show that this new policy, converted into a new FSC for the (unknown) POMDP, outperforms the behavior policy with high probability. Experimental results on several well-established benchmarks show the applicability of the approach, even in cases where finite memory is not sufficient.},
  archive   = {C_AAAI},
  author    = {Thiago D. Simão and Marnix Suilen and Nils Jansen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26763},
  pages     = {15109-15117},
  title     = {Safe policy improvement for POMDPs via finite-state controllers},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust sequence networked submodular maximization.
<em>AAAI</em>, 15100–15108. (<a
href="https://doi.org/10.1609/aaai.v37i12.26762">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we study the Robust optimization for sequence Networked submodular maximization (RoseNets) problem. We interweave the robust optimization with the sequence networked submodular maximization. The elements are connected by a directed acyclic graph and the objective function is not submodular on the elements but on the edges in the graph. Under such networked submodular scenario, the impact of removing an element from a sequence depends both on its position in the sequence and in the network. This makes the existing robust algorithms inapplicable and calls for new robust algorithms. In this paper, we take the first step to study the RoseNets problem. We design a robust greedy algorithms, which is robust against the removal of an arbitrary subset of the selected elements. The approximation ratio of the algorithm depends both on the number of the removed elements and the network topology. We further conduct experiments on real applications of recommendation and link prediction. The experimental results demonstrate the effectiveness of the proposed algorithm.},
  archive   = {C_AAAI},
  author    = {Qihao Shi and Bingyang Fu and Can Wang and Jiawei Chen and Sheng Zhou and Yan Feng and Chun Chen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26762},
  pages     = {15100-15108},
  title     = {Robust sequence networked submodular maximization},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Task and model agnostic adversarial attack on graph neural
networks. <em>AAAI</em>, 15091–15099. (<a
href="https://doi.org/10.1609/aaai.v37i12.26761">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Adversarial attacks on Graph Neural Networks (GNNs) reveal their security vulnerabilities, limiting their adoption in safety-critical applications. However, existing attack strategies rely on the knowledge of either the GNN model being used or the predictive task being attacked. Is this knowledge necessary? For example, a graph may be used for multiple downstream tasks unknown to a practical attacker. It is thus important to test the vulnerability of GNNs to adversarial perturbations in a model and task-agnostic setting. In this work, we study this problem and show that Gnns remain vulnerable even when the downstream task and model are unknown. The proposed algorithm, TANDIS (Targeted Attack via Neighborhood DIStortion) shows that distortion of node neighborhoods is effective in drastically compromising prediction performance. Although neighborhood distortion is an NP-hard problem, TANDIS designs an effective heuristic through a novel combination of Graph Isomorphism Network with deep Q-learning. Extensive experiments on real datasets show that, on average, TANDIS is up to 50\% more effective than state-of-the-art techniques, while being more than 1000 times faster.},
  archive   = {C_AAAI},
  author    = {Kartik Sharma and Samidha Verma and Sourav Medya and Arnab Bhattacharya and Sayan Ranu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26761},
  pages     = {15091-15099},
  title     = {Task and model agnostic adversarial attack on graph neural networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving training and inference of face recognition models
via random temperature scaling. <em>AAAI</em>, 15082–15090. (<a
href="https://doi.org/10.1609/aaai.v37i12.26760">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Data uncertainty is commonly observed in the images for face recognition (FR). However, deep learning algorithms often make predictions with high confidence even for uncertain or irrelevant inputs. Intuitively, FR algorithms can benefit from both the estimation of uncertainty and the detection of out-of-distribution (OOD) samples. Taking a probabilistic view of the current classification model, the temperature scalar is exactly the scale of uncertainty noise implicitly added in the softmax function. Meanwhile, the uncertainty of images in a dataset should follow a prior distribution. Based on the observation, a unified framework for uncertainty modeling and FR, Random Temperature Scaling (RTS), is proposed to learn a reliable FR algorithm. The benefits of RTS are two-fold. (1) In the training phase, it can adjust the learning strength of clean and noisy samples for stability and accuracy. (2) In the test phase, it can provide a score of confidence to detect uncertain, low-quality and even OOD samples, without training on extra labels. Extensive experiments on FR benchmarks demonstrate that the magnitude of variance in RTS, which serves as an OOD detection metric, is closely related to the uncertainty of the input image. RTS can achieve top performance on both the FR and OOD detection tasks. Moreover, the model trained with RTS can perform robustly on datasets with noise. The proposed module is light-weight and only adds negligible computation cost to the model.},
  archive   = {C_AAAI},
  author    = {Lei Shang and Mouxiao Huang and Wu Shi and Yuchen Liu and Yang Liu and Wang Steven and Baigui Sun and Xuansong Xie and Yu Qiao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26760},
  pages     = {15082-15090},
  title     = {Improving training and inference of face recognition models via random temperature scaling},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Formally verified solution methods for markov decision
processes. <em>AAAI</em>, 15073–15081. (<a
href="https://doi.org/10.1609/aaai.v37i12.26759">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We formally verify executable algorithms for solving Markov decision processes (MDPs) in the interactive theorem prover Isabelle/HOL. We build on existing formalizations of probability theory to analyze the expected total reward criterion on finite and infinite-horizon problems. Our developments formalize the Bellman equation and give conditions under which optimal policies exist. Based on this analysis, we verify dynamic programming algorithms to solve tabular MDPs. We evaluate the formally verified implementations experimentally on standard problems, compare them with state-of-the-art systems, and show that they are practical.},
  archive   = {C_AAAI},
  author    = {Maximilian Schäffeler and Mohammad Abdulaziz},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26759},
  pages     = {15073-15081},
  title     = {Formally verified solution methods for markov decision processes},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Defending from physically-realizable adversarial attacks
through internal over-activation analysis. <em>AAAI</em>, 15064–15072.
(<a href="https://doi.org/10.1609/aaai.v37i12.26758">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This work presents Z-Mask, an effective and deterministic strategy to improve the adversarial robustness of convolutional networks against physically-realizable adversarial attacks. The presented defense relies on specific Z-score analysis performed on the internal network features to detect and mask the pixels corresponding to adversarial objects in the input image. To this end, spatially contiguous activations are examined in shallow and deep layers to suggest potential adversarial regions. Such proposals are then aggregated through a multi-thresholding mechanism. The effectiveness of Z-Mask is evaluated with an extensive set of experiments carried out on models for semantic segmentation and object detection. The evaluation is performed with both digital patches added to the input images and printed patches in the real world. The results confirm that Z-Mask outperforms the state-of-the-art methods in terms of detection accuracy and overall performance of the networks under attack. Furthermore, Z-Mask preserves its robustness against defense-aware attacks, making it suitable for safe and secure AI applications.},
  archive   = {C_AAAI},
  author    = {Giulio Rossolini and Federico Nesti and Fabio Brau and Alessandro Biondi and Giorgio Buttazzo},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26758},
  pages     = {15064-15072},
  title     = {Defending from physically-realizable adversarial attacks through internal over-activation analysis},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Constrained reinforcement learning in hard exploration
problems. <em>AAAI</em>, 15055–15063. (<a
href="https://doi.org/10.1609/aaai.v37i12.26757">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {One approach to guaranteeing safety in Reinforcement Learning is through cost constraints that are dependent on the policy. Recent works in constrained RL have developed methods that ensure constraints are enforced even at learning time while maximizing the overall value of the policy. Unfortunately, as demonstrated in our experimental results, such approaches do not perform well on complex multi-level tasks, with longer episode lengths or sparse rewards. To that end, we propose a scalable hierarchical approach for constrained RL problems that employs backward cost value functions in the context of task hierarchy and a novel intrinsic reward function in lower levels of the hierarchy to enable cost constraint enforcement. One of our key contributions is in proving that backward value functions are theoretically viable even when there are multiple levels of decision making. We also show that our new approach, referred to as Hierarchically Limited consTraint Enforcement (HiLiTE) significantly improves on state of the art Constrained RL approaches for many benchmark problems from literature. We further demonstrate that this performance (on value and constraint enforcement) clearly outperforms existing best approaches for constrained RL and hierarchical RL.},
  archive   = {C_AAAI},
  author    = {Pathmanathan Pankayaraj and Pradeep Varakantham},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26757},
  pages     = {15055-15063},
  title     = {Constrained reinforcement learning in hard exploration problems},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Certified policy smoothing for cooperative multi-agent
reinforcement learning. <em>AAAI</em>, 15046–15054. (<a
href="https://doi.org/10.1609/aaai.v37i12.26756">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Cooperative multi-agent reinforcement learning (c-MARL) is widely applied in safety-critical scenarios, thus the analysis of robustness for c-MARL models is profoundly important. However, robustness certification for c-MARLs has not yet been explored in the community. In this paper, we propose a novel certification method, which is the first work to leverage a scalable approach for c-MARLs to determine actions with guaranteed certified bounds. c-MARL certification poses two key challenges compared to single-agent systems: (i) the accumulated uncertainty as the number of agents increases; (ii) the potential lack of impact when changing the action of a single agent into a global team reward. These challenges prevent us from directly using existing algorithms. Hence, we employ the false discovery rate (FDR) controlling procedure considering the importance of each agent to certify per-state robustness. We further propose a tree-search-based algorithm to find a lower bound of the global reward under the minimal certified perturbation. As our method is general, it can also be applied in a single-agent environment. We empirically show that our certification bounds are much tighter than those of state-of-the-art RL certification solutions. We also evaluate our method on two popular c-MARL algorithms: QMIX and VDN, under two different environments, with two and four agents. The experimental results show that our method can certify the robustness of all c-MARL models in various environments. Our tool CertifyCMARL is available at https://github.com/TrustAI/CertifyCMARL.},
  archive   = {C_AAAI},
  author    = {Ronghui Mu and Wenjie Ruan and Leandro Soriano Marcolino and Gaojie Jin and Qiang Ni},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26756},
  pages     = {15046-15054},
  title     = {Certified policy smoothing for cooperative multi-agent reinforcement learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Monitoring model deterioration with explainable uncertainty
estimation via non-parametric bootstrap. <em>AAAI</em>, 15037–15045. (<a
href="https://doi.org/10.1609/aaai.v37i12.26755">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Monitoring machine learning models once they are deployed is challenging. It is even more challenging to decide when to retrain models in real-case scenarios when labeled data is beyond reach, and monitoring performance metrics becomes unfeasible. In this work, we use non-parametric bootstrapped uncertainty estimates and SHAP values to provide explainable uncertainty estimation as a technique that aims to monitor the deterioration of machine learning models in deployment environments, as well as determine the source of model deteri- oration when target labels are not available. Classical methods are purely aimed at detecting distribution shift, which can lead to false positives in the sense that the model has not deterio- rated despite a shift in the data distribution. To estimate model uncertainty we construct prediction intervals using a novel bootstrap method, which improves previous state-of-the-art work. We show that both our model deterioration detection system as well as our uncertainty estimation method achieve better performance than the current state-of-the-art. Finally, we use explainable AI techniques to gain an understanding of the drivers of model deterioration. We release an open source Python package, doubt, which implements our pro- posed methods, as well as the code used to reproduce our experiments.},
  archive   = {C_AAAI},
  author    = {Carlos Mougan and Dan Saattrup Nielsen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26755},
  pages     = {15037-15045},
  title     = {Monitoring model deterioration with explainable uncertainty estimation via non-parametric bootstrap},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Anonymization for skeleton action recognition.
<em>AAAI</em>, 15028–15036. (<a
href="https://doi.org/10.1609/aaai.v37i12.26754">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Skeleton-based action recognition attracts practitioners and researchers due to the lightweight, compact nature of datasets. Compared with RGB-video-based action recognition, skeleton-based action recognition is a safer way to protect the privacy of subjects while having competitive recognition performance. However, due to improvements in skeleton recognition algorithms as well as motion and depth sensors, more details of motion characteristics can be preserved in the skeleton dataset, leading to potential privacy leakage. We first train classifiers to categorize private information from skeleton trajectories to investigate the potential privacy leakage from skeleton datasets. Our preliminary experiments show that the gender classifier achieves 87\% accuracy on average, and the re-identification classifier achieves 80\% accuracy on average with three baseline models: Shift-GCN, MS-G3D, and 2s-AGCN. We propose an anonymization framework based on adversarial learning to protect potential privacy leakage from the skeleton dataset. Experimental results show that an anonymized dataset can reduce the risk of privacy leakage while having marginal effects on action recognition performance even with simple anonymizer architectures. The code used in our experiments is available at https://github.com/ml-postech/Skeleton-anonymization/},
  archive   = {C_AAAI},
  author    = {Saemi Moon and Myeonghyeon Kim and Zhenyue Qin and Yang Liu and Dongwoo Kim},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26754},
  pages     = {15028-15036},
  title     = {Anonymization for skeleton action recognition},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A risk-sensitive approach to policy optimization.
<em>AAAI</em>, 15019–15027. (<a
href="https://doi.org/10.1609/aaai.v37i12.26753">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Standard deep reinforcement learning (DRL) aims to maximize expected reward, considering collected experiences equally in formulating a policy. This differs from human decision-making, where gains and losses are valued differently and outlying outcomes are given increased consideration. It also fails to capitalize on opportunities to improve safety and/or performance through the incorporation of distributional context. Several approaches to distributional DRL have been investigated, with one popular strategy being to evaluate the projected distribution of returns for possible actions. We propose a more direct approach whereby risk-sensitive objectives, specified in terms of the cumulative distribution function (CDF) of the distribution of full-episode rewards, are optimized. This approach allows for outcomes to be weighed based on relative quality, can be used for both continuous and discrete action spaces, and may naturally be applied in both constrained and unconstrained settings. We show how to compute an asymptotically consistent estimate of the policy gradient for a broad class of risk-sensitive objectives via sampling, subsequently incorporating variance reduction and regularization measures to facilitate effective on-policy learning. We then demonstrate that the use of moderately &quot;pessimistic&quot; risk profiles, which emphasize scenarios where the agent performs poorly, leads to enhanced exploration and a continual focus on addressing deficiencies. We test the approach using different risk profiles in six OpenAI Safety Gym environments, comparing to state of the art on-policy methods. Without cost constraints, we find that pessimistic risk profiles can be used to reduce cost while improving total reward accumulation. With cost constraints, they are seen to provide higher positive rewards than risk-neutral approaches at the prescribed allowable cost.},
  archive   = {C_AAAI},
  author    = {Jared Markowitz and Ryan W. Gardner and Ashley Llorens and Raman Arora and I-Jeng Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26753},
  pages     = {15019-15027},
  title     = {A risk-sensitive approach to policy optimization},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A holistic approach to undesired content detection in the
real world. <em>AAAI</em>, 15009–15018. (<a
href="https://doi.org/10.1609/aaai.v37i12.26752">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present a holistic approach to building a robust and useful natural language classification system for real-world content moderation. The success of such a system relies on a chain of carefully designed and executed steps, including the design of content taxonomies and labeling instructions, data quality control, an active learning pipeline to capture rare events, and a variety of methods to make the model robust and to avoid overfitting. Our moderation system is trained to detect a broad set of categories of undesired content, including sexual content, hateful content, violence, self-harm, and harassment. This approach generalizes to a wide range of different content taxonomies and can be used to create high-quality content classifiers that outperform off-the-shelf models.},
  archive   = {C_AAAI},
  author    = {Todor Markov and Chong Zhang and Sandhini Agarwal and Florentine Eloundou Nekoul and Theodore Lee and Steven Adler and Angela Jiang and Lilian Weng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26752},
  pages     = {15009-15018},
  title     = {A holistic approach to undesired content detection in the real world},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Rethinking label refurbishment: Model robustness under label
noise. <em>AAAI</em>, 15000–15008. (<a
href="https://doi.org/10.1609/aaai.v37i12.26751">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A family of methods that generate soft labels by mixing the hard labels with a certain distribution, namely label refurbishment, are widely used to train deep neural networks. However, some of these methods are still poorly understood in the presence of label noise. In this paper, we revisit four label refurbishment methods and reveal the strong connection between them. We find that they affect the neural network models in different manners. Two of them smooth the estimated posterior for regularization effects, and the other two force the model to produce high-confidence predictions. We conduct extensive experiments to evaluate related methods and observe that both effects improve the model generalization under label noise. Furthermore, we theoretically show that both effects lead to generalization guarantees on the clean distribution despite being trained with noisy labels.},
  archive   = {C_AAAI},
  author    = {Yangdi Lu and Zhiwei Xu and Wenbo He},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26751},
  pages     = {15000-15008},
  title     = {Rethinking label refurbishment: Model robustness under label noise},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PLMmark: A secure and robust black-box watermarking
framework for pre-trained language models. <em>AAAI</em>, 14991–14999.
(<a href="https://doi.org/10.1609/aaai.v37i12.26750">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The huge training overhead, considerable commercial value, and various potential security risks make it urgent to protect the intellectual property (IP) of Deep Neural Networks (DNNs). DNN watermarking has become a plausible method to meet this need. However, most of the existing watermarking schemes focus on image classification tasks. The schemes designed for the textual domain lack security and reliability. Moreover, how to protect the IP of widely-used pre-trained language models (PLMs) remains a blank. To fill these gaps, we propose PLMmark, the first secure and robust black-box watermarking framework for PLMs. It consists of three phases: (1) In order to generate watermarks that contain owners’ identity information, we propose a novel encoding method to establish a strong link between a digital signature and trigger words by leveraging the original vocabulary tables of PLMs. Combining this with public key cryptography ensures the security of our scheme. (2) To embed robust, task-agnostic, and highly transferable watermarks in PLMs, we introduce a supervised contrastive loss to deviate the output representations of trigger sets from that of clean samples. In this way, the watermarked models will respond to the trigger sets anomaly and thus can identify the ownership. (3) To make the model ownership verification results reliable, we perform double verification, which guarantees the unforgeability of ownership. Extensive experiments on text classification tasks demonstrate that the embedded watermark can transfer to all the downstream tasks and can be effectively extracted and verified. The watermarking scheme is robust to watermark removing attacks (fine-pruning and re-initializing) and is secure enough to resist forgery attacks.},
  archive   = {C_AAAI},
  author    = {Peixuan Li and Pengzhou Cheng and Fangqi Li and Wei Du and Haodong Zhao and Gongshen Liu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26750},
  pages     = {14991-14999},
  title     = {PLMmark: A secure and robust black-box watermarking framework for pre-trained language models},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). WAT: Improve the worst-class robustness in adversarial
training. <em>AAAI</em>, 14982–14990. (<a
href="https://doi.org/10.1609/aaai.v37i12.26749">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep Neural Networks (DNN) have been shown to be vulnerable to adversarial examples. Adversarial training (AT) is a popular and effective strategy to defend against adversarial attacks. Recent works have shown that a robust model well-trained by AT exhibits a remarkable robustness disparity among classes, and propose various methods to obtain consistent robust accuracy across classes. Unfortunately, these methods sacrifice a good deal of the average robust accuracy. Accordingly, this paper proposes a novel framework of worst-class adversarial training and leverages no-regret dynamics to solve this problem. Our goal is to obtain a classifier with great performance on worst-class and sacrifice just a little average robust accuracy at the same time. We then rigorously analyze the theoretical properties of our proposed algorithm, and the generalization error bound in terms of the worst-class robust risk. Furthermore, we propose a measurement to evaluate the proposed method in terms of both the average and worst-class accuracies. Experiments on various datasets and networks show that our proposed method outperforms the state-of-the-art approaches.},
  archive   = {C_AAAI},
  author    = {Boqi Li and Weiwei Liu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26749},
  pages     = {14982-14990},
  title     = {WAT: Improve the worst-class robustness in adversarial training},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Revisiting the importance of amplifying bias for debiasing.
<em>AAAI</em>, 14974–14981. (<a
href="https://doi.org/10.1609/aaai.v37i12.26748">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In image classification, debiasing aims to train a classifier to be less susceptible to dataset bias, the strong correlation between peripheral attributes of data samples and a target class. For example, even if the frog class in the dataset mainly consists of frog images with a swamp background (i.e., bias aligned samples), a debiased classifier should be able to correctly classify a frog at a beach (i.e., bias conflicting samples). Recent debiasing approaches commonly use two components for debiasing, a biased model fB and a debiased model fD. fB is trained to focus on bias aligned samples (i.e., overfitted to the bias) while fD is mainly trained with bias conflicting samples by concentrating on samples which fB fails to learn, leading fD to be less susceptible to the dataset bias. While the state of the art debiasing techniques have aimed to better train fD, we focus on training fB, an overlooked component until now. Our empirical analysis reveals that removing the bias conflicting samples from the training set for fB is important for improving the debiasing performance of fD. This is due to the fact that the bias conflicting samples work as noisy samples for amplifying the bias for fB since those samples do not include the bias attribute. To this end, we propose a simple yet effective data sample selection method which removes the bias conflicting samples to construct a bias amplified dataset for training fB. Our data sample selection method can be directly applied to existing reweighting based debiasing approaches, obtaining consistent performance boost and achieving the state of the art performance on both synthetic and real-world datasets.},
  archive   = {C_AAAI},
  author    = {Jungsoo Lee and Jeonghoon Park and Daeyoung Kim and Juyoung Lee and Edward Choi and Jaegul Choo},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26748},
  pages     = {14974-14981},
  title     = {Revisiting the importance of amplifying bias for debiasing},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Quantization-aware interval bound propagation for training
certifiably robust quantized neural networks. <em>AAAI</em>,
14964–14973. (<a
href="https://doi.org/10.1609/aaai.v37i12.26747">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the problem of training and certifying adversarially robust quantized neural networks (QNNs). Quantization is a technique for making neural networks more efficient by running them using low-bit integer arithmetic and is therefore commonly adopted in industry. Recent work has shown that floating-point neural networks that have been verified to be robust can become vulnerable to adversarial attacks after quantization, and certification of the quantized representation is necessary to guarantee robustness. In this work, we present quantization-aware interval bound propagation (QA-IBP), a novel method for training robust QNNs. Inspired by advances in robust learning of non-quantized networks, our training algorithm computes the gradient of an abstract representation of the actual network. Unlike existing approaches, our method can handle the discrete semantics of QNNs. Based on QA-IBP, we also develop a complete verification procedure for verifying the adversarial robustness of QNNs, which is guaranteed to terminate and produce a correct answer. Compared to existing approaches, the key advantage of our verification procedure is that it runs entirely on GPU or other accelerator devices. We demonstrate experimentally that our approach significantly outperforms existing methods and establish the new state-of-the-art for training and certifying the robustness of QNNs.},
  archive   = {C_AAAI},
  author    = {Mathias Lechner and Đorđe Žikelić and Krishnendu Chatterjee and Thomas A. Henzinger and Daniela Rus},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26747},
  pages     = {14964-14973},
  title     = {Quantization-aware interval bound propagation for training certifiably robust quantized neural networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust image steganography: Hiding messages in frequency
coefficients. <em>AAAI</em>, 14955–14963. (<a
href="https://doi.org/10.1609/aaai.v37i12.26746">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Steganography is a technique that hides secret messages into a public multimedia object without raising suspicion from third parties. However, most existing works cannot provide good robustness against lossy JPEG compression while maintaining a relatively large embedding capacity. This paper presents an end-to-end robust steganography system based on the invertible neural network (INN). Instead of hiding in the spatial domain, our method directly hides secret messages into the discrete cosine transform (DCT) coefficients of the cover image, which significantly improves the robustness and anti-steganalysis security. A mutual information loss is first proposed to constrain the flow of information in INN. Besides, a two-way fusion module (TWFM) is implemented, utilizing spatial and DCT domain features as auxiliary information to facilitate message extraction. These two designs aid in recovering secret messages from the DCT coefficients losslessly. Experimental results demonstrate that our method yields significantly lower error rates than other existing hiding methods. For example, our method achieves reliable extraction with 0 error rate for 1 bit per pixel (bpp) embedding payload; and under the JPEG compression with quality factor QF=10, the error rate of our method is about 22\% lower than the state-of-the-art robust image hiding methods, which demonstrates remarkable robustness against JPEG compression.},
  archive   = {C_AAAI},
  author    = {Yuhang Lan and Fei Shang and Jianhua Yang and Xiangui Kang and Enping Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26746},
  pages     = {14955-14963},
  title     = {Robust image steganography: Hiding messages in frequency coefficients},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A semidefinite relaxation based branch-and-bound method for
tight neural network verification. <em>AAAI</em>, 14946–14954. (<a
href="https://doi.org/10.1609/aaai.v37i12.26745">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We introduce a novel method based on semidefinite program (SDP) for the tight and efficient verification of neural networks. The proposed SDP relaxation advances the present state of the art in SDP-based neural network verification by adding a set of linear constraints based on eigenvectors. We extend this novel SDP relaxation by combining it with a branch-and-bound method that can provably close the relaxation gap up to zero. We show formally that the proposed approach leads to a provably tighter solution than the present state of the art. We report experimental results showing that the proposed method outperforms baselines in terms of verified accuracy while retaining an acceptable computational overhead.},
  archive   = {C_AAAI},
  author    = {Jianglin Lan and Benedikt Brückner and Alessio Lomuscio},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26745},
  pages     = {14946-14954},
  title     = {A semidefinite relaxation based branch-and-bound method for tight neural network verification},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Iteratively enhanced semidefinite relaxations for efficient
neural network verification. <em>AAAI</em>, 14937–14945. (<a
href="https://doi.org/10.1609/aaai.v37i12.26744">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose an enhanced semidefinite program (SDP) relaxation to enable the tight and efficient verification of neural networks (NNs). The tightness improvement is achieved by introducing a nonlinear constraint to existing SDP relaxations previously proposed for NN verification. The efficiency of the proposal stems from the iterative nature of the proposed algorithm in that it solves the resulting non-convex SDP by recursively solving auxiliary convex layer-based SDP problems. We show formally that the solution generated by our algorithm is tighter than state-of-the-art SDP-based solutions for the problem. We also show that the solution sequence converges to the optimal solution of the non-convex enhanced SDP relaxation. The experimental results on standard benchmarks in the area show that our algorithm achieves the state-of-the-art performance whilst maintaining an acceptable computational cost.},
  archive   = {C_AAAI},
  author    = {Jianglin Lan and Yang Zheng and Alessio Lomuscio},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26744},
  pages     = {14937-14945},
  title     = {Iteratively enhanced semidefinite relaxations for efficient neural network verification},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Heuristic search in dual space for constrained fixed-horizon
POMDPs with durative actions. <em>AAAI</em>, 14927–14936. (<a
href="https://doi.org/10.1609/aaai.v37i12.26743">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Partially Observable Markov Decision Process (POMDP) is widely used in probabilistic planning for stochastic domains. However, current extensions, such as constrained and chance-constrained POMDPs, have limitations in modeling real-world planning problems because they assume that all actions have a fixed duration. To address this issue, we propose a unified model that encompasses durative POMDP and its constrained extensions. To solve the durative POMDP and its constrained extensions, we first convert them into an Integer Linear Programming (ILP) formulation. This approach leverages existing solvers in the ILP literature and provides a foundation for solving these problems. We then introduce a heuristic search approach that prunes the search space, which is guided by solving successive partial ILP programs. Our empirical evaluation results show that our approach outperforms the current state-of-the-art fixed-horizon chance-constrained POMDP solver.},
  archive   = {C_AAAI},
  author    = {Majid Khonji and Duoaa Khalifa},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26743},
  pages     = {14927-14936},
  title     = {Heuristic search in dual space for constrained fixed-horizon POMDPs with durative actions},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sample-dependent adaptive temperature scaling for improved
calibration. <em>AAAI</em>, 14919–14926. (<a
href="https://doi.org/10.1609/aaai.v37i12.26742">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {It is now well known that neural networks can be wrong with high confidence in their predictions, leading to poor calibration. The most common post-hoc approach to compensate for this is to perform temperature scaling, which adjusts the confidences of the predictions on any input by scaling the logits by a fixed value. Whilst this approach typically improves the average calibration across the whole test dataset, this improvement typically reduces the individual confidences of the predictions irrespective of whether the classification of a given input is correct or incorrect. With this insight, we base our method on the observation that different samples contribute to the calibration error by varying amounts, with some needing to increase their confidence and others needing to decrease it. Therefore, for each input, we propose to predict a different temperature value, allowing us to adjust the mismatch between confidence and accuracy at a finer granularity. Our method is applied post-hoc, enabling it to be very fast with a negligible memory footprint and is applied to off-the-shelf pre-trained classifiers. We test our method on the ResNet50 and WideResNet28-10 architectures using the CIFAR10/100 and Tiny-ImageNet datasets, showing that producing per-data-point temperatures improves the expected calibration error across the whole test set.},
  archive   = {C_AAAI},
  author    = {Tom Joy and Francesco Pinto and Ser-Nam Lim and Philip H.S. Torr and Puneet K. Dokania},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26742},
  pages     = {14919-14926},
  title     = {Sample-dependent adaptive temperature scaling for improved calibration},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). READ: Aggregating reconstruction error into
out-of-distribution detection. <em>AAAI</em>, 14910–14918. (<a
href="https://doi.org/10.1609/aaai.v37i12.26741">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Detecting out-of-distribution (OOD) samples is crucial to the safe deployment of a classifier in the real world. However, deep neural networks are known to be overconfident for abnormal data. Existing works directly design score function by mining the inconsistency from classifier for in-distribution (ID) and OOD. In this paper, we further complement this inconsistency with reconstruction error, based on the assumption that an autoencoder trained on ID data cannot reconstruct OOD as well as ID. We propose a novel method, READ (Reconstruction Error Aggregated Detector), to unify inconsistencies from classifier and autoencoder. Specifically, the reconstruction error of raw pixels is transformed to latent space of classifier. We show that the transformed reconstruction error bridges the semantic gap and inherits detection performance from the original. Moreover, we propose an adjustment strategy to alleviate the overconfidence problem of autoencoder according to a fine-grained characterization of OOD data. Under two scenarios of pre-training and retraining, we respectively present two variants of our method, namely READ-MD (Mahalanobis Distance) only based on pre-trained classifier and READ-ED (Euclidean Distance) which retrains the classifier. Our methods do not require access to test time OOD data for fine-tuning hyperparameters. Finally, we demonstrate the effectiveness of the proposed methods through extensive comparisons with state-of-the-art OOD detection algorithms. On a CIFAR-10 pre-trained WideResNet, our method reduces the average FPR@95TPR by up to 9.8\% compared with previous state-of-the-art.},
  archive   = {C_AAAI},
  author    = {Wenyu Jiang and Yuxin Ge and Hao Cheng and Mingcai Chen and Shuai Feng and Chongjun Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26741},
  pages     = {14910-14918},
  title     = {READ: Aggregating reconstruction error into out-of-distribution detection},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Formalising the robustness of counterfactual explanations
for neural networks. <em>AAAI</em>, 14901–14909. (<a
href="https://doi.org/10.1609/aaai.v37i12.26740">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The use of counterfactual explanations (CFXs) is an increasingly popular explanation strategy for machine learning models. However, recent studies have shown that these explanations may not be robust to changes in the underlying model (e.g., following retraining), which raises questions about their reliability in real-world applications. Existing attempts towards solving this problem are heuristic, and the robustness to model changes of the resulting CFXs is evaluated with only a small number of retrained models, failing to provide exhaustive guarantees. To remedy this, we propose ∆-robustness, the first notion to formally and deterministically assess the robustness (to model changes) of CFXs for neural networks. We introduce an abstraction framework based on interval neural networks to verify the ∆-robustness of CFXs against a possibly infinite set of changes to the model parameters, i.e., weights and biases. We then demonstrate the utility of this approach in two distinct ways. First, we analyse the ∆-robustness of a number of CFX generation methods from the literature and show that they unanimously host significant deficiencies in this regard. Second, we demonstrate how embedding ∆-robustness within existing methods can provide CFXs which are provably robust.},
  archive   = {C_AAAI},
  author    = {Junqi Jiang and Francesco Leofante and Antonio Rago and Francesca Toni},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26740},
  pages     = {14901-14909},
  title     = {Formalising the robustness of counterfactual explanations for neural networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CodeAttack: Code-based adversarial attacks for pre-trained
programming language models. <em>AAAI</em>, 14892–14900. (<a
href="https://doi.org/10.1609/aaai.v37i12.26739">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Pre-trained programming language (PL) models (such as CodeT5, CodeBERT, GraphCodeBERT, etc.,) have the potential to automate software engineering tasks involving code understanding and code generation. However, these models operate in the natural channel of code, i.e., primarily concerned with the human understanding of code. They are not robust to changes in the input and thus, are potentially susceptible to adversarial attacks in the natural channel. We propose, Code Attack, a simple yet effective black-box attack model that uses code structure to generate effective, efficient, and imperceptible adversarial code samples and demonstrates the vulnerabilities of the state-of-the-art PL models to code-specific adversarial attacks. We evaluate the transferability of CodeAttack on several code-code (translation and repair) and code-NL (summarization) tasks across different programming languages. Code Attack outperforms state-of-the-art adversarial NLP attack models to achieve the best overall drop in performance while being more efficient, imperceptible, consistent, and fluent. The code can be found at https://github.com/reddy-lab-code-research/CodeAttack.},
  archive   = {C_AAAI},
  author    = {Akshita Jha and Chandan K. Reddy},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26739},
  pages     = {14892-14900},
  title     = {CodeAttack: Code-based adversarial attacks for pre-trained programming language models},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving adversarial robustness with self-paced hard-class
pair reweighting. <em>AAAI</em>, 14883–14891. (<a
href="https://doi.org/10.1609/aaai.v37i12.26738">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep Neural Networks are vulnerable to adversarial attacks. Among many defense strategies, adversarial training with untargeted attacks is one of the most effective methods. Theoretically, adversarial perturbation in untargeted attacks can be added along arbitrary directions and the predicted labels of untargeted attacks should be unpredictable. However, we find that the naturally imbalanced inter-class semantic similarity makes those hard-class pairs become virtual targets of each other. This study investigates the impact of such closely-coupled classes on adversarial attacks and develops a self-paced reweighting strategy in adversarial training accordingly. Specifically, we propose to upweight hard-class pair losses in model optimization, which prompts learning discriminative features from hard classes. We further incorporate a term to quantify hard-class pair consistency in adversarial training, which greatly boosts model robustness. Extensive experiments show that the proposed adversarial training method achieves superior robustness performance over state-of-the-art defenses against a wide range of adversarial attacks. The code of the proposed SPAT is published at https://github.com/puerrrr/Self-Paced-Adversarial-Training.},
  archive   = {C_AAAI},
  author    = {Pengyue Hou and Jie Han and Xingyu Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26738},
  pages     = {14883-14891},
  title     = {Improving adversarial robustness with self-paced hard-class pair reweighting},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Redactor: A data-centric and individualized defense against
inference attacks. <em>AAAI</em>, 14874–14882. (<a
href="https://doi.org/10.1609/aaai.v37i12.26737">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Information leakage is becoming a critical problem as various information becomes publicly available by mistake, and machine learning models train on that data to provide services. As a result, one&#39;s private information could easily be memorized by such trained models. Unfortunately, deleting information is out of the question as the data is already exposed to the Web or third-party platforms. Moreover, we cannot necessarily control the labeling process and the model trainings by other parties either. In this setting, we study the problem of targeted disinformation generation where the goal is to dilute the data and thus make a model safer and more robust against inference attacks on a specific target (e.g., a person&#39;s profile) by only inserting new data. Our method finds the closest points to the target in the input space that will be labeled as a different class. Since we cannot control the labeling process, we instead conservatively estimate the labels probabilistically by combining decision boundaries of multiple classifiers using data programming techniques. Our experiments show that a probabilistic decision boundary can be a good proxy for labelers, and that our approach is effective in defending against inference attacks and can scale to large data.},
  archive   = {C_AAAI},
  author    = {Geon Heo and Steven Euijong Whang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26737},
  pages     = {14874-14882},
  title     = {Redactor: A data-centric and individualized defense against inference attacks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust training of neural networks against bias field
perturbations. <em>AAAI</em>, 14865–14873. (<a
href="https://doi.org/10.1609/aaai.v37i12.26736">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We introduce the problem of training neural networks such that they are robust against a class of smooth intensity perturbations modelled by bias fields. We first develop an approach towards this goal based on a state-of-the-art robust training method utilising Interval Bound Propagation (IBP). We analyse the resulting algorithm and observe that IBP often produces very loose bounds for bias field perturbations, which may be detrimental to training. We then propose an alternative approach based on Symbolic Interval Propagation (SIP), which usually results in significantly tighter bounds than IBP. We present ROBNET, a tool implementing these approaches for bias field robust training. In experiments networks trained with the SIP-based approach achieved up to 31\% higher certified robustness while also maintaining a better accuracy than networks trained with the IBP approach.},
  archive   = {C_AAAI},
  author    = {Patrick Henriksen and Alessio Lomuscio},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26736},
  pages     = {14865-14873},
  title     = {Robust training of neural networks against bias field perturbations},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Test time augmentation meets post-hoc calibration:
Uncertainty quantification under real-world conditions. <em>AAAI</em>,
14856–14864. (<a
href="https://doi.org/10.1609/aaai.v37i12.26735">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Communicating the predictive uncertainty of deep neural networks transparently and reliably is important in many safety-critical applications such as medicine. However, modern neural networks tend to be poorly calibrated, resulting in wrong predictions made with a high confidence. While existing post-hoc calibration methods like temperature scaling or isotonic regression yield strongly calibrated predictions in artificial experimental settings, their efficiency can significantly reduce in real-world applications, where scarcity of labeled data or domain drifts are commonly present. In this paper, we first investigate the impact of these characteristics on post-hoc calibration and introduce an easy-to-implement extension of common post-hoc calibration methods based on test time augmentation. In extensive experiments, we demonstrate that our approach results in substantially better calibration on various architectures. We demonstrate the robustness of our proposed approach on a real-world application for skin cancer classification and show that it facilitates safe decision-making under real-world uncertainties.},
  archive   = {C_AAAI},
  author    = {Achim Hekler and Titus J. Brinker and Florian Buettner},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26735},
  pages     = {14856-14864},
  title     = {Test time augmentation meets post-hoc calibration: Uncertainty quantification under real-world conditions},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AutoCost: Evolving intrinsic cost for zero-violation
reinforcement learning. <em>AAAI</em>, 14847–14855. (<a
href="https://doi.org/10.1609/aaai.v37i12.26734">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Safety is a critical hurdle that limits the application of deep reinforcement learning to real-world control tasks. To this end, constrained reinforcement learning leverages cost functions to improve safety in constrained Markov decision process. However, constrained methods fail to achieve zero violation even when the cost limit is zero. This paper analyzes the reason for such failure, which suggests that a proper cost function plays an important role in constrained RL. Inspired by the analysis, we propose AutoCost, a simple yet effective framework that automatically searches for cost functions that help constrained RL to achieve zero-violation performance. We validate the proposed method and the searched cost function on the safety benchmark Safety Gym. We compare the performance of augmented agents that use our cost function to provide additive intrinsic costs to a Lagrangian-based policy learner and a constrained-optimization policy learner with baseline agents that use the same policy learners but with only extrinsic costs. Results show that the converged policies with intrinsic costs in all environments achieve zero constraint violation and comparable performance with baselines.},
  archive   = {C_AAAI},
  author    = {Tairan He and Weiye Zhao and Changliu Liu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26734},
  pages     = {14847-14855},
  title     = {AutoCost: Evolving intrinsic cost for zero-violation reinforcement learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Contrastive self-supervised learning leads to higher
adversarial susceptibility. <em>AAAI</em>, 14838–14846. (<a
href="https://doi.org/10.1609/aaai.v37i12.26733">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Contrastive self-supervised learning (CSL) has managed to match or surpass the performance of supervised learning in image and video classification. However, it is still largely unknown if the nature of the representations induced by the two learning paradigms is similar. We investigate this under the lens of adversarial robustness. Our analysis of the problem reveals that CSL has intrinsically higher sensitivity to perturbations over supervised learning. We identify the uniform distribution of data representation over a unit hypersphere in the CSL representation space as the key contributor to this phenomenon. We establish that this is a result of the presence of false negative pairs in the training process, which increases model sensitivity to input perturbations. Our finding is supported by extensive experiments for image and video classification using adversarial perturbations and other input corruptions. We devise a strategy to detect and remove false negative pairs that is simple, yet effective in improving model robustness with CSL training. We close up to 68\% of the robustness gap between CSL and its supervised counterpart. Finally, we contribute to adversarial learning by incorporating our method in CSL. We demonstrate an average gain of about 5\% over two different state-of-the-art methods in this domain.},
  archive   = {C_AAAI},
  author    = {Rohit Gupta and Naveed Akhtar and Ajmal Mian and Mubarak Shah},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26733},
  pages     = {14838-14846},
  title     = {Contrastive self-supervised learning leads to higher adversarial susceptibility},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Out-of-distribution detection is not all you need.
<em>AAAI</em>, 14829–14837. (<a
href="https://doi.org/10.1609/aaai.v37i12.26732">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The usage of deep neural networks in safety-critical systems is limited by our ability to guarantee their correct behavior. Runtime monitors are components aiming to identify unsafe predictions and discard them before they can lead to catastrophic consequences. Several recent works on runtime monitoring have focused on out-of-distribution (OOD) detection, i.e., identifying inputs that are different from the training data. In this work, we argue that OOD detection is not a well-suited framework to design efficient runtime monitors and that it is more relevant to evaluate monitors based on their ability to discard incorrect predictions. We call this setting out-of-model-scope detection and discuss the conceptual differences with OOD. We also conduct extensive experiments on popular datasets from the literature to show that studying monitors in the OOD setting can be misleading: 1. very good OOD results can give a false impression of safety, 2. comparison under the OOD setting does not allow identifying the best monitor to detect errors. Finally, we also show that removing erroneous training data samples helps to train better monitors.},
  archive   = {C_AAAI},
  author    = {Joris Guerin and Kevin Delmas and Raul Ferreira and Jérémie Guiochet},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26732},
  pages     = {14829-14837},
  title     = {Out-of-distribution detection is not all you need},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Similarity distribution based membership inference attack on
person re-identification. <em>AAAI</em>, 14820–14828. (<a
href="https://doi.org/10.1609/aaai.v37i12.26731">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {While person Re-identification (Re-ID) has progressed rapidly due to its wide real-world applications, it also causes severe risks of leaking personal information from training data. Thus, this paper focuses on quantifying this risk by membership inference (MI) attack. Most of the existing MI attack algorithms focus on classification models, while Re-ID follows a totally different training and inference paradigm. Re-ID is a fine-grained recognition task with complex feature embedding, and model outputs commonly used by existing MI like logits and losses are not accessible during inference. Since Re-ID focuses on modelling the relative relationship between image pairs instead of individual semantics, we conduct a formal and empirical analysis which validates that the distribution shift of the inter-sample similarity between training and test set is a critical criterion for Re-ID membership inference. As a result, we propose a novel membership inference attack method based on the inter-sample similarity distribution. Specifically, a set of anchor images are sampled to represent the similarity distribution conditioned on a target image, and a neural network with a novel anchor selection module is proposed to predict the membership of the target image. Our experiments validate the effectiveness of the proposed approach on both the Re-ID task and conventional classification task.},
  archive   = {C_AAAI},
  author    = {Junyao Gao and Xinyang Jiang and Huishuai Zhang and Yifan Yang and Shuguang Dou and Dongsheng Li and Duoqian Miao and Cheng Deng and Cairong Zhao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26731},
  pages     = {14820-14828},
  title     = {Similarity distribution based membership inference attack on person re-identification},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PatchNAS: Repairing DNNs in deployment with patched network
architecture search. <em>AAAI</em>, 14811–14819. (<a
href="https://doi.org/10.1609/aaai.v37i12.26730">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Despite being widely deployed in safety-critical applications such as autonomous driving and health care, deep neural networks (DNNs) still suffer from non-negligible reliability issues. Numerous works had reported that DNNs were vulnerable to either natural environmental noises or man-made adversarial noises. How to repair DNNs in deployment with noisy samples is a crucial topic for the robustness of neural networks. While many network repairing methods based on data argumentation and weight adjustment have been proposed, they require retraining and redeploying the whole model, which causes high overhead and is infeasible for varying faulty cases on different deployment environments. In this paper, we propose a novel network repairing framework called PatchNAS from the architecture perspective, where we freeze the pretrained DNNs and introduce a small patch network to deal with failure samples at runtime. PatchNAS introduces a novel network instrumentation method to determine the faulty stage of the network structure given the collected failure samples. A small patch network structure is searched unsupervisedly using neural architecture search (NAS) technique with data samples from deployment environment. The patch network repairs the DNNs by correcting the output feature maps of the faulty stage, which helps to maintain network performance on normal samples and enhance robustness in noisy environments. Extensive experiments based on several DNNs across 15 types of natural noises show that the proposed PatchNAS outperforms the state-of-the-arts with significant performance improvement as well as much lower deployment overhead.},
  archive   = {C_AAAI},
  author    = {Yuchu Fang and Wenzhong Li and Yao Zeng and Yang Zheng and Zheng Hu and Sanglu Lu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26730},
  pages     = {14811-14819},
  title     = {PatchNAS: Repairing DNNs in deployment with patched network architecture search},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SafeLight: A reinforcement learning method toward
collision-free traffic signal control. <em>AAAI</em>, 14801–14810. (<a
href="https://doi.org/10.1609/aaai.v37i12.26729">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Traffic signal control is safety-critical for our daily life. Roughly one-quarter of road accidents in the U.S. happen at intersections due to problematic signal timing, urging the development of safety-oriented intersection control. However, existing studies on adaptive traffic signal control using reinforcement learning technologies have focused mainly on minimizing traffic delay but neglecting the potential exposure to unsafe conditions. We, for the first time, incorporate road safety standards as enforcement to ensure the safety of existing reinforcement learning methods, aiming toward operating intersections with zero collisions. We have proposed a safety-enhanced residual reinforcement learning method (SafeLight) and employed multiple optimization techniques, such as multi-objective loss function and reward shaping for better knowledge integration. Extensive experiments are conducted using both synthetic and real-world benchmark datasets. Results show that our method can significantly reduce collisions while increasing traffic mobility.},
  archive   = {C_AAAI},
  author    = {Wenlu Du and Junyi Ye and Jingyi Gu and Jing Li and Hua Wei and Guiling Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26729},
  pages     = {14801-14810},
  title     = {SafeLight: A reinforcement learning method toward collision-free traffic signal control},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Correct-by-construction reinforcement learning of cardiac
pacemakers from duration calculus requirements. <em>AAAI</em>,
14792–14800. (<a
href="https://doi.org/10.1609/aaai.v37i12.26728">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As the complexity of pacemaker devices continues to grow, the importance of capturing its functional correctness requirement formally cannot be overestimated. The pacemaker system specification document by \emph{Boston Scientific} provides a widely accepted set of specifications for pacemakers. As these specifications are written in a natural language, they are not amenable for automated verification, synthesis, or reinforcement learning of pacemaker systems. This paper presents a formalization of these requirements for a dual-chamber pacemaker in \emph{duration calculus} (DC), a highly expressive real-time specification language. The proposed formalization allows us to automatically translate pacemaker requirements into executable specifications as stopwatch automata, which can be used to enable simulation, monitoring, validation, verification and automatic synthesis of pacemaker systems. The cyclic nature of the pacemaker-heart closed-loop system results in DC requirements that compile to a decidable subclass of stopwatch automata. We present shield reinforcement learning (shield RL), a shield synthesis based reinforcement learning algorithm, by automatically constructing safety envelopes from DC specifications.},
  archive   = {C_AAAI},
  author    = {Kalyani Dole and Ashutosh Gupta and John Komp and Shankaranarayanan Krishna and Ashutosh Trivedi},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26728},
  pages     = {14792-14800},
  title     = {Correct-by-construction reinforcement learning of cardiac pacemakers from duration calculus requirements},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feature-space bayesian adversarial learning improved malware
detector robustness. <em>AAAI</em>, 14783–14791. (<a
href="https://doi.org/10.1609/aaai.v37i12.26727">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present a new algorithm to train a robust malware detector. Malware is a prolific problem and malware detectors are a front-line defense. Modern detectors rely on machine learning algorithms. Now, the adversarial objective is to devise alterations to the malware code to decrease the chance of being detected whilst preserving the functionality and realism of the malware. Adversarial learning is effective in improving robustness but generating functional and realistic adversarial malware samples is non-trivial. Because: i) in contrast to tasks capable of using gradient-based feedback, adversarial learning in a domain without a differentiable mapping function from the problem space (malware code inputs) to the feature space is hard; and ii) it is difficult to ensure the adversarial malware is realistic and functional. This presents a challenge for developing scalable adversarial machine learning algorithms for large datasets at a production or commercial scale to realize robust malware detectors. We propose an alternative; perform adversarial learning in the feature space in contrast to the problem space. We prove the projection of perturbed, yet valid malware, in the problem space into feature space will always be a subset of adversarials generated in the feature space. Hence, by generating a robust network against feature-space adversarial examples, we inherently achieve robustness against problem-space adversarial examples. We formulate a Bayesian adversarial learning objective that captures the distribution of models for improved robustness. To explain the robustness of the Bayesian adversarial learning algorithm, we prove that our learning method bounds the difference between the adversarial risk and empirical risk and improves robustness. We show that Bayesian neural networks (BNNs) achieve state-of-the-art results; especially in the False Positive Rate (FPR) regime. Adversarially trained BNNs achieve state-of-the-art robustness. Notably, adversarially trained BNNs are robust against stronger attacks with larger attack budgets by a margin of up to 15\% on a recent production-scale malware dataset of more than 20 million samples. Importantly, our efforts create a benchmark for future defenses in the malware domain.},
  archive   = {C_AAAI},
  author    = {Bao Gia Doan and Shuiqiao Yang and Paul Montague and Olivier De Vel and Tamas Abraham and Seyit Camtepe and Salil S. Kanhere and Ehsan Abbasnejad and Damith C. Ranashinghe},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26727},
  pages     = {14783-14791},
  title     = {Feature-space bayesian adversarial learning improved malware detector robustness},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Testing the channels of convolutional neural networks.
<em>AAAI</em>, 14774–14782. (<a
href="https://doi.org/10.1609/aaai.v37i12.26726">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Neural networks have complex structures, and thus it is hard to understand their inner workings and ensure correctness. To understand and debug convolutional neural networks (CNNs) we propose techniques for testing the channels of CNNs. We design FtGAN, an extension to GAN, that can generate test data with varying the intensity (i.e., sum of the neurons) of a channel of a target CNN. We also proposed a channel selection algorithm to find representative channels for testing. To efficiently inspect the target CNN’s inference computations, we define unexpectedness score, which estimates how similar the inference computation of the test data is to that of the training data. We evaluated FtGAN with five public datasets and showed that our techniques successfully identify defective channels in five different CNN models.},
  archive   = {C_AAAI},
  author    = {Kang Choi and Donghyun Son and Younghoon Kim and Jiwon Seo},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26726},
  pages     = {14774-14782},
  title     = {Testing the channels of convolutional neural networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Two wrongs don’t make a right: Combating confirmation bias
in learning with label noise. <em>AAAI</em>, 14765–14773. (<a
href="https://doi.org/10.1609/aaai.v37i12.26725">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Noisy labels damage the performance of deep networks. For robust learning, a prominent two-stage pipeline alternates between eliminating possible incorrect labels and semi-supervised training. However, discarding part of noisy labels could result in a loss of information, especially when the corruption has a dependency on data, e.g., class-dependent or instance-dependent. Moreover, from the training dynamics of a representative two-stage method DivideMix, we identify the domination of confirmation bias: pseudo-labels fail to correct a considerable amount of noisy labels, and consequently, the errors accumulate. To sufficiently exploit information from noisy labels and mitigate wrong corrections, we propose Robust Label Refurbishment (Robust LR)—a new hybrid method that integrates pseudo-labeling and confidence estimation techniques to refurbish noisy labels. We show that our method successfully alleviates the damage of both label noise and confirmation bias. As a result, it achieves state-of-the-art performance across datasets and noise types, namely CIFAR under different levels of synthetic noise and mini-WebVision and ANIMAL-10N with real-world noise.},
  archive   = {C_AAAI},
  author    = {Mingcai Chen and Hao Cheng and Yuntao Du and Ming Xu and Wenyu Jiang and Chongjun Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26725},
  pages     = {14765-14773},
  title     = {Two wrongs don’t make a right: Combating confirmation bias in learning with label noise},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PowRL: A reinforcement learning framework for robust
management of power networks. <em>AAAI</em>, 14757–14764. (<a
href="https://doi.org/10.1609/aaai.v37i12.26724">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Power grids, across the world, play an important societal and economical role by providing uninterrupted, reliable and transient-free power to several industries, businesses and household consumers. With the advent of renewable power resources and EVs resulting into uncertain generation and highly dynamic load demands, it has become ever so important to ensure robust operation of power networks through suitable management of transient stability issues and localize the events of blackouts. In the light of ever increasing stress on the modern grid infrastructure and the grid operators, this paper presents a reinforcement learning (RL) framework, PowRL, to mitigate the effects of unexpected network events, as well as reliably maintain electricity everywhere on the network at all times. The PowRL leverages a novel heuristic for overload management, along with the RL-guided decision making on optimal topology selection to ensure that the grid is operated safely and reliably (with no overloads). PowRL is benchmarked on a variety of competition datasets hosted by the L2RPN (Learning to Run a Power Network). Even with its reduced action space, PowRL tops the leaderboard in the L2RPN NeurIPS 2020 challenge (Robustness track) at an aggregate level, while also being the top performing agent in the L2RPN WCCI 2020 challenge. Moreover, detailed analysis depicts state-of-the-art performances by the PowRL agent in some of the test scenarios.},
  archive   = {C_AAAI},
  author    = {Anandsingh Chauhan and Mayank Baranwal and Ansuma Basumatary},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26724},
  pages     = {14757-14764},
  title     = {PowRL: A reinforcement learning framework for robust management of power networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Safe reinforcement learning via shielding under partial
observability. <em>AAAI</em>, 14748–14756. (<a
href="https://doi.org/10.1609/aaai.v37i12.26723">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Safe exploration is a common problem in reinforcement learning (RL) that aims to prevent agents from making disastrous decisions while exploring their environment. A family of approaches to this problem assume domain knowledge in the form of a (partial) model of this environment to decide upon the safety of an action. A so-called shield forces the RL agent to select only safe actions. However, for adoption in various applications, one must look beyond enforcing safety and also ensure the applicability of RL with good performance. We extend the applicability of shields via tight integration with state-of-the-art deep RL, and provide an extensive, empirical study in challenging, sparse-reward environments under partial observability. We show that a carefully integrated shield ensures safety and can improve the convergence rate and final performance of RL agents. We furthermore show that a shield can be used to bootstrap state-of-the-art RL agents: they remain safe after initial learning in a shielded setting, allowing us to disable a potentially too conservative shield eventually.},
  archive   = {C_AAAI},
  author    = {Steven Carr and Nils Jansen and Sebastian Junges and Ufuk Topcu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26723},
  pages     = {14748-14756},
  title     = {Safe reinforcement learning via shielding under partial observability},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Ensemble-in-one: Ensemble learning within random gated
networks for enhanced adversarial robustness. <em>AAAI</em>,
14738–14747. (<a
href="https://doi.org/10.1609/aaai.v37i12.26722">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Adversarial attacks have threatened modern deep learning systems by crafting adversarial examples with small perturbations to fool the convolutional neural networks (CNNs). To alleviate that, ensemble training methods are proposed to facilitate better adversarial robustness by diversifying the vulnerabilities among the sub-models, simultaneously maintaining comparable natural accuracy as standard training. Previous practices also demonstrate that enlarging the ensemble can improve the robustness. However, conventional ensemble methods are with poor scalability, owing to the rapidly increasing complexity when containing more sub-models in the ensemble. Moreover, it is usually infeasible to train or deploy an ensemble with substantial sub-models, owing to the tight hardware resource budget and latency requirement. In this work, we propose Ensemble-in-One (EIO), a simple but effective method to efficiently enlarge the ensemble with a random gated network (RGN). EIO augments a candidate model by replacing the parametrized layers with multi-path random gated blocks (RGBs) to construct an RGN. The scalability is significantly boosted because the number of paths exponentially increases with the RGN depth. Then by learning from the vulnerabilities of numerous other paths within the RGN, every path obtains better adversarial robustness. Our experiments demonstrate that EIO consistently outperforms previous ensemble training methods with smaller computational overheads, simultaneously achieving better accuracy-robustness trade-offs than adversarial training methods under black-box transfer attacks. Code is available at https://github.com/cai-y13/Ensemble-in-One.git},
  archive   = {C_AAAI},
  author    = {Yi Cai and Xuefei Ning and Huazhong Yang and Yu Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26722},
  pages     = {14738-14747},
  title     = {Ensemble-in-one: Ensemble learning within random gated networks for enhanced adversarial robustness},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust-by-design classification via unitary-gradient neural
networks. <em>AAAI</em>, 14729–14737. (<a
href="https://doi.org/10.1609/aaai.v37i12.26721">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The use of neural networks in safety-critical systems requires safe and robust models, due to the existence of adversarial attacks. Knowing the minimal adversarial perturbation of any input x, or, equivalently, knowing the distance of x from the classification boundary, allows evaluating the classification robustness, providing certifiable predictions. Unfortunately, state-of-the-art techniques for computing such a distance are computationally expensive and hence not suited for online applications. This work proposes a novel family of classifiers, namely Signed Distance Classifiers (SDCs), that, from a theoretical perspective, directly output the exact distance of x from the classification boundary, rather than a probability score (e.g., SoftMax). SDCs represent a family of robust-by-design classifiers. To practically address the theoretical requirements of an SDC, a novel network architecture named Unitary-Gradient Neural Network is presented. Experimental results show that the proposed architecture approximates a signed distance classifier, hence allowing an online certifiable classification of x at the cost of a single inference.},
  archive   = {C_AAAI},
  author    = {Fabio Brau and Giulio Rossolini and Alessandro Biondi and Giorgio Buttazzo},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26721},
  pages     = {14729-14737},
  title     = {Robust-by-design classification via unitary-gradient neural networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Attention-conditioned augmentations for self-supervised
anomaly detection and localization. <em>AAAI</em>, 14720–14728. (<a
href="https://doi.org/10.1609/aaai.v37i12.26720">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Self-supervised anomaly detection and localization are critical to real-world scenarios in which collecting anomalous samples and pixel-wise labeling is tedious or infeasible, even worse when a wide variety of unseen anomalies could surface at test time. Our approach involves a pretext task in the context of masked image modeling, where the goal is to impose agreement between cluster assignments obtained from the representation of an image view containing saliency-aware masked patches and the uncorrupted image view. We harness the self-attention map extracted from the transformer to mask non-salient image patches without destroying the crucial structure associated with the foreground object. Subsequently, the pre-trained model is fine-tuned to detect and localize simulated anomalies generated under the guidance of the transformer&#39;s self-attention map. We conducted extensive validation and ablations on the benchmark of industrial images and achieved superior performance against competing methods. We also show the adaptability of our method to the medical images of the chest X-rays benchmark.},
  archive   = {C_AAAI},
  author    = {Behzad Bozorgtabar and Dwarikanath Mahapatra},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26720},
  pages     = {14720-14728},
  title     = {Attention-conditioned augmentations for self-supervised anomaly detection and localization},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Accelerating inverse learning via intelligent localization
with exploratory sampling. <em>AAAI</em>, 14711–14719. (<a
href="https://doi.org/10.1609/aaai.v37i12.26719">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the scope of &quot;AI for Science&quot;, solving inverse problems is a longstanding challenge in materials and drug discovery, where the goal is to determine the hidden structures given a set of desirable properties. Deep generative models are recently proposed to solve inverse problems, but these are currently struggling in expensive forward operators, precisely localizing the exact solutions and fully exploring the parameter spaces without missing solutions. In this work, we propose a novel approach (called iPage) to accelerate the inverse learning process by leveraging probabilistic inference from deep invertible models and deterministic optimization via fast gradient descent. Given a target property, the learned invertible model provides a posterior over the parameter space; we identify these posterior samples as an intelligent prior initialization which enables us to narrow down the search space. We then perform gradient descent to calibrate the inverse solutions within a local region. Meanwhile, a space-filling sampling is imposed on the latent space to better explore and capture all possible solutions. We evaluate our approach on three benchmark tasks and create two datasets of real-world applications from quantum chemistry and additive manufacturing and find our method achieves superior performance compared to several state-of-the-art baseline methods. The iPage code is available at https://github.com/jxzhangjhu/MatDesINNe.},
  archive   = {C_AAAI},
  author    = {Sirui Bi and Victor Fung and Jiaxin Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26719},
  pages     = {14711-14719},
  title     = {Accelerating inverse learning via intelligent localization with exploratory sampling},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Probabilities are not enough: Formal controller synthesis
for stochastic dynamical models with epistemic uncertainty.
<em>AAAI</em>, 14701–14710. (<a
href="https://doi.org/10.1609/aaai.v37i12.26718">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Capturing uncertainty in models of complex dynamical systems is crucial to designing safe controllers. Stochastic noise causes aleatoric uncertainty, whereas imprecise knowledge of model parameters leads to epistemic uncertainty. Several approaches use formal abstractions to synthesize policies that satisfy temporal specifications related to safety and reachability. However, the underlying models exclusively capture aleatoric but not epistemic uncertainty, and thus require that model parameters are known precisely. Our contribution to overcoming this restriction is a novel abstraction-based controller synthesis method for continuous-state models with stochastic noise and uncertain parameters. By sampling techniques and robust analysis, we capture both aleatoric and epistemic uncertainty, with a user-specified confidence level, in the transition probability intervals of a so-called interval Markov decision process (iMDP). We synthesize an optimal policy on this iMDP, which translates (with the specified confidence level) to a feedback controller for the continuous model with the same performance guarantees. Our experimental benchmarks confirm that accounting for epistemic uncertainty leads to controllers that are more robust against variations in parameter values.},
  archive   = {C_AAAI},
  author    = {Thom Badings and Licio Romao and Alessandro Abate and Nils Jansen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26718},
  pages     = {14701-14710},
  title     = {Probabilities are not enough: Formal controller synthesis for stochastic dynamical models with epistemic uncertainty},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Query-based hard-image retrieval for object detection at
test time. <em>AAAI</em>, 14692–14700. (<a
href="https://doi.org/10.1609/aaai.v37i12.26717">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {There is a longstanding interest in capturing the error behaviour of object detectors by finding images where their performance is likely to be unsatisfactory. In real-world applications such as autonomous driving, it is also crucial to characterise potential failures beyond simple requirements of detection performance. For example, a missed detection of a pedestrian close to an ego vehicle will generally require closer inspection than a missed detection of a car in the distance. The problem of predicting such potential failures at test time has largely been overlooked in the literature and conventional approaches based on detection uncertainty fall short in that they are agnostic to such fine-grained characterisation of errors. In this work, we propose to reformulate the problem of finding &quot;hard&quot; images as a query-based hard image retrieval task, where queries are specific definitions of &quot;hardness&quot;, and offer a simple and intuitive method that can solve this task for a large family of queries. Our method is entirely post-hoc, does not require ground-truth annotations, is independent of the choice of a detector, and relies on an efficient Monte Carlo estimation that uses a simple stochastic model in place of the ground-truth. We show experimentally that it can be applied successfully to a wide variety of queries for which it can reliably identify hard images for a given detector without any labelled data. We provide results on ranking and classification tasks using the widely used RetinaNet, Faster-RCNN, Mask-RCNN, and Cascade Mask-RCNN object detectors. The code for this project is available at https://github.com/fiveai/hardest.},
  archive   = {C_AAAI},
  author    = {Edward Ayers and Jonathan Sadeghi and John Redford and Romain Mueller and Puneet K. Dokania},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26717},
  pages     = {14692-14700},
  title     = {Query-based hard-image retrieval for object detection at test time},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Implicit bilevel optimization: Differentiating through
bilevel optimization programming. <em>AAAI</em>, 14683–14691. (<a
href="https://doi.org/10.1609/aaai.v37i12.26716">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Bilevel Optimization Programming is used to model complex and conflicting interactions between agents, for example in Robust AI or Privacy preserving AI. Integrating bilevel mathematical programming within deep learning is thus an essential objective for the Machine Learning community. Previously proposed approaches only consider single-level programming. In this paper, we extend existing single-level optimization programming approaches and thus propose Differentiating through Bilevel Optimization Programming (BiGrad) for end-to-end learning of models that use Bilevel Programming as a layer. BiGrad has wide applicability and can be used in modern machine learning frameworks. BiGrad is applicable to both continuous and combinatorial Bilevel optimization problems. We describe a class of gradient estimators for the combinatorial case which reduces the requirements in terms of computation complexity; for the case of the continuous variable, the gradient computation takes advantage of the push-back approach (i.e. vector-jacobian product) for an efficient implementation. Experiments show that the BiGrad successfully extends existing single-level approaches to Bilevel Programming.},
  archive   = {C_AAAI},
  author    = {Francesco Alesiani},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26716},
  pages     = {14683-14691},
  title     = {Implicit bilevel optimization: Differentiating through bilevel optimization programming},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Shielding in resource-constrained goal POMDPs.
<em>AAAI</em>, 14674–14682. (<a
href="https://doi.org/10.1609/aaai.v37i12.26715">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider partially observable Markov decision processes (POMDPs) modeling an agent that needs a supply of a certain resource (e.g., electricity stored in batteries) to operate correctly. The resource is consumed by the agent&#39;s actions and can be replenished only in certain states. The agent aims to minimize the expected cost of reaching some goal while preventing resource exhaustion, a problem we call resource-constrained goal optimization (RSGO). We take a two-step approach to the RSGO problem. First, using formal methods techniques, we design an algorithm computing a shield for a given scenario: a procedure that observes the agent and prevents it from using actions that might eventually lead to resource exhaustion. Second, we augment the POMCP heuristic search algorithm for POMDP planning with our shields to obtain an algorithm solving the RSGO problem. We implement our algorithm and present experiments showing its applicability to benchmarks from the literature.},
  archive   = {C_AAAI},
  author    = {Michal Ajdarów and Šimon Brlej and Petr Novotný},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26715},
  pages     = {14674-14682},
  title     = {Shielding in resource-constrained goal POMDPs},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Formally verified SAT-based AI planning. <em>AAAI</em>,
14665–14673. (<a
href="https://doi.org/10.1609/aaai.v37i12.26714">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present an executable formally verified SAT encoding of ground classical AI planning problems. We use the theorem prover Isabelle/HOL to perform the verification. We experimentally test the verified encoding and show that it can be used for reasonably sized standard planning benchmarks. We also use it as a reference to test a state-of-the-art SAT-based planner, showing that it sometimes falsely claims that problems have no solutions of certain lengths.},
  archive   = {C_AAAI},
  author    = {Mohammad Abdulaziz and Friedrich Kurz},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26714},
  pages     = {14665-14673},
  title     = {Formally verified SAT-based AI planning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). OpenMapFlow: A library for rapid map creation with machine
learning and remote sensing data. <em>AAAI</em>, 14655–14663. (<a
href="https://doi.org/10.1609/aaai.v37i12.26713">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The desired output for most real-world tasks using machine learning (ML) and remote sensing data is a set of dense predictions that form a predicted map for a geographic region. However, most prior work involving ML and remote sensing follows the traditional practice of reporting metrics on a set of independent, geographically-sparse samples and does not perform dense predictions. To reduce the labor of producing dense prediction maps, we present OpenMapFlow---an open-source python library for rapid map creation with ML and remote sensing data. OpenMapFlow provides 1) a data processing pipeline for users to create labeled datasets for any region, 2) code to train state-of-the-art deep learning models on custom or existing datasets, and 3) a cloud-based architecture to deploy models for efficient map prediction. We demonstrate the benefits of OpenMapFlow through experiments on three binary classification tasks: cropland, crop type (maize), and building mapping. We show that OpenMapFlow drastically reduces the time required for dense prediction compared to traditional workflows. We hope this library will stimulate novel research in areas such as domain shift, unsupervised learning, and societally-relevant applications and lessen the barrier to adopting research methods for real-world tasks.},
  archive   = {C_AAAI},
  author    = {Ivan Zvonkov and Gabriel Tseng and Catherine Nakalembe and Hannah Kerner},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26713},
  pages     = {14655-14663},
  title     = {OpenMapFlow: A library for rapid map creation with machine learning and remote sensing data},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). People taking photos that faces never share: Privacy
protection and fairness enhancement from camera to user. <em>AAAI</em>,
14646–14654. (<a
href="https://doi.org/10.1609/aaai.v37i12.26712">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The soaring number of personal mobile devices and public cameras poses a threat to fundamental human rights and ethical principles. For example, the stolen of private information such as face image by malicious third parties will lead to catastrophic consequences. By manipulating appearance of face in the image, most of existing protection algorithms are effective but irreversible. Here, we propose a practical and systematic solution to invertiblely protect face information in the full-process pipeline from camera to final users. Specifically, We design a novel lightweight Flow-based Face Encryption Method (FFEM) on the local embedded system privately connected to the camera, minimizing the risk of eavesdropping during data transmission. FFEM uses a flow-based face encoder to encode each face to a Gaussian distribution and encrypts the encoded face feature by random rotating the Gaussian distribution with the rotation matrix is as the password. While encrypted latent-variable face images are sent to users through public but less reliable channels, password will be protected through more secure channels through technologies such as asymmetric encryption, blockchain, or other sophisticated security schemes. User could select to decode an image with fake faces from the encrypted image on the public channel. Only trusted users are able to recover the original face using the encrypted matrix transmitted in secure channel. More interestingly, by tuning Gaussian ball in latent space, we could control the fairness of the replaced face on attributes such as gender and race. Extensive experiments demonstrate that our solution could protect privacy and enhance fairness with minimal effect on high-level downstream task.},
  archive   = {C_AAAI},
  author    = {Junjie Zhu and Lin Gu and Xiaoxiao Wu and Zheng Li and Tatsuya Harada and Yingying Zhu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26712},
  pages     = {14646-14654},
  title     = {People taking photos that faces never share: Privacy protection and fairness enhancement from camera to user},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A crowd-AI collaborative duo relational graph learning
framework towards social impact aware photo classification.
<em>AAAI</em>, 14637–14645. (<a
href="https://doi.org/10.1609/aaai.v37i12.26711">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In artificial intelligence (AI), negative social impact (NSI) represents the negative effect on the society as a result of mistakes conducted by AI agents. While the photo classification problem has been widely studied in the AI community, the NSI made by photo misclassification is largely ignored due to the lack of quantitative measurements of the NSI and effective approaches to reduce it. In this paper, we focus on an NSI-aware photo classification problem where the goal is to develop a novel crowd-AI collaborative learning framework that leverages online crowd workers to quantitatively estimate and effectively reduce the NSI of misclassified photos. Our problem is motivated by the limitations of current NSI-aware photo classification approaches that either 1) cannot accurately estimate NSI because they simply model NSI as the semantic difference between true and misclassified categories or 2) require costly human annotations to estimate NSI of pairwise class categories. To address such limitations, we develop SocialCrowd, a crowdsourcing-based NSI-aware photo classification framework that explicitly reduces the NSI of photo misclassification by designing a duo relational NSI-aware graph with the NSI estimated by online crowd workers. The evaluation results on two large-scale image datasets show that SocialCrowd not only reduces the NSI of photo misclassification but also improves the classification accuracy on both datasets.},
  archive   = {C_AAAI},
  author    = {Yang Zhang and Ziyi Kou and Lanyu Shang and Huimin Zeng and Zhenrui Yue and Dong Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26711},
  pages     = {14637-14645},
  title     = {A crowd-AI collaborative duo relational graph learning framework towards social impact aware photo classification},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Future aware pricing and matching for sustainable on-demand
ride pooling. <em>AAAI</em>, 14628–14636. (<a
href="https://doi.org/10.1609/aaai.v37i12.26710">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The popularity of on-demand ride pooling is owing to the benefits offered to customers (lower prices), taxi drivers (higher revenue), environment (lower carbon footprint due to fewer vehicles) and aggregation companies like Uber (higher revenue). To achieve these benefits, two key interlinked challenges have to be solved effectively: (a) pricing -- setting prices to customer requests for taxis; and (b) matching -- assignment of customers (that accepted the prices) to taxis/cars. Traditionally, both these challenges have been studied individually and using myopic approaches (considering only current requests), without considering the impact of current matching on addressing future requests. In this paper, we develop a novel framework that handles the pricing and matching problems together, while also considering the future impact of the pricing and matching decisions. In our experimental results on a real-world taxi dataset, we demonstrate that our framework can significantly improve revenue (up to 17\% and on average 6.4\%) in a sustainable manner by reducing the number of vehicles (up to 14\% and on average 10.6\%) required to obtain a given fixed revenue and the overall distance travelled by vehicles (up to 11.1\% and on average 3.7\%). That is to say, we are able to provide an ideal win-win scenario for all stakeholders (customers, drivers, aggregator, environment) involved by obtaining higher revenue for customers, drivers, aggregator (ride pooling company) while being good for the environment (due to fewer number of vehicles on the road and lesser fuel consumed).},
  archive   = {C_AAAI},
  author    = {Xianjie Zhang and Pradeep Varakantham and Hao Jiang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26710},
  pages     = {14628-14636},
  title     = {Future aware pricing and matching for sustainable on-demand ride pooling},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A continual pre-training approach to tele-triaging pregnant
women in kenya. <em>AAAI</em>, 14620–14627. (<a
href="https://doi.org/10.1609/aaai.v37i12.26709">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Access to high-quality maternal health care services is limited in Kenya, which resulted in ∼36,000 maternal and neonatal deaths in 2018. To tackle this challenge, Jacaranda Health (a non-profit organization working on maternal health in Kenya) developed PROMPTS, an SMS based tele-triage system for pregnant and puerperal women, which has more than 350,000 active users in Kenya. PROMPTS empowers pregnant women living far away from doctors and hospitals to send SMS messages to get quick answers (through human helpdesk agents) to questions about their medical symptoms and pregnancy status. Unfortunately, ∼1.1 million SMS messages are received by PROMPTS every month, which makes it challenging for helpdesk agents to ensure that these messages can be interpreted correctly and evaluated by their level of emergency to ensure timely responses and/or treatments for women in need. This paper reports on a collaborative effort with Jacaranda Health to develop a state-of-the-art natural language processing (NLP) framework, TRIM-AI (TRIage for Mothers using AI), which can automatically predict the emergency level (or severity of medical condition) of a pregnant mother based on the content of their SMS messages. TRIM-AI leverages recent advances in multi-lingual pre-training and continual pre-training to tackle code-mixed SMS messages (between English and Swahili), and achieves a weighted F1 score of 0.774 on real-world datasets. TRIM-AI has been successfully deployed in the field since June 2022, and is being used by Jacaranda Health to prioritize the provision of services and care to pregnant women with the most critical medical conditions. Our preliminary A/B tests in the field show that TRIM-AI is ∼17\% more accurate at predicting high-risk medical conditions from SMS messages sent by pregnant Kenyan mothers, which reduces the helpdesk’s workload by ∼12\%.},
  archive   = {C_AAAI},
  author    = {Wenbo Zhang and Hangzhi Guo and Prerna Ranganathan and Jay Patel and Sathyanath Rajasekharan and Nidhi Danayak and Manan Gupta and Amulya Yadav},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26709},
  pages     = {14620-14627},
  title     = {A continual pre-training approach to tele-triaging pregnant women in kenya},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Censored fairness through awareness. <em>AAAI</em>,
14611–14619. (<a
href="https://doi.org/10.1609/aaai.v37i12.26708">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {There has been increasing concern within the machine learning community and beyond that Artificial Intelligence (AI) faces a bias and discrimination crisis which needs AI fairness with urgency. As many have begun to work on this problem, most existing work depends on the availability of class label for the given fairness definition and algorithm which may not align with real-world usage. In this work, we study an AI fairness problem that stems from the gap between the design of a &quot;fair&quot; model in the lab and its deployment in the real-world. Specifically, we consider defining and mitigating individual unfairness amidst censorship, where the availability of class label is not always guaranteed due to censorship, which is broadly applicable in a diversity of real-world socially sensitive applications. We show that our method is able to quantify and mitigate individual unfairness in the presence of censorship across three benchmark tasks, which provides the first known results on individual fairness guarantee in analysis of censored data.},
  archive   = {C_AAAI},
  author    = {Wenbin Zhang and Tina Hernandez-Boussard and Jeremy Weiss},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26708},
  pages     = {14611-14619},
  title     = {Censored fairness through awareness},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the effectiveness of curriculum learning in educational
text scoring. <em>AAAI</em>, 14602–14610. (<a
href="https://doi.org/10.1609/aaai.v37i12.26707">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Automatic Text Scoring (ATS) is a widely-investigated task in education. Existing approaches often stressed the structure design of an ATS model and neglected the training process of the model. Considering the difficult nature of this task, we argued that the performance of an ATS model could be potentially boosted by carefully selecting data of varying complexities in the training process. Therefore, we aimed to investigate the effectiveness of curriculum learning (CL) in scoring educational text. Specifically, we designed two types of difficulty measurers: (i) pre-defined, calculated by measuring a sample&#39;s readability, length, the number of grammatical errors or unique words it contains; and (ii) automatic, calculated based on whether a model in a training epoch can accurately score the samples. These measurers were tested in both the easy-to-hard to hard-to-easy training paradigms. Through extensive evaluations on two widely-used datasets (one for short answer scoring and the other for long essay scoring), we demonstrated that (a) CL indeed could boost the performance of state-of-the-art ATS models, and the maximum improvement could be up to 4.5\%, but most improvements were achieved when assessing short and easy answers; (b) the pre-defined measurer calculated based on the number of grammatical errors contained in a text sample tended to outperform the other difficulty measurers across different training paradigms.},
  archive   = {C_AAAI},
  author    = {Zijie Zeng and Dragan Gasevic and Guangliang Chen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26707},
  pages     = {14602-14610},
  title     = {On the effectiveness of curriculum learning in educational text scoring},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep learning on a healthy data diet: Finding important
examples for fairness. <em>AAAI</em>, 14593–14601. (<a
href="https://doi.org/10.1609/aaai.v37i12.26706">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Data-driven predictive solutions predominant in commercial applications tend to suffer from biases and stereotypes, which raises equity concerns. Prediction models may discover, use, or amplify spurious correlations based on gender or other protected personal characteristics, thus discriminating against marginalized groups. Mitigating gender bias has become an important research focus in natural language processing (NLP) and is an area where annotated corpora are available. Data augmentation reduces gender bias by adding counterfactual examples to the training dataset. In this work, we show that some of the examples in the augmented dataset can be not important or even harmful to fairness. We hence propose a general method for pruning both the factual and counterfactual examples to maximize the model’s fairness as measured by the demographic parity, equality of opportunity, and equality of odds. The fairness achieved by our method surpasses that of data augmentation on three text classification datasets, using no more than half of the examples in the augmented dataset. Our experiments are conducted using models of varying sizes and pre-training settings. WARNING: This work uses language that is offensive in nature.},
  archive   = {C_AAAI},
  author    = {Abdelrahman Zayed and Prasanna Parthasarathi and Gonçalo Mordido and Hamid Palangi and Samira Shabanian and Sarath Chandar},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26706},
  pages     = {14593-14601},
  title     = {Deep learning on a healthy data diet: Finding important examples for fairness},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ERASER: AdvERsArial sensitive element remover for image
privacy preservation. <em>AAAI</em>, 14584–14592. (<a
href="https://doi.org/10.1609/aaai.v37i12.26705">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The daily practice of online image sharing enriches our lives, but also raises a severe issue of privacy leakage. To mitigate the privacy risks during image sharing, some researchers modify the sensitive elements in images with visual obfuscation methods including traditional ones like blurring and pixelating, as well as generative ones based on deep learning. However, images processed by such methods may be recovered or recognized by models, which cannot guarantee privacy. Further, traditional methods make the images very unnatural with low image quality. Although generative methods produce better images, most of them suffer from insufficiency in the frequency domain, which influences image quality. Therefore, we propose the AdvERsArial Sensitive Element Remover (ERASER) to guarantee both image privacy and image quality. 1) To preserve image privacy, for the regions containing sensitive elements, ERASER guarantees enough difference after being modified in an adversarial way. Specifically, we take both the region and global content into consideration with a Prior Transformer and obtain the corresponding region prior and global prior. Based on the priors, ERASER is trained with an adversarial Difference Loss to make the content in the regions different. As a result, ERASER can reserve the main structure and change the texture of the target regions for image privacy preservation. 2) To guarantee the image quality, ERASER improves the frequency insufficiency of current generative methods. Specifically, the region prior and global prior are processed with Fast Fourier Convolution to capture characteristics and achieve consistency in both pixel and frequency domains. Quantitative analyses demonstrate that the proposed ERASER achieves a balance between image quality and image privacy preservation, while qualitative analyses demonstrate that ERASER indeed reduces the privacy risk from the visual perception aspect.},
  archive   = {C_AAAI},
  author    = {Guang Yang and Juan Cao and Danding Wang and Peng Qi and Jintao Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26705},
  pages     = {14584-14592},
  title     = {ERASER: AdvERsArial sensitive element remover for image privacy preservation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Auto-CM: Unsupervised deep learning for satellite imagery
composition and cloud masking using spatio-temporal dynamics.
<em>AAAI</em>, 14575–14583. (<a
href="https://doi.org/10.1609/aaai.v37i12.26704">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Cloud masking is both a fundamental and a critical task in the vast majority of Earth observation problems across social sectors, including agriculture, energy, water, etc. The sheer volume of satellite imagery to be processed has fast-climbed to a scale (e.g., &gt;10 PBs/year) that is prohibitive for manual processing. Meanwhile, generating reliable cloud masks and image composite is increasingly challenging due to the continued distribution-shifts in the imagery collected by existing sensors and the ever-growing variety of sensors and platforms. Moreover, labeled samples are scarce and geographically limited compared to the needs in real large-scale applications. In related work, traditional remote sensing methods are often physics-based and rely on special spectral signatures from multi- or hyper-spectral bands, which are often not available in data collected by many -- and especially more recent -- high-resolution platforms. Machine learning and deep learning based methods, on the other hand, often require large volumes of up-to-date training data to be reliable and generalizable over space. We propose an autonomous image composition and masking (Auto-CM) framework to learn to solve the fundamental tasks in a label-free manner, by leveraging different dynamics of events in both geographic domains and time-series. Our experiments show that Auto-CM outperforms existing methods on a wide-range of data with different satellite platforms, geographic regions and bands.},
  archive   = {C_AAAI},
  author    = {Yiqun Xie and Zhili Li and Han Bao and Xiaowei Jia and Dongkuan Xu and Xun Zhou and Sergii Skakun},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26704},
  pages     = {14575-14583},
  title     = {Auto-CM: Unsupervised deep learning for satellite imagery composition and cloud masking using spatio-temporal dynamics},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Privacy-preserved evolutionary graph modeling via
gromov-wasserstein autoregression. <em>AAAI</em>, 14566–14574. (<a
href="https://doi.org/10.1609/aaai.v37i12.26703">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Real-world graphs like social networks are often evolutionary over time, whose observations at different timestamps lead to graph sequences. Modeling such evolutionary graphs is important for many applications, but solving this problem often requires the correspondence between the graphs at different timestamps, which may leak private node information, e.g., the temporal behavior patterns of the nodes. We proposed a Gromov-Wasserstein Autoregressive (GWAR) model to capture the generative mechanisms of evolutionary graphs, which does not require the correspondence information and thus preserves the privacy of the graphs&#39; nodes. This model consists of two autoregressions, predicting the number of nodes and the probabilities of nodes and edges, respectively. The model takes observed graphs as its input and predicts future graphs via solving a joint graph alignment and merging task. This task leads to a fused Gromov-Wasserstein (FGW) barycenter problem, in which we approximate the alignment of the graphs based on a novel inductive fused Gromov-Wasserstein (IFGW) distance. The IFGW distance is parameterized by neural networks and can be learned under mild assumptions, thus, we can infer the FGW barycenters without iterative optimization and predict future graphs efficiently. Experiments show that our GWAR achieves encouraging performance in modeling evolutionary graphs in privacy-preserving scenarios.},
  archive   = {C_AAAI},
  author    = {Yue Xiang and Dixin Luo and Hongteng Xu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26703},
  pages     = {14566-14574},
  title     = {Privacy-preserved evolutionary graph modeling via gromov-wasserstein autoregression},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Semi-supervised credit card fraud detection via
attribute-driven graph representation. <em>AAAI</em>, 14557–14565. (<a
href="https://doi.org/10.1609/aaai.v37i12.26702">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Credit card fraud incurs a considerable cost for both cardholders and issuing banks. Contemporary methods apply machine learning-based classifiers to detect fraudulent behavior from labeled transaction records. But labeled data are usually a small proportion of billions of real transactions due to expensive labeling costs, which implies that they do not well exploit many natural features from unlabeled data. Therefore, we propose a semi-supervised graph neural network for fraud detection. Specifically, we leverage transaction records to construct a temporal transaction graph, which is composed of temporal transactions (nodes) and interactions (edges) among them. Then we pass messages among the nodes through a Gated Temporal Attention Network (GTAN) to learn the transaction representation. We further model the fraud patterns through risk propagation among transactions. The extensive experiments are conducted on a real-world transaction dataset and two publicly available fraud detection datasets. The result shows that our proposed method, namely GTAN, outperforms other state-of-the-art baselines on three fraud detection datasets. Semi-supervised experiments demonstrate the excellent fraud detection performance of our model with only a tiny proportion of labeled data.},
  archive   = {C_AAAI},
  author    = {Sheng Xiang and Mingzhi Zhu and Dawei Cheng and Enxia Li and Ruihui Zhao and Yi Ouyang and Ling Chen and Yefeng Zheng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26702},
  pages     = {14557-14565},
  title     = {Semi-supervised credit card fraud detection via attribute-driven graph representation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Noise based deepfake detection via multi-head
relative-interaction. <em>AAAI</em>, 14548–14556. (<a
href="https://doi.org/10.1609/aaai.v37i12.26701">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deepfake brings huge and potential negative impacts to our daily lives. As the real-life Deepfake videos circulated on the Internet become more authentic, most existing detection algorithms have failed since few visual differences can be observed between an authentic video and a Deepfake one. However, the forensic traces are always retained within the synthesized videos. In this study, we present a noise-based Deepfake detection model, NoiseDF for short, which focuses on the underlying forensic noise traces left behind the Deepfake videos. In particular, we enhance the RIDNet denoiser to extract noise traces and features from the cropped face and background squares of the video image frames. Meanwhile, we devise a novel Multi-Head Relative-Interaction method to evaluate the degree of interaction between the faces and backgrounds that plays a pivotal role in the Deepfake detection task. Besides outperforming the state-of-the-art models, the visualization of the extracted Deepfake forensic noise traces has further displayed the evidence and proved the robustness of our approach.},
  archive   = {C_AAAI},
  author    = {Tianyi Wang and Kam Pui Chow},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26701},
  pages     = {14548-14556},
  title     = {Noise based deepfake detection via multi-head relative-interaction},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PateGail: A privacy-preserving mobility trajectory generator
with imitation learning. <em>AAAI</em>, 14539–14547. (<a
href="https://doi.org/10.1609/aaai.v37i12.26700">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Generating human mobility trajectories is of great importance to solve the lack of large-scale trajectory data in numerous applications, which is caused by privacy concerns. However, existing mobility trajectory generation methods still require real-world human trajectories centrally collected as the training data, where there exists an inescapable risk of privacy leakage. To overcome this limitation, in this paper, we propose PateGail, a privacy-preserving imitation learning model to generate mobility trajectories, which utilizes the powerful generative adversary imitation learning model to simulate the decision-making process of humans. Further, in order to protect user privacy, we train this model collectively based on decentralized mobility data stored in user devices, where personal discriminators are trained locally to distinguish and reward the real and generated human trajectories. In the training process, only the generated trajectories and their rewards obtained based on personal discriminators are shared between the server and devices, whose privacy is further preserved by our proposed perturbation mechanisms with theoretical proof to satisfy differential privacy. Further, to better model the human decision-making process, we propose a novel aggregation mechanism of the rewards obtained from personal discriminators. We theoretically prove that under the reward obtained based on the aggregation mechanism, our proposed model maximizes the lower bound of the discounted total rewards of users. Extensive experiments show that the trajectories generated by our model are able to resemble real-world trajectories in terms of five key statistical metrics, outperforming state-of-the-art algorithms by over 48.03\%. Furthermore, we demonstrate that the synthetic trajectories are able to efficiently support practical applications, including mobility prediction and location recommendation.},
  archive   = {C_AAAI},
  author    = {Huandong Wang and Changzheng Gao and Yuchen Wu and Depeng Jin and Lina Yao and Yong Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26700},
  pages     = {14539-14547},
  title     = {PateGail: A privacy-preserving mobility trajectory generator with imitation learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MixFairFace: Towards ultimate fairness via MixFair adapter
in face recognition. <em>AAAI</em>, 14531–14538. (<a
href="https://doi.org/10.1609/aaai.v37i12.26699">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Although significant progress has been made in face recognition, demographic bias still exists in face recognition systems. For instance, it usually happens that the face recognition performance for a certain demographic group is lower than the others. In this paper, we propose MixFairFace framework to improve the fairness in face recognition models. First of all, we argue that the commonly used attribute-based fairness metric is not appropriate for face recognition. A face recognition system can only be considered fair while every person has a close performance. Hence, we propose a new evaluation protocol to fairly evaluate the fairness performance of different approaches. Different from previous approaches that require sensitive attribute labels such as race and gender for reducing the demographic bias, we aim at addressing the identity bias in face representation, i.e., the performance inconsistency between different identities, without the need for sensitive attribute labels. To this end, we propose MixFair Adapter to determine and reduce the identity bias of training samples. Our extensive experiments demonstrate that our MixFairFace approach achieves state-of-the-art fairness performance on all benchmark datasets.},
  archive   = {C_AAAI},
  author    = {Fu-En Wang and Chien-Yi Wang and Min Sun and Shang-Hong Lai},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26699},
  pages     = {14531-14538},
  title     = {MixFairFace: Towards ultimate fairness via MixFair adapter in face recognition},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Everyone’s voice matters: Quantifying annotation
disagreement using demographic information. <em>AAAI</em>, 14523–14530.
(<a href="https://doi.org/10.1609/aaai.v37i12.26698">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In NLP annotation, it is common to have multiple annotators label the text and then obtain the ground truth labels based on major annotators’ agreement. However, annotators are individuals with different backgrounds and various voices. When annotation tasks become subjective, such as detecting politeness, offense, and social norms, annotators’ voices differ and vary. Their diverse voices may represent the true distribution of people’s opinions on subjective matters. Therefore, it is crucial to study the disagreement from annotation to understand which content is controversial from the annotators. In our research, we extract disagreement labels from five subjective datasets, then fine-tune language models to predict annotators’ disagreement. Our results show that knowing annotators’ demographic information (e.g., gender, ethnicity, education level), in addition to the task text, helps predict the disagreement. To investigate the effect of annotators’ demographics on their disagreement level, we simulate different combinations of their artificial demographics and explore the variance of the prediction to distinguish the disagreement from the inherent controversy from text content and the disagreement in the annotators’ perspective. Overall, we propose an innovative disagreement prediction mechanism for better design of the annotation process that will achieve more accurate and inclusive results for NLP systems. Our code and dataset are publicly available.},
  archive   = {C_AAAI},
  author    = {Ruyuan Wan and Jaehyung Kim and Dongyeop Kang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26698},
  pages     = {14523-14530},
  title     = {Everyone’s voice matters: Quantifying annotation disagreement using demographic information},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evaluating digital agriculture recommendations with causal
inference. <em>AAAI</em>, 14514–14522. (<a
href="https://doi.org/10.1609/aaai.v37i12.26697">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In contrast to the rapid digitalization of several industries, agriculture suffers from low adoption of smart farming tools. Even though recent advancements in AI-driven digital agriculture can offer high-performing predictive functionalities, they lack tangible quantitative evidence on their benefits to the farmers. Field experiments can derive such evidence, but are often costly, time consuming and hence limited in scope and scale of application. To this end, we propose an observational causal inference framework for the empirical evaluation of the impact of digital tools on target farm performance indicators (e.g., yield in this case). This way, we can increase farmers&#39; trust via enhancing the transparency of the digital agriculture market, and in turn accelerate the adoption of technologies that aim to secure farmer income resilience and global agricultural sustainability against a changing climate. As a case study, we designed and implemented a recommendation system for the optimal sowing time of cotton based on numerical weather predictions, which was used by a farmers&#39; cooperative during the growing season of 2021. We then leverage agricultural knowledge, collected yield data, and environmental information to develop a causal graph of the farm system. Using the back-door criterion, we identify the impact of sowing recommendations on the yield and subsequently estimate it using linear regression, matching, inverse propensity score weighting and meta-learners. The results revealed that a field sown according to our recommendations exhibited a statistically significant yield increase that ranged from 12\% to 17\%, depending on the method. The effect estimates were robust, as indicated by the agreement among the estimation methods and four successful refutation tests. We argue that this approach can be implemented for decision support systems of other fields, extending their evaluation beyond a performance assessment of internal functionalities.},
  archive   = {C_AAAI},
  author    = {Ilias Tsoumas and Georgios Giannarakis and Vasileios Sitokonstantinou and Alkiviadis Koukos and Dimitra Loka and Nikolaos Bartsotas and Charalampos Kontoes and Ioannis Athanasiadis},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26697},
  pages     = {14514-14522},
  title     = {Evaluating digital agriculture recommendations with causal inference},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Weather2vec: Representation learning for causal inference
with non-local confounding in air pollution and climate studies.
<em>AAAI</em>, 14504–14513. (<a
href="https://doi.org/10.1609/aaai.v37i12.26696">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Estimating the causal effects of a spatially-varying intervention on a spatially-varying outcome may be subject to non-local confounding (NLC), a phenomenon that can bias estimates when the treatments and outcomes of a given unit are dictated in part by the covariates of other nearby units. In particular, NLC is a challenge for evaluating the effects of environmental policies and climate events on health-related outcomes such as air pollution exposure. This paper first formalizes NLC using the potential outcomes framework, providing a comparison with the related phenomenon of causal interference. Then, it proposes a broadly applicable framework, termed weather2vec, that uses the theory of balancing scores to learn representations of non-local information into a scalar or vector defined for each observational unit, which is subsequently used to adjust for confounding in conjunction with causal inference methods. The framework is evaluated in a simulation study and two case studies on air pollution where the weather is an (inherently regional) known confounder.},
  archive   = {C_AAAI},
  author    = {Mauricio Tec and James G. Scott and Corwin M. Zigler},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26696},
  pages     = {14504-14513},
  title     = {Weather2vec: Representation learning for causal inference with non-local confounding in air pollution and climate studies},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). City-scale pollution aware traffic routing by sampling max
flows using MCMC. <em>AAAI</em>, 14496–14503. (<a
href="https://doi.org/10.1609/aaai.v37i12.26695">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A significant cause of air pollution in urban areas worldwide is the high volume of road traffic. Long-term exposure to severe pollution can cause serious health issues. One approach towards tackling this problem is to design a pollution-aware traffic routing policy that balances multiple objectives of i) avoiding extreme pollution in any area ii) enabling short transit times, and iii) making effective use of the road capacities. We propose a novel sampling-based approach for this problem. We give the first construction of a Markov Chain that can sample integer max flow solutions of a planar graph, with theoretical guarantees that the probabilities depend on the aggregate transit length. We designed a traffic policy using diverse samples and simulated traffic on real-world road maps using the SUMO traffic simulator. We observe a considerable decrease in areas with severe pollution when experimented with maps of large cities across the world compared to other approaches.},
  archive   = {C_AAAI},
  author    = {Shreevignesh Suriyanarayanan and Praveen Paruchuri and Girish Varma},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26695},
  pages     = {14496-14503},
  title     = {City-scale pollution aware traffic routing by sampling max flows using MCMC},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Daycare matching in japan: Transfers and siblings.
<em>AAAI</em>, 14487–14495. (<a
href="https://doi.org/10.1609/aaai.v37i12.26694">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we study a daycare matching problem in Japan and report the design and implementation of a new centralized algorithm, which is going to be deployed in one municipality in the Tokyo metropolis. There are two features that make this market different from the classical hospital-doctor matching problem: i) some children are initially enrolled and prefer to be transferred to other daycare centers; ii) one family may be associated with two or more children and is allowed to submit preferences over combinations of daycare centers. We revisit some well-studied properties including individual rationality, non-wastefulness, as well as stability, and generalize them to this new setting. We design an algorithm based on integer programming (IP) that captures these properties and conduct experiments on five real-life data sets provided by three municipalities. Experimental results show that i) our algorithm performs at least as well as currently used methods in terms of numbers of matched children and blocking coalition; ii) we can find a stable outcome for all instances, although the existence of such an outcome is not guaranteed in theory.},
  archive   = {C_AAAI},
  author    = {Zhaohong Sun and Yoshihiro Takenami and Daisuke Moriwaki and Yoji Tomita and Makoto Yokoo},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26694},
  pages     = {14487-14495},
  title     = {Daycare matching in japan: Transfers and siblings},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Practical disruption of image translation deepfake networks.
<em>AAAI</em>, 14478–14486. (<a
href="https://doi.org/10.1609/aaai.v37i12.26693">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {By harnessing the latest advances in deep learning, image-to-image translation architectures have recently achieved impressive capabilities. Unfortunately, the growing representational power of these architectures has prominent unethical uses. Among these, the threats of (1) face manipulation (&quot;DeepFakes&quot;) used for misinformation or pornographic use (2) &quot;DeepNude&quot; manipulations of body images to remove clothes from individuals, etc. Several works tackle the task of disrupting such image translation networks by inserting imperceptible adversarial attacks into the input image. Nevertheless, these works have limitations that may result in disruptions that are not practical in the real world. Specifically, most works generate disruptions in a white-box scenario, assuming perfect knowledge about the image translation network. The few remaining works that assume a black-box scenario require a large number of queries to successfully disrupt the adversary&#39;s image translation network. In this work we propose Leaking Transferable Perturbations (LTP), an algorithm that significantly reduces the number of queries needed to disrupt an image translation network by dynamically re-purposing previous disruptions into new query efficient disruptions.},
  archive   = {C_AAAI},
  author    = {Nataniel Ruiz and Sarah Adel Bargal and Cihang Xie and Stan Sclaroff},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26693},
  pages     = {14478-14486},
  title     = {Practical disruption of image translation deepfake networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Detecting anomalous networks of opioid prescribers and
dispensers in prescription drug data. <em>AAAI</em>, 14470–14477. (<a
href="https://doi.org/10.1609/aaai.v37i12.26692">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The opioid overdose epidemic represents a serious public health crisis, with fatality rates rising considerably over the past several years. To help address the abuse of prescription opioids, state governments collect data on dispensed prescriptions, yet the use of these data is typically limited to manual searches. In this paper, we propose a novel graph-based framework for detecting anomalous opioid prescribing patterns in state Prescription Drug Monitoring Program (PDMP) data, which could aid governments in deterring opioid diversion and abuse. Specifically, we seek to identify connected networks of opioid prescribers and dispensers who engage in high-risk and possibly illicit activity. We develop and apply a novel extension of the Non-Parametric Heterogeneous Graph Scan (NPHGS) to two years of de-identified PDMP data from the state of Kansas, and find that NPHGS identifies subgraphs that are significantly more anomalous than those detected by other graph-based methods. NPHGS also reveals clusters of potentially illicit activity, which may strengthen state law enforcement and regulatory capabilities. Our paper is the first to demonstrate how prescription data can systematically identify anomalous opioid prescribers and dispensers, as well as illustrating the efficacy of a network-based approach. Additionally, our technical extensions to NPHGS offer both improved flexibility and graph density reduction, enabling the framework to be replicated across jurisdictions and extended to other problem domains.},
  archive   = {C_AAAI},
  author    = {Katie Rosman and Daniel B. Neill},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26692},
  pages     = {14470-14477},
  title     = {Detecting anomalous networks of opioid prescribers and dispensers in prescription drug data},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Counterfactual fairness is basically demographic parity.
<em>AAAI</em>, 14461–14469. (<a
href="https://doi.org/10.1609/aaai.v37i12.26691">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Making fair decisions is crucial to ethically implementing machine learning algorithms in social settings. In this work, we consider the celebrated definition of counterfactual fairness. We begin by showing that an algorithm which satisfies counterfactual fairness also satisfies demographic parity, a far simpler fairness constraint. Similarly, we show that all algorithms satisfying demographic parity can be trivially modified to satisfy counterfactual fairness. Together, our results indicate that counterfactual fairness is basically equivalent to demographic parity, which has important implications for the growing body of work on counterfactual fairness. We then validate our theoretical findings empirically, analyzing three existing algorithms for counterfactual fairness against three simple benchmarks. We find that two simple benchmark algorithms outperform all three existing algorithms---in terms of fairness, accuracy, and efficiency---on several data sets. Our analysis leads us to formalize a concrete fairness goal: to preserve the order of individuals within protected groups. We believe transparency around the ordering of individuals within protected groups makes fair algorithms more trustworthy. By design, the two simple benchmark algorithms satisfy this goal while the existing algorithms do not.},
  archive   = {C_AAAI},
  author    = {Lucas Rosenblatt and R. Teal Witter},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26691},
  pages     = {14461-14469},
  title     = {Counterfactual fairness is basically demographic parity},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). EINNs: Epidemiologically-informed neural networks.
<em>AAAI</em>, 14453–14460. (<a
href="https://doi.org/10.1609/aaai.v37i12.26690">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We introduce EINNs, a framework crafted for epidemic forecasting that builds upon the theoretical grounds provided by mechanistic models as well as the data-driven expressibility afforded by AI models, and their capabilities to ingest heterogeneous information. Although neural forecasting models have been successful in multiple tasks, predictions well-correlated with epidemic trends and long-term predictions remain open challenges. Epidemiological ODE models contain mechanisms that can guide us in these two tasks; however, they have limited capability of ingesting data sources and modeling composite signals. Thus, we propose to leverage work in physics-informed neural networks to learn latent epidemic dynamics and transfer relevant knowledge to another neural network which ingests multiple data sources and has more appropriate inductive bias. In contrast with previous work, we do not assume the observability of complete dynamics and do not need to numerically solve the ODE equations during training. Our thorough experiments on all US states and HHS regions for COVID-19 and influenza forecasting showcase the clear benefits of our approach in both short-term and long-term forecasting as well as in learning the mechanistic dynamics over other non-trivial alternatives.},
  archive   = {C_AAAI},
  author    = {Alexander Rodríguez and Jiaming Cui and Naren Ramakrishnan and Bijaya Adhikari and B. Aditya Prakash},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26690},
  pages     = {14453-14460},
  title     = {EINNs: Epidemiologically-informed neural networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FakeSV: A multimodal benchmark with rich social context for
fake news detection on short video platforms. <em>AAAI</em>,
14444–14452. (<a
href="https://doi.org/10.1609/aaai.v37i12.26689">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Short video platforms have become an important channel for news sharing, but also a new breeding ground for fake news. To mitigate this problem, research of fake news video detection has recently received a lot of attention. Existing works face two roadblocks: the scarcity of comprehensive and largescale datasets and insufficient utilization of multimodal information. Therefore, in this paper, we construct the largest Chinese short video dataset about fake news named FakeSV, which includes news content, user comments, and publisher profiles simultaneously. To understand the characteristics of fake news videos, we conduct exploratory analysis of FakeSV from different perspectives. Moreover, we provide a new multimodal detection model named SV-FEND, which exploits the cross-modal correlations to select the most informative features and utilizes the social context information for detection. Extensive experiments evaluate the superiority of the proposed method and provide detailed comparisons of different methods and modalities for future works. Our dataset and codes are available in https://github.com/ICTMCG/FakeSV.},
  archive   = {C_AAAI},
  author    = {Peng Qi and Yuyan Bu and Juan Cao and Wei Ji and Ruihao Shui and Junbin Xiao and Danding Wang and Tat-Seng Chua},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26689},
  pages     = {14444-14452},
  title     = {FakeSV: A multimodal benchmark with rich social context for fake news detection on short video platforms},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). For the underrepresented in gender bias research: Chinese
name gender prediction with heterogeneous graph attention network.
<em>AAAI</em>, 14436–14443. (<a
href="https://doi.org/10.1609/aaai.v37i12.26688">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Achieving gender equality is an important pillar for humankind’s sustainable future. Pioneering data-driven gender bias research is based on large-scale public records such as scientific papers, patents, and company registrations, covering female researchers, inventors and entrepreneurs, and so on. Since gender information is often missing in relevant datasets, studies rely on tools to infer genders from names. However, available open-sourced Chinese gender-guessing tools are not yet suitable for scientific purposes, which may be partially responsible for female Chinese being underrepresented in mainstream gender bias research and affect their universality. Specifically, these tools focus on character-level information while overlooking the fact that the combinations of Chinese characters in multi-character names, as well as the components and pronunciations of characters, convey important messages. As a first effort, we design a Chinese Heterogeneous Graph Attention (CHGAT) model to capture the heterogeneity in component relationships and incorporate the pronunciations of characters. Our model largely surpasses current tools and also outperforms the state-of-the-art algorithm. Last but not least, the most popular Chinese name-gender dataset is single-character based with far less female coverage from an unreliable source, naturally hindering relevant studies. We open-source a more balanced multi-character dataset from an official source together with our code, hoping to help future research promoting gender equality.},
  archive   = {C_AAAI},
  author    = {Zihao Pan and Kai Peng and Shuai Ling and Haipeng Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26688},
  pages     = {14436-14443},
  title     = {For the underrepresented in gender bias research: Chinese name gender prediction with heterogeneous graph attention network},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Joint self-supervised image-volume representation learning
with intra-inter contrastive clustering. <em>AAAI</em>, 14426–14435. (<a
href="https://doi.org/10.1609/aaai.v37i12.26687">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Collecting large-scale medical datasets with fully annotated samples for training of deep networks is prohibitively expensive, especially for 3D volume data. Recent breakthroughs in self-supervised learning (SSL) offer the ability to overcome the lack of labeled training samples by learning feature representations from unlabeled data. However, most current SSL techniques in the medical field have been designed for either 2D images or 3D volumes. In practice, this restricts the capability to fully leverage unlabeled data from numerous sources, which may include both 2D and 3D data. Additionally, the use of these pre-trained networks is constrained to downstream tasks with compatible data dimensions. In this paper, we propose a novel framework for unsupervised joint learning on 2D and 3D data modalities. Given a set of 2D images or 2D slices extracted from 3D volumes, we construct an SSL task based on a 2D contrastive clustering problem for distinct classes. The 3D volumes are exploited by computing vectored embedding at each slice and then assembling a holistic feature through deformable self-attention mechanisms in Transformer, allowing incorporating long-range dependencies between slices inside 3D volumes. These holistic features are further utilized to define a novel 3D clustering agreement-based SSL task and masking embedding prediction inspired by pre-trained language models. Experiments on downstream tasks, such as 3D brain segmentation, lung nodule detection, 3D heart structures segmentation, and abnormal chest X-ray detection, demonstrate the effectiveness of our joint 2D and 3D SSL approach. We improve plain 2D Deep-ClusterV2 and SwAV by a significant margin and also surpass various modern 2D and 3D SSL approaches.},
  archive   = {C_AAAI},
  author    = {Duy M. H. Nguyen and Hoang Nguyen and Truong T. N. Mai and Tri Cao and Binh T. Nguyen and Nhat Ho and Paul Swoboda and Shadi Albarqouni and Pengtao Xie and Daniel Sonntag},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26687},
  pages     = {14426-14435},
  title     = {Joint self-supervised image-volume representation learning with intra-inter contrastive clustering},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Carburacy: Summarization models tuning and comparison in
eco-sustainable regimes with a novel carbon-aware accuracy.
<em>AAAI</em>, 14417–14425. (<a
href="https://doi.org/10.1609/aaai.v37i12.26686">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Generative transformer-based models have reached cutting-edge performance in long document summarization. Nevertheless, this task is witnessing a paradigm shift in developing ever-increasingly computationally-hungry solutions, focusing on effectiveness while ignoring the economic, environmental, and social costs of yielding such results. Accordingly, such extensive resources impact climate change and raise barriers to small and medium organizations distinguished by low-resource regimes of hardware and data. As a result, this unsustainable trend has lifted many concerns in the community, which directs the primary efforts on the proposal of tools to monitor models&#39; energy costs. Despite their importance, no evaluation measure considering models&#39; eco-sustainability exists yet. In this work, we propose Carburacy, the first carbon-aware accuracy measure that captures both model effectiveness and eco-sustainability. We perform a comprehensive benchmark for long document summarization, comparing multiple state-of-the-art quadratic and linear transformers on several datasets under eco-sustainable regimes. Finally, thanks to Carburacy, we found optimal combinations of hyperparameters that let models be competitive in effectiveness with significantly lower costs.},
  archive   = {C_AAAI},
  author    = {Gianluca Moro and Luca Ragazzi and Lorenzo Valgimigli},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26686},
  pages     = {14417-14425},
  title     = {Carburacy: Summarization models tuning and comparison in eco-sustainable regimes with a novel carbon-aware accuracy},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Help me heal: A reinforced polite and empathetic mental
health and legal counseling dialogue system for crime victims.
<em>AAAI</em>, 14408–14416. (<a
href="https://doi.org/10.1609/aaai.v37i12.26685">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The potential for conversational agents offering mental health and legal counseling in an autonomous, interactive, and vitally accessible environment is getting highlighted due to the increased access to information through the internet and mobile devices. A counseling conversational agent should be able to offer higher engagement mimicking the real-time counseling sessions. The ability to empathize or comprehend and feel another person’s emotions and experiences is a crucial quality that promotes effective therapeutic bonding and rapport-building. Further, the use of polite encoded language in the counseling reflects the nobility and creates a familiar, warm, and comfortable atmosphere to resolve human issues. Therefore, focusing on these two aspects, we propose a Polite and Empathetic Mental Health and Legal Counseling Dialogue System (Po-Em-MHLCDS) for the victims of crimes. To build Po-Em-MHLCDS, we first create a Mental Health and Legal Counseling Dataset (MHLCD) by recruiting six employees who are asked to converse with each other, acting as a victim and the agent interchangeably following a fixed stated guidelines. Second, the MHLCD dataset is annotated with three informative labels, viz. counseling strategies, politeness, and empathy. Lastly, we train the Po-Em-MHLCDS in a reinforcement learning framework by designing an efficient and effective reward function to reinforce correct counseling strategy, politeness and empathy while maintaining contextual-coherence and non-repetitiveness in the generated responses. Our extensive automatic and human evaluation demonstrate the strength of the proposed system. Codes and Data can be accessed at https://www.iitp.ac.in/ ai-nlp-ml/resources.html#MHLCD or https://github.com/Mishrakshitij/Po-Em-MHLCDS},
  archive   = {C_AAAI},
  author    = {Kshitij Mishra and Priyanshu Priya and Asif Ekbal},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26685},
  pages     = {14408-14416},
  title     = {Help me heal: A reinforced polite and empathetic mental health and legal counseling dialogue system for crime victims},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neighbor auto-grouping graph neural networks for handover
parameter configuration in cellular network. <em>AAAI</em>, 14400–14407.
(<a href="https://doi.org/10.1609/aaai.v37i12.26684">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The mobile communication enabled by cellular networks is the one of the main foundations of our modern society. Optimizing the performance of cellular networks and providing massive connectivity with improved coverage and user experience has a considerable social and economic impact on our daily life. This performance relies heavily on the configuration of the network parameters. However, with the massive increase in both the size and complexity of cellular networks, network management, especially parameter configuration, is becoming complicated. The current practice, which relies largely on experts&#39; prior knowledge, is not adequate and will require lots of domain experts and high maintenance costs. In this work, we propose a learning-based framework for handover parameter configuration. The key challenge, in this case, is to tackle the complicated dependencies between neighboring cells and jointly optimize the whole network. Our framework addresses this challenge in two ways. First, we introduce a novel approach to imitate how the network responds to different network states and parameter values, called auto-grouping graph convolutional network (AG-GCN). During the parameter configuration stage, instead of solving the global optimization problem, we design a local multi-objective optimization strategy where each cell considers several local performance metrics to balance its own performance and its neighbors. We evaluate our proposed algorithm via a simulator constructed using real network data. We demonstrate that the handover parameters our model can find, achieve better average network throughput compared to those recommended by experts as well as alternative baselines, which can bring better network quality and stability. It has the potential to massively reduce costs arising from human expert intervention and maintenance.},
  archive   = {C_AAAI},
  author    = {Mehrtash Mehrabi and Walid Masoudimansour and Yingxue Zhang and Jie Chuai and Zhitang Chen and Mark Coates and Jianye Hao and Yanhui Geng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26684},
  pages     = {14400-14407},
  title     = {Neighbor auto-grouping graph neural networks for handover parameter configuration in cellular network},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). LUCID: Exposing algorithmic bias through inverse design.
<em>AAAI</em>, 14391–14399. (<a
href="https://doi.org/10.1609/aaai.v37i12.26683">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {AI systems can create, propagate, support, and automate bias in decision-making processes. To mitigate biased decisions, we both need to understand the origin of the bias and define what it means for an algorithm to make fair decisions. Most group fairness notions assess a model&#39;s equality of outcome by computing statistical metrics on the outputs. We argue that these output metrics encounter intrinsic obstacles and present a complementary approach that aligns with the increasing focus on equality of treatment. By Locating Unfairness through Canonical Inverse Design (LUCID), we generate a canonical set that shows the desired inputs for a model given a preferred output. The canonical set reveals the model&#39;s internal logic and exposes potential unethical biases by repeatedly interrogating the decision-making process. We evaluate LUCID on the UCI Adult and COMPAS data sets and find that some biases detected by a canonical set differ from those of output metrics. The results show that by shifting the focus towards equality of treatment and looking into the algorithm&#39;s internal workings, the canonical sets are a valuable addition to the toolbox of algorithmic fairness evaluation.},
  archive   = {C_AAAI},
  author    = {Carmen Mazijn and Carina Prunkl and Andres Algaba and Jan Danckaert and Vincent Ginis},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26683},
  pages     = {14391-14399},
  title     = {LUCID: Exposing algorithmic bias through inverse design},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bugs in the data: How ImageNet misrepresents biodiversity.
<em>AAAI</em>, 14382–14390. (<a
href="https://doi.org/10.1609/aaai.v37i12.26682">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {ImageNet-1k is a dataset often used for benchmarking machine learning (ML) models and evaluating tasks such as image recognition and object detection. Wild animals make up 27\% of ImageNet-1k but, unlike classes representing people and objects, these data have not been closely scrutinized. In the current paper, we analyze the 13,450 images from 269 classes that represent wild animals in the ImageNet-1k validation set, with the participation of expert ecologists. We find that many of the classes are ill-defined or overlapping, and that 12\% of the images are incorrectly labeled, with some classes having &gt;90\% of images incorrect. We also find that both the wildlife-related labels and images included in ImageNet-1k present significant geographical and cultural biases, as well as ambiguities such as artificial animals, multiple species in the same image, or the presence of humans. Our findings highlight serious issues with the extensive use of this dataset for evaluating ML systems, the use of such algorithms in wildlife-related tasks, and more broadly the ways in which ML datasets are commonly created and curated.},
  archive   = {C_AAAI},
  author    = {Alexandra Sasha Luccioni and David Rolnick},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26682},
  pages     = {14382-14390},
  title     = {Bugs in the data: How ImageNet misrepresents biodiversity},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A composite multi-attention framework for intraoperative
hypotension early warning. <em>AAAI</em>, 14374–14381. (<a
href="https://doi.org/10.1609/aaai.v37i12.26681">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Intraoperative hypotension (IOH) events warning plays a crucial role in preventing postoperative complications, such as postoperative delirium and mortality. Despite significant efforts, two fundamental problems limit its wide clinical use. The well-established IOH event warning systems are often built on proprietary medical devices that may not be available in all hospitals. The warnings are also triggered mainly through a predefined IOH event that might not be suitable for all patients. This work proposes a composite multi-attention (CMA) framework to tackle these problems by conducting short-term predictions on user-definable IOH events using vital signals in a low sampling rate with demographic characteristics. Our framework leverages a multi-modal fusion network to make four vital signals and three demographic characteristics as input modalities. For each modality, a multi-attention mechanism is used for feature extraction for better model training. Experiments on two large-scale real-world data sets show that our method can achieve up to 94.1\% accuracy on IOH events early warning while the signals sampling rate is reduced by 3000 times. Our proposal CMA can achieve a mean absolute error of 4.50 mm Hg in the most challenging 15-minute mean arterial pressure prediction task and the error reduction by 42.9\% compared to existing solutions.},
  archive   = {C_AAAI},
  author    = {Feng Lu and Wei Li and Zhiqiang Zhou and Cheng Song and Yifei Sun and Yuwei Zhang and Yufei Ren and Xiaofei Liao and Hai Jin and Ailin Luo and Albert Y. Zomaya},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26681},
  pages     = {14374-14381},
  title     = {A composite multi-attention framework for intraoperative hypotension early warning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Task-adaptive meta-learning framework for advancing spatial
generalizability. <em>AAAI</em>, 14365–14373. (<a
href="https://doi.org/10.1609/aaai.v37i12.26680">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Spatio-temporal machine learning is critically needed for a variety of societal applications, such as agricultural monitoring, hydrological forecast, and traffic management. These applications greatly rely on regional features that characterize spatial and temporal differences. However, spatio-temporal data often exhibit complex patterns and significant data variability across different locations. The labels in many real-world applications can also be limited, which makes it difficult to separately train independent models for different locations. Although meta learning has shown promise in model adaptation with small samples, existing meta learning methods remain limited in handling a large number of heterogeneous tasks, e.g., a large number of locations with varying data patterns. To bridge the gap, we propose task-adaptive formulations and a model-agnostic meta-learning framework that transforms regionally heterogeneous data into location-sensitive meta tasks. We conduct task adaptation following an easy-to-hard task hierarchy in which different meta models are adapted to tasks of different difficulty levels. One major advantage of our proposed method is that it improves the model adaptation to a large number of heterogeneous tasks. It also enhances the model generalization by automatically adapting the meta model of the corresponding difficulty level to any new tasks. We demonstrate the superiority of our proposed framework over a diverse set of baselines and state-of-the-art meta-learning frameworks. Our extensive experiments on real crop yield data show the effectiveness of the proposed method in handling spatial-related heterogeneous tasks in real societal applications.},
  archive   = {C_AAAI},
  author    = {Zhexiong Liu and Licheng Liu and Yiqun Xie and Zhenong Jin and Xiaowei Jia},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26680},
  pages     = {14365-14373},
  title     = {Task-adaptive meta-learning framework for advancing spatial generalizability},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Interpretable chirality-aware graph neural network for
quantitative structure activity relationship modeling in drug discovery.
<em>AAAI</em>, 14356–14364. (<a
href="https://doi.org/10.1609/aaai.v37i12.26679">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In computer-aided drug discovery, quantitative structure activity relation models are trained to predict biological activity from chemical structure. Despite the recent success of applying graph neural network to this task, important chemical information such as molecular chirality is ignored. To fill this crucial gap, we propose Molecular-Kernel Graph NeuralNetwork (MolKGNN) for molecular representation learning, which features SE(3)-/conformation invariance, chirality-awareness, and interpretability. For our MolKGNN, we first design a molecular graph convolution to capture the chemical pattern by comparing the atom&#39;s similarity with the learnable molecular kernels. Furthermore, we propagate the similarity score to capture the higher-order chemical pattern. To assess the method, we conduct a comprehensive evaluation with nine well-curated datasets spanning numerous important drug targets that feature realistic high class imbalance and it demonstrates the superiority of MolKGNN over other graph neural networks in computer-aided drug discovery. Meanwhile, the learned kernels identify patterns that agree with domain knowledge, confirming the pragmatic interpretability of this approach. Our code and supplementary material are publicly available at https://github.com/meilerlab/MolKGNN.},
  archive   = {C_AAAI},
  author    = {Yunchao (Lance) Liu and Yu Wang and Oanh Vu and Rocco Moretti and Bobby Bodenheimer and Jens Meiler and Tyler Derr},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26679},
  pages     = {14356-14364},
  title     = {Interpretable chirality-aware graph neural network for quantitative structure activity relationship modeling in drug discovery},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Human mobility modeling during the COVID-19 pandemic via
deep graph diffusion infomax. <em>AAAI</em>, 14347–14355. (<a
href="https://doi.org/10.1609/aaai.v37i12.26678">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Non-Pharmaceutical Interventions (NPIs), such as social gathering restrictions, have shown effectiveness to slow the transmission of COVID-19 by reducing the contact of people. To support policy-makers, multiple studies have first modelled human mobility via macro indicators (e.g., average daily travel distance) and then study the effectiveness of NPIs. In this work, we focus on mobility modelling and, from a micro perspective, aim to predict locations that will be visited by COVID-19 cases. Since NPIs generally cause economic and societal loss, such a prediction benefits governments when they design and evaluate them. However, in real-world situations, strict privacy data protection regulations result in severe data sparsity problems (i.e., limited case and location information). To address these challenges and jointly model variables including a geometric graph, a set of diffusions and a set of locations, we propose a model named Deep Graph Diffusion Infomax (DGDI). We show the maximization of DGDI can be bounded by two tractable components: a univariate Mutual Information (MI) between geometric graph and diffusion representation, and a univariate MI between diffusion representation and location representation. To facilitate the research of COVID-19 prediction, we present two benchmarks that contain geometric graphs and location histories of COVID-19 cases. Extensive experiments on the two benchmarks show that DGDI significantly outperforms other competing methods.},
  archive   = {C_AAAI},
  author    = {Yang Liu and Yu Rong and Zhuoning Guo and Nuo Chen and Tingyang Xu and Fugee Tsung and Jia Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26678},
  pages     = {14347-14355},
  title     = {Human mobility modeling during the COVID-19 pandemic via deep graph diffusion infomax},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SimFair: A unified framework for fairness-aware multi-label
classification. <em>AAAI</em>, 14338–14346. (<a
href="https://doi.org/10.1609/aaai.v37i12.26677">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent years have witnessed increasing concerns towards unfair decisions made by machine learning algorithms. To improve fairness in model decisions, various fairness notions have been proposed and many fairness-aware methods are developed. However, most of existing definitions and methods focus only on single-label classification. Fairness for multi-label classification, where each instance is associated with more than one labels, is still yet to establish. To fill this gap, we study fairness-aware multi-label classification in this paper. We start by extending Demographic Parity (DP) and Equalized Opportunity (EOp), two popular fairness notions, to multi-label classification scenarios. Through a systematic study, we show that on multi-label data, because of unevenly distributed labels, EOp usually fails to construct a reliable estimate on labels with few instances. We then propose a new framework named Similarity s-induced Fairness (sγ -SimFair). This new framework utilizes data that have similar labels when estimating fairness on a particular label group for better stability, and can unify DP and EOp. Theoretical analysis and experimental results on real-world datasets together demonstrate the advantage of sγ -SimFair over existing methods on multi-label classification tasks.},
  archive   = {C_AAAI},
  author    = {Tianci Liu and Haoyu Wang and Yaqing Wang and Xiaoqian Wang and Lu Su and Jing Gao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26677},
  pages     = {14338-14346},
  title     = {SimFair: A unified framework for fairness-aware multi-label classification},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AirFormer: Predicting nationwide air quality in china with
transformers. <em>AAAI</em>, 14329–14337. (<a
href="https://doi.org/10.1609/aaai.v37i12.26676">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Air pollution is a crucial issue affecting human health and livelihoods, as well as one of the barriers to economic growth. Forecasting air quality has become an increasingly important endeavor with significant social impacts, especially in emerging countries. In this paper, we present a novel Transformer termed AirFormer to predict nationwide air quality in China, with an unprecedented fine spatial granularity covering thousands of locations. AirFormer decouples the learning process into two stages: 1) a bottom-up deterministic stage that contains two new types of self-attention mechanisms to efficiently learn spatio-temporal representations; 2) a top-down stochastic stage with latent variables to capture the intrinsic uncertainty of air quality data. We evaluate AirFormer with 4-year data from 1,085 stations in Chinese Mainland. Compared to prior models, AirFormer reduces prediction errors by 5\%∼8\% on 72-hour future predictions. Our source code is available at https://github.com/yoshall/airformer.},
  archive   = {C_AAAI},
  author    = {Yuxuan Liang and Yutong Xia and Songyu Ke and Yiwei Wang and Qingsong Wen and Junbo Zhang and Yu Zheng and Roger Zimmermann},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26676},
  pages     = {14329-14337},
  title     = {AirFormer: Predicting nationwide air quality in china with transformers},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). Point-to-region co-learning for poverty mapping at high
resolution using satellite imagery. <em>AAAI</em>, 14321–14328. (<a
href="https://doi.org/10.1609/aaai.v37i12.26675">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Despite improvements in safe water and sanitation services in low-income countries, a substantial proportion of the population in Africa still does not have access to these essential services. Up-to-date fine-scale maps of low-income settlements are urgently needed by authorities to improve service provision. We aim to develop a cost-effective solution to generate fine-scale maps of these vulnerable populations using multi-source public information. The problem is challenging as ground-truth maps are available at only a limited number of cities, and the patterns are heterogeneous across cities. Recent attempts tackling the spatial heterogeneity issue focus on scenarios where true labels partially exist for each input region, which are unavailable for the present problem. We propose a dynamic point-to-region co-learning framework to learn heterogeneity patterns that cannot be reflected by point-level information and generalize deep learners to new areas with no labels. We also propose an attention-based correction layer to remove spurious signatures, and a region-gate to capture both region-invariant and variant patterns. Experiment results on real-world fine-scale data in three cities of Kenya show that the proposed approach can largely improve model performance on various base network architectures.},
  archive   = {C_AAAI},
  author    = {Zhili Li and Yiqun Xie and Xiaowei Jia and Kara Stuart and Caroline Delaire and Sergii Skakun},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26675},
  pages     = {14321-14328},
  title     = {Point-to-region co-learning for poverty mapping at high resolution using satellite imagery},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Accurate fairness: Improving individual fairness without
trading accuracy. <em>AAAI</em>, 14312–14320. (<a
href="https://doi.org/10.1609/aaai.v37i12.26674">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Accuracy and individual fairness are both crucial for trustworthy machine learning, but these two aspects are often incompatible with each other so that enhancing one aspect may sacrifice the other inevitably with side effects of true bias or false fairness. We propose in this paper a new fairness criterion, accurate fairness, to align individual fairness with accuracy. Informally, it requires the treatments of an individual and the individual&#39;s similar counterparts to conform to a uniform target, i.e., the ground truth of the individual. We prove that accurate fairness also implies typical group fairness criteria over a union of similar sub-populations. We then present a Siamese fairness in-processing approach to minimize the accuracy and fairness losses of a machine learning model under the accurate fairness constraints. To the best of our knowledge, this is the first time that a Siamese approach is adapted for bias mitigation. We also propose fairness confusion matrix-based metrics, fair-precision, fair-recall, and fair-F1 score, to quantify a trade-off between accuracy and individual fairness. Comparative case studies with popular fairness datasets show that our Siamese fairness approach can achieve on average 1.02\%-8.78\% higher individual fairness (in terms of fairness through awareness) and 8.38\%-13.69\% higher accuracy, as well as 10.09\%-20.57\% higher true fair rate, and 5.43\%-10.01\% higher fair-F1 score, than the state-of-the-art bias mitigation techniques. This demonstrates that our Siamese fairness approach can indeed improve individual fairness without trading accuracy. Finally, the accurate fairness criterion and Siamese fairness approach are applied to mitigate the possible service discrimination with a real Ctrip dataset, by on average fairly serving 112.33\% more customers (specifically, 81.29\% more customers in an accurately fair way) than baseline models.},
  archive   = {C_AAAI},
  author    = {Xuran Li and Peng Wu and Jing Su},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26674},
  pages     = {14312-14320},
  title     = {Accurate fairness: Improving individual fairness without trading accuracy},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Equivariant message passing neural network for crystal
material discovery. <em>AAAI</em>, 14304–14311. (<a
href="https://doi.org/10.1609/aaai.v37i12.26673">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Automatic material discovery with desired properties is a fundamental challenge for material sciences. Considerable attention has recently been devoted to generating stable crystal structures. While existing work has shown impressive success on supervised tasks such as property prediction, the progress on unsupervised tasks such as material generation is still hampered by the limited extent to which the equivalent geometric representations of the same crystal are considered. To address this challenge, we propose EPGNN a periodic equivariant message-passing neural network that learns crystal lattice deformation in an unsupervised fashion. Our model equivalently acts on lattice according to the deformation action that must be performed, making it suitable for crystal generation, relaxation and optimisation. We present experimental evaluations that demonstrate the effectiveness of our approach.},
  archive   = {C_AAAI},
  author    = {Astrid Klipfel and Zied Bouraoui and Olivier Peltre and Yaël Fregier and Najwa Harrati and Adlane Sayede},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26673},
  pages     = {14304-14311},
  title     = {Equivariant message passing neural network for crystal material discovery},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust planning over restless groups: Engagement
interventions for a large-scale maternal telehealth program.
<em>AAAI</em>, 14295–14303. (<a
href="https://doi.org/10.1609/aaai.v37i12.26672">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In 2020, maternal mortality in India was estimated to be as high as 130 deaths per 100K live births, nearly twice the UN&#39;s target. To improve health outcomes, the non-profit ARMMAN sends automated voice messages to expecting and new mothers across India. However, 38\% of mothers stop listening to these calls, missing critical preventative care information. To improve engagement, ARMMAN employs health workers to intervene by making service calls, but workers can only call a fraction of the 100K enrolled mothers. Partnering with ARMMAN, we model the problem of allocating limited interventions across mothers as a restless multi-armed bandit (RMAB), where the realities of large scale and model uncertainty present key new technical challenges. We address these with GROUPS, a double oracle–based algorithm for robust planning in RMABs with scalable grouped arms. Robustness over grouped arms requires several methodological advances. First, to adversarially select stochastic group dynamics, we develop a new method to optimize Whittle indices over transition probability intervals. Second, to learn group-level RMAB policy best responses to these adversarial environments, we introduce a weighted index heuristic. Third, we prove a key theoretical result that planning over grouped arms achieves the same minimax regret--optimal strategy as planning over individual arms, under a technical condition. Finally, using real-world data from ARMMAN, we show that GROUPS produces robust policies that reduce minimax regret by up to 50\%, halving the number of preventable missed voice messages to connect more mothers with life-saving maternal health information.},
  archive   = {C_AAAI},
  author    = {Jackson A. Killian and Arpita Biswas and Lily Xu and Shresth Verma and Vineet Nair and Aparna Taneja and Aparna Hegde and Neha Madhiwalla and Paula Rodriguez Diaz and Sonja Johnson-Yu and Milind Tambe},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26672},
  pages     = {14295-14303},
  title     = {Robust planning over restless groups: Engagement interventions for a large-scale maternal telehealth program},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Winning the CityLearn challenge: Adaptive optimization with
evolutionary search under trajectory-based guidance. <em>AAAI</em>,
14286–14294. (<a
href="https://doi.org/10.1609/aaai.v37i12.26671">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Modern power systems will have to face difficult challenges in the years to come: frequent blackouts in urban areas caused by high peaks of electricity demand, grid instability exacerbated by the intermittency of renewable generation, and climate change on a global scale amplified by increasing carbon emissions. While current practices are growingly inadequate, the pathway of artificial intelligence (AI)-based methods to widespread adoption is hindered by missing aspects of trustworthiness. The CityLearn Challenge is an exemplary opportunity for researchers from multi-disciplinary fields to investigate the potential of AI to tackle these pressing issues within the energy domain, collectively modeled as a reinforcement learning (RL) task. Multiple real-world challenges faced by contemporary RL techniques are embodied in the problem formulation. In this paper, we present a novel method using the solution function of optimization as policies to compute the actions for sequential decision-making, while notably adapting the parameters of the optimization model from online observations. Algorithmically, this is achieved by an evolutionary algorithm under a novel trajectory-based guidance scheme. Formally, the global convergence property is established. Our agent ranked first in the latest 2021 CityLearn Challenge, being able to achieve superior performance in almost all metrics while maintaining some key aspects of interpretability.},
  archive   = {C_AAAI},
  author    = {Vanshaj Khattar and Ming Jin},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26671},
  pages     = {14286-14294},
  title     = {Winning the CityLearn challenge: Adaptive optimization with evolutionary search under trajectory-based guidance},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Taxonomizing and measuring representational harms: A look at
image tagging. <em>AAAI</em>, 14277–14285. (<a
href="https://doi.org/10.1609/aaai.v37i12.26670">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we examine computational approaches for measuring the &quot;fairness&quot; of image tagging systems, finding that they cluster into five distinct categories, each with its own analytic foundation. We also identify a range of normative concerns that are often collapsed under the terms &quot;unfairness,&quot; &quot;bias,&quot; or even &quot;discrimination&quot; when discussing problematic cases of image tagging. Specifically, we identify four types of representational harms that can be caused by image tagging systems, providing concrete examples of each. We then consider how different computational measurement approaches map to each of these types, demonstrating that there is not a one-to-one mapping. Our findings emphasize that no single measurement approach will be definitive and that it is not possible to infer from the use of a particular measurement approach which type of harm was intended to be measured. Lastly, equipped with this more granular understanding of the types of representational harms that can be caused by image tagging systems, we show that attempts to mitigate some of these types of harms may be in tension with one another.},
  archive   = {C_AAAI},
  author    = {Jared Katzman and Angelina Wang and Morgan Scheuerman and Su Lin Blodgett and Kristen Laird and Hanna Wallach and Solon Barocas},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26670},
  pages     = {14277-14285},
  title     = {Taxonomizing and measuring representational harms: A look at image tagging},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spatio-temporal graph neural point process for traffic
congestion event prediction. <em>AAAI</em>, 14268–14276. (<a
href="https://doi.org/10.1609/aaai.v37i12.26669">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Traffic congestion event prediction is an important yet challenging task in intelligent transportation systems. Many existing works about traffic prediction integrate various temporal encoders and graph convolution networks (GCNs), called spatio-temporal graph-based neural networks, which focus on predicting dense variables such as flow, speed and demand in time snapshots, but they can hardly forecast the traffic congestion events that are sparsely distributed on the continuous time axis. In recent years, neural point process (NPP) has emerged as an appropriate framework for event prediction in continuous time scenarios. However, most conventional works about NPP cannot model the complex spatio-temporal dependencies and congestion evolution patterns. To address these limitations, we propose a spatio-temporal graph neural point process framework, named STGNPP for traffic congestion event prediction. Specifically, we first design the spatio-temporal graph learning module to fully capture the long-range spatio-temporal dependencies from the historical traffic state data along with the road network. The extracted spatio-temporal hidden representation and congestion event information are then fed into a continuous gated recurrent unit to model the congestion evolution patterns. In particular, to fully exploit the periodic information, we also improve the intensity function calculation of the point process with a periodic gated mechanism. Finally, our model simultaneously predicts the occurrence time and duration of the next congestion. Extensive experiments on two real-world datasets demonstrate that our method achieves superior performance in comparison to existing state-of-the-art approaches.},
  archive   = {C_AAAI},
  author    = {Guangyin Jin and Lingbo Liu and Fuxian Li and Jincai Huang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26669},
  pages     = {14268-14276},
  title     = {Spatio-temporal graph neural point process for traffic congestion event prediction},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Low emission building control with zero-shot reinforcement
learning. <em>AAAI</em>, 14259–14267. (<a
href="https://doi.org/10.1609/aaai.v37i12.26668">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Heating and cooling systems in buildings account for 31\% of global energy use, much of which are regulated by Rule Based Controllers (RBCs) that neither maximise energy efficiency nor minimise emissions by interacting optimally with the grid. Control via Reinforcement Learning (RL) has been shown to significantly improve building energy efficiency, but existing solutions require access to building-specific simulators or data that cannot be expected for every building in the world. In response, we show it is possible to obtain emission-reducing policies without such knowledge a priori–a paradigm we call zero-shot building control. We combine ideas from system identification and model-based RL to create PEARL (Probabilistic Emission-Abating Reinforcement Learning) and show that a short period of active exploration is all that is required to build a performant model. In experiments across three varied building energy simulations, we show PEARL outperforms an existing RBC once, and popular RL baselines in all cases, reducing building emissions by as much as 31\% whilst maintaining thermal comfort. Our source code is available online via: https://enjeeneer.io/projects/pearl/.},
  archive   = {C_AAAI},
  author    = {Scott Jeen and Alessandro Abate and Jonathan M. Cullen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26668},
  pages     = {14259-14267},
  title     = {Low emission building control with zero-shot reinforcement learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Walkability optimization: Formulations, algorithms, and a
case study of toronto. <em>AAAI</em>, 14249–14258. (<a
href="https://doi.org/10.1609/aaai.v37i12.26667">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The concept of walkable urban development has gained increased attention due to its public health, economic, and environmental sustainability benefits. Unfortunately, land zoning and historic under-investment have resulted in spatial inequality in walkability and social inequality among residents. We tackle the problem of Walkability Optimization through the lens of combinatorial optimization. The task is to select locations in which additional amenities (e.g., grocery stores, schools, restaurants) can be allocated to improve resident access via walking while taking into account existing amenities and providing multiple options (e.g., for restaurants). To this end, we derive Mixed-Integer Linear Programming (MILP) and Constraint Programming (CP) models. Moreover, we show that the problem’s objective function is submodular in special cases, which motivates an efficient greedy heuristic. We conduct a case study on 31 underserved neighborhoods in the City of Toronto, Canada. MILP finds the best solutions in most scenarios but does not scale well with network size. The greedy algorithm scales well and finds high-quality solutions. Our empirical evaluation shows that neighbourhoods with low walkability have a great potential for transformation into pedestrian-friendly neighbourhoods by strategically placing new amenities. Allocating 3 additional grocery stores, schools, and restaurants can improve the “WalkScore” by more than 50 points (on a scale of 100) for 4 neighbourhoods and reduce the walking distances to amenities for 75\% of all residential locations to 10 minutes for all amenity types. Our code and paper appendix are available at https://github.com/khalil-research/walkability.},
  archive   = {C_AAAI},
  author    = {Weimin Huang and Elias B. Khalil},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26667},
  pages     = {14249-14258},
  title     = {Walkability optimization: Formulations, algorithms, and a case study of toronto},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MTDiag: An effective multi-task framework for automatic
diagnosis. <em>AAAI</em>, 14241–14248. (<a
href="https://doi.org/10.1609/aaai.v37i12.26666">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Automatic diagnosis systems aim to probe for symptoms (i.e., symptom checking) and diagnose disease through multi-turn conversations with patients. Most previous works formulate it as a sequential decision process and use reinforcement learning (RL) to decide whether to inquire about symptoms or make a diagnosis. However, these RL-based methods heavily rely on the elaborate reward function and usually suffer from an unstable training process and low data efficiency. In this work, we propose an effective multi-task framework for automatic diagnosis called MTDiag. We first reformulate symptom checking as a multi-label classification task by direct supervision. Each medical dialogue is equivalently converted into multiple samples for classification, which can also help alleviate the data scarcity problem. Furthermore, we design a multi-task learning strategy to guide the symptom checking procedure with disease information and further utilize contrastive learning to better distinguish symptoms between diseases. Extensive experimental results show that our method achieves state-of-the-art performance on four public datasets with 1.7\%~3.1\% improvement in disease diagnosis, demonstrating the superiority of the proposed method. Additionally, our model is now deployed in an online medical consultant system as an assistant tool for real-life doctors.},
  archive   = {C_AAAI},
  author    = {Zhenyu Hou and Yukuo Cen and Ziding Liu and Dongxue Wu and Baoyan Wang and Xuanhe Li and Lei Hong and Jie Tang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26666},
  pages     = {14241-14248},
  title     = {MTDiag: An effective multi-task framework for automatic diagnosis},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). “Nothing abnormal”: Disambiguating medical reports via
contrastive knowledge infusion. <em>AAAI</em>, 14232–14240. (<a
href="https://doi.org/10.1609/aaai.v37i12.26665">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Sharing medical reports is essential for patient-centered care. A recent line of work has focused on automatically generating reports with NLP methods. However, different audiences have different purposes when writing/reading medical reports – for example, healthcare professionals care more about pathology, whereas patients are more concerned with the diagnosis (&quot;Is there any abnormality?&quot;). The expectation gap results in a common situation where patients find their medical reports to be ambiguous and therefore unsure about the next steps. In this work, we explore the audience expectation gap in healthcare and summarize common ambiguities that lead patients to be confused about their diagnosis into three categories: medical jargon, contradictory findings, and misleading grammatical errors. Based on our analysis, we define a disambiguation rewriting task to regenerate an input to be unambiguous while preserving information about the original content. We further propose a rewriting algorithm based on contrastive pretraining and perturbation-based rewriting. In addition, we create two datasets, OpenI-Annotated based on chest reports and VA-Annotated based on general medical reports, with available binary labels for ambiguity and abnormality presence annotated by radiology specialists. Experimental results on these datasets show that our proposed algorithm effectively rewrites input sentences in a less ambiguous way with high content fidelity. Our code and annotated data will be released to facilitate future research.},
  archive   = {C_AAAI},
  author    = {Zexue He and An Yan and Amilcare Gentili and Julian McAuley and Chun-Nan Hsu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26665},
  pages     = {14232-14240},
  title     = {“Nothing abnormal”: Disambiguating medical reports via contrastive knowledge infusion},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Physics guided neural networks for time-aware fairness: An
application in crop yield prediction. <em>AAAI</em>, 14223–14231. (<a
href="https://doi.org/10.1609/aaai.v37i12.26664">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper proposes a physics-guided neural network model to predict crop yield and maintain the fairness over space. Failures to preserve the spatial fairness in predicted maps of crop yields can result in biased policies and intervention strategies in the distribution of assistance or subsidies in supporting individuals at risk. Existing methods for fairness enforcement are not designed for capturing the complex physical processes that underlie the crop growing process, and thus are unable to produce good predictions over large regions under different weather conditions and soil properties. More importantly, the fairness is often degraded when existing methods are applied to different years due to the change of weather conditions and farming practices. To address these issues, we propose a physics-guided neural network model, which leverages the physical knowledge from existing physics-based models to guide the extraction of representative physical information and discover the temporal data shift across years. In particular, we use a reweighting strategy to discover the relationship between training years and testing years using the physics-aware representation. Then the physics-guided neural network will be refined via a bi-level optimization process based on the reweighted fairness objective. The proposed method has been evaluated using real county-level crop yield data and simulated data produced by a physics-based model. The results demonstrate that this method can significantly improve the predictive performance and preserve the spatial fairness when generalized to different years.},
  archive   = {C_AAAI},
  author    = {Erhu He and Yiqun Xie and Licheng Liu and Weiye Chen and Zhenong Jin and Xiaowei Jia},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26664},
  pages     = {14223-14231},
  title     = {Physics guided neural networks for time-aware fairness: An application in crop yield prediction},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GAN-based domain inference attack. <em>AAAI</em>,
14214–14222. (<a
href="https://doi.org/10.1609/aaai.v37i12.26663">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Model-based attacks can infer training data information from deep neural network models. These attacks heavily depend on the attacker&#39;s knowledge of the application domain, e.g., using it to determine the auxiliary data for model-inversion attacks. However, attackers may not know what the model is used for in practice. We propose a generative adversarial network (GAN) based method to explore likely or similar domains of a target model -- the model domain inference (MDI) attack. For a given target (classification) model, we assume that the attacker knows nothing but the input and output formats and can use the model to derive the prediction for any input in the desired form. Our basic idea is to use the target model to affect a GAN training process for a candidate domain&#39;s dataset that is easy to obtain. We find that the target model may distort the training procedure less if the domain is more similar to the target domain. We then measure the distortion level with the distance between GAN-generated datasets, which can be used to rank candidate domains for the target model. Our experiments show that the auxiliary dataset from an MDI top-ranked domain can effectively boost the result of model-inversion attacks.},
  archive   = {C_AAAI},
  author    = {Yuechun Gu and Keke Chen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26663},
  pages     = {14214-14222},
  title     = {GAN-based domain inference attack},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Critical firms prediction for stemming contagion risk in
networked-loans through graph-based deep reinforcement learning.
<em>AAAI</em>, 14205–14213. (<a
href="https://doi.org/10.1609/aaai.v37i12.26662">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The networked-loan is major financing support for Micro, Small and Medium-sized Enterprises (MSMEs) in some developing countries. But external shocks may weaken the financial networks&#39; robustness; an accidental default may spread across the network and collapse the whole network. Thus, predicting the critical firms in networked-loans to stem contagion risk and prevent potential systemic financial crises is of crucial significance to the long-term health of inclusive finance and sustainable economic development. Existing approaches in the banking industry dismiss the contagion risk across loan networks and need extensive knowledge with sophisticated financial expertise. Regarding the issues, we propose a novel approach to predict critical firms for stemming contagion risk in the bank industry with deep reinforcement learning integrated with high-order graph message-passing networks. We demonstrate that our approach outperforms the state-of-the-art baselines significantly on the dataset from a large commercial bank. Moreover, we also conducted empirical studies on the real-world loan dataset for risk mitigation. The proposed approach enables financial regulators and risk managers to better track and understands contagion and systemic risk in networked-loans. The superior performance also represents a paradigm shift in addressing the modern challenges in financing support of MSMEs and sustainable economic development.},
  archive   = {C_AAAI},
  author    = {Dawei Cheng and Zhibin Niu and Jianfu Zhang and Yiyi Zhang and Changjun Jiang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26662},
  pages     = {14205-14213},
  title     = {Critical firms prediction for stemming contagion risk in networked-loans through graph-based deep reinforcement learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Improving interpretability of deep sequential knowledge
tracing models with question-centric cognitive representations.
<em>AAAI</em>, 14196–14204. (<a
href="https://doi.org/10.1609/aaai.v37i12.26661">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Knowledge tracing (KT) is a crucial technique to predict students’ future performance by observing their historical learning processes. Due to the powerful representation ability of deep neural networks, remarkable progress has been made by using deep learning techniques to solve the KT problem. The majority of existing approaches rely on the homogeneous question assumption that questions have equivalent contributions if they share the same set of knowledge components. Unfortunately, this assumption is inaccurate in real-world educational scenarios. Furthermore, it is very challenging to interpret the prediction results from the existing deep learning based KT models. Therefore, in this paper, we present QIKT, a question-centric interpretable KT model to address the above challenges. The proposed QIKT approach explicitly models students’ knowledge state variations at a ﬁne-grained level with question-sensitive cognitive representations that are jointly learned from a question-centric knowledge acquisition module and a question-centric problem solving module. Meanwhile, the QIKT utilizes an item response theory based prediction layer to generate interpretable prediction results. The proposed QIKT model is evaluated on three public real-world educational datasets. The results demonstrate that our approach is superior on the KT prediction task, and it outperforms a wide range of deep learning based KT models in terms of prediction accuracy with better model interpretability. To encourage reproducible results, we have provided all the datasets and code at https://pykt.org/.},
  archive   = {C_AAAI},
  author    = {Jiahao Chen and Zitao Liu and Shuyan Huang and Qiongqiong Liu and Weiqi Luo},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26661},
  pages     = {14196-14204},
  title     = {Improving interpretability of deep sequential knowledge tracing models with question-centric cognitive representations},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SARAS-net: Scale and relation aware siamese network for
change detection. <em>AAAI</em>, 14187–14195. (<a
href="https://doi.org/10.1609/aaai.v37i12.26660">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Change detection (CD) aims to find the difference between two images at different times and output a change map to represent whether the region has changed or not. To achieve a better result in generating the change map, many State-of-The-Art (SoTA) methods design a deep learning model that has a powerful discriminative ability. However, these methods still get lower performance because they ignore spatial information and scaling changes between objects, giving rise to blurry boundaries. In addition to these, they also neglect the interactive information of two different images. To alleviate these problems, we propose our network, the Scale and Relation-Aware Siamese Network (SARAS-Net) to deal with this issue. In this paper, three modules are proposed that include relation-aware, scale-aware, and cross-transformer to tackle the problem of scene change detection more effectively. To verify our model, we tested three public datasets, including LEVIR-CD, WHU-CD, and DSFIN, and obtained SoTA accuracy. Our code is available at https://github.com/f64051041/SARAS-Net.},
  archive   = {C_AAAI},
  author    = {Chao-Peng Chen and Jun-Wei Hsieh and Ping-Yang Chen and YI-Kuan Hsieh and Bor-Shiun Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26660},
  pages     = {14187-14195},
  title     = {SARAS-net: Scale and relation aware siamese network for change detection},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Leveraging old knowledge to continually learn new classes in
medical images. <em>AAAI</em>, 14178–14186. (<a
href="https://doi.org/10.1609/aaai.v37i12.26659">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Class-incremental continual learning is a core step towards developing artificial intelligence systems that can continuously adapt to changes in the environment by learning new concepts without forgetting those previously learned. This is especially needed in the medical domain where continually learning from new incoming data is required to classify an expanded set of diseases. In this work, we focus on how old knowledge can be leveraged to learn new classes without catastrophic forgetting. We propose a framework that comprises of two main components: (1) a dynamic architecture with expanding representations to preserve previously learned features and accommodate new features; and (2) a training procedure alternating between two objectives to balance the learning of new features while maintaining the model’s performance on old classes. Experiment results on multiple medical datasets show that our solution is able to achieve superior performance over state-of-the-art baselines in terms of class accuracy and forgetting.},
  archive   = {C_AAAI},
  author    = {Evelyn Chee and Mong Li Lee and Wynne Hsu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26659},
  pages     = {14178-14186},
  title     = {Leveraging old knowledge to continually learn new classes in medical images},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Seq2Seq surrogates of epidemic models to facilitate bayesian
inference. <em>AAAI</em>, 14170–14177. (<a
href="https://doi.org/10.1609/aaai.v37i12.26658">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Epidemic models are powerful tools in understanding infectious disease. However, as they increase in size and complexity, they can quickly become computationally intractable. Recent progress in modelling methodology has shown that surrogate models can be used to emulate complex epidemic models with a high-dimensional parameter space. We show that deep sequence-to-sequence (seq2seq) models can serve as accurate surrogates for complex epidemic models with sequence based model parameters, effectively replicating seasonal and long-term transmission dynamics. Once trained, our surrogate can predict scenarios a several thousand times faster than the original model, making them ideal for policy exploration. We demonstrate that replacing a traditional epidemic model with a learned simulator facilitates robust Bayesian inference.},
  archive   = {C_AAAI},
  author    = {Giovanni Charles and Timothy M. Wolock and Peter Winskill and Azra Ghani and Samir Bhatt and Seth Flaxman},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26658},
  pages     = {14170-14177},
  title     = {Seq2Seq surrogates of epidemic models to facilitate bayesian inference},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Estimating geographic spillover effects of COVID-19 policies
from large-scale mobility networks. <em>AAAI</em>, 14161–14169. (<a
href="https://doi.org/10.1609/aaai.v37i12.26657">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Many policies in the US are determined locally, e.g., at the county-level. Local policy regimes provide flexibility between regions, but may become less effective in the presence of geographic spillovers, where populations circumvent local restrictions by traveling to less restricted regions nearby. Due to the endogenous nature of policymaking, there have been few opportunities to reliably estimate causal spillover effects or evaluate their impact on local policies. In this work, we identify a novel setting and develop a suitable methodology that allow us to make unconfounded estimates of spillover effects of local policies. Focusing on California’s Blueprint for a Safer Economy, we leverage how county-level mobility restrictions were deterministically set by public COVID-19 severity statistics, enabling a regression discontinuity design framework to estimate spillovers between counties. We estimate these effects using a mobility network with billions of timestamped edges and find significant spillover movement, with larger effects in retail, eating places, and gyms. Contrasting local and global policy regimes, our spillover estimates suggest that county-level restrictions are only 54\% as effective as statewide restrictions at reducing mobility. However, an intermediate strategy of macro-county restrictions---where we optimize county partitions by solving a minimum k-cut problem on a graph weighted by our spillover estimates---can recover over 90\% of statewide mobility reductions, while maintaining substantial flexibility between counties.},
  archive   = {C_AAAI},
  author    = {Serina Chang and Damir Vrabac and Jure Leskovec and Johan Ugander},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26657},
  pages     = {14161-14169},
  title     = {Estimating geographic spillover effects of COVID-19 policies from large-scale mobility networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards learning to discover money laundering sub-network in
massive transaction network. <em>AAAI</em>, 14153–14160. (<a
href="https://doi.org/10.1609/aaai.v37i12.26656">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Anti-money laundering (AML) systems play a critical role in safeguarding global economy. As money laundering is considered as one of the top group crimes, there is a crucial need to discover money laundering sub-network behind a particular money laundering transaction for a robust AML system. However, existing rule-based methods for money laundering sub-network discovery is heavily based on domain knowledge and may lag behind the modus operandi of launderers. Therefore, in this work, we first address the money laundering sub-network discovery problem with a neural network based approach, and propose an AML framework AMAP equipped with an adaptive sub-network proposer. In particular, we design an adaptive sub-network proposer guided by a supervised contrastive loss to discriminate money laundering transactions from massive benign transactions. We conduct extensive experiments on real-word datasets in AliPay of Ant Group. The result demonstrates the effectiveness of our AMAP in both money laundering transaction detection and money laundering sub-network discovering. The learned framework which yields money laundering sub-network from massive transaction network leads to a more comprehensive risk coverage and a deeper insight to money laundering strategies.},
  archive   = {C_AAAI},
  author    = {Ziwei Chai and Yang Yang and Jiawang Dan and Sheng Tian and Changhua Meng and Weiqiang Wang and Yifei Sun},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26656},
  pages     = {14153-14160},
  title     = {Towards learning to discover money laundering sub-network in massive transaction network},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Counterfactuals for the future. <em>AAAI</em>, 14144–14152.
(<a href="https://doi.org/10.1609/aaai.v37i12.26655">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Counterfactuals are often described as &#39;retrospective,&#39; focusing on hypothetical alternatives to a realized past. This description relates to an often implicit assumption about the structure and stability of exogenous variables in the system being modeled --- an assumption that is reasonable in many settings where counterfactuals are used. In this work, we consider cases where we might reasonably make a different assumption about exogenous variables; namely, that the exogenous noise terms of each unit do exhibit some unit-specific structure and/or stability. This leads us to a different use of counterfactuals --- a forward-looking rather than retrospective counterfactual. We introduce &quot;counterfactual treatment choice,&quot; a type of treatment choice problem that motivates using forward-looking counterfactuals. We then explore how mismatches between interventional versus forward-looking counterfactual approaches to treatment choice, consistent with different assumptions about exogenous noise, can lead to counterintuitive results.},
  archive   = {C_AAAI},
  author    = {Lucius E. J. Bynum and Joshua R. Loftus and Julia Stoyanovich},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26655},
  pages     = {14144-14152},
  title     = {Counterfactuals for the future},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Rehabilitating homeless: Dataset and key insights.
<em>AAAI</em>, 14136–14143. (<a
href="https://doi.org/10.1609/aaai.v37i12.26654">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper presents a large anonymized dataset of homelessness alongside insights into the data-driven rehabilitation of homeless people. The dataset was gathered by a large non-profit organization working on rehabilitating the homeless for twenty years. This is the first dataset that we know of that contains rich information on thousands of homeless individuals seeking rehabilitation. We show how data analysis can help to make the rehabilitation of homeless people more effective and successful. Thus, we hope this paper alerts the data science community to the problem of homelessness.},
  archive   = {C_AAAI},
  author    = {Anna Bykova and Nikolay Filippov and Ivan P. Yamshchikov},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26654},
  pages     = {14136-14143},
  title     = {Rehabilitating homeless: Dataset and key insights},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A fair incentive scheme for community health workers.
<em>AAAI</em>, 14127–14135. (<a
href="https://doi.org/10.1609/aaai.v37i12.26653">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Community health workers (CHWs) play a crucial role in the last mile delivery of essential health services to underserved populations in low-income countries. Many nongovernmental organizations (NGOs) provide training and support to enable CHWs to deliver health services to their communities, with no charge to the recipients of the services. This includes monetary compensation for the work that CHWs perform, which is broken down into a series of well defined tasks. In this work, we partner with a NGO D-Tree International to design a fair monetary compensation scheme for tasks performed by CHWs in the semi-autonomous region of Zanzibar in Tanzania, Africa. In consultation with stakeholders, we interpret fairness as the equal opportunity to earn, which means that each CHW has the opportunity to earn roughly the same total payment over a given T month period, if the CHW reacts to the incentive scheme almost rationally. We model this problem as a reward design problem for a Markov Decision Process (MDP) formulation for the CHWs’ earning. There is a need for the mechanism to be simple so that it is understood by the CHWs, thus, we explore linear and piecewise linear rewards in the CHWs’ measured units of work. We solve this design problem via a novel policy-reward gradient result. Our experiments using two real world parameters from the ground provide evidence of reasonable incentive output by our scheme.},
  archive   = {C_AAAI},
  author    = {Avinandan Bose and Tracey Li and Arunesh Sinha and Tien Mai},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26653},
  pages     = {14127-14135},
  title     = {A fair incentive scheme for community health workers},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Improving fairness in information exposure by adding links.
<em>AAAI</em>, 14119–14126. (<a
href="https://doi.org/10.1609/aaai.v37i12.26652">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Fairness in influence maximization has been a very active research topic recently. Most works in this context study the question of how to find seeding strategies (deterministic or probabilistic) such that nodes or communities in the network get their fair share of coverage. Different fairness criteria have been used in this context. All these works assume that the entity that is spreading the information has an inherent interest in spreading the information fairly, otherwise why would they want to use the developed fair algorithms? This assumption may however be flawed in reality -- the spreading entity may be purely efficiency-oriented. In this paper we propose to study two optimization problems with the goal to modify the network structure by adding links in such a way that efficiency-oriented information spreading becomes automatically fair. We study the proposed optimization problems both from a theoretical and experimental perspective, that is, we give several hardness and hardness of approximation results, provide efficient algorithms for some special cases, and more importantly provide heuristics for solving one of the problems in practice. In our experimental study we then first compare the proposed heuristics against each other and establish the most successful one. In a second experiment, we then show that our approach can be very successful in practice. That is, we show that already after adding a few edges to the networks the greedy algorithm that purely maximizes spread surpasses all fairness-tailored algorithms in terms of ex-post fairness. Maybe surprisingly, we even show that our approach achieves ex-post fairness values that are comparable or even better than the ex-ante fairness values of the currently most efficient algorithms that optimize ex-ante fairness.},
  archive   = {C_AAAI},
  author    = {Ruben Becker and Gianlorenzo D&#39;Angelo and Sajjad Ghobadi},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26652},
  pages     = {14119-14126},
  title     = {Improving fairness in information exposure by adding links},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). On the cost of demographic parity in influence
maximization. <em>AAAI</em>, 14110–14118. (<a
href="https://doi.org/10.1609/aaai.v37i12.26651">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Modeling and shaping how information spreads through a network is a major research topic in network analysis. While initially the focus has been mostly on efficiency, recently fairness criteria have been taken into account in this setting. Most work has focused on the maximin criteria however, and thus still different groups can receive very different shares of information. In this work we propose to consider fairness as a notion to be guaranteed by an algorithm rather than as a criterion to be maximized. To this end, we propose three optimization problems that aim at maximizing the overall spread while enforcing strict levels of demographic parity fairness via constraints (either ex-post or ex-ante). The level of fairness hence becomes a user choice rather than a property to be observed upon output. We study this setting from various perspectives. First, we prove that the cost of introducing demographic parity can be high in terms of both overall spread and computational complexity, i.e., the price of fairness may be unbounded for all three problems and optimal solutions are hard to compute, in some case even approximately or when fairness constraints may be violated. For one of our problems, we still design an algorithm with both constant approximation factor and fairness violation. We also give two heuristics that allow the user to choose the tolerated fairness violation. By means of an extensive experimental study, we show that our algorithms perform well in practice, that is, they achieve the best demographic parity fairness values. For certain instances we additionally even obtain an overall spread comparable to the most efficient algorithms that come without any fairness guarantee, indicating that the empirical price of fairness may actually be small when using our algorithms.},
  archive   = {C_AAAI},
  author    = {Ruben Becker and Gianlorenzo D&#39;Angelo and Sajjad Ghobadi},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26651},
  pages     = {14110-14118},
  title     = {On the cost of demographic parity in influence maximization},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the challenges of using reinforcement learning in
precision drug dosing: Delay and prolongedness of action effects.
<em>AAAI</em>, 14102–14109. (<a
href="https://doi.org/10.1609/aaai.v37i12.26650">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Drug dosing is an important application of AI, which can be formulated as a Reinforcement Learning (RL) problem. In this paper, we identify two major challenges of using RL for drug dosing: delayed and prolonged effects of administering medications, which break the Markov assumption of the RL framework. We focus on prolongedness and define PAE-POMDP (Prolonged Action Effect-Partially Observable Markov Decision Process), a subclass of POMDPs in which the Markov assumption does not hold specifically due to prolonged effects of actions. Motivated by the pharmacology literature, we propose a simple and effective approach to converting drug dosing PAE-POMDPs into MDPs, enabling the use of the existing RL algorithms to solve such problems. We validate the proposed approach on a toy task, and a challenging glucose control task, for which we devise a clinically-inspired reward function. Our results demonstrate that: (1) the proposed method to restore the Markov assumption leads to significant improvements over a vanilla baseline; (2) the approach is competitive with recurrent policies which may inherently capture the prolonged affect of actions; (3) it is remarkably more time and memory efficient than the recurrent baseline and hence more suitable for real-time dosing control systems; and (4) it exhibits favourable qualitative behavior in our policy analysis.},
  archive   = {C_AAAI},
  author    = {Sumana Basu and Marc-André Legault and Adriana Romero-Soriano and Doina Precup},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26650},
  pages     = {14102-14109},
  title     = {On the challenges of using reinforcement learning in precision drug dosing: Delay and prolongedness of action effects},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Med-EASi: Finely annotated dataset and models for
controllable simplification of medical texts. <em>AAAI</em>,
14093–14101. (<a
href="https://doi.org/10.1609/aaai.v37i12.26649">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Automatic medical text simplification can assist providers with patient-friendly communication and make medical texts more accessible, thereby improving health literacy. But curating a quality corpus for this task requires the supervision of medical experts. In this work, we present Med-EASi (Medical dataset for Elaborative and Abstractive Simplification), a uniquely crowdsourced and finely annotated dataset for supervised simplification of short medical texts. Its expert-layman-AI collaborative annotations facilitate controllability over text simplification by marking four kinds of textual transformations: elaboration, replacement, deletion, and insertion. To learn medical text simplification, we fine-tune T5-large with four different styles of input-output combinations, leading to two control-free and two controllable versions of the model. We add two types of controllability into text simplification, by using a multi-angle training approach: position-aware, which uses in-place annotated inputs and outputs, and position-agnostic, where the model only knows the contents to be edited, but not their positions. Our results show that our fine-grained annotations improve learning compared to the unannotated baseline. Furthermore, our position-aware control enhances the model&#39;s ability to generate better simplification than the position-agnostic version. The data and code are available at https://github.com/Chandrayee/CTRL-SIMP.},
  archive   = {C_AAAI},
  author    = {Chandrayee Basu and Rosni Vasu and Michihiro Yasunaga and Qian Yang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26649},
  pages     = {14093-14101},
  title     = {Med-EASi: Finely annotated dataset and models for controllable simplification of medical texts},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). COSMOS: Catching out-of-context image misuse using
self-supervised learning. <em>AAAI</em>, 14084–14092. (<a
href="https://doi.org/10.1609/aaai.v37i12.26648">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Despite the recent attention to DeepFakes, one of the most prevalent ways to mislead audiences on social media is the use of unaltered images in a new but false context. We propose a new method that automatically highlights out-of-context image and text pairs, for assisting fact-checkers. Our key insight is to leverage the grounding of images with text to distinguish out-of-context scenarios that cannot be disambiguated with language alone. We propose a self-supervised training strategy where we only need a set of captioned images. At train time, our method learns to selectively align individual objects in an image with textual claims, without explicit supervision. At test time, we check if both captions correspond to the same object(s) in the image but are semantically different, which allows us to make fairly accurate out-of-context predictions. Our method achieves 85\% out-of-context detection accuracy. To facilitate benchmarking of this task, we create a large-scale dataset of 200K images with 450K textual captions from a variety of news websites, blogs, and social media posts},
  archive   = {C_AAAI},
  author    = {Shivangi Aneja and Chris Bregler and Matthias Niessner},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i12.26648},
  pages     = {14084-14092},
  title     = {COSMOS: Catching out-of-context image misuse using self-supervised learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An ensemble distillation framework for sentence embeddings
with multilingual round-trip translation. <em>AAAI</em>, 14074–14082.
(<a href="https://doi.org/10.1609/aaai.v37i11.26647">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this work, we propose a novel unsupervised contrastive learning framework to improve state-of-the-art sentence embeddings. First, we train a set of contrastive submodels which take multilingual round-trip translation(RTT) as data augmentation. The RTT naturally changes the length of the same sentence and replaces Synonyms simultaneously. Then we incorporate them into a single model through knowledge distillation. Specifically, it takes an input sentence and predicts the ensemble output of all submodels via a contrastive objective. Thus we preserve nearly the same semantic expressiveness as the ensemble model without increasing the test cost. We evaluate our framework on standard semantic textual similarity (STS) tasks. Experimental results show the advantage of our framework that we achieve an average of 79.27\% Spearman&#39;s correlation, a 3.02\% improvement compared to the previous best results using BERT-base.},
  archive   = {C_AAAI},
  author    = {Tianyu Zong and Likun Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26647},
  pages     = {14074-14082},
  title     = {An ensemble distillation framework for sentence embeddings with multilingual round-trip translation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). KPT: Keyword-guided pre-training for grounded dialog
generation. <em>AAAI</em>, 14065–14073. (<a
href="https://doi.org/10.1609/aaai.v37i11.26646">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Incorporating external knowledge into the response generation process is essential to building more helpful and reliable dialog agents. However, collecting knowledge-grounded conversations is often costly, calling for a better pre-trained model for grounded dialog generation that generalizes well w.r.t. different types of knowledge. In this work, we propose KPT (Keyword-guided Pre-Training), a novel self-supervised pre-training method for grounded dialog generation without relying on extra knowledge annotation. Specifically, we use a pre-trained language model to extract the most uncertain tokens in the dialog as keywords. With these keywords, we construct two kinds of knowledge and pre-train a knowledge-grounded response generation model, aiming at handling two different scenarios: (1) the knowledge should be faithfully grounded; (2) it can be selectively used. For the former, the grounding knowledge consists of keywords extracted from the response. For the latter, the grounding knowledge is additionally augmented with keywords extracted from other utterances in the same dialog. Since the knowledge is extracted from the dialog itself, KPT can be easily performed on a large volume and variety of dialogue data. We considered three data sources (open-domain, task-oriented, conversational QA) with a total of 2.5M dialogues. We conduct extensive experiments on various few-shot knowledge-grounded generation tasks, including grounding on dialog acts, knowledge graphs, persona descriptions, and Wikipedia passages. Our comprehensive experiments and analyses demonstrate that KPT consistently outperforms state-of-the-art methods on these tasks with diverse grounding knowledge.},
  archive   = {C_AAAI},
  author    = {Qi Zhu and Fei Mi and Zheng Zhang and Yasheng Wang and Yitong Li and Xin Jiang and Qun Liu and Xiaoyan Zhu and Minlie Huang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26646},
  pages     = {14065-14073},
  title     = {KPT: Keyword-guided pre-training for grounded dialog generation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A generative approach for script event prediction via
contrastive fine-tuning. <em>AAAI</em>, 14056–14064. (<a
href="https://doi.org/10.1609/aaai.v37i11.26645">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Script event prediction aims to predict the subsequent event given the context. This requires the capability to infer the correlations between events. Recent works have attempted to improve event correlation reasoning by using pretrained language models and incorporating external knowledge (e.g., discourse relations). Though promising results have been achieved, some challenges still remain. First, the pretrained language models adopted by current works ignore event-level knowledge, resulting in an inability to capture the correlations between events well. Second, modeling correlations between events with discourse relations is limited because it can only capture explicit correlations between events with discourse markers, and cannot capture many implicit correlations. To this end, we propose a novel generative approach for this task, in which a pretrained language model is fine-tuned with an event-centric pretraining objective and predicts the next event within a generative paradigm. Specifically, we first introduce a novel event-level blank infilling strategy as the learning objective to inject event-level knowledge into the pretrained language model, and then design a likelihood-based contrastive loss for fine-tuning the generative model. Instead of using an additional prediction layer, we perform prediction by using sequence likelihoods generated by the generative model. Our approach models correlations between events in a soft way without any external knowledge. The likelihood-based prediction eliminates the need to use additional networks to make predictions and is somewhat interpretable since it scores each word in the event. Experimental results on the multi-choice narrative cloze (MCNC) task demonstrate that our approach achieves better results than other state-of-the-art baselines. Our code will be available at https://github.com/zhufq00/mcnc.},
  archive   = {C_AAAI},
  author    = {Fangqi Zhu and Jun Gao and Changlong Yu and Wei Wang and Chen Xu and Xin Mu and Min Yang and Ruifeng Xu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26645},
  pages     = {14056-14064},
  title     = {A generative approach for script event prediction via contrastive fine-tuning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving distantly supervised relation extraction by
natural language inference. <em>AAAI</em>, 14047–14055. (<a
href="https://doi.org/10.1609/aaai.v37i11.26644">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {To reduce human annotations for relation extraction (RE) tasks, distantly supervised approaches have been proposed, while struggling with low performance. In this work, we propose a novel DSRE-NLI framework, which considers both distant supervision from existing knowledge bases and indirect supervision from pretrained language models for other tasks. DSRE-NLI energizes an off-the-shelf natural language inference (NLI) engine with a semi-automatic relation verbalization (SARV) mechanism to provide indirect supervision and further consolidates the distant annotations to benefit multi-classification RE models. The NLI-based indirect supervision acquires only one relation verbalization template from humans as a semantically general template for each relationship, and then the template set is enriched by high-quality textual patterns automatically mined from the distantly annotated corpus. With two simple and effective data consolidation strategies, the quality of training data is substantially improved. Extensive experiments demonstrate that the proposed framework significantly improves the SOTA performance (up to 7.73\% of F1) on distantly supervised RE benchmark datasets. Our code is available at https://github.com/kangISU/DSRE-NLI.},
  archive   = {C_AAAI},
  author    = {Kang Zhou and Qiao Qiao and Yuepei Li and Qi Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26644},
  pages     = {14047-14055},
  title     = {Improving distantly supervised relation extraction by natural language inference},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Event process typing via hierarchical optimal transport.
<em>AAAI</em>, 14038–14046. (<a
href="https://doi.org/10.1609/aaai.v37i11.26643">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Understanding intention behind event processes in texts is important to many applications. One challenging task in this line is event process typing, which aims to tag the process with one action label and one object label describing the overall action of the process and object the process likely affects respectively. To tackle this task, existing methods mainly rely on the matching of the event process level and label level representation, which ignores two important characteristics: Process Hierarchy and Label Hierarchy. In this paper, we propose a Hierarchical Optimal Transport (HOT) method to address the above problem. Specifically, we first explicitly extract the process hierarchy and label hierarchy. Then the HOT optimally matches the two types of hierarchy. Experimental results show that our model outperforms the baseline models, illustrating the effectiveness of our model.},
  archive   = {C_AAAI},
  author    = {Bo Zhou and Yubo Chen and Kang Liu and Jun Zhao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26643},
  pages     = {14038-14046},
  title     = {Event process typing via hierarchical optimal transport},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Query your model with definitions in FrameNet: An effective
method for frame semantic role labeling. <em>AAAI</em>, 14029–14037. (<a
href="https://doi.org/10.1609/aaai.v37i11.26642">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Frame Semantic Role Labeling (FSRL) identifies arguments and labels them with frame semantic roles defined in FrameNet. Previous researches tend to divide FSRL into argument identification and role classification. Such methods usually model role classification as naive multi-class classification and treat arguments individually, which neglects label semantics and interactions between arguments and thus hindering performance and generalization of models. In this paper, we propose a query-based framework named ArGument Extractor with Definitions in FrameNet (AGED) to mitigate these problems. Definitions of frames and frame elements (FEs) in FrameNet can be used to query arguments in text. Encoding text-definition pairs can guide models in learning label semantics and strengthening argument interactions. Experiments show that AGED outperforms previous state-of-the-art by up to 1.3 F1-score in two FrameNet datasets and the generalization power of AGED in zero-shot and fewshot scenarios. Our code and technical appendix is available at https://github.com/PKUnlp-icler/AGED.},
  archive   = {C_AAAI},
  author    = {Ce Zheng and Yiming Wang and Baobao Chang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26642},
  pages     = {14029-14037},
  title     = {Query your model with definitions in FrameNet: An effective method for frame semantic role labeling},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Knowledge-bridged causal interaction network for causal
emotion entailment. <em>AAAI</em>, 14020–14028. (<a
href="https://doi.org/10.1609/aaai.v37i11.26641">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Causal Emotion Entailment aims to identify causal utterances that are responsible for the target utterance with a non-neutral emotion in conversations. Previous works are limited in thorough understanding of the conversational context and accurate reasoning of the emotion cause. To this end, we propose Knowledge-Bridged Causal Interaction Network (KBCIN) with commonsense knowledge (CSK) leveraged as three bridges. Specifically, we construct a conversational graph for each conversation and leverage the event-centered CSK as the semantics-level bridge (S-bridge) to capture the deep inter-utterance dependencies in the conversational context via the CSK-Enhanced Graph Attention module. Moreover, social-interaction CSK serves as emotion-level bridge (E-bridge) and action-level bridge (A-bridge) to connect candidate utterances with the target one, which provides explicit causal clues for the Emotional Interaction module and Actional Interaction module to reason the target emotion. Experimental results show that our model achieves better performance over most baseline models. Our source code is publicly available at https://github.com/circle-hit/KBCIN.},
  archive   = {C_AAAI},
  author    = {Weixiang Zhao and Yanyan Zhao and Zhuojun Li and Bing Qin},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26641},
  pages     = {14020-14028},
  title     = {Knowledge-bridged causal interaction network for causal emotion entailment},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). MCL: Multi-granularity contrastive learning framework for
chinese NER. <em>AAAI</em>, 14011–14019. (<a
href="https://doi.org/10.1609/aaai.v37i11.26640">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, researchers have applied the word-character lattice framework to integrated word information, which has become very popular for Chinese named entity recognition (NER). However, prior approaches fuse word information by different variants of encoders such as Lattice LSTM or Flat-Lattice Transformer, but are still not data-efficient indeed to fully grasp the depth interaction of cross-granularity and important word information from the lexicon. In this paper, we go beyond the typical lattice structure and propose a novel Multi-Granularity Contrastive Learning framework (MCL), that aims to optimize the inter-granularity distribution distance and emphasize the critical matched words in the lexicon. By carefully combining cross-granularity contrastive learning and bi-granularity contrastive learning, the network can explicitly leverage lexicon information on the initial lattice structure, and further provide more dense interactions of across-granularity, thus significantly improving model performance. Experiments on four Chinese NER datasets show that MCL obtains state-of-the-art results while considering model efficiency. The source code of the proposed method is publicly available at https://github.com/zs50910/MCL},
  archive   = {C_AAAI},
  author    = {Shan Zhao and ChengYu Wang and Minghao Hu and Tianwei Yan and Meng Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26640},
  pages     = {14011-14019},
  title     = {MCL: Multi-granularity contrastive learning framework for chinese NER},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Language model pre-training on true negatives.
<em>AAAI</em>, 14002–14010. (<a
href="https://doi.org/10.1609/aaai.v37i11.26639">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Discriminative pre-trained language models (PrLMs) learn to predict original texts from intentionally corrupted ones. Taking the former text as positive and the latter as negative samples, the PrLM can be trained effectively for contextualized representation. However, the training of such a type of PrLMs highly relies on the quality of the automatically constructed samples. Existing PrLMs simply treat all corrupted texts as equal negative without any examination, which actually lets the resulting model inevitably suffer from the false negative issue where training is carried out on pseudo-negative data and leads to less efficiency and less robustness in the resulting PrLMs. In this work, on the basis of defining the false negative issue in discriminative PrLMs that has been ignored for a long time, we design enhanced pre-training methods to counteract false negative predictions and encourage pre-training language models on true negatives by correcting the harmful gradient updates subject to false negative predictions. Experimental results on GLUE and SQuAD benchmarks show that our counter-false-negative pre-training methods indeed bring about better performance together with stronger robustness.},
  archive   = {C_AAAI},
  author    = {Zhuosheng Zhang and Hai Zhao and Masao Utiyama and Eiichiro Sumita},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26639},
  pages     = {14002-14010},
  title     = {Language model pre-training on true negatives},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A neural span-based continual named entity recognition
model. <em>AAAI</em>, 13993–14001. (<a
href="https://doi.org/10.1609/aaai.v37i11.26638">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Named Entity Recognition (NER) models capable of Continual Learning (CL) are realistically valuable in areas where entity types continuously increase (e.g., personal assistants). Meanwhile the learning paradigm of NER advances to new patterns such as the span-based methods. However, its potential to CL has not been fully explored. In this paper, we propose SpanKL, a simple yet effective Span-based model with Knowledge distillation (KD) to preserve memories and multi-Label prediction to prevent conflicts in CL-NER. Unlike prior sequence labeling approaches, the inherently independent modeling in span and entity level with the designed coherent optimization on SpanKL promotes its learning at each incremental step and mitigates the forgetting. Experiments on synthetic CL datasets derived from OntoNotes and Few-NERD show that SpanKL significantly outperforms previous SoTA in many aspects, and obtains the smallest gap from CL to the upper bound revealing its high practiced value. The code is available at https://github.com/Qznan/SpanKL.},
  archive   = {C_AAAI},
  author    = {Yunan Zhang and Qingcai Chen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26638},
  pages     = {13993-14001},
  title     = {A neural span-based continual named entity recognition model},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving end-to-end speech translation by leveraging
auxiliary speech and text data. <em>AAAI</em>, 13984–13992. (<a
href="https://doi.org/10.1609/aaai.v37i11.26637">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present a method for introducing a text encoder into pre-trained end-to-end speech translation systems. It enhances the ability of adapting one modality (i.e., source-language speech) to another (i.e., source-language text). Thus, the speech translation model can learn from both unlabeled and labeled data, especially when the source-language text data is abundant. Beyond this, we present a denoising method to build a robust text encoder that can deal with both normal and noisy text data. Our system sets new state-of-the-arts on the MuST-C En-De, En-Fr, and LibriSpeech En-Fr tasks.},
  archive   = {C_AAAI},
  author    = {Yuhao Zhang and Chen Xu and Bojie Hu and Chunliang Zhang and Tong Xiao and Jingbo Zhu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26637},
  pages     = {13984-13992},
  title     = {Improving end-to-end speech translation by leveraging auxiliary speech and text data},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-action dialog policy learning from logged user
feedback. <em>AAAI</em>, 13976–13983. (<a
href="https://doi.org/10.1609/aaai.v37i11.26636">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-action dialog policy (MADP), which generates multiple atomic dialog actions per turn, has been widely applied in task-oriented dialog systems to provide expressive and efficient system responses. Existing MADP models usually imitate action combinations from the labeled multi-action dialog samples. Due to data limitations, they generalize poorly toward unseen dialog flows. While reinforcement learning-based methods are proposed to incorporate the service ratings from real users and user simulators as external supervision signals, they suffer from sparse and less credible dialog-level rewards. To cope with this problem, we explore to improve MADPL with explicit and implicit turn-level user feedback received for historical predictions (i.e., logged user feedback) that are cost-efficient to collect and faithful to real-world scenarios. The task is challenging since the logged user feedback provides only partial label feedback limited to the particular historical dialog actions predicted by the agent. To fully exploit such feedback information, we propose BanditMatch, which addresses the task from a feedback-enhanced semi-supervised learning perspective with a hybrid learning objective of SSL and bandit learning. BanditMatch integrates pseudo-labeling methods to better explore the action space through constructing full label feedback. Extensive experiments show that our BanditMatch improves MADPL over the state-of-the-art methods by generating more concise and informative responses. The source code and the appendix of this paper can be obtained from https://github.com/ShuoZhangXJTU/BanditMatch.},
  archive   = {C_AAAI},
  author    = {Shuo Zhang and Junzhou Zhao and Pinghui Wang and Tianxiang Wang and Zi Liang and Jing Tao and Yi Huang and Junlan Feng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26636},
  pages     = {13976-13983},
  title     = {Multi-action dialog policy learning from logged user feedback},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Exploring self-distillation based relational reasoning
training for document-level relation extraction. <em>AAAI</em>,
13967–13975. (<a
href="https://doi.org/10.1609/aaai.v37i11.26635">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Document-level relation extraction (RE) aims to extract relational triples from a document. One of its primary challenges is to predict implicit relations between entities, which are not explicitly expressed in the document but can usually be extracted through relational reasoning. Previous methods mainly implicitly model relational reasoning through the interaction among entities or entity pairs. However, they suffer from two deficiencies: 1) they often consider only one reasoning pattern, of which coverage on relational triples is limited; 2) they do not explicitly model the process of relational reasoning. In this paper, to deal with the first problem, we propose a document-level RE model with a reasoning module that contains a core unit, the reasoning multi-head self-attention unit. This unit is a variant of the conventional multi-head self-attention and utilizes four attention heads to model four common reasoning patterns, respectively, which can cover more relational triples than previous methods. Then, to address the second issue, we propose a self-distillation training framework, which contains two branches sharing parameters. In the first branch, we first randomly mask some entity pair feature vectors in the document, and then train our reasoning module to infer their relations by exploiting the feature information of other related entity pairs. By doing so, we can explicitly model the process of relational reasoning. However, because the additional masking operation is not used during testing, it causes an input gap between training and testing scenarios, which would hurt the model performance. To reduce this gap, we perform conventional supervised training without masking operation in the second branch and utilize Kullback-Leibler divergence loss to minimize the difference between the predictions of the two branches. Finally, we conduct comprehensive experiments on three benchmark datasets, of which experimental results demonstrate that our model consistently outperforms all competitive baselines. Our source code is available at https://github.com/DeepLearnXMU/DocRE-SD},
  archive   = {C_AAAI},
  author    = {Liang Zhang and Jinsong Su and Zijun Min and Zhongjian Miao and Qingguo Hu and Biao Fu and Xiaodong Shi and Yidong Chen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26635},
  pages     = {13967-13975},
  title     = {Exploring self-distillation based relational reasoning training for document-level relation extraction},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). MPMQA: Multimodal question answering on product manuals.
<em>AAAI</em>, 13958–13966. (<a
href="https://doi.org/10.1609/aaai.v37i11.26634">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Visual contents, such as illustrations and images, play a big role in product manual understanding. Existing Product Manual Question Answering (PMQA) datasets tend to ignore visual contents and only retain textual parts. In this work, to emphasize the importance of multimodal contents, we propose a Multimodal Product Manual Question Answering (MPMQA) task. For each question, MPMQA requires the model not only to process multimodal contents but also to provide multimodal answers. To support MPMQA, a large-scale dataset PM209 is constructed with human annotations, which contains 209 product manuals from 27 well-known consumer electronic brands. Human annotations include 6 types of semantic regions for manual contents and 22,021 pairs of question and answer. Especially, each answer consists of a textual sentence and related visual regions from manuals. Taking into account the length of product manuals and the fact that a question is always related to a small number of pages, MPMQA can be naturally split into two subtasks: retrieving most related pages and then generating multimodal answers. We further propose a unified model that can perform these two subtasks all together and achieve comparable performance with multiple task-specific models. The PM209 dataset is available at https://github.com/AIM3-RUC/MPMQA.},
  archive   = {C_AAAI},
  author    = {Liang Zhang and Anwen Hu and Jing Zhang and Shuo Hu and Qin Jin},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26634},
  pages     = {13958-13966},
  title     = {MPMQA: Multimodal question answering on product manuals},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Quantum-inspired representation for long-tail senses of word
sense disambiguation. <em>AAAI</em>, 13949–13957. (<a
href="https://doi.org/10.1609/aaai.v37i11.26633">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Data imbalance, also known as the long-tail distribution of data, is an important challenge for data-driven models. In the Word Sense Disambiguation (WSD) task, the long-tail phenomenon of word sense distribution is more common, making it difficult to effectively represent and identify Long-Tail Senses (LTSs). Therefore exploring representation methods that do not rely heavily on the training sample size is an important way to combat LTSs. Considering that many new states, namely superposition states, can be constructed from several known states in quantum mechanics, superposition states provide the possibility to obtain more accurate representations from inferior representations learned from a small sample size. Inspired by quantum superposition states, a representation method in Hilbert space is proposed to reduce the dependence on large sample sizes and thus combat LTSs. We theoretically prove the correctness of the method, and verify its effectiveness under the standard WSD evaluation framework and obtain state-of-the-art performance. Furthermore, we also test on the constructed LTS and the latest cross-lingual datasets, and achieve promising results.},
  archive   = {C_AAAI},
  author    = {Junwei Zhang and Ruifang He and Fengyu Guo},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26633},
  pages     = {13949-13957},
  title     = {Quantum-inspired representation for long-tail senses of word sense disambiguation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Transferable post-hoc calibration on pretrained transformers
in noisy text classification. <em>AAAI</em>, 13940–13948. (<a
href="https://doi.org/10.1609/aaai.v37i11.26632">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent work has demonstrated that pretrained transformers are overconfident in text classification tasks, which can be calibrated by the famous post-hoc calibration method temperature scaling (TS). Character or word spelling mistakes are frequently encountered in real applications and greatly threaten transformer model safety. Research on calibration under noisy settings is rare, and we focus on this direction. Based on a toy experiment, we discover that TS performs poorly when the datasets are perturbed by slight noise, such as swapping the characters, which results in distribution shift. We further utilize two metrics, predictive uncertainty and maximum mean discrepancy (MMD), to measure the distribution shift between clean and noisy datasets, based on which we propose a simple yet effective transferable TS method for calibrating models dynamically. To evaluate the performance of the proposed methods under noisy settings, we construct a benchmark consisting of four noise types and five shift intensities based on the QNLI, AG-News, and Emotion tasks. Experimental results on the noisy benchmark show that (1) the metrics are effective in measuring distribution shift and (2) transferable TS can significantly decrease the expected calibration error (ECE) compared with the competitive baseline ensemble TS by approximately 46.09\%.},
  archive   = {C_AAAI},
  author    = {Jun Zhang and Wen Yao and Xiaoqian Chen and Ling Feng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26632},
  pages     = {13940-13948},
  title     = {Transferable post-hoc calibration on pretrained transformers in noisy text classification},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Preserve context information for extract-generate long-input
summarization framework. <em>AAAI</em>, 13932–13939. (<a
href="https://doi.org/10.1609/aaai.v37i11.26631">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Extract-generate framework has been a classic approach for text summarization. As pretrained language models struggling with long-input summarization for their high memory cost, extract-generate framework regains researchers&#39; interests. However, the cost of its effectiveness in dealing with long-input summarization is the loss of context information. In this paper, we present a context-aware extract-generate framework (CAEG) for long-input text summarization. It focuses on preserving both local and global context information in an extract-generate framework with little cost, and can be applied to most of existing extract-generate summarization models. CAEG generates a set of context-related text spans called context prompts for each text snippet and use them to transfer the context information from the extractor and generator. To find such context prompts, we propose to capture the context information based on the interpretation of the extractor, where the text spans having the highest contribution to the extraction decision are considered as containing the richest context information. We evaluate our approach on both long-document and long-dialogue summarization datasets: arXiv and QMSum. The experiment results show that CAEG achieves the-state-of-art result on QMSum and outperforms other extract-generate based models in arXiv.},
  archive   = {C_AAAI},
  author    = {Ruifeng Yuan and Zili Wang and Ziqiang Cao and Wenjie Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26631},
  pages     = {13932-13939},
  title     = {Preserve context information for extract-generate long-input summarization framework},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the calibration and uncertainty with pólya-gamma
augmentation for dialog retrieval models. <em>AAAI</em>, 13923–13931.
(<a href="https://doi.org/10.1609/aaai.v37i11.26630">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep neural retrieval models have amply demonstrated their power but estimating the reliability of their predictions remains challenging. Most dialog response retrieval models output a single score for a response on how relevant it is to a given question. However, the bad calibration of deep neural network results in various uncertainty for the single score such that the unreliable predictions always misinform user decisions. To investigate these issues, we present an efficient calibration and uncertainty estimation framework PG-DRR for dialog response retrieval models which adds a Gaussian Process layer to a deterministic deep neural network and recovers conjugacy for tractable posterior inference by Pólya-Gamma augmentation. Finally, PG-DRR achieves the lowest empirical calibration error (ECE) in the in-domain datasets and the distributional shift task while keeping R10@1 and MAP performance.},
  archive   = {C_AAAI},
  author    = {Tong Ye and Shijing Si and Jianzong Wang and Ning Cheng and Zhitao Li and Jing Xiao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26630},
  pages     = {13923-13931},
  title     = {On the calibration and uncertainty with pólya-gamma augmentation for dialog retrieval models},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FiTs: Fine-grained two-stage training for knowledge-aware
question answering. <em>AAAI</em>, 13914–13922. (<a
href="https://doi.org/10.1609/aaai.v37i11.26629">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Knowledge-aware question answering (KAQA) requires the model to answer questions over a knowledge base, which is essential for both open-domain QA and domain-specific QA, especially when language models alone cannot provide all the knowledge needed. Despite the promising result of recent KAQA systems which tend to integrate linguistic knowledge from pre-trained language models (PLM) and factual knowledge from knowledge graphs (KG) to answer complex questions, a bottleneck exists in effectively fusing the representations from PLMs and KGs because of (i) the semantic and distributional gaps between them, and (ii) the difficulties in joint reasoning over the provided knowledge from both modalities. To address the above two problems, we propose a Fine-grained Two-stage training framework (FiTs) to boost the KAQA system performance: The first stage aims at aligning representations from the PLM and the KG, thus bridging the modality gaps between them, named knowledge adaptive post-training. The second stage, called knowledge-aware fine-tuning, aims to improve the model&#39;s joint reasoning ability based on the aligned representations. In detail, we fine-tune the post-trained model via two auxiliary self-supervised tasks in addition to the QA supervision. Extensive experiments demonstrate that our approach achieves state-of-the-art performance on three benchmarks in the commonsense reasoning (i.e., CommonsenseQA, OpenbookQA) and medical question answering (i.e., MedQA-USMILE) domains.},
  archive   = {C_AAAI},
  author    = {Qichen Ye and Bowen Cao and Nuo Chen and Weiyuan Xu and Yuexian Zou},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26629},
  pages     = {13914-13922},
  title     = {FiTs: Fine-grained two-stage training for knowledge-aware question answering},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). What does your face sound like? 3D face shape towards voice.
<em>AAAI</em>, 13905–13913. (<a
href="https://doi.org/10.1609/aaai.v37i11.26628">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Face-based speech synthesis provides a practical solution to generate voices from human faces. However, directly using 2D face images leads to the problems of uninterpretability and entanglement. In this paper, to address the issues, we introduce 3D face shape which (1) has an anatomical relationship between voice characteristics, partaking in the &quot;bone conduction&quot; of human timbre production, and (2) is naturally independent of irrelevant factors by excluding the blending process. We devise a three-stage framework to generate speech from 3D face shapes. Fully considering timbre production in anatomical and acquired terms, our framework incorporates three additional relevant attributes including face texture, facial features, and demographics. Experiments and subjective tests demonstrate our method can generate utterances matching faces well, with good audio quality and voice diversity. We also explore and visualize how the voice changes with the face. Case studies show that our method upgrades the face-voice inference to personalized custom-made voice creating, revealing a promising prospect in virtual human and dubbing applications.},
  archive   = {C_AAAI},
  author    = {Zhihan Yang and Zhiyong Wu and Ying Shan and Jia Jia},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26628},
  pages     = {13905-13913},
  title     = {What does your face sound like? 3D face shape towards voice},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Orders are unwanted: Dynamic deep graph convolutional
network for personality detection. <em>AAAI</em>, 13896–13904. (<a
href="https://doi.org/10.1609/aaai.v37i11.26627">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Predicting personality traits based on online posts has emerged as an important task in many fields such as social network analysis. One of the challenges of this task is assembling information from various posts into an overall profile for each user. While many previous solutions simply concatenate the posts into a long text and then encode the text by sequential or hierarchical models, they introduce unwarranted orders for the posts, which may mislead the models. In this paper, we propose a dynamic deep graph convolutional network (D-DGCN) to overcome the above limitation. Specifically, we design a learn-to-connect approach that adopts a dynamic multi-hop structure instead of a deterministic structure, and combine it with the DGCN module to automatically learn the connections between posts. The modules of post encoder, learn-to-connect, and DGCN are jointly trained in an end-to-end manner. Experimental results on the Kaggle and Pandora datasets show the superior performance of D-DGCN to state-of-the-art baselines. Our code is available at https://github.com/djz233/D-DGCN.},
  archive   = {C_AAAI},
  author    = {Tao Yang and Jinghao Deng and Xiaojun Quan and Qifan Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26627},
  pages     = {13896-13904},
  title     = {Orders are unwanted: Dynamic deep graph convolutional network for personality detection},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). A domain-transfer meta task design paradigm for few-shot
slot tagging. <em>AAAI</em>, 13887–13895. (<a
href="https://doi.org/10.1609/aaai.v37i11.26626">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Few-shot slot tagging is an important task in dialogue systems and attracts much attention of researchers. Most previous few-shot slot tagging methods utilize meta-learning procedure for training and strive to construct a large number of different meta tasks to simulate the testing situation of insufficient data. However, there is a widespread phenomenon of overlap slot between two domains in slot tagging. Traditional meta tasks ignore this special phenomenon and cannot simulate such realistic few-shot slot tagging scenarios. It violates the basic principle of meta-learning which the meta task is consistent with the real testing task, leading to historical information forgetting problem. In this paper, we introduce a novel domain-transfer meta task design paradigm to tackle this problem. We distribute a basic domain to each target domain based on the coincidence degree of slot labels between these two domains. Unlike classic meta tasks which only rely on small samples of target domain, our meta tasks aim to correctly infer the class of target domain query samples based on both abundant data in basic domain and scarce data in target domain. To accomplish our meta task, we propose a Task Adaptation Network to effectively transfer the historical information from the basic domain to the target domain. We carry out sufficient experiments on the benchmark slot tagging dataset SNIPS and the name entity recognition dataset NER. Results demonstrate that our proposed model outperforms previous methods and achieves the state-of-the-art performance.},
  archive   = {C_AAAI},
  author    = {Fengyi Yang and Xi Zhou and Yating Yang and Bo Ma and Rui Dong and Abibulla Atawulla},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26626},
  pages     = {13887-13895},
  title     = {A domain-transfer meta task design paradigm for few-shot slot tagging},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Nested named entity recognition as building local
hypergraphs. <em>AAAI</em>, 13878–13886. (<a
href="https://doi.org/10.1609/aaai.v37i11.26625">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Named entity recognition is a fundamental task in natural language processing. Based on the sequence labeling paradigm for flat named entity recognition, multiple methods have been developed to handle the nested structures. However, they either require fixed recognition order or introduce complex hypergraphs. To tackle this problem, we propose a novel model named Local Hypergraph Builder Network (LHBN) that builds multiple simpler local hypergraphs to capture named entities instead of a single complex full-size hypergraph. The proposed model has three main properties: (1) The named entities that share boundaries are captured in the same local hypergraph. (2) The boundary information is enhanced by building local hypergraphs. (3) The hypergraphs can be built bidirectionally to take advantage of the identification direction preference of different named entities. Experiments illustrate that our model outperforms previous state-of-the-art methods on four widely used nested named entity recognition datasets: ACE04, ACE05, GENIA, and KBP17. The code is available at https://github.com/yanyk13/local-hypergraph-building-network.git.},
  archive   = {C_AAAI},
  author    = {Yukun Yan and Bingling Cai and Sen Song},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26625},
  pages     = {13878-13886},
  title     = {Nested named entity recognition as building local hypergraphs},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving biomedical entity linking with cross-entity
interaction. <em>AAAI</em>, 13869–13877. (<a
href="https://doi.org/10.1609/aaai.v37i11.26624">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Biomedical entity linking (EL) is the task of linking mentions in a biomedical document to corresponding entities in a knowledge base (KB). The challenge in biomedical EL lies in leveraging mention context to select the most appropriate entity among possible candidates. Although some EL models achieve competitive results by retrieving candidate entities and then exploiting context to re-rank them, these re-ranking models concatenate mention context with one candidate at a time. They lack fine-grained interaction among candidates, and potentially cannot handle ambiguous mentions when facing candidates both with high lexical similarity. We cope with this issue using a re-ranking model based on prompt tuning, which represents mention context and all candidates at once, letting candidates in comparison attend to each other. We also propose a KB-enhanced self-supervised pretraining strategy. Instead of large-scale pretraining on biomedical EL data in previous work, we use masked language modeling with synonyms from KB. Our method achieves state-of-the-art results on 3 biomedical EL datasets: NCBI disease, BC5CDR and COMETA, showing the effectiveness of cross-entity interaction and KB-enhanced pretraining strategy. Code is available at https://github.com/HITsz-TMG/Prompt-BioEL.},
  archive   = {C_AAAI},
  author    = {Zhenran Xu and Yulin Chen and Baotian Hu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26624},
  pages     = {13869-13877},
  title     = {Improving biomedical entity linking with cross-entity interaction},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A graph fusion approach for cross-lingual machine reading
comprehension. <em>AAAI</em>, 13861–13868. (<a
href="https://doi.org/10.1609/aaai.v37i11.26623">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Although great progress has been made for Machine Reading Comprehension (MRC) in English, scaling out to a large number of languages remains a huge challenge due to the lack of large amounts of annotated training data in non-English languages. To address this challenge, some recent efforts of cross-lingual MRC employ machine translation to transfer knowledge from English to other languages, through either explicit alignment or implicit attention. For effective knowledge transition, it is beneficial to leverage both semantic and syntactic information. However, the existing methods fail to explicitly incorporate syntax information in model learning. Consequently, the models are not robust to errors in alignment and noises in attention. In this work, we propose a novel approach, which jointly models the cross-lingual alignment information and the mono-lingual syntax information using a graph. We develop a series of algorithms, including graph construction, learning, and pre-training. The experiments on two benchmark datasets for cross-lingual MRC show that our approach outperforms all strong baselines, which verifies the effectiveness of syntax information for cross-lingual MRC.},
  archive   = {C_AAAI},
  author    = {Zenan Xu and Linjun Shou and Jian Pei and Ming Gong and Qinliang Su and Xiaojun Quan and Daxin Jiang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26623},
  pages     = {13861-13868},
  title     = {A graph fusion approach for cross-lingual machine reading comprehension},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Selector-enhancer: Learning dynamic selection of local and
non-local attention operation for speech enhancement. <em>AAAI</em>,
13853–13860. (<a
href="https://doi.org/10.1609/aaai.v37i11.26622">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Attention mechanisms, such as local and non-local attention, play a fundamental role in recent deep learning based speech enhancement (SE) systems. However, a natural speech contains many fast-changing and relatively briefly acoustic events, therefore, capturing the most informative speech features by indiscriminately using local and non-local attention is challenged. We observe that the noise type and speech feature vary within a sequence of speech and the local and non-local can respectively process different types of corrupted speech regions. To leverage this, we propose Selector-Enhancer, a dual-attention based convolution neural network (CNN) with a feature-filter that can dynamically select regions from low-resolution speech features and feed them to local or non-local attention operations. In particular, the proposed feature-filter is trained by using reinforcement learning (RL) with a developed difficulty-regulated reward that related to network performance, model complexity and “the difficulty of the SE task”. The results show that our method achieves comparable or superior performance to existing approaches. In particular, Selector-Enhancer is effective for real-world denoising, where the number and types of noise are varies on a single noisy mixture.},
  archive   = {C_AAAI},
  author    = {Xinmeng Xu and Weiping Tu and Yuhong Yang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26622},
  pages     = {13853-13860},
  title     = {Selector-enhancer: Learning dynamic selection of local and non-local attention operation for speech enhancement},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Balanced meta learning and diverse sampling for lifelong
task-oriented dialogue systems. <em>AAAI</em>, 13843–13852. (<a
href="https://doi.org/10.1609/aaai.v37i11.26621">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In real-world scenarios, it is crucial to build a lifelong taskoriented dialogue system (TDS) that continually adapts to new knowledge without forgetting previously acquired experiences. Existing approaches mainly focus on mitigating the catastrophic forgetting in lifelong TDS. However, the transfer ability to generalize the accumulated old knowledge to new tasks is underexplored. In this paper, we propose a two-stage lifelong task-oriented dialogue generation method to mitigate catastrophic forgetting and encourage knowledge transfer simultaneously, inspired by the learning process. In the first stage, we learn task-specific masks which adaptively preserve the knowledge of each visited task so as to mitigate catastrophic forgetting. In this stage, we are expected to learn the task-specific knowledge which is tailored for each task. In the second stage, we bring the knowledge from the encountered tasks together and understand thoroughly. To this end, we devise a balanced meta learning strategy for both forward and backward knowledge transfer in the lifelong learning process. In particular, we perform meta-update with a meta-test set sampled from the current training data for forward knowledge transfer. In addition, we employ an uncertainty-based sampling strategy to select and store representative dialogue samples into episodic memory and perform meta-update with a meta-test set sampled from the memory for backward knowledge transfer. With extensive experiments on 29 tasks, we show that MetaLTDS outperforms the strong baselines in terms of both effectiveness and efficiency. For reproducibility, we submit our code at: https: //github.com/travis-xu/MetaLTDS.},
  archive   = {C_AAAI},
  author    = {Qiancheng Xu and Min Yang and Ruifeng Xu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26621},
  pages     = {13843-13852},
  title     = {Balanced meta learning and diverse sampling for lifelong task-oriented dialogue systems},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dialogue state distillation network with inter-slot
contrastive learning for dialogue state tracking. <em>AAAI</em>,
13834–13842. (<a
href="https://doi.org/10.1609/aaai.v37i11.26620">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In task-oriented dialogue systems, Dialogue State Tracking (DST) aims to extract users&#39; intentions from the dialogue history. Currently, most existing approaches suffer from error propagation and are unable to dynamically select relevant information when utilizing previous dialogue states. Moreover, the relations between the updates of different slots provide vital clues for DST. However, the existing approaches rely only on predefined graphs to indirectly capture the relations. In this paper, we propose a Dialogue State Distillation Network (DSDN) to utilize relevant information of previous dialogue states and migrate the gap of utilization between training and testing. Thus, it can dynamically exploit previous dialogue states and avoid introducing error propagation simultaneously. Further, we propose an inter-slot contrastive learning loss to effectively capture the slot co-update relations from dialogue context. Experiments are conducted on the widely used MultiWOZ 2.0 and MultiWOZ 2.1 datasets. The experimental results show that our proposed model achieves the state-of-the-art performance for DST.},
  archive   = {C_AAAI},
  author    = {Jing Xu and Dandan Song and Chong Liu and Siu Cheung Hui and Fei Li and Qiang Ju and Xiaonan He and Jian Xie},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26620},
  pages     = {13834-13842},
  title     = {Dialogue state distillation network with inter-slot contrastive learning for dialogue state tracking},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dialogue rewriting via skeleton-guided generation.
<em>AAAI</em>, 13825–13833. (<a
href="https://doi.org/10.1609/aaai.v37i11.26619">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Dialogue rewriting aims to transform multi-turn, context-dependent dialogues into well-formed, context-independent text for most NLP systems. Previous dialogue rewriting benchmarks and systems assume a fluent and informative utterance to rewrite. Unfortunately, dialogue utterances from real-world systems are frequently noisy and with various kinds of errors that can make them almost uninformative. In this paper, we first present Real-world Dialogue Rewriting Corpus (RealDia), a new benchmark to evaluate how well current dialogue rewriting systems can deal with real-world noisy and uninformative dialogue utterances. RealDia contains annotated multi-turn dialogues from real scenes with ASR errors, spelling errors, redundancies and other noises that are ignored by previous dialogue rewriting benchmarks. We show that previous dialogue rewriting approaches are neither effective nor data-efficient to resolve RealDia. Then this paper presents Skeleton-Guided Rewriter (SGR), which can resolve the task of dialogue rewriting via a skeleton-guided generation paradigm. Experiments show that RealDia is a much more challenging benchmark for real-world dialogue rewriting, and SGR can effectively resolve the task and outperform previous approaches by a large margin.},
  archive   = {C_AAAI},
  author    = {Chunlei Xin and Hongyu Lin and Shan Wu and Xianpei Han and Bo Chen and Wen Dai and Shuai Chen and Bin Wang and Le Sun},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26619},
  pages     = {13825-13833},
  title     = {Dialogue rewriting via skeleton-guided generation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Factual and informative review generation for explainable
recommendation. <em>AAAI</em>, 13816–13824. (<a
href="https://doi.org/10.1609/aaai.v37i11.26618">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent models can generate fluent and grammatical synthetic reviews while accurately predicting user ratings. The generated reviews, expressing users&#39; estimated opinions towards related products, are often viewed as natural language ‘rationales’ for the jointly predicted rating. However, previous studies found that existing models often generate repetitive, universally applicable, and generic explanations, resulting in uninformative rationales. Further, our analysis shows that previous models&#39; generated content often contain factual hallucinations. These issues call for novel solutions that could generate both informative and factually grounded explanations. Inspired by recent success in using retrieved content in addition to parametric knowledge for generation, we propose to augment the generator with a personalized retriever, where the retriever&#39;s output serves as external knowledge for enhancing the generator. Experiments on Yelp, TripAdvisor, and Amazon Movie Reviews dataset show our model could generate explanations that more reliably entail existing reviews, are more diverse, and are rated more informative by human evaluators.},
  archive   = {C_AAAI},
  author    = {Zhouhang Xie and Sameer Singh and Julian McAuley and Bodhisattwa Prasad Majumder},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26618},
  pages     = {13816-13824},
  title     = {Factual and informative review generation for explainable recommendation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MoEC: Mixture of expert clusters. <em>AAAI</em>,
13807–13815. (<a
href="https://doi.org/10.1609/aaai.v37i11.26617">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Sparsely Mixture of Experts (MoE) has received great interest due to its promising scaling capability with affordable computational overhead. MoE models convert dense layers into sparse experts, and utilize a gated routing network to make experts conditionally activated. However, as the number of experts grows, MoE with outrageous parameters suffers from overfitting and sparse data allocation. Such problems are especially severe on tasks with limited data, thus hindering the progress towards improving performance by scaling up. We verify that there exists a performance upper bound of scaling up sparse MoE. In this work, we propose Mixture of Expert Clusters — a general approach to enable expert layers to learn more diverse and appropriate knowledge by imposing variance-based constraints on the routing stage. Given this, we could further propose a cluster-level expert dropout strategy specifically designed for the expert cluster structure. Our experiments reveal that MoEC could improve performance on machine translation and natural language understanding tasks. MoEC plays a positive role in mitigating overfitting and sparse data allocation problems, thus fully releasing the potential of large-scale sparse models.},
  archive   = {C_AAAI},
  author    = {Yuan Xie and Shaohan Huang and Tianyu Chen and Furu Wei},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26617},
  pages     = {13807-13815},
  title     = {MoEC: Mixture of expert clusters},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Global mixup: Eliminating ambiguity with clustering.
<em>AAAI</em>, 13798–13806. (<a
href="https://doi.org/10.1609/aaai.v37i11.26616">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Data augmentation with Mixup has been proven an effective method to regularize the current deep neural networks. Mixup generates virtual samples and corresponding labels simultaneously by linear interpolation. However, the one-stage generation paradigm and the use of linear interpolation have two defects: (1) The label of the generated sample is simply combined from the labels of the original sample pairs without reasonable judgment, resulting in ambiguous labels. (2) Linear combination significantly restricts the sampling space for generating samples. To address these issues, we propose a novel and effective augmentation method, Global Mixup, based on global clustering relationships. Specifically, we transform the previous one-stage augmentation process into two-stage by decoupling the process of generating virtual samples from the labeling. And for the labels of the generated samples, relabeling is performed based on clustering by calculating the global relationships of the generated samples. Furthermore, we are no longer restricted to linear relationships, which allows us to generate more reliable virtual samples in a larger sampling space. Extensive experiments for CNN, LSTM, and BERT on five tasks show that Global Mixup outperforms previous baselines. Further experiments also demonstrate the advantage of Global Mixup in low-resource scenarios.},
  archive   = {C_AAAI},
  author    = {Xiangjin Xie and Li Yangning and Wang Chen and Kai Ouyang and Zuotong Xie and Hai-Tao Zheng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26616},
  pages     = {13798-13806},
  title     = {Global mixup: Eliminating ambiguity with clustering},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AMOM: Adaptive masking over masking for conditional masked
language model. <em>AAAI</em>, 13789–13797. (<a
href="https://doi.org/10.1609/aaai.v37i11.26615">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Transformer-based autoregressive (AR) methods have achieved appealing performance for varied sequence-to-sequence generation tasks, e.g., neural machine translation, summarization, and code generation, but suffer from low inference efficiency. To speed up the inference stage, many non-autoregressive (NAR) strategies have been proposed in the past few years. Among them, the conditional masked language model (CMLM) is one of the most versatile frameworks, as it can support many different sequence generation scenarios and achieve very competitive performance on these tasks. In this paper, we further introduce a simple yet effective adaptive masking over masking strategy to enhance the refinement capability of the decoder and make the encoder optimization easier. Experiments on 3 different tasks (neural machine translation, summarization, and code generation) with 15 datasets in total confirm that our proposed simple method achieves significant performance improvement over the strong CMLM model. Surprisingly, our proposed model yields state-of-the-art performance on neural machine translation (34.62 BLEU on WMT16 EN to RO, 34.82 BLEU on WMT16 RO to EN, and 34.84 BLEU on IWSLT De to En) and even better performance than the AR Transformer on 7 benchmark datasets with at least 2.2x speedup. Our code is available at GitHub.},
  archive   = {C_AAAI},
  author    = {Yisheng Xiao and Ruiyang Xu and Lijun Wu and Juntao Li and Tao Qin and Tie-Yan Liu and Min Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26615},
  pages     = {13789-13797},
  title     = {AMOM: Adaptive masking over masking for conditional masked language model},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Don’t be so sure! Boosting ASR decoding via confidence
relaxation. <em>AAAI</em>, 13780–13788. (<a
href="https://doi.org/10.1609/aaai.v37i11.26614">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Automatic Speech Recognition (ASR) systems frequently use a search-based decoding strategy aiming to find the best attainable transcript by considering multiple candidates. One prominent speech recognition decoding heuristic is beam search, which seeks the transcript with the greatest likelihood computed using the predicted distribution. While showing substantial performance gains in various tasks, beam search loses some of its effectiveness when the predicted probabilities are highly confident, i.e., the predicted distribution is massed for a single or very few classes. We show that recently proposed Self-Supervised Learning (SSL)-based ASR models tend to yield exceptionally confident predictions that may hamper beam search from truly considering a diverse set of candidates. We perform a layer analysis to reveal and visualize how predictions evolve, and propose a decoding procedure that improves the performance of fine-tuned ASR models. Our proposed approach does not require further training beyond the original fine-tuning, nor additional model parameters. In fact, we find that our proposed method requires significantly less inference computation than current approaches. We propose aggregating the top M layers, potentially leveraging useful information encoded in intermediate layers, and relaxing model confidence. We demonstrate the effectiveness of our approach by conducting an empirical study on varying amounts of labeled resources and different model sizes, showing consistent improvements in particular when applied to low-resource scenarios.},
  archive   = {C_AAAI},
  author    = {Tomer Wullach and Shlomo E. Chazan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26614},
  pages     = {13780-13788},
  title     = {Don’t be so sure! boosting ASR decoding via confidence relaxation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). VideoDubber: Machine translation with speech-aware length
control for video dubbing. <em>AAAI</em>, 13772–13779. (<a
href="https://doi.org/10.1609/aaai.v37i11.26613">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Video dubbing aims to translate the original speech in a film or television program into the speech in a target language, which can be achieved with a cascaded system consisting of speech recognition, machine translation and speech synthesis. To ensure the translated speech to be well aligned with the corresponding video, the length/duration of the translated speech should be as close as possible to that of the original speech, which requires strict length control. Previous works usually control the number of words or characters generated by the machine translation model to be similar to the source sentence, without considering the isochronicity of speech as the speech duration of words/characters in different languages varies. In this paper, we propose VideoDubber, a machine translation system tailored for the task of video dubbing, which directly considers the speech duration of each token in translation, to match the length of source and target speech. Specifically, we control the speech length of generated sentence by guiding the prediction of each word with the duration information, including the speech duration of itself as well as how much duration is left for the remaining words. We design experiments on four language directions (German -&gt; English, Spanish -&gt; English, Chinese English), and the results show that VideoDubber achieves better length control ability on the generated speech than baseline methods. To make up the lack of real-world datasets, we also construct a real-world test set collected from films to provide comprehensive evaluations on the video dubbing task.},
  archive   = {C_AAAI},
  author    = {Yihan Wu and Junliang Guo and Xu Tan and Chen Zhang and Bohan Li and Ruihua Song and Lei He and Sheng Zhao and Arul Menezes and Jiang Bian},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26613},
  pages     = {13772-13779},
  title     = {VideoDubber: Machine translation with speech-aware length control for video dubbing},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). InfoCTM: A mutual information maximization perspective of
cross-lingual topic modeling. <em>AAAI</em>, 13763–13771. (<a
href="https://doi.org/10.1609/aaai.v37i11.26612">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Cross-lingual topic models have been prevalent for cross-lingual text analysis by revealing aligned latent topics. However, most existing methods suffer from producing repetitive topics that hinder further analysis and performance decline caused by low-coverage dictionaries. In this paper, we propose the Cross-lingual Topic Modeling with Mutual Information (InfoCTM). Instead of the direct alignment in previous work, we propose a topic alignment with mutual information method. This works as a regularization to properly align topics and prevent degenerate topic representations of words, which mitigates the repetitive topic issue. To address the low-coverage dictionary issue, we further propose a cross-lingual vocabulary linking method that finds more linked cross-lingual words for topic alignment beyond the translations of a given dictionary. Extensive experiments on English, Chinese, and Japanese datasets demonstrate that our method outperforms state-of-the-art baselines, producing more coherent, diverse, and well-aligned topics and showing better transferability for cross-lingual classification tasks.},
  archive   = {C_AAAI},
  author    = {Xiaobao Wu and Xinshuai Dong and Thong Nguyen and Chaoqun Liu and Liang-Ming Pan and Anh Tuan Luu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26612},
  pages     = {13763-13771},
  title     = {InfoCTM: A mutual information maximization perspective of cross-lingual topic modeling},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Continual graph convolutional network for text
classification. <em>AAAI</em>, 13754–13762. (<a
href="https://doi.org/10.1609/aaai.v37i11.26611">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph convolutional network (GCN) has been successfully applied to capture global non-consecutive and long-distance semantic information for text classification. However, while GCN-based methods have shown promising results in offline evaluations, they commonly follow a seen-token-seen-document paradigm by constructing a fixed document-token graph and cannot make inferences on new documents. It is a challenge to deploy them in online systems to infer steaming text data. In this work, we present a continual GCN model (ContGCN) to generalize inferences from observed documents to unobserved documents. Concretely, we propose a new all-token-any-document paradigm to dynamically update the document-token graph in every batch during both the training and testing phases of an online system. Moreover, we design an occurrence memory module and a self-supervised contrastive learning objective to update ContGCN in a label-free manner. A 3-month A/B test on Huawei public opinion analysis system shows ContGCN achieves 8.86\% performance gain compared with state-of-the-art methods. Offline experiments on five public datasets also show ContGCN can improve inference quality. The source code will be released at https://github.com/Jyonn/ContGCN.},
  archive   = {C_AAAI},
  author    = {Tiandeng Wu and Qijiong Liu and Yi Cao and Yao Huang and Xiao-Ming Wu and Jiandong Ding},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26611},
  pages     = {13754-13762},
  title     = {Continual graph convolutional network for text classification},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Identify event causality with knowledge and analogy.
<em>AAAI</em>, 13745–13753. (<a
href="https://doi.org/10.1609/aaai.v37i11.26610">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Event causality identification (ECI) aims to identify the causal relationship between events, which plays a crucial role in deep text understanding. Due to the diversity of real-world causality events and difficulty in obtaining sufficient training data, existing ECI approaches have poor generalizability and struggle to identify the relation between seldom seen events. In this paper, we propose to utilize both external knowledge and internal analogy to improve ECI. On the one hand, we utilize a commonsense knowledge graph called ConceptNet to enrich the description of an event sample and reveal the commonalities or associations between different events. On the other hand, we retrieve similar events as analogy exam- ples and glean useful experiences from such analogous neigh- bors to better identify the relationship between a new event pair. By better understanding different events through exter- nal knowledge and making an analogy with similar events, we can alleviate the data sparsity issue and improve model gener- alizability. Extensive evaluations on two benchmark datasets show that our model outperforms other baseline methods by around 18\% on the F1-value on average},
  archive   = {C_AAAI},
  author    = {Sifan Wu and Ruihui Zhao and Yefeng Zheng and Jian Pei and Bang Liu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26610},
  pages     = {13745-13753},
  title     = {Identify event causality with knowledge and analogy},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). See how you read? Multi-reading habits fusion reasoning for
multi-modal fake news detection. <em>AAAI</em>, 13736–13744. (<a
href="https://doi.org/10.1609/aaai.v37i11.26609">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The existing approaches based on different neural networks automatically capture and fuse the multimodal semantics of news, which have achieved great success for fake news detection. However, they still suffer from the limitations of both shallow fusion of multimodal features and less attention to the inconsistency between different modalities. To overcome them, we propose multi-reading habits fusion reasoning networks (MRHFR) for multi-modal fake news detection. In MRHFR, inspired by people&#39;s different reading habits for multimodal news, we summarize three basic cognitive reading habits and put forward cognition-aware fusion layer to learn the dependencies between multimodal features of news, so as to deepen their semantic-level integration. To explore the inconsistency of different modalities of news, we develop coherence constraint reasoning layer from two perspectives, which first measures the semantic consistency between the comments and different modal features of the news, and then probes the semantic deviation caused by unimodal features to the multimodal news content through constraint strategy. Experiments on two public datasets not only demonstrate that MRHFR not only achieves the excellent performance but also provides a new paradigm for capturing inconsistencies between multi-modal news.},
  archive   = {C_AAAI},
  author    = {Lianwei Wu and Pusheng Liu and Yanning Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26609},
  pages     = {13736-13744},
  title     = {See how you read? multi-reading habits fusion reasoning for multi-modal fake news detection},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adversarial self-attention for language understanding.
<em>AAAI</em>, 13727–13735. (<a
href="https://doi.org/10.1609/aaai.v37i11.26608">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep neural models (e.g. Transformer) naturally learn spurious features, which create a ``shortcut&#39;&#39; between the labels and inputs, thus impairing the generalization and robustness. This paper advances self-attention mechanism to its robust variant for Transformer-based pre-trained language models (e.g. BERT). We propose Adversarial Self-Attention mechanism (ASA), which adversarially biases the attentions to effectively suppress the model reliance on features (e.g. specific keywords) and encourage its exploration of broader semantics. We conduct comprehensive evaluation across a wide range of tasks for both pre-training and fine-tuning stages. For pre-training, ASA unfolds remarkable performance gain compared to naive training for longer steps. For fine-tuning, ASA-empowered models outweigh naive models by a large margin considering both generalization and robustness.},
  archive   = {C_AAAI},
  author    = {Hongqiu Wu and Ruixue Ding and Hai Zhao and Pengjun Xie and Fei Huang and Min Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26608},
  pages     = {13727-13735},
  title     = {Adversarial self-attention for language understanding},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Zero-shot face-based voice conversion: Bottleneck-free
speech disentanglement in the real-world scenario. <em>AAAI</em>,
13718–13726. (<a
href="https://doi.org/10.1609/aaai.v37i11.26607">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Often a face has a voice. Appearance sometimes has a strong relationship with one&#39;s voice. In this work, we study how a face can be converted to a voice, which is a face-based voice conversion. Since there is no clean dataset that contains face and speech, voice conversion faces difficult learning and low-quality problems caused by background noise or echo. Too much redundant information for face-to-voice also causes synthesis of a general style of speech. Furthermore, previous work tried to disentangle speech with bottleneck adjustment. However, it is hard to decide on the size of the bottleneck. Therefore, we propose a bottleneck-free strategy for speech disentanglement. To avoid synthesizing the general style of speech, we utilize framewise facial embedding. It applied adversarial learning with a multi-scale discriminator for the model to achieve better quality. In addition, the self-attention module is added to focus on content-related features for in-the-wild data. Quantitative experiments show that our method outperforms previous work.},
  archive   = {C_AAAI},
  author    = {Shao-En Weng and Hong-Han Shuai and Wen-Huang Cheng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26607},
  pages     = {13718-13726},
  title     = {Zero-shot face-based voice conversion: Bottleneck-free speech disentanglement in the real-world scenario},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards reliable neural machine translation with
consistency-aware meta-learning. <em>AAAI</em>, 13709–13717. (<a
href="https://doi.org/10.1609/aaai.v37i11.26606">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Neural machine translation (NMT) has achieved remarkable success in producing high-quality translations. However, current NMT systems suffer from a lack of reliability, as their outputs that are often affected by lexical or syntactic changes in inputs, resulting in large variations in quality. This limitation hinders the practicality and trustworthiness of NMT. A contributing factor to this problem is that NMT models trained with the one-to-one paradigm struggle to handle the source diversity phenomenon, where inputs with the same meaning can be expressed differently. In this work, we treat this problem as a bilevel optimization problem and present a consistency-aware meta-learning (CAML) framework derived from the model-agnostic meta-learning (MAML) algorithm to address it. Specifically, the NMT model with CAML (named CoNMT) first learns a consistent meta representation of semantically equivalent sentences in the outer loop. Subsequently, a mapping from the meta representation to the output sentence is learned in the inner loop, allowing the NMT model to translate semantically equivalent sentences to the same target sentence. We conduct experiments on the NIST Chinese to English task, three WMT translation tasks, and the TED M2O task. The results demonstrate that CoNMT effectively improves overall translation quality and reliably handles diverse inputs.},
  archive   = {C_AAAI},
  author    = {Rongxiang Weng and Qiang Wang and Wensen Cheng and Changfeng Zhu and Min Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26606},
  pages     = {13709-13717},
  title     = {Towards reliable neural machine translation with consistency-aware meta-learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FmLRE: A low-resource relation extraction model based on
feature mapping similarity calculation. <em>AAAI</em>, 13700–13708. (<a
href="https://doi.org/10.1609/aaai.v37i11.26605">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Low-resource relation extraction (LRE) aims to extract relations from limited labeled corpora. Existing work takes advantages of self-training or distant supervision to expand the limited labeled data in the data-driven approaches, while the selection bias of pseudo labels may cause the error accumulation in subsequent relation classification. To address this issue, this paper proposes fmLRE, an iterative feedback method based on feature mapping similarity calculation to improve the accuracy of pseudo labels. First, it calculates the similarities between pseudo-label and real-label data of the same category in a feature mapping space based on semantic features of labeled dataset after feature projection. Then, it fine-tunes initial model according to the iterative process of reinforcement learning. Finally, the similarity is used as a threshold for screening high-precision pseudo-labels and the basis for setting different rewards, which also acts as a penalty term for the loss function of relation classifier. Experimental results demonstrate that fmLRE achieves the state-of-the-art performance compared with strong baselines on two public datasets.},
  archive   = {C_AAAI},
  author    = {Peng Wang and Tong Shao and Ke Ji and Guozheng Li and Wenjun Ke},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26605},
  pages     = {13700-13708},
  title     = {FmLRE: A low-resource relation extraction model based on feature mapping similarity calculation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Disentangled CVAEs with contrastive learning for explainable
recommendation. <em>AAAI</em>, 13691–13699. (<a
href="https://doi.org/10.1609/aaai.v37i11.26604">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Modern recommender systems are increasingly expected to provide informative explanations that enable users to understand the reason for particular recommendations. However, previous methods struggle to interpret the input IDs of user--item pairs in real-world datasets, failing to extract adequate characteristics for controllable generation. To address this issue, we propose disentangled conditional variational autoencoders (CVAEs) for explainable recommendation, which leverage disentangled latent preference factors and guide the explanation generation with the refined condition of CVAEs via a self-regularization contrastive learning loss. Extensive experiments demonstrate that our method generates high-quality explanations and achieves new state-of-the-art results in diverse domains.},
  archive   = {C_AAAI},
  author    = {Linlin Wang and Zefeng Cai and Gerard de Melo and Zhu Cao and Liang He},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26604},
  pages     = {13691-13699},
  title     = {Disentangled CVAEs with contrastive learning for explainable recommendation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Uncertainty-aware self-training for low-resource neural
sequence labeling. <em>AAAI</em>, 13682–13690. (<a
href="https://doi.org/10.1609/aaai.v37i11.26603">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Neural sequence labeling (NSL) aims at assigning labels for input language tokens, which covers a broad range of applications, such as named entity recognition (NER) and slot filling, etc. However, the satisfying results achieved by traditional supervised-based approaches heavily depend on the large amounts of human annotation data, which may not be feasible in real-world scenarios due to data privacy and computation efficiency issues. This paper presents SeqUST, a novel uncertain-aware self-training framework for NSL to address the labeled data scarcity issue and to effectively utilize unlabeled data. Specifically, we incorporate Monte Carlo (MC) dropout in Bayesian neural network (BNN) to perform uncertainty estimation at the token level and then select reliable language tokens from unlabeled data based on the model confidence and certainty. A well-designed masked sequence labeling task with a noise-robust loss supports robust training, which aims to suppress the problem of noisy pseudo labels. In addition, we develop a Gaussian-based consistency regularization technique to further improve the model robustness on Gaussian-distributed perturbed representations. This effectively alleviates the over-fitting dilemma originating from pseudo-labeled augmented data. Extensive experiments over six benchmarks demonstrate that our SeqUST framework effectively improves the performance of self-training, and consistently outperforms strong baselines by a large margin in low-resource scenarios.},
  archive   = {C_AAAI},
  author    = {Jianing Wang and Chengyu Wang and Jun Huang and Ming Gao and Aoying Zhou},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26603},
  pages     = {13682-13690},
  title     = {Uncertainty-aware self-training for low-resource neural sequence labeling},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Taming continuous posteriors for latent variational dialogue
policies. <em>AAAI</em>, 13673–13681. (<a
href="https://doi.org/10.1609/aaai.v37i11.26602">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Utilizing amortized variational inference for latent-action reinforcement learning (RL) has been shown to be an effective approach in Task-oriented Dialogue (ToD) systems for optimizing dialogue success.Until now, categorical posteriors have been argued to be one of the main drivers of performance. In this work we revisit Gaussian variational posteriors for latent-action RL and show that they can yield even better performance than categoricals. We achieve this by introducing an improved variational inference objective for learning continuous representations without auxiliary learning objectives, which streamlines the training procedure. Moreover, we propose ways to regularize the latent dialogue policy, which helps to retain good response coherence. Using continuous latent representations our model achieves state of the art dialogue success rate on the MultiWOZ benchmark, and also compares well to categorical latent methods in response coherence.},
  archive   = {C_AAAI},
  author    = {Marin Vlastelica and Patrick Ernst and Gyuri Szarvas},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26602},
  pages     = {13673-13681},
  title     = {Taming continuous posteriors for latent variational dialogue policies},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). M-sense: Modeling narrative structure in short personal
narratives using protagonist’s mental representations. <em>AAAI</em>,
13664–13672. (<a
href="https://doi.org/10.1609/aaai.v37i11.26601">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Narrative is a ubiquitous component of human communication. Understanding its structure plays a critical role in a wide variety of applications, ranging from simple comparative analyses to enhanced narrative retrieval, comprehension, or reasoning capabilities. Prior research in narratology has highlighted the importance of studying the links between cognitive and linguistic aspects of narratives for effective comprehension. This interdependence is related to the textual semantics and mental language in narratives, referring to characters&#39; motivations, feelings or emotions, and beliefs. However, this interdependence is hardly explored for modeling narratives. In this work, we propose the task of automatically detecting prominent elements of the narrative structure by analyzing the role of characters&#39; inferred mental state along with linguistic information at the syntactic and semantic levels. We introduce a STORIES dataset of short personal narratives containing manual annotations of key elements of narrative structure, specifically climax and resolution. To this end, we implement a computational model that leverages the protagonist&#39;s mental state information obtained from a pre-trained model trained on social commonsense knowledge and integrates their representations with contextual semantic embed-dings using a multi-feature fusion approach. Evaluating against prior zero-shot and supervised baselines, we find that our model is able to achieve significant improvements in the task of identifying climax and resolution.},
  archive   = {C_AAAI},
  author    = {Prashanth Vijayaraghavan and Deb Roy},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26601},
  pages     = {13664-13672},
  title     = {M-sense: Modeling narrative structure in short personal narratives using protagonist’s mental representations},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Latent constraints on unsupervised text-graph alignment with
information asymmetry. <em>AAAI</em>, 13655–13663. (<a
href="https://doi.org/10.1609/aaai.v37i11.26600">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Unsupervised text-graph alignment (UTGA) is a fundamental task that bidirectionally generates texts and graphs without parallel data. Most available models of UTGA suffer from information asymmetry, a common phenomenon that texts and graphs include additional information invisible to each other. On the one hand, these models fail to supplement asymmetric information effectively due to the lack of ground truths. On the other hand, it is challenging to indicate asymmetric information with explicit indicators because it cannot be decoupled from the data directly. To address the challenge posed by information asymmetry, we propose the assumption that asymmetric information is encoded in unobservable latent variables and only affects the one-way generation processes. These latent variables corresponding to asymmetric information should obey prior distributions recovered approximately from original data. Therefore, we first propose a taxonomy of the latent variable that classifies the latent variable into transferrable (TV) and non-transferable (NTV) variables and further distinguish NTV as the dependent variable (DV) and the independent variable (IV). Next, we propose three latent VAE-based regularizations on TV, DV, and IV to constrain their distributions to well-designed prior distributions to introduce asymmetric information into models and enhance the preservation of shared contents. Finally, we impose the three proposed constraints on a cycle-consistent learning framework, back-translation (BT), named ConstrainedBT. Experimental results on three UTGA tasks demonstrate the effectiveness of ConstrainedBT on the information-asymmetric challenge.},
  archive   = {C_AAAI},
  author    = {Jidong Tian and Wenqing Chen and Yitian Li and Caoyun Fan and Hao He and Yaohui Jin},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26600},
  pages     = {13655-13663},
  title     = {Latent constraints on unsupervised text-graph alignment with information asymmetry},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reducing sentiment bias in pre-trained sentiment
classification via adaptive gumbel attack. <em>AAAI</em>, 13646–13654.
(<a href="https://doi.org/10.1609/aaai.v37i11.26599">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Pre-trained language models (PLMs) have recently enabled rapid progress on sentiment classification under the pre-train and fine-tune paradigm, where the fine-tuning phase aims to transfer the factual knowledge learned by PLMs to sentiment classification. However, current fine-tuning methods ignore the risk that PLMs cause the problem of sentiment bias, that is, PLMs tend to inject positive or negative sentiment from the contextual information of certain entities (or aspects) into their word embeddings, leading them to establish spurious correlations with labels. In this paper, we propose an adaptive Gumbel-attacked classifier that immunes sentiment bias from an adversarial-attack perspective. Due to the complexity and diversity of sentiment bias, we construct multiple Gumbel-attack expert networks to generate various noises from mixed Gumbel distribution constrained by mutual information minimization, and design an adaptive training framework to synthesize complex noise by confidence-guided controlling the number of expert networks. Finally, we capture these noises that effectively simulate sentiment bias based on the feedback of the classifier, and then propose a multi-channel parameter updating algorithm to strengthen the classifier to recognize these noises by fusing the parameters between the classifier and each expert network. Experimental results illustrate that our method significantly reduced sentiment bias and improved the performance of sentiment classification.},
  archive   = {C_AAAI},
  author    = {Jiachen Tian and Shizhan Chen and Xiaowang Zhang and Xin Wang and Zhiyong Feng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26599},
  pages     = {13646-13654},
  title     = {Reducing sentiment bias in pre-trained sentiment classification via adaptive gumbel attack},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SlideVQA: A dataset for document visual question answering
on multiple images. <em>AAAI</em>, 13636–13645. (<a
href="https://doi.org/10.1609/aaai.v37i11.26598">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Visual question answering on document images that contain textual, visual, and layout information, called document VQA, has received much attention recently. Although many datasets have been proposed for developing document VQA systems, most of the existing datasets focus on understanding the content relationships within a single image and not across multiple images. In this study, we propose a new multi-image document VQA dataset, SlideVQA, containing 2.6k+ slide decks composed of 52k+ slide images and 14.5k questions about a slide deck. SlideVQA requires complex reasoning, including single-hop, multi-hop, and numerical reasoning, and also provides annotated arithmetic expressions of numerical answers for enhancing the ability of numerical reasoning. Moreover, we developed a new end-to-end document VQA model that treats evidence selection and question answering as a unified sequence-to-sequence format. Experiments on SlideVQA show that our model outperformed existing state-of-the-art QA models, but that it still has a large gap behind human performance. We believe that our dataset will facilitate research on document VQA.},
  archive   = {C_AAAI},
  author    = {Ryota Tanaka and Kyosuke Nishida and Kosuke Nishida and Taku Hasegawa and Itsumi Saito and Kuniko Saito},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26598},
  pages     = {13636-13645},
  title     = {SlideVQA: A dataset for document visual question answering on multiple images},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Revisiting denoising diffusion probabilistic models for
speech enhancement: Condition collapse, efficiency and refinement.
<em>AAAI</em>, 13627–13635. (<a
href="https://doi.org/10.1609/aaai.v37i11.26597">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent literature has shown that denoising diffusion probabilistic models (DDPMs) can be used to synthesize high-fidelity samples with a competitive (or sometimes better) quality than previous state-of-the-art approaches. However, few attempts have been made to apply DDPM for the speech enhancement task. The reported performance of the existing works is relatively poor and significantly inferior to other generative methods. In this work, we first reveal the difficulties in applying existing diffusion models to the field of speech enhancement. Then we introduce DR-DiffuSE, a simple and effective framework for speech enhancement using conditional diffusion models. We present three strategies (two in diffusion training and one in reverse sampling) to tackle the condition collapse and guarantee the sufficient use of condition information. For efficiency, we introduce the fast sampling technique to reduce the sampling process into several steps and exploit a refinement network to calibrate the defective speech. Our proposed method achieves the state-of-the-art performance to the GAN-based model and shows a significant improvement over existing DDPM-based algorithms.},
  archive   = {C_AAAI},
  author    = {Wenxin Tai and Fan Zhou and Goce Trajcevski and Ting Zhong},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26597},
  pages     = {13627-13635},
  title     = {Revisiting denoising diffusion probabilistic models for speech enhancement: Condition collapse, efficiency and refinement},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Contrastive learning reduces hallucination in conversations.
<em>AAAI</em>, 13618–13626. (<a
href="https://doi.org/10.1609/aaai.v37i11.26596">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Pre-trained language models (LMs) store knowledge in their parameters and can generate informative responses when used in conversational systems. However, LMs suffer from the problem of “hallucination:” they may generate plausible-looking statements that are irrelevant or factually incorrect. To address this problem, we propose a contrastive learning scheme, named MixCL. A novel mixed contrastive objective is proposed to explicitly optimize the implicit knowledge elicitation process of LMs, and thus reduce their hallucination in conversations. We also examine negative sampling strategies of retrieved hard negatives and model-generated negatives. We conduct experiments on Wizard-of-Wikipedia, a public, open-domain knowledge-grounded dialogue benchmark, and assess the effectiveness of MixCL. MixCL effectively reduces the hallucination of LMs in conversations and achieves the highest performance among LM-based dialogue agents in terms of relevancy and factuality. We show that MixCL achieves comparable performance to state-of-the-art KB-based approaches while enjoying notable advantages in terms of efficiency and scalability.},
  archive   = {C_AAAI},
  author    = {Weiwei Sun and Zhengliang Shi and Shen Gao and Pengjie Ren and Maarten de Rijke and Zhaochun Ren},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26596},
  pages     = {13618-13626},
  title     = {Contrastive learning reduces hallucination in conversations},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ConvNTM: Conversational neural topic model. <em>AAAI</em>,
13609–13617. (<a
href="https://doi.org/10.1609/aaai.v37i11.26595">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Topic models have been thoroughly investigated for multiple years due to their great potential in analyzing and understanding texts. Recently, researchers combine the study of topic models with deep learning techniques, known as Neural Topic Models (NTMs). However, existing NTMs are mainly tested based on general document modeling without considering different textual analysis scenarios. We assume that there are different characteristics to model topics in different textual analysis tasks. In this paper, we propose a Conversational Neural Topic Model (ConvNTM) designed in particular for the conversational scenario. Unlike the general document topic modeling, a conversation session lasts for multiple turns: each short-text utterance complies with a single topic distribution and these topic distributions are dependent across turns. Moreover, there are roles in conversations, a.k.a., speakers and addressees. Topic distributions are partially determined by such roles in conversations. We take these factors into account to model topics in conversations via the multi-turn and multi-role formulation. We also leverage the word co-occurrence relationship as a new training objective to further improve topic quality. Comprehensive experimental results based on the benchmark datasets demonstrate that our proposed ConvNTM achieves the best performance both in topic modeling and in typical downstream tasks within conversational research (i.e., dialogue act classification and dialogue response generation).},
  archive   = {C_AAAI},
  author    = {Hongda Sun and Quan Tu and Jinpeng Li and Rui Yan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26595},
  pages     = {13609-13617},
  title     = {ConvNTM: Conversational neural topic model},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards diverse, relevant and coherent open-domain dialogue
generation via hybrid latent variables. <em>AAAI</em>, 13600–13608. (<a
href="https://doi.org/10.1609/aaai.v37i11.26594">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Conditional variational models, using either continuous or discrete latent variables, are powerful for open-domain dialogue response generation. However, previous works show that continuous latent variables tend to reduce the coherence of generated responses. In this paper, we also found that discrete latent variables have difficulty capturing more diverse expressions. To tackle these problems, we combine the merits of both continuous and discrete latent variables and propose a Hybrid Latent Variable (HLV) method. Specifically, HLV constrains the global semantics of responses through discrete latent variables and enriches responses with continuous latent variables. Thus, we diversify the generated responses while maintaining relevance and coherence. In addition, we propose Conditional Hybrid Variational Transformer (CHVT) to construct and to utilize HLV with transformers for dialogue generation. Through fine-grained symbolic-level semantic information and additive Gaussian mixing, we construct the distribution of continuous variables, prompting the generation of diverse expressions. Meanwhile, to maintain the relevance and coherence, the discrete latent variable is optimized by self-separation training. Experimental results on two dialogue generation datasets (DailyDialog and Opensubtitles) show that CHVT is superior to traditional transformer-based variational mechanism w.r.t. diversity, relevance and coherence metrics. Moreover, we also demonstrate the benefit of applying HLV to fine-tuning two pre-trained dialogue models (PLATO and BART-base).},
  archive   = {C_AAAI},
  author    = {Bin Sun and Yitong Li and Fei Mi and Weichao Wang and Yiwei Li and Kan Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26594},
  pages     = {13600-13608},
  title     = {Towards diverse, relevant and coherent open-domain dialogue generation via hybrid latent variables},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A latent-variable model for intrinsic probing.
<em>AAAI</em>, 13591–13599. (<a
href="https://doi.org/10.1609/aaai.v37i11.26593">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The success of pre-trained contextualized representations has prompted researchers to analyze them for the presence of linguistic information. Indeed, it is natural to assume that these pre-trained representations do encode some level of linguistic knowledge as they have brought about large empirical improvements on a wide variety of NLP tasks, which suggests they are learning true linguistic generalization. In this work, we focus on intrinsic probing, an analysis technique where the goal is not only to identify whether a representation encodes a linguistic attribute but also to pinpoint where this attribute is encoded. We propose a novel latent-variable formulation for constructing intrinsic probes and derive a tractable variational approximation to the log-likelihood. Our results show that our model is versatile and yields tighter mutual information estimates than two intrinsic probes previously proposed in the literature. Finally, we find empirical evidence that pre-trained representations develop a cross-lingually entangled notion of morphosyntax.},
  archive   = {C_AAAI},
  author    = {Karolina Stańczak and Lucas Torroba Hennigen and Adina Williams and Ryan Cotterell and Isabelle Augenstein},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26593},
  pages     = {13591-13599},
  title     = {A latent-variable model for intrinsic probing},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A speaker turn-aware multi-task adversarial network for
joint user satisfaction estimation and sentiment analysis.
<em>AAAI</em>, 13582–13590. (<a
href="https://doi.org/10.1609/aaai.v37i11.26592">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {User Satisfaction Estimation is an important task and increasingly being applied in goal-oriented dialogue systems to estimate whether the user is satisfied with the service. It is observed that whether the user’s needs are met often triggers various sentiments, which can be pertinent to the successful estimation of user satisfaction, and vice versa. Thus, User Satisfaction Estimation (USE) and Sentiment Analysis (SA) should be treated as a joint, collaborative effort, considering the strong connections between the sentiment states of speakers and the user satisfaction. Existing joint learning frameworks mainly unify the two highly pertinent tasks over cascade or shared-bottom implementations, however they fail to distinguish task-specific and common features, which will produce sub-optimal utterance representations for downstream tasks. In this paper, we propose a novel Speaker Turn-Aware Multi-Task Adversarial Network (STMAN) for dialogue-level USE and utterance-level SA. Specifically, we first introduce a multi-task adversarial strategy which trains a task discriminator to make utterance representation more task-specific, and then utilize a speaker-turn aware multi-task interaction strategy to extract the common features which are complementary to each task. Extensive experiments conducted on two real-world service dialogue datasets show that our model outperforms several state-of-the-art methods.},
  archive   = {C_AAAI},
  author    = {Kaisong Song and Yangyang Kang and Jiawei Liu and Xurui Li and Changlong Sun and Xiaozhong Liu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26592},
  pages     = {13582-13590},
  title     = {A speaker turn-aware multi-task adversarial network for joint user satisfaction estimation and sentiment analysis},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploring faithful rationale for multi-hop fact verification
via salience-aware graph learning. <em>AAAI</em>, 13573–13581. (<a
href="https://doi.org/10.1609/aaai.v37i11.26591">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The opaqueness of the multi-hop fact verification model imposes imperative requirements for explainability. One feasible way is to extract rationales, a subset of inputs, where the performance of prediction drops dramatically when being removed. Though being explainable, most rationale extraction methods for multi-hop fact verification explore the semantic information within each piece of evidence individually, while ignoring the topological information interaction among different pieces of evidence. Intuitively, a faithful rationale bears complementary information being able to extract other rationales through the multi-hop reasoning process. To tackle such disadvantages, we cast explainable multi-hop fact verification as subgraph extraction, which can be solved based on graph convolutional network (GCN) with salience-aware graph learning. In specific, GCN is utilized to incorporate the topological interaction information among multiple pieces of evidence for learning evidence representation. Meanwhile, to alleviate the influence of noisy evidence, the salience-aware graph perturbation is induced into the message passing of GCN. Moreover, the multi-task model with three diagnostic properties of rationale is elaborately designed to improve the quality of an explanation without any explicit annotations. Experimental results on the FEVEROUS benchmark show significant gains over previous state-of-the-art methods for both rationale extraction and fact verification.},
  archive   = {C_AAAI},
  author    = {Jiasheng Si and Yingjie Zhu and Deyu Zhou},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26591},
  pages     = {13573-13581},
  title     = {Exploring faithful rationale for multi-hop fact verification via salience-aware graph learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Which shortcut solution do question answering models prefer
to learn? <em>AAAI</em>, 13564–13572. (<a
href="https://doi.org/10.1609/aaai.v37i11.26590">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Question answering (QA) models for reading comprehension tend to exploit spurious correlations in training sets and thus learn shortcut solutions rather than the solutions intended by QA datasets. QA models that have learned shortcut solutions can achieve human-level performance in shortcut examples where shortcuts are valid, but these same behaviors degrade generalization potential on anti-shortcut examples where shortcuts are invalid. Various methods have been proposed to mitigate this problem, but they do not fully take the characteristics of shortcuts themselves into account. We assume that the learnability of shortcuts, i.e., how easy it is to learn a shortcut, is useful to mitigate the problem. Thus, we first examine the learnability of the representative shortcuts on extractive and multiple-choice QA datasets. Behavioral tests using biased training sets reveal that shortcuts that exploit answer positions and word-label correlations are preferentially learned for extractive and multiple-choice QA, respectively. We find that the more learnable a shortcut is, the flatter and deeper the loss landscape is around the shortcut solution in the parameter space. We also find that the availability of the preferred shortcuts tends to make the task easier to perform from an information-theoretic viewpoint. Lastly, we experimentally show that the learnability of shortcuts can be utilized to construct an effective QA training set; the more learnable a shortcut is, the smaller the proportion of anti-shortcut examples required to achieve comparable performance on shortcut and anti-shortcut examples. We claim that the learnability of shortcuts should be considered when designing mitigation methods.},
  archive   = {C_AAAI},
  author    = {Kazutoshi Shinoda and Saku Sugawara and Akiko Aizawa},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26590},
  pages     = {13564-13572},
  title     = {Which shortcut solution do question answering models prefer to learn?},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CoP: Factual inconsistency detection by controlling the
preference. <em>AAAI</em>, 13556–13563. (<a
href="https://doi.org/10.1609/aaai.v37i11.26589">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Abstractive summarization is the process of generating a summary given a document as input. Although significant progress has been made, the factual inconsistency between the document and the generated summary still limits its practical applications. Previous work found that the probabilities assigned by the generation model reflect its preferences for the generated summary, including the preference for factual consistency, and the preference for the language or knowledge prior as well. To separate the preference for factual consistency, we propose an unsupervised framework named CoP by controlling the preference of the generation model with the help of prompt. More specifically, the framework performs an extra inference step in which a text prompt is introduced as an additional input. In this way, another preference is described by the generation probability of this extra inference process. The difference between the above two preferences, i.e. the difference between the probabilities, could be used as measurements for detecting factual inconsistencies. Interestingly, we found that with the properly designed prompt, our framework could evaluate specific preferences and serve as measurements for fine-grained categories of inconsistency, such as entity-related inconsistency, coreference-related inconsistency, etc. Moreover, our framework could also be extended to the supervised setting to learn better prompt from the labeled data as well. Experiments show that our framework achieves new SOTA results on three factual inconsisency detection tasks.},
  archive   = {C_AAAI},
  author    = {Shuaijie She and Xiang Geng and Shujian Huang and Jiajun Chen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26589},
  pages     = {13556-13563},
  title     = {CoP: Factual inconsistency detection by controlling the preference},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Drop clause: Enhancing performance, robustness and pattern
recognition capabilities of the tsetlin machine. <em>AAAI</em>,
13547–13555. (<a
href="https://doi.org/10.1609/aaai.v37i11.26588">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Logic-based machine learning has the crucial advantage of transparency. However, despite significant recent progress, further research is needed to close the accuracy gap between logic-based architectures and deep neural network ones. This paper introduces a novel variant of the Tsetlin machine (TM) that randomly drops clauses, the logical learning element of TMs. In effect, TM with Drop Clause ignores a random selection of the clauses in each epoch, selected according to a predefined probability. In this way, the TM learning phase becomes more diverse. To explore the effects that Drop Clause has on accuracy, training time and robustness, we conduct extensive experiments on nine benchmark datasets in natural language processing (IMDb, R8, R52, MR, and TREC) and image classification (MNIST, Fashion MNIST, CIFAR-10, and CIFAR-100). Our proposed model outperforms baseline machine learning algorithms by a wide margin and achieves competitive performance compared with recent deep learning models, such as BERT-Large and AlexNet-DFA. In brief, we observe up to +10\% increase in accuracy and 2x to 4x faster learning than for the standard TM. We visualize the patterns learnt by Drop Clause TM in the form of heatmaps and show evidence of the ability of drop clause to learn more unique and discriminative patterns. We finally evaluate how Drop Clause affects learning robustness by introducing corruptions and alterations in the image/language test data, which exposes increased learning robustness.},
  archive   = {C_AAAI},
  author    = {Jivitesh Sharma and Rohan Yadav and Ole-Christoffer Granmo and Lei Jiao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26588},
  pages     = {13547-13555},
  title     = {Drop clause: Enhancing performance, robustness and pattern recognition capabilities of the tsetlin machine},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Rephrasing the reference for non-autoregressive machine
translation. <em>AAAI</em>, 13538–13546. (<a
href="https://doi.org/10.1609/aaai.v37i11.26587">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Non-autoregressive neural machine translation (NAT) models suffer from the multi-modality problem that there may exist multiple possible translations of a source sentence, so the reference sentence may be inappropriate for the training when the NAT output is closer to other translations. In response to this problem, we introduce a rephraser to provide a better training target for NAT by rephrasing the reference sentence according to the NAT output. As we train NAT based on the rephraser output rather than the reference sentence, the rephraser output should fit well with the NAT output and not deviate too far from the reference, which can be quantified as reward functions and optimized by reinforcement learning. Experiments on major WMT benchmarks and NAT baselines show that our approach consistently improves the translation quality of NAT. Specifically, our best variant achieves comparable performance to the autoregressive Transformer, while being 14.7 times more efficient in inference.},
  archive   = {C_AAAI},
  author    = {Chenze Shao and Jinchao Zhang and Jie Zhou and Yang Feng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26587},
  pages     = {13538-13546},
  title     = {Rephrasing the reference for non-autoregressive machine translation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving interpretability via explicit word interaction
graph layer. <em>AAAI</em>, 13528–13537. (<a
href="https://doi.org/10.1609/aaai.v37i11.26586">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent NLP literature has seen growing interest in improving model interpretability. Along this direction, we propose a trainable neural network layer that learns a global interaction graph between words and then selects more informative words using the learned word interactions. Our layer, we call WIGRAPH, can plug into any neural network-based NLP text classifiers right after its word embedding layer. Across multiple SOTA NLP models and various NLP datasets, we demonstrate that adding the WIGRAPH layer substantially improves NLP models&#39; interpretability and enhances models&#39; prediction performance at the same time.},
  archive   = {C_AAAI},
  author    = {Arshdeep Sekhon and Hanjie Chen and Aman Shrivastava and Zhe Wang and Yangfeng Ji and Yanjun Qi},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26586},
  pages     = {13528-13537},
  title     = {Improving interpretability via explicit word interaction graph layer},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Prompting neural machine translation with translation
memories. <em>AAAI</em>, 13519–13527. (<a
href="https://doi.org/10.1609/aaai.v37i11.26585">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Improving machine translation (MT) systems with translation memories (TMs) is of great interest to practitioners in the MT community. However, previous approaches require either a significant update of the model architecture and/or additional training efforts to make the models well-behaved when TMs are taken as additional input. In this paper, we present a simple but effective method to introduce TMs into neural machine translation (NMT) systems. Specifically, we treat TMs as prompts to the NMT model at test time, but leave the training process unchanged. The result is a slight update of an existing NMT system, which can be implemented in a few hours by anyone who is familiar with NMT. Experimental results on several datasets demonstrate that our system significantly outperforms strong baselines.},
  archive   = {C_AAAI},
  author    = {Abudurexiti Reheman and Tao Zhou and Yingfeng Luo and Di Yang and Tong Xiao and Jingbo Zhu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26585},
  pages     = {13519-13527},
  title     = {Prompting neural machine translation with translation memories},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unsupervised cross-domain rumor detection with contrastive
learning and cross-attention. <em>AAAI</em>, 13510–13518. (<a
href="https://doi.org/10.1609/aaai.v37i11.26584">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Massive rumors usually appear along with breaking news or trending topics, seriously hindering the truth. Existing rumor detection methods are mostly focused on the same domain, thus have poor performance in cross-domain scenarios due to domain shift. In this work, we propose an end-to-end instance-wise and prototype-wise contrastive learning model with cross-attention mechanism for cross-domain rumor detection. The model not only performs cross-domain feature alignment, but also enforces target samples to align with the corresponding prototypes of a given source domain. Since target labels in a target domain are unavailable, we use a clustering-based approach with carefully initialized centers by a batch of source domain samples to produce pseudo labels. Moreover, we use a cross-attention mechanism on a pair of source data and target data with the same labels to learn domain-invariant representations. Because the samples in a domain pair tend to express similar semantic patterns especially on the people’s attitudes (e.g., supporting or denying) towards the same category of rumors, the discrepancy between a pair of source domain and target domain will be decreased. We conduct experiments on four groups of cross-domain datasets and show that our proposed model achieves state-of-the-art performance.},
  archive   = {C_AAAI},
  author    = {Hongyan Ran and Caiyan Jia},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26584},
  pages     = {13510-13518},
  title     = {Unsupervised cross-domain rumor detection with contrastive learning and cross-attention},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distantly-supervised named entity recognition with adaptive
teacher learning and fine-grained student ensemble. <em>AAAI</em>,
13501–13509. (<a
href="https://doi.org/10.1609/aaai.v37i11.26583">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Distantly-Supervised Named Entity Recognition (DS-NER) effectively alleviates the data scarcity problem in NER by automatically generating training samples. Unfortunately, the distant supervision may induce noisy labels, thus undermining the robustness of the learned models and restricting the practical application. To relieve this problem, recent works adopt self-training teacher-student frameworks to gradually refine the training labels and improve the generalization ability of NER models. However, we argue that the performance of the current self-training frameworks for DS-NER is severely underestimated by their plain designs, including both inadequate student learning and coarse-grained teacher updating. Therefore, in this paper, we make the first attempt to alleviate these issues by proposing: (1) adaptive teacher learning comprised of joint training of two teacher-student networks and considering both consistent and inconsistent predictions between two teachers, thus promoting comprehensive student learning. (2) fine-grained student ensemble that updates each fragment of the teacher model with a temporal moving average of the corresponding fragment of the student, which enhances consistent predictions on each model fragment against noise. To verify the effectiveness of our proposed method, we conduct experiments on four DS-NER datasets. The experimental results demonstrate that our method significantly surpasses previous SOTA methods. The code is available at https://github.com/zenhjunpro/ATSEN.},
  archive   = {C_AAAI},
  author    = {Xiaoye Qu and Jun Zeng and Daizong Liu and Zhefeng Wang and Baoxing Huai and Pan Zhou},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26583},
  pages     = {13501-13509},
  title     = {Distantly-supervised named entity recognition with adaptive teacher learning and fine-grained student ensemble},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). BERT-ERC: Fine-tuning BERT is enough for emotion recognition
in conversation. <em>AAAI</em>, 13492–13500. (<a
href="https://doi.org/10.1609/aaai.v37i11.26582">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Previous works on emotion recognition in conversation (ERC) follow a two-step paradigm, which can be summarized as first producing context-independent features via fine-tuning pretrained language models (PLMs) and then analyzing contextual information and dialogue structure information among the extracted features. However, we discover that this paradigm has several limitations. Accordingly, we propose a novel paradigm, i.e., exploring contextual information and dialogue structure information in the fine-tuning step, and adapting the PLM to the ERC task in terms of input text, classification structure, and training strategy. Furthermore, we develop our model BERT-ERC according to the proposed paradigm, which improves ERC performance in three aspects, namely suggestive text, fine-grained classification module, and two-stage training. Compared to existing methods, BERT-ERC achieves substantial improvement on four datasets, indicating its effectiveness and generalization capability. Besides, we also set up the limited resources scenario and the online prediction scenario to approximate real-world scenarios. Extensive experiments demonstrate that the proposed paradigm significantly outperforms the previous one and can be adapted to various scenes.},
  archive   = {C_AAAI},
  author    = {Xiangyu Qin and Zhiyu Wu and Tingting Zhang and Yanran Li and Jian Luan and Bin Wang and Li Wang and Jinshi Cui},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26582},
  pages     = {13492-13500},
  title     = {BERT-ERC: Fine-tuning BERT is enough for emotion recognition in conversation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards complex scenarios: Building end-to-end task-oriented
dialogue system across multiple knowledge bases. <em>AAAI</em>,
13483–13491. (<a
href="https://doi.org/10.1609/aaai.v37i11.26581">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With the success of the sequence-to-sequence model, end-to-end task-oriented dialogue systems (EToDs) have obtained remarkable progress. However, most existing EToDs are limited to single KB settings where dialogues can be supported by a single KB, which is still far from satisfying the requirements of some complex applications (multi-KBs setting). In this work, we first empirically show that the existing single-KB EToDs fail to work on multi-KB settings that require models to reason across various KBs. To solve this issue, we take the first step to consider the multi-KBs scenario in EToDs and introduce a KB-over-KB Heterogeneous Graph Attention Network (KoK-HAN) to facilitate model to reason over multiple KBs. The core module is a triple-connection graph interaction layer that can model different granularity levels of interaction information across different KBs (i.e., intra-KB connection, inter-KB connection and dialogue-KB connection). Experimental results confirm the superiority of our model for multiple KBs reasoning.},
  archive   = {C_AAAI},
  author    = {Libo Qin and Zhouyang Li and Qiying Yu and Lehan Wang and Wanxiang Che},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26581},
  pages     = {13483-13491},
  title     = {Towards complex scenarios: Building end-to-end task-oriented dialogue system across multiple knowledge bases},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SSMI: Semantic similarity and mutual information
maximization based enhancement for chinese NER. <em>AAAI</em>,
13474–13482. (<a
href="https://doi.org/10.1609/aaai.v37i11.26580">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Chinese NER task consists of two steps, first determining entity boundaries and then labeling them. Some previous work incorporating related words from pre-trained vocabulary into character-based models has been demonstrated to be effective. However, the number of words that characters can match in the vocabulary is large, and their meanings vary widely. It is unreasonable to concatenate all the matched words into the character&#39;s representation without making semantic distinctions. This is because words with different semantics also have distinct vectors by the distributed representation. Moreover, mutual information maximization (MIM) provides a unified way to characterize the correction between different granularity of embeddings, we find it can be used to enhance the features in our task. Consequently, this paper introduces a novel Chinese NER model named SSMI based on semantic similarity and MIM. We first match all the potential word boundaries of the input characters from the pre-trained vocabulary and employ BERT to segment the input sentence to get the segmentation containing these characters. After computing their cosine similarity, we obtain the word boundary with the highest similarity and the word group with similarity score larger than a specific threshold. Then, we concatenate the most relevant word boundaries with character vectors. We further calculate the mutual information maximization of group, character and sentence, respectively. Finally, we feed the result from the above steps to our novel network. The results on four Chinese public NER datasets show that our SSMI achieves state-of-the-art performance.},
  archive   = {C_AAAI},
  author    = {Pengnian Qi and Biao Qin},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26580},
  pages     = {13474-13482},
  title     = {SSMI: Semantic similarity and mutual information maximization based enhancement for chinese NER},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-mask label mapping for prompt-based learning.
<em>AAAI</em>, 13465–13473. (<a
href="https://doi.org/10.1609/aaai.v37i11.26579">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Prompt-based Learning has shown significant success in few-shot classification. The mainstream approach is to concatenate a template for the input text to transform the classification task into a cloze-type task where label mapping plays an important role in finding the ground-truth labels. While current label mapping methods only use the contexts in one single input, it could be crucial if wrong information is contained in the text. Specifically, it is proved in recent work that even the large language models like BERT/RoBERTa make classification decisions heavily dependent on a specific keyword regardless of the task or the context. Such a word is referred to as a lexical cue and if a misleading lexical cue is included in the instance it will lead the model to make a wrong prediction. We propose a multi-mask prompt-based approach with Multi-Mask Label Mapping (MMLM) to reduce the impact of misleading lexical cues by allowing the model to exploit multiple lexical cues. To satisfy the conditions of few-shot learning, an instance augmentation approach for the cloze-type model is proposed and the misleading cues are gradually excluded through training. We demonstrate the effectiveness of MMLM by both theoretical analysis and empirical studies, and show that MMLM outperforms other existing label mapping approaches.},
  archive   = {C_AAAI},
  author    = {Jirui Qi and Richong Zhang and Jaein Kim and Junfan Chen and Wenyi Qin and Yongyi Mao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26579},
  pages     = {13465-13473},
  title     = {Multi-mask label mapping for prompt-based learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Relation-aware language-graph transformer for question
answering. <em>AAAI</em>, 13457–13464. (<a
href="https://doi.org/10.1609/aaai.v37i11.26578">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Question Answering (QA) is a task that entails reasoning over natural language contexts, and many relevant works augment language models (LMs) with graph neural networks (GNNs) to encode the Knowledge Graph (KG) information. However, most existing GNN-based modules for QA do not take advantage of rich relational information of KGs and depend on limited information interaction between the LM and the KG. To address these issues, we propose Question Answering Transformer (QAT), which is designed to jointly reason over language and graphs with respect to entity relations in a unified manner. Specifically, QAT constructs Meta-Path tokens, which learn relation-centric embeddings based on diverse structural and semantic relations. Then, our Relation-Aware Self-Attention module comprehensively integrates different modalities via the Cross-Modal Relative Position Bias, which guides information exchange between relevant entities of different modalities. We validate the effectiveness of QAT on commonsense question answering datasets like CommonsenseQA and OpenBookQA, and on a medical question answering dataset, MedQA-USMLE. On all the datasets, our method achieves state-of-the-art performance. Our code is available at http://github.com/mlvlab/QAT.},
  archive   = {C_AAAI},
  author    = {Jinyoung Park and Hyeong Kyu Choi and Juyeon Ko and Hyeonjin Park and Ji-Hoon Kim and Jisu Jeong and Kyungmin Kim and Hyunwoo Kim},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26578},
  pages     = {13457-13464},
  title     = {Relation-aware language-graph transformer for question answering},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RINK: Reader-inherited evidence reranker for table-and-text
open domain question answering. <em>AAAI</em>, 13446–13456. (<a
href="https://doi.org/10.1609/aaai.v37i11.26577">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Most approaches used in open-domain question answering on hybrid data that comprises both tabular-and-textual contents are based on a Retrieval-Reader pipeline in which the retrieval module finds relevant “heterogenous” evidence for a given question and the reader module generates an answer from the retrieved evidence. In this paper, we present a Retriever-Reranker-Reader framework by newly proposing a Reader-INherited evidence reranKer (RINK) where a reranker module is designed by finetuning the reader’s neural architecture based on a simple prompting method. Our underlying assumption of reusing the reader’s module for the reranker is that the reader’s ability to generating an answer from evidence contains the knowledge required for the reranking, because the reranker needs to “read” in-depth a question and evidences more carefully and elaborately than a baseline retriever. Furthermore, we present a simple and effective pretraining method by extensively deploying the commonly used data augmentation methods of cell corruption and cell reordering based on the pretraining tasks - tabular-and-textual entailment and cross-modal masked language modeling. Experimental results on OTT-QA, a large-scale table-and-text open-domain question answering dataset, show that the proposed RINK armed with our pretraining procedure makes improvements over the baseline reranking method and leads to state-of-the-art performance.},
  archive   = {C_AAAI},
  author    = {Eunhwan Park and Sung-Min Lee and Dearyong Seo and Seonhoon Kim and Inho Kang and Seung-Hoon Na},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26577},
  pages     = {13446-13456},
  title     = {RINK: Reader-inherited evidence reranker for table-and-text open domain question answering},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hierarchical event grounding. <em>AAAI</em>, 13437–13445.
(<a href="https://doi.org/10.1609/aaai.v37i11.26576">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Event grounding aims at linking mention references in text corpora to events from a knowledge base (KB). Previous work on this task focused primarily on linking to a single KB event, thereby overlooking the hierarchical aspects of events. Events in documents are typically described at various levels of spatio-temporal granularity. These hierarchical relations are utilized in downstream tasks of narrative understanding and schema construction. In this work, we present an extension to the event grounding task that requires tackling hierarchical event structures from the KB. Our proposed task involves linking a mention reference to a set of event labels from a subevent hierarchy in the KB. We propose a retrieval methodology that leverages event hierarchy through an auxiliary hierarchical loss. On an automatically created multilingual dataset from Wikipedia and Wikidata, our experiments demonstrate the effectiveness of the hierarchical loss against retrieve and re-rank baselines. Furthermore, we demonstrate the systems&#39; ability to aid hierarchical discovery among unseen events. Code is available at https://github.com/JefferyO/Hierarchical-Event-Grounding},
  archive   = {C_AAAI},
  author    = {Jiefu Ou and Adithya Pratapa and Rishubh Gupta and Teruko Mitamura},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26576},
  pages     = {13437-13445},
  title     = {Hierarchical event grounding},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RWEN-TTS: Relation-aware word encoding network for natural
text-to-speech synthesis. <em>AAAI</em>, 13428–13436. (<a
href="https://doi.org/10.1609/aaai.v37i11.26575">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With the advent of deep learning, a huge number of text-to-speech (TTS) models which produce human-like speech have emerged. Recently, by introducing syntactic and semantic information w.r.t the input text, various approaches have been proposed to enrich the naturalness and expressiveness of TTS models. Although these strategies showed impressive results, they still have some limitations in utilizing language information. First, most approaches only use graph networks to utilize syntactic and semantic information without considering linguistic features. Second, most previous works do not explicitly consider adjacent words when encoding syntactic and semantic information, even though it is obvious that adjacent words are usually meaningful when encoding the current word. To address these issues, we propose Relation-aware Word Encoding Network (RWEN), which effectively allows syntactic and semantic information based on two modules (i.e., Semantic-level Relation Encoding and Adjacent Word Relation Encoding). Experimental results show substantial improvements compared to previous works.},
  archive   = {C_AAAI},
  author    = {Shinhyeok Oh and HyeongRae Noh and Yoonseok Hong and Insoo Oh},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26575},
  pages     = {13428-13436},
  title     = {RWEN-TTS: Relation-aware word encoding network for natural text-to-speech synthesis},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving the cross-lingual generalisation in visual
question answering. <em>AAAI</em>, 13419–13427. (<a
href="https://doi.org/10.1609/aaai.v37i11.26574">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {While several benefits were realized for multilingual vision-language pretrained models, recent benchmarks across various tasks and languages showed poor cross-lingual generalisation when multilingually pre-trained vision-language models are applied to non-English data, with a large gap between (supervised) English performance and (zero-shot) cross-lingual transfer. In this work, we explore the poor performance of these models on a zero-shot cross-lingual visual question answering (VQA) task, where models are fine-tuned on English visual-question data and evaluated on 7 typologically diverse languages. We improve cross-lingual transfer with three strategies: (1) we introduce a linguistic prior objective to augment the cross-entropy loss with a similarity-based loss to guide the model during training, (2) we learn a task-specific subnetwork that improves cross-lingual generalisation and reduces variance without model modification, (3) we augment training examples using synthetic code-mixing to promote alignment of embeddings between source and target languages. Our experiments on xGQA using the pretrained multilingual multimodal transformers UC2 and M3P demonstrates the consistent effectiveness of the proposed fine-tuning strategy for 7 languages, outperforming existing transfer methods with sparse models.},
  archive   = {C_AAAI},
  author    = {Farhad Nooralahzadeh and Rico Sennrich},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26574},
  pages     = {13419-13427},
  title     = {Improving the cross-lingual generalisation in visual question answering},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards a holistic understanding of mathematical questions
with contrastive pre-training. <em>AAAI</em>, 13409–13418. (<a
href="https://doi.org/10.1609/aaai.v37i11.26573">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Understanding mathematical questions effectively is a crucial task, which can benefit many applications, such as difficulty estimation. Researchers have drawn much attention to designing pre-training models for question representations due to the scarcity of human annotations (e.g., labeling difficulty). However, unlike general free-format texts (e.g., user comments), mathematical questions are generally designed with explicit purposes and mathematical logic, and usually consist of more complex content, such as formulas, and related mathematical knowledge (e.g., Function). Therefore, the problem of holistically representing mathematical questions remains underexplored. To this end, in this paper, we propose a novel contrastive pre-training approach for mathematical question representations, namely QuesCo, which attempts to bring questions with more similar purposes closer. Specifically, we first design two-level question augmentations, including content-level and structure-level, which generate literally diverse question pairs with similar purposes. Then, to fully exploit hierarchical information of knowledge concepts, we propose a knowledge hierarchy-aware rank strategy (KHAR), which ranks the similarities between questions in a fine-grained manner. Next, we adopt a ranking contrastive learning task to optimize our model based on the augmented and ranked questions. We conduct extensive experiments on two real-world mathematical datasets. The experimental results demonstrate the effectiveness of our model.},
  archive   = {C_AAAI},
  author    = {Yuting Ning and Zhenya Huang and Xin Lin and Enhong Chen and Shiwei Tong and Zheng Gong and Shijin Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26573},
  pages     = {13409-13418},
  title     = {Towards a holistic understanding of mathematical questions with contrastive pre-training},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unveiling the black box of PLMs with semantic anchors:
Towards interpretable neural semantic parsing. <em>AAAI</em>,
13400–13408. (<a
href="https://doi.org/10.1609/aaai.v37i11.26572">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The recent prevalence of pretrained language models (PLMs) has dramatically shifted the paradigm of semantic parsing, where the mapping from natural language utterances to structured logical forms is now formulated as a Seq2Seq task. Despite the promising performance, previous PLM-based approaches often suffer from hallucination problems due to their negligence of the structural information contained in the sentence, which essentially constitutes the key semantics of the logical forms. Furthermore, most works treat PLM as a black box in which the generation process of the target logical form is hidden beneath the decoder modules, which greatly hinders the model&#39;s intrinsic interpretability. To address these two issues, we propose to incorporate the current PLMs with a hierarchical decoder network. By taking the first-principle structures as the semantic anchors, we propose two novel intermediate supervision tasks, namely Semantic Anchor Extraction and Semantic Anchor Alignment, for training the hierarchical decoders and probing the model intermediate representations in a self-adaptive manner alongside the fine-tuning process. We conduct intensive experiments on several semantic parsing benchmarks and demonstrate that our approach can consistently outperform the baselines. More importantly, by analyzing the intermediate representations of the hierarchical decoders, our approach also makes a huge step toward the interpretability of PLMs in the domain of semantic parsing.},
  archive   = {C_AAAI},
  author    = {Lunyiu Nie and Jiuding Sun and Yanlin Wang and Lun Du and Shi Han and Dongmei Zhang and Lei Hou and Juanzi Li and Jidong Zhai},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26572},
  pages     = {13400-13408},
  title     = {Unveiling the black box of PLMs with semantic anchors: Towards interpretable neural semantic parsing},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AUC maximization for low-resource named entity recognition.
<em>AAAI</em>, 13389–13399. (<a
href="https://doi.org/10.1609/aaai.v37i11.26571">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Current work in named entity recognition (NER) uses either cross entropy (CE) or conditional random fields (CRF) as the objective/loss functions to optimize the underlying NER model. Both of these traditional objective functions for the NER problem generally produce adequate performance when the data distribution is balanced and there are sufficient annotated training examples. But since NER is inherently an imbalanced tagging problem, the model performance under the low-resource settings could suffer using these standard objective functions. Based on recent advances in area under the ROC curve (AUC) maximization, we propose to optimize the NER model by maximizing the AUC score. We give evidence that by simply combining two binary-classifiers that maximize the AUC score, significant performance improvement over traditional loss functions is achieved under low-resource NER settings. We also conduct extensive experiments to demonstrate the advantages of our method under the low-resource and highly-imbalanced data distribution settings. To the best of our knowledge, this is the first work that brings AUC maximization to the NER setting. Furthermore, we show that our method is agnostic to different types of NER embeddings, models and domains. The code of this work is available at https://github.com/dngu0061/NER-AUC-2T.},
  archive   = {C_AAAI},
  author    = {Ngoc Dang Nguyen and Wei Tan and Lan Du and Wray Buntine and RIchard Beare and Changyou Chen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26571},
  pages     = {13389-13399},
  title     = {AUC maximization for low-resource named entity recognition},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Inferential knowledge-enhanced integrated reasoning for
video question answering. <em>AAAI</em>, 13380–13388. (<a
href="https://doi.org/10.1609/aaai.v37i11.26570">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, video question answering has attracted growing attention. It involves answering a question based on a fine-grained understanding of video multi-modal information. Most existing methods have successfully explored the deep understanding of visual modality. We argue that a deep understanding of linguistic modality is also essential for answer reasoning, especially for videos that contain character dialogues. To this end, we propose an Inferential Knowledge-Enhanced Integrated Reasoning method. Our method consists of two main components: 1) an Inferential Knowledge Reasoner to generate inferential knowledge for linguistic modality inputs that reveals deeper semantics, including the implicit causes, effects, mental states, etc. 2) an Integrated Reasoning Mechanism to enhance video content understanding and answer reasoning by leveraging the generated inferential knowledge. Experimental results show that our method achieves significant improvement on two mainstream datasets. The ablation study further demonstrates the effectiveness of each component of our approach.},
  archive   = {C_AAAI},
  author    = {Jianguo Mao and Wenbin Jiang and Hong Liu and Xiangdong Wang and Yajuan Lyu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26570},
  pages     = {13380-13388},
  title     = {Inferential knowledge-enhanced integrated reasoning for video question answering},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). HybridPrompt: Bridging language models and human priors in
prompt tuning for visual question answering. <em>AAAI</em>, 13371–13379.
(<a href="https://doi.org/10.1609/aaai.v37i11.26569">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Visual Question Answering (VQA) aims to answer the natural language question about a given image by understanding multimodal content. However, the answer quality of most existing visual-language pre-training (VLP) methods is still limited, mainly due to: (1) Incompatibility. Upstream pre-training tasks are generally incompatible with downstream question answering tasks, which makes the knowledge from the language model not well transferable to downstream tasks, and greatly limits their performance in few-shot scenarios; (2) Under-fitting. They generally do not integrate human priors to compensate for universal knowledge from language models, so as to fit the challenging VQA problem and generate reliable answers. To address these issues, we propose HybridPrompt, a cloze- and verify-style hybrid prompt framework with bridging language models and human priors in prompt tuning for VQA. Specifically, we first modify the input questions into the cloze-style prompts to narrow the gap between upstream pre-training tasks and downstream VQA task, which ensures that the universal knowledge in the language model can be better transferred to subsequent human prior-guided prompt tuning. Then, we imitate the cognitive process of human brain to introduce topic and sample related priors to construct a dynamic learnable prompt template for human prior-guided prompt learning. Finally, we add fixed-length learnable free-parameters to further enhance the generalizability and scalability of prompt learning in the VQA model. Experimental results verify the effectiveness of HybridPrompt, showing that it achieves competitive performance against previous methods on widely-used VQAv2 dataset and obtains new state-of-the-art results. Our code is released at: https://github.com/zhizhi111/hybrid.},
  archive   = {C_AAAI},
  author    = {Zhiyuan Ma and Zhihuan Yu and Jianjun Li and Guohui Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26569},
  pages     = {13371-13379},
  title     = {HybridPrompt: Bridging language models and human priors in prompt tuning for visual question answering},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Graph component contrastive learning for concept relatedness
estimation. <em>AAAI</em>, 13362–13370. (<a
href="https://doi.org/10.1609/aaai.v37i11.26568">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Concept relatedness estimation (CRE) aims to determine whether two given concepts are related. Existing methods only consider the pairwise relationship between concepts, while overlooking the higher-order relationship that could be encoded in a concept-level graph structure. We discover that this underlying graph satisfies a set of intrinsic properties of CRE, including reflexivity, commutativity, and transitivity. In this paper, we formalize the CRE properties and introduce a graph structure named ConcreteGraph. To address the data scarcity issue in CRE, we introduce a novel data augmentation approach to sample new concept pairs from the graph. As it is intractable for data augmentation to fully capture the structural information of the ConcreteGraph due to a large amount of potential concept pairs, we further introduce a novel Graph Component Contrastive Learning framework to implicitly learn the complete structure of the ConcreteGraph. Empirical results on three datasets show significant improvement over the state-of-the-art model. Detailed ablation studies demonstrate that our proposed approach can effectively capture the high-order relationship among concepts.},
  archive   = {C_AAAI},
  author    = {Yueen Ma and Zixing Song and Xuming Hu and Jingjing Li and Yifei Zhang and Irwin King},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26568},
  pages     = {13362-13370},
  title     = {Graph component contrastive learning for concept relatedness estimation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feature-level debiased natural language understanding.
<em>AAAI</em>, 13353–13361. (<a
href="https://doi.org/10.1609/aaai.v37i11.26567">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Natural language understanding (NLU) models often rely on dataset biases rather than intended task-relevant features to achieve high performance on specific datasets. As a result, these models perform poorly on datasets outside the training distribution. Some recent studies address this issue by reducing the weights of biased samples during the training process. However, these methods still encode biased latent features in representations and neglect the dynamic nature of bias, which hinders model prediction. We propose an NLU debiasing method, named debiasing contrastive learning (DCT), to simultaneously alleviate the above problems based on contrastive learning. We devise a debiasing, positive sampling strategy to mitigate biased latent features by selecting the least similar biased positive samples. We also propose a dynamic negative sampling strategy to capture the dynamic influence of biases by employing a bias-only model to dynamically select the most similar biased negative samples. We conduct experiments on three NLU benchmark datasets. Experimental results show that DCT outperforms state-of-the-art baselines on out-of-distribution datasets while maintaining in-distribution performance. We also verify that DCT can reduce biased latent features from the model&#39;s representation.},
  archive   = {C_AAAI},
  author    = {Yougang Lyu and Piji Li and Yechang Yang and Maarten de Rijke and Pengjie Ren and Yukun Zhao and Dawei Yin and Zhaochun Ren},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26567},
  pages     = {13353-13361},
  title     = {Feature-level debiased natural language understanding},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Zero-shot slot filling with slot-prefix prompting and
attention relationship descriptor. <em>AAAI</em>, 13344–13352. (<a
href="https://doi.org/10.1609/aaai.v37i11.26566">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper addresses zero-shot slot filling, which tries to build a system that can generalize to unseen slot types without any training data. The key to zero-shot slot-filling is to match the tokens from the utterance with the semantic definition of the slot without training data in the target domain. This paper tackles this problem by devising a scheme to fully leverage pre-trained language models (PLMs). To this end, we propose a new prompting scheme that utilizes both learnable tokens and slot names to guide the model to focus on the relevant text spans for a given slot. Furthermore, we use attention values between tokens to form a feature descriptor for each token, which is motivated by the fact that the attention value in a PLM naturally characterizes various relationships, e.g., syntactic or semantic, between tokens. By further consolidating those features with an additional transformer-based aggregation module, we create a simple-but-effective zero-shot slot filling system that can achieve significantly better performance than the previous methods, as demonstrated by our experimental studies.},
  archive   = {C_AAAI},
  author    = {Qiaoyang Luo and Lingqiao Liu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26566},
  pages     = {13344-13352},
  title     = {Zero-shot slot filling with slot-prefix prompting and attention relationship descriptor},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). KICE: A knowledge consolidation and expansion framework for
relation extraction. <em>AAAI</em>, 13336–13343. (<a
href="https://doi.org/10.1609/aaai.v37i11.26565">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Machine Learning is often challenged by insufficient labeled data. Previous methods employing implicit commonsense knowledge of pre-trained language models (PLMs) or pattern-based symbolic knowledge have achieved great success in mitigating manual annotation efforts. In this paper, we focus on the collaboration among different knowledge sources and present KICE, a Knowledge-evolving framework by Iterative Consolidation and Expansion with the guidance of PLMs and rule-based patterns. Specifically, starting with limited labeled data as seeds, KICE first builds a Rule Generator by prompt-tuning to stimulate the rich knowledge distributed in PLMs, generate seed rules, and initialize the rules set. Afterwards, based on the rule-labeled data, the task model is trained in a self-training pipeline where the knowledge in rules set is consolidated with self-learned high-confidence rules. Finally, for the low-confidence rules, KICE solicits human-enlightened understanding and expands the knowledge coverage for better task model training. Our framework is verified on relation extraction (RE) task, and the experiments on TACRED show that the model performance (F1) grows from 33.24\% to 79.84\% with the enrichment of knowledge, outperforming all the baselines including other knowledgeable methods.},
  archive   = {C_AAAI},
  author    = {Yilin Lu and Xiaoqiang Wang and Haofeng Yang and Siliang Tang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26565},
  pages     = {13336-13343},
  title     = {KICE: A knowledge consolidation and expansion framework for relation extraction},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PUnifiedNER: A prompting-based unified NER system for
diverse datasets. <em>AAAI</em>, 13327–13335. (<a
href="https://doi.org/10.1609/aaai.v37i11.26564">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Much of named entity recognition (NER) research focuses on developing dataset-specific models based on data from the domain of interest, and a limited set of related entity types. This is frustrating as each new dataset requires a new model to be trained and stored. In this work, we present a ``versatile&#39;&#39; model---the Prompting-based Unified NER system (PUnifiedNER)---that works with data from different domains and can recognise up to 37 entity types simultaneously, and theoretically it could be as many as possible. By using prompt learning, PUnifiedNER is a novel approach that is able to jointly train across multiple corpora, implementing intelligent on-demand entity recognition. Experimental results show that PUnifiedNER leads to significant prediction benefits compared to dataset-specific models with impressively reduced model deployment costs. Furthermore, the performance of PUnifiedNER can achieve competitive or even better performance than state-of-the-art domain-specific methods for some datasets. We also perform comprehensive pilot and ablation studies to support in-depth analysis of each component in PUnifiedNER.},
  archive   = {C_AAAI},
  author    = {Jinghui Lu and Rui Zhao and Brian Mac Namee and Fei Tan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26564},
  pages     = {13327-13335},
  title     = {PUnifiedNER: A prompting-based unified NER system for diverse datasets},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Universal information extraction as unified semantic
matching. <em>AAAI</em>, 13318–13326. (<a
href="https://doi.org/10.1609/aaai.v37i11.26563">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The challenge of information extraction (IE) lies in the diversity of label schemas and the heterogeneity of structures. Traditional methods require task-specific model design and rely heavily on expensive supervision, making them difficult to generalize to new schemas. In this paper, we decouple IE into two basic abilities, structuring and conceptualizing, which are shared by different tasks and schemas. Based on this paradigm, we propose to universally model various IE tasks with Unified Semantic Matching (USM) framework, which introduces three unified token linking operations to model the abilities of structuring and conceptualizing. In this way, USM can jointly encode schema and input text, uniformly extract substructures in parallel, and controllably decode target structures on demand. Empirical evaluation on 4 IE tasks shows that the proposed method achieves state-of-the-art performance under the supervised experiments and shows strong generalization ability in zero/few-shot transfer settings.},
  archive   = {C_AAAI},
  author    = {Jie Lou and Yaojie Lu and Dai Dai and Wei Jia and Hongyu Lin and Xianpei Han and Le Sun and Hua Wu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26563},
  pages     = {13318-13326},
  title     = {Universal information extraction as unified semantic matching},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SPRING: Situated conversation agent pretrained with
multimodal questions from incremental layout graph. <em>AAAI</em>,
13309–13317. (<a
href="https://doi.org/10.1609/aaai.v37i11.26562">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Existing multimodal conversation agents have shown impressive abilities to locate absolute positions or retrieve attributes in simple scenarios, but they fail to perform well when complex relative positions and information alignments are involved, which poses a bottleneck in response quality. In this paper, we propose a Situated Conversation Agent Pretrained with Multimodal Questions from Incremental Layout Graph (SPRING) with abilities of reasoning multi-hops spatial relations and connecting them with visual attributes in crowded situated scenarios. Specifically, we design two types of Multimodal Question Answering (MQA) tasks to pretrain the agent. All QA pairs utilized during pretraining are generated from novel Increment Layout Graphs (ILG). QA pair difficulty labels automatically annotated by ILG are used to promote MQA-based Curriculum Learning. Experimental results verify the SPRING&#39;s effectiveness, showing that it significantly outperforms state-of-the-art approaches on both SIMMC 1.0 and SIMMC 2.0 datasets. We release our code and data at https://github.com/LYX0501/SPRING.},
  archive   = {C_AAAI},
  author    = {Yuxing Long and Binyuan Hui and Fulong Ye and Yanyang Li and Zhuoxin Han and Caixia Yuan and Yongbin Li and Xiaojie Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26562},
  pages     = {13309-13317},
  title     = {SPRING: Situated conversation agent pretrained with multimodal questions from incremental layout graph},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning compositional tasks from language instructions.
<em>AAAI</em>, 13300–13308. (<a
href="https://doi.org/10.1609/aaai.v37i11.26561">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The ability to combine learned knowledge and skills to solve novel tasks is a key aspect of generalization in humans that allows us to understand and perform tasks described by novel language utterances. While progress has been made in supervised learning settings, no work has yet studied compositional generalization of a reinforcement learning agent following natural language instructions in an embodied environment. We develop a set of tasks in a photo-realistic simulated kitchen environment that allow us to study the degree to which a behavioral policy captures the systematicity in language by studying its zero-shot generalization performance on held out natural language instructions. We show that our agent which leverages a novel additive action-value decomposition in tandem with attention based subgoal prediction is able to exploit composition in text instructions to generalize to unseen tasks.},
  archive   = {C_AAAI},
  author    = {Lajanugen Logeswaran and Wilka Carvalho and Honglak Lee},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26561},
  pages     = {13300-13308},
  title     = {Learning compositional tasks from language instructions},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Effective open intent classification with k-center
contrastive learning and adjustable decision boundary. <em>AAAI</em>,
13291–13299. (<a
href="https://doi.org/10.1609/aaai.v37i11.26560">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Open intent classification, which aims to correctly classify the known intents into their corresponding classes while identifying the new unknown (open) intents, is an essential but challenging task in dialogue systems. In this paper, we introduce novel K-center contrastive learning and adjustable decision boundary learning (CLAB) to improve the effectiveness of open intent classification. First, we pre-train a feature encoder on the labeled training instances, which transfers knowledge from known intents to unknown intents. Specifically, we devise a K-center contrastive learning algorithm to learn discriminative and balanced intent features, improving the generalization of the model for recognizing open intents. Second, we devise an adjustable decision boundary learning method with expanding and shrinking (ADBES) to determine the suitable decision conditions. Concretely, we learn a decision boundary for each known intent class, which consists of a decision center and the radius of the decision boundary. We then expand the radius of the decision boundary to accommodate more in-class instances if the out-of-class instances are far from the decision boundary; otherwise, we shrink the radius of the decision boundary. Extensive experiments on three benchmark datasets clearly demonstrate the effectiveness of our method for open intent classification.For reproducibility, we submit the code at: https://github.com/lxk00/CLAP},
  archive   = {C_AAAI},
  author    = {Xiaokang Liu and Jianquan Li and Jingjing Mu and Min Yang and Ruifeng Xu and Benyou Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26560},
  pages     = {13291-13299},
  title     = {Effective open intent classification with K-center contrastive learning and adjustable decision boundary},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adjective scale probe: Can language models encode formal
semantics information? <em>AAAI</em>, 13282–13290. (<a
href="https://doi.org/10.1609/aaai.v37i11.26559">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {It is an open question what semantic representations transformer-based language models can encode and whether they have access to more abstract aspects of semantic meaning. Here, we propose a diagnostic dataset to investigate how well language models understand the degree semantics of adjectives. In the dataset, referred as the Adjective Scale Probe (ASP), we semi-automatically generate 8 tests of Natural Language Inference (NLI) questions to test 8 key capabilities of adjective interpretation. We apply the ASP dataset to evaluate the performance of 3 language models, i.e., BERT, DeBERTa, and T0. It is found that language models perform below the majority baseline for most tests of the ASP, even when the models have been fine-tuned to achieve high performance on the large-scale MNLI dataset. But after we fine-tune the pre-trained models on a subset of the ASP, DeBERTa can achieve high performance on the untrained adjectives and untrained tests, suggesting that DeBERTa may have captured degree semantic information of adjectives through pre-training but it needs specific training data to learn how to apply such information to the current tasks. In sum, the ASP provides an easy-to-use method to test fine-grained formal semantic properties of adjectives, and reveals language models&#39; abilities to access formal semantic information.},
  archive   = {C_AAAI},
  author    = {Wei Liu and Ming Xiang and Nai Ding},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26559},
  pages     = {13282-13290},
  title     = {Adjective scale probe: Can language models encode formal semantics information?},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Unsupervised paraphrasing under syntax knowledge.
<em>AAAI</em>, 13273–13281. (<a
href="https://doi.org/10.1609/aaai.v37i11.26558">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The soundness of syntax is an important issue for the paraphrase generation task. Most methods control the syntax of paraphrases by embedding the syntax and semantics in the generation process, which cannot guarantee the syntactical correctness of the results. Different from them, in this paper we investigate the structural patterns of word usages termed as the word composable knowledge and integrate it into the paraphrase generation to control the syntax in an explicit way. This syntax knowledge is pretrained on a large corpus with the dependency relationships and formed as the probabilistic functions on the word-level syntactical soundness. For the sentence-level correctness, we design a hierarchical syntax structure loss to quantitatively verify the syntactical soundness of the paraphrase against the given dependency template. Thus, the generation process can select the appropriate words with consideration on both semantics and syntax. The proposed method is evaluated on a few paraphrase datasets. The experimental results show that the quality of paraphrases by our proposed method outperforms the compared methods, especially in terms of syntax correctness.},
  archive   = {C_AAAI},
  author    = {Tianyuan Liu and Yuqing Sun and Jiaqi Wu and Xi Xu and Yuchen Han and Cheng Li and Bin Gong},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26558},
  pages     = {13273-13281},
  title     = {Unsupervised paraphrasing under syntax knowledge},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards credible human evaluation of open-domain dialog
systems using interactive setup. <em>AAAI</em>, 13264–13272. (<a
href="https://doi.org/10.1609/aaai.v37i11.26557">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Evaluating open-domain conversation models has been an open challenge due to the open-ended nature of conversations. In addition to static evaluations, recent work has started to explore a variety of per-turn and per-dialog interactive evaluation mechanisms and provide advice on the best setup. In this work, we adopt the interactive evaluation framework and further apply to multiple models with a focus on per-turn evaluation techniques. Apart from the widely used setting where participants select the best response among different candidates at each turn, one more novel per-turn evaluation setting is adopted, where participants can select all appropriate responses with different fallback strategies to continue the conversation when no response is selected. We evaluate these settings based on sensitivity and consistency using four GPT2-based models that differ in model sizes or fine-tuning data. To better generalize to any model groups with no prior assumptions on their rankings and control evaluation costs for all setups, we also propose a methodology to estimate the required sample size given a minimum performance gap of interest before running most experiments. Our comprehensive human evaluation results shed light on how to conduct credible human evaluations of open domain dialog systems using the interactive setup, and suggest additional future directions.},
  archive   = {C_AAAI},
  author    = {Sijia Liu and Patrick Lange and Behnam Hedayatnia and Alexandros Papangelis and Di Jin and Andrew Wirth and Yang Liu and Dilek Hakkani-Tur},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26557},
  pages     = {13264-13272},
  title     = {Towards credible human evaluation of open-domain dialog systems using interactive setup},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A disentangled-attention based framework with persona-aware
prompt learning for dialogue generation. <em>AAAI</em>, 13255–13263. (<a
href="https://doi.org/10.1609/aaai.v37i11.26556">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Endowing dialogue agents with personas is the key to delivering more human-like conversations. However, existing persona-grounded dialogue systems still lack informative details of human conversations and tend to reply with inconsistent and generic responses. One of the main underlying causes is that pre-defined persona sentences are generally short and merely superficial descriptions of personal attributes, making appropriate persona selection and understanding non-trivial. Another challenge is that it is crucial to consider the context and the conversation flow to dynamically determine when to invoke different types of persona signals. To address these problems, we propose a disentangled-attention based pre-training architecture, which incorporates persona-aware prompt learning to bridge the connection between the selected persona and response generation. Our model first exploits the conversation flow to select context-relevant personas, and subsequently enriches the superficial persona descriptions with extra personality traits through persona-aware prompting. Finally, the decoder leverages a disentangled-attention mechanism to flexibly control the reliance on personas and dialogue contexts, and incorporates A*-like keyword-based heuristic estimates for controllable generation. Extensive experiments show that our approach can outperform strong baselines and deliver more consistent and engaging responses on the PERSONA-CHAT dataset.},
  archive   = {C_AAAI},
  author    = {Pingsheng Liu and Zhengjie Huang and Xiechi Zhang and Linlin Wang and Gerard de Melo and Xin Lin and Liang Pang and Liang He},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26556},
  pages     = {13255-13263},
  title     = {A disentangled-attention based framework with persona-aware prompt learning for dialogue generation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Selective knowledge distillation for non-autoregressive
neural machine translation. <em>AAAI</em>, 13246–13254. (<a
href="https://doi.org/10.1609/aaai.v37i11.26555">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Benefiting from the sequence-level knowledge distillation, the Non-Autoregressive Transformer (NAT) achieves great success in neural machine translation tasks. However, existing knowledge distillation has side effects, such as propagating errors from the teacher to NAT students, which may limit further improvements of NAT models and are rarely discussed in existing research. In this paper, we introduce selective knowledge distillation by introducing an NAT evaluator to select NAT-friendly targets that are of high quality and easy to learn. In addition, we introduce a simple yet effective progressive distillation method to boost NAT performance. Experiment results on multiple WMT language directions and several representative NAT models show that our approach can realize a flexible trade-off between the quality and complexity of training data for NAT models, achieving strong performances. Further analysis shows that distilling only 5\% of the raw translations can help an NAT outperform its counterpart trained on raw data by about 2.4 BLEU.},
  archive   = {C_AAAI},
  author    = {Min Liu and Yu Bao and Chengqi Zhao and Shujian Huang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26555},
  pages     = {13246-13254},
  title     = {Selective knowledge distillation for non-autoregressive neural machine translation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). LADA-trans-NER: Adaptive efficient transformer for chinese
named entity recognition using lexicon-attention and data-augmentation.
<em>AAAI</em>, 13236–13245. (<a
href="https://doi.org/10.1609/aaai.v37i11.26554">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, word enhancement has become very popular for Chinese Named Entity Recognition (NER), reducing segmentation errors and increasing the semantic and boundary information of Chinese words. However, these methods tend to ignore the semantic relationship before and after the sentence after integrating lexical information. Therefore, the regularity of word length information has not been fully explored in various word-character fusion methods. In this work, we propose a Lexicon-Attention and Data-Augmentation (LADA) method for Chinese NER. We discuss the challenges of using existing methods in incorporating word information for NER and show how our proposed methods could be leveraged to overcome those challenges. LADA is based on a Transformer Encoder that utilizes lexicon to construct a directed graph and fuses word information through updating the optimal edge of the graph. Specially, we introduce the advanced data augmentation method to obtain the optimal representation for the NER task. Experimental results show that the augmentation done using LADA can considerably boost the performance of our NER system and achieve significantly better results than previous state-of-the-art methods and variant models in the literature on four publicly available NER datasets, namely Resume, MSRA, Weibo, and OntoNotes v4. We also observe better generalization and application to a real-world setting from LADA on multi-source complex entities.},
  archive   = {C_AAAI},
  author    = {Jiguo Liu and Chao Liu and Nan Li and Shihao Gao and Mingqi Liu and Dali Zhu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26554},
  pages     = {13236-13245},
  title     = {LADA-trans-NER: Adaptive efficient transformer for chinese named entity recognition using lexicon-attention and data-augmentation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). SSPAttack: A simple and sweet paradigm for black-box
hard-label textual adversarial attack. <em>AAAI</em>, 13228–13235. (<a
href="https://doi.org/10.1609/aaai.v37i11.26553">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Hard-label textual adversarial attack is a challenging task, as only the predicted label information is available, and the text space is discrete and non-differentiable. Relevant research work is still in fancy and just a handful of methods are proposed. However, existing methods suffer from either the high complexity of genetic algorithms or inaccurate gradient estimation, thus are arduous to obtain adversarial examples with high semantic similarity and low perturbation rate under the tight-budget scenario. In this paper, we propose a simple and sweet paradigm for hard-label textual adversarial attack, named SSPAttack. Specifically, SSPAttack first utilizes initialization to generate an adversarial example, and removes unnecessary replacement words to reduce the number of changed words. Then it determines the replacement order and searches for an anchor synonym, thus avoiding going through all the synonyms. Finally, it pushes substitution words towards original words until an appropriate adversarial example is obtained. The core idea of SSPAttack is just swapping words whose mechanism is simple. Experimental results on eight benchmark datasets and two real-world APIs have shown that the performance of SSPAttack is sweet in terms of similarity, perturbation rate and query efficiency.},
  archive   = {C_AAAI},
  author    = {Han Liu and Zhi Xu and Xiaotong Zhang and Xiaoming Xu and Feng Zhang and Fenglong Ma and Hongyang Chen and Hong Yu and Xianchao Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26553},
  pages     = {13228-13235},
  title     = {SSPAttack: A simple and sweet paradigm for black-box hard-label textual adversarial attack},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Boosting few-shot text classification via distribution
estimation. <em>AAAI</em>, 13219–13227. (<a
href="https://doi.org/10.1609/aaai.v37i11.26552">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Distribution estimation has been demonstrated as one of the most effective approaches in dealing with few-shot image classification, as the low-level patterns and underlying representations can be easily transferred across different tasks in computer vision domain. However, directly applying this approach to few-shot text classification is challenging, since leveraging the statistics of known classes with sufficient samples to calibrate the distributions of novel classes may cause negative effects due to serious category difference in text domain. To alleviate this issue, we propose two simple yet effective strategies to estimate the distributions of the novel classes by utilizing unlabeled query samples, thus avoiding the potential negative transfer issue. Specifically, we first assume a class or sample follows the Gaussian distribution, and use the original support set and the nearest few query samples to estimate the corresponding mean and covariance. Then, we augment the labeled samples by sampling from the estimated distribution, which can provide sufficient supervision for training the classification model. Extensive experiments on eight few-shot text classification datasets show that the proposed method outperforms state-of-the-art baselines significantly.},
  archive   = {C_AAAI},
  author    = {Han Liu and Feng Zhang and Xiaotong Zhang and Siyang Zhao and Fenglong Ma and Xiao-Ming Wu and Hongyang Chen and Hong Yu and Xianchao Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26552},
  pages     = {13219-13227},
  title     = {Boosting few-shot text classification via distribution estimation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Detecting and grounding important characters in visual
stories. <em>AAAI</em>, 13210–13218. (<a
href="https://doi.org/10.1609/aaai.v37i11.26551">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Characters are essential to the plot of any story. Establishing the characters before writing a story can improve the clarity of the plot and the overall flow of the narrative. However, previous work on visual storytelling tends to focus on detecting objects in images and discovering relationships between them. In this approach, characters are not distinguished from other objects when they are fed into the generation pipeline. The result is a coherent sequence of events rather than a character-centric story. In order to address this limitation, we introduce the VIST-Character dataset, which provides rich character-centric annotations, including visual and textual co-reference chains and importance ratings for characters. Based on this dataset, we propose two new tasks: important character detection and character grounding in visual stories. For both tasks, we develop simple, unsupervised models based on distributional similarity and pre-trained vision-and-language models. Our new dataset, together with these models, can serve as the foundation for subsequent work on analysing and generating stories from a character-centric perspective.},
  archive   = {C_AAAI},
  author    = {Danyang Liu and Frank Keller},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26551},
  pages     = {13210-13218},
  title     = {Detecting and grounding important characters in visual stories},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). DeAR: A deep-learning-based audio re-recording resilient
watermarking. <em>AAAI</em>, 13201–13209. (<a
href="https://doi.org/10.1609/aaai.v37i11.26550">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Audio watermarking is widely used for leaking source tracing. The robustness of the watermark determines the traceability of the algorithm. With the development of digital technology, audio re-recording (AR) has become an efficient and covert means to steal secrets. AR process could drastically destroy the watermark signal while preserving the original information. This puts forward a new requirement for audio watermarking at this stage, that is, to be robust to AR distortions. Unfortunately, none of the existing algorithms can effectively resist AR attacks due to the complexity of the AR process. To address this limitation, this paper proposes DeAR, a deep-learning-based audio re-recording resistant watermarking. Inspired by DNN-based image watermarking, we pioneer a deep learning framework for audio carriers, based on which the watermark signal can be effectively embedded and extracted. Meanwhile, in order to resist the AR attack, we delicately analyze the distortions that occurred in the AR process and design the corresponding distortion layer to cooperate with the proposed watermarking framework. Extensive experiments show that the proposed algorithm can resist not only common electronic channel distortions but also AR distortions. Under the premise of high-quality embedding (SNR=25.86dB), in the case of a common re-recording distance (20cm), the algorithm can effectively achieve an average bit recovery accuracy of 98.55\%.},
  archive   = {C_AAAI},
  author    = {Chang Liu and Jie Zhang and Han Fang and Zehua Ma and Weiming Zhang and Nenghai Yu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26550},
  pages     = {13201-13209},
  title     = {DeAR: A deep-learning-based audio re-recording resilient watermarking},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On grounded planning for embodied tasks with language
models. <em>AAAI</em>, 13192–13200. (<a
href="https://doi.org/10.1609/aaai.v37i11.26549">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Language models (LMs) have demonstrated their capability in possessing commonsense knowledge of the physical world, a crucial aspect of performing tasks in everyday life. However, it remains unclear whether they have the capacity to generate grounded, executable plans for embodied tasks. This is a challenging task as LMs lack the ability to perceive the environment through vision and feedback from the physical environment. In this paper, we address this important research question and present the first investigation into the topic. Our novel problem formulation, named G-PlanET, inputs a high-level goal and a data table about objects in a specific environment, and then outputs a step-by-step actionable plan for a robotic agent to follow. To facilitate the study, we establish an evaluation protocol and design a dedicated metric, KAS, to assess the quality of the plans. Our experiments demonstrate that the use of tables for encoding the environment and an iterative decoding strategy can significantly enhance the LMs&#39; ability in grounded planning. Our analysis also reveals interesting and non-trivial findings.},
  archive   = {C_AAAI},
  author    = {Bill Yuchen Lin and Chengsong Huang and Qian Liu and Wenda Gu and Sam Sommerer and Xiang Ren},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26549},
  pages     = {13192-13200},
  title     = {On grounded planning for embodied tasks with language models},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generalizing math word problem solvers via solution
diversification. <em>AAAI</em>, 13183–13191. (<a
href="https://doi.org/10.1609/aaai.v37i11.26548">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Current math word problem (MWP) solvers are usually Seq2Seq models trained by the (one-problem; one-solution) pairs, each of which is made of a problem description and a solution showing reasoning flow to get the correct answer. However, one MWP problem naturally has multiple solution equations. The training of an MWP solver with (one-problem; one-solution) pairs excludes other correct solutions, and thus limits the generalizability of the MWP solver. One feasible solution to this limitation is to augment multiple solutions to a given problem. However, it is difficult to collect diverse and accurate augment solutions through human efforts. In this paper, we design a new training framework for an MWP solver by introducing a solution buffer and a solution discriminator. The buffer includes solutions generated by an MWP solver to encourage the training data diversity. The discriminator controls the quality of buffered solutions to participate in training. Our framework is flexibly applicable to a wide setting of fully, semi-weakly and weakly supervised training for all Seq2Seq MWP solvers. We conduct extensive experiments on a benchmark dataset Math23k and a new dataset named Weak12k, and show that our framework improves the performance of various MWP solvers under different settings by generating correct and diverse solutions.},
  archive   = {C_AAAI},
  author    = {Zhenwen Liang and Jipeng Zhang and Lei Wang and Yan Wang and Jie Shao and Xiangliang Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26548},
  pages     = {13183-13191},
  title     = {Generalizing math word problem solvers via solution diversification},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). STAGE: Span tagging and greedy inference scheme for aspect
sentiment triplet extraction. <em>AAAI</em>, 13174–13182. (<a
href="https://doi.org/10.1609/aaai.v37i11.26547">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Aspect Sentiment Triplet Extraction (ASTE) has become an emerging task in sentiment analysis research, aiming to extract triplets of the aspect term, its corresponding opinion term, and its associated sentiment polarity from a given sentence. Recently, many neural networks based models with different tagging schemes have been proposed, but almost all of them have their limitations: heavily relying on 1) prior assumption that each word is only associated with a single role (e.g., aspect term, or opinion term, etc. ) and 2) word-level interactions and treating each opinion/aspect as a set of independent words. Hence, they perform poorly on the complex ASTE task, such as a word associated with multiple roles or an aspect/opinion term with multiple words. Hence, we propose a novel approach, Span TAgging and Greedy infErence (STAGE), to extract sentiment triplets in span-level, where each span may consist of multiple words and play different roles simultaneously. To this end, this paper formulates the ASTE task as a multi-class span classification problem. Specifically, STAGE generates more accurate aspect sentiment triplet extractions via exploring span-level information and constraints, which consists of two components, namely, span tagging scheme and greedy inference strategy. The former tag all possible candidate spans based on a newly-defined tagging set. The latter retrieves the aspect/opinion term with the maximum length from the candidate sentiment snippet to output sentiment triplets. Furthermore, we propose a simple but effective model based on the STAGE, which outperforms the state-of-the-arts by a large margin on four widely-used datasets. Moreover, our STAGE can be easily generalized to other pair/triplet extraction tasks, which also demonstrates the superiority of the proposed scheme STAGE.},
  archive   = {C_AAAI},
  author    = {Shuo Liang and Wei Wei and Xian-Ling Mao and Yuanyuan Fu and Rui Fang and Dangyang Chen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26547},
  pages     = {13174-13182},
  title     = {STAGE: Span tagging and greedy inference scheme for aspect sentiment triplet extraction},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). WIERT: Web information extraction via render tree.
<em>AAAI</em>, 13166–13173. (<a
href="https://doi.org/10.1609/aaai.v37i11.26546">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Web information extraction (WIE) is a fundamental problem in web document understanding, with a significant impact on various applications. Visual information plays a crucial role in WIE tasks as the nodes containing relevant information are often visually distinct, such as being in a larger font size or having a brighter color, from the other nodes. However, rendering visual information of a web page can be computationally expensive. Previous works have mainly focused on the Document Object Model (DOM) tree, which lacks visual information. To efficiently exploit visual information, we propose leveraging the render tree, which combines the DOM tree and Cascading Style Sheets Object Model (CSSOM) tree, and contains not only content and layout information but also rich visual information at a little additional acquisition cost compared to the DOM tree. In this paper, we present WIERT, a method that effectively utilizes the render tree of a web page based on a pretrained language model. We evaluate WIERT on the Klarna product page dataset, a manually labeled dataset of renderable e-commerce web pages, demonstrating its effectiveness and robustness.},
  archive   = {C_AAAI},
  author    = {Zimeng Li and Bo Shao and Linjun Shou and Ming Gong and Gen Li and Daxin Jiang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26546},
  pages     = {13166-13173},
  title     = {WIERT: Web information extraction via render tree},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning to know myself: A coarse-to-fine persona-aware
training framework for personalized dialogue generation. <em>AAAI</em>,
13157–13165. (<a
href="https://doi.org/10.1609/aaai.v37i11.26545">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A critical challenge for open-domain dialogue agents is to generate persona-relevant and consistent responses. Due to the nature of persona sparsity in conversation scenarios, previous persona-based dialogue agents trained with Maximum Likelihood Estimation tend to overlook the given personas and generate responses irrelevant or inconsistent with personas. To address this problem, we propose a two-stage coarse-to-fine persona-aware training framework to improve the persona consistency of a dialogue agent progressively. Specifically, our framework first trains the dialogue agent to answer the constructed persona-aware questions, making it highly sensitive to the personas to generate persona-relevant responses. Then the dialogue agent is further trained with a contrastive learning paradigm by explicitly perceiving the difference between the consistent and the generated inconsistent responses, forcing it to pay more attention to the key persona information to generate consistent responses. By applying our proposed training framework to several representative baseline models, experimental results show significant boosts on both automatic and human evaluation metrics, especially the consistency of generated responses.},
  archive   = {C_AAAI},
  author    = {Yunpeng Li and Yue Hu and Yajing Sun and Luxi Xing and Ping Guo and Yuqiang Xie and Wei Peng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26545},
  pages     = {13157-13165},
  title     = {Learning to know myself: A coarse-to-fine persona-aware training framework for personalized dialogue generation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Heterogeneous-branch collaborative learning for dialogue
generation. <em>AAAI</em>, 13148–13156. (<a
href="https://doi.org/10.1609/aaai.v37i11.26544">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With the development of deep learning, advanced dialogue generation methods usually require a greater amount of computational resources. One promising approach to obtaining a high-performance and lightweight model is knowledge distillation, which relies heavily on the pre-trained powerful teacher. Collaborative learning, also known as online knowledge distillation, is an effective way to conduct one-stage group distillation in the absence of a well-trained large teacher model. However, previous work has a severe branch homogeneity problem due to the same training objective and the independent identical training sets. To alleviate this problem, we consider the dialogue attributes in the training of network branches. Each branch learns the attribute-related features based on the selected subset. Furthermore, we propose a dual group-based knowledge distillation method, consisting of positive distillation and negative distillation, to further diversify the features of different branches in a steadily and interpretable way. The proposed approach significantly improves branch heterogeneity and outperforms state-of-the-art collaborative learning methods on two widely used open-domain dialogue datasets.},
  archive   = {C_AAAI},
  author    = {Yiwei Li and Shaoxiong Feng and Bin Sun and Kan Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26544},
  pages     = {13148-13156},
  title     = {Heterogeneous-branch collaborative learning for dialogue generation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). DyRRen: A dynamic retriever-reranker-generator model for
numerical reasoning over tabular and textual data. <em>AAAI</em>,
13139–13147. (<a
href="https://doi.org/10.1609/aaai.v37i11.26543">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Numerical reasoning over hybrid data containing tables and long texts has recently received research attention from the AI community. To generate an executable reasoning program consisting of math and table operations to answer a question, state-of-the-art methods use a retriever-generator pipeline. However, their retrieval results are static, while different generation steps may rely on different sentences. To attend to the retrieved information that is relevant to each generation step, in this paper, we propose DyRRen, an extended retriever-reranker-generator framework where each generation step is enhanced by a dynamic reranking of retrieved sentences. It outperforms existing baselines on the FinQA dataset.},
  archive   = {C_AAAI},
  author    = {Xiao Li and Yin Zhu and Sichen Liu and Jiangzhou Ju and Yuzhong Qu and Gong Cheng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26543},
  pages     = {13139-13147},
  title     = {DyRRen: A dynamic retriever-reranker-generator model for numerical reasoning over tabular and textual data},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023f). PGSS: Pitch-guided speech separation. <em>AAAI</em>,
13130–13138. (<a
href="https://doi.org/10.1609/aaai.v37i11.26542">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Monaural speech separation aims to separate concurrent speakers from a single-microphone mixture recording. Inspired by the effect of pitch priming in auditory scene analysis (ASA) mechanisms, a novel pitch-guided speech separation framework is proposed in this work. The prominent advantage of this framework is that both the permutation problem and the unknown speaker number problem existing in general models can be avoided by using pitch contours as the primary means to guide the target speaker. In addition, adversarial training is applied, instead of a traditional time-frequency mask, to improve the perceptual quality of separated speech. Specifically, the proposed framework can be divided into two phases: pitch extraction and speech separation. The former aims to extract pitch contour candidates for each speaker from the mixture, modeling the bottom-up process in ASA mechanisms. Any pitch contour can be selected as the condition in the second phase to separate the corresponding speaker, where a conditional generative adversarial network (CGAN) is applied. The second phase models the effect of pitch priming in ASA. Experiments on the WSJ0-2mix corpus reveal that the proposed approaches can achieve higher pitch extraction accuracy and better separation performance, compared to the baseline models, and have the potential to be applied to SOTA architectures.},
  archive   = {C_AAAI},
  author    = {Xiang Li and Yiwen Wang and Yifan Sun and Xihong Wu and Jing Chen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26542},
  pages     = {13130-13138},
  title     = {PGSS: Pitch-guided speech separation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). SKIER: A symbolic knowledge integrated model for
conversational emotion recognition. <em>AAAI</em>, 13121–13129. (<a
href="https://doi.org/10.1609/aaai.v37i11.26541">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Emotion recognition in conversation (ERC) has received increasing attention from the research community. However, the ERC task is challenging, largely due to the complex and unstructured properties of multi-party conversations. Besides, the majority of daily dialogues take place in a specific context or circumstance, which requires rich external knowledge to understand the background of a certain dialogue. In this paper, we address these challenges by explicitly modeling the discourse relations between utterances and incorporating symbolic knowledge into multi-party conversations. We first introduce a dialogue parsing algorithm into ERC and further improve the algorithm through a transfer learning method. Moreover, we leverage different symbolic knowledge graph relations to learn knowledge-enhanced features for the ERC task. Extensive experiments on three benchmarks demonstrate that both dialogue structure graphs and symbolic knowledge are beneficial to the model performance on the task. Additionally, experimental results indicate that the proposed model surpasses baseline models on several indices.},
  archive   = {C_AAAI},
  author    = {Wei Li and Luyao Zhu and Rui Mao and Erik Cambria},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26541},
  pages     = {13121-13129},
  title     = {SKIER: A symbolic knowledge integrated model for conversational emotion recognition},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023e). Low resource quantitative information extraction via
structure searching and prefix-based text generation. <em>AAAI</em>,
13112–13120. (<a
href="https://doi.org/10.1609/aaai.v37i11.26540">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Quantitative information plays an important part in the financial and data analysis areas. Prior work relied on pattern-matching methods and complex hand-crafted rules to extract quantitative information due to the lack of labeled data. Such methods can be unstable and difficult to scale to the open domain. In this paper, we study quantitative information extraction in the low-resource setting. We propose a search-based approach by searching from the syntactic structures to acquire basic training data. The search process is simple yet effective. Then, a prefix-based text-to-text generation method is employed to extract the quantitative information. The prefix design can fully leverage pre-trained language models for text generation to serve the information extraction purpose. Experimental results show that our approaches achieves high performance with a limited amount of labeled data. The extraction result could further boost the performance of other tasks such as quantitative reasoning.},
  archive   = {C_AAAI},
  author    = {Tongliang Li and Zixiang Wang and Zhoujun Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26540},
  pages     = {13112-13120},
  title     = {Low resource quantitative information extraction via structure searching and prefix-based text generation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mitigating negative style transfer in hybrid dialogue
system. <em>AAAI</em>, 13103–13111. (<a
href="https://doi.org/10.1609/aaai.v37i11.26539">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As the functionality of dialogue systems evolves, hybrid dialogue systems that accomplish user-specific goals and participate in open-topic chitchat with users are attracting growing attention. Existing research learns both tasks concurrently utilizing a multi-task fusion technique but ignores the negative transfer phenomenon induced by the unique textual style differences. Therefore, contrastive learning based on the latent variable model is used to decouple the various textual genres in the latent space. We devise supervised and self-supervised positive and negative sample constructions for diverse datasets. In addition, to capitalize on the style information contained in the decoupled latent variables, we employ a style prefix that incorporates latent variables further to control the generation of responses with varying styles. We performed extensive experiments on three dialogue datasets, including a hybrid dialogue dataset and two task-oriented dialogue datasets. The experimental results demonstrate that our method can mitigate the negative style transfer issue and achieves state-of-the-art performance on multiple dialogue datasets.},
  archive   = {C_AAAI},
  author    = {Shimin Li and Qinyuan Cheng and Linyang Li and Xipeng Qiu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26539},
  pages     = {13103-13111},
  title     = {Mitigating negative style transfer in hybrid dialogue system},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TrOCR: Transformer-based optical character recognition with
pre-trained models. <em>AAAI</em>, 13094–13102. (<a
href="https://doi.org/10.1609/aaai.v37i11.26538">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Text recognition is a long-standing research problem for document digitalization. Existing approaches are usually built based on CNN for image understanding and RNN for char-level text generation. In addition, another language model is usually needed to improve the overall accuracy as a post-processing step. In this paper, we propose an end-to-end text recognition approach with pre-trained image Transformer and text Transformer models, namely TrOCR, which leverages the Transformer architecture for both image understanding and wordpiece-level text generation. The TrOCR model is simple but effective, and can be pre-trained with large-scale synthetic data and fine-tuned with human-labeled datasets. Experiments show that the TrOCR model outperforms the current state-of-the-art models on the printed, handwritten and scene text recognition tasks. The TrOCR models and code are publicly available at https://aka.ms/trocr.},
  archive   = {C_AAAI},
  author    = {Minghao Li and Tengchao Lv and Jingye Chen and Lei Cui and Yijuan Lu and Dinei Florencio and Cha Zhang and Zhoujun Li and Furu Wei},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26538},
  pages     = {13094-13102},
  title     = {TrOCR: Transformer-based optical character recognition with pre-trained models},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Compressed heterogeneous graph for abstractive
multi-document summarization. <em>AAAI</em>, 13085–13093. (<a
href="https://doi.org/10.1609/aaai.v37i11.26537">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-document summarization (MDS) aims to generate a summary for a number of related documents. We propose HGSum — an MDS model that extends an encoder-decoder architecture to incorporate a heterogeneous graph to represent different semantic units (e.g., words and sentences) of the documents. This contrasts with existing MDS models which do not consider different edge types of graphs and as such do not capture the diversity of relationships in the documents. To preserve only key information and relationships of the documents in the heterogeneous graph, HGSum uses graph pooling to compress the input graph. And to guide HGSum to learn the compression, we introduce an additional objective that maximizes the similarity between the compressed graph and the graph constructed from the ground-truth summary during training. HGSum is trained end-to-end with the graph similarity and standard cross-entropy objectives. Experimental results over Multi-News, WCEP-100, and Arxiv show that HGSum outperforms state-of-the-art MDS models. The code for our model and experiments is available at: https://github.com/oaimli/HGSum.},
  archive   = {C_AAAI},
  author    = {Miao Li and Jianzhong Qi and Jey Han Lau},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26537},
  pages     = {13085-13093},
  title     = {Compressed heterogeneous graph for abstractive multi-document summarization},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Graphix-t5: Mixing pre-trained transformers with graph-aware
layers for text-to-SQL parsing. <em>AAAI</em>, 13076–13084. (<a
href="https://doi.org/10.1609/aaai.v37i11.26536">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The task of text-to-SQL parsing, which aims at converting natural language questions into executable SQL queries, has garnered increasing attention in recent years. One of the major challenges in text-to-SQL parsing is domain generalization, i.e., how to generalize well to unseen databases. Recently, the pre-trained text-to-text transformer model, namely T5, though not specialized for text-to-SQL parsing, has achieved state-of-the-art performance on standard benchmarks targeting domain generalization. In this work, we explore ways to further augment the pre-trained T5 model with specialized components for text-to-SQL parsing. Such components are expected to introduce structural inductive bias into text-to-SQL parsers thus improving the model’s capacity on (potentially multi-hop) reasoning, which is critical for generating structure-rich SQLs. To this end, we propose a new architecture GRAPHIX-T5, a mixed model with the standard pre-trained transformer model augmented by specially-designed graph-aware layers. Extensive experiments and analysis demonstrate the effectiveness of GRAPHIX-T5 across four text-to-SQL benchmarks: SPIDER, SYN, REALISTIC and DK. GRAPHIX-T5 surpasses all other T5-based parsers with a significant margin, achieving new state-of-the-art performance. Notably, GRAPHIX-T5-large reaches performance superior to the original T5-large by 5.7\% on exact match (EM) accuracy and 6.6\% on execution accuracy (EX). This even outperforms the T5-3B by 1.2\% on EM and 1.5\% on EX},
  archive   = {C_AAAI},
  author    = {Jinyang Li and Binyuan Hui and Reynold Cheng and Bowen Qin and Chenhao Ma and Nan Huo and Fei Huang and Wenyu Du and Luo Si and Yongbin Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26536},
  pages     = {13076-13084},
  title     = {Graphix-t5: Mixing pre-trained transformers with graph-aware layers for text-to-SQL parsing},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RESDSQL: Decoupling schema linking and skeleton parsing for
text-to-SQL. <em>AAAI</em>, 13067–13075. (<a
href="https://doi.org/10.1609/aaai.v37i11.26535">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {One of the recent best attempts at Text-to-SQL is the pre-trained language model. Due to the structural property of the SQL queries, the seq2seq model takes the responsibility of parsing both the schema items (i.e., tables and columns) and the skeleton (i.e., SQL keywords). Such coupled targets increase the difficulty of parsing the correct SQL queries especially when they involve many schema items and logic operators. This paper proposes a ranking-enhanced encoding and skeleton-aware decoding framework to decouple the schema linking and the skeleton parsing. Specifically, for a seq2seq encoder-decode model, its encoder is injected by the most relevant schema items instead of the whole unordered ones, which could alleviate the schema linking effort during SQL parsing, and its decoder first generates the skeleton and then the actual SQL query, which could implicitly constrain the SQL parsing. We evaluate our proposed framework on Spider and its three robustness variants: Spider-DK, Spider-Syn, and Spider-Realistic. The experimental results show that our framework delivers promising performance and robustness. Our code is available at https://github.com/RUCKBReasoning/RESDSQL.},
  archive   = {C_AAAI},
  author    = {Haoyang Li and Jing Zhang and Cuiping Li and Hong Chen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26535},
  pages     = {13067-13075},
  title     = {RESDSQL: Decoupling schema linking and skeleton parsing for text-to-SQL},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Online noisy continual relation learning. <em>AAAI</em>,
13059–13066. (<a
href="https://doi.org/10.1609/aaai.v37i11.26534">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent work for continual relation learning has achieved remarkable progress. However, most existing methods only focus on tackling catastrophic forgetting to improve performance in the existing setup, while continually learning relations in the real-world must overcome many other challenges. One is that the data possibly comes in an online streaming fashion with data distributions gradually changing and without distinct task boundaries. Another is that noisy labels are inevitable in real-world, as relation samples may be contaminated by label inconsistencies or labeled with distant supervision. In this work, therefore, we propose a novel continual relation learning framework that simultaneously addresses both online and noisy relation learning challenges. Our framework contains three key modules: (i) a sample separated online purifying module that divides the online data stream into clean and noisy samples, (ii) a self-supervised online learning module that circumvents inferior training signals caused by noisy data, and (iii) a semi-supervised offline finetuning module that ensures the participation of both clean and noisy samples. Experimental results on FewRel, TACRED and NYT-H with real-world noise demonstrate that our framework greatly outperforms the combinations of the state-of-the-art online continual learning and noisy label learning methods.},
  archive   = {C_AAAI},
  author    = {Guozheng Li and Peng Wang and Qiqing Luo and Yanhe Liu and Wenjun Ke},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26534},
  pages     = {13059-13066},
  title     = {Online noisy continual relation learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reviewing labels: Label graph network with top-k prediction
set for relation extraction. <em>AAAI</em>, 13051–13058. (<a
href="https://doi.org/10.1609/aaai.v37i11.26533">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The typical way for relation extraction is fine-tuning large pre-trained language models on task-specific datasets, then selecting the label with the highest probability of the output distribution as the final prediction. However, the usage of the Top-k prediction set for a given sample is commonly overlooked. In this paper, we first reveal that the Top-k prediction set of a given sample contains useful information for predicting the correct label. To effectively utilizes the Top-k prediction set, we propose Label Graph Network with Top-k Prediction Set, termed as KLG. Specifically, for a given sample, we build a label graph to review candidate labels in the Top-k prediction set and learn the connections between them. We also design a dynamic k selection mechanism to learn more powerful and discriminative relation representation. Our experiments show that KLG achieves the best performances on three relation extraction datasets. Moreover, we observe thatKLG is more effective in dealing with long-tailed classes.},
  archive   = {C_AAAI},
  author    = {Bo Li and Wei Ye and Jinglei Zhang and Shikun Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26533},
  pages     = {13051-13058},
  title     = {Reviewing labels: Label graph network with top-k prediction set for relation extraction},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Sequence generation with label augmentation for relation
extraction. <em>AAAI</em>, 13043–13050. (<a
href="https://doi.org/10.1609/aaai.v37i11.26532">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Sequence generation demonstrates promising performance in recent information extraction efforts, by incorporating large-scale pre-trained Seq2Seq models. This paper investigates the merits of employing sequence generation in relation extraction, finding that with relation names or synonyms as generation targets, their textual semantics and the correlation (in terms of word sequence pattern) among them affect model performance. We then propose Relation Extraction with Label Augmentation (RELA), a Seq2Seq model with automatic label augmentation for RE. By saying label augmentation, we mean prod semantically synonyms for each relation name as the generation target. Besides, we present an in-depth analysis of the Seq2Seq model&#39;s behavior when dealing with RE. Experimental results show that RELA achieves competitive results compared with previous methods on four RE datasets.},
  archive   = {C_AAAI},
  author    = {Bo Li and Dingyao Yu and Wei Ye and Jinglei Zhang and Shikun Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26532},
  pages     = {13043-13050},
  title     = {Sequence generation with label augmentation for relation extraction},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SoftCorrect: Error correction with soft detection for
automatic speech recognition. <em>AAAI</em>, 13034–13042. (<a
href="https://doi.org/10.1609/aaai.v37i11.26531">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Error correction in automatic speech recognition (ASR) aims to correct those incorrect words in sentences generated by ASR models. Since recent ASR models usually have low word error rate (WER), to avoid affecting originally correct tokens, error correction models should only modify incorrect words, and therefore detecting incorrect words is important for error correction. Previous works on error correction either implicitly detect error words through target-source attention or CTC (connectionist temporal classification) loss, or explicitly locate specific deletion/substitution/insertion errors. However, implicit error detection does not provide clear signal about which tokens are incorrect and explicit error detection suffers from low detection accuracy. In this paper, we propose SoftCorrect with a soft error detection mechanism to avoid the limitations of both explicit and implicit error detection. Specifically, we first detect whether a token is correct or not through a probability produced by a dedicatedly designed language model, and then design a constrained CTC loss that only duplicates the detected incorrect tokens to let the decoder focus on the correction of error tokens. Compared with implicit error detection with CTC loss, SoftCorrect provides explicit signal about which words are incorrect and thus does not need to duplicate every token but only incorrect tokens; compared with explicit error detection, SoftCorrect does not detect specific deletion/substitution/insertion errors but just leaves it to CTC loss. Experiments on AISHELL-1 and Aidatatang datasets show that SoftCorrect achieves 26.1\% and 9.4\% CER reduction respectively, outperforming previous works by a large margin, while still enjoying fast speed of parallel generation.},
  archive   = {C_AAAI},
  author    = {Yichong Leng and Xu Tan and Wenjie Liu and Kaitao Song and Rui Wang and Xiang-Yang Li and Tao Qin and Ed Lin and Tie-Yan Liu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26531},
  pages     = {13034-13042},
  title     = {SoftCorrect: Error correction with soft detection for automatic speech recognition},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). UniSyn: An end-to-end unified model for text-to-speech and
singing voice synthesis. <em>AAAI</em>, 13025–13033. (<a
href="https://doi.org/10.1609/aaai.v37i11.26530">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Text-to-speech (TTS) and singing voice synthesis (SVS) aim at generating high-quality speaking and singing voice according to textual input and music scores, respectively. Unifying TTS and SVS into a single system is crucial to the applications requiring both of them. Existing methods usually suffer from some limitations, which rely on either both singing and speaking data from the same person or cascaded models of multiple tasks. To address these problems, a simplified elegant framework for TTS and SVS, named UniSyn, is proposed in this paper. It is an end-to-end unified model that can make a voice speak and sing with only singing or speaking data from this person. To be specific, a multi-conditional variational autoencoder (MC-VAE), which constructs two independent latent sub-spaces with the speaker- and style-related (i.e. speak or sing) conditions for flexible control, is proposed in UniSyn. Moreover, supervised guided-VAE and timbre perturbation with the Wasserstein distance constraint are leveraged to further disentangle the speaker timbre and style. Experiments conducted on two speakers and two singers demonstrate that UniSyn can generate natural speaking and singing voice without corresponding training data. The proposed approach outperforms the state-of-the-art end-to-end voice generation work, which proves the effectiveness and advantages of UniSyn.},
  archive   = {C_AAAI},
  author    = {Yi Lei and Shan Yang and Xinsheng Wang and Qicong Xie and Jixun Yao and Lei Xie and Dan Su},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26530},
  pages     = {13025-13033},
  title     = {UniSyn: An end-to-end unified model for text-to-speech and singing voice synthesis},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). LIQUID: A framework for list question answering dataset
generation. <em>AAAI</em>, 13014–13024. (<a
href="https://doi.org/10.1609/aaai.v37i11.26529">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Question answering (QA) models often rely on large-scale training datasets, which necessitates the development of a data generation framework to reduce the cost of manual annotations. Although several recent studies have aimed to generate synthetic questions with single-span answers, no study has been conducted on the creation of list questions with multiple, non-contiguous spans as answers. To address this gap, we propose LIQUID, an automated framework for generating list QA datasets from unlabeled corpora. We first convert a passage from Wikipedia or PubMed into a summary and extract named entities from the summarized text as candidate answers. This allows us to select answers that are semantically correlated in context and is, therefore, suitable for constructing list questions. We then create questions using an off-the-shelf question generator with the extracted entities and original passage. Finally, iterative filtering and answer expansion are performed to ensure the accuracy and completeness of the answers. Using our synthetic data, we significantly improve the performance of the previous best list QA models by exact-match F1 scores of 5.0 on MultiSpanQA, 1.9 on Quoref, and 2.8 averaged across three BioASQ benchmarks.},
  archive   = {C_AAAI},
  author    = {Seongyun Lee and Hyunjae Kim and Jaewoo Kang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26529},
  pages     = {13014-13024},
  title     = {LIQUID: A framework for list question answering dataset generation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Script, language, and labels: Overcoming three discrepancies
for low-resource language specialization. <em>AAAI</em>, 13004–13013.
(<a href="https://doi.org/10.1609/aaai.v37i11.26528">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Although multilingual pretrained models (mPLMs) enabled support of various natural language processing in diverse languages, its limited coverage of 100+ languages lets 6500+ languages remain ‘unseen’. One common approach for an unseen language is specializing the model for it as target, by performing additional masked language modeling (MLM) with the target language corpus. However, we argue that, due to the discrepancy from multilingual MLM pretraining, a naive specialization as such can be suboptimal. Specifically, we pose three discrepancies to overcome. Script and linguistic discrepancy of the target language from the related seen languages, hinder a positive transfer, for which we propose to maximize representation similarity, unlike existing approaches maximizing overlaps. In addition, label space for MLM prediction can vary across languages, for which we propose to reinitialize top layers for a more effective adaptation. Experiments over four different language families and three tasks shows that our method improves the task performance of unseen languages with statistical significance, while previous approach fails to.},
  archive   = {C_AAAI},
  author    = {Jaeseong Lee and Dohyeon Lee and Seung-won Hwang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26528},
  pages     = {13004-13013},
  title     = {Script, language, and labels: Overcoming three discrepancies for low-resource language specialization},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). COCA: COllaborative CAusal regularization for audio-visual
question answering. <em>AAAI</em>, 12995–13003. (<a
href="https://doi.org/10.1609/aaai.v37i11.26527">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Audio-Visual Question Answering (AVQA) is a sophisticated QA task, which aims at answering textual questions over given video-audio pairs with comprehensive multimodal reasoning. Through detailed causal-graph analyses and careful inspections of their learning processes, we reveal that AVQA models are not only prone to over-exploit prevalent language bias, but also suffer from additional joint-modal biases caused by the shortcut relations between textual-auditory/visual co-occurrences and dominated answers. In this paper, we propose a COllabrative CAusal (COCA) Regularization to remedy this more challenging issue of data biases. Specifically, a novel Bias-centered Causal Regularization (BCR) is proposed to alleviate specific shortcut biases by intervening bias-irrelevant causal effects, and further introspect the predictions of AVQA models in counterfactual and factual scenarios. Based on the fact that the dominated bias impairing model robustness for different samples tends to be different, we introduce a Multi-shortcut Collaborative Debiasing (MCD) to measure how each sample suffers from different biases, and dynamically adjust their debiasing concentration to different shortcut correlations. Extensive experiments demonstrate the effectiveness as well as backbone-agnostic ability of our COCA strategy, and it achieves state-of-the-art performance on the large-scale MUSIC-AVQA dataset.},
  archive   = {C_AAAI},
  author    = {Mingrui Lao and Nan Pu and Yu Liu and Kai He and Erwin M. Bakker and Michael S. Lew},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26527},
  pages     = {12995-13003},
  title     = {COCA: COllaborative CAusal regularization for audio-visual question answering},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Explaining (sarcastic) utterances to enhance affect
understanding in multimodal dialogues. <em>AAAI</em>, 12986–12994. (<a
href="https://doi.org/10.1609/aaai.v37i11.26526">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Conversations emerge as the primary media for exchanging ideas and conceptions. From the listener’s perspective, identifying various affective qualities, such as sarcasm, humour, and emotions, is paramount for comprehending the true connotation of the emitted utterance. However, one of the major hurdles faced in learning these affect dimensions is the presence of figurative language, viz. irony, metaphor, or sarcasm. We hypothesize that any detection system constituting the exhaustive and explicit presentation of the emitted utterance would improve the overall comprehension of the dialogue. To this end, we explore the task of Sarcasm Explanation in Dialogues, which aims to unfold the hidden irony behind sarcastic utterances. We propose MOSES, a deep neural network which takes a multimodal (sarcastic) dialogue instance as an input and generates a natural language sentence as its explanation. Subsequently, we leverage the generated explanation for various natural language understanding tasks in a conversational dialogue setup, such as sarcasm detection, humour identification, and emotion recognition. Our evaluation shows that MOSES outperforms the state-of-the-art system for SED by an average of ∼2\% on different evaluation metrics, such as ROUGE, BLEU, and METEOR. Further, we observe that leveraging the generated explanation advances three downstream tasks for affect classification – an average improvement of ~14\% F1-score in the sarcasm detection task and ∼2\% in the humour identification and emotion recognition task. We also perform extensive analyses to assess the quality of the results.},
  archive   = {C_AAAI},
  author    = {Shivani Kumar and Ishani Mondal and Md Shad Akhtar and Tanmoy Chakraborty},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26526},
  pages     = {12986-12994},
  title     = {Explaining (Sarcastic) utterances to enhance affect understanding in multimodal dialogues},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cross-modal distillation for speaker recognition.
<em>AAAI</em>, 12977–12985. (<a
href="https://doi.org/10.1609/aaai.v37i11.26525">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Speaker recognition achieved great progress recently, however, it is not easy or efficient to further improve its performance via traditional solutions: collecting more data and designing new neural networks. Aiming at the fundamental challenge of speech data, i.e. low information density, multimodal learning can mitigate this challenge by introducing richer and more discriminative information as input for identity recognition. Specifically, since the face image is more discriminative than the speech for identity recognition, we conduct multimodal learning by introducing a face recognition model (teacher) to transfer discriminative knowledge to a speaker recognition model (student) during training. However, this knowledge transfer via distillation is not trivial because the big domain gap between face and speech can easily lead to overfitting. In this work, we introduce a multimodal learning framework, VGSR (Vision-Guided Speaker Recognition). Specifically, we propose a MKD (Margin-based Knowledge Distillation) strategy for cross-modality distillation by introducing a loose constrain to align the teacher and student, greatly reducing overfitting. Our MKD strategy can easily adapt to various existing knowledge distillation methods. In addition, we propose a QAW (Quality-based Adaptive Weights) module to weight input samples via quantified data quality, leading to a robust model training. Experimental results on the VoxCeleb1 and CN-Celeb datasets show our proposed strategies can effectively improve the accuracy of speaker recognition by a margin of 10\% ∼ 15\%, and our methods are very robust to different noises.},
  archive   = {C_AAAI},
  author    = {Yufeng Jin and Guosheng Hu and Haonan Chen and Duoqian Miao and Liang Hu and Cairong Zhao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26525},
  pages     = {12977-12985},
  title     = {Cross-modal distillation for speaker recognition},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Prototypical fine-tuning: Towards robust performance under
varying data sizes. <em>AAAI</em>, 12968–12976. (<a
href="https://doi.org/10.1609/aaai.v37i11.26524">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we move towards combining large parametric models with non-parametric prototypical networks. We propose prototypical fine-tuning, a novel prototypical framework for fine-tuning pretrained language models (LM), which automatically learns a bias to improve predictive performance for varying data sizes, especially low-resource settings. Our prototypical fine-tuning approach can automatically adjust the model capacity according to the number of data points and the model&#39;s inherent attributes. Moreover, we propose four principles for effective prototype fine-tuning towards the optimal solution. Experimental results across various datasets show that our work achieves significant performance improvements under various low-resource settings, as well as comparable and usually better performances in high-resource scenarios.},
  archive   = {C_AAAI},
  author    = {Yiqiao Jin and Xiting Wang and Yaru Hao and Yizhou Sun and Xing Xie},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26524},
  pages     = {12968-12976},
  title     = {Prototypical fine-tuning: Towards robust performance under varying data sizes},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SeDepTTS: Enhancing the naturalness via semantic dependency
and local convolution for text-to-speech synthesis. <em>AAAI</em>,
12959–12967. (<a
href="https://doi.org/10.1609/aaai.v37i11.26523">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Self-attention-based networks have obtained impressive performance in parallel training and global context modeling. However, it is weak in local dependency capturing, especially for data with strong local correlations such as utterances. Therefore, we will mine linguistic information of the original text based on a semantic dependency and the semantic relationship between nodes is regarded as prior knowledge to revise the distribution of self-attention. On the other hand, given the strong correlation between input characters, we introduce a one-dimensional (1-D) convolution neural network (CNN) producing query(Q) and value(V) in the self-attention mechanism for a better fusion of local contextual information. Then, we migrate this variant of the self-attention networks to speech synthesis tasks and propose a non-autoregressive (NAR) neural Text-to-Speech (TTS): SeDepTTS. Experimental results show that our model yields good performance in speech synthesis. Specifically, the proposed method yields significant improvement for the processing of pause, stress, and intonation in speech.},
  archive   = {C_AAAI},
  author    = {Chenglong Jiang and Ying Gao and Wing W.Y. Ng and Jiyong Zhou and Jinghui Zhong and Hongzhong Zhen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26523},
  pages     = {12959-12967},
  title     = {SeDepTTS: Enhancing the naturalness via semantic dependency and local convolution for text-to-speech synthesis},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SheetPT: Spreadsheet pre-training based on hierarchical
attention network. <em>AAAI</em>, 12951–12958. (<a
href="https://doi.org/10.1609/aaai.v37i11.26522">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Spreadsheets are an important and unique type of business document for data storage, analysis and presentation. The distinction between spreadsheets and most other types of digital documents lies in that spreadsheets provide users with high flexibility of data organization on the grid. Existing related techniques mainly focus on the tabular data and are incompetent in understanding the entire sheet. On the one hand, spreadsheets have no explicit separation across tabular data and other information, leaving a gap for the deployment of such techniques. On the other hand, pervasive data dependence and semantic relations across the sheet require comprehensive modeling of all the information rather than only the tables. In this paper, we propose SheetPT, the first pre-training technique on spreadsheets to enable effective representation learning under this scenario. For computational effectiveness and efficiency, we propose the coherent chunk, an intermediate semantic unit of sheet structure; and we accordingly devise a hierarchical attention-based architecture to capture contextual information across different structural granularities. Three pre-training objectives are also designed to ensure sufficient training against millions of spreadsheets. Two representative downstream tasks, formula prediction and sheet structure recognition are utilized to evaluate its capability and the prominent results reveal its superiority over existing state-of-the-art methods.},
  archive   = {C_AAAI},
  author    = {Ran Jia and Qiyu Li and Zihan Xu and Xiaoyuan Jin and Lun Du and Haoyu Dong and Xiao Lv and Shi Han and Dongmei Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26522},
  pages     = {12951-12958},
  title     = {SheetPT: Spreadsheet pre-training based on hierarchical attention network},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). IndicSUPERB: A speech processing universal performance
benchmark for indian languages. <em>AAAI</em>, 12942–12950. (<a
href="https://doi.org/10.1609/aaai.v37i11.26521">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A cornerstone in AI research has been the creation and adoption of standardized training and test datasets to earmark the progress of state-of-the-art models. A particularly successful example is the GLUE dataset for training and evaluating Natural Language Understanding (NLU) models for English. The large body of research around self-supervised BERT-based language models revolved around performance improvements on NLU tasks in GLUE. To evaluate language models in other languages, several language-specific GLUE datasets were created. The area of speech language understanding (SLU) has followed a similar trajectory. The success of large self-supervised models such as wav2vec2 enable creation of speech models with relatively easy to access unlabelled data. These models can then be evaluated on SLU tasks, such as the SUPERB benchmark. In this work, we extend this to Indic languages by releasing the IndicSUPERB benchmark. Specifically, we make the following three contributions. (i) We collect Kathbath containing 1,684 hours of labelled speech data across 12 Indian languages from 1,218 contributors located in 203 districts in India. (ii) Using Kathbath, we create benchmarks across 6 speech tasks: Automatic Speech Recognition, Speaker Verification, Speaker Identification (mono/multi), Language Identification, Query By Example, and Keyword Spotting for 12 languages. (iii) On the released benchmarks, we train and evaluate different self-supervised models alongside the a commonly used baseline FBANK. We show that language-specific fine-tuned models are more accurate than baseline on most of the tasks, including a large gap of 76\% for Language Identification task. However, for speaker identification, self-supervised models trained on large datasets demonstrate an advantage. We hope IndicSUPERB contributes to the progress of developing speech language understanding models for Indian languages.},
  archive   = {C_AAAI},
  author    = {Tahir Javed and Kaushal Bhogale and Abhigyan Raman and Pratyush Kumar and Anoop Kunchukuttan and Mitesh M. Khapra},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26521},
  pages     = {12942-12950},
  title     = {IndicSUPERB: A speech processing universal performance benchmark for indian languages},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hierarchical text classification as sub-hierarchy sequence
generation. <em>AAAI</em>, 12933–12941. (<a
href="https://doi.org/10.1609/aaai.v37i11.26520">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Hierarchical text classification (HTC) is essential for various real applications. However, HTC models are challenging to develop because they often require processing a large volume of documents and labels with hierarchical taxonomy. Recent HTC models based on deep learning have attempted to incorporate hierarchy information into a model structure. Consequently, these models are challenging to implement when the model parameters increase for a large-scale hierarchy because the model structure depends on the hierarchy size. To solve this problem, we formulate HTC as a sub-hierarchy sequence generation to incorporate hierarchy information into a target label sequence instead of the model structure. Subsequently, we propose the Hierarchy DECoder (HiDEC), which decodes a text sequence into a sub-hierarchy sequence using recursive hierarchy decoding, classifying all parents at the same level into children at once. In addition, HiDEC is trained to use hierarchical path information from a root to each leaf in a sub-hierarchy composed of the labels of a target document via an attention mechanism and hierarchy-aware masking. HiDEC achieved state-of-the-art performance with significantly fewer model parameters than existing models on benchmark datasets, such as RCV1-v2, NYT, and EURLEX57K.},
  archive   = {C_AAAI},
  author    = {SangHun Im and GiBaeg Kim and Heung-Seon Oh and Seongung Jo and Dong Hwan Kim},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26520},
  pages     = {12933-12941},
  title     = {Hierarchical text classification as sub-hierarchy sequence generation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Question decomposition tree for answering complex questions
over knowledge bases. <em>AAAI</em>, 12924–12932. (<a
href="https://doi.org/10.1609/aaai.v37i11.26519">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Knowledge base question answering (KBQA) has attracted a lot of interest in recent years, especially for complex questions which require multiple facts to answer. Question decomposition is a promising way to answer complex questions. Existing decomposition methods split the question into sub-questions according to a single compositionality type, which is not sufficient for questions involving multiple compositionality types. In this paper, we propose Question Decomposition Tree (QDT) to represent the structure of complex questions. Inspired by recent advances in natural language generation (NLG), we present a two-staged method called Clue-Decipher to generate QDT. It can leverage the strong ability of NLG model and simultaneously preserve the original questions. To verify that QDT can enhance KBQA task, we design a decomposition-based KBQA system called QDTQA. Extensive experiments show that QDTQA outperforms previous state-of-the-art methods on ComplexWebQuestions dataset. Besides, our decomposition method improves an existing KBQA system by 12\% and sets a new state-of-the-art on LC-QuAD 1.0.},
  archive   = {C_AAAI},
  author    = {Xiang Huang and Sitao Cheng and Yiheng Shu and Yuheng Bao and Yuzhong Qu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26519},
  pages     = {12924-12932},
  title     = {Question decomposition tree for answering complex questions over knowledge bases},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Personalized dialogue generation with persona-adaptive
attention. <em>AAAI</em>, 12916–12923. (<a
href="https://doi.org/10.1609/aaai.v37i11.26518">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Persona-based dialogue systems aim to generate consistent responses based on historical context and predefined persona. Unlike conventional dialogue generation, the persona-based dialogue needs to consider both dialogue context and persona, posing a challenge for coherent training. Specifically, this requires a delicate weight balance between context and persona. To achieve that, in this paper, we propose an effective framework with Persona-Adaptive Attention (PAA), which adaptively integrates the weights from the persona and context information via our designed attention. In addition, a dynamic masking mechanism is applied to the PAA to not only drop redundant information in context and persona but also serve as a regularization mechanism to avoid overfitting. Experimental results demonstrate the superiority of the proposed PAA framework compared to the strong baselines in both automatic and human evaluation. Moreover, the proposed PAA approach can perform equivalently well in a low-resource regime compared to models trained in a full-data setting, which achieve a similar result with only 20\% to 30\% of data compared to the larger models trained in the full-data setting. To fully exploit the effectiveness of our design, we designed several variants for handling the weighted information in different ways, showing the necessity and sufficiency of our weighting and masking designs.},
  archive   = {C_AAAI},
  author    = {Qiushi Huang and Yu Zhang and Tom Ko and Xubo Liu and Bo Wu and Wenwu Wang and H Tang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26518},
  pages     = {12916-12923},
  title     = {Personalized dialogue generation with persona-adaptive attention},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SEAT: Stable and explainable attention. <em>AAAI</em>,
12907–12915. (<a
href="https://doi.org/10.1609/aaai.v37i11.26517">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Attention mechanism has become a standard fixture in many state-of-the-art natural language processing (NLP) models, not only due to its outstanding performance, but also because it provides plausible innate explanations for neural architectures. However, recent studies show that attention is unstable against randomness and perturbations during training or testing, such as random seeds and slight perturbation of embeddings, which impedes it from being a faithful explanation tool. Thus, a natural question is whether we can find an alternative to vanilla attention, which is more stable and could keep the key characteristics of the explanation. In this paper, we provide a rigorous definition of such an attention method named SEAT (Stable and Explainable ATtention). Specifically, SEAT has the following three properties: (1) Its prediction distribution is close to the prediction of the vanilla attention; (2) Its top-k indices largely overlap with those of the vanilla attention; (3) It is robust w.r.t perturbations, i.e., any slight perturbation on SEAT will not change the attention and prediction distribution too much, which implicitly indicates that it is stable to randomness and perturbations. Furthermore, we propose an optimization method for obtaining SEAT, which could be considered as revising the vanilla attention. Finally, through intensive experiments on various datasets, we compare our SEAT with other baseline methods using RNN, BiLSTM and BERT architectures, with different evaluation metrics on model interpretation, stability and accuracy. Results show that, besides preserving the original explainability and model performance, SEAT is more stable against input perturbations and training randomness, which indicates it is a more faithful explanation.},
  archive   = {C_AAAI},
  author    = {Lijie Hu and Yixin Liu and Ninghao Liu and Mengdi Huai and Lichao Sun and Di Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26517},
  pages     = {12907-12915},
  title     = {SEAT: Stable and explainable attention},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A question-answering approach to key value pair extraction
from form-like document images. <em>AAAI</em>, 12899–12906. (<a
href="https://doi.org/10.1609/aaai.v37i11.26516">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we present a new question-answering (QA) based key-value pair extraction approach, called KVPFormer, to robustly extracting key-value relationships between entities from form-like document images. Specifically, KVPFormer first identifies key entities from all entities in an image with a Transformer encoder, then takes these key entities as questions and feeds them into a Transformer decoder to predict their corresponding answers (i.e., value entities) in parallel. To achieve higher answer prediction accuracy, we propose a coarse-to-fine answer prediction approach further, which first extracts multiple answer candidates for each identified question in the coarse stage and then selects the most likely one among these candidates in the fine stage. In this way, the learning difficulty of answer prediction can be effectively reduced so that the prediction accuracy can be improved. Moreover, we introduce a spatial compatibility attention bias into the self-attention/cross-attention mechanism for KVPFormer to better model the spatial interactions between entities. With these new techniques, our proposed KVPFormer achieves state-of-the-art results on FUNSD and XFUND datasets, outperforming the previous best-performing method by 7.2\% and 13.2\% in F1 score, respectively.},
  archive   = {C_AAAI},
  author    = {Kai Hu and Zhuoyuan Wu and Zhuoyao Zhong and Weihong Lin and Lei Sun and Qiang Huo},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26516},
  pages     = {12899-12906},
  title     = {A question-answering approach to key value pair extraction from form-like document images},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A simple yet effective subsequence-enhanced approach for
cross-domain NER. <em>AAAI</em>, 12890–12898. (<a
href="https://doi.org/10.1609/aaai.v37i11.26515">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Cross-domain named entity recognition (NER), aiming to address the limitation of labeled resources in the target domain, is a challenging yet important task. Most existing studies alleviate the data discrepancy across different domains at the coarse level via combing NER with language modelings or introducing domain-adaptive pre-training (DAPT). Notably, source and target domains tend to share more fine-grained local information within denser subsequences than global information within the whole sequence, such that subsequence features are easier to transfer, which has not been explored well. Besides, compared to token-level representation, subsequence-level information can help the model distinguish different meanings of the same word in different domains. In this paper, we propose to incorporate subsequence-level features for promoting the cross-domain NER. In detail, we first utilize a pre-trained encoder to extract the global information. Then, we re-express each sentence as a group of subsequences and propose a novel bidirectional memory recurrent unit (BMRU) to capture features from the subsequences. Finally, an adaptive coupling unit (ACU) is proposed to combine global information and subsequence features for predicting entity labels. Experimental results on several benchmark datasets illustrate the effectiveness of our model, which achieves considerable improvements.},
  archive   = {C_AAAI},
  author    = {Jinpeng Hu and DanDan Guo and Yang Liu and Zhuo Li and Zhihong Chen and Xiang Wan and Tsung-Hui Chang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26515},
  pages     = {12890-12898},
  title     = {A simple yet effective subsequence-enhanced approach for cross-domain NER},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feature normalization and cartography-based demonstrations
for prompt-based fine-tuning on emotion-related tasks. <em>AAAI</em>,
12881–12889. (<a
href="https://doi.org/10.1609/aaai.v37i11.26514">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {To train a model in a traditional supervised learning classification system for natural language processing (NLP) tasks, it is essential to have labeled data, which is not present in large amounts for many tasks. Prompt-based learning methods attempt to combat the supervised learning need for labeled data by directly adapting pre-trained language models and modeling the probability of text itself. In this paper, we propose a novel data-agnostic strategy for prompt-based fine-tuning that leverages feature moments (a.k.a., mean and standard deviation) as a data augmentation technique and employs training dynamics (i.e., confidence and variability) to allow more informative samples to be concatenated for generating demonstrations as input context. Our approach is a strong method for few-shot learning that forces the language model to pay special attention to the feature moments and allows more informative samples to be concatenated for generating demonstrations as input context by selecting high confidence and low variance samples. To demonstrate its effectiveness given limited training data, we conduct extensive experiments in different few-shot settings on three empathy and emotion classification datasets (from various domains). We further evaluate our method&#39;s robustness by introducing noise to our few-shot input data and labels and show that exchanging moments between samples and incorporating cartography-based demonstrations are beneficial when the available data is limited and noisy.},
  archive   = {C_AAAI},
  author    = {Mahshid Hosseini and Cornelia Caragea},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26514},
  pages     = {12881-12889},
  title     = {Feature normalization and cartography-based demonstrations for prompt-based fine-tuning on emotion-related tasks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Competition or cooperation? Exploring unlabeled data via
challenging minimax game for semi-supervised relation extraction.
<em>AAAI</em>, 12872–12880. (<a
href="https://doi.org/10.1609/aaai.v37i11.26513">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Semi-Supervised Relation Extraction aims at learning well-performed RE models with limited labeled and large-scale unlabeled data. Existing methods mainly suffer from semantic drift and insufficient supervision, which severely limit the performance. To address these problems, recent work tends to design dual modules to work cooperatively for mutual enhancement. However, the consensus of two modules greatly restricts the model from exploring diverse relation expressions in unlabeled set, which hinders the performance as well as model generalization. To tackle this problem, in this paper, we propose a novel competition-based method AdvSRE. We set up a challenging minimax game on unlabeled data between two modules, Generator and Discriminator, and assign them with conflicting objectives. During the competition game, one module may find any possible chance to beat the other, which develops two modules&#39; abilities until relation expressions cannot be further explored. To exploit label information, Discriminator is further asked to predict specific relation for each sentence. Experiment results on two benchmarks show new state-of-the-art performance over baselines, demonstrating the effectiveness of proposed AdvSRE.},
  archive   = {C_AAAI},
  author    = {Yu Hong and Jiahang Li and Jianchuan Feng and Chenghua Huang and Zhixu Li and JIanfeng Qu and Yanghua Xiao and Wei Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26513},
  pages     = {12872-12880},
  title     = {Competition or cooperation? exploring unlabeled data via challenging minimax game for semi-supervised relation extraction},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Instance smoothed contrastive learning for unsupervised
sentence embedding. <em>AAAI</em>, 12863–12871. (<a
href="https://doi.org/10.1609/aaai.v37i11.26512">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Contrastive learning-based methods, such as unsup-SimCSE, have achieved state-of-the-art (SOTA) performances in learning unsupervised sentence embeddings. However, in previous studies, each embedding used for contrastive learning only derived from one sentence instance, and we call these embeddings instance-level embeddings. In other words, each embedding is regarded as a unique class of its own, which may hurt the generalization performance. In this study, we propose IS-CSE (instance smoothing contrastive sentence embedding) to smooth the boundaries of embeddings in the feature space. Specifically, we retrieve embeddings from a dynamic memory buffer according to the semantic similarity to get a positive embedding group. Then embeddings in the group are aggregated by a self-attention operation to produce a smoothed instance embedding for further analysis. We evaluate our method on standard semantic text similarity (STS) tasks and achieve an average of 78.30\%, 79.47\%, 77.73\%, and 79.42\% Spearman’s correlation on the base of BERT-base, BERT-large, RoBERTa-base, and RoBERTa-large respectively, a 2.05\%, 1.06\%, 1.16\% and 0.52\% improvement compared to unsup-SimCSE.},
  archive   = {C_AAAI},
  author    = {Hongliang He and Junlei Zhang and Zhenzhong Lan and Yue Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26512},
  pages     = {12863-12871},
  title     = {Instance smoothed contrastive learning for unsupervised sentence embedding},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RenewNAT: Renewing potential translation for
non-autoregressive transformer. <em>AAAI</em>, 12854–12862. (<a
href="https://doi.org/10.1609/aaai.v37i11.26511">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Non-autoregressive neural machine translation (NAT) models are proposed to accelerate the inference process while maintaining relatively high performance. However, existing NAT models are difficult to achieve the desired efficiency-quality trade-off. For one thing, fully NAT models with efficient inference perform inferior to their autoregressive counterparts. For another, iterative NAT models can, though, achieve comparable performance while diminishing the advantage of speed. In this paper, we propose RenewNAT, a flexible framework with high efficiency and effectiveness, to incorporate the merits of fully and iterative NAT models. RenewNAT first generates the potential translation results and then renews them in a single pass. It can achieve significant performance improvements at the same expense as traditional NAT models (without introducing additional model parameters and decoding latency). Experimental results on various translation benchmarks (e.g., 4 WMT) show that our framework consistently improves the performance of strong fully NAT methods (e.g., GLAT and DSLP) without additional speed overhead.},
  archive   = {C_AAAI},
  author    = {Pei Guo and Yisheng Xiao and Juntao Li and Min Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26511},
  pages     = {12854-12862},
  title     = {RenewNAT: Renewing potential translation for non-autoregressive transformer},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning to imagine: Distillation-based interactive context
exploitation for dialogue state tracking. <em>AAAI</em>, 12845–12853.
(<a href="https://doi.org/10.1609/aaai.v37i11.26510">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In dialogue state tracking (DST), the exploitation of dialogue history is a crucial research direction, and the existing DST models can be divided into two categories: full-history models and partial-history models. Since the “select first, use later” mechanism explicitly filters the distracting information being passed to the downstream state prediction, the partial-history models have recently achieved a performance advantage over the full-history models. However, besides the redundant information, some critical dialogue context information was inevitably filtered out by the partial-history models simultaneously. To reconcile the contextual consideration with avoiding the introduction of redundant information, we propose DICE-DST, a model-agnostic module widely applicable to the partial-history DST models, which aims to strengthen the ability of context exploitation for the encoder of each DST model. Specifically, we first construct a teacher encoder and devise two contextual reasoning tasks to train it to acquire extensive dialogue contextual knowledge. Then we transfer the contextual knowledge from the teacher encoder to the student encoder via a novel turn-level attention-alignment distillation. Experimental results show that our approach extensively improves the performance of partial-history DST models and thereby achieves new state-of-the-art performance on multiple mainstream datasets while keeping high efficiency.},
  archive   = {C_AAAI},
  author    = {Jinyu Guo and Kai Shuang and Kaihang Zhang and Yixuan Liu and Jijie Li and Zihan Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26510},
  pages     = {12845-12853},
  title     = {Learning to imagine: Distillation-based interactive context exploitation for dialogue state tracking},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generating coherent narratives by learning dynamic and
discrete entity states with a contrastive framework. <em>AAAI</em>,
12836–12844. (<a
href="https://doi.org/10.1609/aaai.v37i11.26509">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Despite advances in generating fluent texts, existing pretraining models tend to attach incoherent event sequences to involved entities when generating narratives such as stories and news. We conjecture that such issues result from representing entities as static embeddings of superficial words, while neglecting to model their ever-changing states, i.e., the information they carry, as the text unfolds. Therefore, we extend the Transformer model to dynamically conduct entity state updates and sentence realization for narrative generation. We propose a contrastive framework to learn the state representations in a discrete space, and insert additional attention layers into the decoder to better exploit these states. Experiments on two narrative datasets show that our model can generate more coherent and diverse narratives than strong baselines with the guidance of meaningful entity states.},
  archive   = {C_AAAI},
  author    = {Jian Guan and Zhenyu Yang and Rongsheng Zhang and Zhipeng Hu and Minlie Huang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26509},
  pages     = {12836-12844},
  title     = {Generating coherent narratives by learning dynamic and discrete entity states with a contrastive framework},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Denoising pre-training for machine translation quality
estimation with curriculum learning. <em>AAAI</em>, 12827–12835. (<a
href="https://doi.org/10.1609/aaai.v37i11.26508">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Quality estimation (QE) aims to assess the quality of machine translations when reference translations are unavailable. QE plays a crucial role in many real-world applications of machine translation. Because labeled QE data are usually limited in scale, recent research, such as DirectQE, pre-trains QE models with pseudo QE data and obtains remarkable performance. However, there tends to be inevitable noise in the pseudo data, hindering models from learning QE accurately. Our study shows that the noise mainly comes from the differences between pseudo and real translation outputs. To handle this problem, we propose CLQE, a denoising pre-training framework for QE based on curriculum learning. More specifically, we propose to measure the degree of noise in the pseudo QE data with some metrics based on statistical or distributional features. With the guidance of these metrics, CLQE gradually pre-trains the QE model using data from cleaner to noisier. Experiments on various benchmarks reveal that CLQE outperforms DirectQE and other strong baselines. We also show that with our framework, pre-training converges faster than directly using the pseudo data. We make our CLQE code available (https://github.com/NJUNLP/njuqe).},
  archive   = {C_AAAI},
  author    = {Xiang Geng and Yu Zhang and Jiahuan Li and Shujian Huang and Hao Yang and Shimin Tao and Yimeng Chen and Ning Xie and Jiajun Chen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26508},
  pages     = {12827-12835},
  title     = {Denoising pre-training for machine translation quality estimation with curriculum learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ProKD: An unsupervised prototypical knowledge distillation
network for zero-resource cross-lingual named entity recognition.
<em>AAAI</em>, 12818–12826. (<a
href="https://doi.org/10.1609/aaai.v37i11.26507">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {For named entity recognition (NER) in zero-resource languages, utilizing knowledge distillation methods to transfer language-independent knowledge from the rich-resource source languages to zero-resource languages is an effective means. Typically, these approaches adopt a teacher-student architecture, where the teacher network is trained in the source language, and the student network seeks to learn knowledge from the teacher network and is expected to perform well in the target language. Despite the impressive performance achieved by these methods, we argue that they have two limitations. Firstly, the teacher network fails to effectively learn language-independent knowledge shared across languages due to the differences in the feature distribution between the source and target languages. Secondly, the student network acquires all of its knowledge from the teacher network and ignores the learning of target language-specific knowledge. Undesirably, these limitations would hinder the model&#39;s performance in the target language. This paper proposes an unsupervised prototype knowledge distillation network (ProKD) to address these issues. Specifically, ProKD presents a contrastive learning-based prototype alignment method to achieve class feature alignment by adjusting the prototypes&#39; distance from the source and target languages, boosting the teacher network&#39;s capacity to acquire language-independent knowledge. In addition, ProKD introduces a prototype self-training method to learn the intrinsic structure of the language by retraining the student network on the target data using samples&#39; distance information from prototypes, thereby enhancing the student network&#39;s ability to acquire language-specific knowledge. Extensive experiments on three benchmark cross-lingual NER datasets demonstrate the effectiveness of our approach.},
  archive   = {C_AAAI},
  author    = {Ling Ge and Chunming Hu and Guanghui Ma and Hong Zhang and Jihong Liu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26507},
  pages     = {12818-12826},
  title     = {ProKD: An unsupervised prototypical knowledge distillation network for zero-resource cross-lingual named entity recognition},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SumREN: Summarizing reported speech about events in news.
<em>AAAI</em>, 12808–12817. (<a
href="https://doi.org/10.1609/aaai.v37i11.26506">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A primary objective of news articles is to establish the factual record for an event, frequently achieved by conveying both the details of the specified event (i.e., the 5 Ws; Who, What, Where, When and Why regarding the event) and how people reacted to it (i.e., reported statements). However, existing work on news summarization almost exclusively focuses on the event details. In this work, we propose the novel task of summarizing the reactions of different speakers, as expressed by their reported statements, to a given event. To this end, we create a new multi-document summarization benchmark, SumREN, comprising 745 summaries of reported statements from various public figures obtained from 633 news articles discussing 132 events. We propose an automatic silver-training data generation approach for our task, which helps smaller models like BART achieve GPT-3 level performance on this task. Finally, we introduce a pipeline-based framework for summarizing reported speech, which we empirically show to generate summaries that are more abstractive and factual than baseline query-focused summarization approaches.},
  archive   = {C_AAAI},
  author    = {Revanth Gangi Reddy and Heba Elfardy and Hou Pong Chan and Kevin Small and Heng Ji},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26506},
  pages     = {12808-12817},
  title     = {SumREN: Summarizing reported speech about events in news},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the effectiveness of parameter-efficient fine-tuning.
<em>AAAI</em>, 12799–12807. (<a
href="https://doi.org/10.1609/aaai.v37i11.26505">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Fine-tuning pre-trained models has been ubiquitously proven to be effective in a wide range of NLP tasks. However, fine-tuning the whole model is parameter inefficient as it always yields an entirely new model for each task. Currently, many research works propose to only fine-tune a small portion of the parameters while keeping most of the parameters shared across different tasks. These methods achieve surprisingly good performance and are shown to be more stable than their corresponding fully fine-tuned counterparts. However, such kind of methods is still not well understood. Some natural questions arise: How does the parameter sparsity lead to promising performance? Why is the model more stable than the fully fine-tuned models? How to choose the tunable parameters? In this paper, we first categorize the existing methods into random approaches, rule-based approaches, and projection-based approaches based on how they choose which parameters to tune. Then, we show that all of the methods are actually sparse fine-tuned models and conduct a novel theoretical analysis of them. We indicate that the sparsity is actually imposing a regularization on the original model by controlling the upper bound of the stability. Such stability leads to better generalization capability which has been empirically observed in a lot of recent research works. Despite the effectiveness of sparsity grounded by our theory, it still remains an open problem of how to choose the tunable parameters. Currently, the random and rule-based methods do not utilize task-specific data information while the projection-based approaches suffer from the projection discontinuity problem. To better choose the tunable parameters, we propose a novel Second-order Approximation Method (SAM) which approximates the original problem with an analytically solvable optimization function. The tunable parameters are determined by directly optimizing the approximation function. We conduct extensive experiments on several tasks. The experimental results show that our proposed SAM model outperforms many strong baseline models and it also verifies our theoretical analysis. The source code of this paper can be obtained from https://github.com/fuzihaofzh/AnalyzeParameterEff\/icientFinetune .},
  archive   = {C_AAAI},
  author    = {Zihao Fu and Haoran Yang and Anthony Man-Cho So and Wai Lam and Lidong Bing and Nigel Collier},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26505},
  pages     = {12799-12807},
  title     = {On the effectiveness of parameter-efficient fine-tuning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MIGA: A unified multi-task generation framework for
conversational text-to-SQL. <em>AAAI</em>, 12790–12798. (<a
href="https://doi.org/10.1609/aaai.v37i11.26504">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Conversational text-to-SQL is designed to translate multi-turn natural language questions into their corresponding SQL queries. Most advanced conversational text-to-SQL methods are incompatible with generative pre-trained language models (PLMs), such as T5. In this paper, we present a two-stage unified MultI-task Generation frAmework (MIGA) that leverages PLMs’ ability to tackle conversational text-to-SQL. In the pre-training stage, MIGA first decomposes the main task into several related sub-tasks and then unifies them into the same sequence-to-sequence (Seq2Seq) paradigm with task-specific natural language prompts to boost the main task from multi-task training. Later in the fine-tuning stage, we propose four SQL perturbations to alleviate the error propagation problem. MIGA tends to achieve state-of-the-art performance on two benchmarks (SparC and CoSQL). We also provide extensive analyses and discussions to shed light on some new perspectives for conversational text-to-SQL.},
  archive   = {C_AAAI},
  author    = {Yingwen Fu and Wenjie Ou and Zhou Yu and Yue Lin},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26504},
  pages     = {12790-12798},
  title     = {MIGA: A unified multi-task generation framework for conversational text-to-SQL},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cogito ergo summ: Abstractive summarization of biomedical
papers via semantic parsing graphs and consistency rewards.
<em>AAAI</em>, 12781–12789. (<a
href="https://doi.org/10.1609/aaai.v37i11.26503">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The automatic synthesis of biomedical publications catalyzes a profound research interest elicited by literature congestion. Current sequence-to-sequence models mainly rely on the lexical surface and seldom consider the deep semantic interconnections between the entities mentioned in the source document. Such superficiality translates into fabricated, poorly informative, redundant, and near-extractive summaries that severely restrict their real-world application in biomedicine, where the specialized jargon and the convoluted facts further emphasize task complexity. To fill this gap, we argue that the summarizer should acquire semantic interpretation over input, exploiting structured and unambiguous representations to capture and conserve the most relevant parts of the text content. This paper presents CogitoErgoSumm, the first framework for biomedical abstractive summarization equipping large pre-trained language models with rich semantic graphs. Precisely, we infuse graphs from two complementary semantic parsing techniques with different goals and granularities—Event Extraction and Abstract Meaning Representation, also designing a reward signal to maximize information content preservation through reinforcement learning. Extensive quantitative and qualitative evaluations on the CDSR dataset show that our solution achieves competitive performance according to multiple metrics, despite using 2.5x fewer parameters. Results and ablation studies indicate that our joint text-graph model generates more enlightening, readable, and consistent summaries. Code available at: https://github.com/disi-unibo-nlp/cogito-ergo-summ.},
  archive   = {C_AAAI},
  author    = {Giacomo Frisoni and Paolo Italiani and Stefano Salvatori and Gianluca Moro},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26503},
  pages     = {12781-12789},
  title     = {Cogito ergo summ: Abstractive summarization of biomedical papers via semantic parsing graphs and consistency rewards},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Diffuser: Efficient transformers with multi-hop attention
diffusion for long sequences. <em>AAAI</em>, 12772–12780. (<a
href="https://doi.org/10.1609/aaai.v37i11.26502">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Efficient Transformers have been developed for long sequence modeling, due to their subquadratic memory and time complexity. Sparse Transformer is a popular approach to improving the efficiency of Transformers by restricting self-attention to locations specified by the predefined sparse patterns. However, leveraging sparsity may sacrifice expressiveness compared to full-attention, when important token correlations are multiple hops away. To combine advantages of both the efficiency of sparse transformer and the expressiveness of full-attention Transformer, we propose Diffuser, a new state-of-the-art efficient Transformer. Diffuser incorporates all token interactions within one attention layer while maintaining low computation and memory costs. The key idea is to expand the receptive field of sparse attention using Attention Diffusion, which computes multi-hop token correlations based on all paths between corresponding disconnected tokens, besides attention among neighboring tokens. Theoretically, we show the expressiveness of Diffuser as a universal sequence approximator for sequence-to-sequence modeling, and investigate its ability to approximate full-attention by analyzing the graph expander property from the spectral perspective. Experimentally, we investigate the effectiveness of Diffuser with extensive evaluations, including language modeling, image modeling, and Long Range Arena (LRA). Evaluation results show that Diffuser achieves improvements by an average of 0.94\% on text classification tasks and 2.30\% on LRA, with 1.67x memory savings compared to state-of-the-art benchmarks, which demonstrates superior performance of Diffuser in both expressiveness and efficiency aspects.},
  archive   = {C_AAAI},
  author    = {Aosong Feng and Irene Li and Yuang Jiang and Rex Ying},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26502},
  pages     = {12772-12780},
  title     = {Diffuser: Efficient transformers with multi-hop attention diffusion for long sequences},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Real or fake text?: Investigating human ability to detect
boundaries between human-written and machine-generated text.
<em>AAAI</em>, 12763–12771. (<a
href="https://doi.org/10.1609/aaai.v37i11.26501">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As text generated by large language models proliferates, it becomes vital to understand how humans engage with such text, and whether or not they are able to detect when the text they are reading did not originate with a human writer. Prior work on human detection of generated text focuses on the case where an entire passage is either human-written or machine-generated. In this paper, we study a more realistic setting where text begins as human-written and transitions to being generated by state-of-the-art neural language models. We show that, while annotators often struggle at this task, there is substantial variance in annotator skill and that given proper incentives, annotators can improve at this task over time. Furthermore, we conduct a detailed comparison study and analyze how a variety of variables (model size, decoding strategy, fine-tuning, prompt genre, etc.) affect human detection performance. Finally, we collect error annotations from our participants and use them to show that certain textual genres influence models to make different types of errors and that certain sentence-level features correlate highly with annotator selection. We release the RoFT dataset: a collection of over 21,000 human annotations paired with error classifications to encourage future work in human detection and evaluation of generated text.},
  archive   = {C_AAAI},
  author    = {Liam Dugan and Daphne Ippolito and Arun Kirubarajan and Sherry Shi and Chris Callison-Burch},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26501},
  pages     = {12763-12771},
  title     = {Real or fake text?: Investigating human ability to detect boundaries between human-written and machine-generated text},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning to select from multiple options. <em>AAAI</em>,
12754–12762. (<a
href="https://doi.org/10.1609/aaai.v37i11.26500">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Many NLP tasks can be regarded as a selection problem from a set of options, such as classification tasks, multi-choice question answering, etc. Textual entailment (TE) has been shown as the state-of-the-art (SOTA) approach to dealing with those selection problems. TE treats input texts as premises (P), options as hypotheses (H), then handles the selection problem by modeling (P, H) pairwise. Two limitations: first, the pairwise modeling is unaware of other options, which is less intuitive since humans often determine the best options by comparing competing candidates; second, the inference process of pairwise TE is time-consuming, especially when the option space is large. To deal with the two issues, this work first proposes a contextualized TE model (Context-TE) by appending other k options as the context of the current (P, H) modeling. Context-TE is able to learn more reliable decision for the H since it considers various context. Second, we speed up Context-TE by coming up with Parallel-TE, which learns the decisions of multiple options simultaneously. Parallel-TE significantly improves the inference speed while keeping comparable performance with Context-TE. Our methods are evaluated on three tasks (ultra-fine entity typing, intent detection and multi-choice QA) that are typical selection problems with different sizes of options. Experiments show our models set new SOTA performance; particularly, Parallel-TE is faster than the pairwise TE by k times in inference.},
  archive   = {C_AAAI},
  author    = {Jiangshu Du and Wenpeng Yin and Congying Xia and Philip S. Yu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26500},
  pages     = {12754-12762},
  title     = {Learning to select from multiple options},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MultiSpider: Towards benchmarking multilingual text-to-SQL
semantic parsing. <em>AAAI</em>, 12745–12753. (<a
href="https://doi.org/10.1609/aaai.v37i11.26499">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Text-to-SQL semantic parsing is an important NLP task, which facilitates the interaction between users and the database. Much recent progress in text-to-SQL has been driven by large-scale datasets, but most of them are centered on English. In this work, we present MultiSpider, the largest multilingual text-to-SQL semantic parsing dataset which covers seven languages (English, German, French, Spanish, Japanese, Chinese, and Vietnamese). Upon MultiSpider we further identify the lexical and structural challenges of text-to-SQL (caused by specific language properties and dialect sayings) and their intensity across different languages. Experimental results under various settings (zero-shot, monolingual and multilingual) reveal a 6.1\% absolute drop in accuracy in non-English languages. Qualitative and quantitative analyses are conducted to understand the reason for the performance drop of each language. Besides the dataset, we also propose a simple schema augmentation framework SAVe (Schema-Augmentation-with-Verification), which significantly boosts the overall performance by about 1.8\% and closes the 29.5\% performance gap across languages.},
  archive   = {C_AAAI},
  author    = {Longxu Dou and Yan Gao and Mingyang Pan and Dingzirui Wang and Wanxiang Che and Dechen Zhan and Jian-Guang Lou},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26499},
  pages     = {12745-12753},
  title     = {MultiSpider: Towards benchmarking multilingual text-to-SQL semantic parsing},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Domain-adapted dependency parsing for cross-domain named
entity recognition. <em>AAAI</em>, 12737–12744. (<a
href="https://doi.org/10.1609/aaai.v37i11.26498">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In recent years, many researchers have leveraged structural information from dependency trees to improve Named Entity Recognition (NER). Most of their methods take dependency-tree labels as input features for NER model training. However, such dependency information is not inherently provided in most NER corpora, making the methods with low usability in practice. To effectively exploit the potential of word-dependency knowledge, motivated by the success of Multi-Task Learning on cross-domain NER, we investigate a novel NER learning method incorporating cross-domain Dependency Parsing (DP) as its auxiliary learning task. Then, considering the high consistency of word-dependency relations across domains, we present an unsupervised domain-adapted method to transfer word-dependency knowledge from high-resource domains to low-resource ones. With the help of cross-domain DP to bridge different domains, both useful cross-domain and cross-task knowledge can be learned by our model to considerably benefit cross-domain NER. To make better use of the cross-task knowledge between NER and DP, we unify both tasks in a shared network architecture for joint learning, using Maximum Mean Discrepancy(MMD). Finally, through extensive experiments, we show our proposed method can not only effectively take advantage of word-dependency knowledge, but also significantly outperform other Multi-Task Learning methods on cross-domain NER. Our code is open-source and available at https://github.com/xianghuisun/DADP.},
  archive   = {C_AAAI},
  author    = {Chenxiao Dou and Xianghui Sun and Yaoshu Wang and Yunjie Ji and Baochang Ma and Xiangang Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26498},
  pages     = {12737-12744},
  title     = {Domain-adapted dependency parsing for cross-domain named entity recognition},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving simultaneous machine translation with monolingual
data. <em>AAAI</em>, 12728–12736. (<a
href="https://doi.org/10.1609/aaai.v37i11.26497">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Simultaneous machine translation (SiMT) is usually done via sequence-level knowledge distillation (Seq-KD) from a full-sentence neural machine translation (NMT) model. However, there is still a significant performance gap between NMT and SiMT. In this work, we propose to leverage monolingual data to improve SiMT, which trains a SiMT student on the combination of bilingual data and external monolingual data distilled by Seq-KD. Preliminary experiments on En-Zh and En-Ja news domain corpora demonstrate that monolingual data can significantly improve translation quality (e.g., +3.15 BLEU on En-Zh). Inspired by the behavior of human simultaneous interpreters, we propose a novel monolingual sampling strategy for SiMT, considering both chunk length and monotonicity. Experimental results show that our sampling strategy consistently outperforms the random sampling strategy (and other conventional typical NMT monolingual sampling strategies) by avoiding the key problem of SiMT -- hallucination, and has better scalability. We achieve +0.72 BLEU improvements on average against random sampling on En-Zh and En-Ja. Data and codes can be found at https://github.com/hexuandeng/Mono4SiMT.},
  archive   = {C_AAAI},
  author    = {Hexuan Deng and Liang Ding and Xuebo Liu and Meishan Zhang and Dacheng Tao and Min Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26497},
  pages     = {12728-12736},
  title     = {Improving simultaneous machine translation with monolingual data},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural dynamic focused topic model. <em>AAAI</em>,
12719–12727. (<a
href="https://doi.org/10.1609/aaai.v37i11.26496">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Topic models and all their variants analyse text by learning meaningful representations through word co-occurrences. As pointed out by previous work, such models implicitly assume that the probability of a topic to be active and its proportion within each document are positively correlated. This correlation can be strongly detrimental in the case of documents created over time, simply because recent documents are likely better described by new and hence rare topics. In this work we leverage recent advances in neural variational inference and present an alternative neural approach to the dynamic Focused Topic Model. Indeed, we develop a neural model for topic evolution which exploits sequences of Bernoulli random variables in order to track the appearances of topics, thereby decoupling their activities from their proportions. We evaluate our model on three different datasets (the UN general debates, the collection of NeurIPS papers, and the ACL Anthology dataset) and show that it (i) outperforms state-of-the-art topic models in generalization tasks and (ii) performs comparably to them on prediction tasks, while employing roughly the same number of parameters, and converging about two times faster.},
  archive   = {C_AAAI},
  author    = {Kostadin Cvejoski and Ramsés J. Sánchez and César Ojeda},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26496},
  pages     = {12719-12727},
  title     = {Neural dynamic focused topic model},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Prompt-augmented linear probing: Scaling beyond the limit of
few-shot in-context learners. <em>AAAI</em>, 12709–12718. (<a
href="https://doi.org/10.1609/aaai.v37i11.26495">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Through in-context learning (ICL), large-scale language models are effective few-shot learners without additional model fine-tuning. However, the ICL performance does not scale well with the number of available training sample as it is limited by the inherent input length constraint of the underlying language model. Meanwhile, many studies have revealed that language models are also powerful feature extractors, allowing them to be utilized in a black-box manner and enabling the linear probing paradigm, where lightweight discriminators are trained on top of the pre-extracted input representations. This paper proposes prompt-augmented linear probing (PALP), a hybrid of linear probing and ICL, which leverages the best of both worlds. PALP inherits the scalability of linear probing and the capability of enforcing language models to derive more meaningful representations via tailoring input into a more conceivable form. Throughout in-depth investigations on various datasets, we verified that PALP significantly closes the gap between ICL in the data-hungry scenario and fine-tuning in the data-abundant scenario with little training overhead, potentially making PALP a strong alternative in a black-box scenario.},
  archive   = {C_AAAI},
  author    = {Hyunsoo Cho and Hyuhng Joon Kim and Junyeob Kim and Sang-Woo Lee and Sang-goo Lee and Kang Min Yoo and Taeuk Kim},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26495},
  pages     = {12709-12718},
  title     = {Prompt-augmented linear probing: Scaling beyond the limit of few-shot in-context learners},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Unsupervised explanation generation via correct
instantiations. <em>AAAI</em>, 12700–12708. (<a
href="https://doi.org/10.1609/aaai.v37i11.26494">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {While large pre-trained language models (PLM) have shown their great skills at solving discriminative tasks, a significant gap remains when compared with humans for explanation-related tasks. Among them, explaining the reason why a statement is wrong (e.g., against commonsense) is incredibly challenging. The major difficulty is finding the conflict point, where the statement contradicts our real world. This paper proposes Neon, a two-phrase, unsupervised explanation generation framework. Neon first generates corrected instantiations of the statement (phase I), then uses them to prompt large PLMs to find the conflict point and complete the explanation (phase II). We conduct extensive experiments on two standard explanation benchmarks, i.e., ComVE and e-SNLI. According to both automatic and human evaluations, Neon outperforms baselines, even for those with human-annotated instantiations. In addition to explaining a negative prediction, we further demonstrate that Neon remains effective when generalizing to different scenarios. The resources of Neon are available at: https://github.com/Shark-NLP/Neon.},
  archive   = {C_AAAI},
  author    = {Sijie Cheng and Zhiyong Wu and Jiangjie Chen and Zhixing Li and Yang Liu and Lingpeng Kong},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26494},
  pages     = {12700-12708},
  title     = {Unsupervised explanation generation via correct instantiations},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A scope sensitive and result attentive model for
multi-intent spoken language understanding. <em>AAAI</em>, 12691–12699.
(<a href="https://doi.org/10.1609/aaai.v37i11.26493">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-Intent Spoken Language Understanding (SLU), a novel and more complex scenario of SLU, is attracting increasing attention. Unlike traditional SLU, each intent in this scenario has its specific scope. Semantic information outside the scope even hinders the prediction, which tremendously increases the difficulty of intent detection. More seriously, guiding slot filling with these inaccurate intent labels suffers error propagation problems, resulting in unsatisfied overall performance. To solve these challenges, in this paper, we propose a novel Scope-Sensitive Result Attention Network (SSRAN) based on Transformer, which contains a Scope Recognizer (SR) and a Result Attention Network (RAN). SR assignments scope information to each token, reducing the distraction of out-of-scope tokens. RAN effectively utilizes the bidirectional interaction between SF and ID results, mitigating the error propagation problem. Experiments on two public datasets indicate that our model significantly improves SLU performance (5.4\% and 2.1\% on Overall accuracy) over the state-of-the-art baseline.},
  archive   = {C_AAAI},
  author    = {Lizhi Cheng and Wenmian Yang and Weijia Jia},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26493},
  pages     = {12691-12699},
  title     = {A scope sensitive and result attentive model for multi-intent spoken language understanding},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learn from yesterday: A semi-supervised continual learning
method for supervision-limited text-to-SQL task streams. <em>AAAI</em>,
12682–12690. (<a
href="https://doi.org/10.1609/aaai.v37i11.26492">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Conventional text-to-SQL studies are limited to a single task with a fixed-size training and test set. When confronted with a stream of tasks common in real-world applications, existing methods struggle with the problems of insufficient supervised data and high retraining costs. The former tends to cause overfitting on unseen databases for the new task, while the latter makes a full review of instances from past tasks impractical for the model, resulting in forgetting of learned SQL structures and database schemas. To address the problems, this paper proposes integrating semi-supervised learning (SSL) and continual learning (CL) in a stream of text-to-SQL tasks and offers two promising solutions in turn. The first solution Vanilla is to perform self-training, augmenting the supervised training data with predicted pseudo-labeled instances of the current task, while replacing the full volume retraining with episodic memory replay to balance the training efficiency with the performance of previous tasks. The improved solution SFNet takes advantage of the intrinsic connection between CL and SSL. It uses in-memory past information to help current SSL, while adding high-quality pseudo instances in memory to improve future replay. The experiments on two datasets shows that SFNet outperforms the widely-used SSL-only and CL-only baselines on multiple metrics.},
  archive   = {C_AAAI},
  author    = {Yongrui Chen and Xinnan Guo and Tongtong Wu and Guilin Qi and Yang Li and Yang Dong},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26492},
  pages     = {12682-12690},
  title     = {Learn from yesterday: A semi-supervised continual learning method for supervision-limited text-to-SQL task streams},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). Learning towards selective data augmentation for dialogue
generation. <em>AAAI</em>, 12673–12681. (<a
href="https://doi.org/10.1609/aaai.v37i11.26491">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As it is cumbersome and expensive to acquire a huge amount of data for training neural dialog models, data augmentation is proposed to effectively utilize existing training samples. However, current data augmentation techniques on the dialog generation task mostly augment all cases in the training dataset without considering the intrinsic attributes between different cases. We argue that not all cases are beneficial for augmentation task, and the cases suitable for augmentation should obey the following two attributes: (1) low-quality (the dialog model cannot generate a high-quality response for the case), (2) representative (the case should represent the property of the whole dataset). Herein, we explore this idea by proposing a Selective Data Augmentation framework (SDA) for the response generation task. SDA employs a dual adversarial network to select the lowest quality and most representative data points for augmentation in one stage. Extensive experiments conducted on two publicly available datasets, i.e., DailyDialog and OpenSubtitles, show that our framework can improve the response generation performance with respect to various metrics},
  archive   = {C_AAAI},
  author    = {Xiuying Chen and Mingzhe Li and Jiayi Zhang and Xiaoqiang Xia and Chen Wei and Jianwei Cui and Xin Gao and Xiangliang Zhang and Rui Yan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26491},
  pages     = {12673-12681},
  title     = {Learning towards selective data augmentation for dialogue generation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Preference-controlled multi-objective reinforcement learning
for conditional text generation. <em>AAAI</em>, 12662–12672. (<a
href="https://doi.org/10.1609/aaai.v37i11.26490">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Conditional text generation is to generate text sequences conditioning on linguistic or non-linguistic data. The main line of existing work proposed deterministic models to improve the fidelity of the generated text but often ignored the diversity. Another line relied on conditional variational auto-encoders (CVAEs), which increased the diversity over their deterministic backbones. However, CVAEs regard diversity as an implicit objective and may not be optimal. In this paper, we raise two questions: i) Can diversity be further improved with an explicit objective? ii) Since fidelity and diversity are two conflicting objectives, how can we obtain different multi-objective optimal solutions according to user preferences? To answer question i), we propose a multi-objective reinforcement learning (MORL) method which explicitly takes CIDEr and Self-CIDEr scores as the fidelity-oriented and diversity-oriented rewards respectively. To answer question ii), we propose a preference-controlled MORL method, which can obtain infinite multi-objective optimal solutions by tuning the preference variable. We conduct extensive experiments on paraphrasing and image captioning tasks, which show that in the fidelity-diversity trade-off space, our model outperforms both deterministic and CVAE-based baselines.},
  archive   = {C_AAAI},
  author    = {Wenqing Chen and Jidong Tian and Caoyun Fan and Yitian Li and Hao He and Yaohui Jin},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26490},
  pages     = {12662-12672},
  title     = {Preference-controlled multi-objective reinforcement learning for conditional text generation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). Learning to memorize entailment and discourse relations for
persona-consistent dialogues. <em>AAAI</em>, 12653–12661. (<a
href="https://doi.org/10.1609/aaai.v37i11.26489">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Maintaining engagement and consistency is particularly important in dialogue systems. Existing works have improved the performance of dialogue systems by intentionally learning interlocutor personas with sophisticated network structures. One issue with this approach is that it requires more personal corpora with annotations. Additionally, these models typically perform the next utterance prediction to generate a response but neglect the discourse coherence in the entire conversation. To address these issues, this study proposes a method of learning to memorize entailment and discourse relations for persona-consistent dialogue tasks. Entailment text pairs in natural language inference dataset were applied to learn latent entailment relations as external memories by premise-to-hypothesis generation task. Furthermore, an internal memory with a similar architecture was applied to the discourse information in the dialogue. Placing orthogonality restrictions on these two memory spaces ensures that the latent entailment relations remain dialogue-independent. Both memories collaborate to obtain entailment and discourse representation for the generation, allowing a deeper understanding of both consistency and coherence. Experiments on two large public datasets, PersonaChat and DSTC7-AVSD, demonstrated the effectiveness of the proposed method. Both automatic and human evaluations indicate that the proposed model outperforms several strong baselines in terms of both persona consistency and response coherence. Our source code is availabled at https://github.com/Chenrj233/LMEDR.},
  archive   = {C_AAAI},
  author    = {Ruijun Chen and Jin Wang and Liang-Chih Yu and Xuejie Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26489},
  pages     = {12653-12661},
  title     = {Learning to memorize entailment and discourse relations for persona-consistent dialogues},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A vector quantized approach for text to speech synthesis on
real-world spontaneous speech. <em>AAAI</em>, 12644–12652. (<a
href="https://doi.org/10.1609/aaai.v37i11.26488">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent Text-to-Speech (TTS) systems trained on reading or acted corpora have achieved near human-level naturalness. The diversity of human speech, however, often goes beyond the coverage of these corpora. We believe the ability to handle such diversity is crucial for AI systems to achieve human-level communication. Our work explores the use of more abundant real-world data for building speech synthesizers. We train TTS systems using real-world speech from YouTube and podcasts. We observe the mismatch between training and inference alignments in mel-spectrogram based autoregressive models, leading to unintelligible synthesis, and demonstrate that learned discrete codes within multiple code groups effectively resolves this issue. We introduce our MQTTS system whose architecture is designed for multiple code generation and monotonic alignment, along with the use of a clean silence prompt to improve synthesis quality. We conduct ablation analyses to identify the efficacy of our methods. We show that MQTTS outperforms existing TTS systems in several objective and subjective measures.},
  archive   = {C_AAAI},
  author    = {Li-Wei Chen and Shinji Watanabe and Alexander Rudnicky},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26488},
  pages     = {12644-12652},
  title     = {A vector quantized approach for text to speech synthesis on real-world spontaneous speech},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CP-rec: Contextual prompting for conversational recommender
systems. <em>AAAI</em>, 12635–12643. (<a
href="https://doi.org/10.1609/aaai.v37i11.26487">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The conversational recommender system (CRS) aims to provide high-quality recommendations through interactive dialogues. However, previous CRS models have no effective mechanisms for task planning and topic elaboration, and thus they hardly maintain coherence in multi-task recommendation dialogues. Inspired by recent advances in prompt-based learning, we propose a novel contextual prompting framework for dialogue management, which optimizes prompts based on context, topics, and user profiles. Specifically, we develop a topic controller to sequentially plan the subtasks, and a prompt search module to construct context-aware prompts. We further adopt external knowledge to enrich user profiles and make knowledge-aware recommendations. Incorporating these techniques, we propose a conversational recommender system with contextual prompting, namely CP-Rec. Experimental results demonstrate that it achieves state-of-the-art recommendation accuracy and generates more coherent and informative conversations.},
  archive   = {C_AAAI},
  author    = {Keyu Chen and Shiliang Sun},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26487},
  pages     = {12635-12643},
  title     = {CP-rec: Contextual prompting for conversational recommender systems},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Adversarial word dilution as text data augmentation in
low-resource regime. <em>AAAI</em>, 12626–12634. (<a
href="https://doi.org/10.1609/aaai.v37i11.26486">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Data augmentation is widely used in text classification, especially in the low-resource regime where a few examples for each class are available during training. Despite the success, generating data augmentations as hard positive examples that may increase their effectiveness is under-explored. This paper proposes an Adversarial Word Dilution (AWD) method that can generate hard positive examples as text data augmentations to train the low-resource text classification model efficiently. Our idea of augmenting the text data is to dilute the embedding of strong positive words by weighted mixing with unknown-word embedding, making the augmented inputs hard to be recognized as positive by the classification model. We adversarially learn the dilution weights through a constrained min-max optimization process with the guidance of the labels. Empirical studies on three benchmark datasets show that AWD can generate more effective data augmentations and outperform the state-of-the-art text data augmentation methods. The additional analysis demonstrates that the data augmentations generated by AWD are interpretable and can flexibly extend to new examples without further training.},
  archive   = {C_AAAI},
  author    = {Junfan Chen and Richong Zhang and Zheyan Luo and Chunming Hu and Yongyi Mao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26486},
  pages     = {12626-12634},
  title     = {Adversarial word dilution as text data augmentation in low-resource regime},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Converge to the truth: Factual error correction via
iterative constrained editing. <em>AAAI</em>, 12616–12625. (<a
href="https://doi.org/10.1609/aaai.v37i11.26485">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Given a possibly false claim sentence, how can we automatically correct it with minimal editing? Existing methods either require a large number of pairs of false and corrected claims for supervised training or do not handle well errors spanning over multiple tokens within an utterance. In this paper, we propose VENCE, a novel method for factual error correction (FEC) with minimal edits. VENCE formulates the FEC problem as iterative sampling editing actions with respect to a target density function. We carefully design the target function with predicted truthfulness scores from an offline trained fact verification model. VENCE samples the most probable editing positions based on back-calculated gradients of the truthfulness score concerning input tokens and the editing actions using a distantly-supervised language model (T5). Experiments on a public dataset show that VENCE improves the well-adopted SARI metric by 5.3 (or a relative improvement of 11.8\%) over the previous best distantly-supervised methods.},
  archive   = {C_AAAI},
  author    = {Jiangjie Chen and Rui Xu and Wenxuan Zeng and Changzhi Sun and Lei Li and Yanghua Xiao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26485},
  pages     = {12616-12625},
  title     = {Converge to the truth: Factual error correction via iterative constrained editing},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Leveraging modality-specific representations for
audio-visual speech recognition via reinforcement learning.
<em>AAAI</em>, 12607–12615. (<a
href="https://doi.org/10.1609/aaai.v37i11.26484">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Audio-visual speech recognition (AVSR) has gained remarkable success for ameliorating the noise-robustness of speech recognition. Mainstream methods focus on fusing audio and visual inputs to obtain modality-invariant representations. However, such representations are prone to over-reliance on audio modality as it is much easier to recognize than video modality in clean conditions. As a result, the AVSR model underestimates the importance of visual stream in face of noise corruption. To this end, we leverage visual modality-specific representations to provide stable complementary information for the AVSR task. Specifically, we propose a reinforcement learning (RL) based framework called MSRL, where the agent dynamically harmonizes modality-invariant and modality-specific representations in the auto-regressive decoding process. We customize a reward function directly related to task-specific metrics (i.e., word error rate), which encourages the MSRL to effectively explore the optimal integration strategy. Experimental results on the LRS3 dataset show that the proposed method achieves state-of-the-art in both clean and various noisy conditions. Furthermore, we demonstrate the better generality of MSRL system than other baselines when test set contains unseen noises.},
  archive   = {C_AAAI},
  author    = {Chen Chen and Yuchen Hu and Qiang Zhang and Heqing Zou and Beier Zhu and Eng Siong Chng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26484},
  pages     = {12607-12615},
  title     = {Leveraging modality-specific representations for audio-visual speech recognition via reinforcement learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RPA: Reasoning path augmentation in iterative retrieving for
multi-hop QA. <em>AAAI</em>, 12598–12606. (<a
href="https://doi.org/10.1609/aaai.v37i11.26483">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-hop questions are associated with a series of justifications, and one needs to obtain the answers by following the reasoning path (RP) that orders the justifications adequately. So reasoning path retrieval becomes a critical preliminary stage for multi-hop Question Answering (QA). Within the RP, two fundamental challenges emerge for better performance: (i) what the order of the justifications in the RP should be, and (ii) what if the wrong justification has been in the path. In this paper, we propose Reasoning Path Augmentation (RPA), which uses reasoning path reordering and augmentation to handle the above two challenges, respectively. Reasoning path reordering restructures the reasoning by targeting the easier justification first but difficult one later, in which the difficulty is determined by the overlap between query and justifications since the higher overlap means more lexical relevance and easier searchable. Reasoning path augmentation automatically generates artificial RPs, in which the distracted justifications are inserted to aid the model recover from the wrong justification. We build RPA with a naive pre-trained model and evaluate RPA on the QASC and MultiRC datasets. The evaluation results demonstrate that RPA outperforms previously published reasoning path retrieval methods, showing the effectiveness of the proposed methods. Moreover, we present detailed experiments on how the orders of justifications and the percent of augmented paths affect the question- answering performance, revealing the importance of polishing RPs and the necessity of augmentation.},
  archive   = {C_AAAI},
  author    = {Ziyi Cao and Bingquan Liu and Shaobo Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26483},
  pages     = {12598-12606},
  title     = {RPA: Reasoning path augmentation in iterative retrieving for multi-hop QA},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Zero-shot cross-lingual event argument extraction with
language-oriented prefix-tuning. <em>AAAI</em>, 12589–12597. (<a
href="https://doi.org/10.1609/aaai.v37i11.26482">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Event argument extraction (EAE) aims to identify the arguments of a given event, and classify the roles that those arguments play. Due to high data demands of training EAE models, zero-shot cross-lingual EAE has attracted increasing attention, as it greatly reduces human annotation effort. Some prior works indicate that generation-based methods have achieved promising performance for monolingual EAE. However, when applying existing generation-based methods to zero-shot cross-lingual EAE, we find two critical challenges, including Language Discrepancy and Template Construction. In this paper, we propose a novel method termed as Language-oriented Prefix-tuning Network (LAPIN) to address the above challenges. Specifically, we devise a Language-oriented Prefix Generator module to handle the discrepancies between source and target languages. Moreover, we leverage a Language-agnostic Template Constructor module to design templates that can be adapted to any language. Extensive experiments demonstrate that our proposed method achieves the best performance, outperforming the previous state-of-the-art model by 4.8\% and 2.3\% of the average F1-score on two multilingual EAE datasets.},
  archive   = {C_AAAI},
  author    = {Pengfei Cao and Zhuoran Jin and Yubo Chen and Kang Liu and Jun Zhao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26482},
  pages     = {12589-12597},
  title     = {Zero-shot cross-lingual event argument extraction with language-oriented prefix-tuning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-supervised logic induction for explainable fuzzy
temporal commonsense reasoning. <em>AAAI</em>, 12580–12588. (<a
href="https://doi.org/10.1609/aaai.v37i11.26481">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Understanding temporal commonsense concepts, such as times of occurrence and durations is crucial for event-centric language understanding. Reasoning about such temporal concepts in a complex context requires reasoning over both the stated context and the world knowledge that underlines it. A recent study shows massive pre-trained LM still struggle with such temporal reasoning under complex contexts (e.g., dialog) because they only implicitly encode the relevant contexts and fail to explicitly uncover the underlying logical compositions for complex inference, thus may not be robust enough. In this work, we propose to augment LMs with the temporal logic induction ability, which frames the temporal reasoning by defining three modular components: temporal dependency inducer and temporal concept defuzzifier and logic validator. The former two components disentangle the explicit/implicit dependency between temporal concepts across context (before, after, ...) and the specific meaning of fuzzy temporal concepts, respectively, while the validator combines the intermediate reasoning clues for robust contextual reasoning about the temporal concepts. Extensive experimental results on TIMEDIAL, a challenging dataset for temporal reasoning over dialog, show that our method, Logic Induction Enhanced Contextualized TEmporal Reasoning (LECTER), can yield great improvements over the traditional language model for temporal reasoning.},
  archive   = {C_AAAI},
  author    = {Bibo Cai and Xiao Ding and Zhouhao Sun and Bing Qin and Ting Liu and Baojun wang and Lifeng Shang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26481},
  pages     = {12580-12588},
  title     = {Self-supervised logic induction for explainable fuzzy temporal commonsense reasoning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). End-to-end deep reinforcement learning for conversation
disentanglement. <em>AAAI</em>, 12571–12579. (<a
href="https://doi.org/10.1609/aaai.v37i11.26480">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Collaborative Communication platforms (e.g., Slack) support multi-party conversations which contain a large number of messages on shared channels. Multiple conversations intermingle within these messages. The task of conversation disentanglement is to cluster these intermingled messages into conversations. Existing approaches are trained using loss functions that optimize only local decisions, i.e. predicting reply-to links for each message and thereby creating clusters of conversations. In this work, we propose an end-to-end reinforcement learning (RL) approach that directly optimizes a global metric. We observe that using existing global metrics such as variation of information and adjusted rand index as a reward for the RL agent deteriorates its performance. This behaviour is because these metrics completely ignore the reply-to links between messages (local decisions) during reward computation. Therefore, we propose a novel thread-level reward function that captures the global metric without ignoring the local decisions. Through experiments on the Ubuntu IRC dataset, we demonstrate that the proposed RL model improves the performance on both link-level and conversation-level metrics.},
  archive   = {C_AAAI},
  author    = {Karan Bhukar and Harshit Kumar and Dinesh Raghu and Ajay Gupta},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26480},
  pages     = {12571-12579},
  title     = {End-to-end deep reinforcement learning for conversation disentanglement},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Avocodo: Generative adversarial network for artifact-free
vocoder. <em>AAAI</em>, 12562–12570. (<a
href="https://doi.org/10.1609/aaai.v37i11.26479">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Neural vocoders based on the generative adversarial neural network (GAN) have been widely used due to their fast inference speed and lightweight networks while generating high-quality speech waveforms. Since the perceptually important speech components are primarily concentrated in the low-frequency bands, most GAN-based vocoders perform multi-scale analysis that evaluates downsampled speech waveforms. This multi-scale analysis helps the generator improve speech intelligibility. However, in preliminary experiments, we discovered that the multi-scale analysis which focuses on the low-frequency bands causes unintended artifacts, e.g., aliasing and imaging artifacts, which degrade the synthesized speech waveform quality. Therefore, in this paper, we investigate the relationship between these artifacts and GAN-based vocoders and propose a GAN-based vocoder, called Avocodo, that allows the synthesis of high-fidelity speech with reduced artifacts. We introduce two kinds of discriminators to evaluate speech waveforms in various perspectives: a collaborative multi-band discriminator and a sub-band discriminator. We also utilize a pseudo quadrature mirror filter bank to obtain downsampled multi-band speech waveforms while avoiding aliasing. According to experimental results, Avocodo outperforms baseline GAN-based vocoders, both objectively and subjectively, while reproducing speech with fewer artifacts.},
  archive   = {C_AAAI},
  author    = {Taejun Bak and Junmo Lee and Hanbin Bae and Jinhyeok Yang and Jae-Sung Bae and Young-Sun Joo},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26479},
  pages     = {12562-12570},
  title     = {Avocodo: Generative adversarial network for artifact-free vocoder},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Rich event modeling for script event prediction.
<em>AAAI</em>, 12553–12561. (<a
href="https://doi.org/10.1609/aaai.v37i11.26478">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Script is a kind of structured knowledge extracted from texts, which contains a sequence of events. Based on such knowledge, script event prediction aims to predict the subsequent event. To do so, two aspects should be considered for events, namely, event description (i.e., what the events should contain) and event encoding (i.e., how they should be encoded). Most existing methods describe an event by a verb together with a few core arguments (i.e., subject, object, and indirect object), which are not precise enough. In addition, existing event encoders are limited to a fixed number of arguments, which are not flexible enough to deal with extra information. Thus, in this paper, we propose the Rich Event Prediction (REP) framework for script event prediction. Fundamentally, it is based on the proposed rich event description, which enriches the existing ones with three kinds of important information, namely, the senses of verbs, extra semantic roles, and types of participants. REP contains an event extractor to extract such information from texts. Based on the extracted rich information, a predictor then selects the most probable subsequent event. The core component of the predictor is a transformer-based event encoder that integrates the above information flexibly. Experimental results on the widely used Gigaword Corpus show the effectiveness of the proposed framework.},
  archive   = {C_AAAI},
  author    = {Long Bai and Saiping Guan and Zixuan Li and Jiafeng Guo and Xiaolong Jin and Xueqi Cheng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26478},
  pages     = {12553-12561},
  title     = {Rich event modeling for script event prediction},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SegFormer: A topic segmentation model with controllable
range of attention. <em>AAAI</em>, 12545–12552. (<a
href="https://doi.org/10.1609/aaai.v37i11.26477">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Topic segmentation aims to reveal the latent structure of a document and divide it into multiple parts. However, current neural solutions are limited in the context modeling of sentences and feature representation of candidate boundaries. This causes the model to suffer from inefficient sentence context encoding and noise information interference. In this paper, we design a new text segmentation model SegFormer with unidirectional attention blocks to better model sentence representations. To alleviate the problem of noise information interference, SegFormer uses a novel additional context aggregator and a topic classification loss to guide the model to aggregate the information within the appropriate range. In addition, SegFormer applies an iterative prediction algorithm to search for optimal boundaries progressively. We evaluate SegFormer&#39;s generalization ability, multilingual ability, and application ability on multiple challenging real-world datasets. Experiments show that our model significantly improves the performance by 7.5\% on the benchmark WIKI-SECTION compared to several strong baselines. The application of SegFormer to a real-world dataset to separate normal and advertisement segments in product marketing essays also achieves superior performance in the evaluation with other cutting-edge models.},
  archive   = {C_AAAI},
  author    = {Haitao Bai and Pinghui Wang and Ruofei Zhang and Zhou Su},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26477},
  pages     = {12545-12552},
  title     = {SegFormer: A topic segmentation model with controllable range of attention},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Structured case-based reasoning for inference-time
adaptation of text-to-SQL parsers. <em>AAAI</em>, 12536–12544. (<a
href="https://doi.org/10.1609/aaai.v37i11.26476">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Inference-time adaptation methods for semantic parsing are useful for leveraging examples from newly-observed domains without repeated fine-tuning. Existing approaches typically bias the decoder by simply concatenating input-output example pairs (cases) from the new domain at the encoder’s input in a Seq-to-Seq model. Such methods cannot adequately leverage the structure of logical forms in the case examples. We propose StructCBR, a structured case-based reasoning approach, which leverages subtree-level similarity between logical forms of cases and candidate outputs, resulting in better decoder decisions. For the task of adapting Text-to-SQL models to unseen schemas, we show that exploiting case examples in a structured manner via StructCBR offers consistent performance improvements over prior inference-time adaptation methods across five different databases. To the best of our knowledge, we are the first to attempt inference-time adaptation of Text-to-SQL models, and harness trainable structured similarity between subqueries.},
  archive   = {C_AAAI},
  author    = {Abhijeet Awasthi and Soumen Chakrabarti and Sunita Sarawagi},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26476},
  pages     = {12536-12544},
  title     = {Structured case-based reasoning for inference-time adaptation of text-to-SQL parsers},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generalized category discovery with decoupled prototypical
network. <em>AAAI</em>, 12527–12535. (<a
href="https://doi.org/10.1609/aaai.v37i11.26475">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Generalized Category Discovery (GCD) aims to recognize both known and novel categories from a set of unlabeled data, based on another dataset labeled with only known categories. Without considering differences between known and novel categories, current methods learn about them in a coupled manner, which can hurt model&#39;s generalization and discriminative ability. Furthermore, the coupled training approach prevents these models transferring category-specific knowledge explicitly from labeled data to unlabeled data, which can lose high-level semantic information and impair model performance. To mitigate above limitations, we present a novel model called Decoupled Prototypical Network (DPN). By formulating a bipartite matching problem for category prototypes, DPN can not only decouple known and novel categories to achieve different training targets effectively, but also align known categories in labeled and unlabeled data to transfer category-specific knowledge explicitly and capture high-level semantics. Furthermore, DPN can learn more discriminative features for both known and novel categories through our proposed Semantic-aware Prototypical Learning (SPL). Besides capturing meaningful semantic information, SPL can also alleviate the noise of hard pseudo labels through semantic-weighted soft assignment. Extensive experiments show that DPN outperforms state-of-the-art models by a large margin on all evaluation metrics across multiple benchmark datasets. Code and data are available at https://github.com/Lackel/DPN.},
  archive   = {C_AAAI},
  author    = {Wenbin An and Feng Tian and Qinghua Zheng and Wei Ding and Qianying Wang and Ping Chen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i11.26475},
  pages     = {12527-12535},
  title     = {Generalized category discovery with decoupled prototypical network},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A generalized scalarization method for evolutionary
multi-objective optimization. <em>AAAI</em>, 12518–12525. (<a
href="https://doi.org/10.1609/aaai.v37i10.26474">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The decomposition-based multi-objective evolutionary algorithm (MOEA/D) transforms a multi-objective optimization problem (MOP) into a set of single-objective subproblems for collaborative optimization. Mismatches between subproblems and solutions can lead to severe performance degradation of MOEA/D. Most existing mismatch coping strategies only work when the L∞ scalarization is used. A mismatch coping strategy that can use any Lp scalarization, even when facing MOPs with non-convex Pareto fronts, is of great significance for MOEA/D. This paper uses the global replacement (GR) as the backbone. We analyze how GR can no longer avoid mismatches when L∞ is replaced by another Lp with p ∈ [1, ∞), and find that the Lp-based (1 ≤ p &lt; ∞) subproblems having inconsistently large preference regions. When p is set to a small value, some middle subproblems have very small preference regions so that their direction vectors cannot pass through their corresponding preference regions. Therefore, we propose a generalized Lp (GLp) scalarization to ensure that the subproblem’s direction vector passes through its preference region. Our theoretical analysis shows that GR can always avoid mismatches when using the GLp scalarization for any p ≥ 1. The experimental studies on various MOPs conform to the theoretical analysis.},
  archive   = {C_AAAI},
  author    = {Ruihao Zheng and Zhenkun Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26474},
  pages     = {12518-12525},
  title     = {A generalized scalarization method for evolutionary multi-objective optimization},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient gradient approximation method for constrained
bilevel optimization. <em>AAAI</em>, 12509–12517. (<a
href="https://doi.org/10.1609/aaai.v37i10.26473">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Bilevel optimization has been developed for many machine learning tasks with large-scale and high-dimensional data. This paper considers a constrained bilevel optimization problem, where the lower-level optimization problem is convex with equality and inequality constraints and the upper-level optimization problem is non-convex. The overall objective function is non-convex and non-differentiable. To solve the problem, we develop a gradient-based approach, called gradient approximation method, which determines the descent direction by computing several representative gradients of the objective function inside a neighborhood of the current estimate. We show that the algorithm asymptotically converges to the set of Clarke stationary points, and demonstrate the efficacy of the algorithm by the experiments on hyperparameter optimization and meta-learning.},
  archive   = {C_AAAI},
  author    = {Siyuan Xu and Minghui Zhu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26473},
  pages     = {12509-12517},
  title     = {Efficient gradient approximation method for constrained bilevel optimization},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improved algorithm for regret ratio minimization in
multi-objective submodular maximization. <em>AAAI</em>, 12500–12508. (<a
href="https://doi.org/10.1609/aaai.v37i10.26472">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Submodular maximization has attracted extensive attention due to its numerous applications in machine learning and artificial intelligence. Many real-world problems require maximizing multiple submodular objective functions at the same time. In such cases, a common approach is to select a representative subset of Pareto optimal solutions with different trade-offs among multiple objectives. To this end, in this paper, we investigate the regret ratio minimization (RRM) problem in multi-objective submodular maximization, which aims to find at most k solutions to best approximate all Pareto optimal solutions w.r.t. any linear combination of objective functions. We propose a novel HS-RRM algorithm by transforming RRM into HittingSet problems based on the notions of ε-kernel and δ-net, where any α-approximation algorithm for single-objective submodular maximization is used as an oracle. We improve upon the previous best-known bound on the maximum regret ratio (MRR) of the output of HS-RRM and show that the new bound is nearly asymptotically optimal for any fixed number d of objective functions. Experiments on real-world and synthetic data confirm that HS-RRM achieves lower MRRs than existing algorithms.},
  archive   = {C_AAAI},
  author    = {Yanhao Wang and Jiping Zheng and Fanxu Meng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26472},
  pages     = {12500-12508},
  title     = {Improved algorithm for regret ratio minimization in multi-objective submodular maximization},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Electrophysiological brain source imaging via combinatorial
search with provable optimality. <em>AAAI</em>, 12491–12499. (<a
href="https://doi.org/10.1609/aaai.v37i10.26471">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Electrophysiological Source Imaging (ESI) refers to reconstructing the underlying brain source activation from non-invasive Electroencephalography (EEG) and Magnetoencephalography (MEG) measurements on the scalp. Estimating the source locations and their extents is a fundamental tool in clinical and neuroscience applications. However, the estimation is challenging because of the ill-posedness and high coherence in the leadfield matrix as well as the noise in the EEG/MEG data. In this work, we proposed a combinatorial search framework to address the ESI problem with a provable optimality guarantee. Specifically, by exploiting the graph neighborhood information in the brain source space, we converted the ESI problem into a graph search problem and designed a combinatorial search algorithm under the framework of A* to solve it. The proposed algorithm is guaranteed to give an optimal solution to the ESI problem. Experimental results on both synthetic data and real epilepsy EEG data demonstrated that the proposed algorithm could faithfully reconstruct the source activation in the brain.},
  archive   = {C_AAAI},
  author    = {Guihong Wan and Meng Jiao and Xinglong Ju and Yu Zhang and Haim Schweitzer and Feng Liu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26471},
  pages     = {12491-12499},
  title     = {Electrophysiological brain source imaging via combinatorial search with provable optimality},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fully computer-assisted proofs in extremal combinatorics.
<em>AAAI</em>, 12482–12490. (<a
href="https://doi.org/10.1609/aaai.v37i10.26470">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present a fully computer-assisted proof system for solving a particular family of problems in Extremal Combinatorics. Existing techniques using Flag Algebras have proven powerful in the past, but have so far lacked a computational counterpart to derive matching constructive bounds. We demonstrate that common search heuristics are capable of finding constructions far beyond the reach of human intuition. Additionally, the most obvious downside of such heuristics, namely a missing guarantee of global optimality, can often be fully eliminated in this case through lower bounds and stability results coming from the Flag Algebra approach. To illustrate the potential of this approach, we study two related and well-known problems in Extremal Graph Theory that go back to questions of Erdős from the 60s. Most notably, we present the first major improvement in the upper bound of the Ramsey multiplicity of K_4 in 25 years, precisely determine the first off-diagonal Ramsey multiplicity number, and settle the minimum number of independent sets of size four in graphs with clique number strictly less than five.},
  archive   = {C_AAAI},
  author    = {Olaf Parczyk and Sebastian Pokutta and Christoph Spiegel and Tibor Szabó},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26470},
  pages     = {12482-12490},
  title     = {Fully computer-assisted proofs in extremal combinatorics},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Analyzing and improving the use of the FastMap embedding in
pathfinding tasks. <em>AAAI</em>, 12473–12481. (<a
href="https://doi.org/10.1609/aaai.v37i10.26469">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The FastMap algorithm has been proposed as an inexpensive metric embedding which provides admissible distance estimates between all vertices in an embedding. As an embedding, it also supports additional operations such as taking the median location of two vertices, which is important in some problems. This paper studies several aspects of FastMap embeddings, showing the relationship of FastMap to general additive heuristics. As an admissible heuristic, FastMap is not as strong as previous suggested. However, by combining FastMap with the ideas of differential heuristics, we can significantly improve the performance of FastMap heuristics. We show the impact of these ideas in both single-agent pathfinding and the Multi-Agent Meeting problem, where the performance of algorithms using our improved FastMap embedding is improved by up to a factor of two.},
  archive   = {C_AAAI},
  author    = {Reza Mashayekhi and Dor Atzmon and Nathan R. Sturtevant},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26469},
  pages     = {12473-12481},
  title     = {Analyzing and improving the use of the FastMap embedding in pathfinding tasks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). OPT-GAN: A broad-spectrum global optimizer for black-box
problems by learning distribution. <em>AAAI</em>, 12462–12472. (<a
href="https://doi.org/10.1609/aaai.v37i10.26468">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Black-box optimization (BBO) algorithms are concerned with finding the best solutions for problems with missing analytical details. Most classical methods for such problems are based on strong and fixed a priori assumptions, such as Gaussianity. However, the complex real-world problems, especially when the global optimum is desired, could be very far from the a priori assumptions because of their diversities, causing unexpected obstacles. In this study, we propose a generative adversarial net-based broad-spectrum global optimizer (OPT-GAN) which estimates the distribution of optimum gradually, with strategies to balance exploration-exploitation trade-off. It has potential to better adapt to the regularity and structure of diversified landscapes than other methods with fixed prior, e.g., Gaussian assumption or separability. Experiments on diverse BBO benchmarks and high dimensional real world applications exhibit that OPT-GAN outperforms other traditional and neural net-based BBO algorithms. The code and Appendix are available at https://github.com/NBICLAB/OPT-GAN},
  archive   = {C_AAAI},
  author    = {Minfang Lu and Shuai Ning and Shuangrong Liu and Fengyang Sun and Bo Zhang and Bo Yang and Lin Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26468},
  pages     = {12462-12472},
  title     = {OPT-GAN: A broad-spectrum global optimizer for black-box problems by learning distribution},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Human assisted learning by evolutionary multi-objective
optimization. <em>AAAI</em>, 12453–12461. (<a
href="https://doi.org/10.1609/aaai.v37i10.26467">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Machine learning models have liberated manpower greatly in many real-world tasks, but their predictions are still worse than humans on some specific instances. To improve the performance, it is natural to optimize machine learning models to take decisions for most instances while delivering a few tricky instances to humans, resulting in the problem of Human Assisted Learning (HAL). Previous works mainly formulated HAL as a constrained optimization problem that tries to find a limited subset of instances for human decision such that the sum of model and human errors can be minimized; and employed the greedy algorithms, whose performance, however, may be limited due to the greedy nature. In this paper, we propose a new framework HAL-EMO based on Evolutionary Multi-objective Optimization, which reformulates HAL as a bi-objective optimization problem that minimizes the number of selected instances for human decision and the total errors simultaneously, and employs a Multi-Objective Evolutionary Algorithm (MOEA) to solve it. We implement HAL-EMO using two MOEAs, the popular NSGA-II as well as the theoretically grounded GSEMO. We also propose a specific MOEA, called BSEMO, with biased selection and balanced mutation for HAL-EMO, and prove that for human assisted regression and classification, HAL-EMO using BSEMO can achieve better and same theoretical guarantees than previous greedy algorithms, respectively. Experiments on the tasks of medical diagnosis and content moderation show the superiority of HAL-EMO (with either NSGA-II, GSEMO or BSEMO) over previous algorithms, and that using BSEMO leads to the best performance of HAL-EMO.},
  archive   = {C_AAAI},
  author    = {Dan-Xuan Liu and Xin Mu and Chao Qian},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26467},
  pages     = {12453-12461},
  title     = {Human assisted learning by evolutionary multi-objective optimization},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Large-state reinforcement learning for hyper-heuristics.
<em>AAAI</em>, 12444–12452. (<a
href="https://doi.org/10.1609/aaai.v37i10.26466">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Hyper-heuristics are a domain-independent problem solving approach where the main task is to select effective chains of problem-specific low-level heuristics on the fly for an unseen instance. This task can be seen as a reinforcement learning problem, however, the information available to the hyper-heuristic is very limited, usually leading to very limited state representations. In this work, for the first time we use the trajectory of solution changes for a larger set of features for reinforcement learning in the novel hyper-heuristic LAST-RL (Large-State Reinforcement Learning). Further, we introduce a probability distribution for the exploration case in our epsilon-greedy policy that is based on the idea of Iterated Local Search to increase the chance to sample good chains of low-level heuristics. The benefit of the collaboration of our novel components is shown on the academic benchmark of the Cross Domain Heuristic Challenge 2011 consisting of six different problem domains. Our approach can provide state-of-the-art results on this benchmark where it outperforms recent hyper-heuristics based on reinforcement learning, and also demonstrates high performance on a benchmark of complex real-life personnel scheduling domains.},
  archive   = {C_AAAI},
  author    = {Lucas Kletzander and Nysret Musliu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26466},
  pages     = {12444-12452},
  title     = {Large-state reinforcement learning for hyper-heuristics},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TransPath: Learning heuristics for grid-based pathfinding
via transformers. <em>AAAI</em>, 12436–12443. (<a
href="https://doi.org/10.1609/aaai.v37i10.26465">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Heuristic search algorithms, e.g. A*, are the commonly used tools for pathfinding on grids, i.e. graphs of regular structure that are widely employed to represent environments in robotics, video games, etc. Instance-independent heuristics for grid graphs, e.g. Manhattan distance, do not take the obstacles into account, and thus the search led by such heuristics performs poorly in obstacle-rich environments. To this end, we suggest learning the instance-dependent heuristic proxies that are supposed to notably increase the efficiency of the search. The first heuristic proxy we suggest to learn is the correction factor, i.e. the ratio between the instance-independent cost-to-go estimate and the perfect one (computed offline at the training phase). Unlike learning the absolute values of the cost-to-go heuristic function, which was known before, learning the correction factor utilizes the knowledge of the instance-independent heuristic. The second heuristic proxy is the path probability, which indicates how likely the grid cell is lying on the shortest path. This heuristic can be employed in the Focal Search framework as the secondary heuristic, allowing us to preserve the guarantees on the bounded sub-optimality of the solution. We learn both suggested heuristics in a supervised fashion with the state-of-the-art neural networks containing attention blocks (transformers). We conduct a thorough empirical evaluation on a comprehensive dataset of planning tasks, showing that the suggested techniques i) reduce the computational effort of the A* up to a factor of 4x while producing the solutions, whose costs exceed those of the optimal solutions by less than 0.3\% on average; ii) outperform the competitors, which include the conventional techniques from the heuristic search, i.e. weighted A*, as well as the state-of-the-art learnable planners. The project web-page is: https://airi-institute.github.io/TransPath/.},
  archive   = {C_AAAI},
  author    = {Daniil Kirilenko and Anton Andreychuk and Aleksandr Panov and Konstantin Yakovlev},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26465},
  pages     = {12436-12443},
  title     = {TransPath: Learning heuristics for grid-based pathfinding via transformers},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A formal metareasoning model of concurrent planning and
execution. <em>AAAI</em>, 12427–12435. (<a
href="https://doi.org/10.1609/aaai.v37i10.26464">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Agents that plan and act in the real world must deal with the fact that time passes as they are planning. When timing is tight, there may be insufficient time to complete the search for a plan before it is time to act. By commencing execution before search concludes, one gains time to search by making planning and execution concurrent. However, this incurs the risk of making incorrect action choices, especially if actions are irreversible. This tradeoff between opportunity and risk is the problem addressed in this paper. Our main contribution is to formally define this setting as an abstract metareasoning problem. We find that the abstract problem is intractable. However, we identify special cases that are solvable in polynomial time, develop greedy solution algorithms, and, through tests on instances derived from search problems, find several methods that achieve promising practical performance. This work lays the foundation for a principled time-aware executive that concurrently plans and executes.},
  archive   = {C_AAAI},
  author    = {Amihay Elboher and Ava Bensoussan and Erez Karpas and Wheeler Ruml and Shahaf S. Shperberg and Eyal Shimony},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26464},
  pages     = {12427-12435},
  title     = {A formal metareasoning model of concurrent planning and execution},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Ultrafast euclidean shortest path computation using hub
labeling. <em>AAAI</em>, 12417–12426. (<a
href="https://doi.org/10.1609/aaai.v37i10.26463">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Finding shortest paths in a Euclidean plane containing polygonal obstacles is a well-studied problem motivated by a variety of real-world applications. The state-of-the-art algorithms require finding obstacle corners visible to the source and target, and need to consider potentially a large number of candidate paths. This adversely affects their query processing cost. We address these limitations by proposing a novel adaptation of hub labeling which is the state-of-the-art approach for shortest distance computation in road networks. Our experimental study conducted on the widely used benchmark maps shows that our approach is typically 1-2 orders of magnitude faster than two state-of-the-art algorithms.},
  archive   = {C_AAAI},
  author    = {Jinchun Du and Bojie Shen and Muhammad Aamir Cheema},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26463},
  pages     = {12417-12426},
  title     = {Ultrafast euclidean shortest path computation using hub labeling},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). From understanding the population dynamics of the NSGA-II
to the first proven lower bounds. <em>AAAI</em>, 12408–12416. (<a
href="https://doi.org/10.1609/aaai.v37i10.26462">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Due to the more complicated population dynamics of the NSGA-II, none of the existing runtime guarantees for this algorithm is accompanied by a non-trivial lower bound. Via a first mathematical understanding of the population dynamics of the NSGA-II, that is, by estimating the expected number of individuals having a certain objective value, we prove that the NSGA-II with suitable population size needs Omega(Nn log n) function evaluations to find the Pareto front of the OneMinMax problem and Omega(Nn^k) evaluations on the OneJumpZeroJump problem with jump size k. These bounds are asymptotically tight (that is, they match previously shown upper bounds) and show that the NSGA-II here does not even in terms of the parallel runtime (number of iterations) profit from larger population sizes. For the OneJumpZeroJump problem and when the same sorting is used for the computation of the crowding distance contributions of the two objectives, we even obtain a runtime estimate that is tight including the leading constant.},
  archive   = {C_AAAI},
  author    = {Benjamin Doerr and Zhongdi Qu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26462},
  pages     = {12408-12416},
  title     = {From understanding the population dynamics of the NSGA-II to the first proven lower bounds},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Runtime analysis for the NSGA-II: Provable speed-ups from
crossover. <em>AAAI</em>, 12399–12407. (<a
href="https://doi.org/10.1609/aaai.v37i10.26461">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Very recently, the first mathematical runtime analyses for the NSGA-II, the most common multi-objective evolutionary algorithm, have been conducted. Continuing this research direction, we prove that the NSGA-II optimizes the OneJumpZeroJump benchmark asymptotically faster when crossover is employed. Together with a parallel independent work by Dang, Opris, Salehi, and Sudholt, this is the first time such an advantage of crossover is proven for the NSGA-II. Our arguments can be transferred to single-objective optimization. They then prove that crossover can speed up the (mu+1) genetic algorithm in a different way and more pronounced than known before. Our experiments confirm the added value of crossover and show that the observed advantages are even larger than what our proofs can guarantee.},
  archive   = {C_AAAI},
  author    = {Benjamin Doerr and Zhongdi Qu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26461},
  pages     = {12399-12407},
  title     = {Runtime analysis for the NSGA-II: Provable speed-ups from crossover},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A proof that using crossover can guarantee exponential
speed-ups in evolutionary multi-objective optimisation. <em>AAAI</em>,
12390–12398. (<a
href="https://doi.org/10.1609/aaai.v37i10.26460">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Evolutionary algorithms are popular algorithms for multiobjective optimisation (also called Pareto optimisation) as they use a population to store trade-offs between different objectives. Despite their popularity, the theoretical foundation of multiobjective evolutionary optimisation (EMO) is still in its early development. Fundamental questions such as the benefits of the crossover operator are still not fully understood. We provide a theoretical analysis of well-known EMO algorithms GSEMO and NSGA-II to showcase the possible advantages of crossover. We propose a class of problems on which these EMO algorithms using crossover find the Pareto set in expected polynomial time. In sharp contrast, they and many other EMO algorithms without crossover require exponential time to even find a single Pareto-optimal point. This is the first example of an exponential performance gap through the use of crossover for the widely used NSGA-II algorithm.},
  archive   = {C_AAAI},
  author    = {Duc-Cuong Dang and Andre Opris and Bahare Salehi and Dirk Sudholt},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26460},
  pages     = {12390-12398},
  title     = {A proof that using crossover can guarantee exponential speed-ups in evolutionary multi-objective optimisation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Warm-starting nested rollout policy adaptation with optimal
stopping. <em>AAAI</em>, 12381–12389. (<a
href="https://doi.org/10.1609/aaai.v37i10.26459">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Nested Rollout Policy Adaptation (NRPA) is an approach using online learning policies in a nested structure. It has achieved a great result in a variety of difficult combinatorial optimization problems. In this paper, we propose Meta-NRPA, which combines optimal stopping theory with NRPA for warm-starting and significantly improves the performance of NRPA. We also present several exploratory techniques for NRPA which enable it to perform better exploration. We establish this for three notoriously difficult problems ranging from telecommunication, transportation and coding theory namely Minimum Congestion Shortest Path Routing, Traveling Salesman Problem with Time Windows and Snake-in-the-Box. We also improve the lower bounds of the Snake-in-the-Box problem for multiple dimensions.},
  archive   = {C_AAAI},
  author    = {Chen Dang and Cristina Bazgan and Tristan Cazenave and Morgan Chopin and Pierre-Henri Wuillemin},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26459},
  pages     = {12381-12389},
  title     = {Warm-starting nested rollout policy adaptation with optimal stopping},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal pathfinding on weighted grid maps. <em>AAAI</em>,
12373–12380. (<a
href="https://doi.org/10.1609/aaai.v37i10.26458">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In many computer games up to hundreds of agents navigate in real-time across a dynamically changing weighted grid map. Pathfinding in these situations is challenging because the grids are large, traversal costs are not uniform, and because each shortest path has many symmetric permutations, all of which must be considered by an optimal online search. In this work we introduce Weighted Jump Point Search (JPSW), a new type of pathfinding algorithm which breaks weighted grid symmetries by introducing a tiebreaking policy that allows us to apply effective pruning rules in symmetric regions. We show that these pruning rules preserve at least one optimal path to every grid cell and that their application can yield large performance improvements for optimal pathfinding. We give a complete theoretical description of the new algorithm, including pseudo-code. We also conduct a wide-ranging experimental evaluation, including data from real games. Results indicate JPSW is up to orders of magnitude faster than the nearest baseline, online search using A*.},
  archive   = {C_AAAI},
  author    = {Mark Carlson and Sajjad K. Moghadam and Daniel D. Harabor and Peter J. Stuckey and Morteza Ebrahimi},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26458},
  pages     = {12373-12380},
  title     = {Optimal pathfinding on weighted grid maps},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GRASMOS: Graph signage model selection for gene regulatory
networks. <em>AAAI</em>, 12364–12372. (<a
href="https://doi.org/10.1609/aaai.v37i10.26457">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Signed networks (networks with positive and negative edges) commonly arise in various domains from molecular biology to social media. The edge signs -- i.e., the graph signage -- represent the interaction pattern between the vertices and can provide insights into the underlying system formation process. Generative models considering signage formation are essential for testing hypotheses about the emergence of interactions and for creating synthetic datasets for algorithm benchmarking (especially in areas where obtaining real-world datasets is difficult). In this work, we pose a novel Maximum-Likelihood-based optimization problem for modeling signages given their topology and showcase it in the context of gene regulation. Regulatory interactions of genes play a key role in the process of organism development, and when broken can lead to serious organism abnormalities and diseases. Our contributions are threefold: First, we design a new class of signage models for a given topology, and, based on the parameter setting, we discuss its biological interpretations for gene regulatory networks (GRNs). Second, we design algorithms computing the Maximum Likelihood -- depending on the parameter setting, our algorithms range from closed-form expressions to MCMC sampling. Third, we evaluated the results of our algorithms on synthetic datasets and real-world large GRNs. Our work can lead to the prediction of unknown gene regulations, novel biological hypotheses, and realistic benchmark datasets in the realm of gene regulation.},
  archive   = {C_AAAI},
  author    = {Angelina Brilliantova and Hannah Miller and Ivona Bezáková},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26457},
  pages     = {12364-12372},
  title     = {GRASMOS: Graph signage model selection for gene regulatory networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AC-band: A combinatorial bandit-based approach to algorithm
configuration. <em>AAAI</em>, 12355–12363. (<a
href="https://doi.org/10.1609/aaai.v37i10.26456">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the algorithm configuration (AC) problem, in which one seeks to find an optimal parameter configuration of a given target algorithm in an automated way. Although this field of research has experienced much progress recently regarding approaches satisfying strong theoretical guarantees, there is still a gap between the practical performance of these approaches and the heuristic state-of-the-art approaches. Recently, there has been significant progress in designing AC approaches that satisfy strong theoretical guarantees. However, a significant gap still remains between the practical performance of these approaches and state-of-the-art heuristic methods. To this end, we introduce AC-Band, a general approach for the AC problem based on multi-armed bandits that provides theoretical guarantees while exhibiting strong practical performance. We show that AC-Band requires significantly less computation time than other AC approaches providing theoretical guarantees while still yielding high-quality configurations.},
  archive   = {C_AAAI},
  author    = {Jasmin Brandt and Elias Schede and Björn Haddenhorst and Viktor Bengs and Eyke Hüllermeier and Kevin Tierney},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26456},
  pages     = {12355-12363},
  title     = {AC-band: A combinatorial bandit-based approach to algorithm configuration},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fair short paths in vertex-colored graphs. <em>AAAI</em>,
12346–12354. (<a
href="https://doi.org/10.1609/aaai.v37i10.26455">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The computation of short paths in graphs with arc lengths is a pillar of graph algorithmics and network science. In a more diverse world, however, not every short path is equally valuable. For the setting where each vertex is assigned to a group (color), we provide a framework to model multiple natural fairness aspects. We seek to find short paths in which the number of occurrences of each color is within some given lower and upper bounds. Among other results, we prove the introduced problems to be computationally intractable (NP-hard and parameterized hard with respect to the number of colors) even in very restricted settings (such as each color should appear with exactly the same frequency), while also presenting an encouraging algorithmic result (&quot;fixed-parameter tractability&quot;) related to the length of the sought solution path for the general problem.},
  archive   = {C_AAAI},
  author    = {Matthias Bentert and Leon Kellerhals and Rolf Niedermeier},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26455},
  pages     = {12346-12354},
  title     = {Fair short paths in vertex-colored graphs},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Diversity maximization in the presence of outliers.
<em>AAAI</em>, 12338–12345. (<a
href="https://doi.org/10.1609/aaai.v37i10.26454">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Given a set X of n points in a metric space, the problem of diversity maximization is to extract a set S of k points from X so that the diversity of S is maximized. This problem is essential in AI-related fields, such as web search, databases, recommender systems, and data mining. Although there have been extensive studies of this problem, these studies assume that X is clean. This usually does not hold, because real-world datasets usually contain outliers. The state-of-the-art algorithm for the diversity maximization problem is based on furthest point retrieval, which is too sensitive to outliers. We therefore address the problem of diversity maximization with outliers and propose two algorithms with performance guarantee. The first algorithm runs in O((k+z)n) time, guarantees 1/2-approximation, and returns no outliers, where z is the number of outliers. The second algorithm runs in O(kz) time (which is independent of n), guarantees 1/6(1+epsilon)-approximation, and returns no outliers with constant probability. We conduct experiments on real datasets to demonstrate the effectiveness and efficiency of our algorithms.},
  archive   = {C_AAAI},
  author    = {Daichi Amagata},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26454},
  pages     = {12338-12345},
  title     = {Diversity maximization in the presence of outliers},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Safe interval path planning with kinodynamic constraints.
<em>AAAI</em>, 12330–12337. (<a
href="https://doi.org/10.1609/aaai.v37i10.26453">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Safe Interval Path Planning (SIPP) is a powerful algorithm for solving a single-agent pathfinding problem where the agent is confined to a graph and certain vertices/edges of this graph are blocked at certain time intervals due to dynamic obstacles that populate the environment. The original SIPP algorithm relies on the assumption that the agent is able to stop instantaneously. However, this assumption often does not hold in practice, e.g. a mobile robot moving at a cruising speed cannot stop immediately but rather requires gradual deceleration to a full stop that takes time. In other words, the robot is subject to kinodynamic constraints. Unfortunately, as we show in this work, in such a case, the original SIPP is incomplete. To this end, we introduce a novel variant of SIPP that is provably complete and optimal for planning with acceleration/deceleration. In the experimental evaluation, we show that the key property of the original SIPP still holds for the modified version: it performs much fewer expansions compared to A* and, as a result, is notably faster.},
  archive   = {C_AAAI},
  author    = {Zain Alabedeen Ali and Konstantin Yakovlev},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26453},
  pages     = {12330-12337},
  title     = {Safe interval path planning with kinodynamic constraints},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Differentially private nonlinear causal discovery from
numerical data. <em>AAAI</em>, 12321–12328. (<a
href="https://doi.org/10.1609/aaai.v37i10.26452">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, several methods such as private ANM, EM-PC and Priv-PC have been proposed to perform differentially private causal discovery in various scenarios including bivariate, multivariate Gaussian and categorical cases. However, there is little effort on how to conduct private nonlinear causal discovery from numerical data. This work tries to challenge this problem. To this end, we propose a method to infer nonlinear causal relations from observed numerical data by using regression-based conditional independence test (RCIT) that consists of kernel ridge regression (KRR) and Hilbert-Schmidt independence criterion (HSIC) with permutation approximation. Sensitivity analysis for RCIT is given and a private constraint-based causal discovery framework with differential privacy guarantee is developed. Extensive simulations and real-world experiments for both conditional independence test and causal discovery are conducted, which show that our method is effective in handling nonlinear numerical cases and easy to implement. The source code of our method and data are available at https://github.com/Causality-Inference/PCD.},
  archive   = {C_AAAI},
  author    = {Hao Zhang and Yewei Xia and Yixin Ren and Jihong Guan and Shuigeng Zhou},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26452},
  pages     = {12321-12328},
  title     = {Differentially private nonlinear causal discovery from numerical data},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient enumeration of markov equivalent DAGs.
<em>AAAI</em>, 12313–12320. (<a
href="https://doi.org/10.1609/aaai.v37i10.26451">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Enumerating the directed acyclic graphs (DAGs) of a Markov equivalence class (MEC) is an important primitive in causal analysis. The central resource from the perspective of computational complexity is the delay, that is, the time an algorithm that lists all members of the class requires between two consecutive outputs. Commonly used algorithms for this task utilize the rules proposed by Meek (1995) or the transformational characterization by Chickering (1995), both resulting in superlinear delay. In this paper, we present the first linear-time delay algorithm. On the theoretical side, we show that our algorithm can be generalized to enumerate DAGs represented by models that incorporate background knowledge, such as MPDAGs; on the practical side, we provide an efficient implementation and evaluate it in a series of experiments. Complementary to the linear-time delay algorithm, we also provide intriguing insights into Markov equivalence itself: All members of an MEC can be enumerated such that two successive DAGs have structural Hamming distance at most three.},
  archive   = {C_AAAI},
  author    = {Marcel Wienöbst and Malte Luttermann and Max Bannach and Maciej Liskiewicz},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26451},
  pages     = {12313-12320},
  title     = {Efficient enumeration of markov equivalent DAGs},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Vector causal inference between two groups of variables.
<em>AAAI</em>, 12305–12312. (<a
href="https://doi.org/10.1609/aaai.v37i10.26450">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Methods to identify cause-effect relationships currently mostly assume the variables to be scalar random variables. However, in many fields the objects of interest are vectors or groups of scalar variables. We present a new constraint-based non-parametric approach for inferring the causal relationship between two vector-valued random variables from observational data. Our method employs sparsity estimates of directed and undirected graphs and is based on two new principles for groupwise causal reasoning that we justify theoretically in Pearl&#39;s graphical model-based causality framework. Our theoretical considerations are complemented by two new causal discovery algorithms for causal interactions between two random vectors which find the correct causal direction reliably in simulations even if interactions are nonlinear. We evaluate our methods empirically and compare them to other state-of-the-art techniques.},
  archive   = {C_AAAI},
  author    = {Jonas Wahl and Urmi Ninad and Jakob Runge},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26450},
  pages     = {12305-12312},
  title     = {Vector causal inference between two groups of variables},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Lifted inference with linear order axiom. <em>AAAI</em>,
12295–12304. (<a
href="https://doi.org/10.1609/aaai.v37i10.26449">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider the task of weighted first-order model counting (WFOMC) used for probabilistic inference in the area of statistical relational learning. Given a formula φ, domain size n and a pair of weight functions, what is the weighted sum of all models of φ over a domain of size n? It was shown that computing WFOMC of any logical sentence with at most two logical variables can be done in time polynomial in n. However, it was also shown that the task is #P1-complete once we add the third variable, which inspired the search for extensions of the two-variable fragment that would still permit a running time polynomial in n. One of such extension is the two-variable fragment with counting quantifiers. In this paper, we prove that adding a linear order axiom (which forces one of the predicates in φ to introduce a linear ordering of the domain elements in each model of φ) on top of the counting quantifiers still permits a computation time polynomial in the domain size. We present a new dynamic programming-based algorithm which can compute WFOMC with linear order in time polynomial in n, thus proving our primary claim.},
  archive   = {C_AAAI},
  author    = {Jan Tóth and Ondřej Kuželka},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26449},
  pages     = {12295-12304},
  title     = {Lifted inference with linear order axiom},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Probabilities of potential outcome types in experimental
studies: Identification and estimation based on proxy covariate
information. <em>AAAI</em>, 12287–12294. (<a
href="https://doi.org/10.1609/aaai.v37i10.26448">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The concept of potential outcome types is one of the fundamental components of causal inference. However, even in randomized experiments, assumptions on the data generating process, such as monotonicity, are required to evaluate the probabilities of the potential outcome types. To solve the problem without such assumptions in experimental studies, a novel identification condition based on proxy covariate information is proposed in this paper. In addition, the estimation problem of the probabilities of the potential outcome types reduces to that of singular models when they are identifiable through the proposed condition. Thus, they cannot be evaluated by standard statistical estimation methods. To overcome this difficulty, new plug-in estimators of these probabilities are presented, and the asymptotic normality of the proposed estimators is shown.},
  archive   = {C_AAAI},
  author    = {Ryusei Shingaki and Manabu Kuroki},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26448},
  pages     = {12287-12294},
  title     = {Probabilities of potential outcome types in experimental studies: Identification and estimation based on proxy covariate information},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Certifying fairness of probabilistic circuits.
<em>AAAI</em>, 12278–12286. (<a
href="https://doi.org/10.1609/aaai.v37i10.26447">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With the increased use of machine learning systems for decision making, questions about the fairness properties of such systems start to take center stage. Most existing work on algorithmic fairness assume complete observation of features at prediction time, as is the case for popular notions like statistical parity and equal opportunity. However, this is not sufficient for models that can make predictions with partial observation as we could miss patterns of bias and incorrectly certify a model to be fair. To address this, a recently introduced notion of fairness asks whether the model exhibits any discrimination pattern, in which an individual—characterized by (partial) feature observations—receives vastly different decisions merely by disclosing one or more sensitive attributes such as gender and race. By explicitly accounting for partial observations, this provides a much more fine-grained notion of fairness. In this paper, we propose an algorithm to search for discrimination patterns in a general class of probabilistic models, namely probabilistic circuits. Previously, such algorithms were limited to naive Bayes classifiers which make strong independence assumptions; by contrast, probabilistic circuits provide a unifying framework for a wide range of tractable probabilistic models and can even be compiled from certain classes of Bayesian networks and probabilistic programs, making our method much more broadly applicable. Furthermore, for an unfair model, it may be useful to quickly find discrimination patterns and distill them for better interpretability. As such, we also propose a sampling-based approach to more efficiently mine discrimination patterns, and introduce new classes of patterns such as minimal, maximal, and Pareto optimal patterns that can effectively summarize exponentially many discrimination patterns.},
  archive   = {C_AAAI},
  author    = {Nikil Roashan Selvam and Guy Van den Broeck and YooJung Choi},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26447},
  pages     = {12278-12286},
  title     = {Certifying fairness of probabilistic circuits},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Maximizing the probability of fixation in the positional
voter model. <em>AAAI</em>, 12269–12277. (<a
href="https://doi.org/10.1609/aaai.v37i10.26446">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Voter model is a well-studied stochastic process that models the invasion of a novel trait A (e.g., a new opinion, social meme, genetic mutation, magnetic spin) in a network of individuals (agents, people, genes, particles) carrying an existing resident trait B. Individuals change traits by occasionally sampling the trait of a neighbor, while an invasion bias δ ≥ 0 expresses the stochastic preference to adopt the novel trait A over the resident trait B. The strength of an invasion is measured by the probability that eventually the whole population adopts trait A, i.e., the fixation probability. In more realistic settings, however, the invasion bias is not ubiquitous, but rather manifested only in parts of the network. For instance, when modeling the spread of a social trait, the invasion bias represents localized incentives. In this paper, we generalize the standard biased Voter model to the positional Voter model, in which the invasion bias is effectuated only on an arbitrary subset of the network nodes, called biased nodes. We study the ensuing optimization problem, which is, given a budget k, to choose k biased nodes so as to maximize the fixation probability of a randomly occurring invasion. We show that the problem is NP-hard both for finite δ and when δ → ∞ (strong bias), while the objective function is not submodular in either setting, indicating strong computational hardness. On the other hand, we show that, when δ → 0 (weak bias), we can obtain a tight approximation in O(n^2ω ) time, where ω is the matrix-multiplication exponent. We complement our theoretical results with an experimental evaluation of some proposed heuristics.},
  archive   = {C_AAAI},
  author    = {Petros Petsinis and Andreas Pavlogiannis and Panagiotis Karras},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26446},
  pages     = {12269-12277},
  title     = {Maximizing the probability of fixation in the positional voter model},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Novel ordering-based approaches for causal structure
learning in the presence of unobserved variables. <em>AAAI</em>,
12260–12268. (<a
href="https://doi.org/10.1609/aaai.v37i10.26445">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose ordering-based approaches for learning the maximal ancestral graph (MAG) of a structural equation model (SEM) up to its Markov equivalence class (MEC) in the presence of unobserved variables. Existing ordering-based methods in the literature recover a graph through learning a causal order (c-order). We advocate for a novel order called removable order (r-order) as they are advantageous over c-orders for structure learning. This is because r-orders are the minimizers of an appropriately defined optimization problem that could be either solved exactly (using a reinforcement learning approach) or approximately (using a hill-climbing search). Moreover, the r-orders (unlike c-orders) are invariant among all the graphs in a MEC and include c-orders as a subset. Given that set of r-orders is often significantly larger than the set of c-orders, it is easier for the optimization problem to find an r-order instead of a c-order. We evaluate the performance and the scalability of our proposed approaches on both real-world and randomly generated networks.},
  archive   = {C_AAAI},
  author    = {Ehsan Mokhtarian and Mohmmadsadegh Khorasani and Jalal Etesami and Negar Kiyavash},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26445},
  pages     = {12260-12268},
  title     = {Novel ordering-based approaches for causal structure learning in the presence of unobserved variables},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Out-of-distribution generalization by neural-symbolic joint
training. <em>AAAI</em>, 12252–12259. (<a
href="https://doi.org/10.1609/aaai.v37i10.26444">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper develops a novel methodology to simultaneously learn a neural network and extract generalized logic rules. Different from prior neural-symbolic methods that require background knowledge and candidate logical rules to be provided, we aim to induce task semantics with minimal priors. This is achieved by a two-step learning framework that iterates between optimizing neural predictions of task labels and searching for a more accurate representation of the hidden task semantics. Notably, supervision works in both directions: (partially) induced task semantics guide the learning of the neural network and induced neural predictions admit an improved semantic representation. We demonstrate that our proposed framework is capable of achieving superior out-of-distribution generalization performance on two tasks: (i) learning multi-digit addition, where it is trained on short sequences of digits and tested on long sequences of digits; (ii) predicting the optimal action in the Tower of Hanoi, where the model is challenged to discover a policy independent of the number of disks in the puzzle.},
  archive   = {C_AAAI},
  author    = {Anji Liu and Hongming Xu and Guy Van den Broeck and Yitao Liang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26444},
  pages     = {12252-12259},
  title     = {Out-of-distribution generalization by neural-symbolic joint training},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Computing divergences between discrete decomposable models.
<em>AAAI</em>, 12243–12251. (<a
href="https://doi.org/10.1609/aaai.v37i10.26443">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {There are many applications that benefit from computing the exact divergence between 2 discrete probability measures, including machine learning. Unfortunately, in the absence of any assumptions on the structure or independencies within these distributions, computing the divergence between them is an intractable problem in high dimensions. We show that we are able to compute a wide family of functionals and divergences, such as the alpha-beta divergence, between two decomposable models, i.e. chordal Markov networks, in time exponential to the treewidth of these models. The alpha-beta divergence is a family of divergences that include popular divergences such as the Kullback-Leibler divergence, the Hellinger distance, and the chi-squared divergence. Thus, we can accurately compute the exact values of any of this broad class of divergences to the extent to which we can accurately model the two distributions using decomposable models.},
  archive   = {C_AAAI},
  author    = {Loong Kuan Lee and Nico Piatkowski and François Petitjean and Geoffrey I. Webb},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26443},
  pages     = {12243-12251},
  title     = {Computing divergences between discrete decomposable models},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Identification and estimation of the probabilities of
potential outcome types using covariate information in studies with
non-compliance. <em>AAAI</em>, 12234–12242. (<a
href="https://doi.org/10.1609/aaai.v37i10.26442">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose novel identification conditions and a statistical estimation method for the probabilities of potential outcome types using covariate information in randomized trials in which the treatment assignment is randomized but subject compliance is not perfect. Different from existing studies, the proposed identification conditions do not require strict assumptions such as the assumption of monotonicity. When the probabilities of potential outcome types are identifiable through the proposed conditions, the problem of estimating the probabilities of potential outcome types is reduced to that of singular models. Thus, the probabilities cannot be evaluated using standard statistical likelihood-based estimation methods. Rather, the proposed identification conditions show that we can derive consistent estimators of the probabilities of potential outcome types via the method of moments, which leads to the asymptotic normality of the proposed estimators through the delta method under regular conditions. We also propose a new statistical estimation method based on the bounded constrained augmented Lagrangian method to derive more efficient estimators than can be derived through the method of moments.},
  archive   = {C_AAAI},
  author    = {Yuta Kawakami and Ryusei Shingaki and Manabu Kuroki},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26442},
  pages     = {12234-12242},
  title     = {Identification and estimation of the probabilities of potential outcome types using covariate information in studies with non-compliance},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural diffeomorphic non-uniform b-spline flows.
<em>AAAI</em>, 12225–12233. (<a
href="https://doi.org/10.1609/aaai.v37i10.26441">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Normalizing flows have been successfully modeling a complex probability distribution as an invertible transformation of a simple base distribution. However, there are often applications that require more than invertibility. For instance, the computation of energies and forces in physics requires the second derivatives of the transformation to be well-defined and continuous. Smooth normalizing flows employ infinitely differentiable transformation, but with the price of slow non-analytic inverse transforms. In this work, we propose diffeomorphic non-uniform B-spline flows that are at least twice continuously differentiable while bi-Lipschitz continuous, enabling efficient parametrization while retaining analytic inverse transforms based on a sufficient condition for diffeomorphism. Firstly, we investigate the sufficient condition for C(k-2)-diffeomorphic non-uniform kth-order B-spline transformations. Then, we derive an analytic inverse transformation of the non-uniform cubic B-spline transformation for neural diffeomorphic non-uniform B-spline flows. Lastly, we performed experiments on solving the force matching problem in Boltzmann generators, demonstrating that our C2-diffeomorphic non-uniform B-spline flows yielded solutions better than previous spline flows and faster than smooth normalizing flows. Our source code is publicly available at https://github.com/smhongok/Non-uniform-B-spline-Flow.},
  archive   = {C_AAAI},
  author    = {Seongmin Hong and Se Young Chun},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26441},
  pages     = {12225-12233},
  title     = {Neural diffeomorphic non-uniform B-spline flows},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A faster practical approximation scheme for the permanent.
<em>AAAI</em>, 12216–12224. (<a
href="https://doi.org/10.1609/aaai.v37i10.26440">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The permanent of a matrix has numerous applications but is notoriously hard to compute. While nonnegative matrices admit polynomial approximation schemes based on rapidly mixing Markov chains, the known practical estimators of the permanent rely on importance or rejection sampling. We advance the rejection sampling approach, which provides probabilistic accuracy guarantees, unlike importance sampling. Specifically, we give a novel class of nesting upper bounds and a simple preprocessing method that, in comparison to previous works, enable faster sampling with better acceptance rate; we demonstrate order-of-magnitude improvements with both theoretical and empirical analyses. In addition, we display instances on which our approximation scheme is competitive against state-of-the-art importance sampling based estimators.},
  archive   = {C_AAAI},
  author    = {Juha Harviainen and Mikko Koivisto},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26440},
  pages     = {12216-12224},
  title     = {A faster practical approximation scheme for the permanent},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Principled and efficient motif finding for structure
learning of lifted graphical models. <em>AAAI</em>, 12205–12215. (<a
href="https://doi.org/10.1609/aaai.v37i10.26439">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Structure learning is a core problem in AI central to the fields of neuro-symbolic AI and statistical relational learning. It consists in automatically learning a logical theory from data. The basis for structure learning is mining repeating patterns in the data, known as structural motifs. Finding these patterns reduces the exponential search space and therefore guides the learning of formulas. Despite the importance of motif learning, it is still not well understood. We present the first principled approach for mining structural motifs in lifted graphical models, languages that blend first-order logic with probabilistic models, which uses a stochastic process to measure the similarity of entities in the data. Our first contribution is an algorithm, which depends on two intuitive hyperparameters: one controlling the uncertainty in the entity similarity measure, and one controlling the softness of the resulting rules. Our second contribution is a preprocessing step where we perform hierarchical clustering on the data to reduce the search space to the most relevant data. Our third contribution is to introduce an O(n ln(n)) (in the size of the entities in the data) algorithm for clustering structurally-related data. We evaluate our approach using standard benchmarks and show that we outperform state-of-the-art structure learning approaches by up to 6\% in terms of accuracy and up to 80\% in terms of runtime.},
  archive   = {C_AAAI},
  author    = {Jonathan Feldstein and Dominic Phillips and Efthymia Tsamoura},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26439},
  pages     = {12205-12215},
  title     = {Principled and efficient motif finding for structure learning of lifted graphical models},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Entropy regularization for population estimation.
<em>AAAI</em>, 12198–12204. (<a
href="https://doi.org/10.1609/aaai.v37i10.26438">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Entropy regularization is known to improve exploration in sequential decision-making problems. We show that this same mechanism can also lead to nearly unbiased and lower-variance estimates of the mean reward in the optimize-and-estimate structured bandit setting. Mean reward estimation (i.e., population estimation) tasks have recently been shown to be essential for public policy settings where legal constraints often require precise estimates of population metrics. We show that leveraging entropy and KL divergence can yield a better trade-off between reward and estimator variance than existing baselines, all while remaining nearly unbiased. These properties of entropy regularization illustrate an exciting potential for bringing together the optimal exploration and estimation literature.},
  archive   = {C_AAAI},
  author    = {Ben Chugg and Peter Henderson and Jacob Goldin and Daniel E. Ho},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26438},
  pages     = {12198-12204},
  title     = {Entropy regularization for population estimation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Score-based learning of graphical event models with
background knowledge augmentation. <em>AAAI</em>, 12189–12197. (<a
href="https://doi.org/10.1609/aaai.v37i10.26437">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graphical event models (GEMs) are representations of temporal point process dynamics between different event types. Many real-world applications however involve limited event stream data, making it challenging to learn GEMs from data alone. In this paper, we introduce approaches that can work together in a score-based learning paradigm, to augment data with potentially different types of background knowledge. We propose novel scores for learning an important parametric class of GEMs; in particular, we propose a Bayesian score for leveraging prior information as well as a more practical simplification that involves fewer parameters, analogous to Bayesian networks. We also introduce a framework for incorporating easily assessed qualitative background knowledge from domain experts, in the form of statements such as `event X depends on event Y&#39; or `event Y makes event X more likely&#39;. The proposed framework has Bayesian interpretations and can be deployed by any score-based learner. Through an extensive empirical investigation, we demonstrate the practical benefits of background knowledge augmentation while learning GEMs for applications in the low-data regime.},
  archive   = {C_AAAI},
  author    = {Debarun Bhattacharjya and Tian Gao and Dharmashankar Subramanian and Xiao Shou},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26437},
  pages     = {12189-12197},
  title     = {Score-based learning of graphical event models with background knowledge augmentation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A simple unified approach to testing high-dimensional
conditional independences for categorical and ordinal data.
<em>AAAI</em>, 12180–12188. (<a
href="https://doi.org/10.1609/aaai.v37i10.26436">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Conditional independence (CI) tests underlie many approaches to model testing and structure learning in causal inference. Most existing CI tests for categorical and ordinal data stratify the sample by the conditioning variables, perform simple independence tests in each stratum, and combine the results. Unfortunately, the statistical power of this approach degrades rapidly as the number of conditioning variables increases. Here we propose a simple unified CI test for ordinal and categorical data that maintains reasonable calibration and power in high dimensions. We show that our test outperforms existing baselines in model testing and structure learning for dense directed graphical models while being comparable for sparse models. Our approach could be attractive for causal model testing because it is easy to implement, can be used with non-parametric or parametric probability models, has the symmetry property, and has reasonable computational requirements.},
  archive   = {C_AAAI},
  author    = {Ankur Ankan and Johannes Textor},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26436},
  pages     = {12180-12188},
  title     = {A simple unified approach to testing high-dimensional conditional independences for categorical and ordinal data},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Causal effect identification in cluster DAGs. <em>AAAI</em>,
12172–12179. (<a
href="https://doi.org/10.1609/aaai.v37i10.26435">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Reasoning about the effect of interventions and counterfactuals is a fundamental task found throughout the data sciences. A collection of principles, algorithms, and tools has been developed for performing such tasks in the last decades. One of the pervasive requirements found throughout this literature is the articulation of assumptions, which commonly appear in the form of causal diagrams. Despite the power of this approach, there are significant settings where the knowledge necessary to specify a causal diagram over all variables is not available, particularly in complex, high-dimensional domains. In this paper, we introduce a new graphical modeling tool called cluster DAGs (for short, C-DAGs) that allows for the partial specification of relationships among variables based on limited prior knowledge, alleviating the stringent requirement of specifying a full causal diagram. A C-DAG specifies relationships between clusters of variables, while the relationships between the variables within a cluster are left unspecified, and can be seen as a graphical representation of an equivalence class of causal diagrams that share the relationships among the clusters. We develop the foundations and machinery for valid inferences over C-DAGs about the clusters of variables at each layer of Pearl&#39;s Causal Hierarchy - L1 (probabilistic), L2 (interventional), and L3 (counterfactual). In particular, we prove the soundness and completeness of d-separation for probabilistic inference in C-DAGs. Further, we demonstrate the validity of Pearl&#39;s do-calculus rules over C-DAGs and show that the standard ID identification algorithm is sound and complete to systematically compute causal effects from observational data given a C-DAG. Finally, we show that C-DAGs are valid for performing counterfactual inferences about clusters of variables.},
  archive   = {C_AAAI},
  author    = {Tara V. Anand and Adele H. Ribeiro and Jin Tian and Elias Bareinboim},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26435},
  pages     = {12172-12179},
  title     = {Causal effect identification in cluster DAGs},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning relational causal models with cycles through
relational acyclification. <em>AAAI</em>, 12164–12171. (<a
href="https://doi.org/10.1609/aaai.v37i10.26434">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In real-world phenomena which involve mutual influence or causal effects between interconnected units, equilibrium states are typically represented with cycles in graphical models. An expressive class of graphical models, relational causal models, can represent and reason about complex dynamic systems exhibiting such cycles or feedback loops. Existing cyclic causal discovery algorithms for learning causal models from observational data assume that the data instances are independent and identically distributed which makes them unsuitable for relational causal models. At the same time, causal discovery algorithms for relational causal models assume acyclicity. In this work, we examine the necessary and sufficient conditions under which a constraint-based relational causal discovery algorithm is sound and complete for cyclic relational causal models. We introduce relational acyclification, an operation specifically designed for relational models that enables reasoning about the identifiability of cyclic relational causal models. We show that under the assumptions of relational acyclification and sigma-faithfulness, the relational causal discovery algorithm RCD is sound and complete for cyclic relational models. We present experimental results to support our claim.},
  archive   = {C_AAAI},
  author    = {Ragib Ahsan and David Arbour and Elena Zheleva},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26434},
  pages     = {12164-12171},
  title     = {Learning relational causal models with cycles through relational acyclification},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The linear distance traveling tournament problem allows an
EPTAS. <em>AAAI</em>, 12155–12162. (<a
href="https://doi.org/10.1609/aaai.v37i10.26433">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Traveling Tournament Problem (TTP-k) is a well-known benchmark problem in tournament timetabling and has been extensively studied in the field of AI. In this problem, we are going to design a double round-robin schedule such that each pair of teams plays one game in each other&#39;s home venue, minimizing the total distance traveled by all n teams (n is even) under the constraint that each team can have at most k-consecutive home games or away games. The Linear Distance Traveling Tournament Problem (LDTTP-k), where all teams are located on a line, was introduced by Hoshino and Kawarabayashi (AAAI 2012). For LDTTP-3, they gave a 4/3-approximation algorithm for n≡4 (mod 6) teams. In this paper, we show that for any 3≤k=o(∛n), LDTTP-k allows an efficient polynomial-time approximation scheme (EPTAS).},
  archive   = {C_AAAI},
  author    = {Jingyang Zhao and Mingyu Xiao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26433},
  pages     = {12155-12162},
  title     = {The linear distance traveling tournament problem allows an EPTAS},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural TSP solver with progressive distillation.
<em>AAAI</em>, 12147–12154. (<a
href="https://doi.org/10.1609/aaai.v37i10.26432">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Travelling salesman problem (TSP) is NP-Hard with exponential search space. Recently, the adoption of encoder-decoder models as neural TSP solvers has emerged as an attractive topic because they can instantly obtain near-optimal results for small-scale instances. Nevertheless, their training efficiency and solution quality degrade dramatically when dealing with large-scale problems. To address the issue, we propose a novel progressive distillation framework, by adopting curriculum learning to train TSP samples in increasing order of their problem size and progressively distilling high-level knowledge from small models to large models via a distillation loss. In other words, the trained small models are used as the teacher network to guide action selection when training large models. To accelerate training speed, we also propose a Delaunary-graph based action mask and a new attention-based decoder to reduce decoding cost. Experimental results show that our approach establishes clear advantages over existing encoder-decoder models in terms of training effectiveness and solution quality. In addition, we validate its usefulness as an initial solution generator for the state-of-the-art TSP solvers, whose probability of obtaining the optimal solution can be further improved in such a hybrid manner.},
  archive   = {C_AAAI},
  author    = {Dongxiang Zhang and Ziyang Xiao and Yuan Wang and Mingli Song and Gang Chen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26432},
  pages     = {12147-12154},
  title     = {Neural TSP solver with progressive distillation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Scalable decision-focused learning in restless multi-armed
bandits with application to maternal and child health. <em>AAAI</em>,
12138–12146. (<a
href="https://doi.org/10.1609/aaai.v37i10.26431">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper studies restless multi-armed bandit (RMAB) problems with unknown arm transition dynamics but with known correlated arm features. The goal is to learn a model to predict transition dynamics given features, where the Whittle index policy solves the RMAB problems using predicted transitions. However, prior works often learn the model by maximizing the predictive accuracy instead of final RMAB solution quality, causing a mismatch between training and evaluation objectives. To address this shortcoming, we propose a novel approach for decision-focused learning in RMAB that directly trains the predictive model to maximize the Whittle index solution quality. We present three key contributions: (i) we establish differentiability of the Whittle index policy to support decision-focused learning; (ii) we significantly improve the scalability of decision-focused learning approaches in sequential problems, specifically RMAB problems; (iii) we apply our algorithm to a previously collected dataset of maternal and child health to demonstrate its performance. Indeed, our algorithm is the first for decision-focused learning in RMAB that scales to real-world problem sizes.},
  archive   = {C_AAAI},
  author    = {Kai Wang and Shresth Verma and Aditya Mate and Sanket Shah and Aparna Taneja and Neha Madhiwalla and Aparna Hegde and Milind Tambe},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26431},
  pages     = {12138-12146},
  title     = {Scalable decision-focused learning in restless multi-armed bandits with application to maternal and child health},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Smoothed online combinatorial optimization using imperfect
predictions. <em>AAAI</em>, 12130–12137. (<a
href="https://doi.org/10.1609/aaai.v37i10.26430">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Smoothed online combinatorial optimization considers a learner who repeatedly chooses a combinatorial decision to minimize an unknown changing cost function with a penalty on switching decisions in consecutive rounds. We study smoothed online combinatorial optimization problems when an imperfect predictive model is available, where the model can forecast the future cost functions with uncertainty. We show that using predictions to plan for a finite time horizon leads to regret dependent on the total predictive uncertainty and an additional switching cost. This observation suggests choosing a suitable planning window to balance between uncertainty and switching cost, which leads to an online algorithm with guarantees on the upper and lower bounds of the cumulative regret. Empirically, our algorithm shows a significant improvement in cumulative regret compared to other baselines in synthetic online distributed streaming problems.},
  archive   = {C_AAAI},
  author    = {Kai Wang and Zhao Song and Georgios Theocharous and Sridhar Mahadevan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26430},
  pages     = {12130-12137},
  title     = {Smoothed online combinatorial optimization using imperfect predictions},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Predicate invention for bilevel planning. <em>AAAI</em>,
12120–12129. (<a
href="https://doi.org/10.1609/aaai.v37i10.26429">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Efficient planning in continuous state and action spaces is fundamentally hard, even when the transition model is deterministic and known. One way to alleviate this challenge is to perform bilevel planning with abstractions, where a high-level search for abstract plans is used to guide planning in the original transition space. Previous work has shown that when state abstractions in the form of symbolic predicates are hand-designed, operators and samplers for bilevel planning can be learned from demonstrations. In this work, we propose an algorithm for learning predicates from demonstrations, eliminating the need for manually specified state abstractions. Our key idea is to learn predicates by optimizing a surrogate objective that is tractable but faithful to our real efficient-planning objective. We use this surrogate objective in a hill-climbing search over predicate sets drawn from a grammar. Experimentally, we show across four robotic planning environments that our learned abstractions are able to quickly solve held-out tasks, outperforming six baselines.},
  archive   = {C_AAAI},
  author    = {Tom Silver and Rohan Chitnis and Nishanth Kumar and Willie McClinton and Tomás Lozano-Pérez and Leslie Kaelbling and Joshua B. Tenenbaum},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26429},
  pages     = {12120-12129},
  title     = {Predicate invention for bilevel planning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Structurally restricted fragments of numeric planning – a
complexity analysis. <em>AAAI</em>, 12112–12119. (<a
href="https://doi.org/10.1609/aaai.v37i10.26428">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Numeric planning is known to be undecidable even under severe restrictions. Prior work has investigated the decidability boundaries by restricting the expressiveness of the planning formalism in terms of the numeric functions allowed in conditions and effects. We study a well-known restricted form of Hoffmann&#39;s simple numeric planning, which is undecidable. We analyze the complexity by imposing restrictions on the causal structure, exploiting a novel method for bounding variable domain sizes. First, we show that plan existence for tasks where all numeric variables are root nodes in the causal graph is in PSPACE. Second, we show that for tasks with only numeric leaf variables the problem is decidable, and that it is in PSPACE if the propositional state space has a fixed size. Our work lays a strong foundation for future investigations of structurally more complex tasks. From a practical perspective, our method allows to employ heuristics and methods that are geared towards finite variable domains (such as pattern database heuristics or decoupled search) to solve non-trivial families of numeric planning problems.},
  archive   = {C_AAAI},
  author    = {Alexander Shleyfman and Daniel Gnad and Peter Jonsson},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26428},
  pages     = {12112-12119},
  title     = {Structurally restricted fragments of numeric planning – a complexity analysis},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Flexible budgets in restless bandits: A primal-dual
algorithm for efficient budget allocation. <em>AAAI</em>, 12103–12111.
(<a href="https://doi.org/10.1609/aaai.v37i10.26427">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Restless multi-armed bandits (RMABs) are an important model to optimize allocation of limited resources in sequential decision-making settings. Typical RMABs assume the budget --- the number of arms pulled --- to be fixed for each step in the planning horizon. However, for realistic real-world planning, resources are not necessarily limited at each planning step; we may be able to distribute surplus resources in one round to an earlier or later round. In real-world planning settings, this flexibility in budget is often constrained to within a subset of consecutive planning steps, e.g., weekly planning of a monthly budget. In this paper we define a general class of RMABs with flexible budget, which we term F-RMABs, and provide an algorithm to optimally solve for them. We derive a min-max formulation to find optimal policies for F-RMABs and leverage gradient primal-dual algorithms to solve for reward-maximizing policies with flexible budgets. We introduce a scheme to sample expected gradients to apply primal-dual algorithms to the F-RMAB setting and make an otherwise computationally expensive approach tractable. Additionally, we provide heuristics that trade off solution quality for efficiency and present experimental comparisons of different F-RMAB solution approaches.},
  archive   = {C_AAAI},
  author    = {Paula Rodriguez Diaz and Jackson A. Killian and Lily Xu and Arun Sai Suggala and Aparna Taneja and Milind Tambe},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26427},
  pages     = {12103-12111},
  title     = {Flexible budgets in restless bandits: A primal-dual algorithm for efficient budget allocation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Expressive optimal temporal planning via optimization modulo
theory. <em>AAAI</em>, 12095–12102. (<a
href="https://doi.org/10.1609/aaai.v37i10.26426">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Temporal Planning is the problem of synthesizing a course of actions given a predictive model of a system subject to temporal constraints. This kind of planning finds natural applications in the automation of industrial processes and in robotics when the timing and deadlines are important. Finding any plan in temporal planning is often not enough as it is sometimes needed to optimize a certain objective function: particularly interesting are the minimization of the makespan and the optimization of the costs of actions. Despite the importance of the problem, only few works in the literature tackled the problem of optimal temporal planning because of the complicated intermix of planning and scheduling. In this paper, we address the problem of optimal temporal planning for a very expressive class of problems using a reduction of the bounded planning problem to Optimization Modulo Theory (OMT) a powerful discrete/continuous optimization framework. We theoretically and empirically show the expressive power of this approach and we set a baseline for future research in this area.},
  archive   = {C_AAAI},
  author    = {Stefan Panjkovic and Andrea Micheli},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26426},
  pages     = {12095-12102},
  title     = {Expressive optimal temporal planning via optimization modulo theory},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automated verification of social laws in numeric settings.
<em>AAAI</em>, 12087–12094. (<a
href="https://doi.org/10.1609/aaai.v37i10.26425">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {It is possible for agents operating in a shared environment to interfere with one another. One mechanism of coordination is called Social Law. Enacting such a law in a multi-agent setting restricts agents&#39; behaviors. Robustness, in this case, ensures that the agents do not harmfully interfere with each other and that each agent achieves its goals regardless of what other agents do. Previous work on social law verification examined only the case of boolean state variables. However, many real-world problems require reasoning with numeric variables. Moreover, numeric fluents allow a more compact representation of multiple planning problems. In this paper, we develop a method to verify whether a given social law is robust via compilation to numeric planning. A solution to this compilation constitutes a counterexample to the robustness of the problem, i.e., evidence of cross-agent conflict. Thus, the social law is robust if and only if the proposed compilation is unsolvable. We empirically verify robustness in multiple domains using state-of-the-art numeric planners. Additionally, this compilation raises a challenge by generating a set of non-trivial numeric domains where unsolvability should be either proved or disproved.},
  archive   = {C_AAAI},
  author    = {Ronen Nir and Alexander Shleyfman and Erez Karpas},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26425},
  pages     = {12087-12094},
  title     = {Automated verification of social laws in numeric settings},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning safe numeric action models. <em>AAAI</em>,
12079–12086. (<a
href="https://doi.org/10.1609/aaai.v37i10.26424">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Powerful domain-independent planners have been developed to solve various types of planning problems. These planners often require a model of the acting agent&#39;s actions, given in some planning domain description language. Yet obtaining such an action model is a notoriously hard task. This task is even more challenging in mission-critical domains, where a trial-and-error approach to learning how to act is not an option. In such domains, the action model used to generate plans must be safe, in the sense that plans generated with it must be applicable and achieve their goals. Learning safe action models for planning has been recently explored for domains in which states are sufficiently described with Boolean variables. In this work, we go beyond this limitation and propose the NSAM algorithm. NSAM runs in time that is polynomial in the number of observations and, under certain conditions, is guaranteed to return safe action models. We analyze its worst-case sample complexity, which may be intractable for some domains. Empirically, however, NSAM can quickly learn a safe action model that can solve most problems in the domain.},
  archive   = {C_AAAI},
  author    = {Argaman Mordoch and Brendan Juba and Roni Stern},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26424},
  pages     = {12079-12086},
  title     = {Learning safe numeric action models},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning rational subgoals from demonstrations and
instructions. <em>AAAI</em>, 12068–12078. (<a
href="https://doi.org/10.1609/aaai.v37i10.26423">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present a framework for learning useful subgoals that support efficient long-term planning to achieve novel goals. At the core of our framework is a collection of rational subgoals (RSGs), which are essentially binary classifiers over the environmental states. RSGs can be learned from weakly-annotated data, in the form of unsegmented demonstration trajectories, paired with abstract task descriptions, which are composed of terms initially unknown to the agent (e.g., collect-wood then craft-boat then go-across-river). Our framework also discovers dependencies between RSGs, e.g., the task collect-wood is a helpful subgoal for the task craft-boat. Given a goal description, the learned subgoals and the derived dependencies facilitate off-the-shelf planning algorithms, such as A* and RRT, by setting helpful subgoals as waypoints to the planner, which significantly improves performance-time efficiency. Project page: https://rsg.csail.mit.edu},
  archive   = {C_AAAI},
  author    = {Zhezheng Luo and Jiayuan Mao and Jiajun Wu and Tomás Lozano-Pérez and Joshua B. Tenenbaum and Leslie Pack Kaelbling},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26423},
  pages     = {12068-12078},
  title     = {Learning rational subgoals from demonstrations and instructions},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AlphaRoute: Large-scale coordinated route planning via monte
carlo tree search. <em>AAAI</em>, 12058–12067. (<a
href="https://doi.org/10.1609/aaai.v37i10.26422">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper proposes AlphaRoute, an AlphaGo inspired algorithm for coordinating large-scale routes, built upon graph attention reinforcement learning and Monte Carlo Tree Search (MCTS). We first partition the road network into regions and model large-scale coordinated route planning as a Markov game, where each partitioned region is treated as a player instead of each driver. Then, AlphaRoute applies a bilevel optimization framework, consisting of several region planners and a global planner, where the region planner coordinates the route choices for vehicles located in the region and generates several strategies, and the global planner evaluates the combination of strategies. AlphaRoute is built on graph attention network for evaluating each state and MCTS algorithm for dynamically visiting and simulating the future state for narrowing down the search space. AlphaRoute is capable of 1) bridging user fairness and system efficiency, 2) achieving higher search efficiency by alleviating the curse of dimensionality problems, and 3) making an effective and informed route planning by simulating over the future to capture traffic dynamics. Comprehensive experiments are conducted on two real-world road networks as compared with several baselines to evaluate the performance, and results show that AlphaRoute achieves the lowest travel time, and is efficient and effective for coordinating large-scale routes and alleviating the traffic congestion problem. The code will be publicly available.},
  archive   = {C_AAAI},
  author    = {Guiyang Luo and Yantao Wang and Hui Zhang and Quan Yuan and Jinglin Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26422},
  pages     = {12058-12067},
  title     = {AlphaRoute: Large-scale coordinated route planning via monte carlo tree search},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A dynamics and task decoupled reinforcement learning
architecture for high-efficiency dynamic target intercept.
<em>AAAI</em>, 12049–12057. (<a
href="https://doi.org/10.1609/aaai.v37i10.26421">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Due to the flexibility and ease of control, unmanned aerial vehicles (UAVs) have been increasingly used in various scenarios and applications in recent years. Training UAVs with reinforcement learning (RL) for a specific task is often expensive in terms of time and computation. However, it is known that the main effort of the learning process is made to fit the low-level physical dynamics systems instead of the high-level task itself. In this paper, we study to apply UAVs in the dynamic target intercept (DTI) task, where the dynamics systems equipped by different UAV models are correspondingly distinct. To this end, we propose a dynamics and task decoupled RL architecture to address the inefficient learning procedure, where the RL module focuses on modeling the DTI task without involving physical dynamics, and the design of states, actions, and rewards are completely task-oriented while the dynamics control module can adaptively convert actions from the RL module to dynamics signals to control different UAVs without retraining the RL module. We show the efficiency and efficacy of our results in comparison and ablation experiments against state-of-the-art methods.},
  archive   = {C_AAAI},
  author    = {Dora D. Liu and Liang Hu and Qi Zhang and Tangwei Ye and Usman Naseem and Zhong Yuan Lai},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26421},
  pages     = {12049-12057},
  title     = {A dynamics and task decoupled reinforcement learning architecture for high-efficiency dynamic target intercept},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On total-order HTN plan verification with method
preconditions – an extension of the CYK parsing algorithm.
<em>AAAI</em>, 12041–12048. (<a
href="https://doi.org/10.1609/aaai.v37i10.26420">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we consider the plan verification problem for totally ordered (TO) HTN planning. The problem is proved to be solvable in polynomial time by recognizing its connection to the membership decision problem for context-free grammars. Currently, most HTN plan verification approaches do not have special treatments for the TO configuration, and the only one features such an optimization still relies on an exhaustive search. Hence, we will develop a new TOHTN plan verification approach in this paper by extending the standard CYK parsing algorithm which acts as the best decision procedure in general.},
  archive   = {C_AAAI},
  author    = {Songtuan Lin and Gregor Behnke and Simona Ondrčková and Roman Barták and Pascal Bercher},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26420},
  pages     = {12041-12048},
  title     = {On total-order HTN plan verification with method preconditions – an extension of the CYK parsing algorithm},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Was fixing this really that hard? On the complexity of
correcting HTN domains. <em>AAAI</em>, 12032–12040. (<a
href="https://doi.org/10.1609/aaai.v37i10.26419">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Automated modeling assistance is indispensable to the AI planning being deployed in practice, notably in industry and other non-academic contexts. Yet, little progress has been made that goes beyond smart interfaces like programming environments. They focus on autocompletion, but lack intelligent support for guiding the modeler. As a theoretical foundation of a first step towards this direction, we study the computational complexity of correcting a flawed Hierarchical Task Network (HTN) planning domain. Specifically, a modeler provides a (white) list of plans that are supposed to be solutions, and likewise a (black) list of plans that shall not be solutions. We investigate the complexity of finding a set of (optimal or suboptimal) model corrections so that those plans are (resp. not) solutions to the corrected model. More specifically, we factor out each hardness source that contributes towards NP-hardness, including one that we deem important for many other complexity investigations that go beyond our specific context of application. All complexities range between NP and Sigma-2-p, rising the hope for efficient practical tools in the future.},
  archive   = {C_AAAI},
  author    = {Songtuan Lin and Pascal Bercher},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26419},
  pages     = {12032-12040},
  title     = {Was fixing this really that hard? on the complexity of correcting HTN domains},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards automated modeling assistance: An efficient approach
for repairing flawed planning domains. <em>AAAI</em>, 12022–12031. (<a
href="https://doi.org/10.1609/aaai.v37i10.26418">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Designing a planning domain is a difficult task in AI planning. Assisting tools are thus required if we want planning to be used more broadly. In this paper, we are interested in automatically correcting a flawed domain. In particular, we are concerned with the scenario where a domain contradicts a plan that is known to be valid. Our goal is to repair the domain so as to turn the plan into a solution. Specifically, we consider both grounded and lifted representations support for negative preconditions and show how to explore the space of repairs to find the optimal one efficiently. As an evidence of the efficiency of our approach, the experiment results show that all flawed domains except one in the benchmark set can be repaired optimally by our approach within one second.},
  archive   = {C_AAAI},
  author    = {Songtuan Lin and Alban Grastien and Pascal Bercher},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26418},
  pages     = {12022-12031},
  title     = {Towards automated modeling assistance: An efficient approach for repairing flawed planning domains},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fully online matching with stochastic arrivals and
departures. <em>AAAI</em>, 12014–12021. (<a
href="https://doi.org/10.1609/aaai.v37i10.26417">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study a fully online matching problem with stochastic arrivals and departures. In this model, each online arrival follows a known identical and independent distribution over a fixed set of agent types. Its sojourn time is unknown in advance and follows type-specific distributions with known expectations. The goal is to maximize the weighted reward from successful matches. To solve this problem, we first propose a linear program (LP)-based algorithm whose competitive ratio is lower bounded by 0.155 under mild conditions. We further achieve better ratios in some special cases. To demonstrate the challenges of the problem, we further establish several hardness results. In particular, we show that no online algorithm can achieve a competitive ratio better than 2/3 in this model and there is no LP-based algorithm (with respect to our proposed LP) with a competitive ratio better than 1/3. Finally, we demonstrate the effectiveness and efficiency of our algorithm numerically.},
  archive   = {C_AAAI},
  author    = {Zihao Li and Hao Wang and Zhenzhen Yan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26417},
  pages     = {12014-12021},
  title     = {Fully online matching with stochastic arrivals and departures},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Planning for learning object properties. <em>AAAI</em>,
12005–12013. (<a
href="https://doi.org/10.1609/aaai.v37i10.26416">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Autonomous agents embedded in a physical environment need the ability to recognize objects and their properties from sensory data. Such a perceptual ability is often implemented by supervised machine learning models, which are pre-trained using a set of labelled data. In real-world, open-ended deployments, however, it is unrealistic to assume to have a pre-trained model for all possible environments. Therefore, agents need to dynamically learn/adapt/extend their perceptual abilities online, in an autonomous way, by exploring and interacting with the environment where they operate. This paper describes a way to do so, by exploiting symbolic planning. Specifically, we formalize the problem of automatically training a neural network to recognize object properties as a symbolic planning problem (using PDDL). We use planning techniques to produce a strategy for automating the training dataset creation and the learning process. Finally, we provide an experimental evaluation in both a simulated and a real environment, which shows that the proposed approach is able to successfully learn how to recognize new object properties.},
  archive   = {C_AAAI},
  author    = {Leonardo Lamanna and Luciano Serafini and Mohamadreza Faridghasemnia and Alessandro Saffiotti and Alessandro Saetti and Alfonso Gerevini and Paolo Traverso},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26416},
  pages     = {12005-12013},
  title     = {Planning for learning object properties},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Networked restless bandits with positive externalities.
<em>AAAI</em>, 11997–12004. (<a
href="https://doi.org/10.1609/aaai.v37i10.26415">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Restless multi-armed bandits are often used to model budget-constrained resource allocation tasks where receipt of the resource is associated with an increased probability of a favorable state transition. Prior work assumes that individual arms only benefit if they receive the resource directly. However, many allocation tasks occur within communities and can be characterized by positive externalities that allow arms to derive partial benefit when their neighbor(s) receive the resource. We thus introduce networked restless bandits, a novel multi-armed bandit setting in which arms are both restless and embedded within a directed graph. We then present Greta, a graph-aware, Whittle index-based heuristic algorithm that can be used to efficiently construct a constrained reward-maximizing action vector at each timestep. Our empirical results demonstrate that Greta outperforms comparison policies across a range of hyperparameter values and graph topologies. Code and appendices are available at https://github.com/crherlihy/networked_restless_bandits.},
  archive   = {C_AAAI},
  author    = {Christine Herlihy and John P. Dickerson},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26415},
  pages     = {11997-12004},
  title     = {Networked restless bandits with positive externalities},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning-augmented algorithms for online TSP on the line.
<em>AAAI</em>, 11989–11996. (<a
href="https://doi.org/10.1609/aaai.v37i10.26414">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the online Traveling Salesman Problem (TSP) on the line augmented with machine-learned predictions. In the classical problem, there is a stream of requests released over time along the real line. The goal is to minimize the makespan of the algorithm. We distinguish between the open variant and the closed one, in which we additionally require the algorithm to return to the origin after serving all requests. The state of the art is a 1.64-competitive algorithm and a 2.04-competitive algorithm for the closed and open variants, respectively. In both cases, a tight lower bound is known. In both variants, our primary prediction model involves predicted positions of the requests. We introduce algorithms that (i) obtain a tight 1.5 competitive ratio for the closed variant and a 1.66 competitive ratio for the open variant in the case of perfect predictions, (ii) are robust against unbounded prediction error, and (iii) are smooth, i.e., their performance degrades gracefully as the prediction error increases. Moreover, we further investigate the learning-augmented setting in the open variant by additionally considering a prediction for the last request served by the optimal offline algorithm. Our algorithm for this enhanced setting obtains a 1.33 competitive ratio with perfect predictions while also being smooth and robust, beating the lower bound of 1.44 we show for our original prediction setting for the open variant. Also, we provide a lower bound of 1.25 for this enhanced setting.},
  archive   = {C_AAAI},
  author    = {Themistoklis Gouleakis and Konstantinos Lakis and Golnoosh Shahkarami},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26414},
  pages     = {11989-11996},
  title     = {Learning-augmented algorithms for online TSP on the line},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Markov decision processes with time-varying geometric
discounting. <em>AAAI</em>, 11980–11988. (<a
href="https://doi.org/10.1609/aaai.v37i10.26413">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Canonical models of Markov decision processes (MDPs) usually consider geometric discounting based on a constant discount factor. While this standard modeling approach has led to many elegant results, some recent studies indicate the necessity of modeling time-varying discounting in certain applications. This paper studies a model of infinite-horizon MDPs with time-varying discount factors. We take a game-theoretic perspective – whereby each time step is treated as an independent decision maker with their own (fixed) discount factor – and we study the subgame perfect equilibrium (SPE) of the resulting game as well as the related algorithmic problems. We present a constructive proof of the existence of an SPE and demonstrate the EXPTIME-hardness of computing an SPE. We also turn to the approximate notion of epsilon-SPE and show that an epsilon-SPE exists under milder assumptions. An algorithm is presented to compute an epsilon-SPE, of which an upper bound of the time complexity, as a function of the convergence property of the time-varying discount factor, is provided.},
  archive   = {C_AAAI},
  author    = {Jiarui Gan and Annika Hennes and Rupak Majumdar and Debmalya Mandal and Goran Radanovic},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26413},
  pages     = {11980-11988},
  title     = {Markov decision processes with time-varying geometric discounting},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Privacy attacks on schedule-driven data. <em>AAAI</em>,
11972–11979. (<a
href="https://doi.org/10.1609/aaai.v37i10.26412">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Schedules define how resources process jobs in diverse domains, reaching from healthcare to transportation, and, therefore, denote a valuable starting point for analysis of the underlying system. However, publishing a schedule may disclose private information on the considered jobs. In this paper, we provide a first threat model for published schedules, thereby defining a completely new class of data privacy problems. We then propose distance-based measures to assess the privacy loss incurred by a published schedule, and show their theoretical properties for an uninformed adversary, which can be used as a benchmark for informed attacks. We show how an informed attack on a published schedule can be phrased as an inverse scheduling problem. We instantiate this idea by formulating the inverse of a well-studied single-machine scheduling problem, namely minimizing the total weighted completion times. An empirical evaluation for synthetic scheduling problems shows the effectiveness of informed privacy attacks and compares the results to theoretical bounds on uninformed attacks.},
  archive   = {C_AAAI},
  author    = {Stephan A. Fahrenkrog-Petersen and Arik Senderovich and Alexandra Tichauer and Ali Kaan Tutak and J. Christopher Beck and Matthias Weidlich},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26412},
  pages     = {11972-11979},
  title     = {Privacy attacks on schedule-driven data},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Planning with hidden parameter polynomial MDPs.
<em>AAAI</em>, 11963–11971. (<a
href="https://doi.org/10.1609/aaai.v37i10.26411">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {For many applications of Markov Decision Processes (MDPs), the transition function cannot be specified exactly. Bayes-Adaptive MDPs (BAMDPs) extend MDPs to consider transition probabilities governed by latent parameters. To act optimally in BAMDPs, one must maintain a belief distribution over the latent parameters. Typically, this distribution is described by a set of sample (particle) MDPs, and associated weights which represent the likelihood of a sample MDP being the true underlying MDP. However, as the number of dimensions of the latent parameter space increases, the number of sample MDPs required to sufficiently represent the belief distribution grows exponentially. Thus, maintaining an accurate belief in the form of a set of sample MDPs over complex latent spaces is computationally intensive, which in turn affects the performance of planning for these models. In this paper, we propose an alternative approach for maintaining the belief over the latent parameters. We consider a class of BAMDPs where the transition probabilities can be expressed in closed form as a polynomial of the latent parameters, and outline a method to maintain a closed-form belief distribution for the latent parameters which results in an accurate belief representation. Furthermore, the closed-form representation does away with the need to tune the number of sample MDPs required to represent the belief. We evaluate two domains and empirically show that the polynomial, closed-form, belief representation results in better plans than a sampling-based belief representation.},
  archive   = {C_AAAI},
  author    = {Clarissa Costen and Marc Rigter and Bruno Lacerda and Nick Hawes},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26411},
  pages     = {11963-11971},
  title     = {Planning with hidden parameter polynomial MDPs},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Zero-knowledge proofs for classical planning problems.
<em>AAAI</em>, 11955–11962. (<a
href="https://doi.org/10.1609/aaai.v37i10.26410">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In classical planning, the aim is to find a sequence of deterministic actions leading from the initial to a goal state. In this work, we consider the scenario where a party who knows the solution to a planning task, called the prover, wants to convince a second party, the verifier, that it has the solution without revealing any information about the solution itself. This is relevant in domains where privacy is important, for example when plans contain sensitive information or when the solution should not be revealed upfront. We achieve this by introducing a zero-knowledge protocol for plan existence. By restricting ourselves to tasks with polynomially-bounded plan length, we are able to construct a protocol that can be run efficiently by both the prover and verifier. The resulting protocol does not rely on any reduction, has a constant number of rounds, and runs in time polynomial in the size of the task.},
  archive   = {C_AAAI},
  author    = {Augusto B. Corrêa and Clemens Büchner and Remo Christen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26410},
  pages     = {11955-11962},
  title     = {Zero-knowledge proofs for classical planning problems},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Heuristic search for multi-objective probabilistic planning.
<em>AAAI</em>, 11945–11954. (<a
href="https://doi.org/10.1609/aaai.v37i10.26409">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Heuristic search is a powerful approach that has successfully been applied to a broad class of planning problems, including classical planning, multi-objective planning, and probabilistic planning modelled as a stochastic shortest path (SSP) problem. Here, we extend the reach of heuristic search to a more expressive class of problems, namely multi-objective stochastic shortest paths (MOSSPs), which require computing a coverage set of non-dominated policies. We design new heuristic search algorithms MOLAO* and MOLRTDP, which extend well-known SSP algorithms to the multi-objective case. We further construct a spectrum of domain-independent heuristic functions differing in their ability to take into account the stochastic and multi-objective features of the problem to guide the search. Our experiments demonstrate the benefits of these algorithms and the relative merits of the heuristics.},
  archive   = {C_AAAI},
  author    = {Dillon Z. Chen and Felipe Trevizan and Sylvie Thiébaux},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26409},
  pages     = {11945-11954},
  title     = {Heuristic search for multi-objective probabilistic planning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust neuro-symbolic goal and plan recognition.
<em>AAAI</em>, 11937–11944. (<a
href="https://doi.org/10.1609/aaai.v37i10.26408">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Goal Recognition is the task of discerning the intended goal of an agent given a sequence of observations, whereas Plan Recognition consists of identifying the plan to achieve such intended goal. Regardless of the underlying techniques, most recognition approaches are directly affected by the quality of the available observations. In this paper, we develop neuro-symbolic recognition approaches that can combine learning and planning techniques, compensating for noise and missing observations using prior data. We evaluate our approaches in standard human-designed planning domains as well as domain models automatically learned from real-world data. Empirical experimentation shows that our approaches reliably infer goals and compute correct plans in the experimental datasets. An ablation study shows that outperform approaches that rely exclusively on the domain model, or exclusively on machine learning in problems with both noisy observations and low observability.},
  archive   = {C_AAAI},
  author    = {Leonardo Amado and Ramon Fraga Pereira and Felipe Meneguzzi},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26408},
  pages     = {11937-11944},
  title     = {Robust neuro-symbolic goal and plan recognition},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning control policies for stochastic systems with
reach-avoid guarantees. <em>AAAI</em>, 11926–11935. (<a
href="https://doi.org/10.1609/aaai.v37i10.26407">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the problem of learning controllers for discrete-time non-linear stochastic dynamical systems with formal reach-avoid guarantees. This work presents the first method for providing formal reach-avoid guarantees, which combine and generalize stability and safety guarantees, with a tolerable probability threshold p in [0,1] over the infinite time horizon. Our method leverages advances in machine learning literature and it represents formal certificates as neural networks. In particular, we learn a certificate in the form of a reach-avoid supermartingale (RASM), a novel notion that we introduce in this work. Our RASMs provide reachability and avoidance guarantees by imposing constraints on what can be viewed as a stochastic extension of level sets of Lyapunov functions for deterministic systems. Our approach solves several important problems -- it can be used to learn a control policy from scratch, to verify a reach-avoid specification for a fixed control policy, or to fine-tune a pre-trained policy if it does not satisfy the reach-avoid specification. We validate our approach on 3 stochastic non-linear reinforcement learning tasks.},
  archive   = {C_AAAI},
  author    = {Đorđe Žikelić and Mathias Lechner and Thomas A. Henzinger and Krishnendu Chatterjee},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26407},
  pages     = {11926-11935},
  title     = {Learning control policies for stochastic systems with reach-avoid guarantees},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Faster fair machine via transferring fairness constraints to
virtual samples. <em>AAAI</em>, 11918–11925. (<a
href="https://doi.org/10.1609/aaai.v37i10.26406">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Fair classification is an emerging and important research topic in machine learning community. Existing methods usually formulate the fairness metrics as additional inequality constraints, and then embed them into the original objective. This makes fair classification problems unable to be effectively tackled by some solvers specific to unconstrained optimization. Although many new tailored algorithms have been designed to attempt to overcome this limitation, they often increase additional computation burden and cannot cope with all types of fairness metrics. To address these challenging issues, in this paper, we propose a novel method for fair classification. Specifically, we theoretically demonstrate that all types of fairness with linear and non-linear covariance functions can be transferred to two virtual samples, which makes the existing state-of-the-art classification solvers be applicable to these cases. Meanwhile, we generalize the proposed method to multiple fairness constraints. We take SVM as an example to show the effectiveness of our new idea. Empirically, we test the proposed method on real-world datasets and all results confirm its excellent performance.},
  archive   = {C_AAAI},
  author    = {Zhou Zhai and Lei Luo and Heng Huang and Bin Gu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26406},
  pages     = {11918-11925},
  title     = {Faster fair machine via transferring fairness constraints to virtual samples},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Minimax AUC fairness: Efficient algorithm with provable
convergence. <em>AAAI</em>, 11909–11917. (<a
href="https://doi.org/10.1609/aaai.v37i10.26405">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The use of machine learning models in consequential decision making often exacerbates societal inequity, in particular yielding disparate impact on members of marginalized groups defined by race and gender. The area under the ROC curve (AUC) is widely used to evaluate the performance of a scoring function in machine learning, but is studied in algorithmic fairness less than other performance metrics. Due to the pairwise nature of the AUC, defining an AUC-based group fairness metric is pairwise-dependent and may involve both intra-group and inter-group AUCs. Importantly, considering only one category of AUCs is not sufficient to mitigate unfairness in AUC optimization. In this paper, we propose a minimax learning and bias mitigation framework that incorporates both intra-group and inter-group AUCs while maintaining utility. Based on this Rawlsian framework, we design an efficient stochastic optimization algorithm and prove its convergence to the minimum group-level AUC. We conduct numerical experiments on both synthetic and real-world datasets to validate the effectiveness of the minimax framework and the proposed optimization algorithm.},
  archive   = {C_AAAI},
  author    = {Zhenhuan Yang and Yan Lok Ko and Kush R. Varshney and Yiming Ying},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26405},
  pages     = {11909-11917},
  title     = {Minimax AUC fairness: Efficient algorithm with provable convergence},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Online platforms and the fair exposure problem under
homophily. <em>AAAI</em>, 11899–11908. (<a
href="https://doi.org/10.1609/aaai.v37i10.26404">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the wake of increasing political extremism, online platforms have been criticized for contributing to polarization. One line of criticism has focused on echo chambers and the recommended content served to users by these platforms. In this work, we introduce the fair exposure problem: given limited intervention power of the platform, the goal is to enforce balance in the spread of content (e.g., news articles) among two groups of users through constraints similar to those imposed by the Fairness Doctrine in the United States in the past. Groups are characterized by different affiliations (e.g., political views) and have different preferences for content. We develop a stylized framework that models intra- and inter-group content propagation under homophily, and we formulate the platform&#39;s decision as an optimization problem that aims at maximizing user engagement, potentially under fairness constraints. Our main notion of fairness requires that each group see a mixture of their preferred and non-preferred content, encouraging information diversity. Promoting such information diversity is often viewed as desirable and a potential means for breaking out of harmful echo chambers. We study the solutions to both the fairness-agnostic and fairness-aware problems. We prove that a fairness-agnostic approach inevitably leads to group-homogeneous targeting by the platform. This is only partially mitigated by imposing fairness constraints: we show that there exist optimal fairness-aware solutions which target one group with different types of content and the other group with only one type that is not necessarily the group&#39;s most preferred. Finally, using simulations with real-world data, we study the system dynamics and quantify the price of fairness.},
  archive   = {C_AAAI},
  author    = {Jakob Schoeffer and Alexander Ritchie and Keziah Naggita and Faidra Monachou and Jessica Finocchiaro and Marc Juarez},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26404},
  pages     = {11899-11908},
  title     = {Online platforms and the fair exposure problem under homophily},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Equity promotion in public transportation. <em>AAAI</em>,
11890–11898. (<a
href="https://doi.org/10.1609/aaai.v37i10.26403">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {There are many news articles reporting the obstacles confronting poverty-stricken households in access to public transits. These barriers create a great deal of inconveniences for these impoverished families and more importantly, they contribute a lot of social inequalities. A typical approach addressing the issue is to build more transport infrastructure to offer more opportunities to access the public transits especially for those deprived communities. Examples include adding more bus lines connecting needy residents to railways systems and extending existing bus lines to areas with low socioeconomic status. Recently, a new strategy is proposed, which is to harness the ubiquitous ride-hailing services to connect disadvantaged households with the nearest public transportations. Compared with the former infrastructure-based solution, the ride-hailing-based strategy enjoys a few exclusive benefits such as higher effectiveness and more flexibility. In this paper, we propose an optimization model to study how to integrate the two approaches together for equity-promotion purposes. Specifically, we aim to design a strategy of allocating a given limited budget to different candidate programs such that the overall social equity is maximized, which is defined as the minimum covering ratio among all pre-specified protected groups of households (based on race, income, etc.). We have designed a linear-programming (LP) based rounding algorithm, which proves to achieve an optimal approximation ratio of 1-1/e. Additionally, we test our algorithm against a few baselines on real data assembled by outsourcing multiple public datasets collected in the city of Chicago. Experimental results confirm our theoretical predictions and demonstrate the effectiveness of our LP-based strategy in promoting social equity, especially when the budget is insufficient.},
  archive   = {C_AAAI},
  author    = {Anik Pramanik and Pan Xu and Yifan Xu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26403},
  pages     = {11890-11898},
  title     = {Equity promotion in public transportation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mitigating adversarial norm training with moral axioms.
<em>AAAI</em>, 11882–11889. (<a
href="https://doi.org/10.1609/aaai.v37i10.26402">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper addresses the issue of adversarial attacks on ethical AI systems. We investigate using moral axioms and rules of deontic logic in a norm learning framework to mitigate adversarial norm training. This model of moral intuition and construction provides AI systems with moral guard rails yet still allows for learning conventions. We evaluate our approach by drawing inspiration from a study commonly used in moral development research. This questionnaire aims to test an agent&#39;s ability to reason to moral conclusions despite opposed testimony. Our findings suggest that our model can still correctly evaluate moral situations and learn conventions in an adversarial training environment. We conclude that adding axiomatic moral prohibitions and deontic inference rules to a norm learning model makes it less vulnerable to adversarial attacks.},
  archive   = {C_AAAI},
  author    = {Taylor Olson and Kenneth D. Forbus},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26402},
  pages     = {11882-11889},
  title     = {Mitigating adversarial norm training with moral axioms},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). XRand: Differentially private defense against
explanation-guided attacks. <em>AAAI</em>, 11873–11881. (<a
href="https://doi.org/10.1609/aaai.v37i10.26401">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent development in the field of explainable artificial intelligence (XAI) has helped improve trust in Machine-Learning-as-a-Service (MLaaS) systems, in which an explanation is provided together with the model prediction in response to each query. However, XAI also opens a door for adversaries to gain insights into the black-box models in MLaaS, thereby making the models more vulnerable to several attacks. For example, feature-based explanations (e.g., SHAP) could expose the top important features that a black-box model focuses on. Such disclosure has been exploited to craft effective backdoor triggers against malware classifiers. To address this trade-off, we introduce a new concept of achieving local differential privacy (LDP) in the explanations, and from that we establish a defense, called XRand, against such attacks. We show that our mechanism restricts the information that the adversary can learn about the top important features, while maintaining the faithfulness of the explanations.},
  archive   = {C_AAAI},
  author    = {Truc Nguyen and Phung Lai and Hai Phan and My T. Thai},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26401},
  pages     = {11873-11881},
  title     = {XRand: Differentially private defense against explanation-guided attacks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Echo of neighbors: Privacy amplification for personalized
private federated learning with shuffle model. <em>AAAI</em>,
11865–11872. (<a
href="https://doi.org/10.1609/aaai.v37i10.26400">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Federated Learning, as a popular paradigm for collaborative training, is vulnerable against privacy attacks. Different privacy levels regarding users&#39; attitudes need to be satisfied locally, while a strict privacy guarantee for the global model is also required centrally. Personalized Local Differential Privacy (PLDP) is suitable for preserving users&#39; varying local privacy, yet only provides a central privacy guarantee equivalent to the worst-case local privacy level. Thus, achieving strong central privacy as well as personalized local privacy with a utility-promising model is a challenging problem. In this work, a general framework (APES) is built up to strengthen model privacy under personalized local privacy by leveraging the privacy amplification effect of the shuffle model. To tighten the privacy bound, we quantify the heterogeneous contributions to the central privacy user by user. The contributions are characterized by the ability of generating “echos” from the perturbation of each user, which is carefully measured by proposed methods Neighbor Divergence and Clip-Laplace Mechanism. Furthermore, we propose a refined framework (S-APES) with the post-sparsification technique to reduce privacy loss in high-dimension scenarios. To the best of our knowledge, the impact of shuffling on personalized local privacy is considered for the first time. We provide a strong privacy amplification effect, and the bound is tighter than the baseline result based on existing methods for uniform local privacy. Experiments demonstrate that our frameworks ensure comparable or higher accuracy for the global model.},
  archive   = {C_AAAI},
  author    = {Yixuan Liu and Suyun Zhao and Li Xiong and Yuhan Liu and Hong Chen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26400},
  pages     = {11865-11872},
  title     = {Echo of neighbors: Privacy amplification for personalized private federated learning with shuffle model},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Explaining model confidence using counterfactuals.
<em>AAAI</em>, 11856–11864. (<a
href="https://doi.org/10.1609/aaai.v37i10.26399">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Displaying confidence scores in human-AI interaction has been shown to help build trust between humans and AI systems. However, most existing research uses only the confidence score as a form of communication. As confidence scores are just another model output, users may want to understand why the algorithm is confident to determine whether to accept the confidence score. In this paper, we show that counterfactual explanations of confidence scores help study participants to better understand and better trust a machine learning model&#39;s prediction. We present two methods for understanding model confidence using counterfactual explanation: (1) based on counterfactual examples; and (2) based on visualisation of the counterfactual space. Both increase understanding and trust for study participants over a baseline of no explanation, but qualitative results show that they are used quite differently, leading to recommendations of when to use each one and directions of designing better explanations.},
  archive   = {C_AAAI},
  author    = {Thao Le and Tim Miller and Ronal Singh and Liz Sonenberg},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26399},
  pages     = {11856-11864},
  title     = {Explaining model confidence using counterfactuals},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improvement-focused causal recourse (ICR). <em>AAAI</em>,
11847–11855. (<a
href="https://doi.org/10.1609/aaai.v37i10.26398">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Algorithmic recourse recommendations inform stakeholders of how to act to revert unfavorable decisions. However, existing methods may recommend actions that lead to acceptance (i.e., revert the model&#39;s decision) but do not lead to improvement (i.e., may not revert the underlying real-world state). To recommend such actions is to recommend fooling the predictor. We introduce a novel method, Improvement-Focused Causal Recourse (ICR), which involves a conceptual shift: Firstly, we require ICR recommendations to guide toward improvement. Secondly, we do not tailor the recommendations to be accepted by a specific predictor. Instead, we leverage causal knowledge to design decision systems that predict accurately pre- and post-recourse, such that improvement guarantees translate into acceptance guarantees. Curiously, optimal pre-recourse classifiers are robust to ICR actions and thus suitable post-recourse. In semi-synthetic experiments, we demonstrate that given correct causal knowledge ICR, in contrast to existing approaches, guides toward both acceptance and improvement.},
  archive   = {C_AAAI},
  author    = {Gunnar König and Timo Freiesleben and Moritz Grosse-Wentrup},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26398},
  pages     = {11847-11855},
  title     = {Improvement-focused causal recourse (ICR)},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fairness in contextual resource allocation systems: Metrics
and incompatibility results. <em>AAAI</em>, 11837–11846. (<a
href="https://doi.org/10.1609/aaai.v37i10.26397">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study critical systems that allocate scarce resources to satisfy basic needs, such as homeless services that provide housing. These systems often support communities disproportionately affected by systemic racial, gender, or other injustices, so it is crucial to design these systems with fairness considerations in mind. To address this problem, we propose a framework for evaluating fairness in contextual resource allocation systems that is inspired by fairness metrics in machine learning. This framework can be applied to evaluate the fairness properties of a historical policy, as well as to impose constraints in the design of new (counterfactual) allocation policies. Our work culminates with a set of incompatibility results that investigate the interplay between the different fairness metrics we propose. Notably, we demonstrate that: 1) fairness in allocation and fairness in outcomes are usually incompatible; 2) policies that prioritize based on a vulnerability score will usually result in unequal outcomes across groups, even if the score is perfectly calibrated; 3) policies using contextual information beyond what is needed to characterize baseline risk and treatment effects can be fairer in their outcomes than those using just baseline risk and treatment effects; and 4) policies using group status in addition to baseline risk and treatment effects are as fair as possible given all available information. Our framework can help guide the discussion among stakeholders in deciding which fairness metrics to impose when allocating scarce resources.},
  archive   = {C_AAAI},
  author    = {Nathanael Jo and Bill Tang and Kathryn Dullerud and Sina Aghaei and Eric Rice and Phebe Vayanos},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26397},
  pages     = {11837-11846},
  title     = {Fairness in contextual resource allocation systems: Metrics and incompatibility results},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Covariate-shift generalization via random sample weighting.
<em>AAAI</em>, 11828–11836. (<a
href="https://doi.org/10.1609/aaai.v37i10.26396">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Shifts in the marginal distribution of covariates from training to the test phase, named covariate-shifts, often lead to unstable prediction performance across agnostic testing data, especially under model misspecification. Recent literature on invariant learning attempts to learn an invariant predictor from heterogeneous environments. However, the performance of the learned predictor depends heavily on the availability and quality of provided environments. In this paper, we propose a simple and effective non-parametric method for generating heterogeneous environments via Random Sample Weighting (RSW). Given the training dataset from a single source environment, we randomly generate a set of covariate-determining sample weights and use each weighted training distribution to simulate an environment. We theoretically show that under appropriate conditions, such random sample weighting can produce sufficient heterogeneity to be exploited by common invariance constraints to find the invariant variables for stable prediction under covariate shifts. Extensive experiments on both simulated and real-world datasets clearly validate the effectiveness of our method.},
  archive   = {C_AAAI},
  author    = {Yue He and Xinwei Shen and Renzhe Xu and Tong Zhang and Yong Jiang and Wenchao Zou and Peng Cui},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26396},
  pages     = {11828-11836},
  title     = {Covariate-shift generalization via random sample weighting},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Correct for whom? Subjectivity and the evaluation of
personalized image aesthetics assessment models. <em>AAAI</em>,
11818–11827. (<a
href="https://doi.org/10.1609/aaai.v37i10.26395">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The problem of image aesthetic quality assessment is surprisingly difficult to define precisely. Most early work attempted to estimate the average aesthetic rating of a group of observers, while some recent work has shifted to an approach based on few-shot personalization. In this paper, we connect few-shot personalization, via Immanuel Kant&#39;s concept of disinterested judgment, to an argument from feminist aesthetics about the biased tendencies of objective standards for subjective pleasures. To empirically investigate this philosophical debate, we introduce PR-AADB, a relabeling of the existing AADB dataset with labels for pairs of images, and measure how well the existing groundtruth predicts our new pairwise labels. We find, consistent with the feminist critique, that both the existing groundtruth and few-shot personalized predictions represent some users&#39; preferences significantly better than others, but that it is difficult to predict when and for whom the existing groundtruth will be correct. We thus advise against using benchmark datasets to evaluate models for personalized IAQA, and recommend caution when attempting to account for subjective difference using machine learning more generally.},
  archive   = {C_AAAI},
  author    = {Samuel Goree and Weslie Khoo and David J. Crandall},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26395},
  pages     = {11818-11827},
  title     = {Correct for whom? subjectivity and the evaluation of personalized image aesthetics assessment models},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distributionally robust optimization with probabilistic
group. <em>AAAI</em>, 11809–11817. (<a
href="https://doi.org/10.1609/aaai.v37i10.26394">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Modern machine learning models may be susceptible to learning spurious correlations that hold on average but not for the atypical group of samples. To address the problem, previous approaches minimize the empirical worst-group risk. Despite the promise, they often assume that each sample belongs to one and only one group, which does not allow expressing the uncertainty in group labeling. In this paper, we propose a novel framework PG-DRO, which explores the idea of probabilistic group membership for distributionally robust optimization. Key to our framework, we consider soft group membership instead of hard group annotations. The group probabilities can be flexibly generated using either supervised learning or zero-shot approaches. Our framework accommodates samples with group membership ambiguity, offering stronger flexibility and generality than the prior art. We comprehensively evaluate PG-DRO on both image classification and natural language processing benchmarks, establishing superior performance.},
  archive   = {C_AAAI},
  author    = {Soumya Suvra Ghosal and Yixuan Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26394},
  pages     = {11809-11817},
  title     = {Distributionally robust optimization with probabilistic group},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the vulnerability of backdoor defenses for federated
learning. <em>AAAI</em>, 11800–11808. (<a
href="https://doi.org/10.1609/aaai.v37i10.26393">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Federated learning (FL) is a popular distributed machine learning paradigm which enables jointly training a global model without sharing clients&#39; data. However, its repetitive server-client communication gives room for possible backdoor attacks which aims to mislead the global model into a targeted misprediction when a specific trigger pattern is presented. In response to such backdoor threats on federated learning, various defense measures have been proposed. In this paper, we study whether the current defense mechanisms truly neutralize the backdoor threats from federated learning in a practical setting by proposing a new federated backdoor attack framework for possible countermeasures. Different from traditional training (on triggered data) and rescaling (the malicious client model) based backdoor injection, the proposed backdoor attack framework (1) directly modifies (a small proportion of) local model weights to inject the backdoor trigger via sign flips; (2) jointly optimize the trigger pattern with the client model, thus is more persistent and stealthy for circumventing existing defenses. In a case study, we examine the strength and weaknesses of several recent federated backdoor defenses from three major categories and provide suggestions to the practitioners when training federated models in practice.},
  archive   = {C_AAAI},
  author    = {Pei Fang and Jinghui Chen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26393},
  pages     = {11800-11808},
  title     = {On the vulnerability of backdoor defenses for federated learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards robust metrics for concept representation
evaluation. <em>AAAI</em>, 11791–11799. (<a
href="https://doi.org/10.1609/aaai.v37i10.26392">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent work on interpretability has focused on concept-based explanations, where deep learning models are explained in terms of high-level units of information, referred to as concepts. Concept learning models, however, have been shown to be prone to encoding impurities in their representations, failing to fully capture meaningful features of their inputs. While concept learning lacks metrics to measure such phenomena, the field of disentanglement learning has explored the related notion of underlying factors of variation in the data, with plenty of metrics to measure the purity of such factors. In this paper, we show that such metrics are not appropriate for concept learning and propose novel metrics for evaluating the purity of concept representations in both approaches. We show the advantage of these metrics over existing ones and demonstrate their utility in evaluating the robustness of concept representations and interventions performed on them. In addition, we show their utility for benchmarking state-of-the-art methods from both families and find that, contrary to common assumptions, supervision alone may not be sufficient for pure concept representations.},
  archive   = {C_AAAI},
  author    = {Mateo Espinosa Zarlenga and Pietro Barbiero and Zohreh Shams and Dmitry Kazhdan and Umang Bhatt and Adrian Weller and Mateja Jamnik},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26392},
  pages     = {11791-11799},
  title     = {Towards robust metrics for concept representation evaluation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning to play general-sum games against multiple
boundedly rational agents. <em>AAAI</em>, 11781–11789. (<a
href="https://doi.org/10.1609/aaai.v37i10.26391">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the problem of training a principal in a multi-agent general-sum game using reinforcement learning (RL). Learning a robust principal policy requires anticipating the worst possible strategic responses of other agents, which is generally NP-hard. However, we show that no-regret dynamics can identify these worst-case responses in poly-time in smooth games. We propose a framework that uses this policy evaluation method for efficiently learning a robust principal policy using RL. This framework can be extended to provide robustness to boundedly rational agents too. Our motivating application is automated mechanism design: we empirically demonstrate our framework learns robust mechanisms in both matrix games and complex spatiotemporal games. In particular, we learn a dynamic tax policy that improves the welfare of a simulated trade-and-barter economy by 15\%, even when facing previously unseen boundedly rational RL taxpayers.},
  archive   = {C_AAAI},
  author    = {Eric Zhao and Alexander R. Trott and Caiming Xiong and Stephan Zheng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26391},
  pages     = {11781-11789},
  title     = {Learning to play general-sum games against multiple boundedly rational agents},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Effective and stable role-based multi-agent collaboration by
structural information principles. <em>AAAI</em>, 11772–11780. (<a
href="https://doi.org/10.1609/aaai.v37i10.26390">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Role-based learning is a promising approach to improving the performance of Multi-Agent Reinforcement Learning (MARL). Nevertheless, without manual assistance, current role-based methods cannot guarantee stably discovering a set of roles to effectively decompose a complex task, as they assume either a predefined role structure or practical experience for selecting hyperparameters. In this article, we propose a mathematical Structural Information principles-based Role Discovery method, namely SIRD, and then present a SIRD optimizing MARL framework, namely SR-MARL, for multi-agent collaboration. The SIRD transforms role discovery into a hierarchical action space clustering. Specifically, the SIRD consists of structuralization, sparsification, and optimization modules, where an optimal encoding tree is generated to perform abstracting to discover roles. The SIRD is agnostic to specific MARL algorithms and flexibly integrated with various value function factorization approaches. Empirical evaluations on the StarCraft II micromanagement benchmark demonstrate that, compared with state-of-the-art MARL algorithms, the SR-MARL framework improves the average test win rate by 0.17\%, 6.08\%, and 3.24\%, and reduces the deviation by 16.67\%, 30.80\%, and 66.30\%, under easy, hard, and super hard scenarios.},
  archive   = {C_AAAI},
  author    = {Xianghua Zeng and Hao Peng and Angsheng Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26390},
  pages     = {11772-11780},
  title     = {Effective and stable role-based multi-agent collaboration by structural information principles},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DACOM: Learning delay-aware communication for multi-agent
reinforcement learning. <em>AAAI</em>, 11763–11771. (<a
href="https://doi.org/10.1609/aaai.v37i10.26389">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Communication is supposed to improve multi-agent collaboration and overall performance in cooperative Multi-agent reinforcement learning (MARL). However, such improvements are prevalently limited in practice since most existing communication schemes ignore communication overheads (e.g., communication delays). In this paper, we demonstrate that ignoring communication delays has detrimental effects on collaborations, especially in delay-sensitive tasks such as autonomous driving. To mitigate this impact, we design a delay-aware multi-agent communication model (DACOM) to adapt communication to delays. Specifically, DACOM introduces a component, TimeNet, that is responsible for adjusting the waiting time of an agent to receive messages from other agents such that the uncertainty associated with delay can be addressed. Our experiments reveal that DACOM has a non-negligible performance improvement over other mechanisms by making a better trade-off between the benefits of communication and the costs of waiting for messages.},
  archive   = {C_AAAI},
  author    = {Tingting Yuan and Hwei-Ming Chung and Jie Yuan and Xiaoming Fu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26389},
  pages     = {11763-11771},
  title     = {DACOM: Learning delay-aware communication for multi-agent reinforcement learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust multi-agent coordination via evolutionary generation
of auxiliary adversarial attackers. <em>AAAI</em>, 11753–11762. (<a
href="https://doi.org/10.1609/aaai.v37i10.26388">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Cooperative Multi-agent Reinforcement Learning (CMARL) has shown to be promising for many real-world applications. Previous works mainly focus on improving coordination ability via solving MARL-specific challenges (e.g., non-stationarity, credit assignment, scalability), but ignore the policy perturbation issue when testing in a different environment. This issue hasn&#39;t been considered in problem formulation or efficient algorithm design. To address this issue, we firstly model the problem as a Limited Policy Adversary Dec-POMDP (LPA-Dec-POMDP), where some coordinators from a team might accidentally and unpredictably encounter a limited number of malicious action attacks, but the regular coordinators still strive for the intended goal. Then, we propose Robust Multi-Agent Coordination via Evolutionary Generation of Auxiliary Adversarial Attackers (ROMANCE), which enables the trained policy to encounter diversified and strong auxiliary adversarial attacks during training, thus achieving high robustness under various policy perturbations. Concretely, to avoid the ego-system overfitting to a specific attacker, we maintain a set of attackers, which is optimized to guarantee the attackers high attacking quality and behavior diversity. The goal of quality is to minimize the ego-system coordination effect, and a novel diversity regularizer based on sparse action is applied to diversify the behaviors among attackers. The ego-system is then paired with a population of attackers selected from the maintained attacker set, and alternately trained against the constantly evolving attackers. Extensive experiments on multiple scenarios from SMAC indicate our ROMANCE provides comparable or better robustness and generalization ability than other baselines.},
  archive   = {C_AAAI},
  author    = {Lei Yuan and Ziqian Zhang and Ke Xue and Hao Yin and Feng Chen and Cong Guan and Lihe Li and Chao Qian and Yang Yu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26388},
  pages     = {11753-11762},
  title     = {Robust multi-agent coordination via evolutionary generation of auxiliary adversarial attackers},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hierarchical mean-field deep reinforcement learning for
large-scale multiagent systems. <em>AAAI</em>, 11744–11752. (<a
href="https://doi.org/10.1609/aaai.v37i10.26387">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Learning for efficient coordination in large-scale multiagent systems suffers from the problem of the curse of dimensionality due to the exponential growth of agent interactions. Mean-Field (MF)-based methods address this issue by transforming the interactions within the whole system into a single agent played with the average effect of its neighbors. However, considering the neighbors merely by their average may ignore the varying influences of each neighbor, and learning with this kind of local average effect would likely lead to inferior system performance due to lack of an efficient coordination mechanism in the whole population level. In this work, we propose a Hierarchical Mean-Field (HMF) learning framework to further improve the performance of existing MF methods. The basic idea is to approximate the average effect for a sub-group of agents by considering their different influences within the sub-group, and realize population-level coordination through the interactions among different sub-groups. Empirical studies show that HMF significantly outperforms existing baselines on both challenging cooperative and mixed cooperative-competitive tasks with different scales of agent populations.},
  archive   = {C_AAAI},
  author    = {Chao Yu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26387},
  pages     = {11744-11752},
  title     = {Hierarchical mean-field deep reinforcement learning for large-scale multiagent systems},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). HAVEN: Hierarchical cooperative multi-agent reinforcement
learning with dual coordination mechanism. <em>AAAI</em>, 11735–11743.
(<a href="https://doi.org/10.1609/aaai.v37i10.26386">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, some challenging tasks in multi-agent systems have been solved by some hierarchical reinforcement learning methods. Inspired by the intra-level and inter-level coordination in the human nervous system, we propose a novel value decomposition framework HAVEN based on hierarchical reinforcement learning for fully cooperative multi-agent problems. To address the instability arising from the concurrent optimization of policies between various levels and agents, we introduce the dual coordination mechanism of inter-level and inter-agent strategies by designing reward functions in a two-level hierarchy. HAVEN does not require domain knowledge and pre-training, and can be applied to any value decomposition variant. Our method achieves desirable results on different decentralized partially observable Markov decision process domains and outperforms other popular multi-agent hierarchical reinforcement learning algorithms.},
  archive   = {C_AAAI},
  author    = {Zhiwei Xu and Yunpeng Bai and Bin Zhang and Dapeng Li and Guoliang Fan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26386},
  pages     = {11735-11743},
  title     = {HAVEN: Hierarchical cooperative multi-agent reinforcement learning with dual coordination mechanism},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). Consensus learning for cooperative multi-agent
reinforcement learning. <em>AAAI</em>, 11726–11734. (<a
href="https://doi.org/10.1609/aaai.v37i10.26385">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Almost all multi-agent reinforcement learning algorithms without communication follow the principle of centralized training with decentralized execution. During the centralized training, agents can be guided by the same signals, such as the global state. However, agents lack the shared signal and choose actions given local observations during execution. Inspired by viewpoint invariance and contrastive learning, we propose consensus learning for cooperative multi-agent reinforcement learning in this study. Although based on local observations, different agents can infer the same consensus in discrete spaces without communication. We feed the inferred one-hot consensus to the network of agents as an explicit input in a decentralized way, thereby fostering their cooperative spirit. With minor model modifications, our suggested framework can be extended to a variety of multi-agent reinforcement learning algorithms. Moreover, we carry out these variants on some fully cooperative tasks and get convincing results.},
  archive   = {C_AAAI},
  author    = {Zhiwei Xu and Bin Zhang and Dapeng Li and Zeren Zhang and Guangchong Zhou and Hao Chen and Guoliang Fan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26385},
  pages     = {11726-11734},
  title     = {Consensus learning for cooperative multi-agent reinforcement learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Subspace-aware exploration for sparse-reward multi-agent
tasks. <em>AAAI</em>, 11717–11725. (<a
href="https://doi.org/10.1609/aaai.v37i10.26384">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Exploration under sparse rewards is a key challenge for multi-agent reinforcement learning problems. One possible solution to this issue is to exploit inherent task structures for an acceleration of exploration. In this paper, we present a novel exploration approach, which encodes a special structural prior on the reward function into exploration, for sparse-reward multi-agent tasks. Specifically, a novel entropic exploration objective which encodes the structural prior is proposed to accelerate the discovery of rewards. By maximizing the lower bound of this objective, we then propose an algorithm with moderate computational cost, which can be applied to practical tasks. Under the sparse-reward setting, we show that the proposed algorithm significantly outperforms the state-of-the-art algorithms in the multiple-particle environment, the Google Research Football and StarCraft II micromanagement tasks. To the best of our knowledge, on some hard tasks (such as 27m_vs_30m) which have relatively larger number of agents and need non-trivial strategies to defeat enemies, our method is the first to learn winning strategies under the sparse-reward setting.},
  archive   = {C_AAAI},
  author    = {Pei Xu and Junge Zhang and Qiyue Yin and Chao Yu and Yaodong Yang and Kaiqi Huang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26384},
  pages     = {11717-11725},
  title     = {Subspace-aware exploration for sparse-reward multi-agent tasks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Emergence of punishment in social dilemma with
environmental feedback. <em>AAAI</em>, 11708–11716. (<a
href="https://doi.org/10.1609/aaai.v37i10.26383">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Altruistic punishment (or punishment) has been extensively shown as an important mechanism for promoting cooperation in human societies. In AI, the emergence of punishment has received much recent interest. In this paper, we contribute with a novel evolutionary game theoretic model to study the impacts of environmental feedback. Whereas a population of agents plays public goods games, there exists a third-party population whose payoffs depend not only on whether to punish or not, but also on the state of the environment (e.g., how cooperative the agents in a social dilemma are). Focusing on one-shot public goods games, we show that environmental feedback, by itself, can lead to the emergence of punishment. We analyze the co-evolution of punishment and cooperation, and derive conditions for their co-presence, co-dominance and co-extinction. Moreover, we show that the system can exhibit bistability as well as cyclic dynamics. Our findings provide a new explanation for the emergence of punishment. On the other hand, our results also alert the need for careful design of implementing punishment in multi-agent systems, as the resulting evolutionary dynamics can be somewhat complex.},
  archive   = {C_AAAI},
  author    = {Zhen Wang and Zhao Song and Chen Shen and Shuyue Hu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26383},
  pages     = {11708-11716},
  title     = {Emergence of punishment in social dilemma with environmental feedback},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DM²: Decentralized multi-agent reinforcement learning via
distribution matching. <em>AAAI</em>, 11699–11707. (<a
href="https://doi.org/10.1609/aaai.v37i10.26382">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Current approaches to multi-agent cooperation rely heavily on centralized mechanisms or explicit communication protocols to ensure convergence. This paper studies the problem of distributed multi-agent learning without resorting to centralized components or explicit communication. It examines the use of distribution matching to facilitate the coordination of independent agents. In the proposed scheme, each agent independently minimizes the distribution mismatch to the corresponding component of a target visitation distribution. The theoretical analysis shows that under certain conditions, each agent minimizing its individual distribution mismatch allows the convergence to the joint policy that generated the target distribution. Further, if the target distribution is from a joint policy that optimizes a cooperative task, the optimal policy for a combination of this task reward and the distribution matching reward is the same joint policy. This insight is used to formulate a practical algorithm (DM^2), in which each individual agent matches a target distribution derived from concurrently sampled trajectories from a joint expert policy. Experimental validation on the StarCraft domain shows that combining (1) a task reward, and (2) a distribution matching reward for expert demonstrations for the same task, allows agents to outperform a naive distributed baseline. Additional experiments probe the conditions under which expert demonstrations need to be sampled to obtain the learning benefits.},
  archive   = {C_AAAI},
  author    = {Caroline Wang and Ishan Durugkar and Elad Liebman and Peter Stone},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26382},
  pages     = {11699-11707},
  title     = {DM²: Decentralized multi-agent reinforcement learning via distribution matching},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Effective integration of weighted cost-to-go and conflict
heuristic within suboptimal CBS. <em>AAAI</em>, 11691–11698. (<a
href="https://doi.org/10.1609/aaai.v37i10.26381">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Conflict-Based Search (CBS) is a popular multi-agent path finding (MAPF) solver that employs a low-level single agent planner and a high-level constraint tree to resolve conflicts. The vast majority of modern MAPF solvers focus on improving CBS by reducing the size of this tree through various strategies with few methods modifying the low level planner. Typically low level planners in existing CBS methods use an unweighted cost-to-go heuristic, with suboptimal CBS methods also using a conflict heuristic to help the high level search. In this paper, we show that, contrary to prevailing CBS beliefs, a weighted cost-to-go heuristic can be used effectively alongside the conflict heuristic in two possible variants. In particular, one of these variants can obtain large speedups, 2-100x, across several scenarios and suboptimal CBS methods. Importantly, we discover that performance is related not to the weighted cost-to-go heuristic but rather to the relative conflict heuristic weight&#39;s ability to effectively balance low-level and high-level work. Additionally, to the best of our knowledge, we show the first theoretical relation of prioritized planning and bounded suboptimal CBS and demonstrate that our methods are their natural generalization.},
  archive   = {C_AAAI},
  author    = {Rishi Veerapaneni and Tushar Kusnur and Maxim Likhachev},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26381},
  pages     = {11691-11698},
  title     = {Effective integration of weighted cost-to-go and conflict heuristic within suboptimal CBS},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Resource sharing through multi-round matchings.
<em>AAAI</em>, 11681–11690. (<a
href="https://doi.org/10.1609/aaai.v37i10.26380">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Applications such as employees sharing office spaces over a workweek can be modeled as problems where agents are matched to resources over multiple rounds. Agents&#39; requirements limit the set of compatible resources and the rounds in which they want to be matched. Viewing such an application as a multi-round matching problem on a bipartite compatibility graph between agents and resources, we show that a solution (i.e., a set of matchings, with one matching per round) can be found efficiently if one exists. To cope with situations where a solution does not exist, we consider two extensions. In the first extension, a benefit function is defined for each agent and the objective is to find a multi-round matching to maximize the total benefit. For a general class of benefit functions satisfying certain properties (including diminishing returns), we show that this multi-round matching problem is efficiently solvable. This class includes utilitarian and Rawlsian welfare functions. For another benefit function, we show that the maximization problem is NP-hard. In the second extension, the objective is to generate advice to each agent (i.e., a subset of requirements to be relaxed) subject to a budget constraint so that the agent can be matched. We show that this budget-constrained advice generation problem is NP-hard. For this problem, we develop an integer linear programming formulation as well as a heuristic based on local search. We experimentally evaluate our algorithms on synthetic networks and apply them to two real-world situations: shared office spaces and matching courses to classrooms.},
  archive   = {C_AAAI},
  author    = {Yohai Trabelsi and Abhijin Adiga and Sarit Kraus and S. S. Ravi and Daniel J. Rosenkrantz},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26380},
  pages     = {11681-11690},
  title     = {Resource sharing through multi-round matchings},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning from good trajectories in offline multi-agent
reinforcement learning. <em>AAAI</em>, 11672–11680. (<a
href="https://doi.org/10.1609/aaai.v37i10.26379">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Offline multi-agent reinforcement learning (MARL) aims to learn effective multi-agent policies from pre-collected datasets, which is an important step toward the deployment of multi-agent systems in real-world applications. However, in practice, each individual behavior policy that generates multi-agent joint trajectories usually has a different level of how well it performs. e.g., an agent is a random policy while other agents are medium policies. In the cooperative game with global reward, one agent learned by existing offline MARL often inherits this random policy, jeopardizing the utility of the entire team. In this paper, we investigate offline MARL with explicit consideration on the diversity of agent-wise trajectories and propose a novel framework called Shared Individual Trajectories (SIT) to address this problem. Specifically, an attention-based reward decomposition network assigns the credit to each agent through a differentiable key-value memory mechanism in an offline manner. These decomposed credits are then used to reconstruct the joint offline datasets into prioritized experience replay with individual trajectories, thereafter agents can share their good trajectories and conservatively train their policies with a graph attention network (GAT) based critic. We evaluate our method in both discrete control (i.e., StarCraft II and multi-agent particle environment) and continuous control (i.e., multi-agent mujoco). The results indicate that our method achieves significantly better results in complex and mixed offline multi-agent datasets, especially when the difference of data quality between individual trajectories is large.},
  archive   = {C_AAAI},
  author    = {Qi Tian and Kun Kuang and Furui Liu and Baoxiang Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26379},
  pages     = {11672-11680},
  title     = {Learning from good trajectories in offline multi-agent reinforcement learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Networked anti-coordination games meet graphical dynamical
systems: Equilibria and convergence. <em>AAAI</em>, 11663–11671. (<a
href="https://doi.org/10.1609/aaai.v37i10.26378">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Evolutionary anti-coordination games on networks capture real-world strategic situations such as traffic routing and market competition. Two key problems concerning evolutionary games are the existence of a pure Nash equilibrium (NE) and the convergence time. In this work, we study these two problems for anti-coordination games under sequential and synchronous update schemes. For each update scheme, we examine two decision modes based on whether an agent considers its own previous action (self essential) or not (self non-essential) in choosing its next action. Using a relationship between games and dynamical systems, we show that for both update schemes, finding an NE can be done efficiently under the self non-essential mode but is computationally intractable under the self essential mode. We then identify special cases for which an NE can be obtained efficiently. For convergence time, we show that the dynamics converges in a polynomial number of steps under the synchronous scheme; for the sequential scheme, the convergence time is polynomial only under the self non-essential mode. Through experiments, we empirically examine the convergence time and the equilibria for both synthetic and real-world networks.},
  archive   = {C_AAAI},
  author    = {Zirou Qiu and Chen Chen and Madhav V. Marathe and S. S. Ravi and Daniel J. Rosenkrantz and Richard E. Stearns and Anil Vullikanti},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26378},
  pages     = {11663-11671},
  title     = {Networked anti-coordination games meet graphical dynamical systems: Equilibria and convergence},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). LaCAM: Search-based algorithm for quick multi-agent
pathfinding. <em>AAAI</em>, 11655–11662. (<a
href="https://doi.org/10.1609/aaai.v37i10.26377">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose a novel complete algorithm for multi-agent pathfinding (MAPF) called lazy constraints addition search for MAPF (LaCAM). MAPF is a problem of finding collision-free paths for multiple agents on graphs and is the foundation of multi-robot coordination. LaCAM uses a two-level search to find solutions quickly, even with hundreds of agents or more. At the low-level, it searches constraints about agents&#39; locations. At the high-level, it searches a sequence of all agents&#39; locations, following the constraints specified by the low-level. Our exhaustive experiments reveal that LaCAM is comparable to or outperforms state-of-the-art sub-optimal MAPF algorithms in a variety of scenarios, regarding success rate, planning time, and solution quality of sum-of-costs.},
  archive   = {C_AAAI},
  author    = {Keisuke Okumura},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26377},
  pages     = {11655-11662},
  title     = {LaCAM: Search-based algorithm for quick multi-agent pathfinding},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fault-tolerant offline multi-agent path planning.
<em>AAAI</em>, 11647–11654. (<a
href="https://doi.org/10.1609/aaai.v37i10.26376">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study a novel graph path planning problem for multiple agents that may crash at runtime, and block part of the workspace. In our setting, agents can detect neighboring crashed agents, and change followed paths at runtime. The objective is then to prepare a set of paths and switching rules for each agent, ensuring that all correct agents reach their destinations without collisions or deadlocks, despite unforeseen crashes of other agents. Such planning is attractive to build reliable multi-robot systems. We present problem formalization, theoretical analysis such as computational complexities, and how to solve this offline planning problem.},
  archive   = {C_AAAI},
  author    = {Keisuke Okumura and Sébastien Tixeuil},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26376},
  pages     = {11647-11654},
  title     = {Fault-tolerant offline multi-agent path planning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Socially optimal non-discriminatory restrictions for
continuous-action games. <em>AAAI</em>, 11638–11646. (<a
href="https://doi.org/10.1609/aaai.v37i10.26375">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We address the following mechanism design problem: Given a multi-player Normal-Form Game (NFG) with a continuous action space, find a non-discriminatory (i.e., identical for all players) restriction of the action space which maximizes the resulting Nash Equilibrium with respect to a fixed social utility function. First, we propose a formal model of a Restricted Game and the corresponding restriction optimization problem. We then present an algorithm to find optimal non-discriminatory restrictions under some assumptions. Our experimental results with Braess&#39; Paradox and the Cournot Game show that this method leads to an optimized social utility of the Nash Equilibria, even when the assumptions are not guaranteed to hold. Finally, we outline a generalization of our approach to the much wider scope of Stochastic Games.},
  archive   = {C_AAAI},
  author    = {Michael Oesterle and Guni Sharon},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26375},
  pages     = {11638-11646},
  title     = {Socially optimal non-discriminatory restrictions for continuous-action games},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Memory-augmented theory of mind network. <em>AAAI</em>,
11630–11637. (<a
href="https://doi.org/10.1609/aaai.v37i10.26374">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Social reasoning necessitates the capacity of theory of mind (ToM), the ability to contextualise and attribute mental states to others without having access to their internal cognitive structure. Recent machine learning approaches to ToM have demonstrated that we can train the observer to read the past and present behaviours of other agents and infer their beliefs (including false beliefs about things that no longer exist), goals, intentions and future actions. The challenges arise when the behavioural space is complex, demanding skilful space navigation for rapidly changing contexts for an extended period. We tackle the challenges by equipping the observer with novel neural memory mechanisms to encode, and hierarchical attention to selectively retrieve information about others. The memories allow rapid, selective querying of distal related past behaviours of others to deliberatively reason about their current mental state, beliefs and future behaviours. This results in ToMMY, a theory of mind model that learns to reason while making little assumptions about the underlying mental processes. We also construct a new suite of experiments to demonstrate that memories facilitate the learning process and achieve better theory of mind performance, especially for high-demand false-belief tasks that require inferring through multiple steps of changes.},
  archive   = {C_AAAI},
  author    = {Dung Nguyen and Phuoc Nguyen and Hung Le and Kien Do and Svetha Venkatesh and Truyen Tran},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26374},
  pages     = {11630-11637},
  title     = {Memory-augmented theory of mind network},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Formal verification of bayesian mechanisms. <em>AAAI</em>,
11621–11629. (<a
href="https://doi.org/10.1609/aaai.v37i10.26373">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, for the first time, we study the formal verification of Bayesian mechanisms through strategic reasoning. We rely on the framework of Probabilistic Strategy Logic (PSL), which is well-suited for representing and verifying multi-agent systems with incomplete information. We take advantage of the recent results on the decidability of PSL model checking under memoryless strategies, and reduce the problem of formally verifying Bayesian mechanisms to PSL model checking. We show how to encode Bayesian-Nash equilibrium and economical properties, and illustrate our approach with different kinds of mechanisms.},
  archive   = {C_AAAI},
  author    = {Munyque Mittelmann and Bastien Maubert and Aniello Murano and Laurent Perrussel},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26373},
  pages     = {11621-11629},
  title     = {Formal verification of bayesian mechanisms},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reconstructing an epidemic outbreak using steiner
connectivity. <em>AAAI</em>, 11613–11620. (<a
href="https://doi.org/10.1609/aaai.v37i10.26372">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Only a subset of infections is actually observed in an outbreak, due to multiple reasons such as asymptomatic cases and under-reporting. Therefore, reconstructing an epidemic cascade given some observed cases is an important step in responding to such an outbreak. A maximum likelihood solution to this problem ( referred to as CascadeMLE ) can be shown to be a variation of the classical Steiner subgraph problem, which connects a subset of observed infections. In contrast to prior works on epidemic reconstruction, which consider the standard Steiner tree objective, we show that a solution to CascadeMLE, based on the actual MLE objective, has a very different structure. We design a logarithmic approximation algorithm for CascadeMLE, and evaluate it on multiple synthetic and social contact networks, including a contact network constructed for a hospital. Our algorithm has significantly better performance compared to a prior baseline.},
  archive   = {C_AAAI},
  author    = {Ritwick Mishra and Jack Heavey and Gursharn Kaur and Abhijin Adiga and Anil Vullikanti},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26372},
  pages     = {11613-11620},
  title     = {Reconstructing an epidemic outbreak using steiner connectivity},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning to shape rewards using a game of two partners.
<em>AAAI</em>, 11604–11612. (<a
href="https://doi.org/10.1609/aaai.v37i10.26371">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Reward shaping (RS) is a powerful method in reinforcement learning (RL) for overcoming the problem of sparse or uninformative rewards. However, RS typically relies on manually engineered shaping-reward functions whose construc- tion is time-consuming and error-prone. It also requires domain knowledge which runs contrary to the goal of autonomous learning. We introduce Reinforcement Learning Optimising Shaping Algorithm (ROSA), an automated reward shaping framework in which the shaping-reward function is constructed in a Markov game between two agents. A reward-shaping agent (Shaper) uses switching controls to determine which states to add shaping rewards for more efficient learning while the other agent (Controller) learns the optimal policy for the task using these shaped rewards. We prove that ROSA, which adopts existing RL algorithms, learns to construct a shaping-reward function that is beneficial to the task thus ensuring efficient convergence to high performance policies. We demonstrate ROSA’s properties in three didactic experiments and show its superior performance against state-of-the-art RS algorithms in challenging sparse reward environments.},
  archive   = {C_AAAI},
  author    = {David Mguni and Taher Jafferjee and Jianhong Wang and Nicolas Perez-Nieves and Wenbin Song and Feifei Tong and Matthew Taylor and Tianpei Yang and Zipeng Dai and Hui Chen and Jiangcheng Zhu and Kun Shao and Jun Wang and Yaodong Yang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26371},
  pages     = {11604-11612},
  title     = {Learning to shape rewards using a game of two partners},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Contrastive identity-aware learning for multi-agent value
decomposition. <em>AAAI</em>, 11595–11603. (<a
href="https://doi.org/10.1609/aaai.v37i10.26370">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Value Decomposition (VD) aims to deduce the contributions of agents for decentralized policies in the presence of only global rewards, and has recently emerged as a powerful credit assignment paradigm for tackling cooperative Multi-Agent Reinforcement Learning (MARL) problems. One of the main challenges in VD is to promote diverse behaviors among agents, while existing methods directly encourage the diversity of learned agent networks with various strategies. However, we argue that these dedicated designs for agent networks are still limited by the indistinguishable VD network, leading to homogeneous agent behaviors and thus downgrading the cooperation capability. In this paper, we propose a novel Contrastive Identity-Aware learning (CIA) method, explicitly boosting the credit-level distinguishability of the VD network to break the bottleneck of multi-agent diversity. Specifically, our approach leverages contrastive learning to maximize the mutual information between the temporal credits and identity representations of different agents, encouraging the full expressiveness of credit assignment and further the emergence of individualities. The algorithm implementation of the proposed CIA module is simple yet effective that can be readily incorporated into various VD architectures. Experiments on the SMAC benchmarks and across different VD backbones demonstrate that the proposed method yields results superior to the state-of-the-art counterparts. Our code is available at https://github.com/liushunyu/CIA.},
  archive   = {C_AAAI},
  author    = {Shunyu Liu and Yihe Zhou and Jie Song and Tongya Zheng and Kaixuan Chen and Tongtian Zhu and Zunlei Feng and Mingli Song},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26370},
  pages     = {11595-11603},
  title     = {Contrastive identity-aware learning for multi-agent value decomposition},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023d). Solving large-scale pursuit-evasion games using pre-trained
strategies. <em>AAAI</em>, 11586–11594. (<a
href="https://doi.org/10.1609/aaai.v37i10.26369">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Pursuit-evasion games on graphs model the coordination of police forces chasing a fleeing felon in real-world urban settings, using the standard framework of imperfect-information extensive-form games (EFGs). In recent years, solving EFGs has been largely dominated by the Policy-Space Response Oracle (PSRO) methods due to their modularity, scalability, and favorable convergence properties. However, even these methods quickly reach their limits when facing large combinatorial strategy spaces of the pursuit-evasion games. To improve their efficiency, we integrate the pre-training and fine-tuning paradigm into the core module of PSRO -- the repeated computation of the best response. First, we pre-train the pursuer&#39;s policy base model against many different strategies of the evader. Then we proceed with the PSRO loop and fine-tune the pre-trained policy to attain the pursuer&#39;s best responses. The empirical evaluation shows that our approach significantly outperforms the baselines in terms of speed and scalability, and can solve even games on street maps of megalopolises with tens of thousands of crossroads -- a scale beyond the effective reach of previous methods.},
  archive   = {C_AAAI},
  author    = {Shuxin Li and Xinrun Wang and Youzhi Zhang and Wanqi Xue and Jakub Černý and Bo An},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26369},
  pages     = {11586-11594},
  title     = {Solving large-scale pursuit-evasion games using pre-trained strategies},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Intersection coordination with priority-based search for
autonomous vehicles. <em>AAAI</em>, 11578–11585. (<a
href="https://doi.org/10.1609/aaai.v37i10.26368">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The development of connected and autonomous vehicles opens an opportunity to manage intersections without signals. One promising approach is to use a central autonomous intersection manager to optimize the movement of the vehicles in the intersection. Existing work uses Mixed Integer Linear Programming (MILP) to find optimal solutions for this problem but is time-consuming and cannot be applied in real-time. On the other hand, the coordination of the vehicles is essentially a Multi-Agent Path Finding (MAPF) problem, for which dozens of efficient algorithms have been proposed in recent years. Inspired by these MAPF algorithms, we propose a three-level algorithm called PSL to solve the intersection coordination problem. Theoretically, PSL is complete and polynomial-time in the number of vehicles. Empirically, PSL runs significantly faster with only a slight compromise in the solution quality than the optimal MILP method. It also generates significantly better solutions with a slightly larger runtime than the traditional First-Come-First-Served strategy.},
  archive   = {C_AAAI},
  author    = {Jiaoyang Li and The Anh Hoang and Eugene Lin and Hai L. Vu and Sven Koenig},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26368},
  pages     = {11578-11585},
  title     = {Intersection coordination with priority-based search for autonomous vehicles},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reward-based negotiating agent strategies. <em>AAAI</em>,
11569–11577. (<a
href="https://doi.org/10.1609/aaai.v37i10.26367">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This study proposed a novel reward-based negotiating agent strategy using an issue-based represented deep policy network. We compared the negotiation strategies with reinforcement learning (RL) by the tournaments toward heuristics-based champion agents in multi-issue negotiation. A bilateral multi-issue negotiation in which the two agents exchange offers in turn was considered. Existing RL architectures for a negotiation strategy incorporate rich utility function that provides concrete information even though the rewards of RL are considered as generalized signals in practice. Additionally, in existing reinforcement learning architectures for negotiation strategies, both the issue-based representations of the negotiation problems and the policy network to improve the scalability of negotiation domains are yet to be considered. This study proposed a novel reward-based negotiation strategy through deep RL by considering an issue-based represented deep policy network for multi-issue negotiation. Comparative studies analyzed the significant properties of negotiation strategies with RL. The results revealed that the policy-based learning agents with issue-based representations achieved comparable or higher utility than the state-of-the-art baselines with RL and heuristics, especially in the large-sized domains. Additionally, negotiation strategies with RL based on the policy network can achieve agreements by effectively using each step.},
  archive   = {C_AAAI},
  author    = {Ryota Higa and Katsuhide Fujita and Toki Takahashi and Takumu Shimizu and Shinji Nakadai},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26367},
  pages     = {11569-11577},
  title     = {Reward-based negotiating agent strategies},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-unit auctions for allocating chance-constrained
resources. <em>AAAI</em>, 11560–11568. (<a
href="https://doi.org/10.1609/aaai.v37i10.26366">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Sharing scarce resources is a key challenge in multi-agent interaction, especially when individual agents are uncertain about their future consumption. We present a new auction mechanism for preallocating multi-unit resources among agents, while limiting the chance of resource violations. By planning for a chance constraint, we strike a balance between worst-case approaches, which under-utilise resources, and expected-case approaches, which lack formal guarantees. We also present an algorithm that allows agents to generate bids via multi-objective reasoning, which are then submitted to the auction. We then discuss how the auction can be extended to non-cooperative scenarios. Finally, we demonstrate empirically that our auction outperforms state-of-the-art techniques for chance-constrained multi-agent resource allocation in complex settings with up to hundreds of agents.},
  archive   = {C_AAAI},
  author    = {Anna Gautier and Bruno Lacerda and Nick Hawes and Michael Wooldridge},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26366},
  pages     = {11560-11568},
  title     = {Multi-unit auctions for allocating chance-constrained resources},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Zero-shot assistance in sequential decision problems.
<em>AAAI</em>, 11551–11559. (<a
href="https://doi.org/10.1609/aaai.v37i10.26365">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider the problem of creating assistants that can help agents solve new sequential decision problems, assuming the agent is not able to specify the reward function explicitly to the assistant. Instead of acting in place of the agent as in current automation-based approaches, we give the assistant an advisory role and keep the agent in the loop as the main decision maker. The difficulty is that we must account for potential biases of the agent which may cause it to seemingly irrationally reject advice. To do this we introduce a novel formalization of assistance that models these biases, allowing the assistant to infer and adapt to them. We then introduce a new method for planning the assistant&#39;s actions which can scale to large decision making problems. We show experimentally that our approach adapts to these agent biases, and results in higher cumulative reward for the agent than automation-based alternatives. Lastly, we show that an approach combining advice and automation outperforms advice alone at the cost of losing some safety guarantees.},
  archive   = {C_AAAI},
  author    = {Sebastiaan De Peuter and Samuel Kaski},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26365},
  pages     = {11551-11559},
  title     = {Zero-shot assistance in sequential decision problems},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Learning explicit credit assignment for cooperative
multi-agent reinforcement learning via polarization policy gradient.
<em>AAAI</em>, 11542–11550. (<a
href="https://doi.org/10.1609/aaai.v37i10.26364">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Cooperative multi-agent policy gradient (MAPG) algorithms have recently attracted wide attention and are regarded as a general scheme for the multi-agent system. Credit assignment plays an important role in MAPG and can induce cooperation among multiple agents. However, most MAPG algorithms cannot achieve good credit assignment because of the game-theoretic pathology known as centralized-decentralized mismatch. To address this issue, this paper presents a novel method, Multi-Agent Polarization Policy Gradient (MAPPG). MAPPG takes a simple but efficient polarization function to transform the optimal consistency of joint and individual actions into easily realized constraints, thus enabling efficient credit assignment in MAPPG. Theoretically, we prove that individual policies of MAPPG can converge to the global optimum. Empirically, we evaluate MAPPG on the well-known matrix game and differential game, and verify that MAPPG can converge to the global optimum for both discrete and continuous action spaces. We also evaluate MAPPG on a set of StarCraft II micromanagement tasks and demonstrate that MAPPG outperforms the state-of-the-art MAPG algorithms.},
  archive   = {C_AAAI},
  author    = {Wubing Chen and Wenbin Li and Xiao Liu and Shangdong Yang and Yang Gao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26364},
  pages     = {11542-11550},
  title     = {Learning explicit credit assignment for cooperative multi-agent reinforcement learning via polarization policy gradient},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Emergent quantized communication. <em>AAAI</em>,
11533–11541. (<a
href="https://doi.org/10.1609/aaai.v37i10.26363">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The field of emergent communication aims to understand the characteristics of communication as it emerges from artificial agents solving tasks that require information exchange. Communication with discrete messages is considered a desired characteristic, for scientific and applied reasons. However, training a multi-agent system with discrete communication is not straightforward, requiring either reinforcement learning algorithms or relaxing the discreteness requirement via a continuous approximation such as the Gumbel-softmax. Both these solutions result in poor performance compared to fully continuous communication. In this work, we propose an alternative approach to achieve discrete communication -- quantization of communicated message. Using message quantization allows us to train the model end-to-end, achieving superior performance in multiple setups. Moreover, quantization is a natural framework that runs the gamut from continuous to discrete communication. Thus, it sets the ground for a broader view of multi-agent communication in the deep learning era.},
  archive   = {C_AAAI},
  author    = {Boaz Carmeli and Ron Meir and Yonatan Belinkov},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26363},
  pages     = {11533-11541},
  title     = {Emergent quantized communication},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The multi-agent transportation problem. <em>AAAI</em>,
11525–11532. (<a
href="https://doi.org/10.1609/aaai.v37i10.26362">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We introduce the multi-agent transportation (MAT) problem, where agents have to transport containers from their starting positions to their designated goal positions. Movement takes place in a common environment where collisions between agents and between containers must be avoided. In contrast to other frameworks such as multi-agent pathfinding (MAPF) or multi-agent pickup and delivery (MAPD), the agents are allowed to separate from the containers at any time, which can reduce the makespan and also allows for plans in scenarios that are unsolvable otherwise. We present a complexity analysis establishing the problem&#39;s NP-completeness and show how the problem can be reduced to a sequence of SAT problems when optimizing for makespan. A MAT solver is empirically evaluated with regard to varying input characteristics and movement constraints and compared to a MAPD solver that utilizes conflict-based search (CBS).},
  archive   = {C_AAAI},
  author    = {Pascal Bachor and Rolf-David Bergdoll and Bernhard Nebel},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26362},
  pages     = {11525-11532},
  title     = {The multi-agent transportation problem},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Synchronization and diversity of solutions. <em>AAAI</em>,
11516–11524. (<a
href="https://doi.org/10.1609/aaai.v37i10.26361">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A central computational problem in the realm of automata theory is the problem of determining whether a finite automaton A has a synchronizing word. This problem has found applications in a variety of subfields of artificial intelligence, including planning, robotics, and multi-agent systems. In this work, we study this problem within the framework of diversity of solutions, an up-and-coming trend in the field of artificial intelligence where the goal is to compute a set of solutions that are sufficiently distinct from one another. We define a notion of diversity of solutions that is suitable for contexts were solutions are strings that may have distinct lengths. Using our notion of diversity, we show that for each fixed r ∈ N, each fixed finite automaton A, and each finite automaton B given at the input, the problem of determining the existence of a diverse set {w1,w2, . . . ,wr} ⊆ L(B) of words that are synchronizing for A can be solved in polynomial time. Finally, we generalize this result to the realm of conformant planning, where the goal is to devise plans that achieve a goal irrespectively of initial conditions and of nondeterminism that may occur during their execution.},
  archive   = {C_AAAI},
  author    = {Emmanuel Arrighi and Henning Fernau and Mateus de Oliveira Oliveira and Petra Wolf},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i10.26361},
  pages     = {11516-11524},
  title     = {Synchronization and diversity of solutions},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mixed-variable black-box optimisation using value proposal
trees. <em>AAAI</em>, 11506–11514. (<a
href="https://doi.org/10.1609/aaai.v37i9.26360">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Many real-world optimisation problems are defined over both categorical and continuous variables, yet efficient optimisation methods such as Bayesian Optimisation (BO) are ill-equipped to handle such mixed-variable search spaces. The optimisation breadth introduced by categorical variables in the mixed-input setting has seen recent approaches operating on local trust regions, but these methods can be greedy in suboptimal regions of the search space. In this paper, we adopt a holistic view and aim to consolidate optimisation of the categorical and continuous sub-spaces under a single acquisition metric. We develop a tree-based method which retains a global view of the optimisation spaces by identifying regions in the search space with high potential candidates which we call value proposals. Our method uses these proposals to make selections on both the categorical and continuous components of the input. We show that this approach significantly outperforms existing mixed-variable optimisation approaches across several mixed-variable black-box optimisation tasks.},
  archive   = {C_AAAI},
  author    = {Yan Zuo and Vu Nguyen and Amir Dezfouli and David Alexander and Benjamin Ward Muir and Iadine Chades},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26360},
  pages     = {11506-11514},
  title     = {Mixed-variable black-box optimisation using value proposal trees},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SVP-t: A shape-level variable-position transformer for
multivariate time series classification. <em>AAAI</em>, 11497–11505. (<a
href="https://doi.org/10.1609/aaai.v37i9.26359">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multivariate time series classiﬁcation (MTSC), one of the most fundamental time series applications, has not only gained substantial research attentions but has also emerged in many real-life applications. Recently, using transformers to solve MTSC has been reported. However, current transformer-based methods take data points of individual timestamps as inputs (timestamp-level), which only capture the temporal dependencies, not the dependencies among variables. In this paper, we propose a novel method, called SVP-T. Specifically, we ﬁrst propose to take time series subsequences, which can be from different variables and positions (time interval), as the inputs (shape-level). The temporal and variable dependencies are both handled by capturing the long- and short-term dependencies among shapes. Second, we propose a variable-position encoding layer (VP-layer) to utilize both the variable and position information of each shape. Third, we introduce a novel VP-based (Variable-Position) self-attention mechanism to allow the enhancing the attention weights of overlapping shapes. We evaluate our method on all UEA MTS datasets. SVP-T achieves the best accuracy rank when compared with several competitive state-of-the-art methods. Furthermore, we demonstrate the effectiveness of the VP-layer and the VP-based self-attention mechanism. Finally, we present one case study to interpret the result of SVP-T.},
  archive   = {C_AAAI},
  author    = {Rundong Zuo and Guozhong Li and Byron Choi and Sourav S Bhowmick and Daphne Ngar-yin Mah and Grace L.H. Wong},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26359},
  pages     = {11497-11505},
  title     = {SVP-T: A shape-level variable-position transformer for multivariate time series classification},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ILSGAN: Independent layer synthesis for unsupervised
foreground-background segmentation. <em>AAAI</em>, 11488–11496. (<a
href="https://doi.org/10.1609/aaai.v37i9.26358">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Unsupervised foreground-background segmentation aims at extracting salient objects from cluttered backgrounds, where Generative Adversarial Network (GAN) approaches, especially layered GANs, show great promise. However, without human annotations, they are typically prone to produce foreground and background layers with non-negligible semantic and visual confusion, dubbed &quot;information leakage&quot;, resulting in notable degeneration of the generated segmentation mask. To alleviate this issue, we propose a simple-yet-effective explicit layer independence modeling approach, termed Independent Layer Synthesis GAN (ILSGAN), pursuing independent foreground-background layer generation by encouraging their discrepancy. Specifically, it targets minimizing the mutual information between visible and invisible regions of the foreground and background to spur interlayer independence. Through in-depth theoretical and experimental analyses, we justify that explicit layer independence modeling is critical to suppressing information leakage and contributes to impressive segmentation performance gains. Also, our ILSGAN achieves strong state-of-the-art generation quality and segmentation performance on complex real-world data.},
  archive   = {C_AAAI},
  author    = {Qiran Zou and Yu Yang and Wing Yin Cheung and Chang Liu and Xiangyang Ji},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26358},
  pages     = {11488-11496},
  title     = {ILSGAN: Independent layer synthesis for unsupervised foreground-background segmentation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Locate then generate: Bridging vision and language with
bounding box for scene-text VQA. <em>AAAI</em>, 11479–11487. (<a
href="https://doi.org/10.1609/aaai.v37i9.26357">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we propose a novel multi-modal framework for Scene Text Visual Question Answering (STVQA), which requires models to read scene text in images for question answering. Apart from text or visual objects, which could exist independently, scene text naturally links text and visual modalities together by conveying linguistic semantics while being a visual object in an image simultaneously. Different to conventional STVQA models which take the linguistic semantics and visual semantics in scene text as two separate features, in this paper, we propose a paradigm of &quot;Locate Then Generate&quot; (LTG), which explicitly unifies this two semantics with the spatial bounding box as a bridge connecting them. Specifically, at first, LTG locates the region in an image that may contain the answer words with an answer location module (ALM) consisting of a region proposal network and a language refinement network, both of which can transform to each other with one-to-one mapping via the scene text bounding box. Next, given the answer words selected by ALM, LTG generates a readable answer sequence with an answer generation module (AGM) based on a pre-trained language model. As a benefit of the explicit alignment of the visual and linguistic semantics, even without any scene text based pre-training tasks, LTG can boost the absolute accuracy by +6.06\% and +6.92\% on the TextVQA dataset and the ST-VQA dataset respectively, compared with a non-pre-training baseline. We further demonstrate that LTG effectively unifies visual and text modalities through the spatial bounding box connection, which is underappreciated in previous methods.},
  archive   = {C_AAAI},
  author    = {Yongxin Zhu and Zhen Liu and Yukang Liang and Xin Li and Hao Liu and Changcun Bao and Linli Xu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26357},
  pages     = {11479-11487},
  title     = {Locate then generate: Bridging vision and language with bounding box for scene-text VQA},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ContraFeat: Contrasting deep features for semantic
discovery. <em>AAAI</em>, 11470–11478. (<a
href="https://doi.org/10.1609/aaai.v37i9.26356">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {StyleGAN has shown strong potential for disentangled semantic control, thanks to its special design of multi-layer intermediate latent variables. However, existing semantic discovery methods on StyleGAN rely on manual selection of modified latent layers to obtain satisfactory manipulation results, which is tedious and demanding. In this paper, we propose a model that automates this process and achieves state-of-the-art semantic discovery performance. The model consists of an attention-equipped navigator module and losses contrasting deep-feature changes. We propose two model variants, with one contrasting samples in a binary manner, and another one contrasting samples with learned prototype variation patterns. The proposed losses are computed with pretrained deep features, based on our assumption that the features implicitly possess the desired semantic variation structure including consistency and orthogonality. Additionally, we design two metrics to quantitatively evaluate the performance of semantic discovery methods on FFHQ dataset, and also show that disentangled representations can be derived via a simple training process. Experimentally, we show that our models achieve state-of-the-art semantic discovery results without relying on layer-wise manual selection, and these discovered semantics can be used to manipulate real-world images.},
  archive   = {C_AAAI},
  author    = {Xinqi Zhu and Chang Xu and Dacheng Tao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26356},
  pages     = {11470-11478},
  title     = {ContraFeat: Contrasting deep features for semantic discovery},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bayesian cross-modal alignment learning for few-shot
out-of-distribution generalization. <em>AAAI</em>, 11461–11469. (<a
href="https://doi.org/10.1609/aaai.v37i9.26355">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent advances in large pre-trained models showed promising results in few-shot learning. However, their generalization ability on two-dimensional Out-of-Distribution (OoD) data, i.e., correlation shift and diversity shift, has not been thoroughly investigated. Researches have shown that even with a significant amount of training data, few methods can achieve better performance than the standard empirical risk minimization method (ERM) in OoD generalization. This few-shot OoD generalization dilemma emerges as a challenging direction in deep neural network generalization research, where the performance suffers from overfitting on few-shot examples and OoD generalization errors. In this paper, leveraging a broader supervision source, we explore a novel Bayesian cross-modal image-text alignment learning method (Bayes-CAL) to address this issue. Specifically, the model is designed as only text representations are fine-tuned via a Bayesian modelling approach with gradient orthogonalization loss and invariant risk minimization (IRM) loss. The Bayesian approach is essentially introduced to avoid overfitting the base classes observed during training and improve generalization to broader unseen classes. The dedicated loss is introduced to achieve better image-text alignment by disentangling the causal and non-casual parts of image features. Numerical experiments demonstrate that Bayes-CAL achieved state-of-the-art OoD generalization performances on two-dimensional distribution shifts. Moreover, compared with CLIP-like models, Bayes-CAL yields more stable generalization performances on unseen classes. Our code is available at https://github.com/LinLLLL/BayesCAL.},
  archive   = {C_AAAI},
  author    = {Lin Zhu and Xinbing Wang and Chenghu Zhou and Nanyang Ye},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26355},
  pages     = {11461-11469},
  title     = {Bayesian cross-modal alignment learning for few-shot out-of-distribution generalization},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Quantized feature distillation for network quantization.
<em>AAAI</em>, 11452–11460. (<a
href="https://doi.org/10.1609/aaai.v37i9.26354">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Neural network quantization aims to accelerate and trim full-precision neural network models by using low bit approximations. Methods adopting the quantization aware training (QAT) paradigm have recently seen a rapid growth, but are often conceptually complicated. This paper proposes a novel and highly effective QAT method, quantized feature distillation (QFD). QFD first trains a quantized (or binarized) representation as the teacher, then quantize the network using knowledge distillation (KD). Quantitative results show that QFD is more flexible and effective (i.e., quantization friendly) than previous quantization methods. QFD surpasses existing methods by a noticeable margin on not only image classification but also object detection, albeit being much simpler. Furthermore, QFD quantizes ViT and Swin-Transformer on MS-COCO detection and segmentation, which verifies its potential in real world deployment. To the best of our knowledge, this is the first time that vision transformers have been quantized in object detection and image segmentation tasks.},
  archive   = {C_AAAI},
  author    = {Ke Zhu and Yin-Yin He and Jianxin Wu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26354},
  pages     = {11452-11460},
  title     = {Quantized feature distillation for network quantization},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Gradient-adaptive pareto optimization for constrained
reinforcement learning. <em>AAAI</em>, 11443–11451. (<a
href="https://doi.org/10.1609/aaai.v37i9.26353">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Constrained Reinforcement Learning (CRL) burgeons broad interest in recent years, which pursues maximizing long-term returns while constraining costs. Although CRL can be cast as a multi-objective optimization problem, it is still facing the key challenge that gradient-based Pareto optimization methods tend to stick to known Pareto-optimal solutions even when they yield poor returns (e.g., the safest self-driving car that never moves) or violate the constraints (e.g., the record-breaking racer that crashes the car). In this paper, we propose Gradient-adaptive Constrained Policy Optimization (GCPO for short), a novel Pareto optimization method for CRL with two adaptive gradient recalibration techniques. First, to find Pareto-optimal solutions with balanced performance over all targets, we propose gradient rebalancing which forces the agent to improve more on under-optimized objectives at every policy iteration. Second, to guarantee that the cost constraints are satisfied, we propose gradient perturbation that can temporarily sacrifice the returns for costs. Experiments on the SafetyGym benchmarks show that our method consistently outperforms previous CRL methods in reward while satisfying the constraints.},
  archive   = {C_AAAI},
  author    = {Zixian Zhou and Mengda Huang and Feiyang Pan and Jia He and Xiang Ao and Dandan Tu and Qing He},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26353},
  pages     = {11443-11451},
  title     = {Gradient-adaptive pareto optimization for constrained reinforcement learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). Combining adversaries with anti-adversaries in training.
<em>AAAI</em>, 11435–11442. (<a
href="https://doi.org/10.1609/aaai.v37i9.26352">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Adversarial training is an effective learning technique to improve the robustness of deep neural networks. In this study, the influence of adversarial training on deep learning models in terms of fairness, robustness, and generalization is theoretically investigated under more general perturbation scope that different samples can have different perturbation directions (the adversarial and anti-adversarial directions) and varied perturbation bounds. Our theoretical explorations suggest that the combination of adversaries and anti-adversaries (samples with anti-adversarial perturbations) in training can be more effective in achieving better fairness between classes and a better tradeoff between robustness and generalization in some typical learning scenarios (e.g., noisy label learning and imbalance learning) compared with standard adversarial training. On the basis of our theoretical findings, a more general learning objective that combines adversaries and anti-adversaries with varied bounds on each training sample is presented. Meta learning is utilized to optimize the combination weights. Experiments on benchmark datasets under different learning scenarios verify our theoretical findings and the effectiveness of the proposed methodology.},
  archive   = {C_AAAI},
  author    = {Xiaoling Zhou and Nan Yang and Ou Wu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26352},
  pages     = {11435-11442},
  title     = {Combining adversaries with anti-adversaries in training},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Robust temporal smoothness in multi-task learning.
<em>AAAI</em>, 11426–11434. (<a
href="https://doi.org/10.1609/aaai.v37i9.26351">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-task learning models based on temporal smoothness assumption, in which each time point of a sequence of time points concerns a task of prediction, assume the adjacent tasks are similar to each other. However, the effect of outliers is not taken into account. In this paper, we show that even only one outlier task will destroy the performance of the entire model. To solve this problem, we propose two Robust Temporal Smoothness (RoTS) frameworks. Compared with the existing models based on temporal relation, our methods not only chase the temporal smoothness information but identify outlier tasks, however, without increasing the computational complexity. Detailed theoretical analyses are presented to evaluate the performance of our methods. Experimental results on synthetic and real-life datasets demonstrate the effectiveness of our frameworks. We also discuss several potential specific applications and extensions of our RoTS frameworks.},
  archive   = {C_AAAI},
  author    = {Menghui Zhou and Yu Zhang and Yun Yang and Tong Liu and Po Yang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26351},
  pages     = {11426-11434},
  title     = {Robust temporal smoothness in multi-task learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SLOTH: Structured learning and task-based optimization for
time series forecasting on hierarchies. <em>AAAI</em>, 11417–11425. (<a
href="https://doi.org/10.1609/aaai.v37i9.26350">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multivariate time series forecasting with hierarchical structure is widely used in real-world applications, e.g., sales predictions for the geographical hierarchy formed by cities, states, and countries. The hierarchical time series (HTS) forecasting includes two sub-tasks, i.e., forecasting and reconciliation. In the previous works, hierarchical information is only integrated in the reconciliation step to maintain coherency, but not in forecasting step for accuracy improvement. In this paper, we propose two novel tree-based feature integration mechanisms, i.e., top-down convolution and bottom-up attention to leverage the information of the hierarchical structure to improve the forecasting performance. Moreover, unlike most previous reconciliation methods which either rely on strong assumptions or focus on coherent constraints only, we utilize deep neural optimization networks, which not only achieve coherency without any assumptions, but also allow more flexible and realistic constraints to achieve task-based targets, e.g., lower under-estimation penalty and meaningful decision-making loss to facilitate the subsequent downstream tasks. Experiments on real-world datasets demonstrate that our tree-based feature integration mechanism achieves superior performances on hierarchical forecasting tasks compared to the state-of-the-art methods, and our neural optimization networks can be applied to real-world tasks effectively without any additional effort under coherence and task-based constraints.},
  archive   = {C_AAAI},
  author    = {Fan Zhou and Chen Pan and Lintao Ma and Yu Liu and Shiyu Wang and James Zhang and Xinxin Zhu and Xuanwei Hu and Yunhua Hu and Yangfei Zheng and Lei Lei and Hu Yun},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26350},
  pages     = {11417-11425},
  title     = {SLOTH: Structured learning and task-based optimization for time series forecasting on hierarchies},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Does it pay to optimize AUC? <em>AAAI</em>, 11408–11416. (<a
href="https://doi.org/10.1609/aaai.v37i9.26349">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Area Under the ROC Curve (AUC) is an important model metric for evaluating binary classifiers, and many algorithms have been proposed to optimize AUC approximately. It raises the question of whether the generally insignificant gains observed by previous studies are due to inherent limitations of the metric or the inadequate quality of optimization. To better understand the value of optimizing for AUC, we present an efficient algorithm, namely AUC-opt, to find the provably optimal AUC linear classifier in R2, which runs in O(n+n- log n+n-) where n+ and n- are the number of positive and negative samples respectively. Furthermore, it can be naturally extended to Rd in O(n+n-d-1 log (n+n-)) by recursively calling AUC-opt in lower-dimensional spaces. We prove the problem is NP-complete when d is not fixed, reducing from the open hemisphere problem. Compared with other methods, experiments show that AUC-opt achieves statistically significant improvements between 17 to 40 in R2 and 4 to 42 in R3 of 50 t-SNE training datasets. However, generally, the gain proves insignificant on most testing datasets compared to the best standard classifiers. Similar observations are found for nonlinear AUC methods under real-world datasets.},
  archive   = {C_AAAI},
  author    = {Baojian Zhou and Steven Skiena},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26349},
  pages     = {11408-11416},
  title     = {Does it pay to optimize AUC?},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data imputation with iterative graph reconstruction.
<em>AAAI</em>, 11399–11407. (<a
href="https://doi.org/10.1609/aaai.v37i9.26348">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Effective data imputation demands rich latent ``structure&quot; discovery capabilities from ``plain&quot; tabular data. Recent advances in graph neural networks-based data imputation solutions show their structure learning potentials by translating tabular data as bipartite graphs. However, due to a lack of relations between samples, they treat all samples equally which is against one important observation: ``similar sample should give more information about missing values.&quot; This paper presents a novel Iterative graph Generation and Reconstruction framework for Missing data imputation(IGRM). Instead of treating all samples equally, we introduce the concept: ``friend networks&quot; to represent different relations among samples. To generate an accurate friend network with missing data, an end-to-end friend network reconstruction solution is designed to allow for continuous friend network optimization during imputation learning. The representation of the optimized friend network, in turn, is used to further optimize the data imputation process with differentiated message passing. Experiment results on eight benchmark datasets show that IGRM yields 39.13\% lower mean absolute error compared with nine baselines and 9.04\% lower than the second-best. Our code is available at https://github.com/G-AILab/IGRM.},
  archive   = {C_AAAI},
  author    = {Jiajun Zhong and Ning Gui and Weiwei Ye},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26348},
  pages     = {11399-11407},
  title     = {Data imputation with iterative graph reconstruction},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CowClip: Reducing CTR prediction model training time from 12
hours to 10 minutes on 1 GPU. <em>AAAI</em>, 11390–11398. (<a
href="https://doi.org/10.1609/aaai.v37i9.26347">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The click-through rate (CTR) prediction task is to predict whether a user will click on the recommended item. As mind-boggling amounts of data are produced online daily, accelerating CTR prediction model training is critical to ensuring an up-to-date model and reducing the training cost. One approach to increase the training speed is to apply large batch training. However, as shown in computer vision and natural language processing tasks, training with a large batch easily suffers from the loss of accuracy. Our experiments show that previous scaling rules fail in the training of CTR prediction neural networks. To tackle this problem, we first theoretically show that different frequencies of ids make it challenging to scale hyperparameters when scaling the batch size. To stabilize the training process in a large batch size setting, we develop the adaptive Column-wise Clipping (CowClip). It enables an easy and effective scaling rule for the embeddings, which keeps the learning rate unchanged and scales the L2 loss. We conduct extensive experiments with four CTR prediction networks on two real-world datasets and successfully scaled 128 times the original batch size without accuracy loss. In particular, for CTR prediction model DeepFM training on the Criteo dataset, our optimization framework enlarges the batch size from 1K to 128K with over 0.1\% AUC improvement and reduces training time from 12 hours to 10 minutes on a single V100 GPU. Our code locates at github.com/bytedance/LargeBatchCTR.},
  archive   = {C_AAAI},
  author    = {Zangwei Zheng and Pengtai Xu and Xuan Zou and Da Tang and Zhen Li and Chenguang Xi and Peng Wu and Leqi Zou and Yijie Zhu and Ming Chen and Xiangzhuo Ding and Fuzhao Xue and Ziheng Qin and Youlong Cheng and Yang You},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26347},
  pages     = {11390-11398},
  title     = {CowClip: Reducing CTR prediction model training time from 12 hours to 10 minutes on 1 GPU},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-level confidence learning for trustworthy multimodal
classification. <em>AAAI</em>, 11381–11389. (<a
href="https://doi.org/10.1609/aaai.v37i9.26346">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With the rapid development of various data acquisition technologies, more and more multimodal data come into being. It is important to integrate different modalities which are with high-dimensional features for boosting final multimodal data classification task. However, existing multimodal classification methods mainly focus on exploiting the complementary information of different modalities, while ignoring the learning confidence during information fusion. In this paper, we propose a trustworthy multimodal classification network via multi-level confidence learning, referred to as MLCLNet. Considering that a large number of feature dimensions could not contribute to final classification performance but disturb the discriminability of different samples, we propose a feature confidence learning mechanism to suppress some redundant features, as well as enhancing the expression of discriminative feature dimensions in each modality. In order to capture the inherent sample structure information implied in each modality, we design a graph convolutional network branch to learn the corresponding structure preserved feature representation and generate modal-specific initial classification labels. Since samples from different modalities should share consistent labels, a cross-modal label fusion module is deployed to capture the label correlations of different modalities. In addition, motivated the ideally orthogonality of final fused label matrix, we design a label confidence loss to supervise the network for learning more separable data representations. To the best of our knowledge, MLCLNet is the first work which integrates both feature and label-level confidence learning for multimodal classification. Extensive experiments on four multimodal medical datasets are conducted to validate superior performance of MLCLNet when compared to other state-of-the-art methods.},
  archive   = {C_AAAI},
  author    = {Xiao Zheng and Chang Tang and Zhiguo Wan and Chengyu Hu and Wei Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26346},
  pages     = {11381-11389},
  title     = {Multi-level confidence learning for trustworthy multimodal classification},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive policy learning for offline-to-online reinforcement
learning. <em>AAAI</em>, 11372–11380. (<a
href="https://doi.org/10.1609/aaai.v37i9.26345">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Conventional reinforcement learning (RL) needs an environment to collect fresh data, which is impractical when online interactions are costly. Offline RL provides an alternative solution by directly learning from the previously collected dataset. However, it will yield unsatisfactory performance if the quality of the offline datasets is poor. In this paper, we consider an offline-to-online setting where the agent is first learned from the offline dataset and then trained online, and propose a framework called Adaptive Policy Learning for effectively taking advantage of offline and online data. Specifically, we explicitly consider the difference between the online and offline data and apply an adaptive update scheme accordingly, that is, a pessimistic update strategy for the offline dataset and an optimistic/greedy update scheme for the online dataset. Such a simple and effective method provides a way to mix the offline and online RL and achieve the best of both worlds. We further provide two detailed algorithms for implementing the framework through embedding value or policy-based RL algorithms into it. Finally, we conduct extensive experiments on popular continuous control tasks, and results show that our algorithm can learn the expert policy with high sample efficiency even when the quality of offline dataset is poor, e.g., random dataset.},
  archive   = {C_AAAI},
  author    = {Han Zheng and Xufang Luo and Pengfei Wei and Xuan Song and Dongsheng Li and Jing Jiang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26345},
  pages     = {11372-11380},
  title     = {Adaptive policy learning for offline-to-online reinforcement learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). Fairness and explainability: Bridging the gap towards fair
model explanations. <em>AAAI</em>, 11363–11371. (<a
href="https://doi.org/10.1609/aaai.v37i9.26344">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {While machine learning models have achieved unprecedented success in real-world applications, they might make biased/unfair decisions for specific demographic groups and hence result in discriminative outcomes. Although research efforts have been devoted to measuring and mitigating bias, they mainly study bias from the result-oriented perspective while neglecting the bias encoded in the decision-making procedure. This results in their inability to capture procedure-oriented bias, which therefore limits the ability to have a fully debiasing method. Fortunately, with the rapid development of explainable machine learning, explanations for predictions are now available to gain insights into the procedure. In this work, we bridge the gap between fairness and explainability by presenting a novel perspective of procedure-oriented fairness based on explanations. We identify the procedure-based bias by measuring the gap of explanation quality between different groups with Ratio-based and Value-based Explanation Fairness. The new metrics further motivate us to design an optimization objective to mitigate the procedure-based bias where we observe that it will also mitigate bias from the prediction. Based on our designed optimization objective, we propose a Comprehensive Fairness Algorithm (CFA), which simultaneously fulfills multiple objectives - improving traditional fairness, satisfying explanation fairness, and maintaining the utility performance. Extensive experiments on real-world datasets demonstrate the effectiveness of our proposed CFA and highlight the importance of considering fairness from the explainability perspective. Our code: https://github.com/YuyingZhao/FairExplanations-CFA.},
  archive   = {C_AAAI},
  author    = {Yuying Zhao and Yu Wang and Tyler Derr},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26344},
  pages     = {11363-11371},
  title     = {Fairness and explainability: Bridging the gap towards fair model explanations},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AutoGraph: Optimizing DNN computation graph for parallel GPU
kernel execution. <em>AAAI</em>, 11354–11362. (<a
href="https://doi.org/10.1609/aaai.v37i9.26343">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep learning frameworks optimize the computation graphs and intra-operator computations to boost the inference performance on GPUs, while inter-operator parallelism is usually ignored. In this paper, a unified framework, AutoGraph, is proposed to obtain highly optimized computation graphs in favor of parallel executions of GPU kernels. A novel dynamic programming algorithm, combined with backtracking search, is adopted to explore the optimal graph optimization solution, with the fast performance estimation from the mixed critical path cost. Accurate runtime information based on GPU Multi-Stream launched with CUDA Graph is utilized to determine the convergence of the optimization. Experimental results demonstrate that our method achieves up to 3.47x speedup over existing graph optimization methods. Moreover, AutoGraph outperforms state-of-the-art parallel kernel launch frameworks by up to 1.26x.},
  archive   = {C_AAAI},
  author    = {Yuxuan Zhao and Qi Sun and Zhuolun He and Yang Bai and Bei Yu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26343},
  pages     = {11354-11362},
  title     = {AutoGraph: Optimizing DNN computation graph for parallel GPU kernel execution},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CoopInit: Initializing generative adversarial networks via
cooperative learning. <em>AAAI</em>, 11345–11353. (<a
href="https://doi.org/10.1609/aaai.v37i9.26342">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Numerous research efforts have been made to stabilize the training of the Generative Adversarial Networks (GANs), such as through regularization and architecture design. However, we identify the instability can also arise from the fragile balance at the early stage of adversarial learning. This paper proposes the CoopInit, a simple yet effective cooperative learning-based initialization strategy that can quickly learn a good starting point for GANs, with a very small computation overhead during training. The proposed algorithm consists of two learning stages: (i) Cooperative initialization stage: The discriminator of GAN is treated as an energy-based model (EBM) and is optimized via maximum likelihood estimation (MLE), with the help of the GAN&#39;s generator to provide synthetic data to approximate the learning gradients. The EBM also guides the MLE learning of the generator via MCMC teaching; (ii) Adversarial finalization stage: After a few iterations of initialization, the algorithm seamlessly transits to the regular mini-max adversarial training until convergence. The motivation is that the MLE-based initialization stage drives the model towards mode coverage, which is helpful in alleviating the issue of mode dropping during the adversarial learning stage. We demonstrate the effectiveness of the proposed approach on image generation and one-sided unpaired image-to-image translation tasks through extensive experiments.},
  archive   = {C_AAAI},
  author    = {Yang Zhao and Jianwen Xie and Ping Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26342},
  pages     = {11345-11353},
  title     = {CoopInit: Initializing generative adversarial networks via cooperative learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Imbalanced label distribution learning. <em>AAAI</em>,
11336–11344. (<a
href="https://doi.org/10.1609/aaai.v37i9.26341">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Label distribution covers a certain number of labels, representing the degree to which each label describes an instance. The learning process on the instances labeled by label distributions is called Label Distribution Learning (LDL). Although LDL has been applied successfully to many practical applications, one problem with existing LDL methods is that they are limited to data with balanced label information. However, annotation information in real-world data often exhibits imbalanced distributions, which significantly degrades the performance of existing methods. In this paper, we investigate the Imbalanced Label Distribution Learning (ILDL) problem. To handle this challenging problem, we delve into the characteristics of ILDL and empirically find that the representation distribution shift is the underlying reason for the performance degradation of existing methods. Inspired by this finding, we present a novel method named Representation Distribution Alignment (RDA). RDA aligns the distributions of feature representations and label representations to alleviate the impact of the distribution gap between the training set and the test set caused by the imbalance issue. Extensive experiments verify the superior performance of RDA. Our work fills the gap in benchmarks and techniques for practical ILDL problems.},
  archive   = {C_AAAI},
  author    = {Xingyu Zhao and Yuexuan An and Ning Xu and Jing Wang and Xin Geng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26341},
  pages     = {11336-11344},
  title     = {Imbalanced label distribution learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Tensorized incomplete multi-view clustering with intrinsic
graph completion. <em>AAAI</em>, 11327–11335. (<a
href="https://doi.org/10.1609/aaai.v37i9.26340">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Most of the existing incomplete multi-view clustering (IMVC) methods focus on attaining a consensus representation from different views but ignore the important information hidden in the missing views and the latent intrinsic structures in each view. To tackle these issues, in this paper, a unified and novel framework, named tensorized incomplete multi-view clustering with intrinsic graph completion (TIMVC_IGC) is proposed. Firstly, owing to the effectiveness of the low-rank representation in revealing the inherent structure of the data, we exploit it to infer the missing instances and construct the complete graph for each view. Afterwards, inspired by the structural consistency, a between-view consistency constraint is imposed to guarantee the similarity of the graphs from different views. More importantly, the TIMVC_IGC simultaneously learns the low-rank structures of the different views and explores the correlations of the different graphs in a latent manifold sub-space using a low-rank tensor constraint, such that the intrinsic graphs of the different views can be obtained. Finally, a consensus representation for each sample is gained with a co-regularization term for final clustering. Experimental results on several real-world databases illustrates that the proposed method can outperform the other state-of-the-art related methods for incomplete multi-view clustering.},
  archive   = {C_AAAI},
  author    = {Shuping Zhao and Jie Wen and Lunke Fei and Bob Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26340},
  pages     = {11327-11335},
  title     = {Tensorized incomplete multi-view clustering with intrinsic graph completion},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynamic ensemble of low-fidelity experts: Mitigating NAS
“cold-start.” <em>AAAI</em>, 11316–11326. (<a
href="https://doi.org/10.1609/aaai.v37i9.26339">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Predictor-based Neural Architecture Search (NAS) employs an architecture performance predictor to improve the sample efficiency. However, predictor-based NAS suffers from the severe ``cold-start&#39;&#39; problem, since a large amount of architecture-performance data is required to get a working predictor. In this paper, we focus on exploiting information in cheaper-to-obtain performance estimations (i.e., low-fidelity information) to mitigate the large data requirements of predictor training. Despite the intuitiveness of this idea, we observe that using inappropriate low-fidelity information even damages the prediction ability and different search spaces have different preferences for low-fidelity information types. To solve the problem and better fuse beneficial information provided by different types of low-fidelity information, we propose a novel dynamic ensemble predictor framework that comprises two steps. In the first step, we train different sub-predictors on different types of available low-fidelity information to extract beneficial knowledge as low-fidelity experts. In the second step, we learn a gating network to dynamically output a set of weighting coefficients conditioned on each input neural architecture, which will be used to combine the predictions of different low-fidelity experts in a weighted sum. The overall predictor is optimized on a small set of actual architecture-performance data to fuse the knowledge from different low-fidelity experts to make the final prediction. We conduct extensive experiments across five search spaces with different architecture encoders under various experimental settings. For example, our methods can improve the Kendall&#39;s Tau correlation coefficient between actual performance and predicted scores from 0.2549 to 0.7064 with only 25 actual architecture-performance data on NDS-ResNet. Our method can easily be incorporated into existing predictor-based NAS frameworks to discover better architectures. Our method will be implemented in Mindspore (Huawei 2020), and the example code is published at https://github.com/A-LinCui/DELE.},
  archive   = {C_AAAI},
  author    = {Junbo Zhao and Xuefei Ning and Enshu Liu and Binxin Ru and Zixuan Zhou and Tianchen Zhao and Chen Chen and Jiajin Zhang and Qingmin Liao and Yu Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26339},
  pages     = {11316-11326},
  title     = {Dynamic ensemble of low-fidelity experts: Mitigating NAS “Cold-start”},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Dynamic heterogeneous graph attention neural architecture
search. <em>AAAI</em>, 11307–11315. (<a
href="https://doi.org/10.1609/aaai.v37i9.26338">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Dynamic heterogeneous graph neural networks (DHGNNs) have been shown to be effective in handling the ubiquitous dynamic heterogeneous graphs. However, the existing DHGNNs are hand-designed, requiring extensive human efforts and failing to adapt to diverse dynamic heterogeneous graph scenarios. In this paper, we propose to automate the design of DHGNN, which faces two major challenges: 1) how to design the search space to jointly consider the spatial-temporal dependencies and heterogeneous interactions in graphs; 2) how to design an efficient search algorithm in the potentially large and complex search space. To tackle these challenges, we propose a novel Dynamic Heterogeneous Graph Attention Search (DHGAS) method. Our proposed method can automatically discover the optimal DHGNN architecture and adapt to various dynamic heterogeneous graph scenarios without human guidance. In particular, we first propose a unified dynamic heterogeneous graph attention (DHGA) framework, which enables each node to jointly attend its heterogeneous and dynamic neighbors. Based on the framework, we design a localization space to determine where the attention should be applied and a parameterization space to determine how the attention should be parameterized. Lastly, we design a multi-stage differentiable search algorithm to efficiently explore the search space. Extensive experiments on real-world dynamic heterogeneous graph datasets demonstrate that our proposed method significantly outperforms state-of-the-art baselines for tasks including link prediction, node classification and node regression. To the best of our knowledge, DHGAS is the first dynamic heterogeneous graph neural architecture search method.},
  archive   = {C_AAAI},
  author    = {Zeyang Zhang and Ziwei Zhang and Xin Wang and Yijian Qin and Zhou Qin and Wenwu Zhu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26338},
  pages     = {11307-11315},
  title     = {Dynamic heterogeneous graph attention neural architecture search},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023e). Scalable bayesian meta-learning through generalized
implicit gradients. <em>AAAI</em>, 11298–11306. (<a
href="https://doi.org/10.1609/aaai.v37i9.26337">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Meta-learning owns unique effectiveness and swiftness in tackling emerging tasks with limited data. Its broad applicability is revealed by viewing it as a bi-level optimization problem. The resultant algorithmic viewpoint however, faces scalability issues when the inner-level optimization relies on gradient-based iterations. Implicit differentiation has been considered to alleviate this challenge, but it is restricted to an isotropic Gaussian prior, and only favors deterministic meta-learning approaches. This work markedly mitigates the scalability bottleneck by cross-fertilizing the benefits of implicit differentiation to probabilistic Bayesian meta-learning. The novel implicit Bayesian meta-learning (iBaML) method not only broadens the scope of learnable priors, but also quantifies the associated uncertainty. Furthermore, the ultimate complexity is well controlled regardless of the inner-level optimization trajectory. Analytical error bounds are established to demonstrate the precision and efficiency of the generalized implicit gradient over the explicit one. Extensive numerical tests are also carried out to empirically validate the performance of the proposed method.},
  archive   = {C_AAAI},
  author    = {Yilang Zhang and Bingcong Li and Shijian Gao and Georgios B. Giannakis},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26337},
  pages     = {11298-11306},
  title     = {Scalable bayesian meta-learning through generalized implicit gradients},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spectral feature augmentation for graph contrastive learning
and beyond. <em>AAAI</em>, 11289–11297. (<a
href="https://doi.org/10.1609/aaai.v37i9.26336">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Although augmentations (e.g., perturbation of graph edges, image crops) boost the efficiency of Contrastive Learning (CL), feature level augmentation is another plausible, complementary yet not well researched strategy. Thus, we present a novel spectral feature argumentation for contrastive learning on graphs (and images). To this end, for each data view, we estimate a low-rank approximation per feature map and subtract that approximation from the map to obtain its complement. This is achieved by the proposed herein incomplete power iteration, a non-standard power iteration regime which enjoys two valuable byproducts (under mere one or two iterations): (i) it partially balances spectrum of the feature map, and (ii) it injects the noise into rebalanced singular values of the feature map (spectral augmentation). For two views, we align these rebalanced feature maps as such an improved alignment step can focus more on less dominant singular values of matrices of both views, whereas the spectral augmentation does not affect the spectral angle alignment (singular vectors are not perturbed). We derive the analytical form for: (i) the incomplete power iteration to capture its spectrum-balancing effect, and (ii) the variance of singular values augmented implicitly by the noise. We also show that the spectral augmentation improves the generalization bound. Experiments on graph/image datasets show that our spectral feature augmentation outperforms baselines, and is complementary with other augmentation strategies and compatible with various contrastive losses.},
  archive   = {C_AAAI},
  author    = {Yifei Zhang and Hao Zhu and Zixing Song and Piotr Koniusz and Irwin King},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26336},
  pages     = {11289-11297},
  title     = {Spectral feature augmentation for graph contrastive learning and beyond},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). High-dimensional dueling optimization with preference
embedding. <em>AAAI</em>, 11280–11288. (<a
href="https://doi.org/10.1609/aaai.v37i9.26335">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In many scenarios of black-box optimization, evaluating the objective function values of solutions is expensive, while comparing a pair of solutions is relatively cheap, which yields the dueling black-box optimization. The side effect of dueling optimization is that it doubles the dimension of solution space and exacerbates the dimensionality scalability issue of black-box optimization, e.g., Bayesian optimization. To address this issue, the existing dueling optimization methods fix one solution when dueling throughout the optimization process, but it may reduce their efficacy. Fortunately, it has been observed that, in recommendation systems, the dueling results are mainly determined by the latent human preferences. In this paper, we abstract this phenomenon as the preferential intrinsic dimension and inject it into the dueling Bayesian optimization, resulting in the preferential embedding dueling Bayesian optimization (PE-DBO). PE-DBO decouples optimization and pairwise comparison via the preferential embedding matrix. Optimization is performed in the preferential intrinsic subspace with much lower dimensionality, while pairwise comparison is completed in the original dueling solution space. Theoretically, we disclose that the preference function can be approximately preserved in the lower-dimensional preferential intrinsic subspace. Experiment results verify that, on molecule discovery and web page recommendation dueling optimization tasks, the preferential intrinsic dimension exists and PE-DBO is superior in scalability compared with that of the state-of-the-art (SOTA) methods.},
  archive   = {C_AAAI},
  author    = {Yangwenhui Zhang and Hong Qian and Xiang Shu and Aimin Zhou},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26335},
  pages     = {11280-11288},
  title     = {High-dimensional dueling optimization with preference embedding},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal sparse regression trees. <em>AAAI</em>, 11270–11279.
(<a href="https://doi.org/10.1609/aaai.v37i9.26334">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Regression trees are one of the oldest forms of AI models, and their predictions can be made without a calculator, which makes them broadly useful, particularly for high-stakes applications. Within the large literature on regression trees, there has been little effort towards full provable optimization, mainly due to the computational hardness of the problem. This work proposes a dynamic programming-with-bounds approach to the construction of provably-optimal sparse regression trees. We leverage a novel lower bound based on an optimal solution to the k-Means clustering algorithm on one dimensional data. We are often able to find optimal sparse trees in seconds, even for challenging datasets that involve large numbers of samples and highly-correlated features.},
  archive   = {C_AAAI},
  author    = {Rui Zhang and Rui Xin and Margo Seltzer and Cynthia Rudin},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26334},
  pages     = {11270-11279},
  title     = {Optimal sparse regression trees},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Let the data choose: Flexible and diverse anchor graph
fusion for scalable multi-view clustering. <em>AAAI</em>, 11262–11269.
(<a href="https://doi.org/10.1609/aaai.v37i9.26333">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the past few years, numerous multi-view graph clustering algorithms have been proposed to enhance the clustering performance by exploring information from multiple views. Despite the superior performance, the high time and space expenditures limit their scalability. Accordingly, anchor graph learning has been introduced to alleviate the computational complexity. However, existing approaches can be further improved by the following considerations: (i) Existing anchor-based methods share the same number of anchors across views. This strategy violates the diversity and flexibility of multi-view data distribution. (ii) Searching for the optimal anchor number within hyper-parameters takes much extra tuning time, which makes existing methods impractical. (iii) How to flexibly fuse multi-view anchor graphs of diverse sizes has not been well explored in existing literature. To address the above issues, we propose a novel anchor-based method termed Flexible and Diverse Anchor Graph Fusion for Scalable Multi-view Clustering (FDAGF) in this paper. Instead of manually tuning optimal anchor with massive hyper-parameters, we propose to optimize the contribution weights of a group of pre-defined anchor numbers to avoid extra time expenditure among views. Most importantly, we propose a novel hybrid fusion strategy for multi-size anchor graphs with theoretical proof, which allows flexible and diverse anchor graph fusion. Then, an efficient linear optimization algorithm is proposed to solve the resultant problem. Comprehensive experimental results demonstrate the effectiveness and efficiency of our proposed framework. The source code is available at https://github.com/Jeaninezpp/FDAGF.},
  archive   = {C_AAAI},
  author    = {Pei Zhang and Siwei Wang and Liang Li and Changwang Zhang and Xinwang Liu and En Zhu and Zhe Liu and Lu Zhou and Lei Luo},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26333},
  pages     = {11262-11269},
  title     = {Let the data choose: Flexible and diverse anchor graph fusion for scalable multi-view clustering},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). DRGCN: Dynamic evolving initial residual for deep graph
convolutional networks. <em>AAAI</em>, 11254–11261. (<a
href="https://doi.org/10.1609/aaai.v37i9.26332">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph convolutional networks (GCNs) have been proved to be very practical to handle various graph-related tasks. It has attracted considerable research interest to study deep GCNs, due to their potential superior performance compared with shallow ones. However, simply increasing network depth will, on the contrary, hurt the performance due to the over-smoothing problem. Adding residual connection is proved to be effective for learning deep convolutional neural networks (deep CNNs), it is not trivial when applied to deep GCNs. Recent works proposed an initial residual mechanism that did alleviate the over-smoothing problem in deep GCNs. However, according to our study, their algorithms are quite sensitive to different datasets. In their setting, the personalization (dynamic) and correlation (evolving) of how residual applies are ignored. To this end, we propose a novel model called Dynamic evolving initial Residual Graph Convolutional Network (DRGCN). Firstly, we use a dynamic block for each node to adaptively fetch information from the initial representation. Secondly, we use an evolving block to model the residual evolving pattern between layers. Our experimental results show that our model effectively relieves the problem of over-smoothing in deep GCNs and outperforms the state-of-the-art (SOTA) methods on various benchmark datasets. Moreover, we develop a mini-batch version of DRGCN which can be applied to large-scale data. Coupling with several fair training techniques, our model reaches new SOTA results on the large-scale ogbn-arxiv dataset of Open Graph Benchmark (OGB). Our reproducible code is available on GitHub.},
  archive   = {C_AAAI},
  author    = {Lei Zhang and Xiaodong Yan and Jianshan He and Ruopeng Li and Wei Chu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26332},
  pages     = {11254-11261},
  title     = {DRGCN: Dynamic evolving initial residual for deep graph convolutional networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). Delving into the adversarial robustness of federated
learning. <em>AAAI</em>, 11245–11253. (<a
href="https://doi.org/10.1609/aaai.v37i9.26331">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In Federated Learning (FL), models are as fragile as centrally trained models against adversarial examples. However, the adversarial robustness of federated learning remains largely unexplored. This paper casts light on the challenge of adversarial robustness of federated learning. To facilitate a better understanding of the adversarial vulnerability of the existing FL methods, we conduct comprehensive robustness evaluations on various attacks and adversarial training methods. Moreover, we reveal the negative impacts induced by directly adopting adversarial training in FL, which seriously hurts the test accuracy, especially in non-IID settings. In this work, we propose a novel algorithm called Decision Boundary based Federated Adversarial Training (DBFAT), which consists of two components (local re-weighting and global regularization) to improve both accuracy and robustness of FL systems. Extensive experiments on multiple datasets demonstrate that DBFAT consistently outperforms other baselines under both IID and non-IID settings.},
  archive   = {C_AAAI},
  author    = {Jie Zhang and Bo Li and Chen Chen and Lingjuan Lyu and Shuang Wu and Shouhong Ding and Chao Wu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26331},
  pages     = {11245-11253},
  title     = {Delving into the adversarial robustness of federated learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FedALA: Adaptive local aggregation for personalized
federated learning. <em>AAAI</em>, 11237–11244. (<a
href="https://doi.org/10.1609/aaai.v37i9.26330">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A key challenge in federated learning (FL) is the statistical heterogeneity that impairs the generalization of the global model on each client. To address this, we propose a method Federated learning with Adaptive Local Aggregation (FedALA) by capturing the desired information in the global model for client models in personalized FL. The key component of FedALA is an Adaptive Local Aggregation (ALA) module, which can adaptively aggregate the downloaded global model and local model towards the local objective on each client to initialize the local model before training in each iteration. To evaluate the effectiveness of FedALA, we conduct extensive experiments with five benchmark datasets in computer vision and natural language processing domains. FedALA outperforms eleven state-of-the-art baselines by up to 3.27\% in test accuracy. Furthermore, we also apply ALA module to other federated learning methods and achieve up to 24.19\% improvement in test accuracy. Code is available at https://github.com/TsingZ0/FedALA.},
  archive   = {C_AAAI},
  author    = {Jianqing Zhang and Yang Hua and Hao Wang and Tao Song and Zhengui Xue and Ruhui Ma and Haibing Guan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26330},
  pages     = {11237-11244},
  title     = {FedALA: Adaptive local aggregation for personalized federated learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Memorization weights for instance reweighting in adversarial
training. <em>AAAI</em>, 11228–11236. (<a
href="https://doi.org/10.1609/aaai.v37i9.26329">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Adversarial training is an effective way to defend deep neural networks (DNN) against adversarial examples. However, there are atypical samples that are rare and hard to learn, or even hurt DNNs&#39; generalization performance on test data. In this paper, we propose a novel algorithm to reweight the training samples based on self-supervised techniques to mitigate the negative effects of the atypical samples. Specifically, a memory bank is built to record the popular samples as prototypes and calculate the memorization weight for each sample, evaluating the &quot;typicalness&quot; of a sample. All the training samples are reweigthed based on the proposed memorization weights to reduce the negative effects of atypical samples. Experimental results show the proposed method is flexible to boost state-of-the-art adversarial training methods, improving both robustness and standard accuracy of DNNs.},
  archive   = {C_AAAI},
  author    = {Jianfu Zhang and Yan Hong and Qibin Zhao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26329},
  pages     = {11228-11236},
  title     = {Memorization weights for instance reweighting in adversarial training},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). When neural networks fail to generalize? A model sensitivity
perspective. <em>AAAI</em>, 11219–11227. (<a
href="https://doi.org/10.1609/aaai.v37i9.26328">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Domain generalization (DG) aims to train a model to perform well in unseen domains under different distributions. This paper considers a more realistic yet more challenging scenario, namely Single Domain Generalization (Single-DG), where only a single source domain is available for training. To tackle this challenge, we first try to understand when neural networks fail to generalize? We empirically ascertain a property of a model that correlates strongly with its generalization that we coin as &quot;model sensitivity&quot;. Based on our analysis, we propose a novel strategy of Spectral Adversarial Data Augmentation (SADA) to generate augmented images targeted at the highly sensitive frequencies. Models trained with these hard-to-learn samples can effectively suppress the sensitivity in the frequency space, which leads to improved generalization performance. Extensive experiments on multiple public datasets demonstrate the superiority of our approach, which surpasses the state-of-the-art single-DG methods by up to 2.55\%. The source code is available at https://github.com/DIAL-RPI/Spectral-Adversarial-Data-Augmentation.},
  archive   = {C_AAAI},
  author    = {Jiajin Zhang and Hanqing Chao and Amit Dhurandhar and Pin-Yu Chen and Ali Tajer and Yangyang Xu and Pingkun Yan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26328},
  pages     = {11219-11227},
  title     = {When neural networks fail to generalize? a model sensitivity perspective},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DARL: Distance-aware uncertainty estimation for offline
reinforcement learning. <em>AAAI</em>, 11210–11218. (<a
href="https://doi.org/10.1609/aaai.v37i9.26327">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {To facilitate offline reinforcement learning, uncertainty estimation is commonly used to detect out-of-distribution data. By inspecting, we show that current explicit uncertainty estimators such as Monte Carlo Dropout and model ensemble are not competent to provide trustworthy uncertainty estimation in offline reinforcement learning. Accordingly, we propose a non-parametric distance-aware uncertainty estimator which is sensitive to the change in the input space for offline reinforcement learning. Based on our new estimator, adaptive truncated quantile critics are proposed to underestimate the out-of-distribution samples. We show that the proposed distance-aware uncertainty estimator is able to offer better uncertainty estimation compared to previous methods. Experimental results demonstrate that our proposed DARL method is competitive to the state-of-the-art methods in offline evaluation tasks.},
  archive   = {C_AAAI},
  author    = {Hongchang Zhang and Jianzhun Shao and Shuncheng He and Yuhang Jiang and Xiangyang Ji},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26327},
  pages     = {11210-11218},
  title     = {DARL: Distance-aware uncertainty estimation for offline reinforcement learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Behavior estimation from multi-source data for offline
reinforcement learning. <em>AAAI</em>, 11201–11209. (<a
href="https://doi.org/10.1609/aaai.v37i9.26326">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Offline reinforcement learning (RL) have received rising interest due to its appealing data efficiency. The present study addresses behavior estimation, a task that aims at estimating the data-generating policy. In particular, this work considers a scenario where data are collected from multiple sources. Neglecting data heterogeneity, existing approaches cannot provide good estimates and impede policy learning. To overcome this drawback, the present study proposes a latent variable model and a model-learning algorithm to infer a set of policies from data, which allows an agent to use as behavior policy the policy that best describes a particular trajectory. To illustrate the benefit of such a fine-grained characterization for multi-source data, this work showcases how the proposed model can be incorporated into an existing offline RL algorithm. Lastly, with extensive empirical evaluation this work confirms the risks of neglecting data heterogeneity and the efficacy of the proposed model.},
  archive   = {C_AAAI},
  author    = {Guoxi Zhang and Hisashi Kashima},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26326},
  pages     = {11201-11209},
  title     = {Behavior estimation from multi-source data for offline reinforcement learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Rethinking alignment and uniformity in unsupervised image
semantic segmentation. <em>AAAI</em>, 11192–11200. (<a
href="https://doi.org/10.1609/aaai.v37i9.26325">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Unsupervised image segmentation aims to match low-level visual features with semantic-level representations without outer supervision. In this paper, we address the critical properties from the view of feature alignments and feature uniformity for UISS models. We also make a comparison between UISS and image-wise representation learning. Based on the analysis, we argue that the existing MI-based methods in UISS suffer from representation collapse. By this, we proposed a robust network called Semantic Attention Network(SAN), in which a new module Semantic Attention(SEAT) is proposed to generate pixel-wise and semantic features dynamically. Experimental results on multiple semantic segmentation benchmarks show that our unsupervised segmentation framework specializes in catching semantic representations, which outperforms all the unpretrained and even several pretrained methods.},
  archive   = {C_AAAI},
  author    = {Daoan Zhang and Chenming Li and Haoquan Li and Wenjian Huang and Lingyun Huang and Jianguo Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26325},
  pages     = {11192-11200},
  title     = {Rethinking alignment and uniformity in unsupervised image semantic segmentation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Denoising multi-similarity formulation: A self-paced
curriculum-driven approach for robust metric learning. <em>AAAI</em>,
11183–11191. (<a
href="https://doi.org/10.1609/aaai.v37i9.26324">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep Metric Learning (DML) is a group of techniques that aim to measure the similarity between objects through the neural network. Although the number of DML methods has rapidly increased in recent years, most previous studies cannot effectively handle noisy data, which commonly exists in practical applications and often leads to serious performance deterioration. To overcome this limitation, in this paper, we build a connection between noisy samples and hard samples in the framework of self-paced learning, and propose a Balanced Self-Paced Metric Learning (BSPML) algorithm with a denoising multi-similarity formulation, where noisy samples are treated as extremely hard samples and adaptively excluded from the model training by sample weighting. Especially, due to the pairwise relationship and a new balance regularization term, the sub-problem w.r.t. sample weights is a nonconvex quadratic function. To efficiently solve this nonconvex quadratic problem, we propose a doubly stochastic projection coordinate gradient algorithm. Importantly, we theoretically prove the convergence not only for the doubly stochastic projection coordinate gradient algorithm, but also for our BSPML algorithm. Experimental results on several standard data sets demonstrate that our BSPML algorithm has better generalization ability and robustness than the state-of-the-art robust DML approaches.},
  archive   = {C_AAAI},
  author    = {Chenkang Zhang and Lei Luo and Bin Gu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26324},
  pages     = {11183-11191},
  title     = {Denoising multi-similarity formulation: A self-paced curriculum-driven approach for robust metric learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Enhanced tensor low-rank and sparse representation recovery
for incomplete multi-view clustering. <em>AAAI</em>, 11174–11182. (<a
href="https://doi.org/10.1609/aaai.v37i9.26323">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Incomplete multi-view clustering (IMVC) has attracted remarkable attention due to the emergence of multi-view data with missing views in real applications. Recent methods attempt to recover the missing information to address the IMVC problem. However, they generally cannot fully explore the underlying properties and correlations of data similarities across views. This paper proposes a novel Enhanced Tensor Low-rank and Sparse Representation Recovery (ETLSRR) method, which reformulates the IMVC problem as a joint incomplete similarity graphs learning and complete tensor representation recovery problem. Specifically, ETLSRR learns the intra-view similarity graphs and constructs a 3-way tensor by stacking the graphs to explore the inter-view correlations. To alleviate the negative influence of missing views and data noise, ETLSRR decomposes the tensor into two parts: a sparse tensor and an intrinsic tensor, which models the noise and underlying true data similarities, respectively. Both global low-rank and local structured sparse characteristics of the intrinsic tensor are considered, which enhances the discrimination of similarity matrix. Moreover, instead of using the convex tensor nuclear norm, ETLSRR introduces a generalized non-convex tensor low-rank regularization to alleviate the biased approximation. Experiments on several datasets demonstrate the effectiveness of our method compared with the state-of-the-art methods.},
  archive   = {C_AAAI},
  author    = {Chao Zhang and Huaxiong Li and Wei Lv and Zizheng Huang and Yang Gao and Chunlin Chen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26323},
  pages     = {11174-11182},
  title     = {Enhanced tensor low-rank and sparse representation recovery for incomplete multi-view clustering},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Interventional SHAP values and interaction values for
piecewise linear regression trees. <em>AAAI</em>, 11164–11173. (<a
href="https://doi.org/10.1609/aaai.v37i9.26322">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In recent years, game-theoretic Shapley values have gained increasing attention with respect to local model explanation by feature attributions. While the approach using Shapley values is model-independent, their (exact) computation is usually intractable, so efficient model-specific algorithms have been devised including approaches for decision trees or their ensembles in general. Our work goes further in this direction by extending the interventional TreeSHAP algorithm to piecewise linear regression trees, which gained more attention in the past few years. To this end, we introduce a decomposition of the contribution function based on decision paths, which allows a more comprehensible formulation of SHAP algorithms for tree-based models. Our algorithm can also be readily applied to computing SHAP interaction values of these models. In particular, as the main contribution of this paper, we provide a more efficient approach of interventional SHAP for tree-based models by precomputing statistics of the background data based on the tree structure.},
  archive   = {C_AAAI},
  author    = {Artjom Zern and Klaus Broelemann and Gjergji Kasneci},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26322},
  pages     = {11164-11173},
  title     = {Interventional SHAP values and interaction values for piecewise linear regression trees},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Acceleration of large transformer model training by
sensitivity-based layer dropping. <em>AAAI</em>, 11156–11163. (<a
href="https://doi.org/10.1609/aaai.v37i9.26321">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Transformer models are widely used in AI applications such as Natural Language Processing (NLP), Computer Vision (CV), etc. However, enormous computation workload be-comes an obstacle to train large transformer models efficiently. Recently, some methods focus on reducing the computation workload during the training by skipping some layers. How-ever, these methods use simple probability distribution and coarse-grained probability calculation, which significantly affect the model accuracy. To address the issue, in this paper we propose a novel method to accelerate training—Sensitivity-Based Layer Dropping (SBLD). SBLD uses lay-er-wise sensitivity data to switch on/off transformer layers in proper order to keep high accuracy. Besides, we adjust the probability of skipping transformer layers with a scheduler to accelerate training speed and get faster convergence. Our results show that SBLD solves the accuracy drop issue com-pared with prior layer dropping methods. Our SBLD method can decrease end-to-end training time by 19.67\% during training of GPT-3 Medium model, the same time increasing the accuracy by 1.65\% w.r.t. baseline. Furthermore, for SwinV2-L model the obtained Top-1 and Top-5 accuracies are also higher vs. the baseline. Thus, the proposed method is efficient and practical to improve the large transformer model training.},
  archive   = {C_AAAI},
  author    = {Yujie Zeng and Wenlong He and Ihor Vasyltsov and Jiali Pang and Lin Chen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26321},
  pages     = {11156-11163},
  title     = {Acceleration of large transformer model training by sensitivity-based layer dropping},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Foresee what you will learn: Data augmentation for domain
generalization in non-stationary environment. <em>AAAI</em>,
11147–11155. (<a
href="https://doi.org/10.1609/aaai.v37i9.26320">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Existing domain generalization aims to learn a generalizable model to perform well even on unseen domains. For many real-world machine learning applications, the data distribution often shifts gradually along domain indices. For example, a self-driving car with a vision system drives from dawn to dusk, with the sky gradually darkening. Therefore, the system must be able to adapt to changes in ambient illuminations and continue to drive safely on the road. In this paper, we formulate such problems as Evolving Domain Generalization, where a model aims to generalize well on a target domain by discovering and leveraging the evolving pattern of the environment. We then propose Directional Domain Augmentation (DDA), which simulates the unseen target features by mapping source data as augmentations through a domain transformer. Specifically, we formulate DDA as a bi-level optimization problem and solve it through a novel meta-learning approach in the representation space. We evaluate the proposed method on both synthetic datasets and real-world datasets, and empirical results show that our approach can outperform other existing methods.},
  archive   = {C_AAAI},
  author    = {Qiuhao Zeng and Wei Wang and Fan Zhou and Charles Ling and Boyu Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26320},
  pages     = {11147-11155},
  title     = {Foresee what you will learn: Data augmentation for domain generalization in non-stationary environment},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ImGCL: Revisiting graph contrastive learning on imbalanced
node classification. <em>AAAI</em>, 11138–11146. (<a
href="https://doi.org/10.1609/aaai.v37i9.26319">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph contrastive learning (GCL) has attracted a surge of attention due to its superior performance for learning node/graph representations without labels. However, in practice, the underlying class distribution of unlabeled nodes for the given graph is usually imbalanced. This highly imbalanced class distribution inevitably deteriorates the quality of learned node representations in GCL. Indeed, we empirically find that most state-of-the-art GCL methods cannot obtain discriminative representations and exhibit poor performance on imbalanced node classification. Motivated by this observation, we propose a principled GCL framework on Imbalanced node classification (ImGCL), which automatically and adaptively balances the representations learned from GCL without labels. Specifically, we first introduce the online clustering based progressively balanced sampling (PBS) method with theoretical rationale, which balances the training sets based on pseudo-labels obtained from learned representations in GCL. We then develop the node centrality based PBS method to better preserve the intrinsic structure of graphs, by upweighting the important nodes of the given graph. Extensive experiments on multiple imbalanced graph datasets and imbalanced settings demonstrate the effectiveness of our proposed framework, which significantly improves the performance of the recent state-of-the-art GCL methods. Further experimental ablations and analyses show that the ImGCL framework consistently improves the representation quality of nodes in under-represented (tail) classes.},
  archive   = {C_AAAI},
  author    = {Liang Zeng and Lanqing Li and Ziqi Gao and Peilin Zhao and Jian Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26319},
  pages     = {11138-11146},
  title     = {ImGCL: Revisiting graph contrastive learning on imbalanced node classification},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Substructure aware graph neural networks. <em>AAAI</em>,
11129–11137. (<a
href="https://doi.org/10.1609/aaai.v37i9.26318">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Despite the great achievements of Graph Neural Networks (GNNs) in graph learning, conventional GNNs struggle to break through the upper limit of the expressiveness of first-order Weisfeiler-Leman graph isomorphism test algorithm (1-WL) due to the consistency of the propagation paradigm of GNNs with the 1-WL.Based on the fact that it is easier to distinguish the original graph through subgraphs, we propose a novel framework neural network framework called Substructure Aware Graph Neural Networks (SAGNN) to address these issues. We first propose a Cut subgraph which can be obtained from the original graph by continuously and selectively removing edges. Then we extend the random walk encoding paradigm to the return probability of the rooted node on the subgraph to capture the structural information and use it as a node feature to improve the expressiveness of GNNs. We theoretically prove that our framework is more powerful than 1-WL, and is superior in structure perception. Our extensive experiments demonstrate the effectiveness of our framework, achieving state-of-the-art performance on a variety of well-proven graph tasks, and GNNs equipped with our framework perform flawlessly even in 3-WL failed graphs. Specifically, our framework achieves a maximum performance improvement of 83\% compared to the base models and 32\% compared to the previous state-of-the-art methods.},
  archive   = {C_AAAI},
  author    = {DingYi Zeng and Wanlong Liu and Wenyu Chen and Li Zhou and Malu Zhang and Hong Qu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26318},
  pages     = {11129-11137},
  title     = {Substructure aware graph neural networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Are transformers effective for time series forecasting?
<em>AAAI</em>, 11121–11128. (<a
href="https://doi.org/10.1609/aaai.v37i9.26317">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, there has been a surge of Transformer-based solutions for the long-term time series forecasting (LTSF) task. Despite the growing performance over the past few years, we question the validity of this line of research in this work. Specifically, Transformers is arguably the most successful solution to extract the semantic correlations among the elements in a long sequence. However, in time series modeling, we are to extract the temporal relations in an ordered set of continuous points. While employing positional encoding and using tokens to embed sub-series in Transformers facilitate preserving some ordering information, the nature of the permutation-invariant self-attention mechanism inevitably results in temporal information loss. To validate our claim, we introduce a set of embarrassingly simple one-layer linear models named LTSF-Linear for comparison. Experimental results on nine real-life datasets show that LTSF-Linear surprisingly outperforms existing sophisticated Transformer-based LTSF models in all cases, and often by a large margin. Moreover, we conduct comprehensive empirical studies to explore the impacts of various design elements of LTSF models on their temporal relation extraction capability. We hope this surprising finding opens up new research directions for the LTSF task. We also advocate revisiting the validity of Transformer-based solutions for other time series analysis tasks (e.g., anomaly detection) in the future.},
  archive   = {C_AAAI},
  author    = {Ailing Zeng and Muxi Chen and Lei Zhang and Qiang Xu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26317},
  pages     = {11121-11128},
  title     = {Are transformers effective for time series forecasting?},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Leveraging structure for improved classification of grouped
biased data. <em>AAAI</em>, 11113–11120. (<a
href="https://doi.org/10.1609/aaai.v37i9.26316">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider semi-supervised binary classification for applications in which data points are naturally grouped (e.g., survey responses grouped by state) and the labeled data is biased (e.g., survey respondents are not representative of the population). The groups overlap in the feature space and consequently the input-output patterns are related across the groups. To model the inherent structure in such data, we assume the partition-projected class-conditional invariance across groups, defined in terms of the group-agnostic feature space. We demonstrate that under this assumption, the group carries additional information about the class, over the group-agnostic features, with provably improved area under the ROC curve. Further assuming invariance of partition-projected class-conditional distributions across both labeled and unlabeled data, we derive a semi-supervised algorithm that explicitly leverages the structure to learn an optimal, group-aware, probability-calibrated classifier, despite the bias in the labeled data. Experiments on synthetic and real data demonstrate the efficacy of our algorithm over suitable baselines and ablative models, spanning standard supervised and semi-supervised learning approaches, with and without incorporating the group directly as a feature.},
  archive   = {C_AAAI},
  author    = {Daniel Zeiberg and Shantanu Jain and Predrag Radivojac},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26316},
  pages     = {11113-11120},
  title     = {Leveraging structure for improved classification of grouped biased data},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural integro-differential equations. <em>AAAI</em>,
11104–11112. (<a
href="https://doi.org/10.1609/aaai.v37i9.26315">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Modeling continuous dynamical systems from discretely sampled observations is a fundamental problem in data science. Often, such dynamics are the result of non-local processes that present an integral over time. As such, these systems are modeled with Integro-Differential Equations (IDEs); generalizations of differential equations that comprise both an integral and a differential component. For example, brain dynamics are not accurately modeled by differential equations since their behavior is non-Markovian, i.e. dynamics are in part dictated by history. Here, we introduce the Neural IDE (NIDE), a novel deep learning framework based on the theory of IDEs where integral operators are learned using neural networks. We test NIDE on several toy and brain activity datasets and demonstrate that NIDE outperforms other models. These tasks include time extrapolation as well as predicting dynamics from unseen initial conditions, which we test on whole-cortex activity recordings in freely behaving mice. Further, we show that NIDE can decompose dynamics into their Markovian and non-Markovian constituents, via the learned integral operator, which we test on fMRI brain activity recordings of people on ketamine. Finally, the integrand of the integral operator provides a latent space that gives insight into the underlying dynamics, which we demonstrate on wide-field brain imaging recordings. Altogether, NIDE is a novel approach that enables modeling of complex non-local dynamics with neural networks.},
  archive   = {C_AAAI},
  author    = {Emanuele Zappala and Antonio H. de O. Fonseca and Andrew H. Moberly and Michael J. Higley and Chadi Abdallah and Jessica A. Cardin and David van Dijk},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26315},
  pages     = {11104-11112},
  title     = {Neural integro-differential equations},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Linking sketch patches by learning synonymous proximity for
graphic sketch representation. <em>AAAI</em>, 11096–11103. (<a
href="https://doi.org/10.1609/aaai.v37i9.26314">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graphic sketch representations are effective for representing sketches. Existing methods take the patches cropped from sketches as the graph nodes, and construct the edges based on sketch&#39;s drawing order or Euclidean distances on the canvas. However, the drawing order of a sketch may not be unique, while the patches from semantically related parts of a sketch may be far away from each other on the canvas. In this paper, we propose an order-invariant, semantics-aware method for graphic sketch representations. The cropped sketch patches are linked according to their global semantics or local geometric shapes, namely the synonymous proximity, by computing the cosine similarity between the captured patch embeddings. Such constructed edges are learnable to adapt to the variation of sketch drawings, which enable the message passing among synonymous patches. Aggregating the messages from synonymous patches by graph convolutional networks plays a role of denoising, which is beneficial to produce robust patch embeddings and accurate sketch representations. Furthermore, we enforce a clustering constraint over the embeddings jointly with the network learning. The synonymous patches are self-organized as compact clusters, and their embeddings are guided to move towards their assigned cluster centroids. It raises the accuracy of the computed synonymous proximity. Experimental results show that our method significantly improves the performance on both controllable sketch synthesis and sketch healing.},
  archive   = {C_AAAI},
  author    = {Sicong Zang and Shikui Tu and Lei Xu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26314},
  pages     = {11096-11103},
  title     = {Linking sketch patches by learning synonymous proximity for graphic sketch representation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Quantum multi-agent meta reinforcement learning.
<em>AAAI</em>, 11087–11095. (<a
href="https://doi.org/10.1609/aaai.v37i9.26313">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Although quantum supremacy is yet to come, there has recently been an increasing interest in identifying the potential of quantum machine learning (QML) in the looming era of practical quantum computing. Motivated by this, in this article we re-design multi-agent reinforcement learning (MARL) based on the unique characteristics of quantum neural networks (QNNs) having two separate dimensions of trainable parameters: angle parameters affecting the output qubit states, and pole parameters associated with the output measurement basis. Exploiting this dyadic trainability as meta-learning capability, we propose quantum meta MARL (QM2ARL) that first applies angle training for meta-QNN learning, followed by pole training for few-shot or local-QNN training. To avoid overfitting, we develop an angle-to-pole regularization technique injecting noise into the pole domain during angle training. Furthermore, by exploiting the pole as the memory address of each trained QNN, we introduce the concept of pole memory allowing one to save and load trained QNNs using only two-parameter pole values. We theoretically prove the convergence of angle training under the angle-to-pole regularization, and by simulation corroborate the effectiveness of QM2ARL in achieving high reward and fast convergence, as well as of the pole memory in fast adaptation to a time-varying environment.},
  archive   = {C_AAAI},
  author    = {Won Joon Yun and Jihong Park and Joongheon Kim},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26313},
  pages     = {11087-11095},
  title     = {Quantum multi-agent meta reinforcement learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning conflict-noticed architecture for multi-task
learning. <em>AAAI</em>, 11078–11086. (<a
href="https://doi.org/10.1609/aaai.v37i9.26312">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-task learning has been widely used in many applications to enable more efficient learning by sharing part of the architecture across multiple tasks. However, a major challenge is the gradient conflict when optimizing the shared parameters, where the gradients of different tasks could have opposite directions. Directly averaging those gradients will impair the performance of some tasks and cause negative transfer. Different from most existing works that manipulate gradients to mitigate the gradient conflict, in this paper, we address this problem from the perspective of architecture learning and propose a Conflict-Noticed Architecture Learning (CoNAL) method to alleviate the gradient conflict by learning architectures. By introducing purely-specific modules specific to each task in the search space, the CoNAL method can automatically learn when to switch to purely-specific modules in the tree-structured network architectures when the gradient conflict occurs. To handle multi-task problems with a large number of tasks, we propose a progressive extension of the CoNAL method. Extensive experiments on computer vision, natural language processing, and reinforcement learning benchmarks demonstrate the effectiveness of the proposed methods.},
  archive   = {C_AAAI},
  author    = {Zhixiong Yue and Yu Zhang and Jie Liang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26312},
  pages     = {11078-11086},
  title     = {Learning conflict-noticed architecture for multi-task learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Value-consistent representation learning for data-efficient
reinforcement learning. <em>AAAI</em>, 11069–11077. (<a
href="https://doi.org/10.1609/aaai.v37i9.26311">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep reinforcement learning (RL) algorithms suffer severe performance degradation when the interaction data is scarce, which limits their real-world application. Recently, visual representation learning has been shown to be effective and promising for boosting sample efficiency in RL. These methods usually rely on contrastive learning and data augmentation to train a transition model, which is different from how the model is used in RL---performing value-based planning. Accordingly, the learned representation by these visual methods may be good for recognition but not optimal for estimating state value and solving the decision problem. To address this issue, we propose a novel method, called value-consistent representation learning (VCR), to learn representations that are directly related to decision-making. More specifically, VCR trains a model to predict the future state (also referred to as the &quot;imagined state&#39;&#39;) based on the current one and a sequence of actions. Instead of aligning this imagined state with a real state returned by the environment, VCR applies a Q value head on both of the states and obtains two distributions of action values. Then a distance is computed and minimized to force the imagined state to produce a similar action value prediction as that by the real state. We develop two implementations of the above idea for the discrete and continuous action spaces respectively. We conduct experiments on Atari 100k and DeepMind Control Suite benchmarks to validate their effectiveness for improving sample efficiency. It has been demonstrated that our methods achieve new state-of-the-art performance for search-free RL algorithms.},
  archive   = {C_AAAI},
  author    = {Yang Yue and Bingyi Kang and Zhongwen Xu and Gao Huang and Shuicheng Yan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26311},
  pages     = {11069-11077},
  title     = {Value-consistent representation learning for data-efficient reinforcement learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ODE-RSSM: Learning stochastic recurrent state space model
from irregularly sampled data. <em>AAAI</em>, 11060–11068. (<a
href="https://doi.org/10.1609/aaai.v37i9.26310">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {For the complicated input-output systems with nonlinearity and stochasticity, Deep State Space Models (SSMs) are effective for identifying systems in the latent state space, which are of great significance for representation, forecasting, and planning in online scenarios. However, most SSMs are designed for discrete-time sequences and inapplicable when the observations are irregular in time. To solve the problem, we propose a novel continuous-time SSM named Ordinary Differential Equation Recurrent State Space Model (ODE-RSSM). ODE-RSSM incorporates an ordinary differential equation (ODE) network (ODE-Net) to model the continuous-time evolution of latent states between adjacent time points. Inspired from the equivalent linear transformation on integration limits, we propose an efficient reparameterization method for solving batched ODEs with non-uniform time spans in parallel for efficiently training the ODE-RSSM with irregularly sampled sequences. We also conduct extensive experiments to evaluate the proposed ODE-RSSM and the baselines on three input-output datasets, one of which is a rollout of a private industrial dataset with strong long-term delay and stochasticity. The results demonstrate that the ODE-RSSM achieves better performance than other baselines in open loop prediction even if the time spans of predicted points are uneven and the distribution of length is changeable. Code is availiable at https://github.com/yuanzhaolin/ODE-RSSM.},
  archive   = {C_AAAI},
  author    = {Zhaolin Yuan and Xiaojuan Ban and Zixuan Zhang and Xiaorui Li and Hong-Ning Dai},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26310},
  pages     = {11060-11068},
  title     = {ODE-RSSM: Learning stochastic recurrent state space model from irregularly sampled data},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Joint multimodal entity-relation extraction based on
edge-enhanced graph alignment network and word-pair relation tagging.
<em>AAAI</em>, 11051–11059. (<a
href="https://doi.org/10.1609/aaai.v37i9.26309">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multimodal named entity recognition (MNER) and multimodal relation extraction (MRE) are two fundamental subtasks in the multimodal knowledge graph construction task. However, the existing methods usually handle two tasks independently, which ignores the bidirectional interaction between them. This paper is the first to propose jointly performing MNER and MRE as a joint multimodal entity-relation extraction (JMERE) task . Besides, the current MNER and MRE models only consider aligning the visual objects with textual entities in visual and textual graphs but ignore the entity-entity relationships and object-object relationships. To address the above challenges, we propose an edge-enhanced graph alignment network and a word-pair relation tagging (EEGA) for the JMERE task. Specifically, we first design a word-pair relation tagging to exploit the bidirectional interaction between MNER and MRE and avoid error propagation. Then, we propose an edge-enhanced graph alignment network to enhance the JMERE task by aligning nodes and edges in the cross-graph. Compared with previous methods, the proposed method can leverage the edge information to auxiliary alignment between objects and entities and find the correlations between entity-entity relationships and object-object relationships. Experiments are conducted to show the effectiveness of our model.},
  archive   = {C_AAAI},
  author    = {Li Yuan and Yi Cai and Jin Wang and Qing Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26309},
  pages     = {11051-11059},
  title     = {Joint multimodal entity-relation extraction based on edge-enhanced graph alignment network and word-pair relation tagging},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CEMA – cost-efficient machine-assisted document annotations.
<em>AAAI</em>, 11043–11050. (<a
href="https://doi.org/10.1609/aaai.v37i9.26308">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the problem of semantically annotating textual documents that are complex in the sense that the documents are long, feature rich, and domain specific. Due to their complexity, such annotation tasks require trained human workers, which are very expensive in both time and money. We propose CEMA, a method for deploying machine learning to assist humans in complex document annotation. CEMA estimates the human cost of annotating each document and selects the set of documents to be annotated that strike the best balance between model accuracy and human cost. We conduct experiments on complex annotation tasks in which we compare CEMA against other document selection and annotation strategies. Our results show that CEMA is the most cost-efficient solution for those tasks.},
  archive   = {C_AAAI},
  author    = {Guowen Yuan and Ben Kao and Tien-Hsuan Wu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26308},
  pages     = {11043-11050},
  title     = {CEMA – cost-efficient machine-assisted document annotations},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Coordinate descent methods for DC minimization: Optimality
conditions and global convergence. <em>AAAI</em>, 11034–11042. (<a
href="https://doi.org/10.1609/aaai.v37i9.26307">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Difference-of-Convex (DC) minimization, referring to the problem of minimizing the difference of two convex functions, has been found rich applications in statistical learning and studied extensively for decades. However, existing methods are primarily based on multi-stage convex relaxation, only leading to weak optimality of critical points. This paper proposes a coordinate descent method for minimizing a class of DC functions based on sequential nonconvex approximation. Our approach iteratively solves a nonconvex one-dimensional subproblem globally, and it is guaranteed to converge to a coordinate-wise stationary point. We prove that this new optimality condition is always stronger than the standard critical point condition and directional point condition under a mildlocally bounded nonconvexity assumption. For comparisons, we also include a naive variant of coordinate descent methods based on sequential convex approximation in our study. When the objective function satisfies a globally bounded nonconvexity assumption and Luo-Tseng error bound assumption, coordinate descent methods achieve Q-linear convergence rate. Also, for many applications of interest, we show that the nonconvex one-dimensional subproblem can be computed exactly and efficiently using a breakpoint searching method. Finally, we have conducted extensive experiments on several statistical learning tasks to show the superiority of our approach.},
  archive   = {C_AAAI},
  author    = {Ganzhao Yuan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26307},
  pages     = {11034-11042},
  title     = {Coordinate descent methods for DC minimization: Optimality conditions and global convergence},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). High-level semantic feature matters few-shot unsupervised
domain adaptation. <em>AAAI</em>, 11025–11033. (<a
href="https://doi.org/10.1609/aaai.v37i9.26306">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In few-shot unsupervised domain adaptation (FS-UDA), most existing methods followed the few-shot learning (FSL) methods to leverage the low-level local features (learned from conventional convolutional models, e.g., ResNet) for classification. However, the goal of FS-UDA and FSL are relevant yet distinct, since FS-UDA aims to classify the samples in target domain rather than source domain. We found that the local features are insufficient to FS-UDA, which could introduce noise or bias against classification, and not be used to effectively align the domains. To address the above issues, we aim to refine the local features to be more discriminative and relevant to classification. Thus, we propose a novel task-specific semantic feature learning method (TSECS) for FS-UDA. TSECS learns high-level semantic features for image-to-class similarity measurement. Based on the high-level features, we design a cross-domain self-training strategy to leverage the few labeled samples in source domain to build the classifier in target domain. In addition, we minimize the KL divergence of the high-level feature distributions between source and target domains to shorten the distance of the samples between the two domains. Extensive experiments on DomainNet show that the proposed method significantly outperforms SOTA methods in FS-UDA by a large margin (i.e., ~10\%).},
  archive   = {C_AAAI},
  author    = {Lei Yu and Wanqi Yang and Shengqi Huang and Lei Wang and Ming Yang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26306},
  pages     = {11025-11033},
  title     = {High-level semantic feature matters few-shot unsupervised domain adaptation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Offline imitation learning with suboptimal demonstrations
via relaxed distribution matching. <em>AAAI</em>, 11016–11024. (<a
href="https://doi.org/10.1609/aaai.v37i9.26305">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Offline imitation learning (IL) promises the ability to learn performant policies from pre-collected demonstrations without interactions with the environment. However, imitating behaviors fully offline typically requires numerous expert data. To tackle this issue, we study the setting where we have limited expert data and supplementary suboptimal data. In this case, a well-known issue is the distribution shift between the learned policy and the behavior policy that collects the offline data. Prior works mitigate this issue by regularizing the KL divergence between the stationary state-action distributions of the learned policy and the behavior policy. We argue that such constraints based on exact distribution matching can be overly conservative and hamper policy learning, especially when the imperfect offline data is highly suboptimal. To resolve this issue, we present RelaxDICE, which employs an asymmetrically-relaxed f-divergence for explicit support regularization. Specifically, instead of driving the learned policy to exactly match the behavior policy, we impose little penalty whenever the density ratio between their stationary state-action distributions is upper bounded by a constant. Note that such formulation leads to a nested min-max optimization problem, which causes instability in practice. RelaxDICE addresses this challenge by supporting a closed-form solution for the inner maximization problem. Extensive empirical study shows that our method significantly outperforms the best prior offline IL method in six standard continuous control environments with over 30\% performance gain on average, across 22 settings where the imperfect dataset is highly suboptimal.},
  archive   = {C_AAAI},
  author    = {Lantao Yu and Tianhe Yu and Jiaming Song and Willie Neiswanger and Stefano Ermon},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26305},
  pages     = {11016-11024},
  title     = {Offline imitation learning with suboptimal demonstrations via relaxed distribution matching},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Compressing transformers: Features are low-rank, but weights
are not! <em>AAAI</em>, 11007–11015. (<a
href="https://doi.org/10.1609/aaai.v37i9.26304">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Transformer and its variants achieve excellent results in various computer vision and natural language processing tasks, but high computational costs and reliance on large training datasets restrict their deployment in resource-constrained settings. Low-rank approximation of model weights has been effective in compressing CNN models, but its application to transformers has been less explored and is less effective. Existing methods require the complete dataset to fine-tune compressed models, which are both time-consuming and data-hungry. This paper reveals that the features (i.e., activations) are low-rank, but model weights are surprisingly not low-rank. Hence, AAFM is proposed, which adaptively determines the compressed model structure and locally compresses each linear layer&#39;s output features rather than the model weights. A second stage, GFM, optimizes the entire compressed network holistically. Both AAFM and GFM only use few training samples without labels, that is, they are few-shot, unsupervised, fast and effective. For example, with only 2K images without labels, 33\% of the parameters are removed in DeiT-B with 18.8\% relative throughput increase, but only a 0.23\% accuracy loss for ImageNet recognition. The proposed methods are successfully applied to the language modeling task in NLP, too. Besides, the few-shot compressed models generalize well in downstream tasks.},
  archive   = {C_AAAI},
  author    = {Hao Yu and Jianxin Wu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26304},
  pages     = {11007-11015},
  title     = {Compressing transformers: Features are low-rank, but weights are not!},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Stable learning via sparse variable independence.
<em>AAAI</em>, 10998–11006. (<a
href="https://doi.org/10.1609/aaai.v37i9.26303">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The problem of covariate-shift generalization has attracted intensive research attention. Previous stable learning algorithms employ sample reweighting schemes to decorrelate the covariates when there is no explicit domain information about training data. However, with finite samples, it is difficult to achieve the desirable weights that ensure perfect independence to get rid of the unstable variables. Besides, decorrelating within stable variables may bring about high variance of learned models because of the over-reduced effective sample size. A tremendous sample size is required for these algorithms to work. In this paper, with theoretical justification, we propose SVI (Sparse Variable Independence) for the covariate-shift generalization problem. We introduce sparsity constraint to compensate for the imperfectness of sample reweighting under the finite-sample setting in previous methods. Furthermore, we organically combine independence-based sample reweighting and sparsity-based variable selection in an iterative way to avoid decorrelating within stable variables, increasing the effective sample size to alleviate variance inflation. Experiments on both synthetic and real-world datasets demonstrate the improvement of covariate-shift generalization performance brought by SVI.},
  archive   = {C_AAAI},
  author    = {Han Yu and Peng Cui and Yue He and Zheyan Shen and Yong Lin and Renzhe Xu and Xingxuan Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26303},
  pages     = {10998-11006},
  title     = {Stable learning via sparse variable independence},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Boosted dynamic neural networks. <em>AAAI</em>, 10989–10997.
(<a href="https://doi.org/10.1609/aaai.v37i9.26302">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Early-exiting dynamic neural networks (EDNN), as one type of dynamic neural networks, has been widely studied recently. A typical EDNN has multiple prediction heads at different layers of the network backbone. During inference, the model will exit at either the last prediction head or an intermediate prediction head where the prediction confidence is higher than a predefined threshold. To optimize the model, these prediction heads together with the network backbone are trained on every batch of training data. This brings a train-test mismatch problem that all the prediction heads are optimized on all types of data in training phase while the deeper heads will only see difficult inputs in testing phase. Treating training and testing inputs differently at the two phases will cause the mismatch between training and testing data distributions. To mitigate this problem, we formulate an EDNN as an additive model inspired by gradient boosting, and propose multiple training techniques to optimize the model effectively. We name our method BoostNet. Our experiments show it achieves the state-of-the-art performance on CIFAR100 and ImageNet datasets in both anytime and budgeted-batch prediction modes. Our code is released at https://github.com/SHI-Labs/Boosted-Dynamic-Networks.},
  archive   = {C_AAAI},
  author    = {Haichao Yu and Haoxiang Li and Gang Hua and Gao Huang and Humphrey Shi},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26302},
  pages     = {10989-10997},
  title     = {Boosted dynamic neural networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). STARS: Spatial-temporal active re-sampling for
label-efficient learning from noisy annotations. <em>AAAI</em>,
10980–10988. (<a
href="https://doi.org/10.1609/aaai.v37i9.26301">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Active learning (AL) aims to sample the most informative data instances for labeling, which makes the model fitting data efficient while significantly reducing the annotation cost. However, most existing AL models make a strong assumption that the annotated data instances are always assigned correct labels, which may not hold true in many practical settings. In this paper, we develop a theoretical framework to formally analyze the impact of noisy annotations and show that systematically re-sampling guarantees to reduce the noise rate, which can lead to improved generalization capability. More importantly, the theoretical framework demonstrates the key benefit of conducting active re-sampling on label-efficient learning, which is critical for AL. The theoretical results also suggest essential properties of an active re-sampling function with a fast convergence speed and guaranteed error reduction. This inspires us to design a novel spatial-temporal active re-sampling function by leveraging the important spatial and temporal properties of maximum-margin classifiers. Extensive experiments conducted on both synthetic and real-world data clearly demonstrate the effectiveness of the proposed active re-sampling function.},
  archive   = {C_AAAI},
  author    = {Dayou Yu and Weishi Shi and Qi Yu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26301},
  pages     = {10980-10988},
  title     = {STARS: Spatial-temporal active re-sampling for label-efficient learning from noisy annotations},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Priori anchor labels supervised scalable multi-view
bipartite graph clustering. <em>AAAI</em>, 10972–10979. (<a
href="https://doi.org/10.1609/aaai.v37i9.26300">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Although multi-view clustering (MVC) has achieved remarkable performance by integrating the complementary information of views, it is inefficient when facing scalable data. Proverbially, anchor strategy can mitigate such a challenge a certain extent. However, the unsupervised dynamic strategy usually cannot obtain the optimal anchors for MVC. The main reasons are that it does not consider the fairness of different views and lacks the priori supervised guidance. To completely solve these problems, we first propose the priori anchor graph regularization (PAGG) for scalable multi-view bipartite graph clustering, dubbed as SMGC method. Specifically, SMGC learns a few representative consensus anchors to simulate the numerous view data well, and constructs a bipartite graph to bridge the affinities between the anchors and original data points. In order to largely improve the quality of anchors, PAGG predefines prior anchor labels to constrain the anchors with discriminative cluster structure and fair view allocation, such that a better bipartite graph can be obtained for fast clustering. Experimentally, abundant of experiments are accomplished on six scalable benchmark datasets, and the experimental results fully demonstrate the effectiveness and efficiency of our SMGC.},
  archive   = {C_AAAI},
  author    = {Jiali You and Zhenwen Ren and Xiaojian You and Haoran Li and Yuancheng Yao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26300},
  pages     = {10972-10979},
  title     = {Priori anchor labels supervised scalable multi-view bipartite graph clustering},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Policy-based primal-dual methods for convex constrained
markov decision processes. <em>AAAI</em>, 10963–10971. (<a
href="https://doi.org/10.1609/aaai.v37i9.26299">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study convex Constrained Markov Decision Processes (CMDPs) in which the objective is concave and the constraints are convex in the state-action occupancy measure. We propose a policy-based primal-dual algorithm that updates the primal variable via policy gradient ascent and updates the dual variable via projected sub-gradient descent. Despite the loss of additivity structure and the nonconvex nature, we establish the global convergence of the proposed algorithm by leveraging a hidden convexity in the problem, and prove the O(T^-1/3) convergence rate in terms of both optimality gap and constraint violation. When the objective is strongly concave in the occupancy measure, we prove an improved convergence rate of O(T^-1/2). By introducing a pessimistic term to the constraint, we further show that a zero constraint violation can be achieved while preserving the same convergence rate for the optimality gap. This work is the first one in the literature that establishes non-asymptotic convergence guarantees for policy-based primal-dual methods for solving infinite-horizon discounted convex CMDPs.},
  archive   = {C_AAAI},
  author    = {Donghao Ying and Mengzi Amy Guo and Yuhao Ding and Javad Lavaei and Zuo-Jun Shen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26299},
  pages     = {10963-10971},
  title     = {Policy-based primal-dual methods for convex constrained markov decision processes},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GOHSP: A unified framework of graph and optimization-based
heterogeneous structured pruning for vision transformer. <em>AAAI</em>,
10954–10962. (<a
href="https://doi.org/10.1609/aaai.v37i9.26298">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The recently proposed Vision transformers (ViTs) have shown very impressive empirical performance in various computer vision tasks, and they are viewed as an important type of foundation model. However, ViTs are typically constructed with large-scale sizes, which then severely hinder their potential deployment in many practical resources constrained applications. To mitigate this challenging problem, structured pruning is a promising solution to compress model size and enable practical efficiency. However, unlike its current popularity for CNNs and RNNs, structured pruning for ViT models is little explored. In this paper, we propose GOHSP, a unified framework of Graph and Optimization-based Structured Pruning for ViT models. We first develop a graph-based ranking for measuring the importance of attention heads, and the extracted importance information is further integrated to an optimization-based procedure to impose the heterogeneous structured sparsity patterns on the ViT models. Experimental results show that our proposed GOHSP demonstrates excellent compression performance. On CIFAR-10 dataset, our approach can bring 40\% parameters reduction with no accuracy loss for ViT-Small model. On ImageNet dataset, with 30\% and 35\% sparsity ratio for DeiT-Tiny and DeiT-Small models, our approach achieves 1.65\% and 0.76\% accuracy increase over the existing structured pruning methods, respectively.},
  archive   = {C_AAAI},
  author    = {Miao Yin and Burak Uzkent and Yilin Shen and Hongxia Jin and Bo Yuan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26298},
  pages     = {10954-10962},
  title     = {GOHSP: A unified framework of graph and optimization-based heterogeneous structured pruning for vision transformer},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Lottery pools: Winning more by interpolating tickets without
increasing training or inference cost. <em>AAAI</em>, 10945–10953. (<a
href="https://doi.org/10.1609/aaai.v37i9.26297">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Lottery tickets (LTs) is able to discover accurate and sparse subnetworks that could be trained in isolation to match the performance of dense networks. Ensemble, in parallel, is one of the oldest time-proven tricks in machine learning to improve performance by combining the output of multiple independent models. However, the benefits of ensemble in the context of LTs will be diluted since ensemble does not directly lead to stronger sparse subnetworks, but leverages their predictions for a better decision. In this work, we first observe that directly averaging the weights of the adjacent learned subnetworks significantly boosts the performance of LTs. Encouraged by this observation, we further propose an alternative way to perform an &quot;ensemble&#39;&#39; over the subnetworks identified by iterative magnitude pruning via a simple interpolating strategy. We call our method Lottery Pools. In contrast to the naive ensemble which brings no performance gains to each single subnetwork, Lottery Pools yields much stronger sparse subnetworks than the original LTs without requiring any extra training or inference cost. Across various modern architectures on CIFAR-10/100 and ImageNet, we show that our method achieves significant performance gains in both, in-distribution and out-of-distribution scenarios. Impressively, evaluated with VGG-16 and ResNet-18, the produced sparse subnetworks outperform the original LTs by up to 1.88\% on CIFAR-100 and 2.36\% on CIFAR-100-C; the resulting dense network surpasses the pre-trained dense-model up to 2.22\% on CIFAR-100 and 2.38\% on CIFAR-100-C. Our source code can be found at https://github.com/luuyin/Lottery-pools.},
  archive   = {C_AAAI},
  author    = {Lu Yin and Shiwei Liu and Meng Fang and Tianjin Huang and Vlado Menkovski and Mykola Pechenizkiy},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26297},
  pages     = {10945-10953},
  title     = {Lottery pools: Winning more by interpolating tickets without increasing training or inference cost},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Random walk conformer: Learning graph representation from
long and short range. <em>AAAI</em>, 10936–10944. (<a
href="https://doi.org/10.1609/aaai.v37i9.26296">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {While graph neural networks (GNNs) have achieved notable success in various graph mining tasks, conventional GNNs only model the pairwise correlation in 1-hop neighbors without considering the long-term relations and the high-order patterns, thus limiting their performances. Recently, several works have addressed these issues by exploring the motif, i.e., frequent subgraphs. However, these methods usually require an unacceptable computational time to enumerate all possible combinations of motifs. In this paper, we introduce a new GNN framework, namely Random Walk Conformer (RWC), to exploit global correlations and local patterns based on the random walk, which is a promising method to discover the graph structure. Besides, we propose random walk encoding to help RWC capture topological information, which is proven more expressive than conventional spatial encoding. Extensive experiment results manifest that RWC achieves state-of-the-art performance on graph classification and regression tasks. The source code of RWC is available at https://github.com/b05901024/RandomWalkConformer.},
  archive   = {C_AAAI},
  author    = {Pei-Kai Yeh and Hsi-Wen Chen and Ming-Syan Chen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26296},
  pages     = {10936-10944},
  title     = {Random walk conformer: Learning graph representation from long and short range},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Certifiable out-of-distribution generalization.
<em>AAAI</em>, 10927–10935. (<a
href="https://doi.org/10.1609/aaai.v37i9.26295">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Machine learning methods suffer from test-time performance degeneration when faced with out-of-distribution (OoD) data whose distribution is not necessarily the same as training data distribution. Although a plethora of algorithms have been proposed to mitigate this issue, it has been demonstrated that achieving better performance than ERM simultaneously on different types of distributional shift datasets is challenging for existing approaches. Besides, it is unknown how and to what extent these methods work on any OoD datum without theoretical guarantees. In this paper, we propose a certifiable out-of-distribution generalization method that provides provable OoD generalization performance guarantees via a functional optimization framework leveraging random distributions and max-margin learning for each input datum. With this approach, the proposed algorithmic scheme can provide certified accuracy for each input datum&#39;s prediction on the semantic space and achieves better performance simultaneously on OoD datasets dominated by correlation shifts or diversity shifts. Our code is available at https://github.com/ZlatanWilliams/StochasticDisturbanceLearning.},
  archive   = {C_AAAI},
  author    = {Nanyang Ye and Lin Zhu and Jia Wang and Zhaoyu Zeng and Jiayao Shao and Chensheng Peng and Bikang Pan and Kaican Li and Jun Zhu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26295},
  pages     = {10927-10935},
  title     = {Certifiable out-of-distribution generalization},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Continual variational autoencoder via continual generative
knowledge distillation. <em>AAAI</em>, 10918–10926. (<a
href="https://doi.org/10.1609/aaai.v37i9.26294">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Humans and other living beings have the ability of short and long-term memorization during their entire lifespan. However, most existing Continual Learning (CL) methods can only account for short-term information when training on infinite streams of data. In this paper, we develop a new unsupervised continual learning framework consisting of two memory systems using Variational Autoencoders (VAEs). We develop a Short-Term Memory (STM), and a parameterised scalable memory implemented by a Teacher model aiming to preserve the long-term information. To incrementally enrich the Teacher&#39;s knowledge during training, we propose the Knowledge Incremental Assimilation Mechanism (KIAM), which evaluates the knowledge similarity between the STM and the already accumulated information as signals to expand the Teacher&#39;s capacity. Then we train a VAE as a Student module and propose a new Knowledge Distillation (KD) approach that gradually transfers generative knowledge from the Teacher to the Student module. To ensure the quality and diversity of knowledge in KD, we propose a new expert pruning approach that selectively removes the Teacher&#39;s redundant parameters, associated with unnecessary experts which have learnt overlapping information with other experts. This mechanism further reduces the complexity of the Teacher&#39;s module while ensuring the diversity of knowledge for the KD procedure. We show theoretically and empirically that the proposed framework can train a statistically diversified Teacher module for continual VAE learning which is applicable to learning infinite data streams.},
  archive   = {C_AAAI},
  author    = {Fei Ye and Adrian G. Bors},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26294},
  pages     = {10918-10926},
  title     = {Continual variational autoencoder via continual generative knowledge distillation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023d). Lifelong variational autoencoder via online adversarial
expansion strategy. <em>AAAI</em>, 10909–10917. (<a
href="https://doi.org/10.1609/aaai.v37i9.26293">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Variational Autoencoder (VAE) suffers from a significant loss of information when trained on a non-stationary data distribution. This loss in VAE models, called catastrophic forgetting, has not been studied theoretically before. We analyse the forgetting behaviour of a VAE in continual generative modelling by developing a new lower bound on the data likelihood, which interprets the forgetting process as an increase in the probability distance between the generator&#39;s distribution and the evolved data distribution. The proposed bound shows that a VAE-based dynamic expansion model can achieve better performance if its capacity increases appropriately considering the shift in the data distribution. Based on this analysis, we propose a novel expansion criterion that aims to preserve the information diversity among the VAE components, while ensuring that it acquires more knowledge with fewer parameters. Specifically, we implement this expansion criterion from the perspective of a multi-player game and propose the Online Adversarial Expansion Strategy (OAES), which considers all previously learned components as well as the currently updated component as multiple players in a game, while an adversary model evaluates their performance. The proposed OAES can dynamically estimate the discrepancy between each player and the adversary without accessing task information. This leads to the gradual addition of new components while ensuring the knowledge diversity among all of them. We show theoretically and empirically that the proposed extension strategy can enable a VAE model to achieve the best performance given an appropriate model size.},
  archive   = {C_AAAI},
  author    = {Fei Ye and Adrian G. Bors},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26293},
  pages     = {10909-10917},
  title     = {Lifelong variational autoencoder via online adversarial expansion strategy},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). Lifelong compression mixture model via knowledge
relationship graph. <em>AAAI</em>, 10900–10908. (<a
href="https://doi.org/10.1609/aaai.v37i9.26292">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Task-Free Continual Learning (TFCL) represents a challenging scenario for lifelong learning because the model, under this paradigm, does not access any task information. The Dynamic Expansion Model (DEM) has shown promising results in this scenario due to its scalability and generalisation power. However, DEM focuses only on addressing forgetting and ignores minimizing the model size, which limits its deployment in practical systems. In this work, we aim to simultaneously address network forgetting and model size optimization by developing the Lifelong Compression Mixture Model (LGMM) equipped with the Maximum Mean Discrepancy (MMD) based expansion criterion for model expansion. A diversity-aware sample selection approach is proposed to selectively store a variety of samples to promote information diversity among the components of the LGMM, which allows more knowledge to be captured with an appropriate model size. In order to avoid having multiple components with similar knowledge in the LGMM, we propose a data-free component discarding mechanism that evaluates a knowledge relation graph matrix describing the relevance between each pair of components. A greedy selection procedure is proposed to identify and remove the redundant components from the LGMM. The proposed discarding mechanism can be performed during or after the training. Experiments on different datasets show that LGMM achieves the best performance for TFCL.},
  archive   = {C_AAAI},
  author    = {Fei Ye and Adrian G. Bors},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26292},
  pages     = {10900-10908},
  title     = {Lifelong compression mixture model via knowledge relationship graph},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Learning dynamic latent spaces for lifelong generative
modelling. <em>AAAI</em>, 10891–10899. (<a
href="https://doi.org/10.1609/aaai.v37i9.26291">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Task Free Continual Learning (TFCL) aims to capture novel concepts from non-stationary data streams without forgetting previously learned knowledge. Mixture models, which add new components when certain conditions are met, have shown promising results in TFCL tasks. However, such approaches do not make use of the knowledge already accumulated for positive knowledge transfer. In this paper, we develop a new model, namely the Online Recursive Variational Autoencoder (ORVAE). ORVAE utilizes the prior knowledge by selectively incorporating the newly learnt information, by adding new components, according to the knowledge already known from the past learnt data. We introduce a new attention mechanism to regularize the structural latent space in which the most important information is reused while the information that interferes with novel samples is inactivated. The proposed attention mechanism can maximize the benefit from the forward transfer for learning novel information without forgetting previously learnt knowledge. We perform several experiments which show that ORVAE achieves state-of-the-art results under TFCL.},
  archive   = {C_AAAI},
  author    = {Fei Ye and Adrian G. Bors},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26291},
  pages     = {10891-10899},
  title     = {Learning dynamic latent spaces for lifelong generative modelling},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). I-code: An integrative and composable multimodal learning
framework. <em>AAAI</em>, 10880–10890. (<a
href="https://doi.org/10.1609/aaai.v37i9.26290">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Human intelligence is multimodal; we integrate visual, linguistic, and acoustic signals to maintain a holistic worldview. Most current pretraining methods, however, are limited to one or two modalities. We present i-Code, a self-supervised pretraining framework where users may flexibly combine the modalities of vision, speech, and language into unified and general-purpose vector representations. In this framework, data from each modality are first given to pretrained single-modality encoders. The encoder outputs are then integrated with a multimodal fusion network, which uses novel merge- and co-attention mechanisms to effectively combine information from the different modalities. The entire system is pretrained end-to-end with new objectives including masked modality unit modeling and cross-modality contrastive learning. Unlike previous research using only video for pretraining, the i-Code framework can dynamically process single, dual, and triple-modality data during training and inference, flexibly projecting different combinations of modalities into a single representation space. Experimental results demonstrate how i-Code can outperform state-of-the-art techniques on five multimodal understanding tasks and single-modality benchmarks, improving by as much as 11\% and demonstrating the power of integrative multimodal pretraining.},
  archive   = {C_AAAI},
  author    = {Ziyi Yang and Yuwei Fang and Chenguang Zhu and Reid Pryzant and DongDong Chen and Yu Shi and Yichong Xu and Yao Qian and Mei Gao and Yi-Ling Chen and Liyang Lu and Yujia Xie and Robert Gmyr and Noel Codella and Naoyuki Kanda and Bin Xiao and Lu Yuan and Takuya Yoshioka and Michael Zeng and Xuedong Huang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26290},
  pages     = {10880-10890},
  title     = {I-code: An integrative and composable multimodal learning framework},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Purifier: Defending data inference attacks via transforming
confidence scores. <em>AAAI</em>, 10871–10879. (<a
href="https://doi.org/10.1609/aaai.v37i9.26289">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Neural networks are susceptible to data inference attacks such as the membership inference attack, the adversarial model inversion attack and the attribute inference attack, where the attacker could infer useful information such as the membership, the reconstruction or the sensitive attributes of a data sample from the confidence scores predicted by the target classifier. In this paper, we propose a method, namely PURIFIER, to defend against membership inference attacks. It transforms the confidence score vectors predicted by the target classifier and makes purified confidence scores indistinguishable in individual shape, statistical distribution and prediction label between members and non-members. The experimental results show that PURIFIER helps defend membership inference attacks with high effectiveness and efficiency, outperforming previous defense methods, and also incurs negligible utility loss. Besides, our further experiments show that PURIFIER is also effective in defending adversarial model inversion attacks and attribute inference attacks. For example, the inversion error is raised about 4+ times on the Facescrub530 classifier, and the attribute inference accuracy drops significantly when PURIFIER is deployed in our experiment.},
  archive   = {C_AAAI},
  author    = {Ziqi Yang and Lijin Wang and Da Yang and Jie Wan and Ziming Zhao and Ee-Chien Chang and Fan Zhang and Kui Ren},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26289},
  pages     = {10871-10879},
  title     = {Purifier: Defending data inference attacks via transforming confidence scores},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DeCOM: Decomposed policy for constrained cooperative
multi-agent reinforcement learning. <em>AAAI</em>, 10861–10870. (<a
href="https://doi.org/10.1609/aaai.v37i9.26288">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In recent years, multi-agent reinforcement learning (MARL) has presented impressive performance in various applications. However, physical limitations, budget restrictions, and many other factors usually impose constraints on a multi-agent system (MAS), which cannot be handled by traditional MARL frameworks. Specifically, this paper focuses on constrained MASes where agents work cooperatively to maximize the expected team-average return under various constraints on expected team-average costs, and develops a constrained cooperative MARL framework, named DeCOM, for such MASes. In particular, DeCOM decomposes the policy of each agent into two modules, which empowers information sharing among agents to achieve better cooperation. In addition, with such modularization, the training algorithm of DeCOM separates the original constrained optimization into an unconstrained optimization on reward and a constraints satisfaction problem on costs. DeCOM then iteratively solves these problems in a computationally efficient manner, which makes DeCOM highly scalable. We also provide theoretical guarantees on the convergence of DeCOM&#39;s policy update algorithm. Finally, we conduct extensive experiments to show the effectiveness of DeCOM with various types of costs in both moderate-scale and large-scale (with 500 agents) environments that originate from real-world applications.},
  archive   = {C_AAAI},
  author    = {Zhaoxing Yang and Haiming Jin and Rong Ding and Haoyi You and Guiyun Fan and Xinbing Wang and Chenghu Zhou},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26288},
  pages     = {10861-10870},
  title     = {DeCOM: Decomposed policy for constrained cooperative multi-agent reinforcement learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Prototypical partial optimal transport for universal domain
adaptation. <em>AAAI</em>, 10852–10860. (<a
href="https://doi.org/10.1609/aaai.v37i9.26287">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Universal domain adaptation (UniDA) aims to transfer knowledge from a labeled source domain to an unlabeled target domain without requiring the same label sets of both domains. The existence of domain and category shift makes the task challenging and requires us to distinguish “known” samples (i.e., samples whose labels exist in both domains) and “unknown” samples (i.e., samples whose labels exist in only one domain) in both domains before reducing the domain gap. In this paper, we consider the problem from the point of view of distribution matching which we only need to align two distributions partially. A novel approach, dubbed mini-batch Prototypical Partial Optimal Transport (m-PPOT), is proposed to conduct partial distribution alignment for UniDA. In training phase, besides minimizing m-PPOT, we also leverage the transport plan of m-PPOT to reweight source prototypes and target samples, and design reweighted entropy loss and reweighted cross-entropy loss to distinguish “known” and “unknown” samples. Experiments on four benchmarks show that our method outperforms the previous state-of-the-art UniDA methods.},
  archive   = {C_AAAI},
  author    = {Yucheng Yang and Xiang Gu and Jian Sun},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26287},
  pages     = {10852-10860},
  title     = {Prototypical partial optimal transport for universal domain adaptation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Flow to control: Offline reinforcement learning with
lossless primitive discovery. <em>AAAI</em>, 10843–10851. (<a
href="https://doi.org/10.1609/aaai.v37i9.26286">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Offline reinforcement learning (RL) enables the agent to effectively learn from logged data, which significantly extends the applicability of RL algorithms in real-world scenarios where exploration can be expensive or unsafe. Previous works have shown that extracting primitive skills from the recurring and temporally extended structures in the logged data yields better learning. However, these methods suffer greatly when the primitives have limited representation ability to recover the original policy space, especially in offline settings. In this paper, we give a quantitative characterization of the performance of offline hierarchical learning and highlight the importance of learning lossless primitives. To this end, we propose to use a flow-based structure as the representation for low-level policies. This allows us to represent the behaviors in the dataset faithfully while keeping the expression ability to recover the whole policy space. We show that such lossless primitives can drastically improve the performance of hierarchical policies. The experimental results and extensive ablation studies on the standard D4RL benchmark show that our method has a good representation ability for policies and achieves superior performance in most tasks.},
  archive   = {C_AAAI},
  author    = {Yiqin Yang and Hao Hu and Wenzhe Li and Siyuan Li and Jun Yang and Qianchuan Zhao and Chongjie Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26286},
  pages     = {10843-10851},
  title     = {Flow to control: Offline reinforcement learning with lossless primitive discovery},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cluster-guided contrastive graph clustering network.
<em>AAAI</em>, 10834–10842. (<a
href="https://doi.org/10.1609/aaai.v37i9.26285">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Benefiting from the intrinsic supervision information exploitation capability, contrastive learning has achieved promising performance in the field of deep graph clustering recently. However, we observe that two drawbacks of the positive and negative sample construction mechanisms limit the performance of existing algorithms from further improvement. 1) The quality of positive samples heavily depends on the carefully designed data augmentations, while inappropriate data augmentations would easily lead to the semantic drift and indiscriminative positive samples. 2) The constructed negative samples are not reliable for ignoring important clustering information. To solve these problems, we propose a Cluster-guided Contrastive deep Graph Clustering network (CCGC) by mining the intrinsic supervision information in the high-confidence clustering results. Specifically, instead of conducting complex node or edge perturbation, we construct two views of the graph by designing special Siamese encoders whose weights are not shared between the sibling sub-networks. Then, guided by the high-confidence clustering information, we carefully select and construct the positive samples from the same high-confidence cluster in two views. Moreover, to construct semantic meaningful negative sample pairs, we regard the centers of different high-confidence clusters as negative samples, thus improving the discriminative capability and reliability of the constructed sample pairs. Lastly, we design an objective function to pull close the samples from the same cluster while pushing away those from other clusters by maximizing and minimizing the cross-view cosine similarity between positive and negative samples. Extensive experimental results on six datasets demonstrate the effectiveness of CCGC compared with the existing state-of-the-art algorithms. The code of CCGC is available at https://github.com/xihongyang1999/CCGC on Github.},
  archive   = {C_AAAI},
  author    = {Xihong Yang and Yue Liu and Sihang Zhou and Siwei Wang and Wenxuan Tu and Qun Zheng and Xinwang Liu and Liming Fang and En Zhu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26285},
  pages     = {10834-10842},
  title     = {Cluster-guided contrastive graph clustering network},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). T-distributed spherical feature representation for
imbalanced classification. <em>AAAI</em>, 10825–10833. (<a
href="https://doi.org/10.1609/aaai.v37i9.26284">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Real-world classification tasks often show an extremely imbalanced problem. The extreme imbalance will cause a strong bias that the decision boundary of the classifier is completely dominated by the categories with abundant samples, which are also called the head categories. Current methods have alleviated the imbalanced impact from mainly three aspects: class re-balance, decoupling and domain adaptation. However, the existing criterion with the winner-take-all strategy still leads to the crowding problem in the eigenspace. The head categories with many samples can extract features more accurately, but occupy most of the eigenspace. The tail categories sharing the rest of the narrow eigenspace are too crowded together to accurately extract features. Above these issues, we propose a novel T-distributed spherical metric for equalized eigenspace in the imbalanced classification, which has the following innovations: 1) We design the T-distributed spherical metric, which has the characteristics of high kurtosis. Instead of the winner-take-all strategy, the T-distributed spherical metric produces a high logit only when the extracted feature is close enough to the category center, without a strong bias against other categories. 2) The T-distributed spherical metric is integrated into the classifier, which is able to equalize the eigenspace for alleviating the crowding issue in the imbalanced problem. The equalized eigenspace by the T-distributed spherical classifier is capable of improving the accuracy of the tail categories while maintaining the accuracy of the head, which significantly promotes the intraclass compactness and interclass separability of features. Extensive experiments on large-scale imbalanced datasets verify our method, which shows superior results in the long-tailed CIFAR-100/-10 with the imbalanced ratio IR = 100/50. Our method also achieves excellent results on the large-scale ImageNet-LT dataset and the iNaturalist dataset with various backbones. In addition, we provide a case study of the real clinical classification of pancreatic tumor subtypes with 6 categories. Among them, the largest number of PDAC accounts for 315 cases, and the least CP has only 8 cases. After 4-fold cross-validation, we achieved a top-1 accuracy of 69.04\%.},
  archive   = {C_AAAI},
  author    = {Xiaoyu Yang and Yufei Chen and Xiaodong Yue and Shaoxun Xu and Chao Ma},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26284},
  pages     = {10825-10833},
  title     = {T-distributed spherical feature representation for imbalanced classification},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Simple and efficient heterogeneous graph neural network.
<em>AAAI</em>, 10816–10824. (<a
href="https://doi.org/10.1609/aaai.v37i9.26283">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Heterogeneous graph neural networks (HGNNs) have the powerful capability to embed rich structural and semantic information of a heterogeneous graph into node representations. Existing HGNNs inherit many mechanisms from graph neural networks (GNNs) designed for homogeneous graphs, especially the attention mechanism and the multi-layer structure. These mechanisms bring excessive complexity, but seldom work studies whether they are really effective on heterogeneous graphs. In this paper, we conduct an in-depth and detailed study of these mechanisms and propose the Simple and Efficient Heterogeneous Graph Neural Network (SeHGNN). To easily capture structural information, SeHGNN pre-computes the neighbor aggregation using a light-weight mean aggregator, which reduces complexity by removing overused neighbor attention and avoiding repeated neighbor aggregation in every training epoch. To better utilize semantic information, SeHGNN adopts the single-layer structure with long metapaths to extend the receptive field, as well as a transformer-based semantic fusion module to fuse features from different metapaths. As a result, SeHGNN exhibits the characteristics of a simple network structure, high prediction accuracy, and fast training speed. Extensive experiments on five real-world heterogeneous graphs demonstrate the superiority of SeHGNN over the state-of-the-arts on both accuracy and training speed.},
  archive   = {C_AAAI},
  author    = {Xiaocheng Yang and Mingyu Yan and Shirui Pan and Xiaochun Ye and Dongrui Fan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26283},
  pages     = {10816-10824},
  title     = {Simple and efficient heterogeneous graph neural network},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Understanding representation learnability of nonlinear
self-supervised learning. <em>AAAI</em>, 10807–10815. (<a
href="https://doi.org/10.1609/aaai.v37i9.26282">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Self-supervised learning (SSL) has empirically shown its data representation learnability in many downstream tasks. There are only a few theoretical works on data representation learnability, and many of those focus on final data representation, treating the nonlinear neural network as a ``black box&quot;. However, the accurate learning results of neural networks are crucial for describing the data distribution features learned by SSL models. Our paper is the first to analyze the learning results of the nonlinear SSL model accurately. We consider a toy data distribution that contains two features: the label-related feature and the hidden feature. Unlike previous linear setting work that depends on closed-form solutions, we use the gradient descent algorithm to train a 1-layer nonlinear SSL model with a certain initialization region and prove that the model converges to a local minimum. Furthermore, different from the complex iterative analysis, we propose a new analysis process which uses the exact version of Inverse Function Theorem to accurately describe the features learned by the local minimum. With this local minimum, we prove that the nonlinear SSL model can capture the label-related feature and hidden feature at the same time. In contrast, the nonlinear supervised learning (SL) model can only learn the label-related feature. We also present the learning processes and results of the nonlinear SSL and SL model via simulation experiments.},
  archive   = {C_AAAI},
  author    = {Ruofeng Yang and Xiangyuan Li and Bo Jiang and Shuai Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26282},
  pages     = {10807-10815},
  title     = {Understanding representation learnability of nonlinear self-supervised learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CEM: Constrained entropy maximization for task-agnostic safe
exploration. <em>AAAI</em>, 10798–10806. (<a
href="https://doi.org/10.1609/aaai.v37i9.26281">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the absence of assigned tasks, a learning agent typically seeks to explore its environment efficiently. However, the pursuit of exploration will bring more safety risks. An under-explored aspect of reinforcement learning is how to achieve safe efficient exploration when the task is unknown. In this paper, we propose a practical Constrained Entropy Maximization (CEM) algorithm to solve task-agnostic safe exploration problems, which naturally require a finite horizon and undiscounted constraints on safety costs. The CEM algorithm aims to learn a policy that maximizes state entropy under the premise of safety. To avoid approximating the state density in complex domains, CEM leverages a k-nearest neighbor entropy estimator to evaluate the efficiency of exploration. In terms of safety, CEM minimizes the safety costs, and adaptively trades off safety and exploration based on the current constraint satisfaction. The empirical analysis shows that CEM enables the acquisition of a safe exploration policy in complex environments, resulting in improved performance in both safety and sample efficiency for target tasks.},
  archive   = {C_AAAI},
  author    = {Qisong Yang and Matthijs T.J. Spaan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26281},
  pages     = {10798-10806},
  title     = {CEM: Constrained entropy maximization for task-agnostic safe exploration},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Generalized semantic segmentation by self-supervised source
domain projection and multi-level contrastive learning. <em>AAAI</em>,
10789–10797. (<a
href="https://doi.org/10.1609/aaai.v37i9.26280">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep networks trained on the source domain show degraded performance when tested on unseen target domain data. To enhance the model&#39;s generalization ability, most existing domain generalization methods learn domain invariant features by suppressing domain sensitive features. Different from them, we propose a Domain Projection and Contrastive Learning (DPCL) approach for generalized semantic segmentation, which includes two modules: Self-supervised Source Domain Projection (SSDP) and Multi-Level Contrastive Learning (MLCL). SSDP aims to reduce domain gap by projecting data to the source domain, while MLCL is a learning scheme to learn discriminative and generalizable features on the projected data. During test time, we first project the target data by SSDP to mitigate domain shift, then generate the segmentation results by the learned segmentation network based on MLCL. At test time, we can update the projected data by minimizing our proposed pixel-to-pixel contrastive loss to obtain better results. Extensive experiments for semantic segmentation demonstrate the favorable generalization capability of our method on benchmark datasets.},
  archive   = {C_AAAI},
  author    = {Liwei Yang and Xiang Gu and Jian Sun},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26280},
  pages     = {10789-10797},
  title     = {Generalized semantic segmentation by self-supervised source domain projection and multi-level contrastive learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). ADEPT: A DEbiasing PrompT framework. <em>AAAI</em>,
10780–10788. (<a
href="https://doi.org/10.1609/aaai.v37i9.26279">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Several works have proven that finetuning is an applicable approach for debiasing contextualized word embeddings. Similarly, discrete prompts with semantic meanings have shown to be effective in debiasing tasks. With unfixed mathematical representation at the token level, continuous prompts usually surpass discrete ones at providing a pre-trained language model (PLM) with additional task-specific information. Despite this, relatively few efforts have been made to debias PLMs by prompt tuning with continuous prompts compared to its discrete counterpart. Furthermore, for most debiasing methods that alter a PLM&#39;s original parameters, a major problem is the need to not only decrease the bias in the PLM but also to ensure that the PLM does not lose its representation ability. Finetuning methods typically have a hard time maintaining this balance, as they tend to violently remove meanings of attribute words (like the words developing our concepts of &quot;male&quot; and &quot;female&quot; for gender), which also leads to an unstable and unpredictable training process. In this paper, we propose ADEPT, a method to debias PLMs using prompt tuning while maintaining the delicate balance between removing biases and ensuring representation ability. To achieve this, we propose a new training criterion inspired by manifold learning and equip it with an explicit debiasing term to optimize prompt tuning. In addition, we conduct several experiments with regard to the reliability, quality, and quantity of a previously proposed attribute training corpus in order to obtain a clearer prototype of a certain attribute, which indicates the attribute&#39;s position and relative distances to other words on the manifold. We evaluate ADEPT on several widely acknowledged debiasing benchmarks and downstream tasks, and find that it achieves competitive results while maintaining (and in some cases even improving) the PLM&#39;s representation ability. We further visualize words&#39; correlation before and after debiasing a PLM, and give some possible explanations for the visible effects.},
  archive   = {C_AAAI},
  author    = {Ke Yang and Charles Yu and Yi R. Fung and Manling Li and Heng Ji},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26279},
  pages     = {10780-10788},
  title     = {ADEPT: A DEbiasing PrompT framework},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning-assisted algorithm unrolling for online
optimization with budget constraints. <em>AAAI</em>, 10771–10779. (<a
href="https://doi.org/10.1609/aaai.v37i9.26278">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Online optimization with multiple budget constraints is challenging since the online decisions over a short time horizon are coupled together by strict inventory constraints. The existing manually-designed algorithms cannot achieve satisfactory average performance for this setting because they often need a large number of time steps for convergence and/or may violate the inventory constraints. In this paper, we propose a new machine learning (ML) assisted unrolling approach, called LAAU (Learning-Assisted Algorithm Unrolling), which unrolls the agent’s online decision pipeline and leverages an ML model for updating the Lagrangian multiplier online. For efficient training via backpropagation, we derive gradients of the decision pipeline over time. We also provide the average cost bounds for two cases when training data is available offline and collected online, respectively. Finally, we present numerical results to highlight that LAAU can outperform the existing baselines.},
  archive   = {C_AAAI},
  author    = {Jianyi Yang and Shaolei Ren},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26278},
  pages     = {10771-10779},
  title     = {Learning-assisted algorithm unrolling for online optimization with budget constraints},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Layout generation as intermediate action sequence
prediction. <em>AAAI</em>, 10762–10770. (<a
href="https://doi.org/10.1609/aaai.v37i9.26277">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Layout generation plays a crucial role in graphic design intelligence. One important characteristic of the graphic layouts is that they usually follow certain design principles. For example, the principle of repetition emphasizes the reuse of similar visual elements throughout the design. To generate a layout, previous works mainly attempt at predicting the absolute value of bounding box for each element, where such target representation has hidden the information of higher-order design operations like repetition (e.g. copy the size of the previously generated element). In this paper, we introduce a novel action schema to encode these operations for better modeling the generation process. Instead of predicting the bounding box values, our approach autoregressively outputs the intermediate action sequence, which can then be deterministically converted to the final layout. We achieve state-of-the-art performances on three datasets. Both automatic and human evaluations show that our approach generates high-quality and diverse layouts. Furthermore, we revisit the commonly used evaluation metric FID adapted in this task, and observe that previous works use different settings to train the feature extractor for obtaining real/generated data distribution, which leads to inconsistent conclusions. We conduct an in-depth analysis on this metric and settle for a more robust and reliable evaluation setting. Code is available at this website.},
  archive   = {C_AAAI},
  author    = {Huiting Yang and Danqing Huang and Chin-Yew Lin and Shengfeng He},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26277},
  pages     = {10762-10770},
  title     = {Layout generation as intermediate action sequence prediction},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). WaveForM: Graph enhanced wavelet learning for long sequence
forecasting of multivariate time series. <em>AAAI</em>, 10754–10761. (<a
href="https://doi.org/10.1609/aaai.v37i9.26276">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multivariate time series (MTS) analysis and forecasting are crucial in many real-world applications, such as smart traffic management and weather forecasting. However, most existing work either focuses on short sequence forecasting or makes predictions predominantly with time domain features, which is not effective at removing noises with irregular frequencies in MTS. Therefore, we propose WaveForM, an end-to-end graph enhanced Wavelet learning framework for long sequence FORecasting of MTS. WaveForM first utilizes Discrete Wavelet Transform (DWT) to represent MTS in the wavelet domain, which captures both frequency and time domain features with a sound theoretical basis. To enable the effective learning in the wavelet domain, we further propose a graph constructor, which learns a global graph to represent the relationships between MTS variables, and graph-enhanced prediction modules, which utilize dilated convolution and graph convolution to capture the correlations between time series and predict the wavelet coefficients at different levels. Extensive experiments on five real-world forecasting datasets show that our model can achieve considerable performance improvement over different prediction lengths against the most competitive baseline of each dataset.},
  archive   = {C_AAAI},
  author    = {Fuhao Yang and Xin Li and Min Wang and Hongyu Zang and Wei Pang and Mingzhong Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26276},
  pages     = {10754-10761},
  title     = {WaveForM: Graph enhanced wavelet learning for long sequence forecasting of multivariate time series},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AdaTask: A task-aware adaptive learning rate approach to
multi-task learning. <em>AAAI</em>, 10745–10753. (<a
href="https://doi.org/10.1609/aaai.v37i9.26275">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-task learning (MTL) models have demonstrated impressive results in computer vision, natural language processing, and recommender systems. Even though many approaches have been proposed, how well these approaches balance different tasks on each parameter still remains unclear. In this paper, we propose to measure the task dominance degree of a parameter by the total updates of each task on this parameter. Specifically, we compute the total updates by the exponentially decaying Average of the squared Updates (AU) on a parameter from the corresponding task. Based on this novel metric, we observe that many parameters in existing MTL methods, especially those in the higher shared layers, are still dominated by one or several tasks. The dominance of AU is mainly due to the dominance of accumulative gradients from one or several tasks. Motivated by this, we propose a Task-wise Adaptive learning rate approach, AdaTask in short, to separate the accumulative gradients and hence the learning rate of each task for each parameter in adaptive learning rate approaches (e.g., AdaGrad, RMSProp, and Adam). Comprehensive experiments on computer vision and recommender system MTL datasets demonstrate that AdaTask significantly improves the performance of dominated tasks, resulting SOTA average task-wise performance. Analysis on both synthetic and real-world datasets shows AdaTask balance parameters in every shared layer well.},
  archive   = {C_AAAI},
  author    = {Enneng Yang and Junwei Pan and Ximei Wang and Haibin Yu and Li Shen and Xihua Chen and Lei Xiao and Jie Jiang and Guibing Guo},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26275},
  pages     = {10745-10753},
  title     = {AdaTask: A task-aware adaptive learning rate approach to multi-task learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Reinforcement causal structure learning on order graph.
<em>AAAI</em>, 10737–10744. (<a
href="https://doi.org/10.1609/aaai.v37i9.26274">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Learning directed acyclic graph (DAG) that describes the causality of observed data is a very challenging but important task. Due to the limited quantity and quality of observed data, and non-identifiability of causal graph, it is almost impossible to infer a single precise DAG. Some methods approximate the posterior distribution of DAGs to explore the DAG space via Markov chain Monte Carlo (MCMC), but the DAG space is over the nature of super-exponential growth, accurately characterizing the whole distribution over DAGs is very intractable. In this paper, we propose Reinforcement Causal Structure Learning on Order Graph (RCL-OG) that uses order graph instead of MCMC to model different DAG topological orderings and to reduce the problem size. RCL-OG first defines reinforcement learning with a new reward mechanism to approximate the posterior distribution of orderings in an efficacy way, and uses deep Q-learning to update and transfer rewards between nodes. Next, it obtains the probability transition model of nodes on order graph, and computes the posterior probability of different orderings. In this way, we can sample on this model to obtain the ordering with high probability. Experiments on synthetic and benchmark datasets show that RCL-OG provides accurate posterior probability approximation and achieves better results than competitive causal discovery algorithms.},
  archive   = {C_AAAI},
  author    = {Dezhi Yang and Guoxian Yu and Jun Wang and Zhengtian Wu and Maozu Guo},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26274},
  pages     = {10737-10744},
  title     = {Reinforcement causal structure learning on order graph},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Computably continuous reinforcement-learning objectives are
PAC-learnable. <em>AAAI</em>, 10729–10736. (<a
href="https://doi.org/10.1609/aaai.v37i9.26273">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In reinforcement learning, the classic objectives of maximizing discounted and finite-horizon cumulative rewards are PAC-learnable: There are algorithms that learn a near-optimal policy with high probability using a finite amount of samples and computation. In recent years, researchers have introduced objectives and corresponding reinforcement-learning algorithms beyond the classic cumulative rewards, such as objectives specified as linear temporal logic formulas. However, questions about the PAC-learnability of these new objectives have remained open. This work demonstrates the PAC-learnability of general reinforcement-learning objectives through sufficient conditions for PAC-learnability in two analysis settings. In particular, for the analysis that considers only sample complexity, we prove that if an objective given as an oracle is uniformly continuous, then it is PAC-learnable. Further, for the analysis that considers computational complexity, we prove that if an objective is computable, then it is PAC-learnable. In other words, if a procedure computes successive approximations of the objective&#39;s value, then the objective is PAC-learnable. We give three applications of our condition on objectives from the literature with previously unknown PAC-learnability and prove that these objectives are PAC-learnable. Overall, our result helps verify existing objectives&#39; PAC-learnability. Also, as some studied objectives that are not uniformly continuous have been shown to be not PAC-learnable, our results could guide the design of new PAC-learnable objectives.},
  archive   = {C_AAAI},
  author    = {Cambridge Yang and Michael Littman and Michael Carbin},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26273},
  pages     = {10729-10736},
  title     = {Computably continuous reinforcement-learning objectives are PAC-learnable},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). T2G-FORMER: Organizing tabular features into relation graphs
promotes heterogeneous feature interaction. <em>AAAI</em>, 10720–10728.
(<a href="https://doi.org/10.1609/aaai.v37i9.26272">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent development of deep neural networks (DNNs) for tabular learning has largely benefited from the capability of DNNs for automatic feature interaction. However, the heterogeneity nature of tabular features makes such features relatively independent, and developing effective methods to promote tabular feature interaction still remains an open problem. In this paper, we propose a novel Graph Estimator, which automatically estimates the relations among tabular features and builds graphs by assigning edges between related features. Such relation graphs organize independent tabular features into a kind of graph data such that interaction of nodes (tabular features) can be conducted in an orderly fashion. Based on our proposed Graph Estimator, we present a bespoke Transformer network tailored for tabular learning, called T2G-Former, which processes tabular data by performing tabular feature interaction guided by the relation graphs. A specific Cross-level Readout collects salient features predicted by the layers in T2G-Former across different levels, and attains global semantics for final prediction. Comprehensive experiments show that our T2G-Former achieves superior performance among DNNs and is competitive with non-deep Gradient Boosted Decision Tree models. The code and detailed results are available at https://github.com/jyansir/t2g-former.},
  archive   = {C_AAAI},
  author    = {Jiahuan Yan and Jintai Chen and Yixuan Wu and Danny Z. Chen and Jian Wu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26272},
  pages     = {10720-10728},
  title     = {T2G-FORMER: Organizing tabular features into relation graphs promotes heterogeneous feature interaction},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DeFL: Defending against model poisoning attacks in federated
learning via critical learning periods awareness. <em>AAAI</em>,
10711–10719. (<a
href="https://doi.org/10.1609/aaai.v37i9.26271">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Federated learning (FL) is known to be susceptible to model poisoning attacks in which malicious clients hamper the accuracy of the global model by sending manipulated model updates to the central server during the FL training process. Existing defenses mainly focus on Byzantine-robust FL aggregations, and largely ignore the impact of the underlying deep neural network (DNN) that is used to FL training. Inspired by recent findings on critical learning periods (CLP) in DNNs, where small gradient errors have irrecoverable impact on the final model accuracy, we propose a new defense, called a CLP-aware defense against poisoning of FL (DeFL). The key idea of DeFL is to measure fine-grained differences between DNN model updates via an easy-to-compute federated gradient norm vector (FGNV) metric. Using FGNV, DeFL simultaneously detects malicious clients and identifies CLP, which in turn is leveraged to guide the adaptive removal of detected malicious clients from aggregation. As a result, DeFL not only mitigates model poisoning attacks on the global model but also is robust to detection errors. Our extensive experiments on three benchmark datasets demonstrate that DeFL produces significant performance gain over conventional defenses against state-of-the-art model poisoning attacks.},
  archive   = {C_AAAI},
  author    = {Gang Yan and Hao Wang and Xu Yuan and Jian Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26271},
  pages     = {10711-10719},
  title     = {DeFL: Defending against model poisoning attacks in federated learning via critical learning periods awareness},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Semidefinite programming versus burer-monteiro factorization
for matrix sensing. <em>AAAI</em>, 10702–10710. (<a
href="https://doi.org/10.1609/aaai.v37i9.26270">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Many fundamental low-rank optimization problems, such as matrix completion, phase retrieval, and robust PCA, can be formulated as the matrix sensing problem. Two main approaches for solving matrix sensing are based on semidefinite programming (SDP) and Burer-Monteiro (B-M) factorization. The former suffers from high computational and space complexities, whereas the latter may return a spurious solution due to the non-convexity of the problem. The existing theoretical guarantees for the success of these methods have led to similar conservative conditions, which may wrongly imply that these methods have comparable performances. In this paper, we shed light on some major differences between these two methods. First, we present a class of structured matrix completion problems for which the B-M methods fail with an overwhelming probability, while the SDP method works correctly. Second, we identify a class of highly sparse matrix completion problems for which the B-M method works and the SDP method fails. Third, we prove that although the B-M method exhibits the same performance independent of the rank of the unknown solution, the success of the SDP method is correlated to the rank of the solution and improves as the rank increases. Unlike the existing literature that has mainly focused on those instances of matrix sensing for which both SDP and B-M work, this paper offers the first result on the unique merit of each method over the alternative approach.},
  archive   = {C_AAAI},
  author    = {Baturalp Yalçın and Ziye Ma and Javad Lavaei and Somayeh Sojoudi},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26270},
  pages     = {10702-10710},
  title     = {Semidefinite programming versus burer-monteiro factorization for matrix sensing},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning the finer things: Bayesian structure learning at
the instantiation level. <em>AAAI</em>, 10693–10701. (<a
href="https://doi.org/10.1609/aaai.v37i9.26269">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Successful machine learning methods require a trade-off between memorization and generalization. Too much memorization and the model cannot generalize to unobserved examples. Too much over-generalization and we risk under-fitting the data. While we commonly measure their performance through cross validation and accuracy metrics, how should these algorithms cope in domains that are extremely under-determined where accuracy is always unsatisfactory? We present a novel probabilistic graphical model structure learning approach that can learn, generalize and explain in these elusive domains by operating at the random variable instantiation level. Using Minimum Description Length (MDL) analysis, we propose a new decomposition of the learning problem over all training exemplars, fusing together minimal entropy inferences to construct a final knowledge base. By leveraging Bayesian Knowledge Bases (BKBs), a framework that operates at the instantiation level and inherently subsumes Bayesian Networks (BNs), we develop both a theoretical MDL score and associated structure learning algorithm that demonstrates significant improvements over learned BNs on 40 benchmark datasets. Further, our algorithm incorporates recent off-the-shelf DAG learning techniques enabling tractable results even on large problems. We then demonstrate the utility of our approach in a significantly under-determined domain by learning gene regulatory networks on breast cancer gene mutational data available from The Cancer Genome Atlas (TCGA).},
  archive   = {C_AAAI},
  author    = {Chase Yakaboski and Eugene Santos, Jr},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26269},
  pages     = {10693-10701},
  title     = {Learning the finer things: Bayesian structure learning at the instantiation level},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fast and accurate binary neural networks based on
depth-width reshaping. <em>AAAI</em>, 10684–10692. (<a
href="https://doi.org/10.1609/aaai.v37i9.26268">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Network binarization (i.e., binary neural networks, BNNs) can efficiently compress deep neural networks and accelerate model inference but cause severe accuracy degradation. Existing BNNs are mainly implemented based on the commonly used full-precision network backbones, and then the accuracy is improved with various techniques. However, there is a question of whether the full-precision network backbone is well adapted to BNNs. We start from the factors of the performance degradation of BNNs and analyze the problems of directly using full-precision network backbones for BNNs: for a given computational budget, the backbone of a BNN may need to be shallower and wider compared to the backbone of a full-precision network. With this in mind, Depth-Width Reshaping (DWR) is proposed to reshape the depth and width of existing full-precision network backbones and further optimize them by incorporating pruning techniques to better fit the BNNs. Extensive experiments demonstrate the analytical result and the effectiveness of the proposed method. Compared with the original backbones, the DWR backbones constructed by the proposed method result in close to O(√s) decrease in activations, while achieving an absolute accuracy increase by up to 1.7\% with comparable computational cost. Besides, by using the DWR backbones, existing methods can achieve new state-of-the-art (SOTA) accuracy (e.g., 67.2\% on ImageNet with ResNet-18 as the original backbone). We hope this work provides a novel insight into the backbone design of BNNs. The code is available at https://github.com/pingxue-hfut/DWR.},
  archive   = {C_AAAI},
  author    = {Ping Xue and Yang Lu and Jingfei Chang and Xing Wei and Zhen Wei},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26268},
  pages     = {10684-10692},
  title     = {Fast and accurate binary neural networks based on depth-width reshaping},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Global concept-based interpretability for graph neural
networks via neuron analysis. <em>AAAI</em>, 10675–10683. (<a
href="https://doi.org/10.1609/aaai.v37i9.26267">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph neural networks (GNNs) are highly effective on a variety of graph-related tasks; however, they lack interpretability and transparency. Current explainability approaches are typically local and treat GNNs as black-boxes. They do not look inside the model, inhibiting human trust in the model and explanations. Motivated by the ability of neurons to detect high-level semantic concepts in vision models, we perform a novel analysis on the behaviour of individual GNN neurons to answer questions about GNN interpretability. We propose a novel approach for producing global explanations for GNNs using neuron-level concepts to enable practitioners to have a high-level view of the model. Specifically, (i) to the best of our knowledge, this is the first work which shows that GNN neurons act as concept detectors and have strong alignment with concepts formulated as logical compositions of node degree and neighbourhood properties; (ii) we quantitatively assess the importance of detected concepts, and identify a trade-off between training duration and neuron-level interpretability; (iii) we demonstrate that our global explainability approach has advantages over the current state-of-the-art -- we can disentangle the explanation into individual interpretable concepts backed by logical descriptions, which reduces potential for bias and improves user-friendliness.},
  archive   = {C_AAAI},
  author    = {Han Xuanyuan and Pietro Barbiero and Dobrik Georgiev and Lucie Charlotte Magister and Pietro Liò},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26267},
  pages     = {10675-10683},
  title     = {Global concept-based interpretability for graph neural networks via neuron analysis},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Disentangled representation for causal mediation analysis.
<em>AAAI</em>, 10666–10674. (<a
href="https://doi.org/10.1609/aaai.v37i9.26266">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Estimating direct and indirect causal effects from observational data is crucial to understanding the causal mechanisms and predicting the behaviour under different interventions. Causal mediation analysis is a method that is often used to reveal direct and indirect effects. Deep learning shows promise in mediation analysis, but the current methods only assume latent confounders that affect treatment, mediator and outcome simultaneously, and fail to identify different types of latent confounders (e.g., confounders that only affect the mediator or outcome). Furthermore, current methods are based on the sequential ignorability assumption, which is not feasible for dealing with multiple types of latent confounders. This work aims to circumvent the sequential ignorability assumption and applies the piecemeal deconfounding assumption as an alternative. We propose the Disentangled Mediation Analysis Variational AutoEncoder (DMAVAE), which disentangles the representations of latent confounders into three types to accurately estimate the natural direct effect, natural indirect effect and total effect. Experimental results show that the proposed method outperforms existing methods and has strong generalisation ability. We further apply the method to a real-world dataset to show its potential application.},
  archive   = {C_AAAI},
  author    = {Ziqi Xu and Debo Cheng and Jiuyong Li and Jixue Liu and Lin Liu and Ke Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26266},
  pages     = {10666-10674},
  title     = {Disentangled representation for causal mediation analysis},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Trusted fine-grained image classification through
hierarchical evidence fusion. <em>AAAI</em>, 10657–10665. (<a
href="https://doi.org/10.1609/aaai.v37i9.26265">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Fine-Grained Image Classification (FGIC) aims to classify images into specific subordinate classes of a superclass. Due to insufficient training data and confusing data samples, FGIC may produce uncertain classification results that are untrusted for data applications. In fact, FGIC can be viewed as a hierarchical classification process and the multilayer information facilitates to reduce uncertainty and improve the reliability of FGIC. In this paper, we adopt the evidence theory to measure uncertainty and confidence in hierarchical classification process and propose a trusted FGIC method through fusing multilayer classification evidence. Comparing with the traditional approaches, the trusted FGIC method not only generates accurate classification results but also reduces the uncertainty of fine-grained classification. Specifically, we construct an evidence extractor at each classification layer to extract multilayer (multi-grained) evidence for image classification. To fuse the extracted multi-grained evidence from coarse to fine, we formulate evidence fusion with the Dirichlet hyper probability distribution and thereby hierarchically decompose the evidence of coarse-grained classes into fine-grained classes to enhance the classification performances. The ablation experiments validate that the hierarchical evidence fusion can improve the precision and also reduce the uncertainty of fine-grained classification. The comparison with state-of-the-art FGIC methods shows that our proposed method achieves competitive performances.},
  archive   = {C_AAAI},
  author    = {Zhikang Xu and Xiaodong Yue and Ying Lv and Wei Liu and Zihao Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26265},
  pages     = {10657-10665},
  title     = {Trusted fine-grained image classification through hierarchical evidence fusion},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). USDNL: Uncertainty-based single dropout in noisy label
learning. <em>AAAI</em>, 10648–10656. (<a
href="https://doi.org/10.1609/aaai.v37i9.26264">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep Neural Networks (DNNs) possess powerful prediction capability thanks to their over-parameterization design, although the large model complexity makes it suffer from noisy supervision. Recent approaches seek to eliminate impacts from noisy labels by excluding data points with large loss values and showing promising performance. However, these approaches usually associate with significant computation overhead and lack of theoretical analysis. In this paper, we adopt a perspective to connect label noise with epistemic uncertainty. We design a simple, efficient, and theoretically provable robust algorithm named USDNL for DNNs with uncertainty-based Dropout. Specifically, we estimate the epistemic uncertainty of the network prediction after early training through single Dropout. The epistemic uncertainty is then combined with cross-entropy loss to select the clean samples during training. Finally, we theoretically show the equivalence of replacing selection loss with single cross-entropy loss. Compared to existing small-loss selection methods, USDNL features its simplicity for practical scenarios by only applying Dropout to a standard network, while still achieving high model accuracy. Extensive empirical results on both synthetic and real-world datasets show that USDNL outperforms other methods. Our code is available at https://github.com/kovelxyz/USDNL.},
  archive   = {C_AAAI},
  author    = {Yuanzhuo Xu and Xiaoguang Niu and Jie Yang and Steve Drew and Jiayu Zhou and Ruizhi Chen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26264},
  pages     = {10648-10656},
  title     = {USDNL: Uncertainty-based single dropout in noisy label learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). BridgeTower: Building bridges between encoders in
vision-language representation learning. <em>AAAI</em>, 10637–10647. (<a
href="https://doi.org/10.1609/aaai.v37i9.26263">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Vision-Language (VL) models with the Two-Tower architecture have dominated visual-language representation learning in recent years. Current VL models either use lightweight uni-modal encoders and learn to extract, align and fuse both modalities simultaneously in a deep cross-modal encoder, or feed the last-layer uni-modal representations from the deep pre-trained uni-modal encoders into the top cross-modal encoder. Both approaches potentially restrict vision-language representation learning and limit model performance. In this paper, we propose BridgeTower, which introduces multiple bridge layers that build a connection between the top layers of uni-modal encoders and each layer of the cross-modal encoder. This enables effective bottom-up cross-modal alignment and fusion between visual and textual representations of different semantic levels of pre-trained uni-modal encoders in the cross-modal encoder. Pre-trained with only 4M images, BridgeTower achieves state-of-the-art performance on various downstream vision-language tasks. In particular, on the VQAv2 test-std set, BridgeTower achieves an accuracy of 78.73\%, outperforming the previous state-of-the-art model METER by 1.09\% with the same pre-training data and almost negligible additional parameters and computational costs. Notably, when further scaling the model, BridgeTower achieves an accuracy of 81.15\%, surpassing models that are pre-trained on orders-of-magnitude larger datasets. Code and checkpoints are available at https://github.com/microsoft/BridgeTower.},
  archive   = {C_AAAI},
  author    = {Xiao Xu and Chenfei Wu and Shachar Rosenman and Vasudev Lal and Wanxiang Che and Nan Duan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26263},
  pages     = {10637-10647},
  title     = {BridgeTower: Building bridges between encoders in vision-language representation learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Transfer learning enhanced DeepONet for long-time prediction
of evolution equations. <em>AAAI</em>, 10629–10636. (<a
href="https://doi.org/10.1609/aaai.v37i9.26262">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep operator network (DeepONet) has demonstrated great success in various learning tasks, including learning solution operators of partial differential equations. In particular, it provides an efficient approach to predicting the evolution equations in a finite time horizon. Nevertheless, the vanilla DeepONet suffers from the issue of stability degradation in the long- time prediction. This paper proposes a transfer-learning aided DeepONet to enhance the stability. Our idea is to use transfer learning to sequentially update the DeepONets as the surro- gates for propagators learned in different time frames. The evolving DeepONets can better track the varying complexities of the evolution equations, while only need to be updated by efficient training of a tiny fraction of the operator networks. Through systematic experiments, we show that the proposed method not only improves the long-time accuracy of Deep- ONet while maintaining similar computational cost but also substantially reduces the sample size of the training set.},
  archive   = {C_AAAI},
  author    = {Wuzhe Xu and Yulong Lu and Li Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26262},
  pages     = {10629-10636},
  title     = {Transfer learning enhanced DeepONet for long-time prediction of evolution equations},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Resilient binary neural network. <em>AAAI</em>,
10620–10628. (<a
href="https://doi.org/10.1609/aaai.v37i9.26261">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Binary neural networks (BNNs) have received ever-increasing popularity for their great capability of reducing storage burden as well as quickening inference time. However, there is a severe performance drop compared with {real-valued} networks, due to its intrinsic frequent weight oscillation during training. In this paper, we introduce a Resilient Binary Neural Network (ReBNN) to mitigate the frequent oscillation for better BNNs&#39; training. We identify that the weight oscillation mainly stems from the non-parametric scaling factor. To address this issue, we propose to parameterize the scaling factor and introduce a weighted reconstruction loss to build an adaptive training objective. For the first time, we show that the weight oscillation is controlled by the balanced parameter attached to the reconstruction loss, which provides a theoretical foundation to parameterize it in back propagation. Based on this, we learn our ReBNN by calculating the balanced parameter based on its maximum magnitude, which can effectively mitigate the weight oscillation with a resilient training process. Extensive experiments are conducted upon various network models, such as ResNet and Faster-RCNN for computer vision, as well as BERT for natural language processing. The results demonstrate the overwhelming performance of our ReBNN over prior arts. For example, our ReBNN achieves 66.9\% Top-1 accuracy with ResNet-18 backbone on the ImageNet dataset, surpassing existing state-of-the-arts by a significant margin. Our code is open-sourced at https://github.com/SteveTsui/ReBNN.},
  archive   = {C_AAAI},
  author    = {Sheng Xu and Yanjing Li and Teli Ma and Mingbao Lin and Hao Dong and Baochang Zhang and Peng Gao and Jinhu Lu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26261},
  pages     = {10620-10628},
  title     = {Resilient binary neural network},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neighborhood-regularized self-training for learning with few
labels. <em>AAAI</em>, 10611–10619. (<a
href="https://doi.org/10.1609/aaai.v37i9.26260">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Training deep neural networks (DNNs) with limited supervision has been a popular research topic as it can significantly alleviate the annotation burden. Self-training has been successfully applied in semi-supervised learning tasks, but one drawback of self-training is that it is vulnerable to the label noise from incorrect pseudo labels. Inspired by the fact that samples with similar labels tend to share similar representations, we develop a neighborhood-based sample selection approach to tackle the issue of noisy pseudo labels. We further stabilize self-training via aggregating the predictions from different rounds during sample selection. Experiments on eight tasks show that our proposed method outperforms the strongest self-training baseline with 1.83\% and 2.51\% performance gain for text and graph datasets on average. Our further analysis demonstrates that our proposed data selection strategy reduces the noise of pseudo labels by 36.8\% and saves 57.3\% of the time when compared with the best baseline. Our code and appendices will be uploaded to: https://github.com/ritaranx/NeST.},
  archive   = {C_AAAI},
  author    = {Ran Xu and Yue Yu and Hejie Cui and Xuan Kan and Yanqiao Zhu and Joyce Ho and Chao Zhang and Carl Yang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26260},
  pages     = {10611-10619},
  title     = {Neighborhood-regularized self-training for learning with few labels},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Label-specific feature augmentation for long-tailed
multi-label text classification. <em>AAAI</em>, 10602–10610. (<a
href="https://doi.org/10.1609/aaai.v37i9.26259">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-label text classification (MLTC) involves tagging a document with its most relevant subset of labels from a label set. In real applications, labels usually follow a long-tailed distribution, where most labels (called as tail-label) only contain a small number of documents and limit the performance of MLTC. To facilitate this low-resource problem, researchers introduced a simple but effective strategy, data augmentation (DA). However, most existing DA approaches struggle in multi-label settings. The main reason is that the augmented documents for one label may inevitably influence the other co-occurring labels and further exaggerate the long-tailed problem. To mitigate this issue, we propose a new pair-level augmentation framework for MLTC, called Label-Specific Feature Augmentation (LSFA), which merely augments positive feature-label pairs for the tail-labels. LSFA contains two main parts. The first is for label-specific document representation learning in the high-level latent space, the second is for augmenting tail-label features in latent space by transferring the documents second-order statistics (intra-class semantic variations) from head labels to tail labels. At last, we design a new loss function for adjusting classifiers based on augmented datasets. The whole learning procedure can be effectively trained. Comprehensive experiments on benchmark datasets have shown that the proposed LSFA outperforms the state-of-the-art counterparts.},
  archive   = {C_AAAI},
  author    = {Pengyu Xu and Lin Xiao and Bing Liu and Sijin Lu and Liping Jing and Jian Yu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26259},
  pages     = {10602-10610},
  title     = {Label-specific feature augmentation for long-tailed multi-label text classification},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Efficient top-k feature selection using coordinate descent
method. <em>AAAI</em>, 10594–10601. (<a
href="https://doi.org/10.1609/aaai.v37i9.26258">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Sparse learning based feature selection has been widely investigated in recent years. In this study, we focus on the l2,0-norm based feature selection, which is effective for exact top-k feature selection but challenging to optimize. To solve the general l2,0-norm constrained problems, we novelly develop a parameter-free optimization framework based on the coordinate descend (CD) method, termed CD-LSR. Specifically, we devise a skillful conversion from the original problem to solving one continuous matrix and one discrete selection matrix. Then the nontrivial l2,0-norm constraint can be solved efficiently by solving the selection matrix with CD method. We impose the l2,0-norm on a vanilla least square regression (LSR) model for feature selection and optimize it with CD-LSR. Extensive experiments exhibit the efficiency of CD-LSR, as well as the discrimination ability of l2,0-norm to identify informative features. More importantly, the versatility of CD-LSR facilitates the applications of the l2,0-norm in more sophisticated models. Based on the competitive performance of l2,0-norm on the baseline LSR model, the satisfactory performance of its applications is reasonably expected. The source MATLAB code are available at: https://github.com/solerxl/Code_For_AAAI_2023.},
  archive   = {C_AAAI},
  author    = {Lei Xu and Rong Wang and Feiping Nie and Xuelong Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26258},
  pages     = {10594-10601},
  title     = {Efficient top-K feature selection using coordinate descent method},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Open-ended diverse solution discovery with regulated
behavior patterns for cross-domain adaptation. <em>AAAI</em>,
10585–10593. (<a
href="https://doi.org/10.1609/aaai.v37i9.26257">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {While Reinforcement Learning can achieve impressive results for complex tasks, the learned policies are generally prone to fail in downstream tasks with even minor model mismatch or unexpected perturbations. Recent works have demonstrated that a policy population with diverse behavior characteristics can generalize to downstream environments with various discrepancies. However, such policies might result in catastrophic damage during the deployment in practical scenarios like real-world systems due to the unrestricted behaviors of trained policies. Furthermore, training diverse policies without regulation of the behavior can result in inadequate feasible policies for extrapolating to a wide range of test conditions with dynamics shifts. In this work, we aim to train diverse policies under the regularization of the behavior patterns. We motivate our paradigm by observing the inverse dynamics in the environment with partial state information and propose Diversity in Regulation (DiR) training diverse policies with regulated behaviors to discover desired patterns that benefit the generalization. Considerable empirical results on various variations of different environments indicate that our method attains improvements over other diversity-driven counterparts.},
  archive   = {C_AAAI},
  author    = {Kang Xu and Yan Ma and Bingsheng Wei and Wei Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26257},
  pages     = {10585-10593},
  title     = {Open-ended diverse solution discovery with regulated behavior patterns for cross-domain adaptation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). GraphPrompt: Graph-based prompt templates for biomedical
synonym prediction. <em>AAAI</em>, 10576–10584. (<a
href="https://doi.org/10.1609/aaai.v37i9.26256">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the expansion of biomedical dataset, the same category may be labeled with different terms, thus being tedious and onerous to curate these terms. Therefore, automatically mapping synonymous terms onto the ontologies is desirable, which we name as biomedical synonym prediction task. Unlike biomedical concept normalization (BCN), no clues from context can be used to enhance synonym prediction, making it essential to extract graph features from ontology. We introduce an expert-curated dataset OBO-syn encompassing 70 different types of concepts and 2 million curated concept-term pairs for evaluating synonym prediction methods. We find BCN methods perform weakly on this task for not making full use of graph information. Therefore, we propose GraphPrompt, a prompt-based learning approach that creates prompt templates according to the graphs. GraphPrompt obtained 37.2\% and 28.5\% improvement on zero-shot and few-shot settings respectively, indicating the effectiveness of these graph-based prompt templates. We envision that our method GraphPrompt and OBO-syn dataset can be broadly applied to graph-based NLP tasks, and serve as the basis for analyzing diverse and accumulating biomedical data. All the data and codes are avalible at: https://github.com/HanwenXuTHU/GraphPrompt},
  archive   = {C_AAAI},
  author    = {Hanwen Xu and Jiayou Zhang and Zhirui Wang and Shizhuo Zhang and Megh Bhalerao and Yucong Liu and Dawei Zhu and Sheng Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26256},
  pages     = {10576-10584},
  title     = {GraphPrompt: Graph-based prompt templates for biomedical synonym prediction},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A survey on model compression and acceleration for
pretrained language models. <em>AAAI</em>, 10566–10575. (<a
href="https://doi.org/10.1609/aaai.v37i9.26255">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Despite achieving state-of-the-art performance on many NLP tasks, the high energy cost and long inference delay prevent Transformer-based pretrained language models (PLMs) from seeing broader adoption including for edge and mobile computing. Efficient NLP research aims to comprehensively consider computation, time and carbon emission for the entire life-cycle of NLP, including data preparation, model training and inference. In this survey, we focus on the inference stage and review the current state of model compression and acceleration for pretrained language models, including benchmarks, metrics and methodology.},
  archive   = {C_AAAI},
  author    = {Canwen Xu and Julian McAuley},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26255},
  pages     = {10566-10575},
  title     = {A survey on model compression and acceleration for pretrained language models},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Progressive deep multi-view comprehensive representation
learning. <em>AAAI</em>, 10557–10565. (<a
href="https://doi.org/10.1609/aaai.v37i9.26254">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-view Comprehensive Representation Learning (MCRL) aims to synthesize information from multiple views to learn comprehensive representations of data items. Prevalent deep MCRL methods typically concatenate synergistic view-specific representations or average aligned view-specific representations in the fusion stage. However, the performance of synergistic fusion methods inevitably degenerate or even fail when partial views are missing in real-world applications; the aligned based fusion methods usually cannot fully exploit the complementarity of multi-view data. To eliminate all these drawbacks, in this work we present a Progressive Deep Multi-view Fusion (PDMF) method. Considering the multi-view comprehensive representation should contain complete information and the view-specific data contain partial information, we deem that it is unstable to directly learn the mapping from partial information to complete information. Hence, PDMF employs a progressive learning strategy, which contains the pre-training and fine-tuning stages. In the pre-training stage, PDMF decodes the auxiliary comprehensive representation to the view-specific data. It also captures the consistency and complementarity by learning the relations between the dimensions of the auxiliary comprehensive representation and all views. In the fine-tuning stage, PDMF learns the mapping from the original data to the comprehensive representation with the help of the auxiliary comprehensive representation and relations. Experiments conducted on a synthetic toy dataset and 4 real-world datasets show that PDMF outperforms state-of-the-art baseline methods. The code is released at https://github.com/winterant/PDMF.},
  archive   = {C_AAAI},
  author    = {Cai Xu and Wei Zhao and Jinglong Zhao and Ziyu Guan and Yaming Yang and Long Chen and Xiangyu Song},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26254},
  pages     = {10557-10565},
  title     = {Progressive deep multi-view comprehensive representation learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Contrastive open set recognition. <em>AAAI</em>,
10546–10556. (<a
href="https://doi.org/10.1609/aaai.v37i9.26253">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In conventional recognition tasks, models are only trained to recognize learned targets, but it is usually difficult to collect training examples of all potential categories. In the testing phase, when models receive test samples from unknown classes, they mistakenly classify the samples into known classes. Open set recognition (OSR) is a more realistic recognition task, which requires the classifier to detect unknown test samples while keeping a high classification accuracy of known classes. In this paper, we study how to improve the OSR performance of deep neural networks from the perspective of representation learning. We employ supervised contrastive learning to improve the quality of feature representations, propose a new supervised contrastive learning method that enables the model to learn from soft training targets, and design an OSR framework on its basis. With the proposed method, we are able to make use of label smoothing and mixup when training deep neural networks contrastively, so as to improve both the robustness of outlier detection in OSR tasks and the accuracy in conventional classification tasks. We validate our method on multiple benchmark datasets and testing scenarios, achieving experimental results that verify the effectiveness of the proposed method.},
  archive   = {C_AAAI},
  author    = {Baile Xu and Furao Shen and Jian Zhao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26253},
  pages     = {10546-10556},
  title     = {Contrastive open set recognition},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Federated generative model on multi-source heterogeneous
data in IoT. <em>AAAI</em>, 10537–10545. (<a
href="https://doi.org/10.1609/aaai.v37i9.26252">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The study of generative models is a promising branch of deep learning techniques, which has been successfully applied to different scenarios, such as Artificial Intelligence and the Internet of Things. While in most of the existing works, the generative models are realized as a centralized structure, raising the threats of security and privacy and the overburden of communication costs. Rare efforts have been committed to investigating distributed generative models, especially when the training data comes from multiple heterogeneous sources under realistic IoT settings. In this paper, to handle this challenging problem, we design a federated generative model framework that can learn a powerful generator for the hierarchical IoT systems. Particularly, our generative model framework can solve the problem of distributed data generation on multi-source heterogeneous data in two scenarios, i.e., feature related scenario and label related scenario. In addition, in our federated generative models, we develop a synchronous and an asynchronous updating methods to satisfy different application requirements. Extensive experiments on a simulated dataset and multiple real datasets are conducted to evaluate the data generation performance of our proposed generative models through comparison with the state-of-the-arts.},
  archive   = {C_AAAI},
  author    = {Zuobin Xiong and Wei Li and Zhipeng Cai},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26252},
  pages     = {10537-10545},
  title     = {Federated generative model on multi-source heterogeneous data in IoT},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Decentralized stochastic multi-player multi-armed walking
bandits. <em>AAAI</em>, 10528–10536. (<a
href="https://doi.org/10.1609/aaai.v37i9.26251">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-player multi-armed bandit is an increasingly relevant decision-making problem, motivated by applications to cognitive radio systems. Most research for this problem focuses exclusively on the settings that players have full access to all arms and receive no reward when pulling the same arm. Hence all players solve the same bandit problem with the goal of maximizing their cumulative reward. However, these settings neglect several important factors in many real-world applications, where players have limited access to a dynamic local subset of arms (i.e., an arm could sometimes be ``walking&#39;&#39; and not accessible to the player). To this end, this paper proposes a multi-player multi-armed walking bandits model, aiming to address aforementioned modeling issues. The goal now is to maximize the reward, however, players can only pull arms from the local subset and only collect a full reward if no other players pull the same arm. We adopt Upper Confidence Bound (UCB) to deal with the exploration-exploitation tradeoff and employ distributed optimization techniques to properly handle collisions. By carefully integrating these two techniques, we propose a decentralized algorithm with near-optimal guarantee on the regret, and can be easily implemented to obtain competitive empirical performance.},
  archive   = {C_AAAI},
  author    = {Guojun Xiong and Jian Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26251},
  pages     = {10528-10536},
  title     = {Decentralized stochastic multi-player multi-armed walking bandits},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the connection between invariant learning and adversarial
training for out-of-distribution generalization. <em>AAAI</em>,
10519–10527. (<a
href="https://doi.org/10.1609/aaai.v37i9.26250">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Despite impressive success in many tasks, deep learning models are shown to rely on spurious features, which will catastrophically fail when generalized to out-of-distribution (OOD) data. Invariant Risk Minimization (IRM) is proposed to alleviate this issue by extracting domain-invariant features for OOD generalization. Nevertheless, recent work shows that IRM is only effective for a certain type of distribution shift (e.g., correlation shift) while it fails for other cases (e.g., diversity shift). Meanwhile, another thread of method, Adversarial Training (AT), has shown better domain transfer performance, suggesting that it has the potential to be an effective candidate for extracting domain-invariant features. This paper investigates this possibility by exploring the similarity between the IRM and AT objectives. Inspired by this connection, we propose Domain-wise Adversarial Training (DAT), an AT-inspired method for alleviating distribution shift by domain-specific perturbations. Extensive experiments show that our proposed DAT can effectively remove domain-varying features and improve OOD generalization under both correlation shift and diversity shift.},
  archive   = {C_AAAI},
  author    = {Shiji Xin and Yifei Wang and Jingtong Su and Yisen Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26250},
  pages     = {10519-10527},
  title     = {On the connection between invariant learning and adversarial training for out-of-distribution generalization},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Semi-supervised learning with support isolation by
small-paced self-training. <em>AAAI</em>, 10510–10518. (<a
href="https://doi.org/10.1609/aaai.v37i9.26249">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we address a special scenario of semi-supervised learning, where the label missing is caused by a preceding filtering mechanism, i.e., an instance can enter a subsequent process in which its label is revealed if and only if it passes the filtering mechanism. The rejected instances are prohibited to enter the subsequent labeling process due to economical or ethical reasons, making the support of the labeled and unlabeled distributions isolated from each other. In this case, semi-supervised learning approaches which rely on certain coherence of the labeled and unlabeled distribution would suffer from the consequent distribution mismatch, and hence result in poor prediction performance. In this paper, we propose a Small-Paced Self-Training framework, which iteratively discovers labeled and unlabeled instance subspaces with bounded Wasserstein distance. We theoretically prove that such a framework may achieve provably low error on the pseudo labels during learning. Experiments on both benchmark and pneumonia diagnosis tasks show that our method is effective.},
  archive   = {C_AAAI},
  author    = {Zheng Xie and Hui Sun and Ming Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26249},
  pages     = {10510-10518},
  title     = {Semi-supervised learning with support isolation by small-paced self-training},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A tale of two latent flows: Learning latent space
normalizing flow with short-run langevin flow for approximate inference.
<em>AAAI</em>, 10499–10509. (<a
href="https://doi.org/10.1609/aaai.v37i9.26248">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study a normalizing flow in the latent space of a top-down generator model, in which the normalizing flow model plays the role of the informative prior model of the generator. We propose to jointly learn the latent space normalizing flow prior model and the top-down generator model by a Markov chain Monte Carlo (MCMC)-based maximum likelihood algorithm, where a short-run Langevin sampling from the intractable posterior distribution is performed to infer the latent variables for each observed example, so that the parameters of the normalizing flow prior and the generator can be updated with the inferred latent variables. We show that, under the scenario of non-convergent short-run MCMC, the finite step Langevin dynamics is a flow-like approximate inference model and the learning objective actually follows the perturbation of the maximum likelihood estimation (MLE). We further point out that the learning framework seeks to (i) match the latent space normalizing flow and the aggregated posterior produced by the short-run Langevin flow, and (ii) bias the model from MLE such that the short-run Langevin flow inference is close to the true posterior. Empirical results of extensive experiments validate the effectiveness of the proposed latent space normalizing flow model in the tasks of image generation, image reconstruction, anomaly detection, supervised image inpainting and unsupervised image recovery.},
  archive   = {C_AAAI},
  author    = {Jianwen Xie and Yaxuan Zhu and Yifei Xu and Dingcheng Li and Ping Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26248},
  pages     = {10499-10509},
  title     = {A tale of two latent flows: Learning latent space normalizing flow with short-run langevin flow for approximate inference},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards optimal randomized strategies in adversarial example
game. <em>AAAI</em>, 10490–10498. (<a
href="https://doi.org/10.1609/aaai.v37i9.26247">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The vulnerability of deep neural network models to adversarial example attacks is a practical challenge in many artificial intelligence applications. A recent line of work shows that the use of randomization in adversarial training is the key to find optimal strategies against adversarial example attacks. However, in a fully randomized setting where both the defender and the attacker can use randomized strategies, there are no efficient algorithm for finding such an optimal strategy. To fill the gap, we propose the first algorithm of its kind, called FRAT, which models the problem with a new infinite-dimensional continuous-time flow on probability distribution spaces. FRAT maintains a lightweight mixture of models for the defender, with flexibility to efficiently update mixing weights and model parameters at each iteration. Furthermore, FRAT utilizes lightweight sampling subroutines to construct a random strategy for the attacker. We prove that the continuous-time limit of FRAT converges to a mixed Nash equilibria in a zero-sum game formed by a defender and an attacker. Experimental results also demonstrate the efficiency of FRAT on CIFAR-10 and CIFAR-100 datasets.},
  archive   = {C_AAAI},
  author    = {Jiahao Xie and Chao Zhang and Weijie Liu and Wensong Bai and Hui Qian},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26247},
  pages     = {10490-10498},
  title     = {Towards optimal randomized strategies in adversarial example game},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CDMA: A practical cross-device federated learning algorithm
for general minimax problems. <em>AAAI</em>, 10481–10489. (<a
href="https://doi.org/10.1609/aaai.v37i9.26246">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Minimax problems arise in a wide range of important applications including robust adversarial learning and Generative Adversarial Network (GAN) training. Recently, algorithms for minimax problems in the Federated Learning (FL) paradigm have received considerable interest. Existing federated algorithms for general minimax problems require the full aggregation (i.e., aggregation of local model information from all clients) in each training round. Thus, they are inapplicable to an important setting of FL known as the cross-device setting, which involves numerous unreliable mobile/IoT devices. In this paper, we develop the first practical algorithm named CDMA for general minimax problems in the cross-device FL setting. CDMA is based on a Start-Immediately-With-Enough-Responses mechanism, in which the server first signals a subset of clients to perform local computation and then starts to aggregate the local results reported by clients once it receives responses from enough clients in each round. With this mechanism, CDMA is resilient to the low client availability. In addition, CDMA is incorporated with a lightweight global correction in the local update steps of clients, which mitigates the impact of slow network connections. We establish theoretical guarantees of CDMA under different choices of hyperparameters and conduct experiments on AUC maximization, robust adversarial network training, and GAN training tasks. Theoretical and experimental results demonstrate the efficiency of CDMA.},
  archive   = {C_AAAI},
  author    = {Jiahao Xie and Chao Zhang and Zebang Shen and Weijie Liu and Hui Qian},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26246},
  pages     = {10481-10489},
  title     = {CDMA: A practical cross-device federated learning algorithm for general minimax problems},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bayesian federated neural matching that completes full
information. <em>AAAI</em>, 10473–10480. (<a
href="https://doi.org/10.1609/aaai.v37i9.26245">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Federated learning is a contemporary machine learning paradigm where locally trained models are distilled into a global model. Due to the intrinsic permutation invariance of neural networks, Probabilistic Federated Neural Matching (PFNM) employs a Bayesian nonparametric framework in the generation process of local neurons, and then creates a linear sum assignment formulation in each alternative optimization iteration. But according to our theoretical analysis, the optimization iteration in PFNM omits global information from existing. In this study, we propose a novel approach that overcomes this flaw by introducing a Kullback-Leibler divergence penalty at each iteration. The effectiveness of our approach is demonstrated by experiments on both image classification and semantic segmentation tasks.},
  archive   = {C_AAAI},
  author    = {Peng Xiao and Samuel Cheng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26245},
  pages     = {10473-10480},
  title     = {Bayesian federated neural matching that completes full information},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). HALOC: Hardware-aware automatic low-rank compression for
compact neural networks. <em>AAAI</em>, 10464–10472. (<a
href="https://doi.org/10.1609/aaai.v37i9.26244">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Low-rank compression is an important model compression strategy for obtaining compact neural network models. In general, because the rank values directly determine the model complexity and model accuracy, proper selection of layer-wise rank is very critical and desired. To date, though many low-rank compression approaches, either selecting the ranks in a manual or automatic way, have been proposed, they suffer from costly manual trials or unsatisfied compression performance. In addition, all of the existing works are not designed in a hardware-aware way, limiting the practical performance of the compressed models on real-world hardware platforms. To address these challenges, in this paper we propose HALOC, a hardware-aware automatic low-rank compression framework. By interpreting automatic rank selection from an architecture search perspective, we develop an end-to-end solution to determine the suitable layer-wise ranks in a differentiable and hardware-aware way. We further propose design principles and mitigation strategy to efficiently explore the rank space and reduce the potential interference problem. Experimental results on different datasets and hardware platforms demonstrate the effectiveness of our proposed approach. On CIFAR-10 dataset, HALOC enables 0.07\% and 0.38\% accuracy increase over the uncompressed ResNet-20 and VGG-16 models with 72.20\% and 86.44\% fewer FLOPs, respectively. On ImageNet dataset, HALOC achieves 0.9\% higher top-1 accuracy than the original ResNet-18 model with 66.16\% fewer FLOPs. HALOC also shows 0.66\% higher top-1 accuracy increase than the state-of-the-art automatic low-rank compression solution with fewer computational and memory costs. In addition, HALOC demonstrates the practical speedups on different hardware platforms, verified by the measurement results on desktop GPU, embedded GPU and ASIC accelerator.},
  archive   = {C_AAAI},
  author    = {Jinqi Xiao and Chengming Zhang and Yu Gong and Miao Yin and Yang Sui and Lizhi Xiang and Dingwen Tao and Bo Yuan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26244},
  pages     = {10464-10472},
  title     = {HALOC: Hardware-aware automatic low-rank compression for compact neural networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Zero-cost operation scoring in differentiable architecture
search. <em>AAAI</em>, 10453–10463. (<a
href="https://doi.org/10.1609/aaai.v37i9.26243">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We formalize and analyze a fundamental component of dif- ferentiable neural architecture search (NAS): local “opera- tion scoring” at each operation choice. We view existing operation scoring functions as inexact proxies for accuracy, and we find that they perform poorly when analyzed empir- ically on NAS benchmarks. From this perspective, we intro- duce a novel perturbation-based zero-cost operation scor- ing (Zero-Cost-PT) approach, which utilizes zero-cost prox- ies that were recently studied in multi-trial NAS but de- grade significantly on larger search spaces, typical for dif- ferentiable NAS. We conduct a thorough empirical evalu- ation on a number of NAS benchmarks and large search spaces, from NAS-Bench-201, NAS-Bench-1Shot1, NAS- Bench-Macro, to DARTS-like and MobileNet-like spaces, showing significant improvements in both search time and accuracy. On the ImageNet classification task on the DARTS search space, our approach improved accuracy compared to the best current training-free methods (TE-NAS) while be- ing over 10× faster (total searching time 25 minutes on a single GPU), and observed significantly better transferabil- ity on architectures searched on the CIFAR-10 dataset with an accuracy increase of 1.8 pp. Our code is available at: https://github.com/zerocostptnas/zerocost operation score.},
  archive   = {C_AAAI},
  author    = {Lichuan Xiang and Lukasz Dudziak and Mohamed S. Abdelfattah and Thomas Chau and Nicholas D. Lane and Hongkai Wen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26243},
  pages     = {10453-10463},
  title     = {Zero-cost operation scoring in differentiable architecture search},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Differentially private learning with per-sample adaptive
clipping. <em>AAAI</em>, 10444–10452. (<a
href="https://doi.org/10.1609/aaai.v37i9.26242">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Privacy in AI remains a topic that draws attention from researchers and the general public in recent years. As one way to implement privacy-preserving AI, differentially private learning is a framework that enables AI models to use differential privacy (DP). To achieve DP in the learning process, existing algorithms typically limit the magnitude of gradients with a constant clipping, which requires carefully tuned due to its significant impact on model performance. As a solution to this issue, latest works NSGD and Auto-S innovatively propose to use normalization instead of clipping to avoid hyperparameter tuning. However, normalization-based approaches like NSGD and Auto-S rely on a monotonic weight function, which imposes excessive weight on small gradient samples and introduces extra deviation to the update. In this paper, we propose a Differentially Private Per-Sample Adaptive Clipping (DP-PSAC) algorithm based on a non-monotonic adaptive weight function, which guarantees privacy without the typical hyperparameter tuning process of using a constant clipping while significantly reducing the deviation between the update and true batch-averaged gradient. We provide a rigorous theoretical convergence analysis and show that with convergence rate at the same order, the proposed algorithm achieves a lower non-vanishing bound, which is maintained over training iterations, compared with NSGD/Auto-S. In addition, through extensive experimental evaluation, we show that DP-PSAC outperforms or matches the state-of-the-art methods on multiple main-stream vision and language tasks.},
  archive   = {C_AAAI},
  author    = {Tianyu Xia and Shuheng Shen and Su Yao and Xinyi Fu and Ke Xu and Xiaolong Xu and Xing Fu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26242},
  pages     = {10444-10452},
  title     = {Differentially private learning with per-sample adaptive clipping},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Models as agents: Optimizing multi-step predictions of
interactive local models in model-based multi-agent reinforcement
learning. <em>AAAI</em>, 10435–10443. (<a
href="https://doi.org/10.1609/aaai.v37i9.26241">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Research in model-based reinforcement learning has made significant progress in recent years. Compared to single-agent settings, the exponential dimension growth of the joint state-action space in multi-agent systems dramatically increases the complexity of the environment dynamics, which makes it infeasible to learn an accurate global model and thus necessitates the use of agent-wise local models. However, during multi-step model rollouts, the prediction of one local model can affect the predictions of other local models in the next step. As a result, local prediction errors can be propagated to other localities and eventually give rise to considerably large global errors. Furthermore, since the models are generally used to predict for multiple steps, simply minimizing one-step prediction errors regardless of their long-term effect on other models may further aggravate the propagation of local errors. To this end, we propose Models as AGents (MAG), a multi-agent model optimization framework that reversely treats the local models as multi-step decision making agents and the current policies as the dynamics during the model rollout process. In this way, the local models are able to consider the multi-step mutual affect between each other before making predictions. Theoretically, we show that the objective of MAG is approximately equivalent to maximizing a lower bound of the true environment return. Experiments on the challenging StarCraft II benchmark demonstrate the effectiveness of MAG.},
  archive   = {C_AAAI},
  author    = {Zifan Wu and Chao Yu and Chen Chen and Jianye Hao and Hankz Hankui Zhuo},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26241},
  pages     = {10435-10443},
  title     = {Models as agents: Optimizing multi-step predictions of interactive local models in model-based multi-agent reinforcement learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reward poisoning attacks on offline multi-agent
reinforcement learning. <em>AAAI</em>, 10426–10434. (<a
href="https://doi.org/10.1609/aaai.v37i9.26240">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In offline multi-agent reinforcement learning (MARL), agents estimate policies from a given dataset. We study reward-poisoning attacks in this setting where an exogenous attacker modifies the rewards in the dataset before the agents see the dataset. The attacker wants to guide each agent into a nefarious target policy while minimizing the Lp norm of the reward modification. Unlike attacks on single-agent RL, we show that the attacker can install the target policy as a Markov Perfect Dominant Strategy Equilibrium (MPDSE), which rational agents are guaranteed to follow. This attack can be significantly cheaper than separate single-agent attacks. We show that the attack works on various MARL agents including uncertainty-aware learners, and we exhibit linear programs to efficiently solve the attack problem. We also study the relationship between the structure of the datasets and the minimal attack cost. Our work paves the way for studying defense in offline MARL.},
  archive   = {C_AAAI},
  author    = {Young Wu and Jeremy McMahan and Xiaojin Zhu and Qiaomin Xie},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26240},
  pages     = {10426-10434},
  title     = {Reward poisoning attacks on offline multi-agent reinforcement learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adversarial weight perturbation improves generalization in
graph neural networks. <em>AAAI</em>, 10417–10425. (<a
href="https://doi.org/10.1609/aaai.v37i9.26239">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A lot of theoretical and empirical evidence shows that the flatter local minima tend to improve generalization. Adversarial Weight Perturbation (AWP) is an emerging technique to efficiently and effectively find such minima. In AMP we minimize the loss w.r.t. a bounded worst-case perturbation of the model parameters thereby favoring local minima with a small loss in a neighborhood around them. The benefits of AWP, and more generally the connections between flatness and generalization, have been extensively studied for i.i.d. data such as images. In this paper, we extensively study this phenomenon for graph data. Along the way, we first derive a generalization bound for non-i.i.d. node classification tasks. Then we identify a vanishing-gradient issue with all existing formulations of AWP and we propose a new Weighted Truncated AWP (WT-AWP) to alleviate this issue. We show that regularizing graph neural networks with WT-AWP consistently improves both natural and robust generalization across many different graph learning tasks and models.},
  archive   = {C_AAAI},
  author    = {Yihan Wu and Aleksandar Bojchevski and Heng Huang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26239},
  pages     = {10417-10425},
  title     = {Adversarial weight perturbation improves generalization in graph neural networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). MetaZSCIL: A meta-learning approach for generalized
zero-shot class incremental learning. <em>AAAI</em>, 10408–10416. (<a
href="https://doi.org/10.1609/aaai.v37i9.26238">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Generalized zero-shot learning (GZSL) aims to recognize samples whose categories may not have been seen at training. Standard GZSL cannot handle dynamic addition of new seen and unseen classes. In order to address this limitation, some recent attempts have been made to develop continual GZSL methods. However, these methods require end-users to continuously collect and annotate numerous seen class samples, which is unrealistic and hampers the applicability in the real-world. Accordingly, in this paper, we propose a more practical and challenging setting named Generalized Zero-Shot Class Incremental Learning (CI-GZSL). Our setting aims to incrementally learn unseen classes without any training samples, while recognizing all classes previously encountered. We further propose a bi-level meta-learning based method called MetaZSCIL to directly optimize the network to learn how to incrementally learn. Specifically, we sample sequential tasks from seen classes during the offline training to simulate the incremental learning process. For each task, the model is learned using a meta-objective such that it is capable to perform fast adaptation without forgetting. Note that our optimization can be flexibly equipped with most existing generative methods to tackle CI-GZSL. This work introduces a feature generative framework that leverages visual feature distribution alignment to produce replayed samples of previously seen classes to reduce catastrophic forgetting. Extensive experiments conducted on five widely used benchmarks demonstrate the superiority of our proposed method.},
  archive   = {C_AAAI},
  author    = {Yanan Wu and Tengfei Liang and Songhe Feng and Yi Jin and Gengyu Lyu and Haojun Fei and Yang Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26238},
  pages     = {10408-10416},
  title     = {MetaZSCIL: A meta-learning approach for generalized zero-shot class incremental learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FedNP: Towards non-IID federated learning via federated
neural propagation. <em>AAAI</em>, 10399–10407. (<a
href="https://doi.org/10.1609/aaai.v37i9.26237">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Traditional federated learning (FL) algorithms, such as FedAvg, fail to handle non-i.i.d data because they learn a global model by simply averaging biased local models that are trained on non-i.i.d local data, therefore failing to model the global data distribution. In this paper, we present a novel Bayesian FL algorithm that successfully handles such a non-i.i.d FL setting by enhancing the local training task with an auxiliary task that explicitly estimates the global data distribution. One key challenge in estimating the global data distribution is that the data are partitioned in FL, and therefore the ground-truth global data distribution is inaccessible. To address this challenge, we propose an expectation-propagation-inspired probabilistic neural network, dubbed federated neural propagation (FedNP), which efficiently estimates the global data distribution given non-i.i.d data partitions. Our algorithm is sampling-free and end-to-end differentiable, can be applied with any conventional FL frameworks and learns richer global data representation. Experiments on both image classification tasks with synthetic non-i.i.d image data partitions and real-world non-i.i.d speech recognition tasks demonstrate that our framework effectively alleviates the performance deterioration caused by non-i.i.d data.},
  archive   = {C_AAAI},
  author    = {Xueyang Wu and Hengguan Huang and Youlong Ding and Hao Wang and Ye Wang and Qian Xu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26237},
  pages     = {10399-10407},
  title     = {FedNP: Towards non-IID federated learning via federated neural propagation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Practical markov boundary learning without strong
assumptions. <em>AAAI</em>, 10388–10398. (<a
href="https://doi.org/10.1609/aaai.v37i9.26236">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Theoretically, the Markov boundary (MB) is the optimal solution for feature selection. However, existing MB learning algorithms often fail to identify some critical features in real-world feature selection tasks, mainly because the strict assumptions of existing algorithms, on either data distribution, variable types, or correctness of criteria, cannot be satisfied in application scenarios. This paper takes further steps toward opening the door to real-world applications for MB. We contribute in particular to a practical MB learning strategy, which can maintain feasibility and effectiveness in real-world data where variables can be numerical or categorical with linear or nonlinear, pairwise or multivariate relationships. Specifically, the equivalence between MB and the minimal conditional covariance operator (CCO) is investigated, which inspires us to design the objective function based on the predictability evaluation of the mapping variables in a reproducing kernel Hilbert space. Based on this, a kernel MB learning algorithm is proposed, where nonlinear multivariate dependence could be considered without extra requirements on data distribution and variable types. Extensive experiments demonstrate the efficacy of these contributions.},
  archive   = {C_AAAI},
  author    = {Xingyu Wu and Bingbing Jiang and Tianhao Wu and Huanhuan Chen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26236},
  pages     = {10388-10398},
  title     = {Practical markov boundary learning without strong assumptions},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Faster adaptive federated learning. <em>AAAI</em>,
10379–10387. (<a
href="https://doi.org/10.1609/aaai.v37i9.26235">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Federated learning has attracted increasing attention with the emergence of distributed data. While extensive federated learning algorithms have been proposed for the non-convex distributed problem, the federated learning in practice still faces numerous challenges, such as the large training iterations to converge since the sizes of models and datasets keep increasing, and the lack of adaptivity by SGD-based model updates. Meanwhile, the study of adaptive methods in federated learning is scarce and existing works either lack a complete theoretical convergence guarantee or have slow sample complexity. In this paper, we propose an efficient adaptive algorithm (i.e., FAFED) based on the momentum-based variance reduced technique in cross-silo FL. We first explore how to design the adaptive algorithm in the FL setting. By providing a counter-example, we prove that a simple combination of FL and adaptive methods could lead to divergence. More importantly, we provide a convergence analysis for our method and prove that our algorithm is the first adaptive FL algorithm to reach the best-known samples O(epsilon(-3)) and O(epsilon(-2)) communication rounds to find an epsilon-stationary point without large batches. The experimental results on the language modeling task and image classification task with heterogeneous data demonstrate the efficiency of our algorithms.},
  archive   = {C_AAAI},
  author    = {Xidong Wu and Feihu Huang and Zhengmian Hu and Heng Huang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26235},
  pages     = {10379-10387},
  title     = {Faster adaptive federated learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Decentralized riemannian algorithm for nonconvex minimax
problems. <em>AAAI</em>, 10370–10378. (<a
href="https://doi.org/10.1609/aaai.v37i9.26234">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The minimax optimization over Riemannian manifolds (possibly nonconvex constraints) has been actively applied to solve many problems, such as robust dimensionality reduction and deep neural networks with orthogonal weights (Stiefel manifold). Although many optimization algorithms for minimax problems have been developed in the Euclidean setting, it is difficult to convert them into Riemannian cases, and algorithms for nonconvex minimax problems with nonconvex constraints are even rare. On the other hand, to address the big data challenges, decentralized (serverless) training techniques have recently been emerging since they can reduce communications overhead and avoid the bottleneck problem on the server node. Nonetheless, the algorithm for decentralized Riemannian minimax problems has not been studied. In this paper, we study the distributed nonconvex-strongly-concave minimax optimization problem over the Stiefel manifold and propose both deterministic and stochastic minimax methods. The Steifel manifold is a non-convex set. The global function is represented as the finite sum of local functions. For the deterministic setting, we propose DRGDA and prove that our deterministic method achieves a gradient complexity of O( epsilon(-2)) under mild conditions. For the stochastic setting, we propose DRSGDA and prove that our stochastic method achieves a gradient complexity of O( epsilon(-4)). The DRGDA and DRSGDA are the first algorithms for distributed minimax optimization with nonconvex constraints with exact convergence. Extensive experimental results on the Deep Neural Networks (DNNs) training over the Stiefel manifold demonstrate the efficiency of our algorithms.},
  archive   = {C_AAAI},
  author    = {Xidong Wu and Zhengmian Hu and Heng Huang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26234},
  pages     = {10370-10378},
  title     = {Decentralized riemannian algorithm for nonconvex minimax problems},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Symphony in the latent space: Provably integrating
high-dimensional techniques with non-linear machine learning models.
<em>AAAI</em>, 10361–10369. (<a
href="https://doi.org/10.1609/aaai.v37i9.26233">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper revisits building machine learning algorithms that involve interactions between entities, such as those between financial assets in an actively managed portfolio, or interactions between users in a social network. Our goal is to forecast the future evolution of ensembles of multivariate time series in such applications (e.g., the future return of a financial asset or the future popularity of a Twitter account). Designing ML algorithms for such systems requires addressing the challenges of high-dimensional interactions and non-linearity. Existing approaches usually adopt an ad-hoc approach to integrating high-dimensional techniques into non-linear models and recent studies have shown these approaches have questionable efficacy in time-evolving interacting systems. To this end, we propose a novel framework, which we dub as the additive influence model. Under our modeling assumption, we show that it is possible to decouple the learning of high-dimensional interactions from the learning of non-linear feature interactions. To learn the high-dimensional interactions, we leverage kernel-based techniques, with provable guarantees, to embed the entities in a low-dimensional latent space. To learn the non-linear feature-response interactions, we generalize prominent machine learning techniques, including designing a new statistically sound non-parametric method and an ensemble learning algorithm optimized for vector regressions. Extensive experiments on two common applications demonstrate that our new algorithms deliver significantly stronger forecasting power compared to standard and recently proposed methods.},
  archive   = {C_AAAI},
  author    = {Qiong Wu and Jian Li and Zhenming Liu and Yanhua Li and Mihai Cucuringu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26233},
  pages     = {10361-10369},
  title     = {Symphony in the latent space: Provably integrating high-dimensional techniques with non-linear machine learning models},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Extracting low-/high- frequency knowledge from graph neural
networks and injecting it into MLPs: An effective GNN-to-MLP
distillation framework. <em>AAAI</em>, 10351–10360. (<a
href="https://doi.org/10.1609/aaai.v37i9.26232">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent years have witnessed the great success of Graph Neural Networks (GNNs) in handling graph-related tasks. However, MLPs remain the primary workhorse for practical industrial applications due to their desirable inference efficiency and scalability. To reduce their gaps, one can directly distill knowledge from a well-designed teacher GNN to a student MLP, which is termed as GNN-to-MLP distillation. However, the process of distillation usually entails a loss of information, and ``which knowledge patterns of GNNs are more likely to be left and distilled into MLPs?&quot; becomes an important question. In this paper, we first factorize the knowledge learned by GNNs into low- and high-frequency components in the spectral domain and then derive their correspondence in the spatial domain. Furthermore, we identified a potential information drowning problem for existing GNN-to-MLP distillation, i.e., the high-frequency knowledge of the pre-trained GNNs may be overwhelmed by the low-frequency knowledge during distillation; we have described in detail what it represents, how it arises, what impact it has, and how to deal with it. In this paper, we propose an efficient Full-Frequency GNN-to-MLP (FF-G2M) distillation framework, which extracts both low-frequency and high-frequency knowledge from GNNs and injects it into MLPs. Extensive experiments show that FF-G2M improves over the vanilla MLPs by 12.6\% and outperforms its corresponding teacher GNNs by 2.6\% averaged over six graph datasets and three common GNN architectures.},
  archive   = {C_AAAI},
  author    = {Lirong Wu and Haitao Lin and Yufei Huang and Tianyu Fan and Stan Z. Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26232},
  pages     = {10351-10360},
  title     = {Extracting low-/High- frequency knowledge from graph neural networks and injecting it into MLPs: An effective GNN-to-MLP distillation framework},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Non-IID transfer learning on graphs. <em>AAAI</em>,
10342–10350. (<a
href="https://doi.org/10.1609/aaai.v37i9.26231">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Transfer learning refers to the transfer of knowledge or information from a relevant source domain to a target domain. However, most existing transfer learning theories and algorithms focus on IID tasks, where the source/target samples are assumed to be independent and identically distributed. Very little effort is devoted to theoretically studying the knowledge transferability on non-IID tasks, e.g., cross-network mining. To bridge the gap, in this paper, we propose rigorous generalization bounds and algorithms for cross-network transfer learning from a source graph to a target graph. The crucial idea is to characterize the cross-network knowledge transferability from the perspective of the Weisfeiler-Lehman graph isomorphism test. To this end, we propose a novel Graph Subtree Discrepancy to measure the graph distribution shift between source and target graphs. Then the generalization error bounds on cross-network transfer learning, including both cross-network node classification and link prediction tasks, can be derived in terms of the source knowledge and the Graph Subtree Discrepancy across domains. This thereby motivates us to propose a generic graph adaptive network (GRADE) to minimize the distribution shift between source and target graphs for cross-network transfer learning. Experimental results verify the effectiveness and efficiency of our GRADE framework on both cross-network node classification and cross-domain recommendation tasks.},
  archive   = {C_AAAI},
  author    = {Jun Wu and Jingrui He and Elizabeth Ainsworth},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26231},
  pages     = {10342-10350},
  title     = {Non-IID transfer learning on graphs},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Towards in-distribution compatible out-of-distribution
detection. <em>AAAI</em>, 10333–10341. (<a
href="https://doi.org/10.1609/aaai.v37i9.26230">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep neural network, despite its remarkable capability of discriminating targeted in-distribution samples, shows poor performance on detecting anomalous out-of-distribution data. To address this defect, state-of-the-art solutions choose to train deep networks on an auxiliary dataset of outliers. Various training criteria for these auxiliary outliers are proposed based on heuristic intuitions. However, we find that these intuitively designed outlier training criteria can hurt in-distribution learning and eventually lead to inferior performance. To this end, we identify three causes of the in-distribution incompatibility: contradictory gradient, false likelihood, and distribution shift. Based on our new understandings, we propose a new out-of-distribution detection method by adapting both the top-design of deep models and the loss function. Our method achieves in-distribution compatibility by pursuing less interference with the probabilistic characteristic of in-distribution features. On several benchmarks, our method not only achieves the state-of-the-art out-of-distribution detection performance but also improves the in-distribution accuracy.},
  archive   = {C_AAAI},
  author    = {Boxi Wu and Jie Jiang and Haidong Ren and Zifan Du and Wenxiao Wang and Zhifeng Li and Deng Cai and Xiaofei He and Binbin Lin and Wei Liu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26230},
  pages     = {10333-10341},
  title     = {Towards in-distribution compatible out-of-distribution detection},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning instrumental variable from data fusion for
treatment effect estimation. <em>AAAI</em>, 10324–10332. (<a
href="https://doi.org/10.1609/aaai.v37i9.26229">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The advent of the big data era brought new opportunities and challenges to draw treatment effect in data fusion, that is, a mixed dataset collected from multiple sources (each source with an independent treatment assignment mechanism). Due to possibly omitted source labels and unmeasured confounders, traditional methods cannot estimate individual treatment assignment probability and infer treatment effect effectively. Therefore, we propose to reconstruct the source label and model it as a Group Instrumental Variable (GIV) to implement IV-based Regression for treatment effect estimation. In this paper, we conceptualize this line of thought and develop a unified framework (Meta-EM) to (1) map the raw data into a representation space to construct Linear Mixed Models for the assigned treatment variable; (2) estimate the distribution differences and model the GIV for the different treatment assignment mechanisms; and (3) adopt an alternating training strategy to iteratively optimize the representations and the joint distribution to model GIV for IV regression. Empirical results demonstrate the advantages of our Meta-EM compared with state-of-the-art methods. The project page with the code and the Supplementary materials is available at https://github.com/causal-machine-learning-lab/meta-em.},
  archive   = {C_AAAI},
  author    = {Anpeng Wu and Kun Kuang and Ruoxuan Xiong and Minqin Zhu and Yuxuan Liu and Bo Li and Furui Liu and Zhihua Wang and Fei Wu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26229},
  pages     = {10324-10332},
  title     = {Learning instrumental variable from data fusion for treatment effect estimation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Feature distribution fitting with direction-driven weighting
for few-shot images classification. <em>AAAI</em>, 10315–10323. (<a
href="https://doi.org/10.1609/aaai.v37i9.26228">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Few-shot learning has received increasing attention and witnessed significant advances in recent years. However, most of the few-shot learning methods focus on the optimization of training process, and the learning of metric and sample generating networks. They ignore the importance of learning the ground-truth feature distributions of few-shot classes. This paper proposes a direction-driven weighting method to make the feature distributions of few-shot classes precisely fit the ground-truth distributions. The learned feature distributions can generate an unlimited number of training samples for the few-shot classes to avoid overfitting. Specifically, the proposed method consists of two optimization strategies. The direction-driven strategy is for capturing more complete direction information that can describe the feature distributions. The similarity-weighting strategy is proposed to estimate the impact of different classes in the fitting procedure and assign corresponding weights. Our method outperforms the current state-of-the-art performance by an average of 3\% for 1-shot on standard few-shot learning benchmarks like miniImageNet, CIFAR-FS, and CUB. The excellent performance and compelling visualization show that our method can more accurately estimate the ground-truth distributions.},
  archive   = {C_AAAI},
  author    = {Xin Wei and Wei Du and Huan Wan and Weidong Min},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26228},
  pages     = {10315-10323},
  title     = {Feature distribution fitting with direction-driven weighting for few-shot images classification},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Predictive multiplicity in probabilistic classification.
<em>AAAI</em>, 10306–10314. (<a
href="https://doi.org/10.1609/aaai.v37i9.26227">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Machine learning models are often used to inform real world risk assessment tasks: predicting consumer default risk, predicting whether a person suffers from a serious illness, or predicting a person&#39;s risk to appear in court. Given multiple models that perform almost equally well for a prediction task, to what extent do predictions vary across these models? If predictions are relatively consistent for similar models, then the standard approach of choosing the model that optimizes a penalized loss suffices. But what if predictions vary significantly for similar models? In machine learning, this is referred to as predictive multiplicity i.e. the prevalence of conflicting predictions assigned by near-optimal competing models. In this paper, we present a framework for measuring predictive multiplicity in probabilistic classification (predicting the probability of a positive outcome). We introduce measures that capture the variation in risk estimates over the set of competing models, and develop optimization-based methods to compute these measures efficiently and reliably for convex empirical risk minimization problems. We demonstrate the incidence and prevalence of predictive multiplicity in real-world tasks. Further, we provide insight into how predictive multiplicity arises by analyzing the relationship between predictive multiplicity and data set characteristics (outliers, separability, and majority-minority structure). Our results emphasize the need to report predictive multiplicity more widely.},
  archive   = {C_AAAI},
  author    = {Jamelle Watson-Daniels and David C. Parkes and Berk Ustun},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26227},
  pages     = {10306-10314},
  title     = {Predictive multiplicity in probabilistic classification},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Code-aware cross-program transfer hyperparameter
optimization. <em>AAAI</em>, 10297–10305. (<a
href="https://doi.org/10.1609/aaai.v37i9.26226">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Hyperparameter tuning is an essential task in automatic machine learning and big data management. To accelerate tuning, many recent studies focus on augmenting BO, the primary hyperparameter tuning strategy, by transferring information from other tuning tasks. However, existing studies ignore program similarities in their transfer mechanism, thus they are sub-optimal in cross-program transfer when tuning tasks involve different programs. This paper proposes CaTHPO, a code-aware cross-program transfer hyperparameter optimization framework, which makes three improvements. (1) It learns code-aware program representation in a self-supervised manner to give an off-the-shelf estimate of program similarities. (2) It adjusts the surrogate and AF in BO based on program similarities, thus the hyperparameter search is guided by accumulated information across similar programs. (3) It presents a safe controller to dynamically prune undesirable sample points based on tuning experiences of similar programs. Extensive experiments on tuning various recommendation models and Spark applications have demonstrated that CatHPO can steadily obtain better and more robust hyperparameter performances within fewer samples than state-of-the-art competitors.},
  archive   = {C_AAAI},
  author    = {Zijia Wang and Xiangyu He and Kehan Chen and Chen Lin and Jinsong Su},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i9.26226},
  pages     = {10297-10305},
  title     = {Code-aware cross-program transfer hyperparameter optimization},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). Efficient explorative key-term selection strategies for
conversational contextual bandits. <em>AAAI</em>, 10288–10295. (<a
href="https://doi.org/10.1609/aaai.v37i8.26225">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Conversational contextual bandits elicit user preferences by occasionally querying for explicit feedback on key-terms to accelerate learning. However, there are aspects of existing approaches which limit their performance. First, information gained from key-term-level conversations and arm-level recommendations is not appropriately incorporated to speed up learning. Second, it is important to ask explorative key-terms to quickly elicit the user&#39;s potential interests in various domains to accelerate the convergence of user preference estimation, which has never been considered in existing works. To tackle these issues, we first propose ``ConLinUCB&quot;, a general framework for conversational bandits with better information incorporation, combining arm-level and key-term-level feedback to estimate user preference in one step at each time. Based on this framework, we further design two bandit algorithms with explorative key-term selection strategies, ConLinUCB-BS and ConLinUCB-MCR. We prove tighter regret upper bounds of our proposed algorithms. Particularly, ConLinUCB-BS achieves a better regret bound than the previous result. Extensive experiments on synthetic and real-world data show significant advantages of our algorithms in learning accuracy (up to 54\% improvement) and computational efficiency (up to 72\% improvement), compared to the classic ConUCB algorithm, showing the potential benefit to recommender systems.},
  archive   = {C_AAAI},
  author    = {Zhiyong Wang and Xutong Liu and Shuai Li and John C. S. Lui},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26225},
  pages     = {10288-10295},
  title     = {Efficient explorative key-term selection strategies for conversational contextual bandits},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Efficient exploration in resource-restricted reinforcement
learning. <em>AAAI</em>, 10279–10287. (<a
href="https://doi.org/10.1609/aaai.v37i8.26224">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In many real-world applications of reinforcement learning (RL), performing actions requires consuming certain types of resources that are non-replenishable in each episode. Typical applications include robotic control with limited energy and video games with consumable items. In tasks with non-replenishable resources, we observe that popular RL methods such as soft actor critic suffer from poor sample efficiency. The major reason is that, they tend to exhaust resources fast and thus the subsequent exploration is severely restricted due to the absence of resources. To address this challenge, we first formalize the aforementioned problem as a resource-restricted reinforcement learning, and then propose a novel resource-aware exploration bonus (RAEB) to make reasonable usage of resources. An appealing feature of RAEB is that, it can significantly reduce unnecessary resource-consuming trials while effectively encouraging the agent to explore unvisited states. Experiments demonstrate that the proposed RAEB significantly outperforms state-of-the-art exploration strategies in resource-restricted reinforcement learning environments, improving the sample efficiency by up to an order of magnitude.},
  archive   = {C_AAAI},
  author    = {Zhihai Wang and Taoxing Pan and Qi Zhou and Jie Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26224},
  pages     = {10279-10287},
  title     = {Efficient exploration in resource-restricted reinforcement learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FedGS: Federated graph-based sampling with arbitrary client
availability. <em>AAAI</em>, 10271–10278. (<a
href="https://doi.org/10.1609/aaai.v37i8.26223">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {While federated learning has shown strong results in opti- mizing a machine learning model without direct access to the original data, its performance may be hindered by in- termittent client availability which slows down the conver- gence and biases the final learned model. There are significant challenges to achieve both stable and bias-free training un- der arbitrary client availability. To address these challenges, we propose a framework named Federated Graph-based Sam- pling (FEDGS), to stabilize the global model update and mitigate the long-term bias given arbitrary client availabil- ity simultaneously. First, we model the data correlations of clients with a Data-Distribution-Dependency Graph (3DG) that helps keep the sampled clients data apart from each other, which is theoretically shown to improve the approximation to the optimal model update. Second, constrained by the far- distance in data distribution of the sampled clients, we fur- ther minimize the variance of the numbers of times that the clients are sampled, to mitigate long-term bias. To validate the effectiveness of FEDGS, we conduct experiments on three datasets under a comprehensive set of seven client availability modes. Our experimental results confirm FEDGS’s advantage in both enabling a fair client-sampling scheme and improving the model performance under arbitrary client availability. Our code is available at https://github.com/WwZzz/FedGS.},
  archive   = {C_AAAI},
  author    = {Zheng Wang and Xiaoliang Fan and Jianzhong Qi and Haibing Jin and Peizhen Yang and Siqi Shen and Cheng Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26223},
  pages     = {10271-10278},
  title     = {FedGS: Federated graph-based sampling with arbitrary client availability},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unlabeled imperfect demonstrations in adversarial imitation
learning. <em>AAAI</em>, 10262–10270. (<a
href="https://doi.org/10.1609/aaai.v37i8.26222">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Adversarial imitation learning has become a widely used imitation learning framework. The discriminator is often trained by taking expert demonstrations and policy trajectories as examples respectively from two categories (positive vs. negative) and the policy is then expected to produce trajectories that are indistinguishable from the expert demonstrations. But in the real world, the collected expert demonstrations are more likely to be imperfect, where only an unknown fraction of the demonstrations are optimal. Instead of treating imperfect expert demonstrations as absolutely positive or negative, we investigate unlabeled imperfect expert demonstrations as they are. A positive-unlabeled adversarial imitation learning algorithm is developed to dynamically sample expert demonstrations that can well match the trajectories from the constantly optimized agent policy. The trajectories of an initial agent policy could be closer to those non-optimal expert demonstrations, but within the framework of adversarial imitation learning, agent policy will be optimized to cheat the discriminator and produce trajectories that are similar to those optimal expert demonstrations. Theoretical analysis shows that our method learns from the imperfect demonstrations via a self-paced way. Experimental results on MuJoCo and RoboSuite platforms demonstrate the effectiveness of our method from different aspects.},
  archive   = {C_AAAI},
  author    = {Yunke Wang and Bo Du and Chang Xu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26222},
  pages     = {10262-10270},
  title     = {Unlabeled imperfect demonstrations in adversarial imitation learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023d). SEnsor alignment for multivariate time-series unsupervised
domain adaptation. <em>AAAI</em>, 10253–10261. (<a
href="https://doi.org/10.1609/aaai.v37i8.26221">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Unsupervised Domain Adaptation (UDA) methods can reduce label dependency by mitigating the feature discrepancy between labeled samples in a source domain and unlabeled samples in a similar yet shifted target domain. Though achieving good performance, these methods are inapplicable for Multivariate Time-Series (MTS) data. MTS data are collected from multiple sensors, each of which follows various distributions. However, most UDA methods solely focus on aligning global features but cannot consider the distinct distributions of each sensor. To cope with such concerns, a practical domain adaptation scenario is formulated as Multivariate Time-Series Unsupervised Domain Adaptation (MTS-UDA). In this paper, we propose SEnsor Alignment (SEA) for MTS-UDA to reduce the domain discrepancy at both the local and global sensor levels. At the local sensor level, we design the endo-feature alignment to align sensor features and their correlations across domains, whose information represents the features of each sensor and the interactions between sensors. Further, to reduce domain discrepancy at the global sensor level, we design the exo-feature alignment to enforce restrictions on the global sensor features. Meanwhile, MTS also incorporates the essential spatial-temporal dependencies information between sensors, which cannot be transferred by existing UDA methods. Therefore, we model the spatial-temporal information of MTS with a multi-branch self-attention mechanism for simple and effective transfer across domains. Empirical results demonstrate the state-of-the-art performance of our proposed SEA on two public MTS datasets for MTS-UDA. The code is available at https://github.com/Frank-Wang-oss/SEA},
  archive   = {C_AAAI},
  author    = {Yucheng Wang and Yuecong Xu and Jianfei Yang and Zhenghua Chen and Min Wu and Xiaoli Li and Lihua Xie},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26221},
  pages     = {10253-10261},
  title     = {SEnsor alignment for multivariate time-series unsupervised domain adaptation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AutoNF: Automated architecture optimization of normalizing
flows with unconstrained continuous relaxation admitting optimal
discrete solution. <em>AAAI</em>, 10244–10252. (<a
href="https://doi.org/10.1609/aaai.v37i8.26220">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Normalizing flows (NF) build upon invertible neural networks and have wide applications in probabilistic modeling. Currently, building a powerful yet computationally efficient flow model relies on empirical fine-tuning over a large design space. While introducing neural architecture search (NAS) to NF is desirable, the invertibility constraint of NF brings new challenges to existing NAS methods whose application is limited to unstructured neural networks. Developing efficient NAS methods specifically for NF remains an open problem. We present AutoNF, the first automated NF architectural optimization framework. First, we present a new mixture distribution formulation that allows efficient differentiable architecture search of flow models without violating the invertibility constraint. Second, under the new formulation, we convert the original NP-hard combinatorial NF architectural optimization problem to an unconstrained continuous relaxation admitting the discrete optimal architectural solution, circumventing the loss of optimality due to binarization in architectural optimization. We evaluate AutoNF with various density estimation datasets and show its superior performance-cost trade-offs over a set of existing hand-crafted baselines.},
  archive   = {C_AAAI},
  author    = {Yu Wang and Ján Drgoňa and Jiaxin Zhang and Karthik Somayaji Nanjangud Suryanarayana and Malachi Schram and Frank Liu and Peng Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26220},
  pages     = {10244-10252},
  title     = {AutoNF: Automated architecture optimization of normalizing flows with unconstrained continuous relaxation admitting optimal discrete solution},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). USER: Unsupervised structural entropy-based robust graph
neural network. <em>AAAI</em>, 10235–10243. (<a
href="https://doi.org/10.1609/aaai.v37i8.26219">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Unsupervised/self-supervised graph neural networks (GNN) are susceptible to the inherent randomness in the input graph data, which adversely affects the model&#39;s performance in downstream tasks. In this paper, we propose USER, an unsupervised and robust version of GNN based on structural entropy, to alleviate the interference of graph perturbations and learn appropriate representations of nodes without label information. To mitigate the effects of undesirable perturbations, we analyze the property of intrinsic connectivity and define the intrinsic connectivity graph. We also identify the rank of the adjacency matrix as a crucial factor in revealing a graph that provides the same embeddings as the intrinsic connectivity graph. To capture such a graph, we introduce structural entropy in the objective function. Extensive experiments conducted on clustering and link prediction tasks under random-perturbation and meta-attack over three datasets show that USER outperforms benchmarks and is robust to heavier perturbations.},
  archive   = {C_AAAI},
  author    = {Yifei Wang and Yupan Wang and Zeyu Zhang and Song Yang and Kaiqi Zhao and Jiamou Liu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26219},
  pages     = {10235-10243},
  title     = {USER: Unsupervised structural entropy-based robust graph neural network},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Distributed projection-free online learning for smooth and
convex losses. <em>AAAI</em>, 10226–10234. (<a
href="https://doi.org/10.1609/aaai.v37i8.26218">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We investigate the problem of distributed online convex optimization with complicated constraints, in which the projection operation could be the computational bottleneck. To avoid projections, distributed online projection-free methods have been proposed and attain an O(T^{3/4}) regret bound for general convex losses. However, they cannot utilize the smoothness condition, which has been exploited in the centralized setting to improve the regret. In this paper, we propose a new distributed online projection-free method with a tighter regret bound of O(T^{2/3}) for smooth and convex losses. Specifically, we first provide a distributed extension of Follow-the-Perturbed-Leader so that the smoothness can be utilized in the distributed setting. Then, we reduce the computational cost via sampling and blocking techniques. In this way, our method only needs to solve one linear optimization per round on average. Finally, we conduct experiments on benchmark datasets to verify the effectiveness of our proposed method.},
  archive   = {C_AAAI},
  author    = {Yibo Wang and Yuanyu Wan and Shimao Zhang and Lijun Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26218},
  pages     = {10226-10234},
  title     = {Distributed projection-free online learning for smooth and convex losses},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Robust self-supervised multi-instance learning with
structure awareness. <em>AAAI</em>, 10218–10225. (<a
href="https://doi.org/10.1609/aaai.v37i8.26217">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-instance learning (MIL) is a supervised learning where each example is a labeled bag with many instances. The typical MIL strategies are to train an instance-level feature extractor followed by aggregating instances features as bag-level representation with labeled information. However, learning such a bag-level representation highly depends on a large number of labeled datasets, which are difficult to get in real-world scenarios. In this paper, we make the first attempt to propose a robust Self-supervised Multi-Instance LEarning architecture with Structure awareness (SMILEs) that learns unsupervised bag representation. Our proposed approach is: 1) permutation invariant to the order of instances in bag; 2) structure-aware to encode the topological structures among the instances; and 3) robust against instances noise or permutation. Specifically, to yield robust MIL model without label information, we augment the multi-instance bag and train the representation encoder to maximize the correspondence between the representations of the same bag in its different augmented forms. Moreover, to capture topological structures from nearby instances in bags, our framework learns optimal graph structures for the bags and these graphs are optimized together with message passing layers and the ordered weighted averaging operator towards contrastive loss. Our main theorem characterizes the permutation invariance of the bag representation. Compared with state-of-the-art supervised MIL baselines, SMILEs achieves average improvement of 4.9\%, 4.4\% in classification accuracy on 5 benchmark datasets and 20 newsgroups datasets, respectively. In addition, we show that the model is robust to the input corruption.},
  archive   = {C_AAAI},
  author    = {Yejiang Wang and Yuhai Zhao and Zhengkui Wang and Meixia Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26217},
  pages     = {10218-10225},
  title     = {Robust self-supervised multi-instance learning with structure awareness},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Isolation and impartial aggregation: A paradigm of
incremental learning without interference. <em>AAAI</em>, 10209–10217.
(<a href="https://doi.org/10.1609/aaai.v37i8.26216">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper focuses on the prevalent stage interference and stage performance imbalance of incremental learning. To avoid obvious stage learning bottlenecks, we propose a new incremental learning framework, which leverages a series of stage-isolated classifiers to perform the learning task at each stage, without interference from others. To be concrete, to aggregate multiple stage classifiers as a uniform one impartially, we first introduce a temperature-controlled energy metric for indicating the confidence score levels of the stage classifiers. We then propose an anchor-based energy self-normalization strategy to ensure the stage classifiers work at the same energy level. Finally, we design a voting-based inference augmentation strategy for robust inference. The proposed method is rehearsal-free and can work for almost all incremental learning scenarios. We evaluate the proposed method on four large datasets. Extensive results demonstrate the superiority of the proposed method in setting up new state-of-the-art overall performance. Code is available at https://github.com/iamwangyabin/ESN.},
  archive   = {C_AAAI},
  author    = {Yabin Wang and Zhiheng Ma and Zhiwu Huang and Yaowei Wang and Zhou Su and Xiaopeng Hong},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26216},
  pages     = {10209-10217},
  title     = {Isolation and impartial aggregation: A paradigm of incremental learning without interference},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Correspondence-free domain alignment for unsupervised
cross-domain image retrieval. <em>AAAI</em>, 10200–10208. (<a
href="https://doi.org/10.1609/aaai.v37i8.26215">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Cross-domain image retrieval aims at retrieving images across different domains to excavate cross-domain classificatory or correspondence relationships. This paper studies a less-touched problem of cross-domain image retrieval, i.e., unsupervised cross-domain image retrieval, considering the following practical assumptions: (i) no correspondence relationship, and (ii) no category annotations. It is challenging to align and bridge distinct domains without cross-domain correspondence. To tackle the challenge, we present a novel Correspondence-free Domain Alignment (CoDA) method to effectively eliminate the cross-domain gap through In-domain Self-matching Supervision (ISS) and Cross-domain Classifier Alignment (CCA). To be specific, ISS is presented to encapsulate discriminative information into the latent common space by elaborating a novel self-matching supervision mechanism. To alleviate the cross-domain discrepancy, CCA is proposed to align distinct domain-specific classifiers. Thanks to the ISS and CCA, our method could encode the discrimination into the domain-invariant embedding space for unsupervised cross-domain image retrieval. To verify the effectiveness of the proposed method, extensive experiments are conducted on four benchmark datasets compared with six state-of-the-art methods.},
  archive   = {C_AAAI},
  author    = {Xu Wang and Dezhong Peng and Ming Yan and Peng Hu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26215},
  pages     = {10200-10208},
  title     = {Correspondence-free domain alignment for unsupervised cross-domain image retrieval},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep attentive model for knowledge tracing. <em>AAAI</em>,
10192–10199. (<a
href="https://doi.org/10.1609/aaai.v37i8.26214">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Knowledge Tracing (KT) is a crucial task in the field of online education, since it aims to predict students&#39; performance on exercises based on their learning history. One typical solution for knowledge tracing is to combine the classic models in educational psychology, such as Item Response Theory (IRT) and Cognitive Diagnosis (CD), with Deep Neural Networks (DNN) technologies. In this solution, a student and related exercises are mapped into feature vectors based on the student&#39;s performance at the current time step, however, it does not consider the impact of historical behavior sequences, and the relationships between historical sequences and students. In this paper, we develop DAKTN, a novel model which assimilates the historical sequences to tackle this challenge for better knowledge tracing. To be specific, we apply a pooling layer to incorporate the student behavior sequence in the embedding layer. After that, we further design a local activation unit, which can adaptively calculate the representation vectors by taking the relevance of historical sequences into consideration with respect to candidate student and exercises. Through experimental results on three real-world datasets, DAKTN significantly outperforms state-of-the-art baseline models. We also present the reasonableness of DAKTN by ablation testing.},
  archive   = {C_AAAI},
  author    = {Xinping Wang and Liangyu Chen and Min Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26214},
  pages     = {10192-10199},
  title     = {Deep attentive model for knowledge tracing},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). State-conditioned adversarial subgoal generation.
<em>AAAI</em>, 10184–10191. (<a
href="https://doi.org/10.1609/aaai.v37i8.26213">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Hierarchical reinforcement learning (HRL) proposes to solve difficult tasks by performing decision-making and control at successively higher levels of temporal abstraction. However, off-policy HRL often suffers from the problem of a non-stationary high-level policy since the low-level policy is constantly changing. In this paper, we propose a novel HRL approach for mitigating the non-stationarity by adversarially enforcing the high-level policy to generate subgoals compatible with the current instantiation of the low-level policy. In practice, the adversarial learning is implemented by training a simple state conditioned discriminator network concurrently with the high-level policy which determines the compatibility level of subgoals. Comparison to state-of-the-art algorithms shows that our approach improves both learning efficiency and performance in challenging continuous control tasks.},
  archive   = {C_AAAI},
  author    = {Vivienne Huiling Wang and Joni Pajarinen and Tinghuai Wang and Joni-Kristian Kämäräinen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26213},
  pages     = {10184-10191},
  title     = {State-conditioned adversarial subgoal generation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). Beyond ADMM: A unified client-variance-reduced adaptive
federated learning framework. <em>AAAI</em>, 10175–10183. (<a
href="https://doi.org/10.1609/aaai.v37i8.26212">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As a novel distributed learning paradigm, federated learning (FL) faces serious challenges in dealing with massive clients with heterogeneous data distribution and computation and communication resources. Various client-variance-reduction schemes and client sampling strategies have been respectively introduced to improve the robustness of FL. Among others, primal-dual algorithms such as the alternating direction of method multipliers (ADMM) have been found being resilient to data distribution and outperform most of the primal-only FL algorithms. However, the reason behind remains a mystery still. In this paper, we firstly reveal the fact that the federated ADMM is essentially a client-variance-reduced algorithm. While this explains the inherent robustness of federated ADMM, the vanilla version of it lacks the ability to be adaptive to the degree of client heterogeneity. Besides, the global model at the server under client sampling is biased which slows down the practical convergence. To go beyond ADMM, we propose a novel primal-dual FL algorithm, termed FedVRA, that allows one to adaptively control the variance-reduction level and biasness of the global model. In addition, FedVRA unifies several representative FL algorithms in the sense that they are either special instances of FedVRA or are close to it. Extensions of FedVRA to semi/un-supervised learning are also presented. Experiments based on (semi-)supervised image classification tasks demonstrate superiority of FedVRA over the existing schemes in learning scenarios with massive heterogeneous clients and client sampling.},
  archive   = {C_AAAI},
  author    = {Shuai Wang and Yanqing Xu and Zhiguo Wang and Tsung-Hui Chang and Tony Q. S. Quek and Defeng Sun},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26212},
  pages     = {10175-10183},
  title     = {Beyond ADMM: A unified client-variance-reduced adaptive federated learning framework},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hierarchical contrastive learning for temporal point
processes. <em>AAAI</em>, 10166–10174. (<a
href="https://doi.org/10.1609/aaai.v37i8.26211">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As an important sequential model, the temporal point process (TPP) plays a central role in real-world sequence modeling and analysis, whose learning is often based on the maximum likelihood estimation (MLE). However, due to imperfect observations, such as incomplete and sparse sequences that are common in practice, the MLE of TPP models often suffers from overfitting and leads to unsatisfactory generalization power. In this work, we develop a novel hierarchical contrastive (HCL) learning method for temporal point processes, which provides a new regularizer of MLE. In principle, our HCL considers the noise contrastive estimation (NCE) problem at the event-level and at the sequence-level jointly. Given a sequence, the event-level NCE maximizes the probability of each observed event given its history while penalizing the conditional probabilities of the unobserved events. At the same time, we generate positive and negative event sequences from the observed sequence and maximize the discrepancy between their likelihoods through the sequence-level NCE. Instead of using time-consuming simulation methods, we generate the positive and negative sequences via a simple but efficient model-guided thinning process. Experimental results show that the MLE method assisted by the HCL regularizer outperforms classic MLE and other contrastive learning methods in learning various TPP models consistently. The code is available at https://github.com/qingmeiwangdaily/HCL_TPP.},
  archive   = {C_AAAI},
  author    = {Qingmei Wang and Minjie Cheng and Shen Yuan and Hongteng Xu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26211},
  pages     = {10166-10174},
  title     = {Hierarchical contrastive learning for temporal point processes},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Meta-reinforcement learning based on self-supervised task
representation learning. <em>AAAI</em>, 10157–10165. (<a
href="https://doi.org/10.1609/aaai.v37i8.26210">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Meta-reinforcement learning enables artificial agents to learn from related training tasks and adapt to new tasks efficiently with minimal interaction data. However, most existing research is still limited to narrow task distributions that are parametric and stationary, and does not consider out-of-distribution tasks during the evaluation, thus, restricting its application. In this paper, we propose MoSS, a context-based Meta-reinforcement learning algorithm based on Self-Supervised task representation learning to address this challenge. We extend meta-RL to broad non-parametric task distributions which have never been explored before, and also achieve state-of-the-art results in non-stationary and out-of-distribution tasks. Specifically, MoSS consists of a task inference module and a policy module. We utilize the Gaussian mixture model for task representation to imitate the parametric and non-parametric task variations. Additionally, our online adaptation strategy enables the agent to react at the first sight of a task change, thus being applicable in non-stationary tasks. MoSS also exhibits strong generalization robustness in out-of-distributions tasks which benefits from the reliable and robust task representation. The policy is built on top of an off-policy RL algorithm and the entire network is trained completely off-policy to ensure high sample efficiency. On MuJoCo and Meta-World benchmarks, MoSS outperforms prior works in terms of asymptotic performance, sample efficiency (3-50x faster), adaptation efficiency, and generalization robustness on broad and diverse task distributions.},
  archive   = {C_AAAI},
  author    = {Mingyang Wang and Zhenshan Bing and Xiangtong Yao and Shuai Wang and Huang Kai and Hang Su and Chenguang Yang and Alois Knoll},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26210},
  pages     = {10157-10165},
  title     = {Meta-reinforcement learning based on self-supervised task representation learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The implicit regularization of momentum gradient descent in
overparametrized models. <em>AAAI</em>, 10149–10156. (<a
href="https://doi.org/10.1609/aaai.v37i8.26209">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The study of the implicit regularization induced by gradient-based optimization in deep learning is a long-standing pursuit. In the present paper, we characterize the implicit regularization of momentum gradient descent (MGD) in the continuous-time view, so-called momentum gradient flow (MGF). We show that the components of weight vector are learned for a deep linear neural networks at different evolution rates, and this evolution gap increases with the depth. Firstly, we show that if the depth equals one, the evolution gap between the weight vector components is linear, which is consistent with the performance of ridge. In particular, we establish a tight coupling between MGF and ridge for the least squares regression. In detail, we show that when the regularization parameter of ridge is inversely proportional to the square of the time parameter of MGF, the risk of MGF is no more than 1.54 times that of ridge, and their relative Bayesian risks are almost indistinguishable. Secondly, if the model becomes deeper, i.e. the depth is greater than or equal to 2, the evolution gap becomes more significant, which implies an implicit bias towards sparse solutions. The numerical experiments strongly support our theoretical results.},
  archive   = {C_AAAI},
  author    = {Li Wang and Zhiguo Fu and Yingcong Zhou and Zili Yan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26209},
  pages     = {10149-10156},
  title     = {The implicit regularization of momentum gradient descent in overparametrized models},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AEC-GAN: Adversarial error correction GANs for
auto-regressive long time-series generation. <em>AAAI</em>, 10140–10148.
(<a href="https://doi.org/10.1609/aaai.v37i8.26208">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Large-scale high-quality data is critical for training modern deep neural networks. However, data acquisition can be costly or time-consuming for many time-series applications, thus researchers turn to generative models for generating synthetic time-series data. In particular, recent generative adversarial networks (GANs) have achieved remarkable success in time-series generation. Despite their success, existing GAN models typically generate the sequences in an auto-regressive manner, and we empirically observe that they suffer from severe distribution shifts and bias amplification, especially when generating long sequences. To resolve this problem, we propose Adversarial Error Correction GAN (AEC-GAN), which is capable of dynamically correcting the bias in the past generated data to alleviate the risk of distribution shifts and thus can generate high-quality long sequences. AEC-GAN contains two main innovations: (1) We develop an error correction module to mitigate the bias. In the training phase, we adversarially perturb the realistic time-series data and then optimize this module to reconstruct the original data. In the generation phase, this module can act as an efficient regulator to detect and mitigate the bias. (2) We propose an augmentation method to facilitate GAN&#39;s training by introducing adversarial examples. Thus, AEC-GAN can generate high-quality sequences of arbitrary lengths, and the synthetic data can be readily applied to downstream tasks to boost their performance. We conduct extensive experiments on six widely used datasets and three state-of-the-art time-series forecasting models to evaluate the quality of our synthetic time-series data in different lengths and downstream tasks. Both the qualitative and quantitative experimental results demonstrate the superior performance of AEC-GAN over other deep generative models for time-series generation.},
  archive   = {C_AAAI},
  author    = {Lei Wang and Liang Zeng and Jian Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26208},
  pages     = {10140-10148},
  title     = {AEC-GAN: Adversarial error correction GANs for auto-regressive long time-series generation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Optimistic whittle index policy: Online learning for
restless bandits. <em>AAAI</em>, 10131–10139. (<a
href="https://doi.org/10.1609/aaai.v37i8.26207">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Restless multi-armed bandits (RMABs) extend multi-armed bandits to allow for stateful arms, where the state of each arm evolves restlessly with different transitions depending on whether that arm is pulled. Solving RMABs requires information on transition dynamics, which are often unknown upfront. To plan in RMAB settings with unknown transitions, we propose the first online learning algorithm based on the Whittle index policy, using an upper confidence bound (UCB) approach to learn transition dynamics. Specifically, we estimate confidence bounds of the transition probabilities and formulate a bilinear program to compute optimistic Whittle indices using these estimates. Our algorithm, UCWhittle, achieves sublinear O(H \sqrt{T log T}) frequentist regret to solve RMABs with unknown transitions in T episodes with a constant horizon H. Empirically, we demonstrate that UCWhittle leverages the structure of RMABs and the Whittle index policy solution to achieve better performance than existing online learning baselines across three domains, including one constructed from a real-world maternal and childcare dataset.},
  archive   = {C_AAAI},
  author    = {Kai Wang and Lily Xu and Aparna Taneja and Milind Tambe},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26207},
  pages     = {10131-10139},
  title     = {Optimistic whittle index policy: Online learning for restless bandits},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Effective continual learning for text classification with
lightweight snapshots. <em>AAAI</em>, 10122–10130. (<a
href="https://doi.org/10.1609/aaai.v37i8.26206">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Continual learning is known for suffering from catastrophic forgetting, a phenomenon where previously learned concepts are forgotten upon learning new tasks. A natural remedy is to use trained models for old tasks as ‘teachers’ to regularize the update of the current model to prevent such forgetting. However, this requires storing all past models, which is very space-consuming for large models, e.g. BERT, thus impractical in real-world applications. To tackle this issue, we propose to construct snapshots of seen tasks whose key knowledge is captured in lightweight adapters. During continual learning, we transfer knowledge from past snapshots to the current model through knowledge distillation, allowing the current model to review previously learned knowledge while learning new tasks. We also design representation recalibration to better handle the class-incremental setting. Experiments over various task sequences show that our approach effectively mitigates catastrophic forgetting and outperforms all baselines.},
  archive   = {C_AAAI},
  author    = {Jue Wang and Dajie Dong and Lidan Shou and Ke Chen and Gang Chen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26206},
  pages     = {10122-10130},
  title     = {Effective continual learning for text classification with lightweight snapshots},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). Stability-based generalization analysis for mixtures of
pointwise and pairwise learning. <em>AAAI</em>, 10113–10121. (<a
href="https://doi.org/10.1609/aaai.v37i8.26205">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, some mixture algorithms of pointwise and pairwise learning (PPL) have been formulated by employing the hybrid error metric of “pointwise loss + pairwise loss” and have shown empirical effectiveness on feature selection, ranking and recommendation tasks. However, to the best of our knowledge, the learning theory foundation of PPL has not been touched in the existing works. In this paper, we try to fill this theoretical gap by investigating the generalization properties of PPL. After extending the definitions of algorithmic stability to the PPL setting, we establish the high-probability generalization bounds for uniformly stable PPL algorithms. Moreover, explicit convergence rates of stochastic gradient descent (SGD) and regularized risk minimization (RRM) for PPL are stated by developing the stability analysis technique of pairwise learning. In addition, the refined generalization bounds of PPL are obtained by replacing uniform stability with on-average stability.},
  archive   = {C_AAAI},
  author    = {Jiahuan Wang and Jun Chen and Hong Chen and Bin Gu and Weifu Li and Xin Tang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26205},
  pages     = {10113-10121},
  title     = {Stability-based generalization analysis for mixtures of pointwise and pairwise learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spearman rank correlation screening for
ultrahigh-dimensional censored data. <em>AAAI</em>, 10104–10112. (<a
href="https://doi.org/10.1609/aaai.v37i8.26204">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Herein, we propose a Spearman rank correlation-based screening procedure for ultrahigh-dimensional data with censored response cases. The proposed method is model-free without specifying any regression forms of predictors or response variables and is robust under the unknown monotone transformations of these response variable and predictors. The sure-screening and rank-consistency properties are established under some mild regularity conditions. Simulation studies demonstrate that the new screening method performs well in the presence of a heavy-tailed distribution, strongly dependent predictors or outliers, and offers superior performance over the existing nonparametric screening procedures. In particular, the new screening method still works well when a response variable is observed under a high censoring rate. An illustrative example is provided.},
  archive   = {C_AAAI},
  author    = {Hongni Wang and Jingxin Yan and Xiaodong Yan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26204},
  pages     = {10104-10112},
  title     = {Spearman rank correlation screening for ultrahigh-dimensional censored data},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FedABC: Targeting fair competition in personalized federated
learning. <em>AAAI</em>, 10095–10103. (<a
href="https://doi.org/10.1609/aaai.v37i8.26203">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Federated learning aims to collaboratively train models without accessing their client&#39;s local private data. The data may be Non-IID for different clients and thus resulting in poor performance. Recently, personalized federated learning (PFL) has achieved great success in handling Non-IID data by enforcing regularization in local optimization or improving the model aggregation scheme on the server. However, most of the PFL approaches do not take into account the unfair competition issue caused by the imbalanced data distribution and lack of positive samples for some classes in each client. To address this issue, we propose a novel and generic PFL framework termed Federated Averaging via Binary Classification, dubbed FedABC. In particular, we adopt the ``one-vs-all&#39;&#39; training strategy in each client to alleviate the unfair competition between classes by constructing a personalized binary classification problem for each class. This may aggravate the class imbalance challenge and thus a novel personalized binary classification loss that incorporates both the under-sampling and hard sample mining strategies is designed. Extensive experiments are conducted on two popular datasets under different settings, and the results demonstrate that our FedABC can significantly outperform the existing counterparts.},
  archive   = {C_AAAI},
  author    = {Dui Wang and Li Shen and Yong Luo and Han Hu and Kehua Su and Yonggang Wen and Dacheng Tao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26203},
  pages     = {10095-10103},
  title     = {FedABC: Targeting fair competition in personalized federated learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Quantum multi-armed bandits and stochastic linear bandits
enjoy logarithmic regrets. <em>AAAI</em>, 10087–10094. (<a
href="https://doi.org/10.1609/aaai.v37i8.26202">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-arm bandit (MAB) and stochastic linear bandit (SLB) are important models in reinforcement learning, and it is well-known that classical algorithms for bandits with time horizon T suffer from the regret of at least the square root of T. In this paper, we study MAB and SLB with quantum reward oracles and propose quantum algorithms for both models with the order of the polylog T regrets, exponentially improving the dependence in terms of T. To the best of our knowledge, this is the first provable quantum speedup for regrets of bandit problems and in general exploitation in reinforcement learning. Compared to previous literature on quantum exploration algorithms for MAB and reinforcement learning, our quantum input model is simpler and only assumes quantum oracles for each individual arm.},
  archive   = {C_AAAI},
  author    = {Zongqi Wan and Zhijie Zhang and Tongyang Li and Jialin Zhang and Xiaoming Sun},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26202},
  pages     = {10087-10094},
  title     = {Quantum multi-armed bandits and stochastic linear bandits enjoy logarithmic regrets},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Auto-weighted multi-view clustering for large-scale data.
<em>AAAI</em>, 10078–10086. (<a
href="https://doi.org/10.1609/aaai.v37i8.26201">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-view clustering has gained broad attention owing to its capacity to exploit complementary information across multiple data views. Although existing methods demonstrate delightful clustering performance, most of them are of high time complexity and cannot handle large-scale data. Matrix factorization-based models are a representative of solving this problem. However, they assume that the views share a dimension-fixed consensus coefficient matrix and view-specific base matrices, limiting their representability. Moreover, a series of large-scale algorithms that bear one or more hyperparameters are impractical in real-world applications. To address the two issues, we propose an auto-weighted multi-view clustering (AWMVC) algorithm. Specifically, AWMVC first learns coefficient matrices from corresponding base matrices of different dimensions, then fuses them to obtain an optimal consensus matrix. By mapping original features into distinctive low-dimensional spaces, we can attain more comprehensive knowledge, thus obtaining better clustering results. Moreover, we design a six-step alternative optimization algorithm proven to be convergent theoretically. Also, AWMVC shows excellent performance on various benchmark datasets compared with existing ones. The code of AWMVC is publicly available at https://github.com/wanxinhang/AAAI-2023-AWMVC.},
  archive   = {C_AAAI},
  author    = {Xinhang Wan and Xinwang Liu and Jiyuan Liu and Siwei Wang and Yi Wen and Weixuan Liang and En Zhu and Zhe Liu and Lu Zhou},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26201},
  pages     = {10078-10086},
  title     = {Auto-weighted multi-view clustering for large-scale data},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Kalman bayesian neural networks for closed-form online
learning. <em>AAAI</em>, 10069–10077. (<a
href="https://doi.org/10.1609/aaai.v37i8.26200">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Compared to point estimates calculated by standard neural networks, Bayesian neural networks (BNN) provide probability distributions over the output predictions and model parameters, i.e., the weights. Training the weight distribution of a BNN, however, is more involved due to the intractability of the underlying Bayesian inference problem and thus, requires efficient approximations. In this paper, we propose a novel approach for BNN learning via closed-form Bayesian inference. For this purpose, the calculation of the predictive distribution of the output and the update of the weight distribution are treated as Bayesian filtering and smoothing problems, where the weights are modeled as Gaussian random variables. This allows closed-form expressions for training the network&#39;s parameters in a sequential/online fashion without gradient descent. We demonstrate our method on several UCI datasets and compare it to the state of the art.},
  archive   = {C_AAAI},
  author    = {Philipp Wagner and Xinyang Wu and Marco F. Huber},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26200},
  pages     = {10069-10077},
  title     = {Kalman bayesian neural networks for closed-form online learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Machines of finite depth: Towards a formalization of neural
networks. <em>AAAI</em>, 10061–10068. (<a
href="https://doi.org/10.1609/aaai.v37i8.26199">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We provide a unifying framework where artificial neural networks and their architectures can be formally described as particular cases of a general mathematical construction---machines of finite depth. Unlike neural networks, machines have a precise definition, from which several properties follow naturally. Machines of finite depth are modular (they can be combined), efficiently computable, and differentiable. The backward pass of a machine is again a machine and can be computed without overhead using the same procedure as the forward pass. We prove this statement theoretically and practically via a unified implementation that generalizes several classical architectures---dense, convolutional, and recurrent neural networks with a rich shortcut structure---and their respective backpropagation rules.},
  archive   = {C_AAAI},
  author    = {Pietro Vertechi and Mattia G. Bergomi},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26199},
  pages     = {10061-10068},
  title     = {Machines of finite depth: Towards a formalization of neural networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Training-time attacks against k-nearest neighbors.
<em>AAAI</em>, 10053–10060. (<a
href="https://doi.org/10.1609/aaai.v37i8.26198">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Nearest neighbor-based methods are commonly used for classification tasks and as subroutines of other data-analysis methods. An attacker with the capability of inserting their own data points into the training set can manipulate the inferred nearest neighbor structure. We distill this goal to the task of performing a training-set data insertion attack against k-Nearest Neighbor classification (kNN). We prove that computing an optimal training-time (a.k.a. poisoning) attack against kNN classification is NP-Hard, even when k = 1 and the attacker can insert only a single data point. We provide an anytime algorithm to perform such an attack, and a greedy algorithm for general k and attacker budget. We provide theoretical bounds and empirically demonstrate the effectiveness and practicality of our methods on synthetic and real-world datasets. Empirically, we find that kNN is vulnerable in practice and that dimensionality reduction is an effective defense. We conclude with a discussion of open problems illuminated by our analysis.},
  archive   = {C_AAAI},
  author    = {Ara Vartanian and Will Rosenbaum and Scott Alfeld},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26198},
  pages     = {10053-10060},
  title     = {Training-time attacks against K-nearest neighbors},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient distribution similarity identification in
clustered federated learning via principal angles between client data
subspaces. <em>AAAI</em>, 10043–10052. (<a
href="https://doi.org/10.1609/aaai.v37i8.26197">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Clustered federated learning (FL) has been shown to produce promising results by grouping clients into clusters. This is especially effective in scenarios where separate groups of clients have significant differences in the distributions of their local data. Existing clustered FL algorithms are essentially trying to group together clients with similar distributions so that clients in the same cluster can leverage each other&#39;s data to better perform federated learning. However, prior clustered FL algorithms attempt to learn these distribution similarities indirectly during training, which can be quite time consuming as many rounds of federated learning may be required until the formation of clusters is stabilized. In this paper, we propose a new approach to federated learning that directly aims to efficiently identify distribution similarities among clients by analyzing the principal angles between the client data subspaces. Each client applies a truncated singular value decomposition (SVD) step on its local data in a single-shot manner to derive a small set of principal vectors, which provides a signature that succinctly captures the main characteristics of the underlying distribution. This small set of principal vectors is provided to the server so that the server can directly identify distribution similarities among the clients to form clusters. This is achieved by comparing the similarities of the principal angles between the client data subspaces spanned by those principal vectors. The approach provides a simple, yet effective clustered FL framework that addresses a broad range of data heterogeneity issues beyond simpler forms of Non-IIDness like label skews. Our clustered FL approach also enables convergence guarantees for non-convex objectives.},
  archive   = {C_AAAI},
  author    = {Saeed Vahidian and Mahdi Morafah and Weijia Wang and Vyacheslav Kungurtsev and Chen Chen and Mubarak Shah and Bill Lin},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26197},
  pages     = {10043-10052},
  title     = {Efficient distribution similarity identification in clustered federated learning via principal angles between client data subspaces},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A fair generative model using LeCam divergence.
<em>AAAI</em>, 10034–10042. (<a
href="https://doi.org/10.1609/aaai.v37i8.26196">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We explore a fairness-related challenge that arises in generative models. The challenge is that biased training data with imbalanced demographics may yield a high asymmetry in size of generated samples across distinct groups. We focus on practically-relevant scenarios wherein demographic labels are not available and therefore the design of a fair generative model is non-straightforward. In this paper, we propose an optimization framework that regulates the unfairness under such practical settings via one statistical measure, LeCam (LC)-divergence. Specifically to quantify the degree of unfairness, we employ a balanced-yet-small reference dataset and then measure its distance with generated samples using the LC-divergence, which is shown to be particularly instrumental to a small size of the reference dataset. We take a variational optimization approach to implement the LC-based measure. Experiments on benchmark real datasets demonstrate that the proposed framework can significantly improve the fairness performance while maintaining realistic sample quality for a wide range of the reference set size all the way down to 1\% relative to training set.},
  archive   = {C_AAAI},
  author    = {Soobin Um and Changho Suh},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26196},
  pages     = {10034-10042},
  title     = {A fair generative model using LeCam divergence},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Policy-adaptive estimator selection for off-policy
evaluation. <em>AAAI</em>, 10025–10033. (<a
href="https://doi.org/10.1609/aaai.v37i8.26195">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Off-policy evaluation (OPE) aims to accurately evaluate the performance of counterfactual policies using only offline logged data. Although many estimators have been developed, there is no single estimator that dominates the others, because the estimators&#39; accuracy can vary greatly depending on a given OPE task such as the evaluation policy, number of actions, and noise level. Thus, the data-driven estimator selection problem is becoming increasingly important and can have a significant impact on the accuracy of OPE. However, identifying the most accurate estimator using only the logged data is quite challenging because the ground-truth estimation accuracy of estimators is generally unavailable. This paper thus studies this challenging problem of estimator selection for OPE for the first time. In particular, we enable an estimator selection that is adaptive to a given OPE task, by appropriately subsampling available logged data and constructing pseudo policies useful for the underlying estimator selection task. Comprehensive experiments on both synthetic and real-world company data demonstrate that the proposed procedure substantially improves the estimator selection compared to a non-adaptive heuristic. Note that complete version with technical appendix is available on arXiv: http://arxiv.org/abs/2211.13904.},
  archive   = {C_AAAI},
  author    = {Takuma Udagawa and Haruka Kiyohara and Yusuke Narita and Yuta Saito and Kei Tateno},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26195},
  pages     = {10025-10033},
  title     = {Policy-adaptive estimator selection for off-policy evaluation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Linear regularizers enforce the strict saddle property.
<em>AAAI</em>, 10017–10024. (<a
href="https://doi.org/10.1609/aaai.v37i8.26194">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Satisfaction of the strict saddle property has become a standard assumption in non-convex optimization, and it ensures that many first-order optimization algorithms will almost always escape saddle points. However, functions exist in machine learning that do not satisfy this property, such as the loss function of a neural network with at least two hidden layers. First-order methods such as gradient descent may converge to non-strict saddle points of such functions, and there do not currently exist any first-order methods that reliably escape non-strict saddle points. To address this need, we demonstrate that regularizing a function with a linear term enforces the strict saddle property, and we provide justification for only regularizing locally, i.e., when the norm of the gradient falls below a certain threshold. We analyze bifurcations that may result from this form of regularization, and then we provide a selection rule for regularizers that depends only on the gradient of an objective function. This rule is shown to guarantee that gradient descent will escape the neighborhoods around a broad class of non-strict saddle points, and this behavior is demonstrated on numerical examples of non-strict saddle points common in the optimization literature.},
  archive   = {C_AAAI},
  author    = {Matthew Ubl and Matthew Hale and Kasra Yazdani},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26194},
  pages     = {10017-10024},
  title     = {Linear regularizers enforce the strict saddle property},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unbalanced CO-optimal transport. <em>AAAI</em>, 10006–10016.
(<a href="https://doi.org/10.1609/aaai.v37i8.26193">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Optimal transport (OT) compares probability distributions by computing a meaningful alignment between their samples. CO-optimal transport (COOT) takes this comparison further by inferring an alignment between features as well. While this approach leads to better alignments and generalizes both OT and Gromov-Wasserstein distances, we provide a theoretical result showing that it is sensitive to outliers that are omnipresent in real-world data. This prompts us to propose unbalanced COOT for which we provably show its robustness to noise in the compared datasets. To the best of our knowledge, this is the first such result for OT methods in incomparable spaces. With this result in hand, we provide empirical evidence of this robustness for the challenging tasks of heterogeneous domain adaptation with and without varying proportions of classes and simultaneous alignment of samples and features across two single-cell measurements.},
  archive   = {C_AAAI},
  author    = {Quang Huy Tran and Hicham Janati and Nicolas Courty and Rémi Flamary and Ievgen Redko and Pinar Demetci and Ritambhara Singh},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26193},
  pages     = {10006-10016},
  title     = {Unbalanced CO-optimal transport},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Heterogeneous graph masked autoencoders. <em>AAAI</em>,
9997–10005. (<a href="https://doi.org/10.1609/aaai.v37i8.26192">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Generative self-supervised learning (SSL), especially masked autoencoders, has become one of the most exciting learning paradigms and has shown great potential in handling graph data. However, real-world graphs are always heterogeneous, which poses three critical challenges that existing methods ignore: 1) how to capture complex graph structure? 2) how to incorporate various node attributes? and 3) how to encode different node positions? In light of this, we study the problem of generative SSL on heterogeneous graphs and propose HGMAE, a novel heterogeneous graph masked autoencoder model to address these challenges. HGMAE captures comprehensive graph information via two innovative masking techniques and three unique training strategies. In particular, we first develop metapath masking and adaptive attribute masking with dynamic mask rate to enable effective and stable learning on heterogeneous graphs. We then design several training strategies including metapath-based edge reconstruction to adopt complex structural information, target attribute restoration to incorporate various node attributes, and positional feature prediction to encode node positional information. Extensive experiments demonstrate that HGMAE outperforms both contrastive and generative state-of-the-art baselines on several tasks across multiple datasets. Codes are available at https://github.com/meettyj/HGMAE.},
  archive   = {C_AAAI},
  author    = {Yijun Tian and Kaiwen Dong and Chunhui Zhang and Chuxu Zhang and Nitesh V. Chawla},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26192},
  pages     = {9997-10005},
  title     = {Heterogeneous graph masked autoencoders},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Leveraging contaminated datasets to learn clean-data
distribution with purified generative adversarial networks.
<em>AAAI</em>, 9989–9996. (<a
href="https://doi.org/10.1609/aaai.v37i8.26191">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Generative adversarial networks (GANs) are known for their strong abilities on capturing the underlying distribution of training instances. Since the seminal work of GAN, many variants of GAN have been proposed. However, existing GANs are almost established on the assumption that the training dataset is clean. But in many real-world applications, this may not hold, that is, the training dataset may be contaminated by a proportion of undesired instances. When training on such datasets, existing GANs will learn a mixture distribution of desired and contaminated instances, rather than the desired distribution of desired data only (target distribution). To learn the target distribution from contaminated datasets, two purified generative adversarial networks (PuriGAN) are developed, in which the discriminators are augmented with the capability to distinguish between target and contaminated instances by leveraging an extra dataset solely composed of contamination instances. We prove that under some mild conditions, the proposed PuriGANs are guaranteed to converge to the distribution of desired instances. Experimental results on several datasets demonstrate that the proposed PuriGANs are able to generate much better images from the desired distribution than comparable baselines when trained on contaminated datasets. In addition, we also demonstrate the usefulness of PuriGAN on downstream applications by applying it to the tasks of semi-supervised anomaly detection on contaminated datasets and PU-learning. Experimental results show that PuriGAN is able to deliver the best performance over comparable baselines on both tasks.},
  archive   = {C_AAAI},
  author    = {Bowen Tian and Qinliang Su and Jianxing Yu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26191},
  pages     = {9989-9996},
  title     = {Leveraging contaminated datasets to learn clean-data distribution with purified generative adversarial networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Knowledge amalgamation for multi-label classification via
label dependency transfer. <em>AAAI</em>, 9980–9988. (<a
href="https://doi.org/10.1609/aaai.v37i8.26190">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-label classification (MLC), which assigns multiple labels to each instance, is crucial to domains from computer vision to text mining. Conventional methods for MLC require huge amounts of labeled data to capture complex dependencies between labels. However, such labeled datasets are expensive, or even impossible, to acquire. Worse yet, these pre-trained MLC models can only be used for the particular label set covered in the training data. Despite this severe limitation, few methods exist for expanding the set of labels predicted by pre-trained models. Instead, we acquire vast amounts of new labeled data and retrain a new model from scratch. Here, we propose combining the knowledge from multiple pre-trained models (teachers) to train a new student model that covers the union of the labels predicted by this set of teachers. This student supports a broader label set than any one of its teachers without using labeled data. We call this new problem knowledge amalgamation for multi-label classification. Our new method, Adaptive KNowledge Transfer (ANT), trains a student by learning from each teacher’s partial knowledge of label dependencies to infer the global dependencies between all labels across the teachers. We show that ANT succeeds in unifying label dependencies among teachers, outperforming five state-of-the-art methods on eight real-world datasets.},
  archive   = {C_AAAI},
  author    = {Jidapa Thadajarassiri and Thomas Hartvigsen and Walter Gerych and Xiangnan Kong and Elke Rundensteiner},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26190},
  pages     = {9980-9988},
  title     = {Knowledge amalgamation for multi-label classification via label dependency transfer},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DE-net: Dynamic text-guided image editing adversarial
networks. <em>AAAI</em>, 9971–9979. (<a
href="https://doi.org/10.1609/aaai.v37i8.26189">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Text-guided image editing models have shown remarkable results. However, there remain two problems. First, they employ fixed manipulation modules for various editing requirements (e.g., color changing, texture changing, content adding and removing), which results in over-editing or insufficient editing. Second, they do not clearly distinguish between text-required and text-irrelevant parts, which leads to inaccurate editing. To solve these limitations, we propose: (i) a Dynamic Editing Block (DEBlock) that composes different editing modules dynamically for various editing requirements. (ii) a Composition Predictor (Comp-Pred), which predicts the composition weights for DEBlock according to the inference on target texts and source images. (iii) a Dynamic text-adaptive Convolution Block (DCBlock) that queries source image features to distinguish text-required parts and text-irrelevant parts. Extensive experiments demonstrate that our DE-Net achieves excellent performance and manipulates source images more correctly and accurately.},
  archive   = {C_AAAI},
  author    = {Ming Tao and Bing-Kun Bao and Hao Tang and Fei Wu and Longhui Wei and Qi Tian},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26189},
  pages     = {9971-9979},
  title     = {DE-net: Dynamic text-guided image editing adversarial networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Metric multi-view graph clustering. <em>AAAI</em>,
9962–9970. (<a href="https://doi.org/10.1609/aaai.v37i8.26188">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph-based methods have hitherto been used to pursue the coherent patterns of data due to its ease of implementation and efficiency. These methods have been increasingly applied in multi-view learning and achieved promising performance in various clustering tasks. However, despite their noticeable empirical success, existing graph-based multi-view clustering methods may still suffer the suboptimal solution considering that multi-view data can be very complicated in raw feature space. Moreover, existing methods usually adopt the similarity metric by an ad hoc approach, which largely simplifies the relationship among real-world data and results in an inaccurate output. To address these issues, we propose to seamlessly integrates metric learning and graph learning for multi-view clustering. Specifically, we employ a useful metric to depict the inherent structure with linearity-aware of affinity graph representation learned based on the self-expressiveness property. Furthermore, instead of directly utilizing the raw features, we prefer to recover a smooth representation such that the geometric structure of the original data can be retained. We model the above concerns into a unified learning framework, and hence complements each learning subtask in a mutual reinforcement manner. The empirical studies corroborate our theoretical findings, and demonstrate that the proposed method is able to boost the multi-view clustering performance.},
  archive   = {C_AAAI},
  author    = {Yuze Tan and Yixi Liu and Hongjie Wu and Jiancheng Lv and Shudong Huang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26188},
  pages     = {9962-9970},
  title     = {Metric multi-view graph clustering},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Federated learning on non-IID graphs via structural
knowledge sharing. <em>AAAI</em>, 9953–9961. (<a
href="https://doi.org/10.1609/aaai.v37i8.26187">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph neural networks (GNNs) have shown their superiority in modeling graph data. Owing to the advantages of federated learning, federated graph learning (FGL) enables clients to train strong GNN models in a distributed manner without sharing their private data. A core challenge in federated systems is the non-IID problem, which also widely exists in real-world graph data. For example, local data of clients may come from diverse datasets or even domains, e.g., social networks and molecules, increasing the difficulty for FGL methods to capture commonly shared knowledge and learn a generalized encoder. From real-world graph datasets, we observe that some structural properties are shared by various domains, presenting great potential for sharing structural knowledge in FGL. Inspired by this, we propose FedStar, an FGL framework that extracts and shares the common underlying structure information for inter-graph federated learning tasks. To explicitly extract the structure information rather than encoding them along with the node features, we define structure embeddings and encode them with an independent structure encoder. Then, the structure encoder is shared across clients while the feature-based knowledge is learned in a personalized way, making FedStar capable of capturing more structure-based domain-invariant information and avoiding feature misalignment issues. We perform extensive experiments over both cross-dataset and cross-domain non-IID FGL settings, demonstrating the superiority of FedStar.},
  archive   = {C_AAAI},
  author    = {Yue Tan and Yixin Liu and Guodong Long and Jing Jiang and Qinghua Lu and Chengqi Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26187},
  pages     = {9953-9961},
  title     = {Federated learning on non-IID graphs via structural knowledge sharing},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fast convergence in learning two-layer neural networks with
separable data. <em>AAAI</em>, 9944–9952. (<a
href="https://doi.org/10.1609/aaai.v37i8.26186">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Normalized gradient descent has shown substantial success in speeding up the convergence of exponentially-tailed loss functions (which includes exponential and logistic losses) on linear classifiers with separable data. In this paper, we go beyond linear models by studying normalized GD on two-layer neural nets. We prove for exponentially-tailed losses that using normalized GD leads to linear rate of convergence of the training loss to the global optimum. This is made possible by showing certain gradient self-boundedness conditions and a log-Lipschitzness property. We also study generalization of normalized GD for convex objectives via an algorithmic-stability analysis. In particular, we show that normalized GD does not overfit during training by establishing finite-time generalization bounds.},
  archive   = {C_AAAI},
  author    = {Hossein Taheri and Christos Thrampoulidis},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26186},
  pages     = {9944-9952},
  title     = {Fast convergence in learning two-layer neural networks with separable data},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Domain adaptation with adversarial training on penultimate
activations. <em>AAAI</em>, 9935–9943. (<a
href="https://doi.org/10.1609/aaai.v37i8.26185">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Enhancing model prediction confidence on target data is an important objective in Unsupervised Domain Adaptation (UDA). In this paper, we explore adversarial training on penultimate activations, i.e., input features of the final linear classification layer. We show that this strategy is more efficient and better correlated with the objective of boosting prediction confidence than adversarial training on input images or intermediate features, as used in previous works. Furthermore, with activation normalization commonly used in domain adaptation to reduce domain gap, we derive two variants and systematically analyze the effects of normalization on our adversarial training. This is illustrated both in theory and through empirical analysis on real adaptation tasks. Extensive experiments are conducted on popular UDA benchmarks under both standard setting and source-data free setting. The results validate that our method achieves the best scores against previous arts. Code is available at https://github.com/tsun/APA.},
  archive   = {C_AAAI},
  author    = {Tao Sun and Cheng Lu and Haibin Ling},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26185},
  pages     = {9935-9943},
  title     = {Domain adaptation with adversarial training on penultimate activations},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural spline search for quantile probabilistic modeling.
<em>AAAI</em>, 9927–9934. (<a
href="https://doi.org/10.1609/aaai.v37i8.26184">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Accurate estimation of output quantiles is crucial in many use cases, where it is desired to model the range of possibility. Modeling target distribution at arbitrary quantile levels and at arbitrary input attribute levels are important to offer a comprehensive picture of the data, and requires the quantile function to be expressive enough. The quantile function describing the target distribution using quantile levels is critical for quantile regression. Although various parametric forms for the distributions (that the quantile function specifies) can be adopted, an everlasting problem is selecting the most appropriate one that can properly approximate the data distributions. In this paper, we propose a non-parametric and data-driven approach, Neural Spline Search (NSS), to represent the observed data distribution without parametric assumptions. NSS is flexible and expressive for modeling data distributions by transforming the inputs with a series of monotonic spline regressions guided by symbolic operators. We demonstrate that NSS outperforms previous methods on synthetic, real-world regression and time-series forecasting tasks.},
  archive   = {C_AAAI},
  author    = {Ruoxi Sun and Chun-Liang Li and Sercan Ö. Arik and Michael W. Dusenberry and Chen-Yu Lee and Tomas Pfister},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26184},
  pages     = {9927-9934},
  title     = {Neural spline search for quantile probabilistic modeling},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fair-CDA: Continuous and directional augmentation for group
fairness. <em>AAAI</em>, 9918–9926. (<a
href="https://doi.org/10.1609/aaai.v37i8.26183">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this work, we propose Fair-CDA, a fine-grained data augmentation strategy for imposing fairness constraints. We use a feature disentanglement method to extract the features highly related to the sensitive attributes. Then we show that group fairness can be achieved by regularizing the models on transition paths of sensitive features between groups. By adjusting the perturbation strength in the direction of the paths, our proposed augmentation is controllable and auditable. To alleviate the accuracy degradation caused by fairness constraints, we further introduce a calibrated model to impute labels for the augmented data. Our proposed method does not assume any data generative model and ensures good generalization for both accuracy and fairness. Experimental results show that Fair-CDA consistently outperforms state-of-the-art methods on widely-used benchmarks, e.g., Adult, CelebA and MovieLens. Especially, Fair-CDA obtains an 86.3\% relative improvement for fairness while maintaining the accuracy on the Adult dataset. Moreover, we evaluate Fair-CDA in an online recommendation system to demonstrate the effectiveness of our method in terms of accuracy and fairness.},
  archive   = {C_AAAI},
  author    = {Rui Sun and Fengwei Zhou and Zhenhua Dong and Chuanlong Xie and Lanqing Hong and Jiawei Li and Rui Zhang and Zhen Li and Zhenguo Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26183},
  pages     = {9918-9926},
  title     = {Fair-CDA: Continuous and directional augmentation for group fairness},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cooperative and adversarial learning: Co-enhancing
discriminability and transferability in domain adaptation.
<em>AAAI</em>, 9909–9917. (<a
href="https://doi.org/10.1609/aaai.v37i8.26182">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Discriminability and transferability are two goals of feature learning for domain adaptation (DA), as we aim to find the transferable features from the source domain that are helpful for discriminating the class label in the target domain. Modern DA approaches optimize discriminability and transferability by adopting two separate modules for the two goals upon a feature extractor, but lack fully exploiting their relationship. This paper argues that by letting the discriminative module and transfer module help each other, better DA can be achieved. We propose Cooperative and Adversarial LEarning (CALE) to combine the optimization of discriminability and transferability into a whole, provide one solution for making the discriminative module and transfer module guide each other. Specifically, CALE generates cooperative (easy) examples and adversarial (hard) examples with both discriminative module and transfer module. While the easy examples that contain the module knowledge can be used to enhance each other, the hard ones are used to enhance the robustness of the corresponding goal. Experimental results show the effectiveness of CALE for unifying the learning of discriminability and transferability, as well as its superior performance.},
  archive   = {C_AAAI},
  author    = {Hui Sun and Zheng Xie and Xin-Ye Li and Ming Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26182},
  pages     = {9909-9917},
  title     = {Cooperative and adversarial learning: Co-enhancing discriminability and transferability in domain adaptation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). REMIT: Reinforced multi-interest transfer for cross-domain
recommendation. <em>AAAI</em>, 9900–9908. (<a
href="https://doi.org/10.1609/aaai.v37i8.26181">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Cold-start problem is one of the most challenging problems for recommender systems. One promising solution to this problem is cross-domain recommendation (CDR) which leverages rich information from an auxiliary source domain to improve the performance of recommender system in the target domain. In particular, the family of embedding and mapping methods for CDR is very effective, which explicitly learn a mapping function from source embeddings to target embeddings to transfer user’s preferences. Recent works usually transfer an overall source embedding by modeling a common or personalized preference bridge for all users. However, a unified user embedding cannot reflect the user’s multiple interests in auxiliary source domain. In this paper, we propose a novel framework called reinforced multi-interest transfer for CDR (REMIT). Specifically, we first construct a heterogeneous information network and employ different meta-path based aggregations to get user’s multiple interests in source domain, then transform different interest embeddings with different meta-generated personalized bridge functions for each user. To better coordinate the transformed user interest embeddings and the item embedding in target domain, we systematically develop a reinforced method to dynamically assign weights to transformed interests for different training instances and optimize the performance of target model. In addition, the REMIT is a general framework that can be applied upon various base models in target domain. Our extensive experimental results on large real-world datasets demonstrate the superior performance and compatibility of REMIT.},
  archive   = {C_AAAI},
  author    = {Caiqi Sun and Jiewei Gu and Binbin Hu and Xin Dong and Hai Li and Lei Cheng and Linjian Mo},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26181},
  pages     = {9900-9908},
  title     = {REMIT: Reinforced multi-interest transfer for cross-domain recommendation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Scalable optimal multiway-split decision trees with
constraints. <em>AAAI</em>, 9891–9899. (<a
href="https://doi.org/10.1609/aaai.v37i8.26180">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {There has been a surge of interest in learning optimal decision trees using mixed-integer programs (MIP) in recent years, as heuristic-based methods do not guarantee optimality and find it challenging to incorporate constraints that are critical for many practical applications. However, existing MIP methods that build on an arc-based formulation do not scale well as the number of binary variables is in the order of 2 to the power of the depth of the tree and the size of the dataset. Moreover, they can only handle sample-level constraints and linear metrics. In this paper, we propose a novel path-based MIP formulation where the number of decision variables is independent of dataset size. We present a scalable column generation framework to solve the MIP. Our framework produces a multiway-split tree which is more interpretable than the typical binary-split trees due to its shorter rules. Our framework is more general as it can handle nonlinear metrics such as F1 score, and incorporate a broader class of constraints. We demonstrate its efficacy with extensive experiments. We present results on datasets containing up to 1,008,372 samples while existing MIP-based decision tree models do not scale well on data beyond a few thousand points. We report superior or competitive results compared to the state-of-art MIP-based methods with up to a 24X reduction in runtime.},
  archive   = {C_AAAI},
  author    = {Shivaram Subramanian and Wei Sun},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26180},
  pages     = {9891-9899},
  title     = {Scalable optimal multiway-split decision trees with constraints},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sharing pattern submodels for prediction with missing
values. <em>AAAI</em>, 9882–9890. (<a
href="https://doi.org/10.1609/aaai.v37i8.26179">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Missing values are unavoidable in many applications of machine learning and present challenges both during training and at test time. When variables are missing in recurring patterns, fitting separate pattern submodels have been proposed as a solution. However, fitting models independently does not make efficient use of all available data. Conversely, fitting a single shared model to the full data set relies on imputation which often leads to biased results when missingness depends on unobserved factors. We propose an alternative approach, called sharing pattern submodels (SPSM), which i) makes predictions that are robust to missing values at test time, ii) maintains or improves the predictive power of pattern submodels, and iii) has a short description, enabling improved interpretability. Parameter sharing is enforced through sparsity-inducing regularization which we prove leads to consistent estimation. Finally, we give conditions for when a sharing model is optimal, even when both missingness and the target outcome depend on unobserved variables. Classification and regression experiments on synthetic and real-world data sets demonstrate that our models achieve a favorable tradeoff between pattern specialization and information sharing.},
  archive   = {C_AAAI},
  author    = {Lena Stempfle and Ashkan Panahi and Fredrik D. Johansson},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26179},
  pages     = {9882-9890},
  title     = {Sharing pattern submodels for prediction with missing values},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mixture manifold networks: A computationally efficient
baseline for inverse modeling. <em>AAAI</em>, 9874–9881. (<a
href="https://doi.org/10.1609/aaai.v37i8.26178">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose and show the efficacy of a new method to address generic inverse problems. Inverse modeling is the task whereby one seeks to determine the hidden parameters of a natural system that produce a given set of observed measurements. Recent work has shown impressive results using deep learning, but we note that there is a trade-off between model performance and computational time. For some applications, the computational time at inference for the best performing inverse modeling method may be overly prohibitive to its use. In seeking a faster, high-performing model, we present a new method that leverages multiple manifolds as a mixture of backward (e.g., inverse) models in a forward-backward model architecture. These multiple backwards models all share a common forward model, and their training is mitigated by generating training examples from the forward model. The proposed method thus has two innovations: 1) the multiple Manifold Mixture Network (MMN) architecture, and 2) the training procedure involving augmenting backward model training data using the forward model. We demonstrate the advantages of our method by comparing to several baselines on four benchmark inverse problems, and we furthermore provide analysis to motivate its design.},
  archive   = {C_AAAI},
  author    = {Gregory P. Spell and Simiao Ren and Leslie M. Collins and Jordan M. Malof},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26178},
  pages     = {9874-9881},
  title     = {Mixture manifold networks: A computationally efficient baseline for inverse modeling},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Securing secure aggregation: Mitigating multi-round privacy
leakage in federated learning. <em>AAAI</em>, 9864–9873. (<a
href="https://doi.org/10.1609/aaai.v37i8.26177">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Secure aggregation is a critical component in federated learning (FL), which enables the server to learn the aggregate model of the users without observing their local models. Conventionally, secure aggregation algorithms focus only on ensuring the privacy of individual users in a single training round. We contend that such designs can lead to significant privacy leakages over multiple training rounds, due to partial user selection/participation at each round of FL. In fact, we show that the conventional random user selection strategies in FL lead to leaking users&#39; individual models within number of rounds that is linear in the number of users. To address this challenge, we introduce a secure aggregation framework, Multi-RoundSecAgg, with multi-round privacy guarantees. In particular, we introduce a new metric to quantify the privacy guarantees of FL over multiple training rounds, and develop a structured user selection strategy that guarantees the long-term privacy of each user (over any number of training rounds). Our framework also carefully accounts for the fairness and the average number of participating users at each round. Our experiments on MNIST, CIFAR-10 and CIFAR-100 datasets in the IID and the non-IID settings demonstrate the performance improvement over the baselines, both in terms of privacy protection and test accuracy.},
  archive   = {C_AAAI},
  author    = {Jinhyun So and Ramy E. Ali and Başak Güler and Jiantao Jiao and A. Salman Avestimehr},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26177},
  pages     = {9864-9873},
  title     = {Securing secure aggregation: Mitigating multi-round privacy leakage in federated learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive mixing of auxiliary losses in supervised learning.
<em>AAAI</em>, 9855–9863. (<a
href="https://doi.org/10.1609/aaai.v37i8.26176">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In many supervised learning scenarios, auxiliary losses are used in order to introduce additional information or constraints into the supervised learning objective. For instance, knowledge distillation aims to mimic outputs of a powerful teacher model; similarly, in rule-based approaches, weak labeling information is provided by labeling functions which may be noisy rule-based approximations to true labels. We tackle the problem of learning to combine these losses in a principled manner. Our proposal, AMAL, uses a bi-level optimization criterion on validation data to learn optimal mixing weights, at an instance-level, over the training data. We describe a meta-learning approach towards solving this bi-level objective, and show how it can be applied to different scenarios in supervised learning. Experiments in a number of knowledge distillation and rule denoising domains show that AMAL provides noticeable gains over competitive baselines in those domains. We empirically analyze our method and share insights into the mechanisms through which it provides performance gains. The code for AMAL is at: https://github.com/durgas16/AMAL.git.},
  archive   = {C_AAAI},
  author    = {Durga Sivasubramanian and Ayush Maheshwari and Prathosh AP and Pradeep Shenoy and Ganesh Ramakrishnan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26176},
  pages     = {9855-9863},
  title     = {Adaptive mixing of auxiliary losses in supervised learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SLIQ: Quantum image similarity networks on noisy quantum
computers. <em>AAAI</em>, 9846–9854. (<a
href="https://doi.org/10.1609/aaai.v37i8.26175">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Exploration into quantum machine learning has grown tremendously in recent years due to the ability of quantum computers to speed up classical programs. However, these ef- forts have yet to solve unsupervised similarity detection tasks due to the challenge of porting them to run on quantum com- puters. To overcome this challenge, we propose SLIQ, the first open-sourced work for resource-efficient quantum sim- ilarity detection networks, built with practical and effective quantum learning and variance-reducing algorithms.},
  archive   = {C_AAAI},
  author    = {Daniel Silver and Tirthak Patel and Aditya Ranjan and Harshitta Gandhi and William Cutler and Devesh Tiwari},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26175},
  pages     = {9846-9854},
  title     = {SLIQ: Quantum image similarity networks on noisy quantum computers},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Logical satisfiability of counterfactuals for faithful
explanations in NLI. <em>AAAI</em>, 9837–9845. (<a
href="https://doi.org/10.1609/aaai.v37i8.26174">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Evaluating an explanation&#39;s faithfulness is desired for many reasons such as trust, interpretability and diagnosing the sources of model&#39;s errors. In this work, which focuses on the NLI task, we introduce the methodology of Faithfulness-through-Counterfactuals, which first generates a counterfactual hypothesis based on the logical predicates expressed in the explanation, and then evaluates if the model&#39;s prediction on the counterfactual is consistent with that expressed logic (i.e. if the new formula is \textit{logically satisfiable}). In contrast to existing approaches, this does not require any explanations for training a separate verification model. We first validate the efficacy of automatic counterfactual hypothesis generation, leveraging on the few-shot priming paradigm. Next, we show that our proposed metric distinguishes between human-model agreement and disagreement on new counterfactual input. In addition, we conduct a sensitivity analysis to validate that our metric is sensitive to unfaithful explanations.},
  archive   = {C_AAAI},
  author    = {Suzanna Sia and Anton Belyy and Amjad Almahairi and Madian Khabsa and Luke Zettlemoyer and Lambert Mathias},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26174},
  pages     = {9837-9845},
  title     = {Logical satisfiability of counterfactuals for faithful explanations in NLI},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A generalized unbiased risk estimator for learning with
augmented classes. <em>AAAI</em>, 9829–9836. (<a
href="https://doi.org/10.1609/aaai.v37i8.26173">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In contrast to the standard learning paradigm where all classes can be observed in training data, learning with augmented classes (LAC) tackles the problem where augmented classes unobserved in the training data may emerge in the test phase. Previous research showed that given unlabeled data, an unbiased risk estimator (URE) can be derived, which can be minimized for LAC with theoretical guarantees. However, this URE is only restricted to the specific type of one-versus-rest loss functions for multi-class classification, making it not flexible enough when the loss needs to be changed with the dataset in practice. In this paper, we propose a generalized URE that can be equipped with arbitrary loss functions while maintaining the theoretical guarantees, given unlabeled data for LAC. To alleviate the issue of negative empirical risk commonly encountered by previous studies, we further propose a novel risk-penalty regularization term. Experiments demonstrate the effectiveness of our proposed method.},
  archive   = {C_AAAI},
  author    = {Senlin Shu and Shuo He and Haobo Wang and Hongxin Wei and Tao Xiang and Lei Feng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26173},
  pages     = {9829-9836},
  title     = {A generalized unbiased risk estimator for learning with augmented classes},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Concurrent multi-label prediction in event streams.
<em>AAAI</em>, 9820–9828. (<a
href="https://doi.org/10.1609/aaai.v37i8.26172">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Streams of irregularly occurring events are commonly modeled as a marked temporal point process. Many real-world datasets such as e-commerce transactions and electronic health records often involve events where multiple event types co-occur, e.g. multiple items purchased or multiple diseases diagnosed simultaneously. In this paper, we tackle multi-label prediction in such a problem setting, and propose a novel Transformer-based Conditional Mixture of Bernoulli Network (TCMBN) that leverages neural density estimation to capture complex temporal dependence as well as probabilistic dependence between concurrent event types. We also propose potentially incorporating domain knowledge in the objective by regularizing the predicted probability. To represent probabilistic dependence of concurrent event types graphically, we design a two-step approach that first learns the mixture of Bernoulli network and then solves a least-squares semi-definite constrained program to numerically approximate the sparse precision matrix from a learned covariance matrix. This approach proves to be effective for event prediction while also providing an interpretable and possibly non-stationary structure for insights into event co-occurrence. We demonstrate the superior performance of our approach compared to existing baselines on multiple synthetic and real benchmarks.},
  archive   = {C_AAAI},
  author    = {Xiao Shou and Tian Gao and Dharmashankar Subramanian and Debarun Bhattacharjya and Kristin P. Bennett},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26172},
  pages     = {9820-9828},
  title     = {Concurrent multi-label prediction in event streams},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fixed-weight difference target propagation. <em>AAAI</em>,
9811–9819. (<a href="https://doi.org/10.1609/aaai.v37i8.26171">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Target Propagation (TP) is a biologically more plausible algorithm than the error backpropagation (BP) to train deep networks, and improving practicality of TP is an open issue. TP methods require the feedforward and feedback networks to form layer-wise autoencoders for propagating the target values generated at the output layer. However, this causes certain drawbacks; e.g., careful hyperparameter tuning is required to synchronize the feedforward and feedback training, and frequent updates of the feedback path are usually required than that of the feedforward path. Learning of the feedforward and feedback networks is sufficient to make TP methods capable of training, but is having these layer-wise autoencoders a necessary condition for TP to work? We answer this question by presenting Fixed-Weight Difference Target Propagation (FW-DTP) that keeps the feedback weights constant during training. We confirmed that this simple method, which naturally resolves the abovementioned problems of TP, can still deliver informative target values to hidden layers for a given task; indeed, FW-DTP consistently achieves higher test performance than a baseline, the Difference Target Propagation (DTP), on four classification datasets. We also present a novel propagation architecture that explains the exact form of the feedback function of DTP to analyze FW-DTP. Our code is available at https://github.com/TatsukichiShibuya/Fixed-Weight-Difference-Target-Propagation.},
  archive   = {C_AAAI},
  author    = {Tatsukichi Shibuya and Nakamasa Inoue and Rei Kawakami and Ikuro Sato},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26171},
  pages     = {9811-9819},
  title     = {Fixed-weight difference target propagation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Contrastive predictive autoencoders for dynamic point cloud
self-supervised learning. <em>AAAI</em>, 9802–9810. (<a
href="https://doi.org/10.1609/aaai.v37i8.26170">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present a new self-supervised paradigm on point cloud sequence understanding. Inspired by the discriminative and generative self-supervised methods, we design two tasks, namely point cloud sequence based Contrastive Prediction and Reconstruction (CPR), to collaboratively learn more comprehensive spatiotemporal representations. Specifically, dense point cloud segments are first input into an encoder to extract embeddings. All but the last ones are then aggregated by a context-aware autoregressor to make predictions for the last target segment. Towards the goal of modeling multi-granularity structures, local and global contrastive learning are performed between predictions and targets. To further improve the generalization of representations, the predictions are also utilized to reconstruct raw point cloud sequences by a decoder, where point cloud colorization is employed to discriminate against different frames. By combining classic contrast and reconstruction paradigms, it makes the learned representations with both global discrimination and local perception. We conduct experiments on four point cloud sequence benchmarks, and report the results on action recognition and gesture recognition under multiple experimental settings. The performances are comparable with supervised methods and show powerful transferability.},
  archive   = {C_AAAI},
  author    = {Xiaoxiao Sheng and Zhiqiang Shen and Gang Xiao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26170},
  pages     = {9802-9810},
  title     = {Contrastive predictive autoencoders for dynamic point cloud self-supervised learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ProxyBO: Accelerating neural architecture search via
bayesian optimization with zero-cost proxies. <em>AAAI</em>, 9792–9801.
(<a href="https://doi.org/10.1609/aaai.v37i8.26169">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Designing neural architectures requires immense manual efforts. This has promoted the development of neural architecture search (NAS) to automate the design. While previous NAS methods achieve promising results but run slowly, zero-cost proxies run extremely fast but are less promising. Therefore, it’s of great potential to accelerate NAS via those zero-cost proxies. The existing method has two limitations, which are unforeseeable reliability and one-shot usage. To address the limitations, we present ProxyBO, an efficient Bayesian optimization (BO) framework that utilizes the zero-cost proxies to accelerate neural architecture search. We apply the generalization ability measurement to estimate the fitness of proxies on the task during each iteration and design a novel acquisition function to combine BO with zero-cost proxies based on their dynamic influence. Extensive empirical studies show that ProxyBO consistently outperforms competitive baselines on five tasks from three public benchmarks. Concretely, ProxyBO achieves up to 5.41× and 3.86× speedups over the state-of-the-art approaches REA and BRP-NAS.},
  archive   = {C_AAAI},
  author    = {Yu Shen and Yang Li and Jian Zheng and Wentao Zhang and Peng Yao and Jixiang Li and Sen Yang and Ji Liu and Bin Cui},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26169},
  pages     = {9792-9801},
  title     = {ProxyBO: Accelerating neural architecture search via bayesian optimization with zero-cost proxies},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neighbor contrastive learning on learnable graph
augmentation. <em>AAAI</em>, 9782–9791. (<a
href="https://doi.org/10.1609/aaai.v37i8.26168">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent years, graph contrastive learning (GCL), which aims to learn representations from unlabeled graphs, has made great progress. However, the existing GCL methods mostly adopt human-designed graph augmentations, which are sensitive to various graph datasets. In addition, the contrastive losses originally developed in computer vision have been directly applied to graph data, where the neighboring nodes are regarded as negatives and consequently pushed far apart from the anchor. However, this is contradictory with the homophily assumption of net-works that connected nodes often belong to the same class and should be close to each other. In this work, we propose an end-to-end automatic GCL method, named NCLA to apply neighbor contrastive learning on learnable graph augmentation. Several graph augmented views with adaptive topology are automatically learned by the multi-head graph attention mechanism, which can be compatible with various graph datasets without prior domain knowledge. In addition, a neighbor contrastive loss is devised to allow multiple positives per anchor by taking network topology as the supervised signals. Both augmentations and embeddings are learned end-to-end in the proposed NCLA. Extensive experiments on the benchmark datasets demonstrate that NCLA yields the state-of-the-art node classification performance on self-supervised GCL and even exceeds the supervised ones, when the labels are extremely limited. Our code is released at https://github.com/shenxiaocam/NCLA.},
  archive   = {C_AAAI},
  author    = {Xiao Shen and Dewang Sun and Shirui Pan and Xi Zhou and Laurence T. Yang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26168},
  pages     = {9782-9791},
  title     = {Neighbor contrastive learning on learnable graph augmentation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Post-hoc uncertainty learning using a dirichlet meta-model.
<em>AAAI</em>, 9772–9781. (<a
href="https://doi.org/10.1609/aaai.v37i8.26167">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {It is known that neural networks have the problem of being over-confident when directly using the output label distribution to generate uncertainty measures. Existing methods mainly resolve this issue by retraining the entire model to impose the uncertainty quantification capability so that the learned model can achieve desired performance in accuracy and uncertainty prediction simultaneously. However, training the model from scratch is computationally expensive, and a trade-off might exist between prediction accuracy and uncertainty quantification. To this end, we consider a more practical post-hoc uncertainty learning setting, where a well-trained base model is given, and we focus on the uncertainty quantification task at the second stage of training. We propose a novel Bayesian uncertainty learning approach using the Dirichlet meta-model, which is effective and computationally efficient. Our proposed method requires no additional training data and is flexible enough to quantify different uncertainties and easily adapt to different application settings, including out-of-domain data detection, misclassification detection, and trustworthy transfer learning. Finally, we demonstrate our proposed meta-model approach&#39;s flexibility and superior empirical performance on these applications over multiple representative image classification benchmarks.},
  archive   = {C_AAAI},
  author    = {Maohao Shen and Yuheng Bu and Prasanna Sattigeri and Soumya Ghosh and Subhro Das and Gregory Wornell},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26167},
  pages     = {9772-9781},
  title     = {Post-hoc uncertainty learning using a dirichlet meta-model},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). What do you MEME? Generating explanations for visual
semantic role labelling in memes. <em>AAAI</em>, 9763–9771. (<a
href="https://doi.org/10.1609/aaai.v37i8.26166">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Memes are powerful means for effective communication on social media. Their effortless amalgamation of viral visuals and compelling messages can have far-reaching implications with proper marketing. Previous research on memes has primarily focused on characterizing their affective spectrum and detecting whether the meme&#39;s message insinuates any intended harm, such as hate, offense, racism, etc. However, memes often use abstraction, which can be elusive. Here, we introduce a novel task - EXCLAIM, generating explanations for visual semantic role labeling in memes. To this end, we curate ExHVV, a novel dataset that offers natural language explanations of connotative roles for three types of entities - heroes, villains, and victims, encompassing 4,680 entities present in 3K memes. We also benchmark ExHVV with several strong unimodal and multimodal baselines. Moreover, we posit LUMEN, a novel multimodal, multi-task learning framework that endeavors to address EXCLAIM optimally by jointly learning to predict the correct semantic roles and correspondingly to generate suitable natural language explanations. LUMEN distinctly outperforms the best baseline across 18 standard natural language generation evaluation metrics. Our systematic evaluation and analyses demonstrate that characteristic multimodal cues required for adjudicating semantic roles are also helpful for generating suitable explanations.},
  archive   = {C_AAAI},
  author    = {Shivam Sharma and Siddhant Agarwal and Tharun Suresh and Preslav Nakov and Md. Shad Akhtar and Tanmoy Chakraborty},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26166},
  pages     = {9763-9771},
  title     = {What do you MEME? generating explanations for visual semantic role labelling in memes},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-source survival domain adaptation. <em>AAAI</em>,
9752–9762. (<a href="https://doi.org/10.1609/aaai.v37i8.26165">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Survival analysis is the branch of statistics that studies the relation between the characteristics of living entities and their respective survival times, taking into account the partial information held by censored cases. A good analysis can, for example, determine whether one medical treatment for a group of patients is better than another. With the rise of machine learning, survival analysis can be modeled as learning a function that maps studied patients to their survival times. To succeed with that, there are three crucial issues to be tackled. First, some patient data is censored: we do not know the true survival times for all patients. Second, data is scarce, which led past research to treat different illness types as domains in a multi-task setup. Third, there is the need for adaptation to new or extremely rare illness types, where little or no labels are available. In contrast to previous multi-task setups, we want to investigate how to efficiently adapt to a new survival target domain from multiple survival source domains. For this, we introduce a new survival metric and the corresponding discrepancy measure between survival distributions. These allow us to define domain adaptation for survival analysis while incorporating censored data, which would otherwise have to be dropped. Our experiments on two cancer data sets reveal a superb performance on target domains, a better treatment recommendation, and a weight matrix with a plausible explanation.},
  archive   = {C_AAAI},
  author    = {Ammar Shaker and Carolin Lawrence},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26165},
  pages     = {9752-9762},
  title     = {Multi-source survival domain adaptation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploration via epistemic value estimation. <em>AAAI</em>,
9742–9751. (<a href="https://doi.org/10.1609/aaai.v37i8.26164">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {How to efficiently explore in reinforcement learning is an open problem. Many exploration algorithms employ the epistemic uncertainty of their own value predictions -- for instance to compute an exploration bonus or upper confidence bound. Unfortunately the required uncertainty is difficult to estimate in general with function approximation. We propose epistemic value estimation (EVE): a recipe that is compatible with sequential decision making and with neural network function approximators. It equips agents with a tractable posterior over all their parameters from which epistemic value uncertainty can be computed efficiently. We use the recipe to derive an epistemic Q-Learning agent and observe competitive performance on a series of benchmarks. Experiments confirm that the EVE recipe facilitates efficient exploration in hard exploration tasks.},
  archive   = {C_AAAI},
  author    = {Simon Schmitt and John Shawe-Taylor and Hado van Hasselt},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26164},
  pages     = {9742-9751},
  title     = {Exploration via epistemic value estimation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dropout is NOT all you need to prevent gradient leakage.
<em>AAAI</em>, 9733–9741. (<a
href="https://doi.org/10.1609/aaai.v37i8.26163">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Gradient inversion attacks on federated learning systems reconstruct client training data from exchanged gradient information. To defend against such attacks, a variety of defense mechanisms were proposed. However, they usually lead to an unacceptable trade-off between privacy and model utility. Recent observations suggest that dropout could mitigate gradient leakage and improve model utility if added to neural networks. Unfortunately, this phenomenon has not been systematically researched yet. In this work, we thoroughly analyze the effect of dropout on iterative gradient inversion attacks. We find that state of the art attacks are not able to reconstruct the client data due to the stochasticity induced by dropout during model training. Nonetheless, we argue that dropout does not offer reliable protection if the dropout induced stochasticity is adequately modeled during attack optimization. Consequently, we propose a novel Dropout Inversion Attack (DIA) that jointly optimizes for client data and dropout masks to approximate the stochastic client model. We conduct an extensive systematic evaluation of our attack on four seminal model architectures and three image classification datasets of increasing complexity. We find that our proposed attack bypasses the protection seemingly induced by dropout and reconstructs client data with high fidelity. Our work demonstrates that privacy inducing changes to model architectures alone cannot be assumed to reliably protect from gradient leakage and therefore should be combined with complementary defense mechanisms.},
  archive   = {C_AAAI},
  author    = {Daniel Scheliga and Patrick Maeder and Marco Seeland},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26163},
  pages     = {9733-9741},
  title     = {Dropout is NOT all you need to prevent gradient leakage},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-supervised audio-visual representation learning with
relaxed cross-modal synchronicity. <em>AAAI</em>, 9723–9732. (<a
href="https://doi.org/10.1609/aaai.v37i8.26162">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present CrissCross, a self-supervised framework for learning audio-visual representations. A novel notion is introduced in our framework whereby in addition to learning the intra-modal and standard &#39;synchronous&#39; cross-modal relations, CrissCross also learns &#39;asynchronous&#39; cross-modal relationships. We perform in-depth studies showing that by relaxing the temporal synchronicity between the audio and visual modalities, the network learns strong generalized representations useful for a variety of downstream tasks. To pretrain our proposed solution, we use 3 different datasets with varying sizes, Kinetics-Sound, Kinetics400, and AudioSet. The learned representations are evaluated on a number of downstream tasks namely action recognition, sound classification, and action retrieval. Our experiments show that CrissCross either outperforms or achieves performances on par with the current state-of-the-art self-supervised methods on action recognition and action retrieval with UCF101 and HMDB51, as well as sound classification with ESC50 and DCASE. Moreover, CrissCross outperforms fully-supervised pretraining while pretrained on Kinetics-Sound.},
  archive   = {C_AAAI},
  author    = {Pritam Sarkar and Ali Etemad},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26162},
  pages     = {9723-9732},
  title     = {Self-supervised audio-visual representation learning with relaxed cross-modal synchronicity},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sparse coding in a dual memory system for lifelong learning.
<em>AAAI</em>, 9714–9722. (<a
href="https://doi.org/10.1609/aaai.v37i8.26161">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Efficient continual learning in humans is enabled by a rich set of neurophysiological mechanisms and interactions between multiple memory systems. The brain efficiently encodes information in non-overlapping sparse codes, which facilitates the learning of new associations faster with controlled interference with previous associations. To mimic sparse coding in DNNs, we enforce activation sparsity along with a dropout mechanism which encourages the model to activate similar units for semantically similar inputs and have less overlap with activation patterns of semantically dissimilar inputs. This provides us with an efficient mechanism for balancing the reusability and interference of features, depending on the similarity of classes across tasks. Furthermore, we employ sparse coding in a multiple-memory replay mechanism. Our method maintains an additional long-term semantic memory that aggregates and consolidates information encoded in the synaptic weights of the working model. Our extensive evaluation and characteristics analysis show that equipped with these biologically inspired mechanisms, the model can further mitigate forgetting. Code available at \url{https://github.com/NeurAI-Lab/SCoMMER}.},
  archive   = {C_AAAI},
  author    = {Fahad Sarfraz and Elahe Arani and Bahram Zonooz},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26161},
  pages     = {9714-9722},
  title     = {Sparse coding in a dual memory system for lifelong learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Representation learning by detecting incorrect location
embeddings. <em>AAAI</em>, 9704–9713. (<a
href="https://doi.org/10.1609/aaai.v37i8.26160">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we introduce a novel self-supervised learning (SSL) loss for image representation learning. There is a growing belief that generalization in deep neural networks is linked to their ability to discriminate object shapes. Since object shape is related to the location of its parts, we propose to detect those that have been artificially misplaced. We represent object parts with image tokens and train a ViT to detect which token has been combined with an incorrect positional embedding. We then introduce sparsity in the inputs to make the model more robust to occlusions and to speed up the training. We call our method DILEMMA, which stands for Detection of Incorrect Location EMbeddings with MAsked inputs. We apply DILEMMA to MoCoV3, DINO and SimCLR and show an improvement in their performance of respectively 4.41\%, 3.97\%, and 0.5\% under the same training time and with a linear probing transfer on ImageNet-1K. We also show full fine-tuning improvements of MAE combined with our method on ImageNet-100. We evaluate our method via fine-tuning on common SSL benchmarks. Moreover, we show that when downstream tasks are strongly reliant on shape (such as in the YOGA-82 pose dataset), our pre-trained features yield a significant gain over prior work.},
  archive   = {C_AAAI},
  author    = {Sepehr Sameni and Simon Jenni and Paolo Favaro},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26160},
  pages     = {9704-9713},
  title     = {Representation learning by detecting incorrect location embeddings},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Losses over labels: Weakly supervised learning via direct
loss construction. <em>AAAI</em>, 9695–9703. (<a
href="https://doi.org/10.1609/aaai.v37i8.26159">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Owing to the prohibitive costs of generating large amounts of labeled data, programmatic weak supervision is a growing paradigm within machine learning. In this setting, users design heuristics that provide noisy labels for subsets of the data. These weak labels are combined (typically via a graphical model) to form pseudolabels, which are then used to train a downstream model. In this work, we question a foundational premise of the typical weakly supervised learning pipeline: given that the heuristic provides all “label” information, why do we need to generate pseudolabels at all? Instead, we propose to directly transform the heuristics themselves into corresponding loss functions that penalize differences between our model and the heuristic. By constructing losses directly from the heuristics, we can incorporate more information than is used in the standard weakly supervised pipeline, such as how the heuristics make their decisions, which explicitly informs feature selection during training. We call our method Losses over Labels (LoL) as it creates losses directly from heuristics without going through the intermediate step of a label. We show that LoL improves upon existing weak supervision methods on several benchmark text and image classification tasks and further demonstrate that incorporating gradient information leads to better performance on almost every task.},
  archive   = {C_AAAI},
  author    = {Dylan Sam and J. Zico Kolter},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26159},
  pages     = {9695-9703},
  title     = {Losses over labels: Weakly supervised learning via direct loss construction},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fast offline policy optimization for large scale
recommendation. <em>AAAI</em>, 9686–9694. (<a
href="https://doi.org/10.1609/aaai.v37i8.26158">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Personalised interactive systems such as recommender systems require selecting relevant items from massive catalogs dependent on context. Reward-driven offline optimisation of these systems can be achieved by a relaxation of the discrete problem resulting in policy learning or REINFORCE style learning algorithms. Unfortunately, this relaxation step requires computing a sum over the entire catalogue making the complexity of the evaluation of the gradient (and hence each stochastic gradient descent iterations) linear in the catalogue size. This calculation is untenable in many real world examples such as large catalogue recommender systems, severely limiting the usefulness of this method in practice. In this paper, we derive an approximation of these policy learning algorithms that scale logarithmically with the catalogue size. Our contribution is based upon combining three novel ideas: a new Monte Carlo estimate of the gradient of a policy, the self normalised importance sampling estimator and the use of fast maximum inner product search at training time. Extensive experiments show that our algorithm is an order of magnitude faster than naive approaches yet produces equally good policies.},
  archive   = {C_AAAI},
  author    = {Otmane Sakhi and David Rohde and Alexandre Gilotte},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26158},
  pages     = {9686-9694},
  title     = {Fast offline policy optimization for large scale recommendation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Continual learning with scaled gradient projection.
<em>AAAI</em>, 9677–9685. (<a
href="https://doi.org/10.1609/aaai.v37i8.26157">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In neural networks, continual learning results in gradient interference among sequential tasks, leading to catastrophic forgetting of old tasks while learning new ones. This issue is addressed in recent methods by storing the important gradient spaces for old tasks and updating the model orthogonally during new tasks. However, such restrictive orthogonal gradient updates hamper the learning capability of the new tasks resulting in sub-optimal performance. To improve new learning while minimizing forgetting, in this paper we propose a Scaled Gradient Projection (SGP) method, where we combine the orthogonal gradient projections with scaled gradient steps along the important gradient spaces for the past tasks. The degree of gradient scaling along these spaces depends on the importance of the bases spanning them. We propose an efficient method for computing and accumulating importance of these bases using the singular value decomposition of the input representations for each task. We conduct extensive experiments ranging from continual image classification to reinforcement learning tasks and report better performance with less training overhead than the state-of-the-art approaches.},
  archive   = {C_AAAI},
  author    = {Gobinda Saha and Kaushik Roy},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26157},
  pages     = {9677-9685},
  title     = {Continual learning with scaled gradient projection},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Simultaneously updating all persistence values in
reinforcement learning. <em>AAAI</em>, 9668–9676. (<a
href="https://doi.org/10.1609/aaai.v37i8.26156">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In Reinforcement Learning, the performance of learning agents is highly sensitive to the choice of time discretization. Agents acting at high frequencies have the best control opportunities, along with some drawbacks, such as possible inefficient exploration and vanishing of the action advantages. The repetition of the actions, i.e., action persistence, comes into help, as it allows the agent to visit wider regions of the state space and improve the estimation of the action effects. In this work, we derive a novel operator, the All-Persistence Bellman Operator, which allows an effective use of both the low-persistence experience, by decomposition into sub-transition, and the high-persistence experience, thanks to the introduction of a suitable bootstrap procedure. In this way, we employ transitions collected at any time scale to update simultaneously the action values of the considered persistence set. We prove the contraction property of the All-Persistence Bellman Operator and, based on it, we extend classic Q-learning and DQN. After providing a study on the effects of persistence, we experimentally evaluate our approach in both tabular contexts and more challenging frameworks, including some Atari games.},
  archive   = {C_AAAI},
  author    = {Luca Sabbioni and Luca Al Daire and Lorenzo Bisi and Alberto Maria Metelli and Marcello Restelli},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26156},
  pages     = {9668-9676},
  title     = {Simultaneously updating all persistence values in reinforcement learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the sample complexity of representation learning in
multi-task bandits with global and local structure. <em>AAAI</em>,
9658–9667. (<a href="https://doi.org/10.1609/aaai.v37i8.26155">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We investigate the sample complexity of learning the optimal arm for multi-task bandit problems. Arms consist of two components: one that is shared across tasks (that we call representation) and one that is task-specific (that we call predictor). The objective is to learn the optimal (representation, predictor)-pair for each task, under the assumption that the optimal representation is common to all tasks. Within this framework, efficient learning algorithms should transfer knowledge across tasks. We consider the best-arm identification problem with fixed confidence, where, in each round, the learner actively selects both a task, and an arm, and observes the corresponding reward. We derive instance-specific sample complexity lower bounds, which apply to any algorithm that identifies the best representation, and the best predictor for a task, with prescribed confidence levels. We devise an algorithm, OSRL-SC, that can learn the optimal representation, and the optimal predictors, separately, and whose sample complexity approaches the lower bound. Theoretical and numerical results demonstrate that OSRL-SC achieves a better scaling with respect to the number of tasks compared to the classical best-arm identification algorithm. The code can be found here https://github.com/rssalessio/OSRL-SC.},
  archive   = {C_AAAI},
  author    = {Alessio Russo and Alexandre Proutiere},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26155},
  pages     = {9658-9667},
  title     = {On the sample complexity of representation learning in multi-task bandits with global and local structure},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Forecasting with sparse but informative variables: A case
study in predicting blood glucose. <em>AAAI</em>, 9650–9657. (<a
href="https://doi.org/10.1609/aaai.v37i8.26154">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In time-series forecasting, future target values may be affected by both intrinsic and extrinsic effects. When forecasting blood glucose, for example, intrinsic effects can be inferred from the history of the target signal alone (i.e. blood glucose), but accurately modeling the impact of extrinsic effects requires auxiliary signals, like the amount of carbohydrates ingested. Standard forecasting techniques often assume that extrinsic and intrinsic effects vary at similar rates. However, when auxiliary signals are generated at a much lower frequency than the target variable (e.g., blood glucose measurements are made every 5 minutes, while meals occur once every few hours), even well-known extrinsic effects (e.g., carbohydrates increase blood glucose) may prove difficult to learn. To better utilize these sparse but informative variables (SIVs), we introduce a novel encoder/decoder forecasting approach that accurately learns the per-timepoint effect of the SIV, by (i) isolating it from intrinsic effects and (ii) restricting its learned effect based on domain knowledge. On a simulated dataset pertaining to the task of blood glucose forecasting, when the SIV is accurately recorded our approach outperforms baseline approaches in terms of rMSE (13.07 [95\% CI: 11.77,14.16] vs. 14.14 [12.69,15.27]). In the presence of a corrupted SIV, the proposed approach can still result in lower error compared to the baseline but the advantage is reduced as noise increases. By isolating their effects and incorporating domain knowledge, our approach makes it possible to better utilize SIVs in forecasting.},
  archive   = {C_AAAI},
  author    = {Harry Rubin-Falcone and Joyce Lee and Jenna Wiens},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26154},
  pages     = {9650-9657},
  title     = {Forecasting with sparse but informative variables: A case study in predicting blood glucose},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Accommodating audio modality in CLIP for multimodal
processing. <em>AAAI</em>, 9641–9649. (<a
href="https://doi.org/10.1609/aaai.v37i8.26153">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multimodal processing has attracted much attention lately especially with the success of pre-training. However, the exploration has mainly focused on vision-language pre-training, as introducing more modalities can greatly complicate model design and optimization. In this paper, we extend the state-of-the-art Vision-Language model CLIP to accommodate the audio modality for Vision-Language-Audio multimodal processing. Specifically, we apply inter-modal and intra-modal contrastive learning to explore the correlation between audio and other modalities in addition to the inner characteristics of the audio modality. Moreover, we further design an audio type token to dynamically learn different audio information type for different scenarios, as both verbal and nonverbal heterogeneous information is conveyed in general audios. Our proposed CLIP4VLA model is validated in different downstream tasks including video retrieval and video captioning, and achieves the state-of-the-art performance on the benchmark datasets of MSR-VTT, VATEX, and Audiocaps.The corresponding code and checkpoints will be released at https://github.com/ludanruan/CLIP4VLA.},
  archive   = {C_AAAI},
  author    = {Ludan Ruan and Anwen Hu and Yuqing Song and Liang Zhang and Sipeng Zheng and Qin Jin},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26153},
  pages     = {9641-9649},
  title     = {Accommodating audio modality in CLIP for multimodal processing},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Inferring patient zero on temporal networks via graph neural
networks. <em>AAAI</em>, 9632–9640. (<a
href="https://doi.org/10.1609/aaai.v37i8.26152">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The world is currently seeing frequent local outbreaks of epidemics, such as COVID-19 and Monkeypox. Preventing further propagation of the outbreak requires prompt implementation of control measures, and a critical step is to quickly infer patient zero. This backtracking task is challenging for two reasons. First, due to the sudden emergence of local epidemics, information recording the spreading process is limited. Second, the spreading process has strong randomness. To address these challenges, we tailor a gnn-based model to establish the inverse statistical association between the current and initial state implicitly. This model uses contact topology and the current state of the local population to determine the possibility that each individual could be patient zero. We benchmark our model on data from important epidemiological models on five real temporal networks, showing performance significantly superior to previous methods. We also demonstrate that our method is robust to missing information about contact structure or current state. Further, we find the individuals assigned higher inferred possibility by model are closer to patient zero in terms of core number and the activity sequence recording the times at which the individual had contact with other nodes.},
  archive   = {C_AAAI},
  author    = {Xiaolei Ru and Jack Murdoch Moore and Xin-Ya Zhang and Yeting Zeng and Gang Yan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26152},
  pages     = {9632-9640},
  title     = {Inferring patient zero on temporal networks via graph neural networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Overcoming concept shift in domain-aware settings through
consolidated internal distributions. <em>AAAI</em>, 9623–9631. (<a
href="https://doi.org/10.1609/aaai.v37i8.26151">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We develop an algorithm to improve the predictive performance of a pre-trained model under \textit{concept shift} without retraining the model from scratch when only unannotated samples of initial concepts are accessible. We model this problem as a domain adaptation problem, where the source domain data is inaccessible during model adaptation. The core idea is based on consolidating the intermediate internal distribution, learned to represent the source domain data, after adapting the model. We provide theoretical analysis and conduct extensive experiments on five benchmark datasets to demonstrate that the proposed method is effective.},
  archive   = {C_AAAI},
  author    = {Mohammad Rostami and Aram Galstyan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26151},
  pages     = {9623-9631},
  title     = {Overcoming concept shift in domain-aware settings through consolidated internal distributions},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DisGUIDE: Disagreement-guided data-free model extraction.
<em>AAAI</em>, 9614–9622. (<a
href="https://doi.org/10.1609/aaai.v37i8.26150">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent model-extraction attacks on Machine Learning as a Service (MLaaS) systems have moved towards data-free approaches, showing the feasibility of stealing models trained with difficult-to-access data. However, these attacks are ineffective or limited due to the low accuracy of extracted models and the high number of queries to the models under attack. The high query cost makes such techniques infeasible for online MLaaS systems that charge per query. We create a novel approach to get higher accuracy and query efficiency than prior data-free model extraction techniques. Specifically, we introduce a novel generator training scheme that maximizes the disagreement loss between two clone models that attempt to copy the model under attack. This loss, combined with diversity loss and experience replay, enables the generator to produce better instances to train the clone models. Our evaluation on popular datasets CIFAR-10 and CIFAR-100 shows that our approach improves the final model accuracy by up to 3.42\% and 18.48\% respectively. The average number of queries required to achieve the accuracy of the prior state of the art is reduced by up to 64.95\%. We hope this will promote future work on feasible data-free model extraction and defenses against such attacks.},
  archive   = {C_AAAI},
  author    = {Jonathan Rosenthal and Eric Enouen and Hung Viet Pham and Lin Tan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26150},
  pages     = {9614-9622},
  title     = {DisGUIDE: Disagreement-guided data-free model extraction},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Planning and learning with adaptive lookahead.
<em>AAAI</em>, 9606–9613. (<a
href="https://doi.org/10.1609/aaai.v37i8.26149">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Some of the most powerful reinforcement learning frameworks use planning for action selection. Interestingly, their planning horizon is either fixed or determined arbitrarily by the state visitation history. Here, we expand beyond the naive fixed horizon and propose a theoretically justified strategy for adaptive selection of the planning horizon as a function of the state-dependent value estimate. We propose two variants for lookahead selection and analyze the trade-off between iteration count and computational complexity per iteration. We then devise a corresponding deep Q-network algorithm with an adaptive tree search horizon. We separate the value estimation per depth to compensate for the off-policy discrepancy between depths. Lastly, we demonstrate the efficacy of our adaptive lookahead method in a maze environment and Atari.},
  archive   = {C_AAAI},
  author    = {Aviv Rosenberg and Assaf Hallak and Shie Mannor and Gal Chechik and Gal Dalal},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26149},
  pages     = {9606-9613},
  title     = {Planning and learning with adaptive lookahead},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ESPT: A self-supervised episodic spatial pretext task for
improving few-shot learning. <em>AAAI</em>, 9596–9605. (<a
href="https://doi.org/10.1609/aaai.v37i8.26148">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Self-supervised learning (SSL) techniques have recently been integrated into the few-shot learning (FSL) framework and have shown promising results in improving the few-shot image classification performance. However, existing SSL approaches used in FSL typically seek the supervision signals from the global embedding of every single image. Therefore, during the episodic training of FSL, these methods cannot capture and fully utilize the local visual information in image samples and the data structure information of the whole episode, which are beneficial to FSL. To this end, we propose to augment the few-shot learning objective with a novel self-supervised Episodic Spatial Pretext Task (ESPT). Specifically, for each few-shot episode, we generate its corresponding transformed episode by applying a random geometric transformation to all the images in it. Based on these, our ESPT objective is defined as maximizing the local spatial relationship consistency between the original episode and the transformed one. With this definition, the ESPT-augmented FSL objective promotes learning more transferable feature representations that capture the local spatial features of different images and their inter-relational structural information in each input episode, thus enabling the model to generalize better to new categories with only a few samples. Extensive experiments indicate that our ESPT method achieves new state-of-the-art performance for few-shot image classification on three mainstay benchmark datasets. The source code will be available at: https://github.com/Whut-YiRong/ESPT.},
  archive   = {C_AAAI},
  author    = {Yi Rong and Xiongbo Lu and Zhaoyang Sun and Yaxiong Chen and Shengwu Xiong},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26148},
  pages     = {9596-9605},
  title     = {ESPT: A self-supervised episodic spatial pretext task for improving few-shot learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automata cascades: Expressivity and sample complexity.
<em>AAAI</em>, 9588–9595. (<a
href="https://doi.org/10.1609/aaai.v37i8.26147">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Every automaton can be decomposed into a cascade of basic prime automata. This is the Prime Decomposition Theorem by Krohn and Rhodes. Guided by this theory, we propose automata cascades as a structured, modular, way to describe automata as complex systems made of many components, each implementing a specific functionality. Any automaton can serve as a component; using specific components allows for a fine-grained control of the expressivity of the resulting class of automata; using prime automata as components implies specific expressivity guarantees. Moreover, specifying automata as cascades allows for describing the sample complexity of automata in terms of their components. We show that the sample complexity is linear in the number of components and the maximum complexity of a single component, modulo logarithmic factors. This opens to the possibility of learning automata representing large dynamical systems consisting of many parts interacting with each other. It is in sharp contrast with the established understanding of the sample complexity of automata, described in terms of the overall number of states and input letters, which implies that it is only possible to learn automata where the number of states is linear in the amount of data available. Instead our results show that one can learn automata with a number of states that is exponential in the amount of data available.},
  archive   = {C_AAAI},
  author    = {Alessandro Ronca and Nadezda Alexandrovna Knorozova and Giuseppe De Giacomo},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26147},
  pages     = {9588-9595},
  title     = {Automata cascades: Expressivity and sample complexity},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hypernetworks for zero-shot transfer in reinforcement
learning. <em>AAAI</em>, 9579–9587. (<a
href="https://doi.org/10.1609/aaai.v37i8.26146">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, hypernetworks are trained to generate behaviors across a range of unseen task conditions, via a novel TD-based training objective and data from a set of near-optimal RL solutions for training tasks. This work relates to meta RL, contextual RL, and transfer learning, with a particular focus on zero-shot performance at test time, enabled by knowledge of the task parameters (also known as context). Our technical approach is based upon viewing each RL algorithm as a mapping from the MDP specifics to the near-optimal value function and policy and seek to approximate it with a hypernetwork that can generate near-optimal value functions and policies, given the parameters of the MDP. We show that, under certain conditions, this mapping can be considered as a supervised learning problem. We empirically evaluate the effectiveness of our method for zero-shot transfer to new reward and transition dynamics on a series of continuous control tasks from DeepMind Control Suite. Our method demonstrates significant improvements over baselines from multitask and meta RL approaches.},
  archive   = {C_AAAI},
  author    = {Sahand Rezaei-Shoshtari and Charlotte Morissette and Francois R. Hogan and Gregory Dudek and David Meger},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26146},
  pages     = {9579-9587},
  title     = {Hypernetworks for zero-shot transfer in reinforcement learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Diffusing gaussian mixtures for generating categorical data.
<em>AAAI</em>, 9570–9578. (<a
href="https://doi.org/10.1609/aaai.v37i8.26145">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Learning a categorical distribution comes with its own set of challenges. A successful approach taken by state-of-the-art works is to cast the problem in a continuous domain to take advantage of the impressive performance of the generative models for continuous data. Amongst them are the recently emerging diffusion probabilistic models, which have the observed advantage of generating high-quality samples. Recent advances for categorical generative models have focused on log likelihood improvements. In this work, we propose a generative model for categorical data based on diffusion models with a focus on high-quality sample generation, and propose sampled-based evaluation methods. The efficacy of our method stems from performing diffusion in the continuous domain while having its parameterization informed by the structure of the categorical nature of the target distribution. Our method of evaluation highlights the capabilities and limitations of different generative models for generating categorical data, and includes experiments on synthetic and real-world protein datasets.},
  archive   = {C_AAAI},
  author    = {Florence Regol and Mark Coates},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26145},
  pages     = {9570-9578},
  title     = {Diffusing gaussian mixtures for generating categorical data},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Provable detection of propagating sampling bias in
prediction models. <em>AAAI</em>, 9562–9569. (<a
href="https://doi.org/10.1609/aaai.v37i8.26144">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With an increased focus on incorporating fairness in machine learning models, it becomes imperative not only to assess and mitigate bias at each stage of the machine learning pipeline but also to understand the downstream impacts of bias across stages. Here we consider a general, but realistic, scenario in which a predictive model is learned from (potentially biased) training data, and model predictions are assessed post-hoc for fairness by some auditing method. We provide a theoretical analysis of how a specific form of data bias, differential sampling bias, propagates from the data stage to the prediction stage. Unlike prior work, we evaluate the downstream impacts of data biases quantitatively rather than qualitatively and prove theoretical guarantees for detection. Under reasonable assumptions, we quantify how the amount of bias in the model predictions varies as a function of the amount of differential sampling bias in the data, and at what point this bias becomes provably detectable by the auditor. Through experiments on two criminal justice datasets-- the well-known COMPAS dataset and historical data from NYPD&#39;s stop and frisk policy-- we demonstrate that the theoretical results hold in practice even when our assumptions are relaxed.},
  archive   = {C_AAAI},
  author    = {Pavan Ravishankar and Qingyu Mo and Edward McFowland III and Daniel B. Neill},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26144},
  pages     = {9562-9569},
  title     = {Provable detection of propagating sampling bias in prediction models},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GLUECons: A generic benchmark for learning under
constraints. <em>AAAI</em>, 9552–9561. (<a
href="https://doi.org/10.1609/aaai.v37i8.26143">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent research has shown that integrating domain knowledge into deep learning architectures is effective; It helps reduce the amount of required data, improves the accuracy of the models&#39; decisions, and improves the interpretability of models. However, the research community lacks a convened benchmark for systematically evaluating knowledge integration methods. In this work, we create a benchmark that is a collection of nine tasks in the domains of natural language processing and computer vision. In all cases, we model external knowledge as constraints, specify the sources of the constraints for each task, and implement various models that use these constraints. We report the results of these models using a new set of extended evaluation criteria in addition to the task performances for a more in-depth analysis. This effort provides a framework for a more comprehensive and systematic comparison of constraint integration techniques and for identifying related research challenges. It will facilitate further research for alleviating some problems of state-of-the-art neural models.},
  archive   = {C_AAAI},
  author    = {Hossein Rajaby Faghihi and Aliakbar Nafar and Chen Zheng and Roshanak Mirzaee and Yue Zhang and Andrzej Uszok and Alexander Wan and Tanawan Premsri and Dan Roth and Parisa Kordjamshidi},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26143},
  pages     = {9552-9561},
  title     = {GLUECons: A generic benchmark for learning under constraints},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bellman meets hawkes: Model-based reinforcement learning via
temporal point processes. <em>AAAI</em>, 9543–9551. (<a
href="https://doi.org/10.1609/aaai.v37i8.26142">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider a sequential decision making problem where the agent faces the environment characterized by the stochastic discrete events and seeks an optimal intervention policy such that its long-term reward is maximized. This problem exists ubiquitously in social media, finance and health informatics but is rarely investigated by the conventional research in reinforcement learning. To this end, we present a novel framework of the model-based reinforcement learning where the agent&#39;s actions and observations are asynchronous stochastic discrete events occurring in continuous-time. We model the dynamics of the environment by Hawkes process with external intervention control term and develop an algorithm to embed such process in the Bellman equation which guides the direction of the value gradient. We demonstrate the superiority of our method in both synthetic simulator and real-data experiments.},
  archive   = {C_AAAI},
  author    = {Chao Qu and Xiaoyu Tan and Siqiao Xue and Xiaoming Shi and James Zhang and Hongyuan Mei},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26142},
  pages     = {9543-9551},
  title     = {Bellman meets hawkes: Model-based reinforcement learning via temporal point processes},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Gradient-variation bound for online convex optimization with
constraints. <em>AAAI</em>, 9534–9542. (<a
href="https://doi.org/10.1609/aaai.v37i8.26141">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study online convex optimization with constraints consisting of multiple functional constraints and a relatively simple constraint set, such as a Euclidean ball. As enforcing the constraints at each time step through projections is computationally challenging in general, we allow decisions to violate the functional constraints but aim to achieve a low regret and cumulative violation of the constraints over a horizon of T time steps. First-order methods achieve an O(sqrt{T}) regret and an O(1) constraint violation, which is the best-known bound under the Slater&#39;s condition, but do not take into account the structural information of the problem. Furthermore, the existing algorithms and analysis are limited to Euclidean space. In this paper, we provide an instance-dependent bound for online convex optimization with complex constraints obtained by a novel online primal-dual mirror-prox algorithm. Our instance-dependent regret is quantified by the total gradient variation V_*(T) in the sequence of loss functions. The proposed algorithm works in general normed spaces and simultaneously achieves an O(sqrt{V_*(T)}) regret and an O(1) constraint violation, which is never worse than the best-known (O(sqrt{T}), O(1)) result and improves over previous works that applied mirror-prox-type algorithms for this problem achieving O(T^{2/3}) regret and constraint violation. Finally, our algorithm is computationally efficient, as it only performs mirror descent steps in each iteration instead of solving a general Lagrangian minimization problem.},
  archive   = {C_AAAI},
  author    = {Shuang Qiu and Xiaohan Wei and Mladen Kolar},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26141},
  pages     = {9534-9542},
  title     = {Gradient-variation bound for online convex optimization with constraints},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Stochastic contextual bandits with long horizon rewards.
<em>AAAI</em>, 9525–9533. (<a
href="https://doi.org/10.1609/aaai.v37i8.26140">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The growing interest in complex decision-making and language modeling problems highlights the importance of sample-efficient learning over very long horizons. This work takes a step in this direction by investigating contextual linear bandits where the current reward depends on at most s prior actions and contexts (not necessarily consecutive), up to a time horizon of h. In order to avoid polynomial dependence on h, we propose new algorithms that leverage sparsity to discover the dependence pattern and arm parameters jointly. We consider both the data-poor (T= h) regimes and derive respective regret upper bounds O(d square-root(sT) +min(q, T) and O( square-root(sdT) ), with sparsity s, feature dimension d, total time horizon T, and q that is adaptive to the reward dependence pattern. Complementing upper bounds, we also show that learning over a single trajectory brings inherent challenges: While the dependence pattern and arm parameters form a rank-1 matrix, circulant matrices are not isometric over rank-1 manifolds and sample complexity indeed benefits from the sparse reward dependence structure. Our results necessitate a new analysis to address long-range temporal dependencies across data and avoid polynomial dependence on the reward horizon h. Specifically, we utilize connections to the restricted isometry property of circulant matrices formed by dependent sub-Gaussian vectors and establish new guarantees that are also of independent interest.},
  archive   = {C_AAAI},
  author    = {Yuzhen Qin and Yingcong Li and Fabio Pasqualetti and Maryam Fazel and Samet Oymak},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26140},
  pages     = {9525-9533},
  title     = {Stochastic contextual bandits with long horizon rewards},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Training meta-surrogate model for transferable adversarial
attack. <em>AAAI</em>, 9516–9524. (<a
href="https://doi.org/10.1609/aaai.v37i8.26139">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The problem of adversarial attacks to a black-box model when no queries are allowed has posed a great challenge to the community and has been extensively investigated. In this setting, one simple yet effective method is to transfer the obtained adversarial examples from attacking surrogate models to fool the target model. Previous works have studied what kind of attacks to the surrogate model can generate more transferable adversarial examples, but their performances are still limited due to the mismatches between surrogate models and the target model. In this paper, we tackle this problem from a novel angle---instead of using the original surrogate models, can we obtain a Meta-Surrogate Model (MSM) such that attacks to this model can be easily transferred to other models? We show that this goal can be mathematically formulated as a bi-level optimization problem and design a differentiable attacker to make training feasible. Given one or a set of surrogate models, our method can thus obtain an MSM such that adversarial examples generated on MSM enjoy eximious transferability. Comprehensive experiments on Cifar-10 and ImageNet demonstrate that by attacking the MSM, we can obtain stronger transferable adversarial examples to deceive black-box models including adversarially trained ones, with much higher success rates than existing methods.},
  archive   = {C_AAAI},
  author    = {Yunxiao Qin and Yuanhao Xiong and Jinfeng Yi and Cho-Jui Hsieh},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26139},
  pages     = {9516-9524},
  title     = {Training meta-surrogate model for transferable adversarial attack},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mutual-enhanced incongruity learning network for multi-modal
sarcasm detection. <em>AAAI</em>, 9507–9515. (<a
href="https://doi.org/10.1609/aaai.v37i8.26138">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Sarcasm is a sophisticated linguistic phenomenon that is prevalent on today&#39;s social media platforms. Multi-modal sarcasm detection aims to identify whether a given sample with multi-modal information (i.e., text and image) is sarcastic. This task&#39;s key lies in capturing both inter- and intra-modal incongruities within the same context. Although existing methods have achieved compelling success, they are disturbed by irrelevant information extracted from the whole image and text, or overlooking some important information due to the incomplete input. To address these limitations, we propose a Mutual-enhanced Incongruity Learning Network for multi-modal sarcasm detection, named MILNet. In particular, we design a local semantic-guided incongruity learning module and a global incongruity learning module. Moreover, we introduce a mutual enhancement module to take advantage of the underlying consistency between the two modules to boost the performance. Extensive experiments on a widely-used dataset demonstrate the superiority of our model over cutting-edge methods.},
  archive   = {C_AAAI},
  author    = {Yang Qiao and Liqiang Jing and Xuemeng Song and Xiaolin Chen and Lei Zhu and Liqiang Nie},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26138},
  pages     = {9507-9515},
  title     = {Mutual-enhanced incongruity learning network for multi-modal sarcasm detection},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mixture uniform distribution modeling and asymmetric mix
distillation for class incremental learning. <em>AAAI</em>, 9498–9506.
(<a href="https://doi.org/10.1609/aaai.v37i8.26137">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Exemplar rehearsal-based methods with knowledge distillation (KD) have been widely used in class incremental learning (CIL) scenarios. However, they still suffer from performance degradation because of severely distribution discrepancy between training and test set caused by the limited storage memory on previous classes. In this paper, we mathematically model the data distribution and the discrepancy at the incremental stages with mixture uniform distribution (MUD). Then, we propose the asymmetric mix distillation method to uniformly minimize the error of each class from distribution discrepancy perspective. Specifically, we firstly promote mixup in CIL scenarios with the incremental mix samplers and incremental mix factor to calibrate the raw training data distribution. Next, mix distillation label augmentation is incorporated into the data distribution to inherit the knowledge information from the previous models. Based on the above augmented data distribution, our trained model effectively alleviates the performance degradation and extensive experimental results validate that our method exhibits superior performance on CIL benchmarks.},
  archive   = {C_AAAI},
  author    = {Sunyuan Qiang and Jiayi Hou and Jun Wan and Yanyan Liang and Zhen Lei and Du Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26137},
  pages     = {9498-9506},
  title     = {Mixture uniform distribution modeling and asymmetric mix distillation for class incremental learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Rethinking data-free quantization as a zero-sum game.
<em>AAAI</em>, 9489–9497. (<a
href="https://doi.org/10.1609/aaai.v37i8.26136">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Data-free quantization (DFQ) recovers the performance of quantized network (Q) without accessing the real data, but generates the fake sample via a generator (G) by learning from full-precision network (P) instead. However, such sample generation process is totally independence of Q, specialized as failing to consider the adaptability of the generated samples, i.e., beneficial or adversarial, over the learning process of Q, resulting into non-ignorable performance loss. Building on this, several crucial questions --- how to measure and exploit the sample adaptability to Q under varied bit-width scenarios? how to generate the samples with desirable adaptability to benefit the quantized network? --- impel us to revisit DFQ. In this paper, we answer the above questions from a game-theory perspective to specialize DFQ as a zero-sum game between two players --- a generator and a quantized network, and further propose an Adaptability-aware Sample Generation (AdaSG) method. Technically, AdaSG reformulates DFQ as a dynamic maximization-vs-minimization game process anchored on the sample adaptability. The maximization process aims to generate the sample with desirable adaptability, such sample adaptability is further reduced by the minimization process after calibrating Q for performance recovery. The Balance Gap is defined to guide the stationarity of the game process to maximally benefit Q. The theoretical analysis and empirical studies verify the superiority of AdaSG over the state-of-the-arts. Our code is available at https://github.com/hfutqian/AdaSG.},
  archive   = {C_AAAI},
  author    = {Biao Qian and Yang Wang and Richang Hong and Meng Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26136},
  pages     = {9489-9497},
  title     = {Rethinking data-free quantization as a zero-sum game},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CMVAE: Causal meta VAE for unsupervised meta-learning.
<em>AAAI</em>, 9480–9488. (<a
href="https://doi.org/10.1609/aaai.v37i8.26135">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Unsupervised meta-learning aims to learn the meta knowledge from unlabeled data and rapidly adapt to novel tasks. However, existing approaches may be misled by the context-bias (e.g. background) from the training data. In this paper, we abstract the unsupervised meta-learning problem into a Structural Causal Model (SCM) and point out that such bias arises due to hidden confounders. To eliminate the confounders, we define the priors are conditionally independent, learn the relationships between priors and intervene on them with casual factorization. Furthermore, we propose Causal Meta VAE (CMVAE) that encodes the priors into latent codes in the causal space and learns their relationships simultaneously to achieve the downstream few-shot image classification task. Results on toy datasets and three benchmark datasets demonstrate that our method can remove the context-bias and it outperforms other state-of-the-art unsupervised meta-learning algorithms because of bias-removal. Code is available at https://github.com/GuodongQi/CMVAE.},
  archive   = {C_AAAI},
  author    = {Guodong Qi and Huimin Yu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26135},
  pages     = {9480-9488},
  title     = {CMVAE: Causal meta VAE for unsupervised meta-learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Experimental observations of the topology of convolutional
neural network activations. <em>AAAI</em>, 9470–9479. (<a
href="https://doi.org/10.1609/aaai.v37i8.26134">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Topological data analysis (TDA) is a branch of computational mathematics, bridging algebraic topology and data science, that provides compact, noise-robust representations of complex structures. Deep neural networks (DNNs) learn millions of parameters associated with a series of transformations defined by the model architecture resulting in high-dimensional, difficult to interpret internal representations of input data. As DNNs become more ubiquitous across multiple sectors of our society, there is increasing recognition that mathematical methods are needed to aid analysts, researchers, and practitioners in understanding and interpreting how these models&#39; internal representations relate to the final classification. In this paper we apply cutting edge techniques from TDA with the goal of gaining insight towards interpretability of convolutional neural networks used for image classification. We use two common TDA approaches to explore several methods for modeling hidden layer activations as high-dimensional point clouds, and provide experimental evidence that these point clouds capture valuable structural information about the model&#39;s process. First, we demonstrate that a distance metric based on persistent homology can be used to quantify meaningful differences between layers and discuss these distances in the broader context of existing representational similarity metrics for neural network interpretability. Second, we show that a mapper graph can provide semantic insight as to how these models organize hierarchical class knowledge at each layer. These observations demonstrate that TDA is a useful tool to help deep learning practitioners unlock the hidden structures of their models.},
  archive   = {C_AAAI},
  author    = {Emilie Purvine and Davis Brown and Brett Jefferson and Cliff Joslyn and Brenda Praggastis and Archit Rathore and Madelyn Shapiro and Bei Wang and Youjia Zhou},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26134},
  pages     = {9470-9479},
  title     = {Experimental observations of the topology of convolutional neural network activations},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A model-agnostic heuristics for selective classification.
<em>AAAI</em>, 9461–9469. (<a
href="https://doi.org/10.1609/aaai.v37i8.26133">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Selective classification (also known as classification with reject option) conservatively extends a classifier with a selection function to determine whether or not a prediction should be accepted (i.e., trusted, used, deployed). This is a highly relevant issue in socially sensitive tasks, such as credit scoring. State-of-the-art approaches rely on Deep Neural Networks (DNNs) that train at the same time both the classifier and the selection function. These approaches are model-specific and computationally expensive. We propose a model-agnostic approach, as it can work with any base probabilistic binary classification algorithm, and it can be scalable to large tabular datasets if the base classifier is so. The proposed algorithm, called SCROSS, exploits a cross-fitting strategy and theoretical results for quantile estimation to build the selection function. Experiments on real-world data show that SCROSS improves over existing methods.},
  archive   = {C_AAAI},
  author    = {Andrea Pugnana and Salvatore Ruggieri},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26133},
  pages     = {9461-9469},
  title     = {A model-agnostic heuristics for selective classification},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Explaining random forests using bipolar argumentation and
markov networks. <em>AAAI</em>, 9453–9460. (<a
href="https://doi.org/10.1609/aaai.v37i8.26132">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Random forests are decision tree ensembles that can be used to solve a variety of machine learning problems. However, as the number of trees and their individual size can be large, their decision making process is often incomprehensible. We show that their decision process can be naturally represented as an argumentation problem, which allows creating global explanations via argumentative reasoning. We generalize sufficient and necessary argumentative explanations using a Markov network encoding, discuss the relevance of these explanations and establish relationships to families of abductive explanations from the literature. As the complexity of the explanation problems is high, we present an efficient approximation algorithm with probabilistic approximation guarantees.},
  archive   = {C_AAAI},
  author    = {Nico Potyka and Xiang Yin and Francesca Toni},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26132},
  pages     = {9453-9460},
  title     = {Explaining random forests using bipolar argumentation and markov networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Latent autoregressive source separation. <em>AAAI</em>,
9444–9452. (<a href="https://doi.org/10.1609/aaai.v37i8.26131">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Autoregressive models have achieved impressive results over a wide range of domains in terms of generation quality and downstream task performance. In the continuous domain, a key factor behind this success is the usage of quantized latent spaces (e.g., obtained via VQ-VAE autoencoders), which allow for dimensionality reduction and faster inference times. However, using existing pre-trained models to perform new non-trivial tasks is difficult since it requires additional fine-tuning or extensive training to elicit prompting. This paper introduces LASS as a way to perform vector-quantized Latent Autoregressive Source Separation (i.e., de-mixing an input signal into its constituent sources) without requiring additional gradient-based optimization or modifications of existing models. Our separation method relies on the Bayesian formulation in which the autoregressive models are the priors, and a discrete (non-parametric) likelihood function is constructed by performing frequency counts over latent sums of addend tokens. We test our method on images and audio with several sampling strategies (e.g., ancestral, beam search) showing competitive results with existing approaches in terms of separation quality while offering at the same time significant speedups in terms of inference time and scalability to higher dimensional data.},
  archive   = {C_AAAI},
  author    = {Emilian Postolache and Giorgio Mariani and Michele Mancusi and Andrea Santilli and Luca Cosmo and Emanuele Rodolà},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26131},
  pages     = {9444-9452},
  title     = {Latent autoregressive source separation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Weighted policy constraints for offline reinforcement
learning. <em>AAAI</em>, 9435–9443. (<a
href="https://doi.org/10.1609/aaai.v37i8.26130">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Offline reinforcement learning (RL) aims to learn policy from the passively collected offline dataset. Applying existing RL methods on the static dataset straightforwardly will raise distribution shift, causing these unconstrained RL methods to fail. To cope with the distribution shift problem, a common practice in offline RL is to constrain the policy explicitly or implicitly close to behavioral policy. However, the available dataset usually contains sub-optimal or inferior actions, constraining the policy near all these actions will make the policy inevitably learn inferior behaviors, limiting the performance of the algorithm. Based on this observation, we propose a weighted policy constraints (wPC) method that only constrains the learned policy to desirable behaviors, making room for policy improvement on other parts. Our algorithm outperforms existing state-of-the-art offline RL algorithms on the D4RL offline gym datasets. Moreover, the proposed algorithm is simple to implement with few hyper-parameters, making the proposed wPC algorithm a robust offline RL method with low computational complexity.},
  archive   = {C_AAAI},
  author    = {Zhiyong Peng and Changlin Han and Yadong Liu and Zongtan Zhou},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26130},
  pages     = {9435-9443},
  title     = {Weighted policy constraints for offline reinforcement learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Conceptual reinforcement learning for language-conditioned
tasks. <em>AAAI</em>, 9426–9434. (<a
href="https://doi.org/10.1609/aaai.v37i8.26129">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Despite the broad application of deep reinforcement learning (RL), transferring and adapting the policy to unseen but similar environments is still a significant challenge. Recently, the language-conditioned policy is proposed to facilitate policy transfer through learning the joint representation of observation and text that catches the compact and invariant information across various environments. Existing studies of language-conditioned RL methods often learn the joint representation as a simple latent layer for the given instances (episode-specific observation and text), which inevitably includes noisy or irrelevant information and cause spurious correlations that are dependent on instances, thus hurting generalization performance and training efficiency. To address the above issue, we propose a conceptual reinforcement learning (CRL) framework to learn the concept-like joint representation for language-conditioned policy. The key insight is that concepts are compact and invariant representations in human cognition through extracting similarities from numerous instances in real-world. In CRL, we propose a multi-level attention encoder and two mutual information constraints for learning compact and invariant concepts. Verified in two challenging environments, RTFM and Messenger, CRL significantly improves the training efficiency (up to 70\%) and generalization ability (up to 30\%) to the new environment dynamics.},
  archive   = {C_AAAI},
  author    = {Shaohui Peng and Xing Hu and Rui Zhang and Jiaming Guo and Qi Yi and Ruizhi Chen and Zidong Du and Ling Li and Qi Guo and Yunji Chen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26129},
  pages     = {9426-9434},
  title     = {Conceptual reinforcement learning for language-conditioned tasks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Scaling marginalized importance sampling to high-dimensional
state-spaces via state abstraction. <em>AAAI</em>, 9417–9425. (<a
href="https://doi.org/10.1609/aaai.v37i8.26128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider the problem of off-policy evaluation (OPE) in reinforcement learning (RL), where the goal is to estimate the performance of an evaluation policy, pie, using a fixed dataset, D, collected by one or more policies that may be different from pie. Current OPE algorithms may produce poor OPE estimates under policy distribution shift i.e., when the probability of a particular state-action pair occurring under pie is very different from the probability of that same pair occurring in D. In this work, we propose to improve the accuracy of OPE estimators by projecting the high-dimensional state-space into a low-dimensional state-space using concepts from the state abstraction literature. Specifically, we consider marginalized importance sampling (MIS) OPE algorithms which compute state-action distribution correction ratios to produce their OPE estimate. In the original ground state-space, these ratios may have high variance which may lead to high variance OPE. However, we prove that in the lower-dimensional abstract state-space the ratios can have lower variance resulting in lower variance OPE. We then highlight the challenges that arise when estimating the abstract ratios from data, identify sufficient conditions to overcome these issues, and present a minimax optimization problem whose solution yields these abstract ratios. Finally, our empirical evaluation on difficult, high-dimensional state-space OPE tasks shows that the abstract ratios can make MIS OPE estimators achieve lower mean-squared error and more robust to hyperparameter tuning than the ground ratios.},
  archive   = {C_AAAI},
  author    = {Brahma S. Pavse and Josiah P. Hanna},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26128},
  pages     = {9417-9425},
  title     = {Scaling marginalized importance sampling to high-dimensional state-spaces via state abstraction},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynamic structure pruning for compressing CNNs.
<em>AAAI</em>, 9408–9416. (<a
href="https://doi.org/10.1609/aaai.v37i8.26127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Structure pruning is an effective method to compress and accelerate neural networks. While filter and channel pruning are preferable to other structure pruning methods in terms of realistic acceleration and hardware compatibility, pruning methods with a finer granularity, such as intra-channel pruning, are expected to be capable of yielding more compact and computationally efficient networks. Typical intra-channel pruning methods utilize a static and hand-crafted pruning granularity due to a large search space, which leaves room for improvement in their pruning performance. In this work, we introduce a novel structure pruning method, termed as dynamic structure pruning, to identify optimal pruning granularities for intra-channel pruning. In contrast to existing intra-channel pruning methods, the proposed method automatically optimizes dynamic pruning granularities in each layer while training deep neural networks. To achieve this, we propose a differentiable group learning method designed to efficiently learn a pruning granularity based on gradient-based learning of filter groups. The experimental results show that dynamic structure pruning achieves state-of-the-art pruning performance and better realistic acceleration on a GPU compared with channel pruning. In particular, it reduces the FLOPs of ResNet50 by 71.85\% without accuracy degradation on the ImageNet dataset. Our code is available at https://github.com/irishev/DSP.},
  archive   = {C_AAAI},
  author    = {Jun-Hyung Park and Yeachan Kim and Junho Kim and Joon-Young Choi and SangKeun Lee},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26127},
  pages     = {9408-9416},
  title     = {Dynamic structure pruning for compressing CNNs},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Balanced column-wise block pruning for maximizing GPU
parallelism. <em>AAAI</em>, 9398–9407. (<a
href="https://doi.org/10.1609/aaai.v37i8.26126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Pruning has been an effective solution to reduce the number of computations and the memory requirement in deep learning. The pruning unit plays an important role in exploiting the GPU resources efficiently. The filter is proposed as a simple pruning unit of structured pruning. However, since the filter is quite large as pruning unit, the accuracy drop is considerable with a high pruning ratio. GPU rearranges the weight and input tensors into tiles (blocks) for efficient computation. To fully utilize GPU resources, this tile structure should be considered, which is the goal of block pruning. However, previous block pruning prunes both row vectors and column vectors. Pruning of row vectors in a tile corresponds to filter pruning, and it also interferes with column-wise block pruning of the following layer. In contrast, column vectors are much smaller than row vectors and can achieve lower accuracy drop. Additionally, if the pruning ratio for each tile is different, GPU utilization can be limited by imbalanced workloads by irregular-sized blocks. The same pruning ratio for the weight tiles processed in parallel enables the actual inference process to fully utilize the resources without idle time. This paper proposes balanced column-wise block pruning, named BCBP, to satisfy two conditions: the column-wise minimal size of the pruning unit and balanced workloads. We demonstrate that BCBP is superior to previous pruning methods through comprehensive experiments.},
  archive   = {C_AAAI},
  author    = {Cheonjun Park and Mincheol Park and Hyun Jae Oh and Minkyu Kim and Myung Kuk Yoon and Suhyun Kim and Won Woo Ro},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26126},
  pages     = {9398-9407},
  title     = {Balanced column-wise block pruning for maximizing GPU parallelism},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evidential conditional neural processes. <em>AAAI</em>,
9389–9397. (<a href="https://doi.org/10.1609/aaai.v37i8.26125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Conditional Neural Process (CNP) family of models offer a promising direction to tackle few-shot problems by achieving better scalability and competitive predictive performance. However, the current CNP models only capture the overall uncertainty for the prediction made on a target data point. They lack a systematic fine-grained quantification on the distinct sources of uncertainty that are essential for model training and decision-making under the few-shot setting. We propose Evidential Conditional Neural Processes (ECNP), which replace the standard Gaussian distribution used by CNP with a much richer hierarchical Bayesian structure through evidential learning to achieve epistemic-aleatoric uncertainty decomposition. The evidential hierarchical structure also leads to a theoretically justified robustness over noisy training tasks. Theoretical analysis on the proposed ECNP establishes the relationship with CNP while offering deeper insights on the roles of the evidential parameters. Extensive experiments conducted on both synthetic and real-world data demonstrate the effectiveness of our proposed model in various few-shot settings.},
  archive   = {C_AAAI},
  author    = {Deep Shankar Pandey and Qi Yu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26125},
  pages     = {9389-9397},
  title     = {Evidential conditional neural processes},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Isometric manifold learning using hierarchical flow.
<em>AAAI</em>, 9381–9388. (<a
href="https://doi.org/10.1609/aaai.v37i8.26124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose the Hierarchical Flow (HF) model constrained by isometric regularizations for manifold learning that combines manifold learning goals such as dimensionality reduction, inference, sampling, projection and density estimation into one unified framework. Our proposed HF model is regularized to not only produce embeddings preserving the geometric structure of the manifold, but also project samples onto the manifold in a manner conforming to the rigorous definition of projection. Theoretical guarantees are provided for our HF model to satisfy the two desired properties. In order to detect the real dimensionality of the manifold, we also propose a two-stage dimensionality reduction algorithm, which is a time-efficient algorithm thanks to the hierarchical architecture design of our HF model. Experimental results justify our theoretical analysis, demonstrate the superiority of our dimensionality reduction algorithm in cost of training time, and verify the effect of the aforementioned properties in improving performances on downstream tasks such as anomaly detection.},
  archive   = {C_AAAI},
  author    = {Ziqi Pan and Jianfu Zhang and Li Niu and Liqing Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26124},
  pages     = {9381-9388},
  title     = {Isometric manifold learning using hierarchical flow},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Geometric inductive biases for identifiable unsupervised
learning of disentangled representations. <em>AAAI</em>, 9372–9380. (<a
href="https://doi.org/10.1609/aaai.v37i8.26123">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The model identifiability is a considerable issue in the unsupervised learning of disentangled representations. The PCA inductive biases revealed recently for unsupervised disentangling in VAE-based models are shown to improve local alignment of latent dimensions with principal components of the data. In this paper, in additional to the PCA inductive biases, we propose novel geometric inductive biases from the manifold perspective for unsupervised disentangling, which induce the model to capture the global geometric properties of the data manifold with guaranteed model identifiability. We also propose a Geometric Disentangling Regularized AutoEncoder (GDRAE) that combines the PCA and the proposed geometric inductive biases in one unified framework. The experimental results show the usefulness of the geometric inductive biases in unsupervised disentangling and the effectiveness of our GDRAE in capturing the geometric inductive biases.},
  archive   = {C_AAAI},
  author    = {Ziqi Pan and Li Niu and Liqing Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26123},
  pages     = {9372-9380},
  title     = {Geometric inductive biases for identifiable unsupervised learning of disentangled representations},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FedMDFG: Federated learning with multi-gradient descent and
fair guidance. <em>AAAI</em>, 9364–9371. (<a
href="https://doi.org/10.1609/aaai.v37i8.26122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Fairness has been considered as a critical problem in federated learning (FL). In this work, we analyze two direct causes of unfairness in FL - an unfair direction and an improper step size when updating the model. To solve these issues, we introduce an effective way to measure fairness of the model through the cosine similarity, and then propose a federated multiple gradient descent algorithm with fair guidance (FedMDFG) to drive the model fairer. We first convert FL into a multi-objective optimization problem (MOP) and design an advanced multiple gradient descent algorithm to calculate a fair descent direction by adding a fair-driven objective to MOP. A low-communication-cost line search strategy is then designed to find a better step size for the model update. We further show the theoretical analysis on how it can enhance fairness and guarantee the convergence. Finally, extensive experiments in several FL scenarios verify that FedMDFG is robust and outperforms the SOTA FL algorithms in convergence and fairness. The source code is available at https://github.com/zibinpan/FedMDFG.},
  archive   = {C_AAAI},
  author    = {Zibin Pan and Shuyi Wang and Chi Li and Haijin Wang and Xiaoying Tang and Junhua Zhao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26122},
  pages     = {9364-9371},
  title     = {FedMDFG: Federated learning with multi-gradient descent and fair guidance},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Ising-traffic: Using ising machine learning to predict
traffic congestion under uncertainty. <em>AAAI</em>, 9354–9363. (<a
href="https://doi.org/10.1609/aaai.v37i8.26121">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper addresses the challenges in accurate and real-time traffic congestion prediction under uncertainty by proposing Ising-Traffic, a dual-model Ising-based traffic prediction framework that delivers higher accuracy and lower latency than SOTA solutions. While traditional solutions face the dilemma from the trade-off between algorithm complexity and computational efficiency, our Ising-based method breaks away from the trade-off leveraging the Ising model&#39;s strong expressivity and the Ising machine&#39;s strong computation power. In particular, Ising-Traffic formulates traffic prediction under uncertainty into two Ising models: Reconstruct-Ising and Predict-Ising. Reconstruct-Ising is mapped onto modern Ising machines and handles uncertainty in traffic accurately with negligible latency and energy consumption, while Predict-Ising is mapped onto traditional processors and predicts future congestion precisely with only at most 1.8\% computational demands of existing solutions. Our evaluation shows Ising-Traffic delivers on average 98X speedups and 5\% accuracy improvement over SOTA.},
  archive   = {C_AAAI},
  author    = {Zhenyu Pan and Anshujit Sharma and Jerry Yao-Chieh Hu and Zhuo Liu and Ang Li and Han Liu and Michael Huang and Tony Geng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26121},
  pages     = {9354-9363},
  title     = {Ising-traffic: Using ising machine learning to predict traffic congestion under uncertainty},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). H-TSP: Hierarchically solving the large-scale traveling
salesman problem. <em>AAAI</em>, 9345–9353. (<a
href="https://doi.org/10.1609/aaai.v37i8.26120">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose an end-to-end learning framework based on hierarchical reinforcement learning, called H-TSP, for addressing the large-scale Traveling Salesman Problem (TSP). The proposed H-TSP constructs a solution of a TSP instance starting from the scratch relying on two components: the upper-level policy chooses a small subset of nodes (up to 200 in our experiment) from all nodes that are to be traversed, while the lower-level policy takes the chosen nodes as input and outputs a tour connecting them to the existing partial route (initially only containing the depot). After jointly training the upper-level and lower-level policies, our approach can directly generate solutions for the given TSP instances without relying on any time-consuming search procedures. To demonstrate effectiveness of the proposed approach, we have conducted extensive experiments on randomly generated TSP instances with different numbers of nodes. We show that H-TSP can achieve comparable results (gap 3.42\% vs. 7.32\%) as SOTA search-based approaches, and more importantly, we reduce the time consumption up to two orders of magnitude (3.32s vs. 395.85s). To the best of our knowledge, H-TSP is the first end-to-end deep reinforcement learning approach that can scale to TSP instances of up to 10000 nodes. Although there are still gaps to SOTA results with respect to solution quality, we believe that H-TSP will be useful for practical applications, particularly those that are time-sensitive e.g., on-call routing and ride hailing service.},
  archive   = {C_AAAI},
  author    = {Xuanhao Pan and Yan Jin and Yuandong Ding and Mingxiao Feng and Li Zhao and Lei Song and Jiang Bian},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26120},
  pages     = {9345-9353},
  title     = {H-TSP: Hierarchically solving the large-scale traveling salesman problem},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bilinear exponential family of MDPs: Frequentist regret
bound with tractable exploration &amp; planning. <em>AAAI</em>,
9336–9344. (<a href="https://doi.org/10.1609/aaai.v37i8.26119">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the problem of episodic reinforcement learning in continuous state-action spaces with unknown rewards and transitions. Specifically, we consider the setting where the rewards and transitions are modeled using parametric bilinear exponential families. We propose an algorithm, that a) uses penalized maximum likelihood estimators to learn the unknown parameters, b) injects a calibrated Gaussian noise in the parameter of rewards to ensure exploration, and c) leverages linearity of the bilinear exponential family transitions with respect to an underlying RKHS to perform tractable planning. We provide a frequentist regret upper-bound for our algorithm which, in the case of tabular MDPs, is order-optimal with respect to H and K, where H is the episode length and K is the number of episodes. Our analysis improves the existing bounds for the bilinear exponential family of MDPs by square root of H and removes the handcrafted clipping deployed in existing RLSVI-type algorithms.},
  archive   = {C_AAAI},
  author    = {Reda Ouhamma and Debabrota Basu and Odalric Maillard},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26119},
  pages     = {9336-9344},
  title     = {Bilinear exponential family of MDPs: Frequentist regret bound with tractable exploration &amp; planning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Backpropagation-free deep learning with recursive local
representation alignment. <em>AAAI</em>, 9327–9335. (<a
href="https://doi.org/10.1609/aaai.v37i8.26118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Training deep neural networks on large-scale datasets requires significant hardware resources whose costs (even on cloud platforms) put them out of reach of smaller organizations, groups, and individuals. Backpropagation (backprop), the workhorse for training these networks, is an inherently sequential process that is difficult to parallelize. Furthermore, researchers must continually develop various specialized techniques, such as particular weight initializations and enhanced activation functions, to ensure stable parameter optimization. Our goal is to seek an effective, neuro-biologically plausible alternative to backprop that can be used to train deep networks. In this paper, we propose a backprop-free procedure, recursive local representation alignment, for training large-scale architectures. Experiments with residual networks on CIFAR-10 and the large benchmark, ImageNet, show that our algorithm generalizes as well as backprop while converging sooner due to weight updates that are parallelizable and computationally less demanding. This is empirical evidence that a backprop-free algorithm can scale up to larger datasets.},
  archive   = {C_AAAI},
  author    = {Alexander G. Ororbia and Ankur Mali and Daniel Kifer and C. Lee Giles},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26118},
  pages     = {9327-9335},
  title     = {Backpropagation-free deep learning with recursive local representation alignment},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fast saturating gate for learning long time scales with
recurrent neural networks. <em>AAAI</em>, 9319–9326. (<a
href="https://doi.org/10.1609/aaai.v37i8.26117">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Gate functions in recurrent models, such as an LSTM and GRU, play a central role in learning various time scales in modeling time series data by using a bounded activation function. However, it is difficult to train gates to capture extremely long time scales due to gradient vanishing of the bounded function for large inputs, which is known as the saturation problem. We closely analyze the relation between saturation of the gate function and efficiency of the training. We prove that the gradient vanishing of the gate function can be mitigated by accelerating the convergence of the saturating function, i.e., making the output of the function converge to 0 or 1 faster. Based on the analysis results, we propose a gate function called fast gate that has a doubly exponential convergence rate with respect to inputs by simple function composition. We empirically show that our method outperforms previous methods in accuracy and computational efficiency on benchmark tasks involving extremely long time scales.},
  archive   = {C_AAAI},
  author    = {Kentaro Ohno and Sekitoshi Kanai and Yasutoshi Ida},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26117},
  pages     = {9319-9326},
  title     = {Fast saturating gate for learning long time scales with recurrent neural networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On instance-dependent bounds for offline reinforcement
learning with linear function approximation. <em>AAAI</em>, 9310–9318.
(<a href="https://doi.org/10.1609/aaai.v37i8.26116">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Sample-efficient offline reinforcement learning (RL) with linear function approximation has been studied extensively recently. Much of the prior work has yielded instance-independent rates that hold even for the worst-case realization of problem instances. This work seeks to understand instance-dependent bounds for offline RL with linear function approximation. We present an algorithm called Bootstrapped and Constrained Pessimistic Value Iteration (BCP-VI), which leverages data bootstrapping and constrained optimization on top of pessimism. We show that under a partial data coverage assumption, that of concentrability with respect to an optimal policy, the proposed algorithm yields a fast rate for offline RL when there is a positive gap in the optimal Q-value functions, even if the offline data were collected adaptively. Moreover, when the linear features of the optimal actions in the states reachable by an optimal policy span those reachable by the behavior policy and the optimal actions are unique, offline RL achieves absolute zero sub-optimality error when the number of episodes exceeds a (finite) instance-dependent threshold. To the best of our knowledge, these are the first results that give a fast rate bound on the sub-optimality and an absolute zero sub-optimality bound for offline RL with linear function approximation from adaptive data with partial coverage. We also provide instance-agnostic and instance-dependent information-theoretical lower bounds to complement our upper bounds.},
  archive   = {C_AAAI},
  author    = {Thanh Nguyen-Tang and Ming Yin and Sunil Gupta and Svetha Venkatesh and Raman Arora},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26116},
  pages     = {9310-9318},
  title     = {On instance-dependent bounds for offline reinforcement learning with linear function approximation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Behavioral learning in security games: Threat of multi-step
manipulative attacks. <em>AAAI</em>, 9302–9309. (<a
href="https://doi.org/10.1609/aaai.v37i8.26115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper studies the problem of multi-step manipulative attacks in Stackelberg security games, in which a clever attacker attempts to orchestrate its attacks over multiple time steps to mislead the defender&#39;s learning of the attacker&#39;s behavior. This attack manipulation eventually influences the defender&#39;s patrol strategy towards the attacker&#39;s benefit. Previous work along this line of research only focuses on one-shot games in which the defender learns the attacker&#39;s behavior and then designs a corresponding strategy only once. Our work, on the other hand, investigates the long-term impact of the attacker&#39;s manipulation in which current attack and defense choices of players determine the future learning and patrol planning of the defender. This paper has three key contributions. First, we introduce a new multi-step manipulative attack game model that captures the impact of sequential manipulative attacks carried out by the attacker over the entire time horizon. Second, we propose a new algorithm to compute an optimal manipulative attack plan for the attacker, which tackles the challenge of multiple connected optimization components involved in the computation across multiple time steps. Finally, we present extensive experimental results on the impact of such misleading attacks, showing a significant benefit for the attacker and loss for the defender.},
  archive   = {C_AAAI},
  author    = {Thanh H. Nguyen and Arunesh Sinha},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26115},
  pages     = {9302-9309},
  title     = {Behavioral learning in security games: Threat of multi-step manipulative attacks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient and accurate learning of mixtures of plackett-luce
models. <em>AAAI</em>, 9294–9301. (<a
href="https://doi.org/10.1609/aaai.v37i8.26114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Mixture models of Plackett-Luce (PL), one of the most fundamental ranking models, are an active research area of both theoretical and practical significance. Most previously proposed parameter estimation algorithms instantiate the EM algorithm, often with random initialization. However, such an initialization scheme may not yield a good initial estimate and the algorithms require multiple restarts, incurring a large time complexity. As for the EM procedure, while the E-step can be performed efficiently, maximizing the log-likelihood in the M-step is difficult due to the combinatorial nature of the PL likelihood function. Therefore, previous authors favor algorithms that maximize surrogate likelihood functions. However, the final estimate may deviate from the true maximum likelihood estimate as a consequence. In this paper, we address these known limitations. We propose an initialization algorithm that can provide a provably accurate initial estimate and an EM algorithm that maximizes the true log-likelihood function efficiently. Experiments on both synthetic and real datasets show that our algorithm is competitive in terms of accuracy and speed to baseline algorithms, especially on datasets with a large number of items.},
  archive   = {C_AAAI},
  author    = {Duc Nguyen and Anderson Y. Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26114},
  pages     = {9294-9301},
  title     = {Efficient and accurate learning of mixtures of plackett-luce models},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Counterfactual learning with general data-generating
policies. <em>AAAI</em>, 9286–9293. (<a
href="https://doi.org/10.1609/aaai.v37i8.26113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Off-policy evaluation (OPE) attempts to predict the performance of counterfactual policies using log data from a different policy. We extend its applicability by developing an OPE method for a class of both full support and deficient support logging policies in contextual-bandit settings. This class includes deterministic bandit (such as Upper Confidence Bound) as well as deterministic decision-making based on supervised and unsupervised learning. We prove that our method&#39;s prediction converges in probability to the true performance of a counterfactual policy as the sample size increases. We validate our method with experiments on partly and entirely deterministic logging policies. Finally, we apply it to evaluate coupon targeting policies by a major online platform and show how to improve the existing policy.},
  archive   = {C_AAAI},
  author    = {Yusuke Narita and Kyohei Okumura and Akihiro Shimizu and Kohei Yata},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26113},
  pages     = {9286-9293},
  title     = {Counterfactual learning with general data-generating policies},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Do invariances in deep neural networks align with human
perception? <em>AAAI</em>, 9277–9285. (<a
href="https://doi.org/10.1609/aaai.v37i8.26112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {An evaluation criterion for safe and trustworthy deep learning is how well the invariances captured by representations of deep neural networks (DNNs) are shared with humans. We identify challenges in measuring these invariances. Prior works used gradient-based methods to generate identically represented inputs (IRIs), ie, inputs which have identical representations (on a given layer) of a neural network, and thus capture invariances of a given network. One necessary criterion for a network&#39;s invariances to align with human perception is for its IRIs look &#39;similar&#39; to humans. Prior works, however, have mixed takeaways; some argue that later layers of DNNs do not learn human-like invariances yet others seem to indicate otherwise. We argue that the loss function used to generate IRIs can heavily affect takeaways about invariances of the network and is the primary reason for these conflicting findings. We propose an adversarial regularizer on the IRI generation loss that finds IRIs that make any model appear to have very little shared invariance with humans. Based on this evidence, we argue that there is scope for improving models to have human-like invariances, and further, to have meaningful comparisons between models one should use IRIs generated using the regularizer-free loss. We then conduct an in-depth investigation of how different components (eg architectures, training losses, data augmentations) of the deep learning pipeline contribute to learning models that have good alignment with humans. We find that architectures with residual connections trained using a (self-supervised) contrastive loss with l_p ball adversarial data augmentation tend to learn invariances that are most aligned with humans. Code: github.com/nvedant07/Human-NN-Alignment},
  archive   = {C_AAAI},
  author    = {Vedant Nanda and Ayan Majumdar and Camila Kolling and John P. Dickerson and Krishna P. Gummadi and Bradley C. Love and Adrian Weller},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26112},
  pages     = {9277-9285},
  title     = {Do invariances in deep neural networks align with human perception?},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An operator theoretic approach for analyzing sequence neural
networks. <em>AAAI</em>, 9268–9276. (<a
href="https://doi.org/10.1609/aaai.v37i8.26111">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Analyzing the inner mechanisms of deep neural networks is a fundamental task in machine learning. Existing work provides limited analysis or it depends on local theories, such as fixed-point analysis. In contrast, we propose to analyze trained neural networks using an operator theoretic approach which is rooted in Koopman theory, the Koopman Analysis of Neural Networks (KANN). Key to our method is the Koopman operator, which is a linear object that globally represents the dominant behavior of the network dynamics. The linearity of the Koopman operator facilitates analysis via its eigenvectors and eigenvalues. Our method reveals that the latter eigendecomposition holds semantic information related to the neural network inner workings. For instance, the eigenvectors highlight positive and negative n-grams in the sentiments analysis task; similarly, the eigenvectors capture the salient features of healthy heart beat signals in the ECG classification problem.},
  archive   = {C_AAAI},
  author    = {Ilan Naiman and Omri Azencot},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26111},
  pages     = {9268-9276},
  title     = {An operator theoretic approach for analyzing sequence neural networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mean estimation of truncated mixtures of two gaussians: A
gradient based approach. <em>AAAI</em>, 9260–9267. (<a
href="https://doi.org/10.1609/aaai.v37i8.26110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Even though data is abundant, it is often subjected to some form of censoring or truncation which inherently creates biases. Removing such biases and performing parameter estimation is a classical challenge in Statistics. In this paper, we focus on the problem of estimating the means of a mixture of two balanced d-dimensional Gaussians when the samples are prone to truncation. A recent theoretical study on the performance of the Expectation-Maximization (EM) algorithm for the aforementioned problem showed EM almost surely converges for d=1 and exhibits local convergence for d&gt;1 to the true means. Nevertheless, the EM algorithm for the case of truncated mixture of two Gaussians is not easy to implement as it requires solving a set of nonlinear equations at every iteration which makes the algorithm impractical. In this work, we propose a gradient based variant of the EM algorithm that has global convergence guarantees when d=1 and local convergence for d&gt;1 to the true means. Moreover, the update rule at every iteration is easy to compute which makes the proposed method practical. We also provide numerous experiments to obtain more insights into the effect of truncation on the convergence to the true parameters in high dimensions.},
  archive   = {C_AAAI},
  author    = {Sai Ganesh Nagarajan and Gerasimos Palaiopanos and Ioannis Panageas and Tushar Vaidya and Samson Yu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26110},
  pages     = {9260-9267},
  title     = {Mean estimation of truncated mixtures of two gaussians: A gradient based approach},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Provably efficient causal model-based reinforcement learning
for systematic generalization. <em>AAAI</em>, 9251–9259. (<a
href="https://doi.org/10.1609/aaai.v37i8.26109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the sequential decision making setting, an agent aims to achieve systematic generalization over a large, possibly infinite, set of environments. Such environments are modeled as discrete Markov decision processes with both states and actions represented through a feature vector. The underlying structure of the environments allows the transition dynamics to be factored into two components: one that is environment-specific and another that is shared. Consider a set of environments that share the laws of motion as an example. In this setting, the agent can take a finite amount of reward-free interactions from a subset of these environments. The agent then must be able to approximately solve any planning task defined over any environment in the original set, relying on the above interactions only. Can we design a provably efficient algorithm that achieves this ambitious goal of systematic generalization? In this paper, we give a partially positive answer to this question. First, we provide a tractable formulation of systematic generalization by employing a causal viewpoint. Then, under specific structural assumptions, we provide a simple learning algorithm that guarantees any desired planning error up to an unavoidable sub-optimality term, while showcasing a polynomial sample complexity.},
  archive   = {C_AAAI},
  author    = {Mirco Mutti and Riccardo De Santi and Emanuele Rossi and Juan Felipe Calderon and Michael Bronstein and Marcello Restelli},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26109},
  pages     = {9251-9259},
  title     = {Provably efficient causal model-based reinforcement learning for systematic generalization},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Corruption-tolerant algorithms for generalized linear
models. <em>AAAI</em>, 9243–9250. (<a
href="https://doi.org/10.1609/aaai.v37i8.26108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper presents SVAM (Sequential Variance-Altered MLE), a unified framework for learning generalized linear models under adversarial label corruption in training data. SVAM extends to tasks such as least squares regression, logistic regression, and gamma regression, whereas many existing works on learning with label corruptions focus only on least squares regression. SVAM is based on a novel variance reduction technique that may be of independent interest and works by iteratively solving weighted MLEs over variance-altered versions of the GLM objective. SVAM offers provable model recovery guarantees superior to the state-of-the-art for robust regression even when a constant fraction of training labels are adversarially corrupted. SVAM also empirically outperforms several existing problem-specific techniques for robust regression and classification. Code for SVAM is available at https://github.com/purushottamkar/svam/},
  archive   = {C_AAAI},
  author    = {Bhaskar Mukhoty and Debojyoti Dey and Purushottam Kar},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26108},
  pages     = {9243-9250},
  title     = {Corruption-tolerant algorithms for generalized linear models},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploring the interaction between local and global latent
configurations for clustering single-cell RNA-seq: A unified
perspective. <em>AAAI</em>, 9235–9242. (<a
href="https://doi.org/10.1609/aaai.v37i8.26107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The most recent approaches for clustering single-cell RNA-sequencing data rely on deep auto-encoders. However, three major challenges remain unaddressed. First, current models overlook the impact of the cumulative errors induced by the pseudo-supervised embedding clustering task (Feature Randomness). Second, existing methods neglect the effect of the strong competition between embedding clustering and reconstruction (Feature Drift). Third, the previous deep clustering models regularly fail to consider the topological information of the latent data, even though the local and global latent configurations can bring complementary views to the clustering task. To address these challenges, we propose a novel approach that explores the interaction between local and global latent configurations to progressively adjust the reconstruction and embedding clustering tasks. We elaborate a topological and probabilistic filter to mitigate Feature Randomness and a cell-cell graph structure and content correction mechanism to counteract Feature Drift. The Zero-Inflated Negative Binomial model is also integrated to capture the characteristics of gene expression profiles. We conduct detailed experiments on real-world datasets from multiple representative genome sequencing platforms. Our approach outperforms the state-of-the-art clustering methods in various evaluation metrics.},
  archive   = {C_AAAI},
  author    = {Nairouz Mrabah and Mohamed Mahmoud Amar and Mohamed Bouguessa and Abdoulaye Banire Diallo},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26107},
  pages     = {9235-9242},
  title     = {Exploring the interaction between local and global latent configurations for clustering single-cell RNA-seq: A unified perspective},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fundamentals of task-agnostic data valuation. <em>AAAI</em>,
9226–9234. (<a href="https://doi.org/10.1609/aaai.v37i8.26106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study valuing the data of a data owner/seller for a data seeker/buyer. Data valuation is often carried out for a specific task assuming a particular utility metric, such as test accuracy on a validation set, that may not exist in practice. In this work, we focus on task-agnostic data valuation without any validation requirements. The data buyer has access to a limited amount of data (which could be publicly available) and seeks more data samples from a data seller. We formulate the problem as estimating the differences in the statistical properties of the data at the seller with respect to the baseline data available at the buyer. We capture these statistical differences through second moment by measuring diversity and relevance of the seller’s data for the buyer; we estimate these measures through queries to the seller without requesting the raw data. We design the queries with the proposed approach so that the seller is blind to the buyer’s raw data and has no knowledge to fabricate responses to the queries to obtain a desired outcome of the diversity and relevance trade-off. We will show through extensive experiments on real tabular and image datasets that the proposed estimates capture the diversity and relevance of the seller’s data for the buyer.},
  archive   = {C_AAAI},
  author    = {Mohammad Mohammadi Amiri and Frederic Berdoz and Ramesh Raskar},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26106},
  pages     = {9226-9234},
  title     = {Fundamentals of task-agnostic data valuation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multiplex graph representation learning via common and
private information mining. <em>AAAI</em>, 9217–9225. (<a
href="https://doi.org/10.1609/aaai.v37i8.26105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Self-supervised multiplex graph representation learning (SMGRL) has attracted increasing interest, but previous SMGRL methods still suffer from the following issues: (i) they focus on the common information only (but ignore the private information in graph structures) to lose some essential characteristics related to downstream tasks, and (ii) they ignore the redundant information in node representations of each graph. To solve these issues, this paper proposes a new SMGRL method by jointly mining the common information and the private information in the multiplex graph while minimizing the redundant information within node representations. Specifically, the proposed method investigates the decorrelation losses to extract the common information and minimize the redundant information, while investigating the reconstruction losses to maintain the private information. Comprehensive experimental results verify the superiority of the proposed method, on four public benchmark datasets.},
  archive   = {C_AAAI},
  author    = {Yujie Mo and Zongqian Wu and Yuhuan Chen and Xiaoshuang Shi and Heng Tao Shen and Xiaofeng Zhu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26105},
  pages     = {9217-9225},
  title     = {Multiplex graph representation learning via common and private information mining},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Why capsule neural networks do not scale: Challenging the
dynamic parse-tree assumption. <em>AAAI</em>, 9209–9216. (<a
href="https://doi.org/10.1609/aaai.v37i8.26104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Capsule neural networks replace simple, scalar-valued neurons with vector-valued capsules. They are motivated by the pattern recognition system in the human brain, where complex objects are decomposed into a hierarchy of simpler object parts. Such a hierarchy is referred to as a parse-tree. Conceptually, capsule neural networks have been defined to mimic this behavior. The capsule neural network (CapsNet), by Sabour, Frosst, and Hinton, is the first actual implementation of the conceptual idea of capsule neural networks. CapsNets achieved state-of-the-art performance on simple image recognition tasks with fewer parameters and greater robustness to affine transformations than comparable approaches. This sparked extensive follow-up research. However, despite major efforts, no work was able to scale the CapsNet architecture to more reasonable-sized datasets. Here, we provide a reason for this failure and argue that it is most likely not possible to scale CapsNets beyond toy examples. In particular, we show that the concept of a parse-tree, the main idea behind capsule neuronal networks, is not present in CapsNets. We also show theoretically and experimentally that CapsNets suffer from a vanishing gradient problem that results in the starvation of many capsules during training.},
  archive   = {C_AAAI},
  author    = {Matthias Mitterreiter and Marcel Koch and Joachim Giesen and Sören Laue},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26104},
  pages     = {9209-9216},
  title     = {Why capsule neural networks do not scale: Challenging the dynamic parse-tree assumption},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive perturbation-based gradient estimation for discrete
latent variable models. <em>AAAI</em>, 9200–9208. (<a
href="https://doi.org/10.1609/aaai.v37i8.26103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The integration of discrete algorithmic components in deep learning architectures has numerous applications. Recently, Implicit Maximum Likelihood Estimation, a class of gradient estimators for discrete exponential family distributions, was proposed by combining implicit differentiation through perturbation with the path-wise gradient estimator. However, due to the finite difference approximation of the gradients, it is especially sensitive to the choice of the finite difference step size, which needs to be specified by the user. In this work, we present Adaptive IMLE (AIMLE), the first adaptive gradient estimator for complex discrete distributions: it adaptively identifies the target distribution for IMLE by trading off the density of gradient information with the degree of bias in the gradient estimates. We empirically evaluate our estimator on synthetic examples, as well as on Learning to Explain, Discrete Variational Auto-Encoders, and Neural Relational Inference tasks. In our experiments, we show that our adaptive gradient estimator can produce faithful estimates while requiring orders of magnitude fewer samples than other gradient estimators.},
  archive   = {C_AAAI},
  author    = {Pasquale Minervini and Luca Franceschi and Mathias Niepert},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26103},
  pages     = {9200-9208},
  title     = {Adaptive perturbation-based gradient estimation for discrete latent variable models},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GENNAPE: Towards generalized neural architecture performance
estimators. <em>AAAI</em>, 9190–9199. (<a
href="https://doi.org/10.1609/aaai.v37i8.26102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Predicting neural architecture performance is a challenging task and is crucial to neural architecture design and search. Existing approaches either rely on neural performance predictors which are limited to modeling architectures in a predefined design space involving specific sets of operators and connection rules, and cannot generalize to unseen architectures, or resort to Zero-Cost Proxies which are not always accurate. In this paper, we propose GENNAPE, a Generalized Neural Architecture Performance Estimator, which is pretrained on open neural architecture benchmarks, and aims to generalize to completely unseen architectures through combined innovations in network representation, contrastive pretraining, and a fuzzy clustering-based predictor ensemble. Specifically, GENNAPE represents a given neural network as a Computation Graph (CG) of atomic operations which can model an arbitrary architecture. It first learns a graph encoder via Contrastive Learning to encourage network separation by topological features, and then trains multiple predictor heads, which are soft-aggregated according to the fuzzy membership of a neural network. Experiments show that GENNAPE pretrained on NAS-Bench-101 can achieve superior transferability to 5 different public neural network benchmarks, including NAS-Bench-201, NAS-Bench-301, MobileNet and ResNet families under no or minimum fine-tuning. We further introduce 3 challenging newly labelled neural network benchmarks: HiAML, Inception and Two-Path, which can concentrate in narrow accuracy ranges. Extensive experiments show that GENNAPE can correctly discern high-performance architectures in these families. Finally, when paired with a search algorithm, GENNAPE can find architectures that improve accuracy while reducing FLOPs on three families.},
  archive   = {C_AAAI},
  author    = {Keith G. Mills and Fred X. Han and Jialin Zhang and Fabian Chudak and Ali Safari Mamaghani and Mohammad Salameh and Wei Lu and Shangling Jui and Di Niu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26102},
  pages     = {9190-9199},
  title     = {GENNAPE: Towards generalized neural architecture performance estimators},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AIO-p: Expanding neural performance predictors beyond image
classification. <em>AAAI</em>, 9180–9189. (<a
href="https://doi.org/10.1609/aaai.v37i8.26101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Evaluating neural network performance is critical to deep neural network design but a costly procedure. Neural predictors provide an efficient solution by treating architectures as samples and learning to estimate their performance on a given task. However, existing predictors are task-dependent, predominantly estimating neural network performance on image classification benchmarks. They are also search-space dependent; each predictor is designed to make predictions for a specific architecture search space with predefined topologies and set of operations. In this paper, we propose a novel All-in-One Predictor (AIO-P), which aims to pretrain neural predictors on architecture examples from multiple, separate computer vision (CV) task domains and multiple architecture spaces, and then transfer to unseen downstream CV tasks or neural architectures. We describe our proposed techniques for general graph representation, efficient predictor pretraining and knowledge infusion techniques, as well as methods to transfer to downstream tasks/spaces. Extensive experimental results show that AIO-P can achieve Mean Absolute Error (MAE) and Spearman’s Rank Correlation (SRCC) below 1p\% and above 0.5, respectively, on a breadth of target downstream CV tasks with or without fine-tuning, outperforming a number of baselines. Moreover, AIO-P can directly transfer to new architectures not seen during training, accurately rank them and serve as an effective performance estimator when paired with an algorithm designed to preserve performance while reducing FLOPs.},
  archive   = {C_AAAI},
  author    = {Keith G. Mills and Di Niu and Mohammad Salameh and Weichen Qiu and Fred X. Han and Puyuan Liu and Jialin Zhang and Wei Lu and Shangling Jui},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26101},
  pages     = {9180-9189},
  title     = {AIO-P: Expanding neural performance predictors beyond image classification},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Information-theoretic causal discovery and intervention
detection over multiple environments. <em>AAAI</em>, 9171–9179. (<a
href="https://doi.org/10.1609/aaai.v37i8.26100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Given multiple datasets over a fixed set of random variables, each collected from a different environment, we are interested in discovering the shared underlying causal network and the local interventions per environment, without assuming prior knowledge on which datasets are observational or interventional, and without assuming the shape of the causal dependencies. We formalize this problem using the Algorithmic Model of Causation, instantiate a consistent score via the Minimum Description Length principle, and show under which conditions the network and interventions are identifiable. To efficiently discover causal networks and intervention targets in practice, we introduce the ORION algorithm, which through extensive experiments we show outperforms the state of the art in causal inference over multiple environments.},
  archive   = {C_AAAI},
  author    = {Osman Mian and Michael Kamp and Jilles Vreeken},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26100},
  pages     = {9171-9179},
  title     = {Information-theoretic causal discovery and intervention detection over multiple environments},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Off-policy proximal policy optimization. <em>AAAI</em>,
9162–9170. (<a href="https://doi.org/10.1609/aaai.v37i8.26099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Proximal Policy Optimization (PPO) is an important reinforcement learning method, which has achieved great success in sequential decision-making problems. However, PPO faces the issue of sample inefficiency, which is due to the PPO cannot make use of off-policy data. In this paper, we propose an Off-Policy Proximal Policy Optimization method (Off-Policy PPO) that improves the sample efficiency of PPO by utilizing off-policy data. Specifically, we first propose a clipped surrogate objective function that can utilize off-policy data and avoid excessively large policy updates. Next, we theoretically clarify the stability of the optimization process of the proposed surrogate objective by demonstrating the degree of policy update distance is consistent with that in the PPO. We then describe the implementation details of the proposed Off-Policy PPO which iteratively updates policies by optimizing the proposed clipped surrogate objective. Finally, the experimental results on representative continuous control tasks validate that our method outperforms the state-of-the-art methods on most tasks.},
  archive   = {C_AAAI},
  author    = {Wenjia Meng and Qian Zheng and Gang Pan and Yilong Yin},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26099},
  pages     = {9162-9170},
  title     = {Off-policy proximal policy optimization},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MHCCL: Masked hierarchical cluster-wise contrastive learning
for multivariate time series. <em>AAAI</em>, 9153–9161. (<a
href="https://doi.org/10.1609/aaai.v37i8.26098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Learning semantic-rich representations from raw unlabeled time series data is critical for downstream tasks such as classification and forecasting. Contrastive learning has recently shown its promising representation learning capability in the absence of expert annotations. However, existing contrastive approaches generally treat each instance independently, which leads to false negative pairs that share the same semantics. To tackle this problem, we propose MHCCL, a Masked Hierarchical Cluster-wise Contrastive Learning model, which exploits semantic information obtained from the hierarchical structure consisting of multiple latent partitions for multivariate time series. Motivated by the observation that fine-grained clustering preserves higher purity while coarse-grained one reflects higher-level semantics, we propose a novel downward masking strategy to filter out fake negatives and supplement positives by incorporating the multi-granularity information from the clustering hierarchy. In addition, a novel upward masking strategy is designed in MHCCL to remove outliers of clusters at each partition to refine prototypes, which helps speed up the hierarchical clustering process and improves the clustering quality. We conduct experimental evaluations on seven widely-used multivariate time series datasets. The results demonstrate the superiority of MHCCL over the state-of-the-art approaches for unsupervised time series representation learning.},
  archive   = {C_AAAI},
  author    = {Qianwen Meng and Hangwei Qian and Yong Liu and Lizhen Cui and Yonghui Xu and Zhiqi Shen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26098},
  pages     = {9153-9161},
  title     = {MHCCL: Masked hierarchical cluster-wise contrastive learning for multivariate time series},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). HyperJump: Accelerating HyperBand via risk modelling.
<em>AAAI</em>, 9143–9152. (<a
href="https://doi.org/10.1609/aaai.v37i8.26097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the literature on hyper-parameter tuning, a number of recent solutions rely on low-fidelity observations (e.g., training with sub-sampled datasets) to identify promising configurations to be tested via high-fidelity observations (e.g., using the full dataset). Among these, HyperBand is arguably one of the most popular solutions, due to its efficiency and theoretically provable robustness. In this work, we introduce HyperJump, a new approach that builds on HyperBand’s robust search strategy and complements it with novel model-based risk analysis techniques that accelerate the search by skipping the evaluation of low risk configurations, i.e., configurations that are likely to be eventually discarded by HyperBand. We evaluate HyperJump on a suite of hyper-parameter optimization problems and show that it provides over one-order of magnitude speed-ups, both in sequential and parallel deployments, on a variety of deep-learning, kernel-based learning and neural architectural search problems when compared to HyperBand and to several state-of-the-art optimizers.},
  archive   = {C_AAAI},
  author    = {Pedro Mendes and Maria Casimiro and Paolo Romano and David Garlan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26097},
  pages     = {9143-9152},
  title     = {HyperJump: Accelerating HyperBand via risk modelling},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The unreasonable effectiveness of deep evidential
regression. <em>AAAI</em>, 9134–9142. (<a
href="https://doi.org/10.1609/aaai.v37i8.26096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {There is a significant need for principled uncertainty reasoning in machine learning systems as they are increasingly deployed in safety-critical domains. A new approach with uncertainty-aware regression-based neural networks (NNs), based on learning evidential distributions for aleatoric and epistemic uncertainties, shows promise over traditional deterministic methods and typical Bayesian NNs, notably with the capabilities to disentangle aleatoric and epistemic uncertainties. Despite some empirical success of Deep Evidential Regression (DER), there are important gaps in the mathematical foundation that raise the question of why the proposed technique seemingly works. We detail the theoretical shortcomings and analyze the performance on synthetic and real-world data sets, showing that Deep Evidential Regression is a heuristic rather than an exact uncertainty quantification. We go on to discuss corrections and redefinitions of how aleatoric and epistemic uncertainties should be extracted from NNs.},
  archive   = {C_AAAI},
  author    = {Nis Meinert and Jakob Gawlikowski and Alexander Lavin},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26096},
  pages     = {9134-9142},
  title     = {The unreasonable effectiveness of deep evidential regression},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards interpreting and utilizing symmetry property in
adversarial examples. <em>AAAI</em>, 9126–9133. (<a
href="https://doi.org/10.1609/aaai.v37i8.26095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we identify symmetry property in adversarial scenario by viewing adversarial attack in a fine-grained manner. A newly designed metric called attack proportion, is thus proposed to count the proportion of the adversarial examples misclassified between classes. We observe that the distribution of attack proportion is unbalanced as each class shows vulnerability to particular classes. Further, some class pairs correlate strongly and have the same degree of attack proportion for each other. We call this intriguing phenomenon symmetry property. We empirically prove this phenomenon is widespread and then analyze the reason behind the existence of symmetry property. This explanation, to some extent, could be utilized to understand robust models, which also inspires us to strengthen adversarial defenses.},
  archive   = {C_AAAI},
  author    = {Shibin Mei and Chenglong Zhao and Bingbing Ni and Shengchao Yuan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26095},
  pages     = {9126-9133},
  title     = {Towards interpreting and utilizing symmetry property in adversarial examples},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). VIDM: Video implicit diffusion models. <em>AAAI</em>,
9117–9125. (<a href="https://doi.org/10.1609/aaai.v37i8.26094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Diffusion models have emerged as a powerful generative method for synthesizing high-quality and diverse set of images. In this paper, we propose a video generation method based on diffusion models, where the effects of motion are modeled in an implicit condition manner, i.e. one can sample plausible video motions according to the latent feature of frames. We improve the quality of the generated videos by proposing multiple strategies such as sampling space truncation, robustness penalty, and positional group normalization. Various experiments are conducted on datasets consisting of videos with different resolutions and different number of frames. Results show that the proposed method outperforms the state-of-the-art generative adversarial network-based methods by a significant margin in terms of FVD scores as well as perceptible visual quality.},
  archive   = {C_AAAI},
  author    = {Kangfu Mei and Vishal Patel},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26094},
  pages     = {9117-9125},
  title     = {VIDM: Video implicit diffusion models},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Diffusion models beat GANs on topology optimization.
<em>AAAI</em>, 9108–9116. (<a
href="https://doi.org/10.1609/aaai.v37i8.26093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Structural topology optimization, which aims to find the optimal physical structure that maximizes mechanical performance, is vital in engineering design applications in aerospace, mechanical, and civil engineering. Recently, generative adversarial networks (GANs) have emerged as a popular alternative to traditional iterative topology optimization methods. However, GANs can be challenging to train, have limited generalizability, and often neglect important performance objectives such as mechanical compliance and manufacturability. To address these issues, we propose a new architecture called TopoDiff that uses conditional diffusion models to perform performance-aware and manufacturability-aware topology optimization. Our method introduces a surrogate model-based guidance strategy that actively favors structures with low compliance and good manufacturability. Compared to a state-of-the-art conditional GAN, our approach reduces the average error on physical performance by a factor of eight and produces eleven times fewer infeasible samples. Our work demonstrates the potential of using diffusion models in topology optimization and suggests a general framework for solving engineering optimization problems using external performance with constraint-aware guidance. We provide access to our data, code, and trained models at the following link: https://decode.mit.edu/projects/topodiff/.},
  archive   = {C_AAAI},
  author    = {François Mazé and Faez Ahmed},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26093},
  pages     = {9108-9116},
  title     = {Diffusion models beat GANs on topology optimization},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Boundary graph neural networks for 3D simulations.
<em>AAAI</em>, 9099–9107. (<a
href="https://doi.org/10.1609/aaai.v37i8.26092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The abundance of data has given machine learning considerable momentum in natural sciences and engineering, though modeling of physical processes is often difficult. A particularly tough problem is the efficient representation of geometric boundaries. Triangularized geometric boundaries are well understood and ubiquitous in engineering applications. However, it is notoriously difficult to integrate them into machine learning approaches due to their heterogeneity with respect to size and orientation. In this work, we introduce an effective theory to model particle-boundary interactions, which leads to our new Boundary Graph Neural Networks (BGNNs) that dynamically modify graph structures to obey boundary conditions. The new BGNNs are tested on complex 3D granular flow processes of hoppers, rotating drums and mixers, which are all standard components of modern industrial machinery but still have complicated geometry. BGNNs are evaluated in terms of computational efficiency as well as prediction accuracy of particle flows and mixing entropies. BGNNs are able to accurately reproduce 3D granular flows within simulation uncertainties over hundreds of thousands of simulation timesteps. Most notably, in our experiments, particles stay within the geometric objects without using handcrafted conditions or restrictions.},
  archive   = {C_AAAI},
  author    = {Andreas Mayr and Sebastian Lehner and Arno Mayrhofer and Christoph Kloss and Sepp Hochreiter and Johannes Brandstetter},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26092},
  pages     = {9099-9107},
  title     = {Boundary graph neural networks for 3D simulations},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning revenue maximization using posted prices for
stochastic strategic patient buyers. <em>AAAI</em>, 9090–9098. (<a
href="https://doi.org/10.1609/aaai.v37i8.26091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider a seller faced with buyers which have the ability to delay their decision, which we call patience. Each buyer&#39;s type is composed of value and patience, and it is sampled i.i.d. from a distribution. The seller, using posted prices, would like to maximize her revenue from selling to the buyer. In this paper, we formalize this setting and characterize the resulting Stackelberg equilibrium, where the seller first commits to her strategy, and then the buyers best respond. Following this, we show how to compute both the optimal pure and mixed strategies. We then consider a learning setting, where the seller does not have access to the distribution over buyer&#39;s types. Our main results are the following. We derive a sample complexity bound for the learning of an approximate optimal pure strategy, by computing the fat-shattering dimension of this setting. Moreover, we provide a general sample complexity bound for the approximate optimal mixed strategy. We also consider an online setting and derive a vanishing regret bound with respect to both the optimal pure strategy and the optimal mixed strategy.},
  archive   = {C_AAAI},
  author    = {Eitan-Hai Mashiah and Idan Attias and Yishay Mansour},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26091},
  pages     = {9090-9098},
  title     = {Learning revenue maximization using posted prices for stochastic strategic patient buyers},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Weight predictor network with feature selection for small
sample tabular biomedical data. <em>AAAI</em>, 9081–9089. (<a
href="https://doi.org/10.1609/aaai.v37i8.26090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Tabular biomedical data is often high-dimensional but with a very small number of samples. Although recent work showed that well-regularised simple neural networks could outperform more sophisticated architectures on tabular data, they are still prone to overfitting on tiny datasets with many potentially irrelevant features. To combat these issues, we propose Weight Predictor Network with Feature Selection (WPFS) for learning neural networks from high-dimensional and small sample data by reducing the number of learnable parameters and simultaneously performing feature selection. In addition to the classification network, WPFS uses two small auxiliary networks that together output the weights of the first layer of the classification model. We evaluate on nine real-world biomedical datasets and demonstrate that WPFS outperforms other standard as well as more recent methods typically applied to tabular data. Furthermore, we investigate the proposed feature selection mechanism and show that it improves performance while providing useful insights into the learning task.},
  archive   = {C_AAAI},
  author    = {Andrei Margeloiu and Nikola Simidjievski and Pietro Liò and Mateja Jamnik},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26090},
  pages     = {9081-9089},
  title     = {Weight predictor network with feature selection for small sample tabular biomedical data},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Tight performance guarantees of imitator policies with
continuous actions. <em>AAAI</em>, 9073–9080. (<a
href="https://doi.org/10.1609/aaai.v37i8.26089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Behavioral Cloning (BC) aims at learning a policy that mimics the behavior demonstrated by an expert. The current theoretical understanding of BC is limited to the case of finite actions. In this paper, we study BC with the goal of providing theoretical guarantees on the performance of the imitator policy in the case of continuous actions. We start by deriving a novel bound on the performance gap based on Wasserstein distance, applicable for continuous-action experts, holding under the assumption that the value function is Lipschitz continuous. Since this latter condition is hardy fulfilled in practice, even for Lipschitz Markov Decision Processes and policies, we propose a relaxed setting, proving that value function is always H\&quot;older continuous. This result is of independent interest and allows obtaining in BC a general bound for the performance of the imitator policy. Finally, we analyze noise injection, a common practice in which the expert&#39;s action is executed in the environment after the application of a noise kernel. We show that this practice allows deriving stronger performance guarantees, at the price of a bias due to the noise addition.},
  archive   = {C_AAAI},
  author    = {Davide Maran and Alberto Maria Metelli and Marcello Restelli},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i8.26089},
  pages     = {9073-9080},
  title     = {Tight performance guarantees of imitator policies with continuous actions},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Online reinforcement learning with uncertain episode
lengths. <em>AAAI</em>, 9064–9071. (<a
href="https://doi.org/10.1609/aaai.v37i7.26088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Existing episodic reinforcement algorithms assume that the length of an episode is fixed across time and known a priori. In this paper, we consider a general framework of episodic reinforcement learning when the length of each episode is drawn from a distribution. We first establish that this problem is equivalent to online reinforcement learning with general discounting where the learner is trying to optimize the expected discounted sum of rewards over an infinite horizon, but where the discounting function is not necessarily geometric. We show that minimizing regret with this new general discounting is equivalent to minimizing regret with uncertain episode lengths. We then design a reinforcement learning algorithm that minimizes regret with general discounting but acts for the setting with uncertain episode lengths. We instantiate our general bound for different types of discounting, including geometric and polynomial discounting. We also show that we can obtain similar regret bounds even when the uncertainty over the episode lengths is unknown, by estimating the unknown distribution over time. Finally, we compare our learning algorithms with existing value-iteration based episodic RL algorithms on a grid-world environment.},
  archive   = {C_AAAI},
  author    = {Debmalya Mandal and Goran Radanovic and Jiarui Gan and Adish Singla and Rupak Majumdar},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26088},
  pages     = {9064-9071},
  title     = {Online reinforcement learning with uncertain episode lengths},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Proximal stochastic recursive momentum methods for nonconvex
composite decentralized optimization. <em>AAAI</em>, 9055–9063. (<a
href="https://doi.org/10.1609/aaai.v37i7.26087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Consider a network of N decentralized computing agents collaboratively solving a nonconvex stochastic composite problem. In this work, we propose a single-loop algorithm, called DEEPSTORM, that achieves optimal sample complexity for this setting. Unlike double-loop algorithms that require a large batch size to compute the (stochastic) gradient once in a while, DEEPSTORM uses a small batch size, creating advantages in occasions such as streaming data and online learning. This is the first method achieving optimal sample complexity for decentralized nonconvex stochastic composite problems, requiring O(1) batch size. We conduct convergence analysis for DEEPSTORM with both constant and diminishing step sizes. Additionally, under proper initialization and a small enough desired solution error, we show that DEEPSTORM with a constant step size achieves a network-independent sample complexity, with an additional linear speed-up with respect to N over centralized methods. All codes are made available at https://github.com/gmancino/DEEPSTORM.},
  archive   = {C_AAAI},
  author    = {Gabriel Mancino-Ball and Shengnan Miao and Yangyang Xu and Jie Chen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26087},
  pages     = {9055-9063},
  title     = {Proximal stochastic recursive momentum methods for nonconvex composite decentralized optimization},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). LIMIP: Lifelong learning to solve mixed integer programs.
<em>AAAI</em>, 9047–9054. (<a
href="https://doi.org/10.1609/aaai.v37i7.26086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Mixed Integer programs (MIPs) are typically solved by the Branch-and-Bound algorithm. Recently, Learning to imitate fast approximations of the expert strong branching heuristic has gained attention due to its success in reducing the running time for solving MIPs. However, existing learning-to-branch methods assume that the entire training data is available in a single session of training. This assumption is often not true, and if the training data is supplied in continual fashion over time, existing techniques suffer from catastrophic forgetting. In this work, we study the hitherto unexplored paradigm of Lifelong Learning to Branch on Mixed Integer Programs. To mitigate catastrophic forgetting, we propose LIMIP, which is powered by the idea of modeling an MIP instance in the form of a bipartite graph, which we map to an embedding space using a bipartite Graph Attention Network. This rich embedding space avoids catastrophic forgetting through the application of knowledge distillation and elastic weight consolidation, wherein we learn the parameters key towards retaining efficacy and are therefore protected from significant drift. We evaluate LIMIP on a series of NP-hard problems and establish that in comparison to existing baselines, LIMIP is up to 50\% better when confronted with lifelong learning},
  archive   = {C_AAAI},
  author    = {Sahil Manchanda and Sayan Ranu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26086},
  pages     = {9047-9054},
  title     = {LIMIP: Lifelong learning to solve mixed integer programs},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Recovering the graph underlying networked dynamical systems
under partial observability: A deep learning approach. <em>AAAI</em>,
9038–9046. (<a href="https://doi.org/10.1609/aaai.v37i7.26085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the problem of graph structure identification, i.e., of recovering the graph of dependencies among time series. We model these time series data as components of the state of linear stochastic networked dynamical systems. We assume partial observability, where the state evolution of only a subset of nodes comprising the network is observed. We propose a new feature-based paradigm: to each pair of nodes, we compute a feature vector from the observed time series. We prove that these features are linearly separable, i.e., there exists a hyperplane that separates the cluster of features associated with connected pairs of nodes from those of disconnected pairs. This renders the features amenable to train a variety of classifiers to perform causal inference. In particular, we use these features to train Convolutional Neural Networks (CNNs). The resulting causal inference mechanism outperforms state-of-the-art counterparts w.r.t. sample-complexity. The trained CNNs generalize well over structurally distinct networks (dense or sparse) and noise-level profiles. Remarkably, they also generalize well to real-world networks while trained over a synthetic network -- namely, a particular realization of a random graph.},
  archive   = {C_AAAI},
  author    = {Sérgio Machado and Anirudh Sridhar and Paulo Gil and Jorge Henriques and José M. F. Moura and Augusto Santos},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26085},
  pages     = {9038-9046},
  title     = {Recovering the graph underlying networked dynamical systems under partial observability: A deep learning approach},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). OMPQ: Orthogonal mixed precision quantization.
<em>AAAI</em>, 9029–9037. (<a
href="https://doi.org/10.1609/aaai.v37i7.26084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {To bridge the ever-increasing gap between deep neural networks&#39; complexity and hardware capability, network quantization has attracted more and more research attention. The latest trend of mixed precision quantization takes advantage of hardware&#39;s multiple bit-width arithmetic operations to unleash the full potential of network quantization. However, existing approaches rely heavily on an extremely time-consuming search process and various relaxations when seeking the optimal bit configuration. To address this issue, we propose to optimize a proxy metric of network orthogonality that can be efficiently solved with linear programming, which proves to be highly correlated with quantized model accuracy and bit-width. Our approach significantly reduces the search time and the required data amount by orders of magnitude, but without a compromise on quantization accuracy. Specifically, we achieve 72.08\% Top-1 accuracy on ResNet-18 with 6.7Mb parameters, which does not require any searching iterations. Given the high efficiency and low data dependency of our algorithm, we use it for the post-training quantization, which achieves 71.27\% Top-1 accuracy on MobileNetV2 with only 1.5Mb parameters.},
  archive   = {C_AAAI},
  author    = {Yuexiao Ma and Taisong Jin and Xiawu Zheng and Yan Wang and Huixia Li and Yongjian Wu and Guannan Jiang and Wei Zhang and Rongrong Ji},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26084},
  pages     = {9029-9037},
  title     = {OMPQ: Orthogonal mixed precision quantization},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Poisoning with cerberus: Stealthy and colluded backdoor
attack against federated learning. <em>AAAI</em>, 9020–9028. (<a
href="https://doi.org/10.1609/aaai.v37i7.26083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Are Federated Learning (FL) systems free from backdoor poisoning with the arsenal of various defense strategies deployed? This is an intriguing problem with significant practical implications regarding the utility of FL services. Despite the recent flourish of poisoning-resilient FL methods, our study shows that carefully tuning the collusion between malicious participants can minimize the trigger-induced bias of the poisoned local model from the poison-free one, which plays the key role in delivering stealthy backdoor attacks and circumventing a wide spectrum of state-of-the-art defense methods in FL. In our work, we instantiate the attack strategy by proposing a distributed backdoor attack method, namely Cerberus Poisoning (CerP). It jointly tunes the backdoor trigger and controls the poisoned model changes on each malicious participant to achieve a stealthy yet successful backdoor attack against a wide spectrum of defensive mechanisms of federated learning techniques. Our extensive study on 3 large-scale benchmark datasets and 13 mainstream defensive mechanisms confirms that Cerberus Poisoning raises a significantly severe threat to the integrity and security of federated learning practices, regardless of the flourish of robust Federated Learning methods.},
  archive   = {C_AAAI},
  author    = {Xiaoting Lyu and Yufei Han and Wei Wang and Jingkai Liu and Bin Wang and Jiqiang Liu and Xiangliang Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26083},
  pages     = {9020-9028},
  title     = {Poisoning with cerberus: Stealthy and colluded backdoor attack against federated learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Compositional prototypical networks for few-shot
classification. <em>AAAI</em>, 9011–9019. (<a
href="https://doi.org/10.1609/aaai.v37i7.26082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {It is assumed that pre-training provides the feature extractor with strong class transferability and that high novel class generalization can be achieved by simply reusing the transferable feature extractor. In this work, our motivation is to explicitly learn some fine-grained and transferable meta-knowledge so that feature reusability can be further improved. Concretely, inspired by the fact that humans can use learned concepts or components to help them recognize novel classes, we propose Compositional Prototypical Networks (CPN) to learn a transferable prototype for each human-annotated attribute, which we call a component prototype. We empirically demonstrate that the learned component prototypes have good class transferability and can be reused to construct compositional prototypes for novel classes. Then a learnable weight generator is utilized to adaptively fuse the compositional and visual prototypes. Extensive experiments demonstrate that our method can achieve state-of-the-art results on different datasets and settings. The performance gains are especially remarkable in the 5-way 1-shot setting. The code is available at https://github.com/fikry102/CPN.},
  archive   = {C_AAAI},
  author    = {Qiang Lyu and Weiqiang Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26082},
  pages     = {9011-9019},
  title     = {Compositional prototypical networks for few-shot classification},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Local explanations for reinforcement learning.
<em>AAAI</em>, 9002–9010. (<a
href="https://doi.org/10.1609/aaai.v37i7.26081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Many works in explainable AI have focused on explaining black-box classification models. Explaining deep reinforcement learning (RL) policies in a manner that could be understood by domain users has received much less attention. In this paper, we propose a novel perspective to understanding RL policies based on identifying important states from automatically learned meta-states. The key conceptual difference between our approach and many previous ones is that we form meta-states based on locality governed by the expert policy dynamics rather than based on similarity of actions, and that we do not assume any particular knowledge of the underlying topology of the state space. Theoretically, we show that our algorithm to find meta-states converges and the objective that selects important states from each meta-state is submodular leading to efficient high quality greedy selection. Experiments on four domains (four rooms, door-key, minipacman, and pong) and a carefully conducted user study illustrate that our perspective leads to better understanding of the policy. We conjecture that this is a result of our meta-states being more intuitive in that the corresponding important states are strong indicators of tractable intermediate goals that are easier for humans to interpret and follow.},
  archive   = {C_AAAI},
  author    = {Ronny Luss and Amit Dhurandhar and Miao Liu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26081},
  pages     = {9002-9010},
  title     = {Local explanations for reinforcement learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MVCINN: Multi-view diabetic retinopathy detection using a
deep cross-interaction neural network. <em>AAAI</em>, 8993–9001. (<a
href="https://doi.org/10.1609/aaai.v37i7.26080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Diabetic retinopathy (DR) is the main cause of irreversible blindness for working-age adults. The previous models for DR detection have difficulties in clinical application. The main reason is that most of the previous methods only use single-view data, and the single field of view (FOV) only accounts for about 13\% of the FOV of the retina, resulting in the loss of most lesion features. To alleviate this problem, we propose a multi-view model for DR detection, which takes full advantage of multi-view images covering almost all of the retinal field. To be specific, we design a Cross-Interaction Self-Attention based Module (CISAM) that interfuses local features extracted from convolutional blocks with long-range global features learned from transformer blocks. Furthermore, considering the pathological association in different views, we use the feature jigsaw to assemble and learn the features of multiple views. Extensive experiments on the latest public multi-view MFIDDR dataset with 34,452 images demonstrate the superiority of our method, which performs favorably against state-of-the-art models. To the best of our knowledge, this work is the first study on the public large-scale multi-view fundus images dataset for DR detection.},
  archive   = {C_AAAI},
  author    = {Xiaoling Luo and Chengliang Liu and Waikeung Wong and Jie Wen and Xiaopeng Jin and Yong Xu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26080},
  pages     = {8993-9001},
  title     = {MVCINN: Multi-view diabetic retinopathy detection using a deep cross-interaction neural network},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Crowd-level abnormal behavior detection via multi-scale
motion consistency learning. <em>AAAI</em>, 8984–8992. (<a
href="https://doi.org/10.1609/aaai.v37i7.26079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Detecting abnormal crowd motion emerging from complex interactions of individuals is paramount to ensure the safety of crowds. Crowd-level abnormal behaviors (CABs), e.g., counter flow and crowd turbulence, are proven to be the crucial causes of many crowd disasters. In the recent decade, video anomaly detection (VAD) techniques have achieved remarkable success in detecting individual-level abnormal behaviors (e.g., sudden running, fighting and stealing), but research on VAD for CABs is rather limited. Unlike individual-level anomaly, CABs usually do not exhibit salient difference from the normal behaviors when observed locally, and the scale of CABs could vary from one scenario to another. In this paper, we present a systematic study to tackle the important problem of VAD for CABs with a novel crowd motion learning framework, multi-scale motion consistency network (MSMC-Net). MSMC-Net first captures the spatial and temporal crowd motion consistency information in a graph representation. Then, it simultaneously trains multiple feature graphs constructed at different scales to capture rich crowd patterns. An attention network is used to adaptively fuse the multi-scale features for better CAB detection. For the empirical study, we consider three large-scale crowd event datasets, UMN, Hajj and Love Parade. Experimental results show that MSMC-Net could substantially improve the state-of-the-art performance on all the datasets.},
  archive   = {C_AAAI},
  author    = {Linbo Luo and Yuanjing Li and Haiyan Yin and Shangwei Xie and Ruimin Hu and Wentong Cai},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26079},
  pages     = {8984-8992},
  title     = {Crowd-level abnormal behavior detection via multi-scale motion consistency learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generative label enhancement with gaussian mixture and
partial ranking. <em>AAAI</em>, 8975–8983. (<a
href="https://doi.org/10.1609/aaai.v37i7.26078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Label distribution learning (LDL) is an effective learning paradigm for dealing with label ambiguity. When applying LDL, the datasets annotated with label distributions (i.e., the real-valued vectors like the probability distribution) are typically required. Unfortunately, most existing datasets only contain the logical labels, and manual annotating with label distributions is costly. To address this problem, we treat the label distribution as a latent vector and infer its posterior by variational Bayes. Specifically, we propose a generative label enhancement model to encode the process of generating feature vectors and logical label vectors from label distributions in a principled way. In terms of features, we assume that the feature vector is generated by a Gaussian mixture dominated by the label distribution, which captures the one-to-many relationship from the label distribution to the feature vector and thus reduces the feature generation error. In terms of logical labels, we design a probability distribution to generate the logical label vector from a label distribution, which captures partial label ranking in the logical label vector and thus provides a more accurate guidance for inferring the label distribution. Besides, to approximate the posterior of the label distribution, we design a inference model, and derive the variational learning objective. Finally, extensive experiments on real-world datasets validate our proposal.},
  archive   = {C_AAAI},
  author    = {Yunan Lu and Liang He and Fan Min and Weiwei Li and Xiuyi Jia},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26078},
  pages     = {8975-8983},
  title     = {Generative label enhancement with gaussian mixture and partial ranking},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-view domain adaptive object detection on camera
networks. <em>AAAI</em>, 8966–8974. (<a
href="https://doi.org/10.1609/aaai.v37i7.26077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we study a new domain adaptation setting on camera networks, namely Multi-View Domain Adaptive Object Detection (MVDA-OD), in which labeled source data is unavailable in the target adaptation process and target data is captured from multiple overlapping cameras. In such a challenging context, existing methods including adversarial training and self-training fall short due to multi-domain data shift and the lack of source data. To tackle this problem, we propose a novel training framework consisting of two stages. First, we pre-train the backbone using self-supervised learning, in which a multi-view association is developed to construct an effective pretext task. Second, we fine-tune the detection head using robust self-training, where a tracking-based single-view augmentation is introduced to achieve weak-hard consistency learning. By doing so, an object detection model can take advantage of informative samples generated by multi-view association and single-view augmentation to learn discriminative backbones as well as robust detection classifiers. Experiments on two real-world multi-camera datasets demonstrate significant advantages of our approach over the state-of-the-art domain adaptive object detection methods.},
  archive   = {C_AAAI},
  author    = {Yan Lu and Zhun Zhong and Yuanchao Shu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26077},
  pages     = {8966-8974},
  title     = {Multi-view domain adaptive object detection on camera networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PINAT: A permutation INvariance augmented transformer for
NAS predictor. <em>AAAI</em>, 8957–8965. (<a
href="https://doi.org/10.1609/aaai.v37i7.26076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Time-consuming performance evaluation is the bottleneck of traditional Neural Architecture Search (NAS) methods. Predictor-based NAS can speed up performance evaluation by directly predicting performance, rather than training a large number of sub-models and then validating their performance. Most predictor-based NAS approaches use a proxy dataset to train model-based predictors efficiently but suffer from performance degradation and generalization problems. We attribute these problems to the poor abilities of existing predictors to character the sub-models&#39; structure, specifically the topology information extraction and the node feature representation of the input graph data. To address these problems, we propose a Transformer-like NAS predictor PINAT, consisting of a Permutation INvariance Augmentation module serving as both token embedding layer and self-attention head, as well as a Laplacian matrix to be the positional encoding. Our design produces more representative features of the encoded architecture and outperforms state-of-the-art NAS predictors on six search spaces: NAS-Bench-101, NAS-Bench-201, DARTS, ProxylessNAS, PPI, and ModelNet. The code is available at https://github.com/ShunLu91/PINAT.},
  archive   = {C_AAAI},
  author    = {Shun Lu and Yu Hu and Peihao Wang and Yan Han and Jianchao Tan and Jixiang Li and Sen Yang and Ji Liu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26076},
  pages     = {8957-8965},
  title     = {PINAT: A permutation INvariance augmented transformer for NAS predictor},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Centerless multi-view k-means based on the adjacency matrix.
<em>AAAI</em>, 8949–8956. (<a
href="https://doi.org/10.1609/aaai.v37i7.26075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Although K-Means clustering has been widely studied due to its simplicity, these methods still have the following fatal drawbacks. Firstly, they need to initialize the cluster centers, which causes unstable clustering performance. Secondly, they have poor performance on non-Gaussian datasets. Inspired by the affinity matrix, we propose a novel multi-view K-Means based on the adjacency matrix. It maps the affinity matrix to the distance matrix according to the principle that every sample has a small distance from the points in its neighborhood and a large distance from the points outside of the neighborhood. Moreover, this method well exploits the complementary information embedded in different views by minimizing the tensor Schatten p-norm regularize on the third-order tensor which consists of cluster assignment matrices of different views. Additionally, this method avoids initializing cluster centroids to obtain stable performance. And there is no need to compute the means of clusters so that our model is not sensitive to outliers. Experiment on a toy dataset shows the excellent performance on non-Gaussian datasets. And other experiments on several benchmark datasets demonstrate the superiority of our proposed method.},
  archive   = {C_AAAI},
  author    = {Han Lu and Quanxue Gao and Qianqian Wang and Ming Yang and Wei Xia},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26075},
  pages     = {8949-8956},
  title     = {Centerless multi-view K-means based on the adjacency matrix},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A coreset learning reality check. <em>AAAI</em>, 8940–8948.
(<a href="https://doi.org/10.1609/aaai.v37i7.26074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Subsampling algorithms are a natural approach to reduce data size before fitting models on massive datasets. In recent years, several works have proposed methods for subsampling rows from a data matrix while maintaining relevant information for classification. While these works are supported by theory and limited experiments, to date there has not been a comprehensive evaluation of these methods. In our work, we directly compare multiple methods for logistic regression drawn from the coreset and optimal subsampling literature and discover inconsistencies in their effectiveness. In many cases, methods do not outperform simple uniform subsampling.},
  archive   = {C_AAAI},
  author    = {Fred Lu and Edward Raff and James Holt},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26074},
  pages     = {8940-8948},
  title     = {A coreset learning reality check},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Q-functionals for value-based continuous control.
<em>AAAI</em>, 8932–8939. (<a
href="https://doi.org/10.1609/aaai.v37i7.26073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present Q-functionals, an alternative architecture for continuous control deep reinforcement learning. Instead of returning a single value for a state-action pair, our network transforms a state into a function that can be rapidly evaluated in parallel for many actions, allowing us to efficiently choose high-value actions through sampling. This contrasts with the typical architecture of off-policy continuous control, where a policy network is trained for the sole purpose of selecting actions from the Q-function. We represent our action-dependent Q-function as a weighted sum of basis functions (Fourier, Polynomial, etc) over the action space, where the weights are state-dependent and output by the Q-functional network. Fast sampling makes practical a variety of techniques that require Monte-Carlo integration over Q-functions, and enables action-selection strategies besides simple value-maximization. We characterize our framework, describe various implementations of Q-functionals, and demonstrate strong performance on a suite of continuous control tasks.},
  archive   = {C_AAAI},
  author    = {Samuel Lobel and Sreehari Rammohan and Bowen He and Shangqun Yu and George Konidaris},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26073},
  pages     = {8932-8939},
  title     = {Q-functionals for value-based continuous control},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Temporal-frequency co-training for time series
semi-supervised learning. <em>AAAI</em>, 8923–8931. (<a
href="https://doi.org/10.1609/aaai.v37i7.26072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Semi-supervised learning (SSL) has been actively studied due to its ability to alleviate the reliance of deep learning models on labeled data. Although existing SSL methods based on pseudo-labeling strategies have made great progress, they rarely consider time-series data&#39;s intrinsic properties (e.g., temporal dependence). Learning representations by mining the inherent properties of time series has recently gained much attention. Nonetheless, how to utilize feature representations to design SSL paradigms for time series has not been explored. To this end, we propose a Time Series SSL framework via Temporal-Frequency Co-training (TS-TFC), leveraging the complementary information from two distinct views for unlabeled data learning. In particular, TS-TFC employs time-domain and frequency-domain views to train two deep neural networks simultaneously, and each view&#39;s pseudo-labels generated by label propagation in the representation space are adopted to guide the training of the other view&#39;s classifier. To enhance the discriminative of representations between categories, we propose a temporal-frequency supervised contrastive learning module, which integrates the learning difficulty of categories to improve the quality of pseudo-labels. Through co-training the pseudo-labels obtained from temporal-frequency representations, the complementary information in the two distinct views is exploited to enable the model to better learn the distribution of categories. Extensive experiments on 106 UCR datasets show that TS-TFC outperforms state-of-the-art methods, demonstrating the effectiveness and robustness of our proposed model.},
  archive   = {C_AAAI},
  author    = {Zhen Liu and Qianli Ma and Peitian Ma and Linghao Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26072},
  pages     = {8923-8931},
  title     = {Temporal-frequency co-training for time series semi-supervised learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hard sample aware network for contrastive deep graph
clustering. <em>AAAI</em>, 8914–8922. (<a
href="https://doi.org/10.1609/aaai.v37i7.26071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Contrastive deep graph clustering, which aims to divide nodes into disjoint groups via contrastive mechanisms, is a challenging research spot. Among the recent works, hard sample mining-based algorithms have achieved great attention for their promising performance. However, we find that the existing hard sample mining methods have two problems as follows. 1) In the hardness measurement, the important structural information is overlooked for similarity calculation, degrading the representativeness of the selected hard negative samples. 2) Previous works merely focus on the hard negative sample pairs while neglecting the hard positive sample pairs. Nevertheless, samples within the same cluster but with low similarity should also be carefully learned. To solve the problems, we propose a novel contrastive deep graph clustering method dubbed Hard Sample Aware Network (HSAN) by introducing a comprehensive similarity measure criterion and a general dynamic sample weighing strategy. Concretely, in our algorithm, the similarities between samples are calculated by considering both the attribute embeddings and the structure embeddings, better revealing sample relationships and assisting hardness measurement. Moreover, under the guidance of the carefully collected high-confidence clustering information, our proposed weight modulating function will first recognize the positive and negative samples and then dynamically up-weight the hard sample pairs while down-weighting the easy ones. In this way, our method can mine not only the hard negative samples but also the hard positive sample, thus improving the discriminative capability of the samples further. Extensive experiments and analyses demonstrate the superiority and effectiveness of our proposed method. The source code of HSAN is shared at https://github.com/yueliu1999/HSAN and a collection (papers, codes and, datasets) of deep graph clustering is shared at https://github.com/yueliu1999/Awesome-Deep-Graph-Clustering on Github.},
  archive   = {C_AAAI},
  author    = {Yue Liu and Xihong Yang and Sihang Zhou and Xinwang Liu and Zhen Wang and Ke Liang and Wenxuan Tu and Liang Li and Jingcan Duan and Cancan Chen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26071},
  pages     = {8914-8922},
  title     = {Hard sample aware network for contrastive deep graph clustering},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). Online hyperparameter optimization for class-incremental
learning. <em>AAAI</em>, 8906–8913. (<a
href="https://doi.org/10.1609/aaai.v37i7.26070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Class-incremental learning (CIL) aims to train a classification model while the number of classes increases phase-by-phase. An inherent challenge of CIL is the stability-plasticity tradeoff, i.e., CIL models should keep stable to retain old knowledge and keep plastic to absorb new knowledge. However, none of the existing CIL models can achieve the optimal tradeoff in different data-receiving settings—where typically the training-from-half (TFH) setting needs more stability, but the training-from-scratch (TFS) needs more plasticity. To this end, we design an online learning method that can adaptively optimize the tradeoff without knowing the setting as a priori. Specifically, we first introduce the key hyperparameters that influence the tradeoff, e.g., knowledge distillation (KD) loss weights, learning rates, and classifier types. Then, we formulate the hyperparameter optimization process as an online Markov Decision Process (MDP) problem and propose a specific algorithm to solve it. We apply local estimated rewards and a classic bandit algorithm Exp3 to address the issues when applying online MDP methods to the CIL protocol. Our method consistently improves top-performing CIL methods in both TFH and TFS settings, e.g., boosting the average accuracy of TFH and TFS by 2.2 percentage points on ImageNet-Full, compared to the state-of-the-art. Code is provided at https://class-il.mpi-inf.mpg.de/online/},
  archive   = {C_AAAI},
  author    = {Yaoyao Liu and Yingying Li and Bernt Schiele and Qianru Sun},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26070},
  pages     = {8906-8913},
  title     = {Online hyperparameter optimization for class-incremental learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). EASAL: Entity-aware subsequence-based active learning for
named entity recognition. <em>AAAI</em>, 8897–8905. (<a
href="https://doi.org/10.1609/aaai.v37i7.26069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Active learning is a critical technique for reducing labelling load by selecting the most informative data. Most previous works applied active learning on Named Entity Recognition (token-level task) similar to the text classification (sentence-level task). They failed to consider the heterogeneity of uncertainty within each sentence and required access to the entire sentence for the annotator when labelling. To overcome the mentioned limitations, in this paper, we allow the active learning algorithm to query subsequences within sentences and propose an Entity-Aware Subsequences-based Active Learning (EASAL) that utilizes an effective Head-Tail pointer to query one entity-aware subsequence for each sentence based on BERT. For other tokens outside this subsequence, we randomly select 30\% of these tokens to be pseudo-labelled for training together where the model directly predicts their pseudo-labels. Experimental results on both news and biomedical datasets demonstrate the effectiveness of our proposed method. The code is released at https://github.com/lylylylylyly/EASAL.},
  archive   = {C_AAAI},
  author    = {Yang Liu and Jinpeng Hu and Zhihong Chen and Xiang Wan and Tsung-Hui Chang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26069},
  pages     = {8897-8905},
  title     = {EASAL: Entity-aware subsequence-based active learning for named entity recognition},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Coupling artificial neurons in BERT and biological neurons
in the human brain. <em>AAAI</em>, 8888–8896. (<a
href="https://doi.org/10.1609/aaai.v37i7.26068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Linking computational natural language processing (NLP) models and neural responses to language in the human brain on the one hand facilitates the effort towards disentangling the neural representations underpinning language perception, on the other hand provides neurolinguistics evidence to evaluate and improve NLP models. Mappings of an NLP model’s representations of and the brain activities evoked by linguistic input are typically deployed to reveal this symbiosis. However, two critical problems limit its advancement: 1) The model’s representations (artificial neurons, ANs) rely on layer-level embeddings and thus lack fine-granularity; 2) The brain activities (biological neurons, BNs) are limited to neural recordings of isolated cortical unit (i.e., voxel/region) and thus lack integrations and interactions among brain functions. To address those problems, in this study, we 1) define ANs with fine-granularity in transformer-based NLP models (BERT in this study) and measure their temporal activations to input text sequences; 2) define BNs as functional brain networks (FBNs) extracted from functional magnetic resonance imaging (fMRI) data to capture functional interactions in the brain; 3) couple ANs and BNs by maximizing the synchronization of their temporal activations. Our experimental results demonstrate 1) The activations of ANs and BNs are significantly synchronized; 2) the ANs carry meaningful linguistic/semantic information and anchor to their BN signatures; 3) the anchored BNs are interpretable in a neurolinguistic context. Overall, our study introduces a novel, general, and effective framework to link transformer-based NLP models and neural activities in response to language and may provide novel insights for future studies such as brain-inspired evaluation and development of NLP models.},
  archive   = {C_AAAI},
  author    = {Xu Liu and Mengyue Zhou and Gaosheng Shi and Yu Du and Lin Zhao and Zihao Wu and David Liu and Tianming Liu and Xintao Hu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26068},
  pages     = {8888-8896},
  title     = {Coupling artificial neurons in BERT and biological neurons in the human brain},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Tensor compressive sensing fused low-rankness and
local-smoothness. <em>AAAI</em>, 8879–8887. (<a
href="https://doi.org/10.1609/aaai.v37i7.26067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A plethora of previous studies indicates that making full use of multifarious intrinsic properties of primordial data is a valid pathway to recover original images from their degraded observations. Typically, both low-rankness and local-smoothness broadly exist in real-world tensor data such as hyperspectral images and videos. Modeling based on both properties has received a great deal of attention, whereas most studies concentrate on experimental performance, and theoretical investigations are still lacking. In this paper, we study the tensor compressive sensing problem based on the tensor correlated total variation, which is a new regularizer used to simultaneously capture both properties existing in the same dataset. The new regularizer has the outstanding advantage of not using a trade-off parameter to balance the two properties. The obtained theories provide a robust recovery guarantee, where the error bound shows that our model certainly benefits from both properties in ground-truth data adaptively. Moreover, based on the ADMM update procedure, we design an algorithm with a global convergence guarantee to solve this model. At last, we carry out experiments to apply our model to hyperspectral image and video restoration problems. The experimental results show that our method is prominently better than many other competing ones. Our code and Supplementary Material are available at https://github.com/fsliuxl/cs-tctv.},
  archive   = {C_AAAI},
  author    = {Xinling Liu and Jingyao Hou and Jiangjun Peng and Hailin Wang and Deyu Meng and Jianjun Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26067},
  pages     = {8879-8887},
  title     = {Tensor compressive sensing fused low-rankness and local-smoothness},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). Safe multi-view deep classification. <em>AAAI</em>,
8870–8878. (<a href="https://doi.org/10.1609/aaai.v37i7.26066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-view deep classification expects to obtain better classification performance than using a single view. However, due to the uncertainty and inconsistency of data sources, adding data views does not necessarily lead to the performance improvements in multi-view classification. How to avoid worsening classification performance when adding views is crucial for multi-view deep learning but rarely studied. To tackle this limitation, in this paper, we reformulate the multi-view classification problem from the perspective of safe learning and thereby propose a Safe Multi-view Deep Classification (SMDC) method, which can guarantee that the classification performance does not deteriorate when fusing multiple views. In the SMDC method, we dynamically integrate multiple views and estimate the inherent uncertainties among multiple views with different root causes based on evidence theory. Through minimizing the uncertainties, SMDC promotes the evidences from data views for correct classification, and in the meantime excludes the incorrect evidences to produce the safe multi-view classification results. Furthermore, we theoretically prove that in the safe multi-view classification, adding data views will certainly not increase the empirical risk of classification. The experiments on various kinds of multi-view datasets validate that the proposed SMDC method can achieve precise and safe classification results.},
  archive   = {C_AAAI},
  author    = {Wei Liu and Yufei Chen and Xiaodong Yue and Changqing Zhang and Shaorong Xie},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26066},
  pages     = {8870-8878},
  title     = {Safe multi-view deep classification},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enhancing the antidote: Improved pointwise certifications
against poisoning attacks. <em>AAAI</em>, 8861–8869. (<a
href="https://doi.org/10.1609/aaai.v37i7.26065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Poisoning attacks can disproportionately influence model behaviour by making small changes to the training corpus. While defences against specific poisoning attacks do exist, they in general do not provide any guarantees, leaving them potentially countered by novel attacks. In contrast, by examining worst-case behaviours Certified Defences make it possible to provide guarantees of the robustness of a sample against adversarial attacks modifying a finite number of training samples, known as pointwise certification. We achieve this by exploiting both Differential Privacy and the Sampled Gaussian Mechanism to ensure the invariance of prediction for each testing instance against finite numbers of poisoned examples. In doing so, our model provides guarantees of adversarial robustness that are more than twice as large as those provided by prior certifications.},
  archive   = {C_AAAI},
  author    = {Shijie Liu and Andrew C. Cullen and Paul Montague and Sarah M. Erfani and Benjamin I. P. Rubinstein},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26065},
  pages     = {8861-8869},
  title     = {Enhancing the antidote: Improved pointwise certifications against poisoning attacks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reliable robustness evaluation via automatically constructed
attack ensembles. <em>AAAI</em>, 8852–8860. (<a
href="https://doi.org/10.1609/aaai.v37i7.26064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Attack Ensemble (AE), which combines multiple attacks together, provides a reliable way to evaluate adversarial robustness. In practice, AEs are often constructed and tuned by human experts, which however tends to be sub-optimal and time-consuming. In this work, we present AutoAE, a conceptually simple approach for automatically constructing AEs. In brief, AutoAE repeatedly adds the attack and its iteration steps to the ensemble that maximizes ensemble improvement per additional iteration consumed. We show theoretically that AutoAE yields AEs provably within a constant factor of the optimal for a given defense. We then use AutoAE to construct two AEs for l∞ and l2 attacks, and apply them without any tuning or adaptation to 45 top adversarial defenses on the RobustBench leaderboard. In all except one cases we achieve equal or better (often the latter) robustness evaluation than existing AEs, and notably, in 29 cases we achieve better robustness evaluation than the best known one. Such performance of AutoAE shows itself as a reliable evaluation protocol for adversarial robustness, which further indicates the huge potential of automatic AE construction. Code is available at https://github.com/LeegerPENG/AutoAE.},
  archive   = {C_AAAI},
  author    = {Shengcai Liu and Fu Peng and Ke Tang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26064},
  pages     = {8852-8860},
  title     = {Reliable robustness evaluation via automatically constructed attack ensembles},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust representation learning by clustering with
bisimulation metrics for visual reinforcement learning with
distractions. <em>AAAI</em>, 8843–8851. (<a
href="https://doi.org/10.1609/aaai.v37i7.26063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent work has shown that representation learning plays a critical role in sample-efficient reinforcement learning (RL) from pixels. Unfortunately, in real-world scenarios, representation learning is usually fragile to task-irrelevant distractions such as variations in background or viewpoint. To tackle this problem, we propose a novel clustering-based approach, namely Clustering with Bisimulation Metrics (CBM), which learns robust representations by grouping visual observations in the latent space. Specifically, CBM alternates between two steps: (1) grouping observations by measuring their bisimulation distances to the learned prototypes; (2) learning a set of prototypes according to the current cluster assignments. Computing cluster assignments with bisimulation metrics enables CBM to capture task-relevant information, as bisimulation metrics quantify the behavioral similarity between observations. Moreover, CBM encourages the consistency of representations within each group, which facilitates filtering out task-irrelevant information and thus induces robust representations against distractions. An appealing feature is that CBM can achieve sample-efficient representation learning even if multiple distractions exist simultaneously. Experiments demonstrate that CBM significantly improves the sample efficiency of popular visual RL algorithms and achieves state-of-the-art performance on both multiple and single distraction settings. The code is available at https://github.com/MIRALab-USTC/RL-CBM.},
  archive   = {C_AAAI},
  author    = {Qiyuan Liu and Qi Zhou and Rui Yang and Jie Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26063},
  pages     = {8843-8851},
  title     = {Robust representation learning by clustering with bisimulation metrics for visual reinforcement learning with distractions},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Combating mode collapse via offline manifold entropy
estimation. <em>AAAI</em>, 8834–8842. (<a
href="https://doi.org/10.1609/aaai.v37i7.26062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Generative Adversarial Networks (GANs) have shown compelling results in various tasks and applications in recent years. However, mode collapse remains a critical problem in GANs. In this paper, we propose a novel training pipeline to address the mode collapse issue of GANs. Different from existing methods, we propose to generalize the discriminator as feature embedding and maximize the entropy of distributions in the embedding space learned by the discriminator. Specifically, two regularization terms, i.e., Deep Local Linear Embedding (DLLE) and Deep Isometric feature Mapping (DIsoMap), are introduced to encourage the discriminator to learn the structural information embedded in the data, such that the embedding space learned by the discriminator can be well-formed. Based on the well-learned embedding space supported by the discriminator, a non-parametric entropy estimator is designed to efficiently maximize the entropy of embedding vectors, playing as an approximation of maximizing the entropy of the generated distribution. By improving the discriminator and maximizing the distance of the most similar samples in the embedding space, our pipeline effectively reduces the mode collapse without sacrificing the quality of generated samples. Extensive experimental results show the effectiveness of our method which outperforms the GAN baseline, MaF-GAN on CelebA (9.13 vs. 12.43 in FID) and surpasses the recent state-of-the-art energy-based model on the ANIMEFACE dataset (2.80 vs. 2.26 in Inception score).},
  archive   = {C_AAAI},
  author    = {Haozhe Liu and Bing Li and Haoqian Wu and Hanbang Liang and Yawen Huang and Yuexiang Li and Bernard Ghanem and Yefeng Zheng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26062},
  pages     = {8834-8842},
  title     = {Combating mode collapse via offline manifold entropy estimation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive discrete communication bottlenecks with dynamic
vector quantization for heterogeneous representational coarseness.
<em>AAAI</em>, 8825–8833. (<a
href="https://doi.org/10.1609/aaai.v37i7.26061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Vector Quantization (VQ) is a method for discretizing latent representations and has become a major part of the deep learning toolkit. It has been theoretically and empirically shown that discretization of representations leads to improved generalization, including in reinforcement learning where discretization can be used to bottleneck multi-agent communication to promote agent specialization and robustness. The discretization tightness of most VQ-based methods is defined by the number of discrete codes in the representation vector and the codebook size, which are fixed as hyperparameters. In this work, we propose learning to dynamically select discretization tightness conditioned on inputs, based on the hypothesis that data naturally contains variations in complexity that call for different levels of representational coarseness which is observed in many heterogeneous data sets. We show that dynamically varying tightness in communication bottlenecks can improve model performance on visual reasoning and reinforcement learning tasks with heterogeneity in representations.},
  archive   = {C_AAAI},
  author    = {Dianbo Liu and Alex Lamb and Xu Ji and Pascal Junior Tikeng Notsawo and Michael Mozer and Yoshua Bengio and Kenji Kawaguchi},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26061},
  pages     = {8825-8833},
  title     = {Adaptive discrete communication bottlenecks with dynamic vector quantization for heterogeneous representational coarseness},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Incomplete multi-view multi-label learning via label-guided
masked view- and category-aware transformers. <em>AAAI</em>, 8816–8824.
(<a href="https://doi.org/10.1609/aaai.v37i7.26060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As we all know, multi-view data is more expressive than single-view data and multi-label annotation enjoys richer supervision information than single-label, which makes multi-view multi-label learning widely applicable for various pattern recognition tasks. In this complex representation learning problem, three main challenges can be characterized as follows: i) How to learn consistent representations of samples across all views? ii) How to exploit and utilize category correlations of multi-label to guide inference? iii) How to avoid the negative impact resulting from the incompleteness of views or labels? To cope with these problems, we propose a general multi-view multi-label learning framework named label-guided masked view- and category-aware transformers in this paper. First, we design two transformer-style based modules for cross-view features aggregation and multi-label classification, respectively. The former aggregates information from different views in the process of extracting view-specific features, and the latter learns subcategory embedding to improve classification performance. Second, considering the imbalance of expressive power among views, an adaptively weighted view fusion module is proposed to obtain view-consistent embedding features. Third, we impose a label manifold constraint in sample-level representation learning to maximize the utilization of supervised information. Last but not least, all the modules are designed under the premise of incomplete views and labels, which makes our method adaptable to arbitrary multi-view and multi-label data. Extensive experiments on five datasets confirm that our method has clear advantages over other state-of-the-art methods.},
  archive   = {C_AAAI},
  author    = {Chengliang Liu and Jie Wen and Xiaoling Luo and Yong Xu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26060},
  pages     = {8816-8824},
  title     = {Incomplete multi-view multi-label learning via label-guided masked view- and category-aware transformers},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DICNet: Deep instance-level contrastive network for double
incomplete multi-view multi-label classification. <em>AAAI</em>,
8807–8815. (<a href="https://doi.org/10.1609/aaai.v37i7.26059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In recent years, multi-view multi-label learning has aroused extensive research enthusiasm. However, multi-view multi-label data in the real world is commonly incomplete due to the uncertain factors of data collection and manual annotation, which means that not only multi-view features are often missing, and label completeness is also difficult to be satisfied. To deal with the double incomplete multi-view multi-label classification problem, we propose a deep instance-level contrastive network, namely DICNet. Different from conventional methods, our DICNet focuses on leveraging deep neural network to exploit the high-level semantic representations of samples rather than shallow-level features. First, we utilize the stacked autoencoders to build an end-to-end multi-view feature extraction framework to learn the view-specific representations of samples. Furthermore, in order to improve the consensus representation ability, we introduce an incomplete instance-level contrastive learning scheme to guide the encoders to better extract the consensus information of multiple views and use a multi-view weighted fusion module to enhance the discrimination of semantic features. Overall, our DICNet is adept in capturing consistent discriminative representations of multi-view multi-label data and avoiding the negative effects of missing views and missing labels. Extensive experiments performed on five datasets validate that our method outperforms other state-of-the-art methods.},
  archive   = {C_AAAI},
  author    = {Chengliang Liu and Jie Wen and Xiaoling Luo and Chao Huang and Zhihao Wu and Yong Xu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26059},
  pages     = {8807-8815},
  title     = {DICNet: Deep instance-level contrastive network for double incomplete multi-view multi-label classification},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Metric residual network for sample efficient
goal-conditioned reinforcement learning. <em>AAAI</em>, 8799–8806. (<a
href="https://doi.org/10.1609/aaai.v37i7.26058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Goal-conditioned reinforcement learning (GCRL) has a wide range of potential real-world applications, including manipulation and navigation problems in robotics. Especially in such robotics tasks, sample efficiency is of the utmost importance for GCRL since, by default, the agent is only rewarded when it reaches its goal. While several methods have been proposed to improve the sample efficiency of GCRL, one relatively under-studied approach is the design of neural architectures to support sample efficiency. In this work, we introduce a novel neural architecture for GCRL that achieves significantly better sample efficiency than the commonly-used monolithic network architecture. The key insight is that the optimal action-value function must satisfy the triangle inequality in a specific sense. Furthermore, we introduce the metric residual network (MRN) that deliberately decomposes the action-value function into the negated summation of a metric plus a residual asymmetric component. MRN provably approximates any optimal action-value function, thus making it a fitting neural architecture for GCRL. We conduct comprehensive experiments across 12 standard benchmark environments in GCRL. The empirical results demonstrate that MRN uniformly outperforms other state-of-the-art GCRL neural architectures in terms of sample efficiency. The code is available at https://github.com/Cranial-XIX/metric-residual-network.},
  archive   = {C_AAAI},
  author    = {Bo Liu and Yihao Feng and Qiang Liu and Peter Stone},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26058},
  pages     = {8799-8806},
  title     = {Metric residual network for sample efficient goal-conditioned reinforcement learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dual label-guided graph refinement for multi-view graph
clustering. <em>AAAI</em>, 8791–8798. (<a
href="https://doi.org/10.1609/aaai.v37i7.26057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With the increase of multi-view graph data, multi-view graph clustering (MVGC) that can discover the hidden clusters without label supervision has attracted growing attention from researchers. Existing MVGC methods are often sensitive to the given graphs, especially influenced by the low quality graphs, i.e., they tend to be limited by the homophily assumption. However, the widespread real-world data hardly satisfy the homophily assumption. This gap limits the performance of existing MVGC methods on low homophilous graphs. To mitigate this limitation, our motivation is to extract high-level view-common information which is used to refine each view&#39;s graph, and reduce the influence of non-homophilous edges. To this end, we propose dual label-guided graph refinement for multi-view graph clustering (DuaLGR), to alleviate the vulnerability in facing low homophilous graphs. Specifically, DuaLGR consists of two modules named dual label-guided graph refinement module and graph encoder module. The first module is designed to extract the soft label from node features and graphs, and then learn a refinement matrix. In cooperation with the pseudo label from the second module, these graphs are refined and aggregated adaptively with different orders. Subsequently, a consensus graph can be generated in the guidance of the pseudo label. Finally, the graph encoder module encodes the consensus graph along with node features to produce the high-level pseudo label for iteratively clustering. The experimental results show the superior performance on coping with low homophilous graph data. The source code for DuaLGR is available at https://github.com/YwL-zhufeng/DuaLGR.},
  archive   = {C_AAAI},
  author    = {Yawen Ling and Jianpeng Chen and Yazhou Ren and Xiaorong Pu and Jie Xu and Xiaofeng Zhu and Lifang He},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26057},
  pages     = {8791-8798},
  title     = {Dual label-guided graph refinement for multi-view graph clustering},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Wasserstein actor-critic: Directed exploration via optimism
for continuous-actions control. <em>AAAI</em>, 8782–8790. (<a
href="https://doi.org/10.1609/aaai.v37i7.26056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Uncertainty quantification has been extensively used as a means to achieve efficient directed exploration in Reinforcement Learning (RL). However, state-of-the-art methods for continuous actions still suffer from high sample complexity requirements. Indeed, they either completely lack strategies for propagating the epistemic uncertainty throughout the updates, or they mix it with aleatoric uncertainty while learning the full return distribution (e.g., distributional RL). In this paper, we propose Wasserstein Actor-Critic (WAC), an actor-critic architecture inspired by the recent Wasserstein Q-Learning (WQL), that employs approximate Q-posteriors to represent the epistemic uncertainty and Wasserstein barycenters for uncertainty propagation across the state-action space. WAC enforces exploration in a principled way by guiding the policy learning process with the optimization of an upper bound of the Q-value estimates. Furthermore, we study some peculiar issues that arise when using function approximation, coupled with the uncertainty estimation, and propose a regularized loss for the uncertainty estimation. Finally, we evaluate our algorithm on standard MujoCo tasks as well as suite of continuous-actions domains, where exploration is crucial, in comparison with state-of-the-art baselines. Additional details and results can be found in the supplementary material with our Arxiv preprint.},
  archive   = {C_AAAI},
  author    = {Amarildo Likmeta and Matteo Sacco and Alberto Maria Metelli and Marcello Restelli},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26056},
  pages     = {8782-8790},
  title     = {Wasserstein actor-critic: Directed exploration via optimism for continuous-actions control},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the expressive flexibility of self-attention matrices.
<em>AAAI</em>, 8773–8781. (<a
href="https://doi.org/10.1609/aaai.v37i7.26055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Transformer networks are able to capture patterns in data coming from many domains (text, images, videos, proteins, etc.) with little or no change to architecture components. We perform a theoretical analysis of the core component responsible for signal propagation between elements, i.e. the self-attention matrix. We ask the following question: Can self-attention matrix approximate arbitrary patterns? How small is the query dimension d required for such approximation? Our first result shows that the task of deciding whether approximation of a given pattern is possible or not is NP-hard for a fixed d greater than one. In practice, self-attention matrix typically exhibits two properties: it is sparse, and it changes dynamically depending on the input to the module. Motivated by this observation, we show that the self-attention matrix can provably approximate sparse matrices. While the parameters of self-attention are fixed, various sparse matrices can be approximated by only modifying the inputs. Our proof is based on the random projection technique and uses the seminal Johnson-Lindenstrauss lemma. In particular, we show that, in order to approximate any sparse matrix up to a given precision defined in terms of preserving matrix element ratios, d grows only logarithmically with the sequence length n.},
  archive   = {C_AAAI},
  author    = {Valerii Likhosherstov and Krzysztof Choromanski and Adrian Weller},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26055},
  pages     = {8773-8781},
  title     = {On the expressive flexibility of self-attention matrices},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Social bias meets data bias: The impacts of labeling and
measurement errors on fairness criteria. <em>AAAI</em>, 8764–8772. (<a
href="https://doi.org/10.1609/aaai.v37i7.26054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Although many fairness criteria have been proposed to ensure that machine learning algorithms do not exhibit or amplify our existing social biases, these algorithms are trained on datasets that can themselves be statistically biased. In this paper, we investigate the robustness of existing (demographic) fairness criteria when the algorithm is trained on biased data. We consider two forms of dataset bias: errors by prior decision makers in the labeling process, and errors in the measurement of the features of disadvantaged individuals. We analytically show that some constraints (such as Demographic Parity) can remain robust when facing certain statistical biases, while others (such as Equalized Odds) are significantly violated if trained on biased data. We provide numerical experiments based on three real-world datasets (the FICO, Adult, and German credit score datasets) supporting our analytical findings. While fairness criteria are primarily chosen under normative considerations in practice, our results show that naively applying a fairness constraint can lead to not only a loss in utility for the decision maker, but more severe unfairness when data bias exists. Thus, understanding how fairness criteria react to different forms of data bias presents a critical guideline for choosing among existing fairness criteria, or for proposing new criteria, when available datasets may be biased.},
  archive   = {C_AAAI},
  author    = {Yiqiao Liao and Parinaz Naghizadeh},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26054},
  pages     = {8764-8772},
  title     = {Social bias meets data bias: The impacts of labeling and measurement errors on fairness criteria},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Geometry-aware network for domain adaptive semantic
segmentation. <em>AAAI</em>, 8755–8763. (<a
href="https://doi.org/10.1609/aaai.v37i7.26053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Measuring and alleviating the discrepancies between the synthetic (source) and real scene (target) data is the core issue for domain adaptive semantic segmentation. Though recent works have introduced depth information in the source domain to reinforce the geometric and semantic knowledge transfer, they cannot extract the intrinsic 3D information of objects, including positions and shapes, merely based on 2D estimated depth. In this work, we propose a novel Geometry-Aware Network for Domain Adaptation (GANDA), leveraging more compact 3D geometric point cloud representations to shrink the domain gaps. In particular, we first utilize the auxiliary depth supervision from the source domain to obtain the depth prediction in the target domain to accomplish structure-texture disentanglement. Beyond depth estimation, we explicitly exploit 3D topology on the point clouds generated from RGB-D images for further coordinate-color disentanglement and pseudo-labels refinement in the target domain. Moreover, to improve the 2D classifier in the target domain, we perform domain-invariant geometric adaptation from source to target and unify the 2D semantic and 3D geometric segmentation results in two domains. Note that our GANDA is plug-and-play in any existing UDA framework. Qualitative and quantitative results demonstrate that our model outperforms state-of-the-arts on GTA5-&gt;Cityscapes and SYNTHIA-&gt;Cityscapes.},
  archive   = {C_AAAI},
  author    = {Yinghong Liao and Wending Zhou and Xu Yan and Zhen Li and Yizhou Yu and Shuguang Cui},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26053},
  pages     = {8755-8763},
  title     = {Geometry-aware network for domain adaptive semantic segmentation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Policy-independent behavioral metric-based representation
for deep reinforcement learning. <em>AAAI</em>, 8746–8754. (<a
href="https://doi.org/10.1609/aaai.v37i7.26052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Behavioral metrics can calculate the distance between states or state-action pairs from the rewards and transitions difference. By virtue of their capability to filter out task-irrelevant information in theory, using them to shape a state embedding space becomes a new trend of representation learning for deep reinforcement learning (RL), especially when there are explicit distracting factors in observation backgrounds. However, due to the tight coupling between the metric and the RL policy, such metric-based methods may result in less informative embedding spaces which can weaken their aid to the baseline RL algorithm and even consume more samples to learn. We resolve this by proposing a new behavioral metric. It decouples the learning of RL policy and metric owing to its independence on RL policy. We theoretically justify its scalability to continuous state and action spaces and design a practical way to incorporate it into an RL procedure as a representation learning target. We evaluate our approach on DeepMind control tasks with default and distracting backgrounds. By statistically reliable evaluation protocols, our experiments demonstrate our approach is superior to previous metric-based methods in terms of sample efficiency and asymptotic performance in both backgrounds.},
  archive   = {C_AAAI},
  author    = {Weijian Liao and Zongzhang Zhang and Yang Yu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26052},
  pages     = {8746-8754},
  title     = {Policy-independent behavioral metric-based representation for deep reinforcement learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Positive distribution pollution: Rethinking positive
unlabeled learning from a unified perspective. <em>AAAI</em>, 8737–8745.
(<a href="https://doi.org/10.1609/aaai.v37i7.26051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Positive Unlabeled (PU) learning, which has a wide range of applications, is becoming increasingly prevalent. However, it suffers from problems such as data imbalance, selection bias, and prior agnostic in real scenarios. Existing studies focus on addressing part of these problems, which fail to provide a unified perspective to understand these problems. In this paper, we first rethink these problems by analyzing a typical PU scenario and come up with an insightful point of view that all these problems are inherently connected to one problem, i.e., positive distribution pollution, which refers to the inaccuracy in estimating positive data distribution under very little labeled data. Then, inspired by this insight, we devise a variational model named CoVPU, which addresses all three problems in a unified perspective by targeting the positive distribution pollution problem. CoVPU not only accurately separates the positive data from the unlabeled data based on discrete normalizing flows, but also effectively approximates the positive distribution based on our derived unbiased rebalanced risk estimator and supervises the approximation based on a novel prior-free variational loss. Rigorous theoretical analysis proves the convergence of CoVPU to an optimal Bayesian classifier. Extensive experiments demonstrate the superiority of CoVPU over the state-of-the-art PU learning methods under these problems.},
  archive   = {C_AAAI},
  author    = {Qianqiao Liang and Mengying Zhu and Yan Wang and Xiuyuan Wang and Wanjia Zhao and Mengyuan Yang and Hua Wei and Bing Han and Xiaolin Zheng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26051},
  pages     = {8737-8745},
  title     = {Positive distribution pollution: Rethinking positive unlabeled learning from a unified perspective},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Stepdown SLOPE for controlled feature selection.
<em>AAAI</em>, 8728–8736. (<a
href="https://doi.org/10.1609/aaai.v37i7.26050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Sorted L-One Penalized Estimation (SLOPE) has shown the nice theoretical property as well as empirical behavior recently on the false discovery rate (FDR) control of high-dimensional feature selection by adaptively imposing the non-increasing sequence of tuning parameters on the sorted L1 penalties. This paper goes beyond the previous concern limited to the FDR control by considering the stepdown-based SLOPE in order to control the probability of k or more false rejections (k-FWER) and the false discovery proportion (FDP). Two new SLOPEs, called k-SLOPE and F-SLOPE, are proposed to realize k-FWER and FDP control respectively, where the stepdown procedure is injected into the SLOPE scheme. For the proposed stepdown SLOPEs, we establish their theoretical guarantees on controlling k-FWER and FDP under the orthogonal design setting, and also provide an intuitive guideline for the choice of regularization parameter sequence in much general setting. Empirical evaluations on simulated data validate the effectiveness of our approaches on controlled feature selection and support our theoretical findings.},
  archive   = {C_AAAI},
  author    = {Jingxuan Liang and Xuelin Zhang and Hong Chen and Weifu Li and Xin Tang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26050},
  pages     = {8728-8736},
  title     = {Stepdown SLOPE for controlled feature selection},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SplitNet: A reinforcement learning based sequence splitting
method for the MinMax multiple travelling salesman problem.
<em>AAAI</em>, 8720–8727. (<a
href="https://doi.org/10.1609/aaai.v37i7.26049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {MinMax Multiple Travelling Salesman Problem (mTSP) is an important class of combinatorial optimization problems with many practical applications, of which the goal is to minimize the longest tour of all vehicles. Due to its high computational complexity, existing methods for solving this problem cannot obtain a solution of satisfactory quality with fast speed, especially when the scale of the problem is large. In this paper, we propose a learning-based method named SplitNet to transform the single TSP solutions into the MinMax mTSP solutions of the same instances. Specifically, we generate single TSP solution sequences and split them into mTSP subsequences using an attention-based model trained by reinforcement learning. We also design a decision region for the splitting policy, which significantly reduces the policy action space on instances of various scales and thus improves the generalization ability of SplitNet. The experimental results show that SplitNet generalizes well and outperforms existing learning-based baselines and Google OR-Tools on widely-used random datasets of different scales and public datasets with fast solving speed.},
  archive   = {C_AAAI},
  author    = {Hebin Liang and Yi Ma and Zilin Cao and Tianyang Liu and Fei Ni and Zhigang Li and Jianye Hao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26049},
  pages     = {8720-8727},
  title     = {SplitNet: A reinforcement learning based sequence splitting method for the MinMax multiple travelling salesman problem},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Towards inference efficient deep ensemble learning.
<em>AAAI</em>, 8711–8719. (<a
href="https://doi.org/10.1609/aaai.v37i7.26048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Ensemble methods can deliver surprising performance gains but also bring significantly higher computational costs, e.g., can be up to 2048X in large-scale ensemble tasks. However, we found that the majority of computations in ensemble methods are redundant. For instance, over 77\% of samples in CIFAR-100 dataset can be correctly classified with only a single ResNet-18 model, which indicates that only around 23\% of the samples need an ensemble of extra models. To this end, we propose an inference efficient ensemble learning method, to simultaneously optimize for effectiveness and efficiency in ensemble learning. More specifically, we regard ensemble of models as a sequential inference process and learn the optimal halting event for inference on a specific sample. At each timestep of the inference process, a common selector judges if the current ensemble has reached ensemble effectiveness and halt further inference, otherwise filters this challenging sample for the subsequent models to conduct more powerful ensemble. Both the base models and common selector are jointly optimized to dynamically adjust ensemble inference for different samples with various hardness, through the novel optimization goals including sequential ensemble boosting and computation saving. The experiments with different backbones on real-world datasets illustrate our method can bring up to 56\% inference cost reduction while maintaining comparable performance to full ensemble, achieving significantly better ensemble utility than other baselines. Code and supplemental materials are available at https://seqml.github.io/irene.},
  archive   = {C_AAAI},
  author    = {Ziyue Li and Kan Ren and Yifan Yang and Xinyang Jiang and Yuqing Yang and Dongsheng Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26048},
  pages     = {8711-8719},
  title     = {Towards inference efficient deep ensemble learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Provable pathways: Learning multiple tasks over multiple
paths. <em>AAAI</em>, 8701–8710. (<a
href="https://doi.org/10.1609/aaai.v37i7.26047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Constructing useful representations across a large number of tasks is a key requirement for sample-efficient intelligent systems. A traditional idea in multitask learning (MTL) is building a shared representation across tasks which can then be adapted to new tasks by tuning last layers. A desirable refinement of using a shared one-fits-all representation is to construct task-specific representations. To this end, recent PathNet/muNet architectures represent individual tasks as pathways within a larger supernet. The subnetworks induced by pathways can be viewed as task-specific representations that are composition of modules within supernet&#39;s computation graph. This work explores the pathways proposal from the lens of statistical learning: We first develop novel generalization bounds for empirical risk minimization problems learning multiple tasks over multiple paths (Multipath MTL). In conjunction, we formalize the benefits of resulting multipath representation when adapting to new downstream tasks. Our bounds are expressed in terms of Gaussian complexity, lead to tangible guarantees for the class of linear representations, and provide novel insights into the quality and benefits of a multipath representation. When computation graph is a tree, Multipath MTL hierarchically clusters the tasks and builds cluster-specific representations. We provide further discussion and experiments for hierarchical MTL and rigorously identify the conditions under which Multipath MTL is provably superior to traditional MTL approaches with shallow supernets.},
  archive   = {C_AAAI},
  author    = {Yingcong Li and Samet Oymak},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26047},
  pages     = {8701-8710},
  title     = {Provable pathways: Learning multiple tasks over multiple paths},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023d). Implicit stochastic gradient descent for training
physics-informed neural networks. <em>AAAI</em>, 8692–8700. (<a
href="https://doi.org/10.1609/aaai.v37i7.26046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Physics-informed neural networks (PINNs) have effectively been demonstrated in solving forward and inverse differential equation problems, but they are still trapped in training failures when the target functions to be approximated exhibit high-frequency or multi-scale features. In this paper, we propose to employ implicit stochastic gradient descent (ISGD) method to train PINNs for improving the stability of training process. We heuristically analyze how ISGD overcome stiffness in the gradient flow dynamics of PINNs, especially for problems with multi-scale solutions. We theoretically prove that for two-layer fully connected neural networks with large hidden nodes, randomly initialized ISGD converges to a globally optimal solution for the quadratic loss function. Empirical results demonstrate that ISGD works well in practice and compares favorably to other gradient-based optimization methods such as SGD and Adam, while can also effectively address the numerical stiffness in training dynamics via gradient descent.},
  archive   = {C_AAAI},
  author    = {Ye Li and Song-Can Chen and Sheng-Jun Huang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26046},
  pages     = {8692-8700},
  title     = {Implicit stochastic gradient descent for training physics-informed neural networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). An extreme-adaptive time series prediction model based on
probability-enhanced LSTM neural networks. <em>AAAI</em>, 8684–8691. (<a
href="https://doi.org/10.1609/aaai.v37i7.26045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Forecasting time series with extreme events has been a challenging and prevalent research topic, especially when the time series data are affected by complicated uncertain factors, such as is the case in hydrologic prediction. Diverse traditional and deep learning models have been applied to discover the nonlinear relationships and recognize the complex patterns in these types of data. However, existing methods usually ignore the negative influence of imbalanced data, or severe events, on model training. Moreover, methods are usually evaluated on a small number of generally well-behaved time series, which does not show their ability to generalize. To tackle these issues, we propose a novel probability-enhanced neural network model, called NEC+, which concurrently learns extreme and normal prediction functions and a way to choose among them via selective back propagation. We evaluate the proposed model on the difficult 3-day ahead hourly water level prediction task applied to 9 reservoirs in California. Experimental results demonstrate that the proposed model significantly outperforms state-of-the-art baselines and exhibits superior generalization ability on data with diverse distributions.},
  archive   = {C_AAAI},
  author    = {Yanhong Li and Jack Xu and David C. Anastasiu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26045},
  pages     = {8684-8691},
  title     = {An extreme-adaptive time series prediction model based on probability-enhanced LSTM neural networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning compact features via in-training representation
alignment. <em>AAAI</em>, 8675–8683. (<a
href="https://doi.org/10.1609/aaai.v37i7.26044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep neural networks (DNNs) for supervised learning can be viewed as a pipeline of the feature extractor (i.e., last hidden layer) and a linear classifier (i.e., output layer) that are trained jointly with stochastic gradient descent (SGD) on the loss function (e.g., cross-entropy). In each epoch, the true gradient of the loss function is estimated using a mini-batch sampled from the training set and model parameters are then updated with the mini-batch gradients. Although the latter provides an unbiased estimation of the former, they are subject to substantial variances derived from the size and number of sampled mini-batches, leading to noisy and jumpy updates. To stabilize such undesirable variance in estimating the true gradients, we propose In-Training Representation Alignment (ITRA) that explicitly aligns feature distributions of two different mini-batches with a matching loss in the SGD training process. We also provide a rigorous analysis of the desirable effects of the matching loss on feature representation learning: (1) extracting compact feature representation; (2) reducing over-adaption on mini-batches via an adaptively weighting mechanism; and (3) accommodating to multi-modalities. Finally, we conduct large-scale experiments on both image and text classifications to demonstrate its superior performance to the strong baselines.},
  archive   = {C_AAAI},
  author    = {Xin Li and Xiangrui Li and Deng Pan and Yao Qiang and Dongxiao Zhu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26044},
  pages     = {8675-8683},
  title     = {Learning compact features via in-training representation alignment},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning with partial labels from semi-supervised
perspective. <em>AAAI</em>, 8666–8674. (<a
href="https://doi.org/10.1609/aaai.v37i7.26043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Partial Label (PL) learning refers to the task of learning from the partially labeled data, where each training instance is ambiguously equipped with a set of candidate labels but only one is valid. Advances in the recent deep PL learning literature have shown that the deep learning paradigms, e.g., self-training, contrastive learning, or class activate values, can achieve promising performance. Inspired by the impressive success of deep Semi-Supervised (SS) learning, we transform the PL learning problem into the SS learning problem, and propose a novel PL learning method, namely Partial Label learning with Semi-supervised Perspective (PLSP). Specifically, we first form the pseudo-labeled dataset by selecting a small number of reliable pseudo-labeled instances with high-confidence prediction scores and treating the remaining instances as pseudo-unlabeled ones. Then we design a SS learning objective, consisting of a supervised loss for pseudo-labeled instances and a semantic consistency regularization for pseudo-unlabeled instances. We further introduce a complementary regularization for those non-candidate labels to constrain the model predictions on them to be as small as possible. Empirical results demonstrate that PLSP significantly outperforms the existing PL baseline methods, especially on high ambiguity levels. Code available: https://github.com/changchunli/PLSP.},
  archive   = {C_AAAI},
  author    = {Ximing Li and Yuanzhi Jiang and Changchun Li and Yiyuan Wang and Jihong Ouyang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26043},
  pages     = {8666-8674},
  title     = {Learning with partial labels from semi-supervised perspective},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Predictive exit: Prediction of fine-grained early exits for
computation- and energy-efficient inference. <em>AAAI</em>, 8657–8665.
(<a href="https://doi.org/10.1609/aaai.v37i7.26042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {By adding exiting layers to the deep learning networks, early exit can terminate the inference earlier with accurate results. However, the passive decision-making of whether to exit or continue the next layer has to go through every pre-placed exiting layer until it exits. In addition, it is hard to adjust the configurations of the computing platforms alongside the inference proceeds. By incorporating a low-cost prediction engine, we propose a Predictive Exit framework for computation- and energy-efficient deep learning applications. Predictive Exit can forecast where the network will exit (i.e., establish the number of remaining layers to finish the inference), which effectively reduces the network computation cost by exiting on time without running every pre-placed exiting layer. Moreover, according to the number of remaining layers, proper computing configurations (i.e., frequency and voltage) are selected to execute the network to further save energy. Extensive experimental results demonstrate that Predictive Exit achieves up to 96.2\% computation reduction and 72.9\% energy-saving compared with classic deep learning networks; and 12.8\% computation reduction and 37.6\% energy-saving compared with the early exit under state-of-the-art exiting strategies, given the same inference accuracy and latency.},
  archive   = {C_AAAI},
  author    = {Xiangjie Li and Chenfei Lou and Yuchi Chen and Zhengping Zhu and Yingtao Shen and Yehan Ma and An Zou},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26042},
  pages     = {8657-8665},
  title     = {Predictive exit: Prediction of fine-grained early exits for computation- and energy-efficient inference},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023d). Metric nearness made practical. <em>AAAI</em>, 8648–8656.
(<a href="https://doi.org/10.1609/aaai.v37i7.26041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Given a square matrix with noisy dissimilarity measures between pairs of data samples, the metric nearness model computes the best approximation of the matrix from a set of valid distance metrics. Despite its wide applications in machine learning and data processing tasks, the model faces non-trivial computational requirements in seeking the solution due to the large number of metric constraints associated with the feasible region. Our work designed a practical approach in two stages to tackle the challenge and improve the model&#39;s scalability and applicability. The first stage computes a fast yet high-quality approximate solution from a set of isometrically embeddable metrics, further improved by an effective heuristic. The second stage refines the approximate solution with the Halpern-Lions-Wittmann-Bauschke projection algorithm, which converges quickly to the optimal solution. In empirical evaluations, the proposed approach runs at least an order of magnitude faster than the state-of-the-art solutions, with significantly improved scalability, complete conformity to constraints, less memory consumption, and other desirable features in real applications.},
  archive   = {C_AAAI},
  author    = {Wenye Li and Fangchen Yu and Zichen Ma},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26041},
  pages     = {8648-8656},
  title     = {Metric nearness made practical},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards fine-grained explainability for heterogeneous graph
neural network. <em>AAAI</em>, 8640–8647. (<a
href="https://doi.org/10.1609/aaai.v37i7.26040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Heterogeneous graph neural networks (HGNs) are prominent approaches to node classification tasks on heterogeneous graphs. Despite the superior performance, insights about the predictions made from HGNs are obscure to humans. Existing explainability techniques are mainly proposed for GNNs on homogeneous graphs. They focus on highlighting salient graph objects to the predictions whereas the problem of how these objects affect the predictions remains unsolved. Given heterogeneous graphs with complex structures and rich semantics, it is imperative that salient objects can be accompanied with their influence paths to the predictions, unveiling the reasoning process of HGNs. In this paper, we develop xPath, a new framework that provides fine-grained explanations for black-box HGNs specifying a cause node with its influence path to the target node. In xPath, we differentiate the influence of a node on the prediction w.r.t. every individual influence path, and measure the influence by perturbing graph structure via a novel graph rewiring algorithm. Furthermore, we introduce a greedy search algorithm to find the most influential fine-grained explanations efficiently. Empirical results on various HGNs and heterogeneous graphs show that xPath yields faithful explanations efficiently, outperforming the adaptations of advanced GNN explanation approaches.},
  archive   = {C_AAAI},
  author    = {Tong Li and Jiale Deng and Yanyan Shen and Luyu Qiu and Huang Yongxiang and Caleb Chen Cao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26040},
  pages     = {8640-8647},
  title     = {Towards fine-grained explainability for heterogeneous graph neural network},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Nearest-neighbor sampling based conditional independence
testing. <em>AAAI</em>, 8631–8639. (<a
href="https://doi.org/10.1609/aaai.v37i7.26039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The conditional randomization test (CRT) was recently proposed to test whether two random variables X and Y are conditionally independent given random variables Z. The CRT assumes that the conditional distribution of X given Z is known under the null hypothesis and then it is compared to the distribution of the observed samples of the original data. The aim of this paper is to develop a novel alternative of CRT by using nearest-neighbor sampling without assuming the exact form of the distribution of X given Z. Specifically, we utilize the computationally efficient 1-nearest-neighbor to approximate the conditional distribution that encodes the null hypothesis. Then, theoretically, we show that the distribution of the generated samples is very close to the true conditional distribution in terms of total variation distance. Furthermore, we take the classifier-based conditional mutual information estimator as our test statistic. The test statistic as an empirical fundamental information theoretic quantity is able to well capture the conditional-dependence feature. We show that our proposed test is computationally very fast, while controlling type I and II errors quite well. Finally, we demonstrate the efficiency of our proposed test in both synthetic and real data analyses.},
  archive   = {C_AAAI},
  author    = {Shuai Li and Ziqi Chen and Hongtu Zhu and Christina Dan Wang and Wang Wen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26039},
  pages     = {8631-8639},
  title     = {Nearest-neighbor sampling based conditional independence testing},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Restructuring graph for higher homophily via adaptive
spectral clustering. <em>AAAI</em>, 8622–8630. (<a
href="https://doi.org/10.1609/aaai.v37i7.26038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {While a growing body of literature has been studying new Graph Neural Networks (GNNs) that work on both homophilic and heterophilic graphs, little has been done on adapting classical GNNs to less-homophilic graphs. Although the ability to handle less-homophilic graphs is restricted, classical GNNs still stand out in several nice properties such as efficiency, simplicity, and explainability. In this work, we propose a novel graph restructuring method that can be integrated into any type of GNNs, including classical GNNs, to leverage the benefits of existing GNNs while alleviating their limitations. Our contribution is threefold: a) learning the weight of pseudo-eigenvectors for an adaptive spectral clustering that aligns well with known node labels, b) proposing a new density-aware homophilic metric that is robust to label imbalance, and c) reconstructing the adjacency matrix based on the result of adaptive spectral clustering to maximize the homophilic scores. The experimental results show that our graph restructuring method can significantly boost the performance of six classical GNNs by an average of 25\% on less-homophilic graphs. The boosted performance is comparable to state-of-the-art methods.},
  archive   = {C_AAAI},
  author    = {Shouheng Li and Dongwoo Kim and Qing Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26038},
  pages     = {8622-8630},
  title     = {Restructuring graph for higher homophily via adaptive spectral clustering},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Understanding the generalization performance of spectral
clustering algorithms. <em>AAAI</em>, 8614–8621. (<a
href="https://doi.org/10.1609/aaai.v37i7.26037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The theoretical analysis of spectral clustering is mainly devoted to consistency, while there is little research on its generalization performance. In this paper, we study the excess risk bounds of the popular spectral clustering algorithms: relaxed RatioCut and relaxed NCut. Our analysis follows the two practical steps of spectral clustering algorithms: continuous solution and discrete solution. Firstly, we provide the convergence rate of the excess risk bounds between the empirical continuous optimal solution and the population-level continuous optimal solution. Secondly, we show the fundamental quantity influencing the excess risk between the empirical discrete optimal solution and the population-level discrete optimal solution. At the empirical level, algorithms can be designed to reduce this quantity. Based on our theoretical analysis, we propose two novel algorithms that can penalize this quantity and, additionally, can cluster the out-of-sample data without re-eigendecomposition on the overall samples. Numerical experiments on toy and real datasets confirm the effectiveness of our proposed algorithms.},
  archive   = {C_AAAI},
  author    = {Shaojie Li and Sheng Ouyang and Yong Liu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26037},
  pages     = {8614-8621},
  title     = {Understanding the generalization performance of spectral clustering algorithms},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). VBLC: Visibility boosting and logit-constraint learning for
domain adaptive semantic segmentation under adverse conditions.
<em>AAAI</em>, 8605–8613. (<a
href="https://doi.org/10.1609/aaai.v37i7.26036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Generalizing models trained on normal visual conditions to target domains under adverse conditions is demanding in the practical systems. One prevalent solution is to bridge the domain gap between clear- and adverse-condition images to make satisfactory prediction on the target. However, previous methods often reckon on additional reference images of the same scenes taken from normal conditions, which are quite tough to collect in reality. Furthermore, most of them mainly focus on individual adverse condition such as nighttime or foggy, weakening the model versatility when encountering other adverse weathers. To overcome the above limitations, we propose a novel framework, Visibility Boosting and Logit-Constraint learning (VBLC), tailored for superior normal-toadverse adaptation. VBLC explores the potential of getting rid of reference images and resolving the mixture of adverse conditions simultaneously. In detail, we first propose the visibility boost module to dynamically improve target images via certain priors in the image level. Then, we figure out the overconfident drawback in the conventional cross-entropy loss for self-training method and devise the logit-constraint learning, which enforces a constraint on logit outputs during training to mitigate this pain point. To the best of our knowledge, this is a new perspective for tackling such a challenging task. Extensive experiments on two normal-to-adverse domain adaptation benchmarks, i.e., Cityscapes to ACDC and Cityscapes to FoggyCityscapes + RainCityscapes, verify the effectiveness of VBLC, where it establishes the new state of the art. Code is available at https://github.com/BIT-DA/VBLC.},
  archive   = {C_AAAI},
  author    = {Mingjia Li and Binhui Xie and Shuang Li and Chi Harold Liu and Xinjing Cheng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26036},
  pages     = {8605-8613},
  title     = {VBLC: Visibility boosting and logit-constraint learning for domain adaptive semantic segmentation under adverse conditions},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improved kernel alignment regret bound for online kernel
learning. <em>AAAI</em>, 8597–8604. (<a
href="https://doi.org/10.1609/aaai.v37i7.26035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we improve the kernel alignment regret bound for online kernel learning in the regime of the Hinge loss function. Previous algorithm achieves a regret of O((A_TT ln T)^{1/4}) at a computational complexity (space and per-round time) of O((A_TT ln T)^{1/2}), where A_T is called kernel alignment. We propose an algorithm whose regret bound and computational complexity are better than previous results. Our results depend on the decay rate of eigenvalues of the kernel matrix. If the eigenvalues of the kernel matrix decay exponentially, then our algorithm enjoys a regret of O((A_T)^{1/2}) at a computational complexity of O((ln T)^2). Otherwise, our algorithm enjoys a regret of O((A_TT)^{1/4}) at a computational complexity of O((A_TT)^{1/2}). We extend our algorithm to batch learning and obtain a O(T^{-1}(E[A_T])^{1/2}) excess risk bound which improves the previous O(T^{-1/2}) bound.},
  archive   = {C_AAAI},
  author    = {Junfan Li and Shizhong Liao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26035},
  pages     = {8597-8604},
  title     = {Improved kernel alignment regret bound for online kernel learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Scaling up dynamic graph representation learning via spiking
neural networks. <em>AAAI</em>, 8588–8596. (<a
href="https://doi.org/10.1609/aaai.v37i7.26034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent years have seen a surge in research on dynamic graph representation learning, which aims to model temporal graphs that are dynamic and evolving constantly over time. However, current work typically models graph dynamics with recurrent neural networks (RNNs), making them suffer seriously from computation and memory overheads on large temporal graphs. So far, scalability of dynamic graph representation learning on large temporal graphs remains one of the major challenges. In this paper, we present a scalable framework, namely SpikeNet, to efficiently capture the temporal and structural patterns of temporal graphs. We explore a new direction in that we can capture the evolving dynamics of temporal graphs with spiking neural networks (SNNs) instead of RNNs. As a low-power alternative to RNNs, SNNs explicitly model graph dynamics as spike trains of neuron populations and enable spike-based propagation in an efficient way. Experiments on three large real-world temporal graph datasets demonstrate that SpikeNet outperforms strong baselines on the temporal node classification task with lower computational costs. Particularly, SpikeNet generalizes to a large temporal graph (2.7M nodes and 13.9M edges) with significantly fewer parameters and computation overheads.},
  archive   = {C_AAAI},
  author    = {Jintang Li and Zhouxin Yu and Zulun Zhu and Liang Chen and Qi Yu and Zibin Zheng and Sheng Tian and Ruofan Wu and Changhua Meng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26034},
  pages     = {8588-8596},
  title     = {Scaling up dynamic graph representation learning via spiking neural networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). AdaBoost.C2: Boosting classifiers chains for multi-label
classification. <em>AAAI</em>, 8580–8587. (<a
href="https://doi.org/10.1609/aaai.v37i7.26033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {During the last decades, multi-label classification (MLC) has attracted the attention of more and more researchers due to its wide real-world applications. Many boosting methods for MLC have been proposed and achieved great successes. However, these methods only extend existing boosting frameworks to MLC and take loss functions in multi-label version to guide the iteration. These loss functions generally give a comprehensive evaluation on the label set entirety, and thus the characteristics of different labels are ignored. In this paper, we propose a multi-path AdaBoost framework specific to MLC, where each boosting path is established for distinct label and the combination of them is able to provide a maximum optimization to Hamming Loss. In each iteration, classifiers chain is taken as the base classifier to strengthen the connection between multiple AdaBoost paths and exploit the label correlation. Extensive experiments demonstrate the effectiveness of the proposed method.},
  archive   = {C_AAAI},
  author    = {Jiaxuan Li and Xiaoyan Zhu and Jiayin Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26033},
  pages     = {8580-8587},
  title     = {AdaBoost.C2: Boosting classifiers chains for multi-label classification},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dual mutual information constraints for discriminative
clustering. <em>AAAI</em>, 8571–8579. (<a
href="https://doi.org/10.1609/aaai.v37i7.26032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep clustering is a fundamental task in machine learning and data mining that aims at learning clustering-oriented feature representations. In previous studies, most of deep clustering methods follow the idea of self-supervised representation learning by maximizing the consistency of all similar instance pairs while ignoring the effect of feature redundancy on clustering performance. In this paper, to address the above issue, we design a dual mutual information constrained clustering method named DMICC which is based on deep contrastive clustering architecture, in which the dual mutual information constraints are particularly employed with solid theoretical guarantees and experimental validations. Specifically, at the feature level, we reduce the redundancy among features by minimizing the mutual information across all the dimensionalities to encourage the neural network to extract more discriminative features. At the instance level, we maximize the mutual information of the similar instance pairs to obtain more unbiased and robust representations. The dual mutual information constraints happen simultaneously and thus complement each other to jointly optimize better features that are suitable for the clustering task. We also prove that our adopted mutual information constraints are superior in feature extraction, and the proposed dual mutual information constraints are clearly bounded and thus solvable. Extensive experiments on five benchmark datasets show that our proposed approach outperforms most other clustering algorithms. The code is available at https://github.com/Li-Hyn/DMICC.},
  archive   = {C_AAAI},
  author    = {Hongyu Li and Lefei Zhang and Kehua Su},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26032},
  pages     = {8571-8579},
  title     = {Dual mutual information constraints for discriminative clustering},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Causal recurrent variational autoencoder for medical time
series generation. <em>AAAI</em>, 8562–8570. (<a
href="https://doi.org/10.1609/aaai.v37i7.26031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose causal recurrent variational autoencoder (CR-VAE), a novel generative model that is able to learn a Granger causal graph from a multivariate time series x and incorporates the underlying causal mechanism into its data generation process. Distinct to the classical recurrent VAEs, our CR-VAE uses a multi-head decoder, in which the p-th head is responsible for generating the p-th dimension of x (i.e., x^p). By imposing a sparsity-inducing penalty on the weights (of the decoder) and encouraging specific sets of weights to be zero, our CR-VAE learns a sparse adjacency matrix that encodes causal relations between all pairs of variables. Thanks to this causal matrix, our decoder strictly obeys the underlying principles of Granger causality, thereby making the data generating process transparent. We develop a two-stage approach to train the overall objective. Empirically, we evaluate the behavior of our model in synthetic data and two real-world human brain datasets involving, respectively, the electroencephalography (EEG) signals and the functional magnetic resonance imaging (fMRI) data. Our model consistently outperforms state-of-the-art time series generative models both qualitatively and quantitatively. Moreover, it also discovers a faithful causal graph with similar or improved accuracy over existing Granger causality-based causal inference methods. Code of CR-VAE is publicly available at https://github.com/hongmingli1995/CR-VAE.},
  archive   = {C_AAAI},
  author    = {Hongming Li and Shujian Yu and Jose Principe},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26031},
  pages     = {8562-8570},
  title     = {Causal recurrent variational autoencoder for medical time series generation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FanoutNet: A neuralized PCB fanout automation method using
deep reinforcement learning. <em>AAAI</em>, 8554–8561. (<a
href="https://doi.org/10.1609/aaai.v37i7.26030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In modern electronic manufacturing processes, multi-layer Printed Circuit Board (PCB) routing requires connecting more than hundreds of nets with perplexing topology under complex routing constraints and highly limited resources, so that takes intense effort and time of human engineers. PCB fanout as a pre-design of PCB routing has been proved to be an ideal technique to reduce the complexity of PCB routing by pre-allocating resources and pre-routing. However, current PCB fanout design heavily relies on the experience of human engineers, and there is no existing solution for PCB fanout automation in industry, which limits the quality of PCB routing automation. To address the problem, we propose a neuralized PCB fanout method by deep reinforcement learning. To the best of our knowledge, we are the first in the literature to propose the automation method for PCB fanout. We combine with Convolution Neural Network (CNN) and attention-based network to train our fanout policy model and value model. The models learn representations of PCB layout and netlist to make decisions and evaluations in place of human engineers. We employ Proximal Policy Optimization (PPO) to update the parameters of the models. In addition, we apply our PCB fanout method to a PCB router to improve the quality of PCB routing. Extensive experimental results on real-world industrial PCB benchmarks demonstrate that our approach achieves 100\% routability in all industrial cases and improves wire length by an average of 6.8\%, which makes a significant improvement compared with the state-of-the-art methods.},
  archive   = {C_AAAI},
  author    = {Haiyun Li and Jixin Zhang and Ning Xu and Mingyu Liu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26030},
  pages     = {8554-8561},
  title     = {FanoutNet: A neuralized PCB fanout automation method using deep reinforcement learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). When online learning meets ODE: Learning without forgetting
on variable feature space. <em>AAAI</em>, 8545–8553. (<a
href="https://doi.org/10.1609/aaai.v37i7.26029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Machine learning systems that built upon varying feature space are ubiquitous across the world. When the set of practical or virtual features changes, the online learning approach can adjust the learned model accordingly rather than re-training from scratch and has been an attractive area of research. Despite its importance, most studies for algorithms that are capable of handling online features have no ensurance of stationarity point convergence, while the accuracy guaranteed methods are still limited to some simple cases such as L_1 or L_2 norms with square loss. To address this challenging problem, we develop an efficient Dynamic Feature Learning System (DFLS) to perform online learning on the unfixed feature set for more general statistical models and demonstrate how DFLS opens up many new applications. We are the first to achieve accurate &amp; reliable feature-wise online learning for a broad class of models like logistic regression, spline interpolation, group Lasso and Poisson regression. By utilizing DFLS, the updated model is theoretically the same as the model trained from scratch using the entire new feature space. Specifically, we reparameterize the feature-varying procedure and devise the corresponding ordinary differential equation (ODE) system to compute the optimal solutions of the new model status. Simulation studies reveal that the proposed DFLS can substantially ease the computational cost without forgetting.},
  archive   = {C_AAAI},
  author    = {Diyang Li and Bin Gu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26029},
  pages     = {8545-8553},
  title     = {When online learning meets ODE: Learning without forgetting on variable feature space},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). ACE: Cooperative multi-agent q-learning with bidirectional
action-dependency. <em>AAAI</em>, 8536–8544. (<a
href="https://doi.org/10.1609/aaai.v37i7.26028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-agent reinforcement learning (MARL) suffers from the non-stationarity problem, which is the ever-changing targets at every iteration when multiple agents update their policies at the same time. Starting from first principle, in this paper, we manage to solve the non-stationarity problem by proposing bidirectional action-dependent Q-learning (ACE). Central to the development of ACE is the sequential decision making process wherein only one agent is allowed to take action at one time. Within this process, each agent maximizes its value function given the actions taken by the preceding agents at the inference stage. In the learning phase, each agent minimizes the TD error that is dependent on how the subsequent agents have reacted to their chosen action. Given the design of bidirectional dependency, ACE effectively turns a multi-agent MDP into a single-agent MDP. We implement the ACE framework by identifying the proper network representation to formulate the action dependency, so that the sequential decision process is computed implicitly in one forward pass. To validate ACE, we compare it with strong baselines on two MARL benchmarks. Empirical experiments demonstrate that ACE outperforms the state-of-the-art algorithms on Google Research Football and StarCraft Multi-Agent Challenge by a large margin. In particular, on SMAC tasks, ACE achieves 100\% success rate on almost all the hard and super hard maps. We further study extensive research problems regarding ACE, including extension, generalization and practicability.},
  archive   = {C_AAAI},
  author    = {Chuming Li and Jie Liu and Yinmin Zhang and Yuhong Wei and Yazhe Niu and Yaodong Yang and Yu Liu and Wanli Ouyang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26028},
  pages     = {8536-8544},
  title     = {ACE: Cooperative multi-agent Q-learning with bidirectional action-dependency},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning adversarially robust sparse networks via weight
reparameterization. <em>AAAI</em>, 8527–8535. (<a
href="https://doi.org/10.1609/aaai.v37i7.26027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Although increasing model size can enhance the adversarial robustness of deep neural networks, in resource-constrained environments, there exist critical sparsity constraints. While the recent robust pruning technologies show promising direction to obtain adversarially robust sparse networks, they perform poorly with high sparsity. In this work, we bridge this performance gap by reparameterizing network parameters to simultaneously learn the sparse structure and the robustness. Specifically, we introduce Twin-Rep, which reparameterizes original weights into the product of two factors during training and performs pruning on the reparameterized weights to satisfy the target sparsity constraint. Twin-Rep implicitly adds the sparsity constraint without changing the robust training objective, thus can enhance robustness under high sparsity. We also introduce another variant of weight reparameterization for better channel pruning. When inferring, we restore the original weight structure to obtain compact and robust networks. Extensive experiments on diverse datasets demonstrate that our method achieves state-of-the-art results, outperforming the current sparse robust training method and robustness-aware pruning method. Our code is available at https://github.com/UCAS-LCH/Twin-Rep.},
  archive   = {C_AAAI},
  author    = {Chenhao Li and Qiang Qiu and Zhibin Zhang and Jiafeng Guo and Xueqi Cheng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26027},
  pages     = {8527-8535},
  title     = {Learning adversarially robust sparse networks via weight reparameterization},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Differentiable meta multigraph search with partial message
propagation on heterogeneous information networks. <em>AAAI</em>,
8518–8526. (<a href="https://doi.org/10.1609/aaai.v37i7.26026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Heterogeneous information networks (HINs) are widely employed for describing real-world data with intricate entities and relationships. To automatically utilize their semantic information, graph neural architecture search has recently been developed for various tasks of HINs. Existing works, on the other hand, show weaknesses in instability and inflexibility. To address these issues, we propose a novel method called Partial Message Meta Multigraph search (PMMM) to automatically optimize the neural architecture design on HINs. Specifically, to learn how graph neural networks (GNNs) propagate messages along various types of edges, PMMM adopts an efficient differentiable framework to search for a meaningful meta multigraph, which can capture more flexible and complex semantic relations than a meta graph. The differentiable search typically suffers from performance instability, so we further propose a stable algorithm called partial message search to ensure that the searched meta multigraph consistently surpasses the manually designed meta-structures, i.e., meta-paths. Extensive experiments on six benchmark datasets over two representative tasks, including node classification and recommendation, demonstrate the effectiveness of the proposed method. Our approach outperforms the state-of-the-art heterogeneous GNNs, finds out meaningful meta multigraphs, and is significantly more stable. Our code is available at https://github.com/JHL-HUST/PMMM.},
  archive   = {C_AAAI},
  author    = {Chao Li and Hao Xu and Kun He},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26026},
  pages     = {8518-8526},
  title     = {Differentiable meta multigraph search with partial message propagation on heterogeneous information networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimism in face of a context: Regret guarantees for
stochastic contextual MDP. <em>AAAI</em>, 8510–8517. (<a
href="https://doi.org/10.1609/aaai.v37i7.26025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present regret minimization algorithms for stochastic contextual MDPs under minimum reachability assumption, using an access to an offline least square regression oracle. We analyze three different settings: where the dynamics is known, where the dynamics is unknown but independent of the context and the most challenging setting where the dynamics is unknown and context-dependent. For the latter, our algorithm obtains regret bound (up to poly-logarithmic factors) of order (H+1/pₘᵢₙ)H|S|³ᐟ²(|A|Tlog(max{|?|,|?|} /?))¹ᐟ² with probability 1−?, where ? and ? are finite and realizable function classes used to approximate the dynamics and rewards respectively, pₘᵢₙ is the minimum reachability parameter, S is the set of states, A the set of actions, H the horizon, and T the number of episodes. To our knowledge, our approach is the first optimistic approach applied to contextual MDPs with general function approximation (i.e., without additional knowledge regarding the function class, such as it being linear and etc.). We present a lower bound of ?((TH|S||A|ln|?| /ln|A| )¹ᐟ² ), on the expected regret which holds even in the case of known dynamics. Lastly, we discuss an extension of our results to CMDPs without minimum reachability, that obtains order of T³ᐟ⁴ regret.},
  archive   = {C_AAAI},
  author    = {Orin Levy and Yishay Mansour},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26025},
  pages     = {8510-8517},
  title     = {Optimism in face of a context: Regret guarantees for stochastic contextual MDP},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Goal-conditioned q-learning as knowledge distillation.
<em>AAAI</em>, 8500–8509. (<a
href="https://doi.org/10.1609/aaai.v37i7.26024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Many applications of reinforcement learning can be formalized as goal-conditioned environments, where, in each episode, there is a &quot;goal&quot; that affects the rewards obtained during that episode but does not affect the dynamics. Various techniques have been proposed to improve performance in goal-conditioned environments, such as automatic curriculum generation and goal relabeling. In this work, we explore a connection between off-policy reinforcement learning in goal-conditioned settings and knowledge distillation. In particular: the current Q-value function and the target Q-value estimate are both functions of the goal, and we would like to train the Q-value function to match its target for all goals. We therefore apply Gradient-Based Attention Transfer (Zagoruyko and Komodakis 2017), a knowledge distillation technique, to the Q-function update. We empirically show that this can improve the performance of goal-conditioned off-policy reinforcement learning when the space of goals is high-dimensional. We also show that this technique can be adapted to allow for efficient learning in the case of multiple simultaneous sparse goals, where the agent can attain a reward by achieving any one of a large set of objectives, all specified at test time. Finally, to provide theoretical support, we give examples of classes of environments where (under some assumptions) standard off-policy algorithms such as DDPG require at least O(d^2) replay buffer transitions to learn an optimal policy, while our proposed technique requires only O(d) transitions, where d is the dimensionality of the goal and state space. Code and appendix are available at https://github.com/alevine0/ReenGAGE.},
  archive   = {C_AAAI},
  author    = {Alexander Levine and Soheil Feizi},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26024},
  pages     = {8500-8509},
  title     = {Goal-conditioned Q-learning as knowledge distillation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Layer-wise adaptive model aggregation for scalable federated
learning. <em>AAAI</em>, 8491–8499. (<a
href="https://doi.org/10.1609/aaai.v37i7.26023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In Federated Learning (FL), a common approach for aggregating local solutions across clients is periodic full model averaging. It is, however, known that different layers of neural networks can have a different degree of model discrepancy across the clients. The conventional full aggregation scheme does not consider such a difference and synchronizes the whole model parameters at once, resulting in inefficient network bandwidth consumption. Aggregating the parameters that are similar across the clients does not make meaningful training progress while increasing the communication cost. We propose FedLAMA, a layer-wise adaptive model aggregation scheme for scalable FL. FedLAMA adjusts the aggregation interval in a layer-wise manner, jointly considering the model discrepancy and the communication cost. This fine-grained aggregation strategy enables to reduce the communication cost without significantly harming the model accuracy. Our extensive empirical study shows that, as the aggregation interval increases, FedLAMA shows a remarkably smaller accuracy drop than the periodic full aggregation, while achieving comparable communication efficiency.},
  archive   = {C_AAAI},
  author    = {Sunwoo Lee and Tuo Zhang and A. Salman Avestimehr},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26023},
  pages     = {8491-8499},
  title     = {Layer-wise adaptive model aggregation for scalable federated learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Demystifying randomly initialized networks for evaluating
generative models. <em>AAAI</em>, 8482–8490. (<a
href="https://doi.org/10.1609/aaai.v37i7.26022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Evaluation of generative models is mostly based on the comparison between the estimated distribution and the ground truth distribution in a certain feature space. To embed samples into informative features, previous works often use convolutional neural networks optimized for classification, which is criticized by recent studies. Therefore, various feature spaces have been explored to discover alternatives. Among them, a surprising approach is to use a randomly initialized neural network for feature embedding. However, the fundamental basis to employ the random features has not been sufficiently justified. In this paper, we rigorously investigate the feature space of models with random weights in comparison to that of trained models. Furthermore, we provide an empirical evidence to choose networks for random features to obtain consistent and reliable results. Our results indicate that the features from random networks can evaluate generative models well similarly to those from trained networks, and furthermore, the two types of features can be used together in a complementary way.},
  archive   = {C_AAAI},
  author    = {Junghyuk Lee and Jun-Hyuk Kim and Jong-Seok Lee},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26022},
  pages     = {8482-8490},
  title     = {Demystifying randomly initialized networks for evaluating generative models},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Time-aware random walk diffusion to improve dynamic graph
learning. <em>AAAI</em>, 8473–8481. (<a
href="https://doi.org/10.1609/aaai.v37i7.26021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {How can we augment a dynamic graph for improving the performance of dynamic graph neural networks? Graph augmentation has been widely utilized to boost the learning performance of GNN-based models. However, most existing approaches only enhance spatial structure within an input static graph by transforming the graph, and do not consider dynamics caused by time such as temporal locality, i.e., recent edges are more influential than earlier ones, which remains challenging for dynamic graph augmentation. In this work, we propose TiaRa (Time-aware Random Walk Diffusion), a novel diffusion-based method for augmenting a dynamic graph represented as a discrete-time sequence of graph snapshots. For this purpose, we first design a time-aware random walk proximity so that a surfer can walk along the time dimension as well as edges, resulting in spatially and temporally localized scores. We then derive our diffusion matrices based on the time-aware random walk, and show they become enhanced adjacency matrices that both spatial and temporal localities are augmented. Throughout extensive experiments, we demonstrate that TiaRa effectively augments a given dynamic graph, and leads to significant improvements in dynamic GNN models for various graph datasets and tasks.},
  archive   = {C_AAAI},
  author    = {Jong-whi Lee and Jinhong Jung},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26021},
  pages     = {8473-8481},
  title     = {Time-aware random walk diffusion to improve dynamic graph learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bespoke: A block-level neural network optimization framework
for low-cost deployment. <em>AAAI</em>, 8465–8472. (<a
href="https://doi.org/10.1609/aaai.v37i7.26020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As deep learning models become popular, there is a lot of need for deploying them to diverse device environments. Because it is costly to develop and optimize a neural network for every single environment, there is a line of research to search neural networks for multiple target environments efficiently. However, existing works for such a situation still suffer from requiring many GPUs and expensive costs. Motivated by this, we propose a novel neural network optimization framework named Bespoke for low-cost deployment. Our framework searches for a lightweight model by replacing parts of an original model with randomly selected alternatives, each of which comes from a pretrained neural network or the original model. In the practical sense, Bespoke has two significant merits. One is that it requires near zero cost for designing the search space of neural networks. The other merit is that it exploits the sub-networks of public pretrained neural networks, so the total cost is minimal compared to the existing works. We conduct experiments exploring Bespoke&#39;s the merits, and the results show that it finds efficient models for multiple targets with meager cost.},
  archive   = {C_AAAI},
  author    = {Jong-Ryul Lee and Yong-Hyuk Moon},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26020},
  pages     = {8465-8472},
  title     = {Bespoke: A block-level neural network optimization framework for low-cost deployment},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). I’m me, we’re us, and i’m us: Tri-directional contrastive
learning on hypergraphs. <em>AAAI</em>, 8456–8464. (<a
href="https://doi.org/10.1609/aaai.v37i7.26019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Although machine learning on hypergraphs has attracted considerable attention, most of the works have focused on (semi-)supervised learning, which may cause heavy labeling costs and poor generalization. Recently, contrastive learning has emerged as a successful unsupervised representation learning method. Despite the prosperous development of contrastive learning in other domains, contrastive learning on hypergraphs remains little explored. In this paper, we propose TriCL (Tri-directional Contrastive Learning), a general framework for contrastive learning on hypergraphs. Its main idea is tri-directional contrast, and specifically, it aims to maximize in two augmented views the agreement (a) between the same node, (b) between the same group of nodes, and (c) between each group and its members. Together with simple but surprisingly effective data augmentation and negative sampling schemes, these three forms of contrast enable TriCL to capture both node- and group-level structural information in node embeddings. Our extensive experiments using 14 baseline approaches, 10 datasets, and two tasks demonstrate the effectiveness of TriCL, and most noticeably, TriCL almost consistently outperforms not just unsupervised competitors but also (semi-)supervised competitors mostly by significant margins for node classification. The code and datasets are available at https://github.com/wooner49/TriCL.},
  archive   = {C_AAAI},
  author    = {Dongjin Lee and Kijung Shin},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26019},
  pages     = {8456-8464},
  title     = {I’m me, we’re us, and i’m us: Tri-directional contrastive learning on hypergraphs},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generalization bounds for inductive matrix completion in
low-noise settings. <em>AAAI</em>, 8447–8455. (<a
href="https://doi.org/10.1609/aaai.v37i7.26018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study inductive matrix completion (matrix completion with side information) under an i.i.d. subgaussian noise assumption at a low noise regime, with uniform sampling of the entries. We obtain for the first time generalization bounds with the following three properties: (1) they scale like the standard deviation of the noise and in particular approach zero in the exact recovery case; (2) even in the presence of noise, they converge to zero when the sample size approaches infinity; and (3) for a fixed dimension of the side information, they only have a logarithmic dependence on the size of the matrix. Differently from many works in approximate recovery, we present results both for bounded Lipschitz losses and for the absolute loss, with the latter relying on Talagrand-type inequalities. The proofs create a bridge between two approaches to the theoretical analysis of matrix completion, since they consist in a combination of techniques from both the exact recovery literature and the approximate recovery literature.},
  archive   = {C_AAAI},
  author    = {Antoine Ledent and Rodrigo Alves and Yunwen Lei and Yann Guermeur and Marius Kloft},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26018},
  pages     = {8447-8455},
  title     = {Generalization bounds for inductive matrix completion in low-noise settings},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A data source for reasoning embodied agents. <em>AAAI</em>,
8438–8446. (<a href="https://doi.org/10.1609/aaai.v37i7.26017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent progress in using machine learning models for reasoning tasks has been driven by novel model architectures, large-scale pre-training protocols, and dedicated reasoning datasets for fine-tuning. In this work, to further pursue these advances, we introduce a new data generator for machine reasoning that integrates with an embodied agent. The generated data consists of templated text queries and answers, matched with world-states encoded into a database. The world-states are a result of both world dynamics and the actions of the agent. We show the results of several baseline models on instantiations of train sets. These include pre-trained language models fine-tuned on a text-formatted representation of the database, and graph-structured Transformers operating on a knowledge-graph representation of the database. We find that these models can answer some questions about the world-state, but struggle with others. These results hint at new research directions in designing neural reasoning models and database representations. Code to generate the data and train the models will be released at github.com/facebookresearch/neuralmemory},
  archive   = {C_AAAI},
  author    = {Jack Lanchantin and Sainbayar Sukhbaatar and Gabriel Synnaeve and Yuxuan Sun and Kavya Srinet and Arthur Szlam},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26017},
  pages     = {8438-8446},
  title     = {A data source for reasoning embodied agents},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SpatialFormer: Semantic and target aware attentions for
few-shot learning. <em>AAAI</em>, 8430–8437. (<a
href="https://doi.org/10.1609/aaai.v37i7.26016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent Few-Shot Learning (FSL) methods put emphasis on generating a discriminative embedding features to precisely measure the similarity between support and query sets. Current CNN-based cross-attention approaches generate discriminative representations via enhancing the mutually semantic similar regions of support and query pairs. However, it suffers from two problems: CNN structure produces inaccurate attention map based on local features, and mutually similar backgrounds cause distraction. To alleviate these problems, we design a novel SpatialFormer structure to generate more accurate attention regions based on global features. Different from the traditional Transformer modeling intrinsic instance-level similarity which causes accuracy degradation in FSL, our SpatialFormer explores the semantic-level similarity between pair inputs to boost the performance. Then we derive two specific attention modules, named SpatialFormer Semantic Attention (SFSA) and SpatialFormer Target Attention (SFTA), to enhance the target object regions while reduce the background distraction. Particularly, SFSA highlights the regions with same semantic information between pair features, and SFTA finds potential foreground object regions of novel feature that are similar to base categories. Extensive experiments show that our methods are effective and achieve new state-of-the-art results on few-shot classification benchmarks.},
  archive   = {C_AAAI},
  author    = {Jinxiang Lai and Siqian Yang and Wenlong Wu and Tao Wu and Guannan Jiang and Xi Wang and Jun Liu and Bin-Bin Gao and Wei Zhang and Yuan Xie and Chengjie Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26016},
  pages     = {8430-8437},
  title     = {SpatialFormer: Semantic and target aware attentions for few-shot learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). WLD-reg: A data-dependent within-layer diversity
regularizer. <em>AAAI</em>, 8421–8429. (<a
href="https://doi.org/10.1609/aaai.v37i7.26015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Neural networks are composed of multiple layers arranged in a hierarchical structure jointly trained with a gradient-based optimization, where the errors are back-propagated from the last layer back to the first one. At each optimization step, neurons at a given layer receive feedback from neurons belonging to higher layers of the hierarchy. In this paper, we propose to complement this traditional &#39;between-layer&#39; feedback with additional &#39;within-layer&#39; feedback to encourage the diversity of the activations within the same layer. To this end, we measure the pairwise similarity between the outputs of the neurons and use it to model the layer&#39;s overall diversity. We present an extensive empirical study confirming that the proposed approach enhances the performance of several state-of-the-art neural network models in multiple tasks. The code is publically available at https://github.com/firasl/AAAI-23-WLD-Reg.},
  archive   = {C_AAAI},
  author    = {Firas Laakom and Jenni Raitoharju and Alexandros Iosifidis and Moncef Gabbouj},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26015},
  pages     = {8421-8429},
  title     = {WLD-reg: A data-dependent within-layer diversity regularizer},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). LoNe sampler: Graph node embeddings by coordinated local
neighborhood sampling. <em>AAAI</em>, 8413–8420. (<a
href="https://doi.org/10.1609/aaai.v37i7.26014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Local graph neighborhood sampling is a fundamental computational problem that is at the heart of algorithms for node representation learning. Several works have presented algorithms for learning discrete node embeddings where graph nodes are represented by discrete features such as attributes of neighborhood nodes. Discrete embeddings offer several advantages compared to continuous word2vec-like node embeddings: ease of computation, scalability, and interpretability. We present LoNe Sampler, a suite of algorithms for generating discrete node embeddings by Local Neighborhood Sampling, and address two shortcomings of previous work. First, our algorithms have rigorously understood theoretical properties. Second, we show how to generate approximate explicit vector maps that avoid the expensive computation of a Gram matrix for the training of a kernel model. Experiments on benchmark datasets confirm the theoretical findings and demonstrate the advantages of the proposed methods.},
  archive   = {C_AAAI},
  author    = {Konstantin Kutzkov},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26014},
  pages     = {8413-8420},
  title     = {LoNe sampler: Graph node embeddings by coordinated local neighborhood sampling},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Gradient estimation for binary latent variables via gradient
variance clipping. <em>AAAI</em>, 8405–8412. (<a
href="https://doi.org/10.1609/aaai.v37i7.26013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Gradient estimation is often necessary for fitting generative models with discrete latent variables, in contexts such as reinforcement learning and variational autoencoder (VAE) training. The DisARM estimator achieves state of the art gradient variance for Bernoulli latent variable models in many contexts. However, DisARM and other estimators have potentially exploding variance near the boundary of the parameter space, where solutions tend to lie. To ameliorate this issue, we propose a new gradient estimator bitflip-1 that is lower variance at the boundaries of the parameter space. As bitflip-1 has complementary properties to existing estimators, we introduce an aggregated estimator, unbiased gradient variance clipping (UGC) that uses either a bitflip-1 or a DisARM gradient update for each coordinate. We theoretically prove that UGC has uniformly lower variance than DisARM. Empirically, we observe that UGC achieves the optimal value of the optimization objectives in toy experiments, discrete VAE training, and in a best subset selection problem.},
  archive   = {C_AAAI},
  author    = {Russell Z. Kunes and Mingzhang Yin and Max Land and Doron Haviv and Dana Pe&#39;er and Simon Tavaré},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26013},
  pages     = {8405-8412},
  title     = {Gradient estimation for binary latent variables via gradient variance clipping},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The effect of diversity in meta-learning. <em>AAAI</em>,
8396–8404. (<a href="https://doi.org/10.1609/aaai.v37i7.26012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent studies show that task distribution plays a vital role in the meta-learner&#39;s performance. Conventional wisdom is that task diversity should improve the performance of meta-learning. In this work, we find evidence to the contrary; (i) our experiments draw into question the efficacy of our learned models: similar manifolds can be learned with a subset of the data (lower task diversity). This finding questions the advantage of providing more data to the model, and (ii) adding diversity to the task distribution (higher task diversity) sometimes hinders the model and does not lead to a significant improvement in performance as previously believed. To strengthen our findings, we provide both empirical and theoretical evidence.},
  archive   = {C_AAAI},
  author    = {Ramnath Kumar and Tristan Deleu and Yoshua Bengio},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26012},
  pages     = {8396-8404},
  title     = {The effect of diversity in meta-learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). UEQMS: UMAP embedded quick mean shift algorithm for high
dimensional clustering. <em>AAAI</em>, 8386–8395. (<a
href="https://doi.org/10.1609/aaai.v37i7.26011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The mean shift algorithm is a simple yet very effective clustering method widely used for image and video segmentation as well as other exploratory data analysis applications. Recently, a new algorithm called MeanShift++ (MS++) for low-dimensional clustering was proposed with a speedup of 4000 times over the vanilla mean shift. In this work, starting with a first-of-its-kind theoretical analysis of MS++, we extend its reach to high-dimensional data clustering by integrating the Uniform Manifold Approximation and Projection (UMAP) based dimensionality reduction in the same framework. Analytically, we show that MS++ can indeed converge to a non-critical point. Subsequently, we suggest modifications to MS++ to improve its convergence characteristics. In addition, we propose a way to further speed up MS++ by avoiding the execution of the MS++ iterations for every data point. By incorporating UMAP with modified MS++, we design a faster algorithm, named UMAP embedded quick mean shift (UEQMS), for partitioning data with a relatively large number of recorded features. Through extensive experiments, we showcase the efficacy of UEQMS over other state-of-the-art algorithms in terms of accuracy and runtime.},
  archive   = {C_AAAI},
  author    = {Abhishek Kumar and Swagatam Das and Rammohan Mallipeddi},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26011},
  pages     = {8386-8395},
  title     = {UEQMS: UMAP embedded quick mean shift algorithm for high dimensional clustering},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Almost cost-free communication in federated best arm
identification. <em>AAAI</em>, 8378–8385. (<a
href="https://doi.org/10.1609/aaai.v37i7.26010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the problem of best arm identification in a federated learning multi-armed bandit setup with a central server and multiple clients. Each client is associated with a multi-armed bandit in which each arm yields i.i.d. rewards following a Gaussian distribution with an unknown mean and known variance. The set of arms is assumed to be the same at all the clients. We define two notions of best arm local and global. The local best arm at a client is the arm with the largest mean among the arms local to the client, whereas the global best arm is the arm with the largest average mean across all the clients. We assume that each client can only observe the rewards from its local arms and thereby estimate its local best arm. The clients communicate with a central server on uplinks that entail a cost of C&gt;=0 units per usage per uplink. The global best arm is estimated at the server. The goal is to identify the local best arms and the global best arm with minimal total cost, defined as the sum of the total number of arm selections at all the clients and the total communication cost, subject to an upper bound on the error probability. We propose a novel algorithm FedElim that is based on successive elimination and communicates only in exponential time steps and obtain a high probability instance-dependent upper bound on its total cost. The key takeaway from our paper is that for any C&gt;=0 and error probabilities sufficiently small, the total number of arm selections (resp. the total cost) under FedElim is at most 2 (resp. 3) times the maximum total number of arm selections under its variant that communicates in every time step. Additionally, we show that the latter is optimal in expectation up to a constant factor, thereby demonstrating that communication is almost cost-free in FedElim. We numerically validate the efficacy of FedElim on two synthetic datasets and the MovieLens dataset.},
  archive   = {C_AAAI},
  author    = {Srinivas Reddy Kota and P. N. Karthik and Vincent Y. F. Tan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26010},
  pages     = {8378-8385},
  title     = {Almost cost-free communication in federated best arm identification},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adversarial robust deep reinforcement learning requires
redefining robustness. <em>AAAI</em>, 8369–8377. (<a
href="https://doi.org/10.1609/aaai.v37i7.26009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Learning from raw high dimensional data via interaction with a given environment has been effectively achieved through the utilization of deep neural networks. Yet the observed degradation in policy performance caused by imperceptible worst-case policy dependent translations along high sensitivity directions (i.e. adversarial perturbations) raises concerns on the robustness of deep reinforcement learning policies. In our paper, we show that these high sensitivity directions do not lie only along particular worst-case directions, but rather are more abundant in the deep neural policy landscape and can be found via more natural means in a black-box setting. Furthermore, we show that vanilla training techniques intriguingly result in learning more robust policies compared to the policies learnt via the state-of-the-art adversarial training techniques. We believe our work lays out intriguing properties of the deep reinforcement learning policy manifold and our results can help to build robust and generalizable deep reinforcement learning policies.},
  archive   = {C_AAAI},
  author    = {Ezgi Korkmaz},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26009},
  pages     = {8369-8377},
  title     = {Adversarial robust deep reinforcement learning requires redefining robustness},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Peeling the onion: Hierarchical reduction of data redundancy
for efficient vision transformer training. <em>AAAI</em>, 8360–8368. (<a
href="https://doi.org/10.1609/aaai.v37i7.26008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Vision transformers (ViTs) have recently obtained success in many applications, but their intensive computation and heavy memory usage at both training and inference time limit their generalization. Previous compression algorithms usually start from the pre-trained dense models and only focus on efficient inference, while time-consuming training is still unavoidable. In contrast, this paper points out that the million-scale training data is redundant, which is the fundamental reason for the tedious training. To address the issue, this paper aims to introduce sparsity into data and proposes an end-to-end efficient training framework from three sparse perspectives, dubbed Tri-Level E-ViT. Specifically, we leverage a hierarchical data redundancy reduction scheme, by exploring the sparsity under three levels: number of training examples in the dataset, number of patches (tokens) in each example, and number of connections between tokens that lie in attention weights. With extensive experiments, we demonstrate that our proposed technique can noticeably accelerate training for various ViT architectures while maintaining accuracy. Remarkably, under certain ratios, we are able to improve the ViT accuracy rather than compromising it. For example, we can achieve 15.2\% speedup with 72.6\% (+0.4) Top-1 accuracy on Deit-T, and 15.7\% speedup with 79.9\% (+0.1) Top-1 accuracy on Deit-S. This proves the existence of data redundancy in ViT. Our code is released at https://github.com/ZLKong/Tri-Level-ViT},
  archive   = {C_AAAI},
  author    = {Zhenglun Kong and Haoyu Ma and Geng Yuan and Mengshu Sun and Yanyue Xie and Peiyan Dong and Xin Meng and Xuan Shen and Hao Tang and Minghai Qin and Tianlong Chen and Xiaolong Ma and Xiaohui Xie and Zhangyang Wang and Yanzhi Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26008},
  pages     = {8360-8368},
  title     = {Peeling the onion: Hierarchical reduction of data redundancy for efficient vision transformer training},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning similarity metrics for volumetric simulations with
multiscale CNNs. <em>AAAI</em>, 8351–8359. (<a
href="https://doi.org/10.1609/aaai.v37i7.26007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Simulations that produce three-dimensional data are ubiquitous in science, ranging from fluid flows to plasma physics. We propose a similarity model based on entropy, which allows for the creation of physically meaningful ground truth distances for the similarity assessment of scalar and vectorial data, produced from transport and motion-based simulations. Utilizing two data acquisition methods derived from this model, we create collections of fields from numerical PDE solvers and existing simulation data repositories. Furthermore, a multiscale CNN architecture that computes a volumetric similarity metric (VolSiM) is proposed. To the best of our knowledge this is the first learning method inherently designed to address the challenges arising for the similarity assessment of high-dimensional simulation data. Additionally, the tradeoff between a large batch size and an accurate correlation computation for correlation-based loss functions is investigated, and the metric&#39;s invariance with respect to rotation and scale operations is analyzed. Finally, the robustness and generalization of VolSiM is evaluated on a large range of test data, as well as a particularly challenging turbulence case study, that is close to potential real-world applications.},
  archive   = {C_AAAI},
  author    = {Georg Kohl and Li-Wei Chen and Nils Thuerey},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26007},
  pages     = {8351-8359},
  title     = {Learning similarity metrics for volumetric simulations with multiscale CNNs},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The influence of dimensions on the complexity of computing
decision trees. <em>AAAI</em>, 8343–8350. (<a
href="https://doi.org/10.1609/aaai.v37i7.26006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A decision tree recursively splits a feature space \mathbb{R}^d and then assigns class labels based on the resulting partition. Decision trees have been part of the basic machine-learning toolkit for decades. A large body of work considers heuristic algorithms that compute a decision tree from training data, usually aiming to minimize in particular the size of the resulting tree. In contrast, little is known about the complexity of the underlying computational problem of computing a minimum-size tree for the given training data. We study this problem with respect to the number d of dimensions of the feature space \mathbb{R}^d, which contains n training examples. We show that it can be solved in O(n^(2d + 1)) time, but under reasonable complexity-theoretic assumptions it is not possible to achieve f(d) * n^o(d / log d) running time. The problem is solvable in (dR)^O(dR) * n^(1+o(1)) time, if there are exactly two classes and R is an upper bound on the number of tree leaves labeled with the first class.},
  archive   = {C_AAAI},
  author    = {Stephen G. Kobourov and Maarten Löffler and Fabrizio Montecchiani and Marcin Pilipczuk and Ignaz Rutter and Raimund Seidel and Manuel Sorge and Jules Wulms},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26006},
  pages     = {8343-8350},
  title     = {The influence of dimensions on the complexity of computing decision trees},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Grouping matrix based graph pooling with adaptive number of
clusters. <em>AAAI</em>, 8334–8342. (<a
href="https://doi.org/10.1609/aaai.v37i7.26005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph pooling is a crucial operation for encoding hierarchical structures within graphs. Most existing graph pooling approaches formulate the problem as a node clustering task which effectively captures the graph topology. Conventional methods ask users to specify an appropriate number of clusters as a hyperparameter, then assuming that all input graphs share the same number of clusters. In inductive settings where the number of clusters could vary, however, the model should be able to represent this variation in its pooling layers in order to learn suitable clusters. Thus we propose GMPool, a novel differentiable graph pooling architecture that automatically determines the appropriate number of clusters based on the input data. The main intuition involves a grouping matrix defined as a quadratic form of the pooling operator, which induces use of binary classification probabilities of pairwise combinations of nodes. GMPool obtains the pooling operator by first computing the grouping matrix, then decomposing it. Extensive evaluations on molecular property prediction tasks demonstrate that our method outperforms conventional methods.},
  archive   = {C_AAAI},
  author    = {Sung Moon Ko and Sungjun Cho and Dae-Woong Jeong and Sehui Han and Moontae Lee and Honglak Lee},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26005},
  pages     = {8334-8342},
  title     = {Grouping matrix based graph pooling with adaptive number of clusters},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A gift from label smoothing: Robust training with adaptive
label smoothing via auxiliary classifier under label noise.
<em>AAAI</em>, 8325–8333. (<a
href="https://doi.org/10.1609/aaai.v37i7.26004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As deep neural networks can easily overfit noisy labels, robust training in the presence of noisy labels is becoming an important challenge in modern deep learning. While existing methods address this problem in various directions, they still produce unpredictable sub-optimal results since they rely on the posterior information estimated by the feature extractor corrupted by noisy labels. Lipschitz regularization successfully alleviates this problem by training a robust feature extractor, but it requires longer training time and expensive computations. Motivated by this, we propose a simple yet effective method, called ALASCA, which efficiently provides a robust feature extractor under label noise. ALASCA integrates two key ingredients: (1) adaptive label smoothing based on our theoretical analysis that label smoothing implicitly induces Lipschitz regularization, and (2) auxiliary classifiers that enable practical application of intermediate Lipschitz regularization with negligible computations. We conduct wide-ranging experiments for ALASCA and combine our proposed method with previous noise-robust methods on several synthetic and real-world datasets. Experimental results show that our framework consistently improves the robustness of feature extractors and the performance of existing baselines with efficiency.},
  archive   = {C_AAAI},
  author    = {Jongwoo Ko and Bongsoo Yi and Se-Young Yun},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26004},
  pages     = {8325-8333},
  title     = {A gift from label smoothing: Robust training with adaptive label smoothing via auxiliary classifier under label noise},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FastAMI – a monte carlo approach to the adjustment for
chance in clustering comparison metrics. <em>AAAI</em>, 8317–8324. (<a
href="https://doi.org/10.1609/aaai.v37i7.26003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Clustering is at the very core of machine learning, and its applications proliferate with the increasing availability of data. However, as datasets grow, comparing clusterings with an adjustment for chance becomes computationally difficult, preventing unbiased ground-truth comparisons and solution selection. We propose FastAMI, a Monte Carlo-based method to efficiently approximate the Adjusted Mutual Information (AMI) and extend it to the Standardized Mutual Information (SMI). The approach is compared with the exact calculation and a recently developed variant of the AMI based on pairwise permutations, using both synthetic and real data. In contrast to the exact calculation our method is fast enough to enable these adjusted information-theoretic comparisons for large datasets while maintaining considerably more accurate results than the pairwise approach.},
  archive   = {C_AAAI},
  author    = {Kai Klede and Leo Schwinn and Dario Zanca and Björn Eskofier},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26003},
  pages     = {8317-8324},
  title     = {FastAMI – a monte carlo approach to the adjustment for chance in clustering comparison metrics},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploring temporal information dynamics in spiking neural
networks. <em>AAAI</em>, 8308–8316. (<a
href="https://doi.org/10.1609/aaai.v37i7.26002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Most existing Spiking Neural Network (SNN) works state that SNNs may utilize temporal information dynamics of spikes. However, an explicit analysis of temporal information dynamics is still missing. In this paper, we ask several important questions for providing a fundamental understanding of SNNs: What are temporal information dynamics inside SNNs? How can we measure the temporal information dynamics? How do the temporal information dynamics affect the overall learning performance? To answer these questions, we estimate the Fisher Information of the weights to measure the distribution of temporal information during training in an empirical manner. Surprisingly, as training goes on, Fisher information starts to concentrate in the early timesteps. After training, we observe that information becomes highly concentrated in earlier few timesteps, a phenomenon we refer to as temporal information concentration. We observe that the temporal information concentration phenomenon is a common learning feature of SNNs by conducting extensive experiments on various configurations such as architecture, dataset, optimization strategy, time constant, and timesteps. Furthermore, to reveal how temporal information concentration affects the performance of SNNs, we design a loss function to change the trend of temporal information. We find that temporal information concentration is crucial to building a robust SNN but has little effect on classification accuracy. Finally, we propose an efficient iterative pruning method based on our observation on temporal information concentration. Code is available at https://github.com/Intelligent-Computing-Lab-Yale/Exploring-Temporal-Information-Dynamics-in-Spiking-Neural-Networks.},
  archive   = {C_AAAI},
  author    = {Youngeun Kim and Yuhang Li and Hyoungseob Park and Yeshwanth Venkatesha and Anna Hambitzer and Priyadarshini Panda},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26002},
  pages     = {8308-8316},
  title     = {Exploring temporal information dynamics in spiking neural networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Double doubly robust thompson sampling for generalized
linear contextual bandits. <em>AAAI</em>, 8300–8307. (<a
href="https://doi.org/10.1609/aaai.v37i7.26001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose a novel algorithm for generalized linear contextual bandits (GLBs) with a regret bound sublinear to the time horizon, the minimum eigenvalue of the covariance of contexts and a lower bound of the variance of rewards. In several identified cases, our result is the first regret bound for generalized linear bandits (GLBs) achieving the regret bound sublinear to the dimension of contexts without discarding the observed rewards. Previous approaches achieve the regret bound sublinear to the dimension of contexts by discarding the observed rewards, whereas our algorithm achieves the bound incorporating contexts from all arms in our double doubly robust (DDR) estimator. The DDR estimator is a subclass of doubly robust estimator but with a tighter error bound. We also provide a logarithmic cumulative regret bound under a probabilistic margin condition. This is the first regret bound under the margin condition for linear models or GLMs when contexts are different for all arms but coefficients are common. We conduct empirical studies using synthetic data and real examples, demonstrating the effectiveness of our algorithm.},
  archive   = {C_AAAI},
  author    = {Wonyoung Kim and Kyungbok Lee and Myunghee Cho Paik},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26001},
  pages     = {8300-8307},
  title     = {Double doubly robust thompson sampling for generalized linear contextual bandits},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning topology-specific experts for molecular property
prediction. <em>AAAI</em>, 8291–8299. (<a
href="https://doi.org/10.1609/aaai.v37i7.26000">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, graph neural networks (GNNs) have been successfully applied to predicting molecular properties, which is one of the most classical cheminformatics tasks with various applications. Despite their effectiveness, we empirically observe that training a single GNN model for diverse molecules with distinct structural patterns limits its prediction performance. In this paper, motivated by this observation, we propose TopExpert to leverage topology-specific prediction models (referred to as experts), each of which is responsible for each molecular group sharing similar topological semantics. That is, each expert learns topology-specific discriminative features while being trained with its corresponding topological group. To tackle the key challenge of grouping molecules by their topological patterns, we introduce a clustering-based gating module that assigns an input molecule into one of the clusters and further optimizes the gating module with two different types of self-supervision: topological semantics induced by GNNs and molecular scaffolds, respectively. Extensive experiments demonstrate that TopExpert has boosted the performance for molecular property prediction and also achieved better generalization for new molecules with unseen scaffolds than baselines. The code is available at https://github.com/kimsu55/ToxExpert.},
  archive   = {C_AAAI},
  author    = {Suyeon Kim and Dongha Lee and SeongKu Kang and Seonghyeon Lee and Hwanjo Yu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.26000},
  pages     = {8291-8299},
  title     = {Learning topology-specific experts for molecular property prediction},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Better generalized few-shot learning even without base data.
<em>AAAI</em>, 8282–8290. (<a
href="https://doi.org/10.1609/aaai.v37i7.25999">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper introduces and studies zero-base generalized few-shot learning (zero-base GFSL), which is an extreme yet practical version of few-shot learning problem. Motivated by the cases where base data is not available due to privacy or ethical issues, the goal of zero-base GFSL is to newly incorporate the knowledge of few samples of novel classes into a pretrained model without any samples of base classes. According to our analysis, we discover the fact that both mean and variance of the weight distribution of novel classes are not properly established, compared to those of base classes. The existing GFSL methods attempt to make the weight norms balanced, which we find help only the variance part, but discard the importance of mean of weights particularly for novel classes, leading to the limited performance in the GFSL problem even with base data. In this paper, we overcome this limitation by proposing a simple yet effective normalization method that can effectively control both mean and variance of the weight distribution of novel classes without using any base samples and thereby achieve a satisfactory performance on both novel and base classes. Our experimental results somewhat surprisingly show that the proposed zero-base GFSL method that does not utilize any base samples even outperforms the existing GFSL methods that make the best use of base data. Our implementation is available at: https://github.com/bigdata-inha/Zero-Base-GFSL.},
  archive   = {C_AAAI},
  author    = {Seong-Woong Kim and Dong-Wan Choi},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.25999},
  pages     = {8282-8290},
  title     = {Better generalized few-shot learning even without base data},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Deep visual forced alignment: Learning to align
transcription with talking face video. <em>AAAI</em>, 8273–8281. (<a
href="https://doi.org/10.1609/aaai.v37i7.25998">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Forced alignment refers to a technology that time-aligns a given transcription with a corresponding speech. However, as the forced alignment technologies have developed using speech audio, they might fail in alignment when the input speech audio is noise-corrupted or is not accessible. We focus on that there is another component that the speech can be inferred from, the speech video (i.e., talking face video). Since the drawbacks of audio-based forced alignment can be complemented using the visual information when the audio signal is under poor condition, we try to develop a novel video-based forced alignment method. However, different from audio forced alignment, it is challenging to develop a reliable visual forced alignment technology for the following two reasons: 1) Visual Speech Recognition (VSR) has a much lower performance compared to audio-based Automatic Speech Recognition (ASR), and 2) the translation from text to video is not reliable, so the method typically used for building audio forced alignment cannot be utilized in developing visual forced alignment. In order to alleviate these challenges, in this paper, we propose a new method that is appropriate for visual forced alignment, namely Deep Visual Forced Alignment (DVFA). The proposed DVFA can align the input transcription (i.e., sentence) with the talking face video without accessing the speech audio. Moreover, by augmenting the alignment task with anomaly case detection, DVFA can detect mismatches between the input transcription and the input video while performing the alignment. Therefore, we can robustly align the text with the talking face video even if there exist error words in the text. Through extensive experiments, we show the effectiveness of the proposed DVFA not only in the alignment task but also in interpreting the outputs of VSR models.},
  archive   = {C_AAAI},
  author    = {Minsu Kim and Chae Won Kim and Yong Man Ro},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.25998},
  pages     = {8273-8281},
  title     = {Deep visual forced alignment: Learning to align transcription with talking face video},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Inverse-reference priors for fisher regularization of
bayesian neural networks. <em>AAAI</em>, 8264–8272. (<a
href="https://doi.org/10.1609/aaai.v37i7.25997">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent studies have shown that the generalization ability of deep neural networks (DNNs) is closely related to the Fisher information matrix (FIM) calculated during the early training phase. Several methods have been proposed to regularize the FIM for increased generalization of DNNs. However, they cannot be used directly for Bayesian neural networks (BNNs) because the variable parameters of BNNs make it difficult to calculate the FIM. To address this problem, we achieve regularization of the FIM of BNNs by specifying a new suitable prior distribution called the inverse-reference (IR) prior. To regularize the FIM, the IR prior is derived as the inverse of the reference prior that imposes minimal prior knowledge on the parameters and maximizes the trace of the FIM. We demonstrate that the IR prior can enhance the generalization ability of BNNs for large-scale data over previously used priors while providing adequate uncertainty quantifications using various benchmark image datasets and BNN structures.},
  archive   = {C_AAAI},
  author    = {Keunseo Kim and Eun-Yeol Ma and Jeongman Choi and Heeyoung Kim},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.25997},
  pages     = {8264-8272},
  title     = {Inverse-reference priors for fisher regularization of bayesian neural networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FLAME: Free-form language-based motion synthesis &amp;
editing. <em>AAAI</em>, 8255–8263. (<a
href="https://doi.org/10.1609/aaai.v37i7.25996">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Text-based motion generation models are drawing a surge of interest for their potential for automating the motion-making process in the game, animation, or robot industries. In this paper, we propose a diffusion-based motion synthesis and editing model named FLAME. Inspired by the recent successes in diffusion models, we integrate diffusion-based generative models into the motion domain. FLAME can generate high-fidelity motions well aligned with the given text. Also, it can edit the parts of the motion, both frame-wise and joint-wise, without any fine-tuning. FLAME involves a new transformer-based architecture we devise to better handle motion data, which is found to be crucial to manage variable-length motions and well attend to free-form text. In experiments, we show that FLAME achieves state-of-the-art generation performances on three text-motion datasets: HumanML3D, BABEL, and KIT. We also demonstrate that FLAME’s editing capability can be extended to other tasks such as motion prediction or motion in-betweening, which have been previously covered by dedicated models.},
  archive   = {C_AAAI},
  author    = {Jihoon Kim and Jiseob Kim and Sungjoon Choi},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.25996},
  pages     = {8255-8263},
  title     = {FLAME: Free-form language-based motion synthesis &amp; editing},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Key feature replacement of in-distribution samples for
out-of-distribution detection. <em>AAAI</em>, 8246–8254. (<a
href="https://doi.org/10.1609/aaai.v37i7.25995">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Out-of-distribution (OOD) detection can be used in deep learning-based applications to reject outlier samples from being unreliably classified by deep neural networks. Learning to classify between OOD and in-distribution samples is difficult because data comprising the former is extremely diverse. It has been observed that an auxiliary OOD dataset is most effective in training a ``rejection&#39;&#39; network when its samples are semantically similar to in-distribution images. We first deduce that OOD images are perceived by a deep neural network to be semantically similar to in-distribution samples when they share a common background, as deep networks are observed to incorrectly classify such images with high confidence. We then propose a simple yet effective Key In-distribution feature Replacement BY inpainting (KIRBY) procedure that constructs a surrogate OOD dataset by replacing class-discriminative features of in-distribution samples with marginal background features. The procedure can be implemented using off-the-shelf vision algorithms, where each step within the algorithm is shown to make the surrogate data increasingly similar to in-distribution data. Design choices in each step are studied extensively, and an exhaustive comparison with state-of-the-art algorithms demonstrates KIRBY&#39;s competitiveness on various benchmarks.},
  archive   = {C_AAAI},
  author    = {Jaeyoung Kim and Seo Taek Kong and Dongbin Na and Kyu-Hwan Jung},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.25995},
  pages     = {8246-8254},
  title     = {Key feature replacement of in-distribution samples for out-of-distribution detection},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CertiFair: A framework for certified global fairness of
neural networks. <em>AAAI</em>, 8237–8245. (<a
href="https://doi.org/10.1609/aaai.v37i7.25994">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider the problem of whether a Neural Network (NN) model satisfies global individual fairness. Individual Fairness (defined in (Dwork et al. 2012)) suggests that similar individuals with respect to a certain task are to be treated similarly by the decision model. In this work, we have two main objectives. The first is to construct a verifier which checks whether the fairness property holds for a given NN in a classification task or provides a counterexample if it is violated, i.e., the model is fair if all similar individuals are classified the same, and unfair if a pair of similar individuals are classified differently. To that end, we construct a sound and complete verifier that verifies global individual fairness properties of ReLU NN classifiers using distance-based similarity metrics. The second objective of this paper is to provide a method for training provably fair NN classifiers from unfair (biased) data. We propose a fairness loss that can be used during training to enforce fair outcomes for similar individuals. We then provide provable bounds on the fairness of the resulting NN. We run experiments on commonly used fairness datasets that are publicly available and we show that global individual fairness can be improved by 96\% without a significant drop in test accuracy.},
  archive   = {C_AAAI},
  author    = {Haitham Khedr and Yasser Shoukry},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.25994},
  pages     = {8237-8245},
  title     = {CertiFair: A framework for certified global fairness of neural networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On error and compression rates for prototype rules.
<em>AAAI</em>, 8228–8236. (<a
href="https://doi.org/10.1609/aaai.v37i7.25993">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the close interplay between error and compression in the non-parametric multiclass classification setting in terms of prototype learning rules. We focus in particular on a recently proposed compression-based learning rule termed OptiNet. Beyond its computational merits, this rule has been recently shown to be universally consistent in any metric instance space that admits a universally consistent rule---the first learning algorithm known to enjoy this property. However, its error and compression rates have been left open. Here we derive such rates in the case where instances reside in Euclidean space under commonly posed smoothness and tail conditions on the data distribution. We first show that OptiNet achieves non-trivial compression rates while enjoying near minimax-optimal error rates. We then proceed to study a novel general compression scheme for further compressing prototype rules that locally adapts to the noise level without sacrificing accuracy. Applying it to OptiNet, we show that under a geometric margin condition further gain in the compression rate is achieved. Experimental results comparing the performance of the various methods are presented.},
  archive   = {C_AAAI},
  author    = {Omer Kerem and Roi Weiss},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.25993},
  pages     = {8228-8236},
  title     = {On error and compression rates for prototype rules},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Design amortization for bayesian optimal experimental
design. <em>AAAI</em>, 8220–8227. (<a
href="https://doi.org/10.1609/aaai.v37i7.25992">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Bayesian optimal experimental design is a sub-field of statistics focused on developing methods to make efficient use of experimental resources. Any potential design is evaluated in terms of a utility function, such as the (theoretically well-justified) expected information gain (EIG); unfortunately however, under most circumstances the EIG is intractable to evaluate. In this work we build off of successful variational approaches, which optimize a parameterized variational model with respect to bounds on the EIG. Past work focused on learning a new variational model from scratch for each new design considered. Here we present a novel neural architecture that allows experimenters to optimize a single variational model that can estimate the EIG for potentially infinitely many designs. To further improve computational efficiency, we also propose to train the variational model on a significantly cheaper-to-evaluate lower bound, and show empirically that the resulting model provides an excellent guide for more accurate, but expensive to evaluate bounds on the EIG. We demonstrate the effectiveness of our technique on generalized linear models, a class of statistical models that is widely used in the analysis of controlled experiments. Experiments show that our method is able to greatly improve accuracy over existing approximation strategies, and achieve these results with far better sample efficiency.},
  archive   = {C_AAAI},
  author    = {Noble Kennamer and Steven Walton and Alexander Ihler},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.25992},
  pages     = {8220-8227},
  title     = {Design amortization for bayesian optimal experimental design},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Variable-based calibration for machine learning classifiers.
<em>AAAI</em>, 8211–8219. (<a
href="https://doi.org/10.1609/aaai.v37i7.25991">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The deployment of machine learning classifiers in high-stakes domains requires well-calibrated confidence scores for model predictions. In this paper we introduce the notion of variable-based calibration to characterize calibration properties of a model with respect to a variable of interest, generalizing traditional score-based metrics such as expected calibration error (ECE). In particular, we find that models with near-perfect ECE can exhibit significant miscalibration as a function of features of the data. We demonstrate this phenomenon both theoretically and in practice on multiple well-known datasets, and show that it can persist after the application of existing calibration methods. To mitigate this issue, we propose strategies for detection, visualization, and quantification of variable-based calibration error. We then examine the limitations of current score-based calibration methods and explore potential modifications. Finally, we discuss the implications of these findings, emphasizing that an understanding of calibration beyond simple aggregate measures is crucial for endeavors such as fairness and model interpretability.},
  archive   = {C_AAAI},
  author    = {Markelle Kelly and Padhraic Smyth},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.25991},
  pages     = {8211-8219},
  title     = {Variable-based calibration for machine learning classifiers},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Communication-efficient collaborative best arm
identification. <em>AAAI</em>, 8203–8210. (<a
href="https://doi.org/10.1609/aaai.v37i7.25990">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We investigate top-m arm identification, a basic problem in bandit theory, in a multi-agent learning model in which agents collaborate to learn an objective function. We are interested in designing collaborative learning algorithms that achieve maximum speedup (compared to single-agent learning algorithms) using minimum communication cost, as communication is frequently the bottleneck in multi-agent learning. We give both algorithmic and impossibility results, and conduct a set of experiments to demonstrate the effectiveness of our algorithms.},
  archive   = {C_AAAI},
  author    = {Nikolai Karpov and Qin Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.25990},
  pages     = {8203-8210},
  title     = {Communication-efficient collaborative best arm identification},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the sample complexity of vanilla model-based offline
reinforcement learning with dependent samples. <em>AAAI</em>, 8195–8202.
(<a href="https://doi.org/10.1609/aaai.v37i7.25989">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Offline reinforcement learning (offline RL) considers problems where learning is performed using only previously collected samples and is helpful for the settings in which collecting new data is costly or risky. In model-based offline RL, the learner performs estimation (or optimization) using a model constructed according to the empirical transition frequencies. We analyze the sample complexity of vanilla model-based offline RL with dependent samples in the infinite-horizon discounted-reward setting. In our setting, the samples obey the dynamics of the Markov decision process and, consequently, may have interdependencies. Under no assumption of independent samples, we provide a high-probability, polynomial sample complexity bound for vanilla model-based off-policy evaluation that requires partial or uniform coverage. We extend this result to the off-policy optimization under uniform coverage. As a comparison to the model-based approach, we analyze the sample complexity of off-policy evaluation with vanilla importance sampling in the infinite-horizon setting. Finally, we provide an estimator that outperforms the sample-mean estimator for almost deterministic dynamics that are prevalent in reinforcement learning.},
  archive   = {C_AAAI},
  author    = {Mustafa O. Karabag and Ufuk Topcu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.25989},
  pages     = {8195-8202},
  title     = {On the sample complexity of vanilla model-based offline reinforcement learning with dependent samples},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PIXEL: Physics-informed cell representations for fast and
accurate PDE solvers. <em>AAAI</em>, 8186–8194. (<a
href="https://doi.org/10.1609/aaai.v37i7.25988">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With the increases in computational power and advances in machine learning, data-driven learning-based methods have gained significant attention in solving PDEs. Physics-informed neural networks (PINNs) have recently emerged and succeeded in various forward and inverse PDE problems thanks to their excellent properties, such as flexibility, mesh-free solutions, and unsupervised training. However, their slower convergence speed and relatively inaccurate solutions often limit their broader applicability in many science and engineering domains. This paper proposes a new kind of data-driven PDEs solver, physics-informed cell representations (PIXEL), elegantly combining classical numerical methods and learning-based approaches. We adopt a grid structure from the numerical methods to improve accuracy and convergence speed and overcome the spectral bias presented in PINNs. Moreover, the proposed method enjoys the same benefits in PINNs, e.g., using the same optimization frameworks to solve both forward and inverse PDE problems and readily enforcing PDE constraints with modern automatic differentiation techniques. We provide experimental results on various challenging PDEs that the original PINNs have struggled with and show that PIXEL achieves fast convergence speed and high accuracy. Project page: https://namgyukang.github.io/PIXEL/},
  archive   = {C_AAAI},
  author    = {Namgyu Kang and Byeonghyeon Lee and Youngjoon Hong and Seok-Bae Yun and Eunbyung Park},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.25988},
  pages     = {8186-8194},
  title     = {PIXEL: Physics-informed cell representations for fast and accurate PDE solvers},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Identifying selection bias from observational data.
<em>AAAI</em>, 8177–8185. (<a
href="https://doi.org/10.1609/aaai.v37i7.25987">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Access to a representative sample from the population is an assumption that underpins all of machine learning. Selection effects can cause observations to instead come from a subpopulation, by which our inferences may be subject to bias. It is therefore important to know whether or not a sample is affected by selection effects. We study under which conditions we can identify selection bias and give results for both parametric and non-parametric families of distributions. Based on these results we develop two practical methods to determine whether or not an observed sample comes from a distribution subject to selection bias. Through extensive evaluation on synthetic and real world data we verify that our methods beat the state of the art both in detecting as well as characterizing selection bias.},
  archive   = {C_AAAI},
  author    = {David Kaltenpoth and Jilles Vreeken},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.25987},
  pages     = {8177-8185},
  title     = {Identifying selection bias from observational data},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards more robust interpretation via local gradient
alignment. <em>AAAI</em>, 8168–8176. (<a
href="https://doi.org/10.1609/aaai.v37i7.25986">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Neural network interpretation methods, particularly feature attribution methods, are known to be fragile with respect to adversarial input perturbations. To address this, several methods for enhancing the local smoothness of the gradient while training have been proposed for attaining robust feature attributions. However, the lack of considering the normalization of the attributions, which is essential in their visualizations, has been an obstacle to understanding and improving the robustness of feature attribution methods. In this paper, we provide new insights by taking such normalization into account. First, we show that for every non-negative homogeneous neural network, a naive l2-robust criterion for gradients is not normalization invariant, which means that two functions with the same normalized gradient can have different values. Second, we formulate a normalization invariant cosine distance-based criterion and derive its upper bound, which gives insight for why simply minimizing the Hessian norm at the input, as has been done in previous work, is not sufficient for attaining robust feature attribution. Finally, we propose to combine both l2 and cosine distance-based criteria as regularization terms to leverage the advantages of both in aligning the local gradient. As a result, we experimentally show that models trained with our method produce much more robust interpretations on CIFAR-10 and ImageNet-100 without significantly hurting the accuracy, compared to the recent baselines. To the best of our knowledge, this is the first work to verify the robustness of interpretation on a larger-scale dataset beyond CIFAR-10, thanks to the computational efficiency of our method.},
  archive   = {C_AAAI},
  author    = {Sunghwan Joo and SeokHyeon Jeong and Juyeon Heo and Adrian Weller and Taesup Moon},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.25986},
  pages     = {8168-8176},
  title     = {Towards more robust interpretation via local gradient alignment},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An efficient algorithm for fair multi-agent multi-armed
bandit with low regret. <em>AAAI</em>, 8159–8167. (<a
href="https://doi.org/10.1609/aaai.v37i7.25985">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently a multi-agent variant of the classical multi-armed bandit was proposed to tackle fairness issues in online learning. Inspired by a long line of work in social choice and economics, the goal is to optimize the Nash social welfare instead of the total utility. Unfortunately previous algorithms either are not efficient or achieve sub-optimal regret in terms of the number of rounds. We propose a new efficient algorithm with lower regret than even previous inefficient ones. We also complement our efficient algorithm with an inefficient approach with regret that matches the lower bound for one agent. The experimental findings confirm the effectiveness of our efficient algorithm compared to the previous approaches.},
  archive   = {C_AAAI},
  author    = {Matthew Jones and Huy Nguyen and Thy Nguyen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.25985},
  pages     = {8159-8167},
  title     = {An efficient algorithm for fair multi-agent multi-armed bandit with low regret},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). POEM: Polarization of embeddings for domain-invariant
representations. <em>AAAI</em>, 8150–8158. (<a
href="https://doi.org/10.1609/aaai.v37i7.25984">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Handling out-of-distribution samples is a long-lasting challenge for deep visual models. In particular, domain generalization (DG) is one of the most relevant tasks that aims to train a model with a generalization capability on novel domains. Most existing DG approaches share the same philosophy to minimize the discrepancy between domains by finding the domain-invariant representations. On the contrary, our proposed method called POEM acquires a strong DG capability by learning domain-invariant and domain-specific representations and polarizing them. Specifically, POEM co-trains category-classifying and domain-classifying embeddings while regularizing them to be orthogonal via minimizing the cosine-similarity between their features, i.e., the polarization of embeddings. The clear separation of embeddings suppresses domain-specific features in the domain-invariant embeddings. The concept of POEM shows a unique direction to enhance the domain robustness of representations that brings considerable and consistent performance gains when combined with existing DG methods. Extensive simulation results in popular DG benchmarks with the PACS, VLCS, OfficeHome, TerraInc, and DomainNet datasets show that POEM indeed facilitates the category-classifying embedding to be more domain-invariant.},
  archive   = {C_AAAI},
  author    = {Sang-Yeong Jo and Sung Whan Yoon},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.25984},
  pages     = {8150-8158},
  title     = {POEM: Polarization of embeddings for domain-invariant representations},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Knowledge-constrained answer generation for open-ended video
question answering. <em>AAAI</em>, 8141–8149. (<a
href="https://doi.org/10.1609/aaai.v37i7.25983">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Open-ended Video question answering (open-ended VideoQA) aims to understand video content and question semantics to generate the correct answers. Most of the best performing models define the problem as a discriminative task of multi-label classification. In real-world scenarios, however, it is difficult to define a candidate set that includes all possible answers. In this paper, we propose a Knowledge-constrained Generative VideoQA Algorithm (KcGA) with an encoder-decoder pipeline, which enables out-of-domain answer generation through an adaptive external knowledge module and a multi-stream information control mechanism. We use ClipBERT to extract the video-question features, extract framewise object-level external knowledge from a commonsense knowledge base and compute the contextual-aware episode memory units via an attention based GRU to form the external knowledge features, and exploit multi-stream information control mechanism to fuse video-question and external knowledge features such that the semantic complementation and alignment are well achieved. We evaluate our model on two open-ended benchmark datasets to demonstrate that we can effectively and robustly generate high-quality answers without restrictions of training data.},
  archive   = {C_AAAI},
  author    = {Yao Jin and Guocheng Niu and Xinyan Xiao and Jian Zhang and Xi Peng and Jun Yu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.25983},
  pages     = {8141-8149},
  title     = {Knowledge-constrained answer generation for open-ended video question answering},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Pointerformer: Deep reinforced multi-pointer transformer for
the traveling salesman problem. <em>AAAI</em>, 8132–8140. (<a
href="https://doi.org/10.1609/aaai.v37i7.25982">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Traveling Salesman Problem (TSP), as a classic routing optimization problem originally arising in the domain of transportation and logistics, has become a critical task in broader domains, such as manufacturing and biology. Recently, Deep Reinforcement Learning (DRL) has been increasingly employed to solve TSP due to its high inference efficiency. Nevertheless, most of existing end-to-end DRL algorithms only perform well on small TSP instances and can hardly generalize to large scale because of the drastically soaring memory consumption and computation time along with the enlarging problem scale. In this paper, we propose a novel end-to-end DRL approach, referred to as Pointerformer, based on multi-pointer Transformer. Particularly, Pointerformer adopts both reversible residual network in the encoder and multi-pointer network in the decoder to effectively contain memory consumption of the encoder-decoder architecture. To further improve the performance of TSP solutions, Pointerformer employs a feature augmentation method to explore the symmetries of TSP at both training and inference stages as well as an enhanced context embedding approach to include more comprehensive context information in the query. Extensive experiments on a randomly generated benchmark and a public benchmark have shown that, while achieving comparative results on most small-scale TSP instances as state-of-the-art DRL approaches do, Pointerformer can also well generalize to large-scale TSPs.},
  archive   = {C_AAAI},
  author    = {Yan Jin and Yuandong Ding and Xuanhao Pan and Kun He and Li Zhao and Tao Qin and Lei Song and Jiang Bian},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.25982},
  pages     = {8132-8140},
  title     = {Pointerformer: Deep reinforced multi-pointer transformer for the traveling salesman problem},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On solution functions of optimization: Universal
approximation and covering number bounds. <em>AAAI</em>, 8123–8131. (<a
href="https://doi.org/10.1609/aaai.v37i7.25981">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the expressibility and learnability of solution functions of convex optimization and their multi-layer architectural extension. The main results are: (1) the class of solution functions of linear programming (LP) and quadratic programming (QP) is a universal approximant for the smooth model class or some restricted Sobolev space, and we characterize the rate-distortion, (2) the approximation power is investigated through a viewpoint of regression error, where information about the target function is provided in terms of data observations, (3) compositionality in the form of deep architecture with optimization as a layer is shown to reconstruct some basic functions used in numerical analysis without error, which implies that (4) a substantial reduction in rate-distortion can be achieved with a universal network architecture, and (5) we discuss the statistical bounds of empirical covering numbers for LP/QP, as well as a generic optimization problem (possibly nonconvex) by exploiting tame geometry. Our results provide the **first rigorous analysis of the approximation and learning-theoretic properties of solution functions** with implications for algorithmic design and performance guarantees.},
  archive   = {C_AAAI},
  author    = {Ming Jin and Vanshaj Khattar and Harshal Kaushik and Bilgehan Sel and Ruoxi Jia},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.25981},
  pages     = {8123-8131},
  title     = {On solution functions of optimization: Universal approximation and covering number bounds},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Trafformer: Unify time and space in traffic prediction.
<em>AAAI</em>, 8114–8122. (<a
href="https://doi.org/10.1609/aaai.v37i7.25980">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Traffic prediction is an important component of the intelligent transportation system. Existing deep learning methods encode temporal information and spatial information separately or iteratively. However, the spatial and temporal information is highly correlated in a traffic network, so existing methods may not learn the complex spatial-temporal dependencies hidden in the traffic network due to the decomposed model design. To overcome this limitation, we propose a new model named Trafformer, which unifies spatial and temporal information in one transformer-style model. Trafformer enables every node at every timestamp interact with every other node in every other timestamp in just one step in the spatial-temporal correlation matrix. This design enables Trafformer to catch complex spatial-temporal dependencies. Following the same design principle, we use the generative style decoder to predict multiple timestamps in only one forward operation instead of the iterative style decoder in Transformer. Furthermore, to reduce the complexity brought about by the huge spatial-temporal self-attention matrix, we also propose two variants of Trafformer to further improve the training and inference speed without losing much effectivity. Extensive experiments on two traffic datasets demonstrate that Trafformer outperforms existing methods and provides a promising future direction for the spatial-temporal traffic prediction problem.},
  archive   = {C_AAAI},
  author    = {Di Jin and Jiayi Shi and Rui Wang and Yawen Li and Yuxiao Huang and Yu-Bin Yang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.25980},
  pages     = {8114-8122},
  title     = {Trafformer: Unify time and space in traffic prediction},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Local-global defense against unsupervised adversarial
attacks on graphs. <em>AAAI</em>, 8105–8113. (<a
href="https://doi.org/10.1609/aaai.v37i7.25979">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Unsupervised pre-training algorithms for graph representation learning are vulnerable to adversarial attacks, such as first-order perturbations on graphs, which will have an impact on particular downstream applications. Designing an effective representation learning strategy against white-box attacks remains a crucial open topic. Prior research attempts to improve representation robustness by maximizing mutual information between the representation and the perturbed graph, which is sub-optimal because it does not adapt its defense techniques to the severity of the attack. To address this issue, we propose an unsupervised defense method that combines local and global defense to improve the robustness of representation. Note that we put forward the Perturbed Edges Harmfulness (PEH) metric to determine the riskiness of the attack. Thus, when the edges are attacked, the model can automatically identify the risk of attack. We present a method of attention-based protection against high-risk attacks that penalizes attention coefficients of perturbed edges to encoders. Extensive experiments demonstrate that our strategies can enhance the robustness of representation against various adversarial attacks on three benchmark graphs.},
  archive   = {C_AAAI},
  author    = {Di Jin and Bingdao Feng and Siqi Guo and Xiaobao Wang and Jianguo Wei and Zhen Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.25979},
  pages     = {8105-8113},
  title     = {Local-global defense against unsupervised adversarial attacks on graphs},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Energy-motivated equivariant pretraining for 3D molecular
graphs. <em>AAAI</em>, 8096–8104. (<a
href="https://doi.org/10.1609/aaai.v37i7.25978">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Pretraining molecular representation models without labels is fundamental to various applications. Conventional methods mainly process 2D molecular graphs and focus solely on 2D tasks, making their pretrained models incapable of characterizing 3D geometry and thus defective for downstream 3D tasks. In this work, we tackle 3D molecular pretraining in a complete and novel sense. In particular, we first propose to adopt an equivariant energy-based model as the backbone for pretraining, which enjoys the merits of fulfilling the symmetry of 3D space. Then we develop a node-level pretraining loss for force prediction, where we further exploit the Riemann-Gaussian distribution to ensure the loss to be E(3)-invariant, enabling more robustness. Moreover, a graph-level noise scale prediction task is also leveraged to further promote the eventual performance. We evaluate our model pretrained from a large-scale 3D dataset GEOM-QM9 on two challenging 3D benchmarks: MD17 and QM9. Experimental results demonstrate the efficacy of our method against current state-of-the-art pretraining approaches, and verify the validity of our design for each proposed component. Code is available at https://github.com/jiaor17/3D-EMGP.},
  archive   = {C_AAAI},
  author    = {Rui Jiao and Jiaqi Han and Wenbing Huang and Yu Rong and Yang Liu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.25978},
  pages     = {8096-8104},
  title     = {Energy-motivated equivariant pretraining for 3D molecular graphs},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Complement sparsification: Low-overhead model pruning for
federated learning. <em>AAAI</em>, 8087–8095. (<a
href="https://doi.org/10.1609/aaai.v37i7.25977">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Federated Learning (FL) is a privacy-preserving distributed deep learning paradigm that involves substantial communication and computation effort, which is a problem for resource-constrained mobile and IoT devices. Model pruning/sparsification develops sparse models that could solve this problem, but existing sparsification solutions cannot satisfy at the same time the requirements for low bidirectional communication overhead between the server and the clients, low computation overhead at the clients, and good model accuracy, under the FL assumption that the server does not have access to raw data to fine-tune the pruned models. We propose Complement Sparsification (CS), a pruning mechanism that satisfies all these requirements through a complementary and collaborative pruning done at the server and the clients. At each round, CS creates a global sparse model that contains the weights that capture the general data distribution of all clients, while the clients create local sparse models with the weights pruned from the global model to capture the local trends. For improved model performance, these two types of complementary sparse models are aggregated into a dense model in each round, which is subsequently pruned in an iterative process. CS requires little computation overhead on the top of vanilla FL for both the server and the clients. We demonstrate that CS is an approximation of vanilla FL and, thus, its models perform well. We evaluate CS experimentally with two popular FL benchmark datasets. CS achieves substantial reduction in bidirectional communication, while achieving performance comparable with vanilla FL. In addition, CS outperforms baseline pruning mechanisms for FL.},
  archive   = {C_AAAI},
  author    = {Xiaopeng Jiang and Cristian Borcea},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.25977},
  pages     = {8087-8095},
  title     = {Complement sparsification: Low-overhead model pruning for federated learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spatio-temporal meta-graph learning for traffic forecasting.
<em>AAAI</em>, 8078–8086. (<a
href="https://doi.org/10.1609/aaai.v37i7.25976">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Traffic forecasting as a canonical task of multivariate time series forecasting has been a significant research topic in AI community. To address the spatio-temporal heterogeneity and non-stationarity implied in the traffic stream, in this study, we propose Spatio-Temporal Meta-Graph Learning as a novel Graph Structure Learning mechanism on spatio-temporal data. Specifically, we implement this idea into Meta-Graph Convolutional Recurrent Network (MegaCRN) by plugging the Meta-Graph Learner powered by a Meta-Node Bank into GCRN encoder-decoder. We conduct a comprehensive evaluation on two benchmark datasets (i.e., METR-LA and PEMS-BAY) and a new large-scale traffic speed dataset called EXPY-TKY that covers 1843 expressway road links in Tokyo. Our model outperformed the state-of-the-arts on all three datasets. Besides, through a series of qualitative evaluations, we demonstrate that our model can explicitly disentangle the road links and time slots with different patterns and be robustly adaptive to any anomalous traffic situations. Codes and datasets are available at https://github.com/deepkashiwa20/MegaCRN.},
  archive   = {C_AAAI},
  author    = {Renhe Jiang and Zhaonan Wang and Jiawei Yong and Puneet Jeph and Quanjun Chen and Yasumasa Kobayashi and Xuan Song and Shintaro Fukushima and Toyotaro Suzumura},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.25976},
  pages     = {8078-8086},
  title     = {Spatio-temporal meta-graph learning for traffic forecasting},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-view MOOC quality evaluation via information-aware
graph representation learning. <em>AAAI</em>, 8070–8077. (<a
href="https://doi.org/10.1609/aaai.v37i7.25975">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we study the problem of MOOC quality evaluation that is essential for improving the course materials, promoting students&#39; learning efficiency, and benefiting user services. While achieving promising performances, current works still suffer from the complicated interactions and relationships of entities in MOOC platforms. To tackle the challenges, we formulate the problem as a course representation learning task based, and develop an Information-aware Graph Representation Learning(IaGRL) for multi-view MOOC quality evaluation. Specifically, We first build a MOOC Heterogeneous Network (HIN) to represent the interactions and relationships among entities in MOOC platforms. And then we decompose the MOOC HIN into multiple single-relation graphs based on meta-paths to depict multi-view semantics of courses. The course representation learning can be further converted to a multi-view graph representation task. Different from traditional graph representation learning, the learned course representations are expected to match the following three types of validity: (1) the agreement on expressiveness between the raw course portfolio and the learned course representations; (2) the consistency between the representations in each view and the unified representations; (3) the alignment between the course and MOOC platform representations. Therefore, we propose to exploit mutual information for preserving the validity of course representations. We conduct extensive experiments over real-world MOOC datasets to demonstrate the effectiveness of our proposed method.},
  archive   = {C_AAAI},
  author    = {Lu Jiang and Yibin Wang and Jianan Wang and Pengyang Wang and Minghao Yin},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.25975},
  pages     = {8070-8077},
  title     = {Multi-view MOOC quality evaluation via information-aware graph representation learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust domain adaptation for machine reading comprehension.
<em>AAAI</em>, 8060–8069. (<a
href="https://doi.org/10.1609/aaai.v37i7.25974">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Most domain adaptation methods for machine reading comprehension (MRC) use a pre-trained question-answer (QA) construction model to generate pseudo QA pairs for MRC transfer. Such a process will inevitably introduce mismatched pairs (i.e., Noisy Correspondence) due to i) the unavailable QA pairs in target documents, and ii) the domain shift during applying the QA construction model to the target domain. Undoubtedly, the noisy correspondence will degenerate the performance of MRC, which however is neglected by existing works. To solve such an untouched problem, we propose to construct QA pairs by additionally using the dialogue related to the documents, as well as a new domain adaptation method for MRC. Specifically, we propose Robust Domain Adaptation for Machine Reading Comprehension (RMRC) method which consists of an answer extractor (AE), a question selector (QS), and an MRC model. Specifically, RMRC filters out the irrelevant answers by estimating the correlation to the document via the AE, and extracts the questions by fusing the candidate questions in multiple rounds of dialogue chats via the QS. With the extracted QA pairs, MRC is fine-tuned and provides the feedback to optimize the QS through a novel reinforced self-training method. Thanks to the optimization of the QS, our method will greatly alleviate the noisy correspondence problem caused by the domain shift. To the best of our knowledge, this could be the first study to reveal the influence of noisy correspondence in domain adaptation MRC models and show a feasible solution to achieve the robustness against the mismatched pairs. Extensive experiments on three datasets demonstrate the effectiveness of our method.},
  archive   = {C_AAAI},
  author    = {Liang Jiang and Zhenyu Huang and Jia Liu and Zujie Wen and Xi Peng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.25974},
  pages     = {8060-8069},
  title     = {Robust domain adaptation for machine reading comprehension},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Online tuning for offline decentralized multi-agent
reinforcement learning. <em>AAAI</em>, 8050–8059. (<a
href="https://doi.org/10.1609/aaai.v37i7.25973">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Offline reinforcement learning could learn effective policies from a fixed dataset, which is promising for real-world applications. However, in offline decentralized multi-agent reinforcement learning, due to the discrepancy between the behavior policy and learned policy, the transition dynamics in offline experiences do not accord with the transition dynamics in online execution, which creates severe errors in value estimates, leading to uncoordinated low-performing policies. One way to overcome this problem is to bridge offline training and online tuning. However, considering both deployment efficiency and sample efficiency, we could only collect very limited online experiences, making it insufficient to use merely online data for updating the agent policy. To utilize both offline and online experiences to tune the policies of agents, we introduce online transition correction (OTC) to implicitly correct the offline transition dynamics by modifying sampling probabilities. We design two types of distances, i.e., embedding-based and value-based distance, to measure the similarity between transitions, and further propose an adaptive rank-based prioritization to sample transitions according to the transition similarity. OTC is simple yet effective to increase data efficiency and improve agent policies in online tuning. Empirically, OTC outperforms baselines in a variety of tasks.},
  archive   = {C_AAAI},
  author    = {Jiechuan Jiang and Zongqing Lu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.25973},
  pages     = {8050-8059},
  title     = {Online tuning for offline decentralized multi-agent reinforcement learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning from training dynamics: Identifying mislabeled data
beyond manually designed features. <em>AAAI</em>, 8041–8049. (<a
href="https://doi.org/10.1609/aaai.v37i7.25972">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {While mislabeled or ambiguously-labeled samples in the training set could negatively affect the performance of deep models, diagnosing the dataset and identifying mislabeled samples helps to improve the generalization power. Training dynamics, i.e., the traces left by iterations of optimization algorithms, have recently been proved to be effective to localize mislabeled samples with hand-crafted features. In this paper, beyond manually designed features, we introduce a novel learning-based solution, leveraging a noise detector, instanced by an LSTM network, which learns to predict whether a sample was mislabeled using the raw training dynamics as input. Specifically, the proposed method trains the noise detector in a supervised manner using the dataset with synthesized label noises and can adapt to various datasets (either naturally or synthesized label-noised) without retraining. We conduct extensive experiments to evaluate the proposed method. We train the noise detector based on the synthesized label-noised CIFAR dataset and test such noise detector on Tiny ImageNet, CUB-200, Caltech-256, WebVision and Clothing1M. Results show that the proposed method precisely detects mislabeled samples on various datasets without further adaptation, and outperforms state-of-the-art methods. Besides, more experiments demonstrate that the mislabel identification can guide a label correction, namely data debugging, providing orthogonal improvements of algorithm-centric state-of-the-art techniques from the data aspect.},
  archive   = {C_AAAI},
  author    = {Qingrui Jia and Xuhong Li and Lei Yu and Jiang Bian and Penghao Zhao and Shupeng Li and Haoyi Xiong and Dejing Dou},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.25972},
  pages     = {8041-8049},
  title     = {Learning from training dynamics: Identifying mislabeled data beyond manually designed features},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MNER-QG: An end-to-end MRC framework for multimodal named
entity recognition with query grounding. <em>AAAI</em>, 8032–8040. (<a
href="https://doi.org/10.1609/aaai.v37i7.25971">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multimodal named entity recognition (MNER) is a critical step in information extraction, which aims to detect entity spans and classify them to corresponding entity types given a sentence-image pair. Existing methods either (1) obtain named entities with coarse-grained visual clues from attention mechanisms, or (2) first detect fine-grained visual regions with toolkits and then recognize named entities. However, they suffer from improper alignment between entity types and visual regions or error propagation in the two-stage manner, which finally imports irrelevant visual information into texts. In this paper, we propose a novel end-to-end framework named MNER-QG that can simultaneously perform MRC-based multimodal named entity recognition and query grounding. Specifically, with the assistance of queries, MNER-QG can provide prior knowledge of entity types and visual regions, and further enhance representations of both text and image. To conduct the query grounding task, we provide manual annotations and weak supervisions that are obtained via training a highly flexible visual grounding model with transfer learning. We conduct extensive experiments on two public MNER datasets, Twitter2015 and Twitter2017. Experimental results show that MNER-QG outperforms the current state-of-the-art models on the MNER task, and also improves the query grounding performance.},
  archive   = {C_AAAI},
  author    = {Meihuizi Jia and Lei Shen and Xin Shen and Lejian Liao and Meng Chen and Xiaodong He and Zhendong Chen and Jiaqi Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.25971},
  pages     = {8032-8040},
  title     = {MNER-QG: An end-to-end MRC framework for multimodal named entity recognition with query grounding},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DrugOOD: Out-of-distribution dataset curator and benchmark
for AI-aided drug discovery – a focus on affinity prediction problems
with noise annotations. <em>AAAI</em>, 8023–8031. (<a
href="https://doi.org/10.1609/aaai.v37i7.25970">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {AI-aided drug discovery (AIDD) is gaining popularity due to its potential to make the search for new pharmaceuticals faster, less expensive, and more effective. Despite its extensive use in numerous fields (e.g., ADMET prediction, virtual screening), little research has been conducted on the out-of-distribution (OOD) learning problem with noise. We present DrugOOD, a systematic OOD dataset curator and benchmark for AIDD. Particularly, we focus on the drug-target binding affinity prediction problem, which involves both macromolecule (protein target) and small-molecule (drug compound). DrugOOD offers an automated dataset curator with user-friendly customization scripts, rich domain annotations aligned with biochemistry knowledge, realistic noise level annotations, and rigorous benchmarking of SOTA OOD algorithms, as opposed to only providing fixed datasets. Since the molecular data is often modeled as irregular graphs using graph neural network (GNN) backbones, DrugOOD also serves as a valuable testbed for graph OOD learning problems. Extensive empirical studies have revealed a significant performance gap between in-distribution and out-of-distribution experiments, emphasizing the need for the development of more effective schemes that permit OOD generalization under noise for AIDD.},
  archive   = {C_AAAI},
  author    = {Yuanfeng Ji and Lu Zhang and Jiaxiang Wu and Bingzhe Wu and Lanqing Li and Long-Kai Huang and Tingyang Xu and Yu Rong and Jie Ren and Ding Xue and Houtim Lai and Wei Liu and Junzhou Huang and Shuigeng Zhou and Ping Luo and Peilin Zhao and Yatao Bian},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.25970},
  pages     = {8023-8031},
  title     = {DrugOOD: Out-of-distribution dataset curator and benchmark for AI-aided drug discovery – a focus on affinity prediction problems with noise annotations},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learnable path in neural controlled differential equations.
<em>AAAI</em>, 8014–8022. (<a
href="https://doi.org/10.1609/aaai.v37i7.25969">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Neural controlled differential equations (NCDEs), which are continuous analogues to recurrent neural networks (RNNs), are a specialized model in (irregular) time-series processing. In comparison with similar models, e.g., neural ordinary differential equations (NODEs), the key distinctive characteristics of NCDEs are i) the adoption of the continuous path created by an interpolation algorithm from each raw discrete time-series sample and ii) the adoption of the Riemann--Stieltjes integral. It is the continuous path which makes NCDEs be analogues to continuous RNNs. However, NCDEs use existing interpolation algorithms to create the path, which is unclear whether they can create an optimal path. To this end, we present a method to generate another latent path (rather than relying on existing interpolation algorithms), which is identical to learning an appropriate interpolation method. We design an encoder-decoder module based on NCDEs and NODEs, and a special training method for it. Our method shows the best performance in both time-series classification and forecasting.},
  archive   = {C_AAAI},
  author    = {Sheo Yon Jhin and Minju Jo and Seungji Kook and Noseong Park},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.25969},
  pages     = {8014-8022},
  title     = {Learnable path in neural controlled differential equations},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Confidence-aware training of smoothed classifiers for
certified robustness. <em>AAAI</em>, 8005–8013. (<a
href="https://doi.org/10.1609/aaai.v37i7.25968">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Any classifier can be &quot;smoothed out&quot; under Gaussian noise to build a new classifier that is provably robust to l2-adversarial perturbations, viz., by averaging its predictions over the noise via randomized smoothing. Under the smoothed classifiers, the fundamental trade-off between accuracy and (adversarial) robustness has been well evidenced in the literature: i.e., increasing the robustness of a classifier for an input can be at the expense of decreased accuracy for some other inputs. In this paper, we propose a simple training method leveraging this trade-off to obtain robust smoothed classifiers, in particular, through a sample-wise control of robustness over the training samples. We make this control feasible by using &quot;accuracy under Gaussian noise&quot; as an easy-to-compute proxy of adversarial robustness for an input. Specifically, we differentiate the training objective depending on this proxy to filter out samples that are unlikely to benefit from the worst-case (adversarial) objective. Our experiments show that the proposed method, despite its simplicity, consistently exhibits improved certified robustness upon state-of-the-art training methods. Somewhat surprisingly, we find these improvements persist even for other notions of robustness, e.g., to various types of common corruptions. Code is available at https://github.com/alinlab/smoothing-catrs.},
  archive   = {C_AAAI},
  author    = {Jongheon Jeong and Seojin Kim and Jinwoo Shin},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.25968},
  pages     = {8005-8013},
  title     = {Confidence-aware training of smoothed classifiers for certified robustness},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Audio-visual contrastive learning with temporal
self-supervision. <em>AAAI</em>, 7996–8004. (<a
href="https://doi.org/10.1609/aaai.v37i7.25967">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose a self-supervised learning approach for videos that learns representations of both the RGB frames and the accompanying audio without human supervision. In contrast to images that capture the static scene appearance, videos also contain sound and temporal scene dynamics. To leverage the temporal and aural dimension inherent to videos, our method extends temporal self-supervision to the audio-visual setting and integrates it with multi-modal contrastive objectives. As temporal self-supervision, we pose playback speed and direction recognition in both modalities and propose intra- and inter-modal temporal ordering tasks. Furthermore, we design a novel contrastive objective in which the usual pairs are supplemented with additional sample-dependent positives and negatives sampled from the evolving feature space. In our model, we apply such losses among video clips and between videos and their temporally corresponding audio clips. We verify our model design in extensive ablation experiments and evaluate the video and audio representations in transfer experiments to action recognition and retrieval on UCF101 and HMBD51, audio classification on ESC50, and robust video fingerprinting on VGG-Sound, with state-of-the-art results.},
  archive   = {C_AAAI},
  author    = {Simon Jenni and Alexander Black and John Collomosse},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.25967},
  pages     = {7996-8004},
  title     = {Audio-visual contrastive learning with temporal self-supervision},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neural representations reveal distinct modes of class
fitting in residual convolutional networks. <em>AAAI</em>, 7988–7995.
(<a href="https://doi.org/10.1609/aaai.v37i7.25966">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We leverage probabilistic models of neural representations to investigate how residual networks fit classes. To this end, we estimate class-conditional density models for representations learned by deep ResNets. We then use these models to characterize distributions of representations across learned classes. Surprisingly, we find that classes in the investigated models are not fitted in a uniform way. On the contrary: we uncover two groups of classes that are fitted with markedly different distributions of representations. These distinct modes of class-fitting are evident only in the deeper layers of the investigated models, indicating that they are not related to low-level image features. We show that the uncovered structure in neural representations correlate with memorization of training examples and adversarial robustness. Finally, we compare class-conditional distributions of neural representations between memorized and typical examples. This allows us to uncover where in the network structure class labels arise for memorized and standard inputs.},
  archive   = {C_AAAI},
  author    = {Michał Jamroż and Marcin Kurdziel},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.25966},
  pages     = {7988-7995},
  title     = {Neural representations reveal distinct modes of class fitting in residual convolutional networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fast regularized discrete optimal transport with
group-sparse regularizers. <em>AAAI</em>, 7980–7987. (<a
href="https://doi.org/10.1609/aaai.v37i7.25965">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Regularized discrete optimal transport (OT) is a powerful tool to measure the distance between two discrete distributions that have been constructed from data samples on two different domains. While it has a wide range of applications in machine learning, in some cases the sampled data from only one of the domains will have class labels such as unsupervised domain adaptation. In this kind of problem setting, a group-sparse regularizer is frequently leveraged as a regularization term to handle class labels. In particular, it can preserve the label structure on the data samples by corresponding the data samples with the same class label to one group-sparse regularization term. As a result, we can measure the distance while utilizing label information by solving the regularized optimization problem with gradient-based algorithms. However, the gradient computation is expensive when the number of classes or data samples is large because the number of regularization terms and their respective sizes also turn out to be large. This paper proposes fast discrete OT with group-sparse regularizers. Our method is based on two ideas. The first is to safely skip the computations of the gradients that must be zero. The second is to efficiently extract the gradients that are expected to be nonzero. Our method is guaranteed to return the same value of the objective function as that of the original approach. Experiments demonstrate that our method is up to 8.6 times faster than the original method without degrading accuracy.},
  archive   = {C_AAAI},
  author    = {Yasutoshi Ida and Sekitoshi Kanai and Kazuki Adachi and Atsutoshi Kumagai and Yasuhiro Fujiwara},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.25965},
  pages     = {7980-7987},
  title     = {Fast regularized discrete optimal transport with group-sparse regularizers},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Model-based reinforcement learning with multinomial logistic
function approximation. <em>AAAI</em>, 7971–7979. (<a
href="https://doi.org/10.1609/aaai.v37i7.25964">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study model-based reinforcement learning (RL) for episodic Markov decision processes (MDP) whose transition probability is parametrized by an unknown transition core with features of state and action. Despite much recent progress in analyzing algorithms in the linear MDP setting, the understanding of more general transition models is very restrictive. In this paper, we propose a provably efficient RL algorithm for the MDP whose state transition is given by a multinomial logistic model. We show that our proposed algorithm based on the upper confidence bounds achieves O(d√(H^3 T)) regret bound where d is the dimension of the transition core, H is the horizon, and T is the total number of steps. To the best of our knowledge, this is the first model-based RL algorithm with multinomial logistic function approximation with provable guarantees. We also comprehensively evaluate our proposed algorithm numerically and show that it consistently outperforms the existing methods, hence achieving both provable efficiency and practical superior performance.},
  archive   = {C_AAAI},
  author    = {Taehyun Hwang and Min-hwan Oh},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.25964},
  pages     = {7971-7979},
  title     = {Model-based reinforcement learning with multinomial logistic function approximation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). XClusters: Explainability-first clustering. <em>AAAI</em>,
7962–7970. (<a href="https://doi.org/10.1609/aaai.v37i7.25963">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the problem of explainability-first clustering where explainability becomes a first-class citizen for clustering. Previous clustering approaches use decision trees for explanation, but only after the clustering is completed. In contrast, our approach is to perform clustering and decision tree training holistically where the decision tree&#39;s performance and size also influence the clustering results. We assume the attributes for clustering and explaining are distinct, although this is not necessary. We observe that our problem is a monotonic optimization where the objective function is a difference of monotonic functions. We then propose an efficient branch-and-bound algorithm for finding the best parameters that lead to a balance of clustering accuracy and decision tree explainability. Our experiments show that our method can improve the explainability of any clustering that fits in our framework.},
  archive   = {C_AAAI},
  author    = {Hyunseung Hwang and Steven Euijong Whang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.25963},
  pages     = {7962-7970},
  title     = {XClusters: Explainability-first clustering},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning noise-induced reward functions for surpassing
demonstrations in imitation learning. <em>AAAI</em>, 7953–7961. (<a
href="https://doi.org/10.1609/aaai.v37i7.25962">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Imitation learning (IL) has recently shown impressive performance in training a reinforcement learning agent with human demonstrations, eliminating the difficulty of designing elaborate reward functions in complex environments. However, most IL methods work under the assumption of the optimality of the demonstrations and thus cannot learn policies to surpass the demonstrators. Some methods have been investigated to obtain better-than-demonstration (BD) performance with inner human feedback or preference labels. In this paper, we propose a method to learn rewards from suboptimal demonstrations via a weighted preference learning technique (LERP). Specifically, we first formulate the suboptimality of demonstrations as the inaccurate estimation of rewards. The inaccuracy is modeled with a reward noise random variable following the Gumbel distribution. Moreover, we derive an upper bound of the expected return with different noise coefficients and propose a theorem to surpass the demonstrations. Unlike existing literature, our analysis does not depend on the linear reward constraint. Consequently, we develop a BD model with a weighted preference learning technique. Experimental results on continuous control and high-dimensional discrete control tasks show the superiority of our LERP method over other state-of-the-art BD methods.},
  archive   = {C_AAAI},
  author    = {Liangyu Huo and Zulin Wang and Mai Xu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.25962},
  pages     = {7953-7961},
  title     = {Learning noise-induced reward functions for surpassing demonstrations in imitation learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reward-biased maximum likelihood estimation for neural
contextual bandits: A distributional learning perspective.
<em>AAAI</em>, 7944–7952. (<a
href="https://doi.org/10.1609/aaai.v37i7.25961">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Reward-biased maximum likelihood estimation (RBMLE) is a classic principle in the adaptive control literature for tackling explore-exploit trade-offs. This paper studies the neural contextual bandit problem from a distributional perspective and proposes NeuralRBMLE, which leverages the likelihood of surrogate parametric distributions to learn the unknown reward distributions and thereafter adapts the RBMLE principle to achieve efficient exploration by properly adding a reward-bias term. NeuralRBMLE leverages the representation power of neural networks and directly encodes exploratory behavior in the parameter space, without constructing confidence intervals of the estimated rewards. We propose two variants of NeuralRBMLE algorithms: The first variant directly obtains the RBMLE estimator by gradient ascent, and the second variant simplifies RBMLE to a simple index policy through an approximation. We show that both algorithms achieve order-optimality. Through extensive experiments, we demonstrate that the NeuralRBMLE algorithms achieve comparable or better empirical regrets than the state-of-the-art methods on real-world datasets with non-linear reward functions.},
  archive   = {C_AAAI},
  author    = {Yu-Heng Hung and Ping-Chun Hsieh},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.25961},
  pages     = {7944-7952},
  title     = {Reward-biased maximum likelihood estimation for neural contextual bandits: A distributional learning perspective},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-supervised graph attention networks for deep weighted
multi-view clustering. <em>AAAI</em>, 7936–7943. (<a
href="https://doi.org/10.1609/aaai.v37i7.25960">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As one of the most important research topics in the unsupervised learning field, Multi-View Clustering (MVC) has been widely studied in the past decade and numerous MVC methods have been developed. Among these methods, the recently emerged Graph Neural Networks (GNN) shine a light on modeling both topological structure and node attributes in the form of graphs, to guide unified embedding learning and clustering. However, the effectiveness of existing GNN-based MVC methods is still limited due to the insufficient consideration in utilizing the self-supervised information and graph information, which can be reflected from the following two aspects: 1) most of these models merely use the self-supervised information to guide the feature learning and fail to realize that such information can be also applied in graph learning and sample weighting; 2) the usage of graph information is generally limited to the feature aggregation in these models, yet it also provides valuable evidence in detecting noisy samples. To this end, in this paper we propose Self-Supervised Graph Attention Networks for Deep Weighted Multi-View Clustering (SGDMC), which promotes the performance of GNN-based deep MVC models by making full use of the self-supervised information and graph information. Specifically, a novel attention-allocating approach that considers both the similarity of node attributes and the self-supervised information is developed to comprehensively evaluate the relevance among different nodes. Meanwhile, to alleviate the negative impact caused by noisy samples and the discrepancy of cluster structures, we further design a sample-weighting strategy based on the attention graph as well as the discrepancy between the global pseudo-labels and the local cluster assignment. Experimental results on multiple real-world datasets demonstrate the effectiveness of our method over existing approaches.},
  archive   = {C_AAAI},
  author    = {Zongmo Huang and Yazhou Ren and Xiaorong Pu and Shudong Huang and Zenglin Xu and Lifang He},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.25960},
  pages     = {7936-7943},
  title     = {Self-supervised graph attention networks for deep weighted multi-view clustering},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enabling knowledge refinement upon new concepts in abductive
learning. <em>AAAI</em>, 7928–7935. (<a
href="https://doi.org/10.1609/aaai.v37i7.25959">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently there are great efforts on leveraging machine learning and logical reasoning. Many approaches start from a given knowledge base, and then try to utilize the knowledge to help machine learning. In real practice, however, the given knowledge base can often be incomplete or even noisy, and thus, it is crucial to develop the ability of knowledge refinement or enhancement. This paper proposes to enable the Abductive learning (ABL) paradigm to have the ability of knowledge refinement/enhancement. In particular, we focus on the problem that, in contrast to closed-environment tasks where a fixed set of symbols are enough to represent the concepts in the domain, in open-environment tasks new concepts may emerge. Ignoring those new concepts can lead to significant performance decay, whereas it is challenging to identify new concepts and add them to the existing knowledge base with potential conflicts resolved. We propose the ABL_nc approach which exploits machine learning in ABL to identify new concepts from data, exploits knowledge graph to match them with entities, and refines existing knowledge base to resolve conflicts. The refined/enhanced knowledge base can then be used in the next loop of ABL and help improve the performance of machine learning. Experiments on three neuro-symbolic learning tasks verified the effectiveness of the proposed approach.},
  archive   = {C_AAAI},
  author    = {Yu-Xuan Huang and Wang-Zhou Dai and Yuan Jiang and Zhi-Hua Zhou},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.25959},
  pages     = {7928-7935},
  title     = {Enabling knowledge refinement upon new concepts in abductive learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Background-mixed augmentation for weakly supervised change
detection. <em>AAAI</em>, 7919–7927. (<a
href="https://doi.org/10.1609/aaai.v37i7.25958">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Change detection (CD) is to decouple object changes (i.e., object missing or appearing) from background changes (i.e., environment variations) like light and season variations in two images captured in the same scene over a long time span, presenting critical applications in disaster management, urban development, etc. In particular, the endless patterns of background changes require detectors to have a high generalization against unseen environment variations, making this task significantly challenging. Recent deep learning-based methods develop novel network architectures or optimization strategies with paired-training examples, which do not handle the generalization issue explicitly and require huge manual pixel-level annotation efforts. In this work, for the first attempt in the CD community, we study the generalization issue of CD from the perspective of data augmentation and develop a novel weakly supervised training algorithm that only needs image-level labels. Different from general augmentation techniques for classification, we propose the background-mixed augmentation that is specifically designed for change detection by augmenting examples under the guidance of a set of background changing images and letting deep CD models see diverse environment variations. Moreover, we propose the augmented &amp; real data consistency loss that encourages the generalization increase significantly. Our method as a general framework can enhance a wide range of existing deep learning-based detectors. We conduct extensive experiments in two public datasets and enhance four state-of-the-art methods, demonstrating the advantages of our method. We release the code at https://github.com/tsingqguo/bgmix.},
  archive   = {C_AAAI},
  author    = {Rui Huang and Ruofei Wang and Qing Guo and Jieda Wei and Yuxiang Zhang and Wei Fan and Yang Liu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.25958},
  pages     = {7919-7927},
  title     = {Background-mixed augmentation for weakly supervised change detection},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RLEKF: An optimizer for deep potential with ab initio
accuracy. <em>AAAI</em>, 7910–7918. (<a
href="https://doi.org/10.1609/aaai.v37i7.25957">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {It is imperative to accelerate the training of neural network force field such as Deep Potential, which usually requires thousands of images based on first-principles calculation and a couple of days to generate an accurate potential energy surface. To this end, we propose a novel optimizer named reorganized layer extended Kalman filtering (RLEKF), an optimized version of global extended Kalman filtering (GEKF) with a strategy of splitting big and gathering small layers to overcome the O(N^2) computational cost of GEKF. This strategy provides an approximation of the dense weights error covariance matrix with a sparse diagonal block matrix for GEKF. We implement both RLEKF and the baseline Adam in our alphaDynamics package and numerical experiments are performed on 13 unbiased datasets. Overall, RLEKF converges faster with slightly better accuracy. For example, a test on a typical system, bulk copper, shows that RLEKF converges faster by both the number of training epochs (x11.67) and wall-clock time (x1.19). Besides, we theoretically prove that the updates of weights converge and thus are against the gradient exploding problem. Experimental results verify that RLEKF is not sensitive to the initialization of weights. The RLEKF sheds light on other AI-for-science applications where training a large neural network (with tons of thousands parameters) is a bottleneck.},
  archive   = {C_AAAI},
  author    = {Siyu Hu and Wentao Zhang and Qiuchen Sha and Feng Pan and Lin-Wang Wang and Weile Jia and Guangming Tan and Tong Zhao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.25957},
  pages     = {7910-7918},
  title     = {RLEKF: An optimizer for deep potential with ab initio accuracy},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Compressed decentralized learning of conditional mean
embedding operators in reproducing kernel hilbert spaces. <em>AAAI</em>,
7902–7909. (<a href="https://doi.org/10.1609/aaai.v37i7.25956">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Conditional mean embedding (CME) operators encode conditional probability densities within Reproducing Kernel Hilbert Space (RKHS). In this paper, we present a decentralized algorithm for a collection of agents to cooperatively approximate CME over a network. Communication constraints limit the agents from sending all data to their neighbors; we only allow sparse representations of covariance operators to be exchanged among agents, compositions of which defines CME. Using a coherence-based compression scheme, we present a consensus-type algorithm that preserves the average of the approximations of the covariance operators across the network. We theoretically prove that the iterative dynamics in RKHS is stable. We then empirically study our algorithm to estimate CMEs to learn spectra of Koopman operators for Markovian dynamical systems and to execute approximate value iteration for Markov decision processes (MDPs).},
  archive   = {C_AAAI},
  author    = {Boya Hou and Sina Sanjari and Nathan Dahlin and Subhonmesh Bose},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.25956},
  pages     = {7902-7909},
  title     = {Compressed decentralized learning of conditional mean embedding operators in reproducing kernel hilbert spaces},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Federated robustness propagation: Sharing adversarial
robustness in heterogeneous federated learning. <em>AAAI</em>,
7893–7901. (<a href="https://doi.org/10.1609/aaai.v37i7.25955">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Federated learning (FL) emerges as a popular distributed learning schema that learns a model from a set of participating users without sharing raw data. One major challenge of FL comes with heterogeneous users, who may have distributionally different (or non-iid) data and varying computation resources. As federated users would use the model for prediction, they often demand the trained model to be robust against malicious attackers at test time. Whereas adversarial training (AT) provides a sound solution for centralized learning, extending its usage for federated users has imposed significant challenges, as many users may have very limited training data and tight computational budgets, to afford the data-hungry and costly AT. In this paper, we study a novel FL strategy: propagating adversarial robustness from rich-resource users that can afford AT, to those with poor resources that cannot afford it, during federated learning. We show that existing FL techniques cannot be effectively integrated with the strategy to propagate robustness among non-iid users and propose an efficient propagation approach by the proper use of batch-normalization. We demonstrate the rationality and effectiveness of our method through extensive experiments. Especially, the proposed method is shown to grant federated models remarkable robustness even when only a small portion of users afford AT during learning. Source code can be accessed at https://github.com/illidanlab/FedRBN.},
  archive   = {C_AAAI},
  author    = {Junyuan Hong and Haotao Wang and Zhangyang Wang and Jiayu Zhou},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.25955},
  pages     = {7893-7901},
  title     = {Federated robustness propagation: Sharing adversarial robustness in heterogeneous federated learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards better visualizing the decision basis of networks
via unfold and conquer attribution guidance. <em>AAAI</em>, 7884–7892.
(<a href="https://doi.org/10.1609/aaai.v37i7.25954">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Revealing the transparency of Deep Neural Networks (DNNs) has been widely studied to describe the decision mechanisms of network inner structures. In this paper, we propose a novel post-hoc framework, Unfold and Conquer Attribution Guidance (UCAG), which enhances the explainability of the network decision by spatially scrutinizing the input features with respect to the model confidence. Addressing the phenomenon of missing detailed descriptions, UCAG sequentially complies with the confidence of slices of the image, leading to providing an abundant and clear interpretation. Therefore, it is possible to enhance the representation ability of explanation by preserving the detailed descriptions of assistant input features, which are commonly overwhelmed by the main meaningful regions. We conduct numerous evaluations to validate the performance in several metrics: i) deletion and insertion, ii) (energy-based) pointing games, and iii) positive and negative density maps. Experimental results, including qualitative comparisons, demonstrate that our method outperforms the existing methods with the nature of clear and detailed explanations and applicability.},
  archive   = {C_AAAI},
  author    = {Jung-Ho Hong and Woo-Jeoung Nam and Kyu-Sung Jeon and Seong-Whan Lee},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.25954},
  pages     = {7884-7892},
  title     = {Towards better visualizing the decision basis of networks via unfold and conquer attribution guidance},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving pareto front learning via multi-sample
hypernetworks. <em>AAAI</em>, 7875–7883. (<a
href="https://doi.org/10.1609/aaai.v37i7.25953">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Pareto Front Learning (PFL) was recently introduced as an effective approach to obtain a mapping function from a given trade-off vector to a solution on the Pareto front, which solves the multi-objective optimization (MOO) problem. Due to the inherent trade-off between conflicting objectives, PFL offers a flexible approach in many scenarios in which the decision makers can not specify the preference of one Pareto solution over another, and must switch between them depending on the situation. However, existing PFL methods ignore the relationship between the solutions during the optimization process, which hinders the quality of the obtained front. To overcome this issue, we propose a novel PFL framework namely PHN-HVI, which employs a hypernetwork to generate multiple solutions from a set of diverse trade-off preferences and enhance the quality of the Pareto front by maximizing the Hypervolume indicator defined by these solutions. The experimental results on several MOO machine learning tasks show that the proposed framework significantly outperforms the baselines in producing the trade-off Pareto front.},
  archive   = {C_AAAI},
  author    = {Long P. Hoang and Dung D. Le and Tran Anh Tuan and Tran Ngoc Thang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.25953},
  pages     = {7875-7883},
  title     = {Improving pareto front learning via multi-sample hypernetworks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-supervised learning for anomalous channel detection in
EEG graphs: Application to seizure analysis. <em>AAAI</em>, 7866–7874.
(<a href="https://doi.org/10.1609/aaai.v37i7.25952">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Electroencephalogram (EEG) signals are effective tools towards seizure analysis where one of the most important challenges is accurate detection of seizure events and brain regions in which seizure happens or initiates. However, all existing machine learning-based algorithms for seizure analysis require access to the labeled seizure data while acquiring labeled data is very labor intensive, expensive, as well as clinicians dependent given the subjective nature of the visual qualitative interpretation of EEG signals. In this paper, we propose to detect seizure channels and clips in a self-supervised manner where no access to the seizure data is needed. The proposed method considers local structural and contextual information embedded in EEG graphs by employing positive and negative sub-graphs. We train our method through minimizing contrastive and generative losses. The employ of local EEG sub-graphs makes the algorithm an appropriate choice when accessing to the all EEG channels is impossible due to complications such as skull fractures. We conduct an extensive set of experiments on the largest seizure dataset and demonstrate that our proposed framework outperforms the state-of-the-art methods in the EEG-based seizure study. The proposed method is the only study that requires no access to the seizure data in its training phase, yet establishes a new state-of-the-art to the field, and outperforms all related supervised methods.},
  archive   = {C_AAAI},
  author    = {Thi Kieu Khanh Ho and Narges Armanfard},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.25952},
  pages     = {7866-7874},
  title     = {Self-supervised learning for anomalous channel detection in EEG graphs: Application to seizure analysis},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving long-horizon imitation through instruction
prediction. <em>AAAI</em>, 7857–7865. (<a
href="https://doi.org/10.1609/aaai.v37i7.25951">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Complex, long-horizon planning and its combinatorial nature pose steep challenges for learning-based agents. Difficulties in such settings are exacerbated in low data regimes where over-fitting stifles generalization and compounding errors hurt accuracy. In this work, we explore the use of an often unused source of auxiliary supervision: language. Inspired by recent advances in transformer-based models, we train agents with an instruction prediction loss that encourages learning temporally extended representations that operate at a high level of abstraction. Concretely, we demonstrate that instruction modeling significantly improves performance in planning environments when training with a limited number of demonstrations on the BabyAI and Crafter benchmarks. In further analysis we find that instruction modeling is most important for tasks that require complex reasoning, while understandably offering smaller gains in environments that require simple plans. More details and code can be found at \url{https://github.com/jhejna/instruction-prediction}.},
  archive   = {C_AAAI},
  author    = {Joey Hejna and Pieter Abbeel and Lerrel Pinto},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i7.25951},
  pages     = {7857-7865},
  title     = {Improving long-horizon imitation through instruction prediction},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Safeguarded learned convex optimization. <em>AAAI</em>,
7848–7855. (<a href="https://doi.org/10.1609/aaai.v37i6.25950">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Applications abound in which optimization problems must be repeatedly solved, each time with new (but similar) data. Analytic optimization algorithms can be hand-designed to provably solve these problems in an iterative fashion. On one hand, data-driven algorithms can &quot;learn to optimize&quot; (L2O) with much fewer iterations and similar cost per iteration as general-purpose optimization algorithms. On the other hand, unfortunately, many L2O algorithms lack converge guarantees. To fuse the advantages of these approaches, we present a Safe-L2O framework. Safe-L2O updates incorporate a safeguard to guarantee convergence for convex problems with proximal and/or gradient oracles. The safeguard is simple and computationally cheap to implement, and it is activated only when the data-driven L2O updates would perform poorly or appear to diverge. This yields the numerical benefits of employing machine learning to create rapid L2O algorithms while still guaranteeing convergence. Our numerical examples show convergence of Safe-L2O algorithms, even when the provided data is not from the distribution of training data.},
  archive   = {C_AAAI},
  author    = {Howard Heaton and Xiaohan Chen and Zhangyang Wang and Wotao Yin},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25950},
  pages     = {7848-7855},
  title     = {Safeguarded learned convex optimization},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). NAS-LID: Efficient neural architecture search with local
intrinsic dimension. <em>AAAI</em>, 7839–7847. (<a
href="https://doi.org/10.1609/aaai.v37i6.25949">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {One-shot neural architecture search (NAS) substantially improves the search efficiency by training one supernet to estimate the performance of every possible child architecture (i.e., subnet). However, the inconsistency of characteristics among subnets incurs serious interference in the optimization, resulting in poor performance ranking correlation of subnets. Subsequent explorations decompose supernet weights via a particular criterion, e.g., gradient matching, to reduce the interference; yet they suffer from huge computational cost and low space separability. In this work, we propose a lightweight and effective local intrinsic dimension (LID)-based method NAS-LID. NAS-LID evaluates the geometrical properties of architectures by calculating the low-cost LID features layer-by-layer, and the similarity characterized by LID enjoys better separability compared with gradients, which thus effectively reduces the interference among subnets. Extensive experiments on NASBench-201 indicate that NAS-LID achieves superior performance with better efficiency. Specifically, compared to the gradient-driven method, NAS-LID can save up to 86\% of GPU memory overhead when searching on NASBench-201. We also demonstrate the effectiveness of NAS-LID on ProxylessNAS and OFA spaces. Source code:https://github.com/marsggbo/NAS-LID.},
  archive   = {C_AAAI},
  author    = {Xin He and Jiangchao Yao and Yuxin Wang and Zhenheng Tang and Ka Chun Cheung and Simon See and Bo Han and Xiaowen Chu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25949},
  pages     = {7839-7847},
  title     = {NAS-LID: Efficient neural architecture search with local intrinsic dimension},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Estimating regression predictive distributions with sample
networks. <em>AAAI</em>, 7830–7838. (<a
href="https://doi.org/10.1609/aaai.v37i6.25948">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Estimating the uncertainty in deep neural network predictions is crucial for many real-world applications. A common approach to model uncertainty is to choose a parametric distribution and fit the data to it using maximum likelihood estimation. The chosen parametric form can be a poor fit to the data-generating distribution, resulting in unreliable uncertainty estimates. In this work, we propose SampleNet, a flexible and scalable architecture for modeling uncertainty that avoids specifying a parametric form on the output distribution. SampleNets do so by defining an empirical distribution using samples that are learned with the Energy Score and regularized with the Sinkhorn Divergence. SampleNets are shown to be able to well-fit a wide range of distributions and to outperform baselines on large-scale real-world regression tasks.},
  archive   = {C_AAAI},
  author    = {Ali Harakeh and Jordan Sir Kwang Hu and Naiqing Guan and Steven Waslander and Liam Paull},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25948},
  pages     = {7830-7838},
  title     = {Estimating regression predictive distributions with sample networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Astromorphic self-repair of neuromorphic hardware systems.
<em>AAAI</em>, 7821–7829. (<a
href="https://doi.org/10.1609/aaai.v37i6.25947">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {While neuromorphic computing architectures based on Spiking Neural Networks (SNNs) are increasingly gaining interest as a pathway toward bio-plausible machine learning, attention is still focused on computational units like the neuron and synapse. Shifting from this neuro-synaptic perspective, this paper attempts to explore the self-repair role of glial cells, in particular, astrocytes. The work investigates stronger correlations with astrocyte computational neuroscience models to develop macro-models with a higher degree of bio-fidelity that accurately captures the dynamic behavior of the self-repair process. Hardware-software co-design analysis reveals that bio-morphic astrocytic regulation has the potential to self-repair hardware realistic faults in neuromorphic hardware systems with significantly better accuracy and repair convergence for unsupervised learning tasks on the MNIST and F-MNIST datasets. Our implementation source code and trained models are available at https://github.com/NeuroCompLab-psu/Astromorphic_Self_Repair.},
  archive   = {C_AAAI},
  author    = {Zhuangyu Han and A N M Nafiul Islam and Abhronil Sengupta},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25947},
  pages     = {7821-7829},
  title     = {Astromorphic self-repair of neuromorphic hardware systems},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Discriminability and transferability estimation: A bayesian
source importance estimation approach for multi-source-free domain
adaptation. <em>AAAI</em>, 7811–7820. (<a
href="https://doi.org/10.1609/aaai.v37i6.25946">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Source free domain adaptation (SFDA) transfers a single-source model to the unlabeled target domain without accessing the source data. With the intelligence development of various fields, a zoo of source models is more commonly available, arising in a new setting called multi-source-free domain adaptation (MSFDA). We find that the critical inborn challenge of MSFDA is how to estimate the importance (contribution) of each source model. In this paper, we shed new Bayesian light on the fact that the posterior probability of source importance connects to discriminability and transferability. We propose Discriminability And Transferability Estimation (DATE), a universal solution for source importance estimation. Specifically, a proxy discriminability perception module equips with habitat uncertainty and density to evaluate each sample&#39;s surrounding environment. A source-similarity transferability perception module quantifies the data distribution similarity and encourages the transferability to be reasonably distributed with a domain diversity loss. Extensive experiments show that DATE can precisely and objectively estimate the source importance and outperform prior arts by non-trivial margins. Moreover, experiments demonstrate that DATE can take the most popular SFDA networks as backbones and make them become advanced MSFDA solutions.},
  archive   = {C_AAAI},
  author    = {Zhongyi Han and Zhiyan Zhang and Fan Wang and Rundong He and Wan Su and Xiaoming Xi and Yilong Yin},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25946},
  pages     = {7811-7820},
  title     = {Discriminability and transferability estimation: A bayesian source importance estimation approach for multi-source-free domain adaptation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dream to generalize: Zero-shot model-based reinforcement
learning for unseen visual distractions. <em>AAAI</em>, 7802–7810. (<a
href="https://doi.org/10.1609/aaai.v37i6.25945">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Model-based reinforcement learning (MBRL) has been used to efficiently solve vision-based control tasks in high-dimensional image observations. Although recent MBRL algorithms perform well in trained observations, they fail when faced with visual distractions in observations. These task-irrelevant distractions (e.g., clouds, shadows, and light) may be constantly present in real-world scenarios. In this study, we propose a novel self-supervised method, Dream to Generalize (Dr. G), for zero-shot MBRL. Dr. G trains its encoder and world model with dual contrastive learning which efficiently captures task-relevant features among multi-view data augmentations. We also introduce a recurrent state inverse dynamics model that helps the world model to better understand the temporal structure. The proposed methods can enhance the robustness of the world model against visual distractions. To evaluate the generalization performance, we first train Dr. G on simple backgrounds and then test it on complex natural video backgrounds in the DeepMind Control suite, and the randomizing environments in Robosuite. Dr. G yields a performance improvement of 117\% and 14\% over prior works, respectively. Our code is open-sourced and available at https://github.com/JeongsooHa/DrG.git},
  archive   = {C_AAAI},
  author    = {Jeongsoo Ha and Kyungsoo Kim and Yusung Kim},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25945},
  pages     = {7802-7810},
  title     = {Dream to generalize: Zero-shot model-based reinforcement learning for unseen visual distractions},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Boosting graph neural networks via adaptive knowledge
distillation. <em>AAAI</em>, 7793–7801. (<a
href="https://doi.org/10.1609/aaai.v37i6.25944">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph neural networks (GNNs) have shown remarkable performance on diverse graph mining tasks. While sharing the same message passing framework, our study shows that different GNNs learn distinct knowledge from the same graph. This implies potential performance improvement by distilling the complementary knowledge from multiple models. However, knowledge distillation (KD) transfers knowledge from high-capacity teachers to a lightweight student, which deviates from our scenario: GNNs are often shallow. To transfer knowledge effectively, we need to tackle two challenges: how to transfer knowledge from compact teachers to a student with the same capacity; and, how to exploit student GNN&#39;s own learning ability. In this paper, we propose a novel adaptive KD framework, called BGNN, which sequentially transfers knowledge from multiple GNNs into a student GNN. We also introduce an adaptive temperature module and a weight boosting module. These modules guide the student to the appropriate knowledge for effective learning. Extensive experiments have demonstrated the effectiveness of BGNN. In particular, we achieve up to 3.05\% improvement for node classification and 6.35\% improvement for graph classification over vanilla GNNs.},
  archive   = {C_AAAI},
  author    = {Zhichun Guo and Chunhui Zhang and Yujie Fan and Yijun Tian and Chuxu Zhang and Nitesh V. Chawla},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25944},
  pages     = {7793-7801},
  title     = {Boosting graph neural networks via adaptive knowledge distillation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-supervised bidirectional learning for graph matching.
<em>AAAI</em>, 7784–7792. (<a
href="https://doi.org/10.1609/aaai.v37i6.25943">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep learning methods have demonstrated promising performance on the NP-hard Graph Matching (GM) problems. However, the state-of-the-art methods usually require the ground-truth labels, which may take extensive human efforts or be impractical to collect. In this paper, we present a robust self-supervised bidirectional learning method (IA-SSGM) to tackle GM in an unsupervised manner. It involves an affinity learning component and a classic GM solver. Specifically, we adopt the Hungarian solver to generate pseudo correspondence labels for the simple probabilistic relaxation of the affinity matrix. In addition, a bidirectional recycling consistency module is proposed to generate pseudo samples by recycling the pseudo correspondence back to permute the input. It imposes a consistency constraint between the pseudo affinity and the original one, which is theoretically supported to help reduce the matching error. Our method further develops a graph contrastive learning jointly with the affinity learning to enhance its robustness against the noise and outliers in real applications. Experiments deliver superior performance over the previous state-of-the-arts on five real-world benchmarks, especially under the more difficult outlier scenarios, demon- strating the effectiveness of our method.},
  archive   = {C_AAAI},
  author    = {Wenqi Guo and Lin Zhang and Shikui Tu and Lei Xu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25943},
  pages     = {7784-7792},
  title     = {Self-supervised bidirectional learning for graph matching},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Graph knows unknowns: Reformulate zero-shot learning as
sample-level graph recognition. <em>AAAI</em>, 7775–7783. (<a
href="https://doi.org/10.1609/aaai.v37i6.25942">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Zero-shot learning (ZSL) is an extreme case of transfer learning that aims to recognize samples (e.g., images) of unseen classes relying on a train-set covering only seen classes and a set of auxiliary knowledge (e.g., semantic descriptors). Existing methods usually resort to constructing a visual-to-semantics mapping based on features extracted from each whole sample. However, since the visual and semantic spaces are inherently independent and may exist in different manifolds, these methods may easily suffer from the domain bias problem due to the knowledge transfer from seen to unseen classes. Unlike existing works, this paper investigates the fine-grained ZSL from a novel perspective of sample-level graph. Specifically, we decompose an input into several fine-grained elements and construct a graph structure per sample to measure and utilize element-granularity relations within each sample. Taking advantage of recently developed graph neural networks (GNNs), we formulate the ZSL problem to a graph-to-semantics mapping task, which can better exploit element-semantics correlation and local sub-structural information in samples. Experimental results on the widely used benchmark datasets demonstrate that the proposed method can mitigate the domain bias problem and achieve competitive performance against other representative methods.},
  archive   = {C_AAAI},
  author    = {Jingcai Guo and Song Guo and Qihua Zhou and Ziming Liu and Xiaocheng Lu and Fushuo Huo},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25942},
  pages     = {7775-7783},
  title     = {Graph knows unknowns: Reformulate zero-shot learning as sample-level graph recognition},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Interpolating graph pair to regularize graph classification.
<em>AAAI</em>, 7766–7774. (<a
href="https://doi.org/10.1609/aaai.v37i6.25941">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present a simple and yet effective interpolation-based regularization technique, aiming to improve the generalization of Graph Neural Networks (GNNs) on supervised graph classification. We leverage Mixup, an effective regularizer for vision, where random sample pairs and their labels are interpolated to create synthetic images for training. Unlike images with grid-like coordinates, graphs have arbitrary structure and topology, which can be very sensitive to any modification that alters the graph&#39;s semantic meanings. This posts two unanswered questions for Mixup-like regularization schemes: Can we directly mix up a pair of graph inputs? If so, how well does such mixing strategy regularize the learning of GNNs? To answer these two questions, we propose ifMixup, which first adds dummy nodes to make two graphs have the same input size and then simultaneously performs linear interpolation between the aligned node feature vectors and the aligned edge representations of the two graphs. We empirically show that such simple mixing schema can effectively regularize the classification learning, resulting in superior predictive accuracy to popular graph augmentation and GNN methods.},
  archive   = {C_AAAI},
  author    = {Hongyu Guo and Yongyi Mao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25941},
  pages     = {7766-7774},
  title     = {Interpolating graph pair to regularize graph classification},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An adaptive layer to leverage both domain and task specific
information from scarce data. <em>AAAI</em>, 7757–7765. (<a
href="https://doi.org/10.1609/aaai.v37i6.25940">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Many companies make use of customer service chats to help the customer and try to solve their problem. However, customer service data is confidential and as such, cannot easily be shared in the research community. This also implies that these data are rarely labeled, making it difficult to take advantage of it with machine learning methods. In this paper we present the first work on a customer’s problem status prediction and identification of problematic conversations. Given very small subsets of labeled textual conversations and unlabeled ones, we propose a semi-supervised framework dedicated to customer service data leveraging speaker role information to adapt the model to the domain and the task using a two-step process. Our framework, Task-Adaptive Fine-tuning, goes from predicting customer satisfaction to identifying the status of the customer’s problem, with the latter being the main objective of the multi-task setting. It outperforms recent inductive semi-supervised approaches on this novel task while only considering a relatively low number of parameters to train on during the final target task. We believe it can not only serve models dedicated to customer service but also to any other application making use of confidential conversational data where labeled sets are rare. Source code is available at https://github.com/gguibon/taft},
  archive   = {C_AAAI},
  author    = {Gaël Guibon and Matthieu Labeau and Luce Lefeuvre and Chloé Clavel},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25940},
  pages     = {7757-7765},
  title     = {An adaptive layer to leverage both domain and task specific information from scarce data},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynamic representation learning with temporal point
processes for higher-order interaction forecasting. <em>AAAI</em>,
7748–7756. (<a href="https://doi.org/10.1609/aaai.v37i6.25939">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The explosion of digital information and the growing involvement of people in social networks led to enormous research activity to develop methods that can extract meaningful information from interaction data. Commonly, interactions are represented by edges in a network or a graph, which implicitly assumes that the interactions are pairwise and static. However, real-world interactions deviate from these assumptions: (i) interactions can be multi-way, involving more than two nodes or individuals (e.g., family relationships, protein interactions), and (ii) interactions can change over a period of time (e.g., change of opinions and friendship status). While pairwise interactions have been studied in a dynamic network setting and multi-way interactions have been studied using hypergraphs in static networks, there exists no method, at present, that can predict multi-way interactions or hyperedges in dynamic settings. Existing related methods cannot answer temporal queries like what type of interaction will occur next and when it will occur. This paper proposes a temporal point process model for hyperedge prediction to address these problems. Our proposed model uses dynamic representation learning techniques for nodes in a neural point process framework to forecast hyperedges. We present several experimental results and set benchmark results. As far as our knowledge, this is the first work that uses the temporal point process to forecast hyperedges in dynamic networks.},
  archive   = {C_AAAI},
  author    = {Tony Gracious and Ambedkar Dukkipati},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25939},
  pages     = {7748-7756},
  title     = {Dynamic representation learning with temporal point processes for higher-order interaction forecasting},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep latent regularity network for modeling stochastic
partial differential equations. <em>AAAI</em>, 7740–7747. (<a
href="https://doi.org/10.1609/aaai.v37i6.25938">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Stochastic partial differential equations (SPDEs) are crucial for modelling dynamics with randomness in many areas including economics, physics, and atmospheric sciences. Recently, using deep learning approaches to learn the PDE solution for accelerating PDE simulation becomes increasingly popular. However, SPDEs have two unique properties that require new design on the models. First, the model to approximate the solution of SPDE should be generalizable over both initial conditions and the random sampled forcing term. Second, the random forcing terms usually have poor regularity whose statistics may diverge (e.g., the space-time white noise). To deal with the problems, in this work, we design a deep neural network called \emph{Deep Latent Regularity Net} (DLR-Net). DLR-Net includes a regularity feature block as the main component, which maps the initial condition and the random forcing term to a set of regularity features. The processing of regularity features is inspired by regularity structure theory and the features provably compose a set of basis to represent the SPDE solution. The regularity features are then fed into a small backbone neural operator to get the output. We conduct experiments on various SPDEs including the dynamic $\Phi^4_1$ model and the stochastic 2D Navier-Stokes equation to predict their solutions, and the results demonstrate that the proposed DLR-Net can achieve SOTA accuracy compared with the baselines. Moreover, the inference time is over 20 times faster than the traditional numerical solver and is comparable with the baseline deep learning models.},
  archive   = {C_AAAI},
  author    = {Shiqi Gong and Peiyan Hu and Qi Meng and Yue Wang and Rongchan Zhu and Bingguang Chen and Zhiming Ma and Hao Ni and Tie-Yan Liu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25938},
  pages     = {7740-7747},
  title     = {Deep latent regularity network for modeling stochastic partial differential equations},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive hierarchy-branch fusion for online knowledge
distillation. <em>AAAI</em>, 7731–7739. (<a
href="https://doi.org/10.1609/aaai.v37i6.25937">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Online Knowledge Distillation (OKD) is designed to alleviate the dilemma that the high-capacity pre-trained teacher model is not available. However, the existing methods mostly focus on improving the ensemble prediction accuracy from multiple students (a.k.a. branches), which often overlook the homogenization problem that makes student model saturate quickly and hurts the performance. We assume that the intrinsic bottleneck of the homogenization problem comes from the identical branch architecture and coarse ensemble strategy. We propose a novel Adaptive Hierarchy-Branch Fusion framework for Online Knowledge Distillation, termed AHBF-OKD, which designs hierarchical branches and adaptive hierarchy-branch fusion module to boost the model diversity and aggregate complementary knowledge. Specifically, we first introduce hierarchical branch architectures to construct diverse peers by increasing the depth of branches monotonously on the basis of target branch. To effectively transfer knowledge from the most complex branch to the simplest target branch, we propose an adaptive hierarchy-branch fusion module to create hierarchical teacher assistants recursively, which regards the target branch as the smallest teacher assistant. During the training, the teacher assistant from the previous hierarchy is explicitly distilled by the teacher assistant and the branch from the current hierarchy. Thus, the important scores to different branches are effectively and adaptively allocated to reduce the branch homogenization. Extensive experiments demonstrate the effectiveness of AHBF-OKD on different datasets, including CIFAR-10/100 and ImageNet 2012. For example, on ImageNet 2012, the distilled ResNet-18 achieves Top-1 error of 29.28\%, which significantly outperforms the state-of-the-art methods. The source code is available at https://github.com/linruigong965/AHBF.},
  archive   = {C_AAAI},
  author    = {Linrui Gong and Shaohui Lin and Baochang Zhang and Yunhang Shen and Ke Li and Ruizhi Qiao and Bo Ren and Muqing Li and Zhou Yu and Lizhuang Ma},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25937},
  pages     = {7731-7739},
  title     = {Adaptive hierarchy-branch fusion for online knowledge distillation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving uncertainty quantification of deep classifiers via
neighborhood conformal prediction: Novel algorithm and theoretical
analysis. <em>AAAI</em>, 7722–7730. (<a
href="https://doi.org/10.1609/aaai.v37i6.25936">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Safe deployment of deep neural networks in high-stake real-world applications require theoretically sound uncertainty quantification. Conformal prediction (CP) is a principled framework for uncertainty quantification of deep models in the form of prediction set for classification tasks with a user-specified coverage (i.e., true class label is contained with high probability). This paper proposes a novel algorithm referred to as Neighborhood Conformal Prediction (NCP) to improve the efficiency of uncertainty quantification from CP for deep classifiers (i.e., reduce prediction set size). The key idea behind NCP is to use the learned representation of the neural network to identify k nearest-neighbor calibration examples for a given testing input and assign them importance weights proportional to their distance to create adaptive prediction sets. We theoretically show that if the learned data representation of the neural network satisfies some mild conditions, NCP will produce smaller prediction sets than traditional CP algorithms. Our comprehensive experiments on CIFAR-10, CIFAR-100, and ImageNet datasets using diverse deep neural networks strongly demonstrate that NCP leads to significant reduction in prediction set size over prior CP methods.},
  archive   = {C_AAAI},
  author    = {Subhankar Ghosh and Taha Belkhouja and Yan Yan and Janardhan Rao Doppa},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25936},
  pages     = {7722-7730},
  title     = {Improving uncertainty quantification of deep classifiers via neighborhood conformal prediction: Novel algorithm and theoretical analysis},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Local intrinsic dimensional entropy. <em>AAAI</em>,
7714–7721. (<a href="https://doi.org/10.1609/aaai.v37i6.25935">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Most entropy measures depend on the spread of the probability distribution over the sample space |X|, and the maximum entropy achievable scales proportionately with the sample space cardinality |X|. For a finite |X|, this yields robust entropy measures which satisfy many important properties, such as invariance to bijections, while the same is not true for continuous spaces (where |X|=infinity). Furthermore, since R and R^d (d in Z+) have the same cardinality (from Cantor&#39;s correspondence argument), cardinality-dependent entropy measures cannot encode the data dimensionality. In this work, we question the role of cardinality and distribution spread in defining entropy measures for continuous spaces, which can undergo multiple rounds of transformations and distortions, e.g., in neural networks. We find that the average value of the local intrinsic dimension of a distribution, denoted as ID-Entropy, can serve as a robust entropy measure for continuous spaces, while capturing the data dimensionality. We find that ID-Entropy satisfies many desirable properties and can be extended to conditional entropy, joint entropy and mutual-information variants. ID-Entropy also yields new information bottleneck principles and also links to causality. In the context of deep learning, for feedforward architectures, we show, theoretically and empirically, that the ID-Entropy of a hidden layer directly controls the generalization gap for both classifiers and auto-encoders, when the target function is Lipschitz continuous. Our work primarily shows that, for continuous spaces, taking a structural rather than a statistical approach yields entropy measures which preserve intrinsic data dimensionality, while being relevant for studying various architectures.},
  archive   = {C_AAAI},
  author    = {Rohan Ghosh and Mehul Motani},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25935},
  pages     = {7714-7721},
  title     = {Local intrinsic dimensional entropy},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DiFA: Differentiable feature acquisition. <em>AAAI</em>,
7705–7713. (<a href="https://doi.org/10.1609/aaai.v37i6.25934">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Feature acquisition in predictive modeling is an important task in many practical applications. For example, in patient health prediction, we do not fully observe their personal features and need to dynamically select features to acquire. Our goal is to acquire a small subset of features that maximize prediction performance. Recently, some works reformulated feature acquisition as a Markov decision process and applied reinforcement learning (RL) algorithms, where the reward reflects both prediction performance and feature acquisition cost. However, RL algorithms only use zeroth-order information on the reward, which leads to slow empirical convergence, especially when there are many actions (number of features) to consider. For predictive modeling, it is possible to use first-order information on the reward, i.e., gradients, since we are often given an already collected dataset. Therefore, we propose differentiable feature acquisition (DiFA), which uses a differentiable representation of the feature selection policy to enable gradients to flow from the prediction loss to the policy parameters. We conduct extensive experiments on various real-world datasets and show that DiFA significantly outperforms existing feature acquisition methods when the number of features is large.},
  archive   = {C_AAAI},
  author    = {Aritra Ghosh and Andrew Lan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25934},
  pages     = {7705-7713},
  title     = {DiFA: Differentiable feature acquisition},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Differentially private heatmaps. <em>AAAI</em>, 7696–7704.
(<a href="https://doi.org/10.1609/aaai.v37i6.25933">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider the task of producing heatmaps from users&#39; aggregated data while protecting their privacy. We give a differentially private (DP) algorithm for this task and demonstrate its advantages over previous algorithms on real-world datasets. Our core algorithmic primitive is a DP procedure that takes in a set of distributions and produces an output that is close in Earth Mover&#39;s Distance (EMD) to the average of the inputs. We prove theoretical bounds on the error of our algorithm under a certain sparsity assumption and that these are essentially optimal.},
  archive   = {C_AAAI},
  author    = {Badih Ghazi and Junfeng He and Kai Kohlhoff and Ravi Kumar and Pasin Manurangsi and Vidhya Navalpakkam and Nachiappan Valliappan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25933},
  pages     = {7696-7704},
  title     = {Differentially private heatmaps},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-classifier adversarial optimization for active
learning. <em>AAAI</em>, 7687–7695. (<a
href="https://doi.org/10.1609/aaai.v37i6.25932">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Active learning (AL) aims to find a better trade-off between labeling costs and model performance by consciously selecting more informative samples to label. Recently, adversarial approaches have emerged as effective solutions. Most of them leverage generative adversarial networks to align feature distributions of labeled and unlabeled data, upon which discriminators are trained to better distinguish between them. However, these methods fail to consider the relationship between unlabeled samples and decision boundaries, and their training processes are often complex and unstable. To this end, this paper proposes a novel adversarial AL method, namely multi-classifier adversarial optimization for active learning (MAOAL). MAOAL employs task-specific decision boundaries for data alignment while selecting the most informative samples to label. To fulfill this, we introduce a novel classifier class confusion (C3) metric, which represents the classifier discrepancy as the inter-class correlation of classifier outputs. Without any additional hyper-parameters, the C3 metric further reduces the negative impacts of ambiguous samples in the process of distribution alignment and sample selection. More concretely, the network is trained adversarially by adding two auxiliary classifiers, reducing the distribution bias of labeled and unlabeled samples by minimizing the C3 loss between classifiers, while learning tighter decision boundaries and highlighting hard samples by maximizing the C3 loss. Finally, the unlabeled samples with the highest C3 loss are selected to label. Extensive experiments demonstrate the superiority of our approach over state-of-the-art AL methods in terms of image classification and object detection.},
  archive   = {C_AAAI},
  author    = {Lin Geng and Ningzhong Liu and Jie Qin},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25932},
  pages     = {7687-7695},
  title     = {Multi-classifier adversarial optimization for active learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Semi-transductive learning for generalized zero-shot
sketch-based image retrieval. <em>AAAI</em>, 7678–7686. (<a
href="https://doi.org/10.1609/aaai.v37i6.25931">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Sketch-based image retrieval (SBIR) is an attractive research area where freehand sketches are used as queries to retrieve relevant images. Existing solutions have advanced the task to the challenging zero-shot setting (ZS-SBIR), where the trained models are tested on new classes without seen data. However, they are prone to overfitting under a realistic scenario when the test data includes both seen and unseen classes. In this paper, we study generalized ZS-SBIR (GZS-SBIR) and propose a novel semi-transductive learning paradigm. Transductive learning is performed on the image modality to explore the potential data distribution within unseen classes, and zero-shot learning is performed on the sketch modality sharing the learned knowledge through a semi-heterogeneous architecture. A hybrid metric learning strategy is proposed to establish semantics-aware ranking property and calibrate the joint embedding space. Extensive experiments are conducted on two large-scale benchmarks and four evaluation metrics. The results show that our method is superior over the state-of-the-art competitors in the challenging GZS-SBIR task.},
  archive   = {C_AAAI},
  author    = {Ce Ge and Jingyu Wang and Qi Qi and Haifeng Sun and Tong Xu and Jianxin Liao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25931},
  pages     = {7678-7686},
  title     = {Semi-transductive learning for generalized zero-shot sketch-based image retrieval},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning program synthesis for integer sequences from
scratch. <em>AAAI</em>, 7670–7677. (<a
href="https://doi.org/10.1609/aaai.v37i6.25930">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present a self-learning approach for synthesizing programs from integer sequences. Our method relies on a tree search guided by a learned policy. Our system is tested on the On-Line Encyclopedia of Integer Sequences. There, it discovers, on its own, solutions for 27987 sequences starting from basic operators and without human-written training examples.},
  archive   = {C_AAAI},
  author    = {Thibault Gauthier and Josef Urban},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25930},
  pages     = {7670-7677},
  title     = {Learning program synthesis for integer sequences from scratch},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reinforced approximate exploratory data analysis.
<em>AAAI</em>, 7660–7669. (<a
href="https://doi.org/10.1609/aaai.v37i6.25929">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Exploratory data analytics (EDA) is a sequential decision making process where analysts choose subsequent queries that might lead to some interesting insights based on the previous queries and corresponding results. Data processing systems often execute the queries on samples to produce results with low latency. Different downsampling strategy preserves different statistics of the data and have different magnitude of latency reductions. The optimum choice of sampling strategy often depends on the particular context of the analysis flow and the hidden intent of the analyst. In this paper, we are the first to consider the impact of sampling in interactive data exploration settings as they introduce approximation errors. We propose a Deep Reinforcement Learning (DRL) based framework which can optimize the sample selection in order to keep the analysis and insight generation flow intact. Evaluations with real datasets show that our technique can preserve the original insight generation flow while improving the interaction latency, compared to baseline methods.},
  archive   = {C_AAAI},
  author    = {Shaddy Garg and Subrata Mitra and Tong Yu and Yash Gadhia and Arjun Kashettiwar},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25929},
  pages     = {7660-7669},
  title     = {Reinforced approximate exploratory data analysis},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Handling missing data via max-entropy regularized graph
autoencoder. <em>AAAI</em>, 7651–7659. (<a
href="https://doi.org/10.1609/aaai.v37i6.25928">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph neural networks (GNNs) are popular weapons for modeling relational data. Existing GNNs are not specified for attribute-incomplete graphs, making missing attribute imputation a burning issue. Until recently, many works notice that GNNs are coupled with spectral concentration, which means the spectrum obtained by GNNs concentrates on a local part in spectral domain, e.g., low-frequency due to oversmoothing issue. As a consequence, GNNs may be seriously flawed for reconstructing graph attributes as graph spectral concentration tends to cause a low imputation precision. In this work, we present a regularized graph autoencoder for graph attribute imputation, named MEGAE, which aims at mitigating spectral concentration problem by maximizing the graph spectral entropy. Notably, we first present the method for estimating graph spectral entropy without the eigen-decomposition of Laplacian matrix and provide the theoretical upper error bound. A maximum entropy regularization then acts in the latent space, which directly increases the graph spectral entropy. Extensive experiments show that MEGAE outperforms all the other state-of-the-art imputation methods on a variety of benchmark datasets.},
  archive   = {C_AAAI},
  author    = {Ziqi Gao and Yifan Niu and Jiashun Cheng and Jianheng Tang and Lanqing Li and Tingyang Xu and Peilin Zhao and Fugee Tsung and Jia Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25928},
  pages     = {7651-7659},
  title     = {Handling missing data via max-entropy regularized graph autoencoder},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Long-tail cross modal hashing. <em>AAAI</em>, 7642–7650. (<a
href="https://doi.org/10.1609/aaai.v37i6.25927">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Existing Cross Modal Hashing (CMH) methods are mainly designed for balanced data, while imbalanced data with long-tail distribution is more general in real-world. Several long-tail hashing methods have been proposed but they can not adapt for multi-modal data, due to the complex interplay between labels and individuality and commonality information of multi-modal data. Furthermore, CMH methods mostly mine the commonality of multi-modal data to learn hash codes, which may override tail labels encoded by the individuality of respective modalities. In this paper, we propose LtCMH (Long-tail CMH) to handle imbalanced multi-modal data. LtCMH firstly adopts auto-encoders to mine the individuality and commonality of different modalities by minimizing the dependency between the individuality of respective modalities and by enhancing the commonality of these modalities. Then it dynamically combines the individuality and commonality with direct features extracted from respective modalities to create meta features that enrich the representation of tail labels, and binaries meta features to generate hash codes. LtCMH significantly outperforms state-of-the-art baselines on long-tail datasets and holds a better (or comparable) performance on datasets with balanced labels.},
  archive   = {C_AAAI},
  author    = {Zijun Gao and Jun Wang and Guoxian Yu and Zhongmin Yan and Carlotta Domeniconi and Jinglin Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25927},
  pages     = {7642-7650},
  title     = {Long-tail cross modal hashing},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards decision-friendly AUC: Learning multi-classifier
with AUCµ. <em>AAAI</em>, 7633–7641. (<a
href="https://doi.org/10.1609/aaai.v37i6.25926">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Area Under the ROC Curve (AUC) is a widely used ranking metric in imbalanced learning due to its insensitivity to label distributions. As a well-known multiclass extension of AUC, Multiclass AUC (MAUC, a.k.a. M-metric) measures the average AUC of multiple binary classifiers. In this paper, we argue that simply optimizing MAUC is far from enough for imbalanced multi-classification. More precisely, MAUC only focuses on learning scoring functions via ranking optimization, while leaving the decision process unconsidered. Therefore, scoring functions being able to make good decisions might suffer from low performance in terms of MAUC. To overcome this issue, we turn to explore AUCµ, another multiclass variant of AUC, which further takes the decision process into consideration. Motivated by this fact, we propose a surrogate risk optimization framework to improve model performance from the perspective of AUCµ. Practically, we propose a two-stage training framework for multi-classification, where at the first stage a scoring function is learned maximizing AUCµ, and at the second stage we seek for a decision function to improve the F1-metric via our proposed soft F1. Theoretically, we first provide sufficient conditions that optimizing the surrogate losses could lead to the Bayes optimal scoring function. Afterward, we show that the proposed surrogate risk enjoys a generalization bound in order of O(1/√N). Experimental results on four benchmark datasets demonstrate the effectiveness of our proposed method in both AUCµ and F1-metric.},
  archive   = {C_AAAI},
  author    = {Peifeng Gao and Qianqian Xu and Peisong Wen and Huiyang Shao and Yuan He and Qingming Huang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25926},
  pages     = {7633-7641},
  title     = {Towards decision-friendly AUC: Learning multi-classifier with AUCµ},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust causal graph representation learning against
confounding effects. <em>AAAI</em>, 7624–7632. (<a
href="https://doi.org/10.1609/aaai.v37i6.25925">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The prevailing graph neural network models have achieved significant progress in graph representation learning. However, in this paper, we uncover an ever-overlooked phenomenon: the pre-trained graph representation learning model tested with full graphs underperforms the model tested with well-pruned graphs. This observation reveals that there exist confounders in graphs, which may interfere with the model learning semantic information, and current graph representation learning methods have not eliminated their influence. To tackle this issue, we propose Robust Causal Graph Representation Learning (RCGRL) to learn robust graph representations against confounding effects. RCGRL introduces an active approach to generate instrumental variables under unconditional moment restrictions, which empowers the graph representation learning model to eliminate confounders, thereby capturing discriminative information that is causally related to downstream predictions. We offer theorems and proofs to guarantee the theoretical effectiveness of the proposed approach. Empirically, we conduct extensive experiments on a synthetic dataset and multiple benchmark datasets. Experimental results demonstrate the effectiveness and generalization ability of RCGRL. Our codes are available at https://github.com/hang53/RCGRL.},
  archive   = {C_AAAI},
  author    = {Hang Gao and Jiangmeng Li and Wenwen Qiang and Lingyu Si and Bing Xu and Changwen Zheng and Fuchun Sun},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25925},
  pages     = {7624-7632},
  title     = {Robust causal graph representation learning against confounding effects},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fast counterfactual inference for history-based
reinforcement learning. <em>AAAI</em>, 7613–7623. (<a
href="https://doi.org/10.1609/aaai.v37i6.25924">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Incorporating sequence-to-sequence models into history-based Reinforcement Learning (RL) provides a general way to extend RL to partially-observable tasks. This method compresses history spaces according to the correlations between historical observations and the rewards. However, they do not adjust for the confounding correlations caused by data sampling and assign high beliefs to uninformative historical observations, leading to limited compression of history spaces. Counterfactual Inference (CI), which estimates causal effects by single-variable intervention, is a promising way to adjust for confounding. However, it is computationally infeasible to directly apply the single-variable intervention to a huge number of historical observations. This paper proposes to perform CI on observation sub-spaces instead of single observations and develop a coarse-to-fine CI algorithm, called Tree-based History Counterfactual Inference (T-HCI), to reduce the number of interventions exponentially. We show that T-HCI is computationally feasible in practice and brings significant sample efficiency gains in various challenging partially-observable tasks, including Maze, BabyAI, and robot manipulation tasks.},
  archive   = {C_AAAI},
  author    = {Haichuan Gao and Tianren Zhang and Zhile Yang and Yuqing Guo and Jinsheng Ren and Shangqi Guo and Feng Chen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25924},
  pages     = {7613-7623},
  title     = {Fast counterfactual inference for history-based reinforcement learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). EffConv: Efficient learning of kernel sizes for convolution
layers of CNNs. <em>AAAI</em>, 7604–7612. (<a
href="https://doi.org/10.1609/aaai.v37i6.25923">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Determining kernel sizes of a CNN model is a crucial and non-trivial design choice and significantly impacts its performance. The majority of kernel size design methods rely on complex heuristic tricks or leverage neural architecture search that requires extreme computational resources. Thus, learning kernel sizes, using methods such as modeling kernels as a combination of basis functions, jointly with the model weights has been proposed as a workaround. However, previous methods cannot achieve satisfactory results or are inefficient for large-scale datasets. To fill this gap, we design a novel efficient kernel size learning method in which a size predictor model learns to predict optimal kernel sizes for a classifier given a desired number of parameters. It does so in collaboration with a kernel predictor model that predicts the weights of the kernels - given kernel sizes predicted by the size predictor - to minimize the training objective, and both models are trained end-to-end. Our method only needs a small fraction of the training epochs of the original CNN to train these two models and find proper kernel sizes for it. Thus, it offers an efficient and effective solution for the kernel size learning problem. Our extensive experiments on MNIST, CIFAR-10, STL-10, and ImageNet-32 demonstrate that our method can achieve the best training time vs. accuracy trade-off compared to previous kernel size learning methods and significantly outperform them on challenging datasets such as STL-10 and ImageNet-32. Our implementations are available at https://github.com/Alii-Ganjj/EffConv.},
  archive   = {C_AAAI},
  author    = {Alireza Ganjdanesh and Shangqian Gao and Heng Huang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25923},
  pages     = {7604-7612},
  title     = {EffConv: Efficient learning of kernel sizes for convolution layers of CNNs},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Decorate the newcomers: Visual domain prompt for continual
test time adaptation. <em>AAAI</em>, 7595–7603. (<a
href="https://doi.org/10.1609/aaai.v37i6.25922">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Continual Test-Time Adaptation (CTTA) aims to adapt the source model to continually changing unlabeled target domains without access to the source data. Existing methods mainly focus on model-based adaptation in a self-training manner, such as predicting pseudo labels for new domain datasets. Since pseudo labels are noisy and unreliable, these methods suffer from catastrophic forgetting and error accumulation when dealing with dynamic data distributions. Motivated by the prompt learning in NLP, in this paper, we propose to learn an image-layer visual domain prompt for target domains while having the source model parameters frozen. During testing, the changing target datasets can be adapted to the source model by reformulating the input data with the learned visual prompts. Specifically, we devise two types of prompts, i.e., domains-specific prompts and domains-agnostic prompts, to extract current domain knowledge and maintain the domain-shared knowledge in the continual adaptation. Furthermore, we design a homeostasis-based adaptation strategy to suppress domain-sensitive parameters in domain-invariant prompts to learn domain-shared knowledge more effectively. This transition from the model-dependent paradigm to the model-free one enables us to bypass the catastrophic forgetting and error accumulation problems. Experiments show that our proposed method achieves significant performance gains over state-of-the-art methods on four widely-used benchmarks, including CIFAR-10C, CIFAR-100C, ImageNet-C, and VLCS datasets.},
  archive   = {C_AAAI},
  author    = {Yulu Gan and Yan Bai and Yihang Lou and Xianzheng Ma and Renrui Zhang and Nian Shi and Lin Luo},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25922},
  pages     = {7595-7603},
  title     = {Decorate the newcomers: Visual domain prompt for continual test time adaptation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Estimating average causal effects from patient trajectories.
<em>AAAI</em>, 7586–7594. (<a
href="https://doi.org/10.1609/aaai.v37i6.25921">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In medical practice, treatments are selected based on the expected causal effects on patient outcomes. Here, the gold standard for estimating causal effects are randomized controlled trials; however, such trials are costly and sometimes even unethical. Instead, medical practice is increasingly interested in estimating causal effects among patient (sub)groups from electronic health records, that is, observational data. In this paper, we aim at estimating the average causal effect (ACE) from observational data (patient trajectories) that are collected over time. For this, we propose DeepACE: an end-to-end deep learning model. DeepACE leverages the iterative G-computation formula to adjust for the bias induced by time-varying confounders. Moreover, we develop a novel sequential targeting procedure which ensures that DeepACE has favorable theoretical properties, i.e., is doubly robust and asymptotically efficient. To the best of our knowledge, this is the first work that proposes an end-to-end deep learning model tailored for estimating time-varying ACEs. We compare DeepACE in an extensive number of experiments, confirming that it achieves state-of-the-art performance. We further provide a case study for patients suffering from low back pain to demonstrate that DeepACE generates important and meaningful findings for clinical practice. Our work enables practitioners to develop effective treatment recommendations based on population effects.},
  archive   = {C_AAAI},
  author    = {Dennis Frauen and Tobias Hatt and Valentyn Melnychuk and Stefan Feuerriegel},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25921},
  pages     = {7586-7594},
  title     = {Estimating average causal effects from patient trajectories},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal decision diagrams for classification. <em>AAAI</em>,
7577–7585. (<a href="https://doi.org/10.1609/aaai.v37i6.25920">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Decision diagrams for classification have some notable advantages over decision trees, as their internal connections can be determined at training time and their width is not bound to grow exponentially with their depth. Accordingly, decision diagrams are usually less prone to data fragmentation in internal nodes. However, the inherent complexity of training these classifiers acted as a long-standing barrier to their widespread adoption. In this context, we study the training of optimal decision diagrams (ODDs) from a mathematical programming perspective. We introduce a novel mixed-integer linear programming model for training and demonstrate its applicability for many datasets of practical importance. Further, we show how this model can be easily extended for fairness, parsimony, and stability notions. We present numerical analyses showing that our model allows training ODDs in short computational times, and that ODDs achieve better accuracy than optimal decision trees, while allowing for improved stability without significant accuracy losses.},
  archive   = {C_AAAI},
  author    = {Alexandre M. Florio and Pedro Martins and Maximilian Schiffer and Thiago Serra and Thibaut Vidal},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25920},
  pages     = {7577-7585},
  title     = {Optimal decision diagrams for classification},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SigMaNet: One laplacian to rule them all. <em>AAAI</em>,
7568–7576. (<a href="https://doi.org/10.1609/aaai.v37i6.25919">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper introduces SigMaNet, a generalized Graph Convolutional Network (GCN) capable of handling both undirected and directed graphs with weights not restricted in sign nor magnitude. The cornerstone of SigMaNet is the Sign-Magnetic Laplacian (LSM), a new Laplacian matrix that we introduce ex novo in this work. LSM allows us to bridge a gap in the current literature by extending the theory of spectral GCNs to (directed) graphs with both positive and negative weights. LSM exhibits several desirable properties not enjoyed by other Laplacian matrices on which several state-of-the-art architectures are based, among which encoding the edge direction and weight in a clear and natural way that is not negatively affected by the weight magnitude. LSM is also completely parameter-free, which is not the case of other Laplacian operators such as, e.g., the Magnetic Laplacian. The versatility and the performance of our proposed approach is amply demonstrated via computational experiments. Indeed, our results show that, for at least a metric, SigMaNet achieves the best performance in 15 out of 21 cases and either the first- or second-best performance in 21 cases out of 21, even when compared to architectures that are either more complex or that, due to being designed for a narrower class of graphs, should---but do not---achieve a better performance.},
  archive   = {C_AAAI},
  author    = {Stefano Fiorini and Stefano Coniglio and Michele Ciavotta and Enza Messina},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25919},
  pages     = {7568-7576},
  title     = {SigMaNet: One laplacian to rule them all},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Scalable attributed-graph subspace clustering.
<em>AAAI</em>, 7559–7567. (<a
href="https://doi.org/10.1609/aaai.v37i6.25918">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Over recent years, graph convolutional networks emerged as powerful node clustering methods and have set state of the art results for this task. In this paper, we argue that some of these methods are unnecessarily complex and propose a node clustering model that is more scalable while being more effective. The proposed model uses Laplacian smoothing to learn an initial representation of the graph before applying an efficient self-expressive subspace clustering procedure. This is performed via learning a factored coefficient matrix. These factors are then embedded into a new feature space in such a way as to generate a valid affinity matrix (symmetric and non-negative) on which an implicit spectral clustering algorithm is performed. Experiments on several real-world attributed datasets demonstrate the cost-effective nature of our method with respect to the state of the art.},
  archive   = {C_AAAI},
  author    = {Chakib Fettal and Lazhar Labiod and Mohamed Nadif},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25918},
  pages     = {7559-7567},
  title     = {Scalable attributed-graph subspace clustering},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Combinatorial causal bandits. <em>AAAI</em>, 7550–7558. (<a
href="https://doi.org/10.1609/aaai.v37i6.25917">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In combinatorial causal bandits (CCB), the learning agent chooses at most K variables in each round to intervene, collects feedback from the observed variables, with the goal of minimizing expected regret on the target variable Y. We study under the context of binary generalized linear models (BGLMs) with a succinct parametric representation of the causal models. We present the algorithm BGLM-OFU for Markovian BGLMs (i.e., no hidden variables) based on the maximum likelihood estimation method and give regret analysis for it. For the special case of linear models with hidden variables, we apply causal inference techniques such as the do calculus to convert the original model into a Markovian model, and then show that our BGLM-OFU algorithm and another algorithm based on the linear regression both solve such linear models with hidden variables. Our novelty includes (a) considering the combinatorial intervention action space and the general causal graph structures including ones with hidden variables, (b) integrating and adapting techniques from diverse studies such as generalized linear bandits and online influence maximization, and (c) avoiding unrealistic assumptions (such as knowing the joint distribution of the parents of Y under all interventions) and regret factors exponential to causal graph size in prior studies.},
  archive   = {C_AAAI},
  author    = {Shi Feng and Wei Chen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25917},
  pages     = {7550-7558},
  title     = {Combinatorial causal bandits},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Wasserstein graph distance based on L1–approximated tree
edit distance between weisfeiler–lehman subtrees. <em>AAAI</em>,
7539–7549. (<a href="https://doi.org/10.1609/aaai.v37i6.25916">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Weisfeiler-Lehman (WL) test is a widely used algorithm in graph machine learning, including graph kernels, graph metrics, and graph neural networks. However, it focuses only on the consistency of the graph, which means that it is unable to detect slight structural differences. Consequently, this limits its ability to capture structural information, which also limits the performance of existing models that rely on the WL test. This limitation is particularly severe for traditional metrics defined by the WL test, which cannot precisely capture slight structural differences. In this paper, we propose a novel graph metric called the Wasserstein WL Subtree (WWLS) distance to address this problem. Our approach leverages the WL subtree as structural information for node neighborhoods and defines node metrics using the L1-approximated tree edit distance (L1-TED) between WL subtrees of nodes. Subsequently, we combine the Wasserstein distance and the L1-TED to define the WWLS distance, which can capture slight structural differences that may be difficult to detect using conventional metrics. We demonstrate that the proposed WWLS distance outperforms baselines in both metric validation and graph classification experiments.},
  archive   = {C_AAAI},
  author    = {Zhongxi Fang and Jianming Huang and Xun Su and Hiroyuki Kasai},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25916},
  pages     = {7539-7549},
  title     = {Wasserstein graph distance based on L1–Approximated tree edit distance between Weisfeiler–Lehman subtrees},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning decomposed spatial relations for multi-variate
time-series modeling. <em>AAAI</em>, 7530–7538. (<a
href="https://doi.org/10.1609/aaai.v37i6.25915">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Modeling multi-variate time-series (MVTS) data is a long-standing research subject and has found wide applications. Recently, there is a surge of interest in modeling spatial relations between variables as graphs, i.e., first learning one static graph for each dataset and then exploiting the graph structure via graph neural networks. However, as spatial relations may differ substantially across samples, building one static graph for all the samples inherently limits flexibility and severely degrades the performance in practice. To address this issue, we propose a framework for fine-grained modeling and utilization of spatial correlation between variables. By analyzing the statistical properties of real-world datasets, a universal decomposition of spatial correlation graphs is first identified. Specifically, the hidden spatial relations can be decomposed into a prior part, which applies across all the samples, and a dynamic part, which varies between samples, and building different graphs is necessary to model these relations. To better coordinate the learning of the two relational graphs, we propose a min-max learning paradigm that not only regulates the common part of different dynamic graphs but also guarantees spatial distinguishability among samples. The experimental results show that our proposed model outperforms the state-of-the-art baseline methods on both time-series forecasting and time-series point prediction tasks.},
  archive   = {C_AAAI},
  author    = {Yuchen Fang and Kan Ren and Caihua Shan and Yifei Shen and You Li and Weinan Zhang and Yong Yu and Dongsheng Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25915},
  pages     = {7530-7538},
  title     = {Learning decomposed spatial relations for multi-variate time-series modeling},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dish-TS: A general paradigm for alleviating distribution
shift in time series forecasting. <em>AAAI</em>, 7522–7529. (<a
href="https://doi.org/10.1609/aaai.v37i6.25914">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The distribution shift in Time Series Forecasting (TSF), indicating series distribution changes over time, largely hinders the performance of TSF models. Existing works towards distribution shift in time series are mostly limited in the quantification of distribution and, more importantly, overlook the potential shift between lookback and horizon windows. To address above challenges, we systematically summarize the distribution shift in TSF into two categories. Regarding lookback windows as input-space and horizon windows as output-space, there exist (i) intra-space shift, that the distribution within the input-space keeps shifted over time, and (ii) inter-space shift, that the distribution is shifted between input-space and output-space. Then we introduce, Dish-TS, a general neural paradigm for alleviating distribution shift in TSF. Specifically, for better distribution estimation, we propose the coefficient net (Conet), which can be any neural architectures, to map input sequences into learnable distribution coefficients. To relieve intra-space and inter-space shift, we organize Dish-TS as a Dual-Conet framework to separately learn the distribution of input- and output-space, which naturally captures the distribution difference of two spaces. In addition, we introduce a more effective training strategy for intractable Conet learning. Finally, we conduct extensive experiments on several datasets coupled with different state-of-the-art forecasting models. Experimental results show Dish-TS consistently boosts them with a more than 20\% average improvement. Code is available at https://github.com/weifantt/Dish-TS.},
  archive   = {C_AAAI},
  author    = {Wei Fan and Pengyang Wang and Dongkun Wang and Dongjie Wang and Yuanchun Zhou and Yanjie Fu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25914},
  pages     = {7522-7529},
  title     = {Dish-TS: A general paradigm for alleviating distribution shift in time series forecasting},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Directed acyclic graph structure learning from dynamic
graphs. <em>AAAI</em>, 7512–7521. (<a
href="https://doi.org/10.1609/aaai.v37i6.25913">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Estimating the structure of directed acyclic graphs (DAGs) of features (variables) plays a vital role in revealing the latent data generation process and providing causal insights in various applications. Although there have been many studies on structure learning with various types of data, the structure learning on the dynamic graph has not been explored yet, and thus we study the learning problem of node feature generation mechanism on such ubiquitous dynamic graph data. In a dynamic graph, we propose to simultaneously estimate contemporaneous relationships and time-lagged interaction relationships between the node features. These two kinds of relationships form a DAG, which could effectively characterize the feature generation process in a concise way. To learn such a DAG, we cast the learning problem as a continuous score-based optimization problem, which consists of a differentiable score function to measure the validity of the learned DAGs and a smooth acyclicity constraint to ensure the acyclicity of the learned DAGs. These two components are translated into an unconstraint augmented Lagrangian objective which could be minimized by mature continuous optimization techniques. The resulting algorithm, named GraphNOTEARS, outperforms baselines on simulated data across a wide range of settings that may encounter in real-world applications. We also apply the proposed approach on two dynamic graphs constructed from the real-world Yelp dataset, demonstrating our method could learn the connections between node features, which conforms with the domain knowledge.},
  archive   = {C_AAAI},
  author    = {Shaohua Fan and Shuyang Zhang and Xiao Wang and Chuan Shi},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25913},
  pages     = {7512-7521},
  title     = {Directed acyclic graph structure learning from dynamic graphs},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Goal-conditioned generators of deep policies. <em>AAAI</em>,
7503–7511. (<a href="https://doi.org/10.1609/aaai.v37i6.25912">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Goal-conditioned Reinforcement Learning (RL) aims at learning optimal policies, given goals encoded in special command inputs. Here we study goal-conditioned neural nets (NNs) that learn to generate deep NN policies in form of context-specific weight matrices, similar to Fast Weight Programmers and other methods from the 1990s. Using context commands of the form ``generate a policy that achieves a desired expected return,&#39;&#39; our NN generators combine powerful exploration of parameter space with generalization across commands to iteratively find better and better policies. A form of weight-sharing HyperNetworks and policy embeddings scales our method to generate deep NNs. Experiments show how a single learned policy generator can produce policies that achieve any return seen during training. Finally, we evaluate our algorithm on a set of continuous control tasks where it exhibits competitive performance. Our code is public.},
  archive   = {C_AAAI},
  author    = {Francesco Faccio and Vincent Herrmann and Aditya Ramesh and Louis Kirsch and Jürgen Schmidhuber},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25912},
  pages     = {7503-7511},
  title     = {Goal-conditioned generators of deep policies},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FairFed: Enabling group fairness in federated learning.
<em>AAAI</em>, 7494–7502. (<a
href="https://doi.org/10.1609/aaai.v37i6.25911">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Training ML models which are fair across different demographic groups is of critical importance due to the increased integration of ML in crucial decision-making scenarios such as healthcare and recruitment. Federated learning has been viewed as a promising solution for collaboratively training machine learning models among multiple parties while maintaining their local data privacy. However, federated learning also poses new challenges in mitigating the potential bias against certain populations (e.g., demographic groups), as this typically requires centralized access to the sensitive information (e.g., race, gender) of each datapoint. Motivated by the importance and challenges of group fairness in federated learning, in this work, we propose FairFed, a novel algorithm for fairness-aware aggregation to enhance group fairness in federated learning. Our proposed approach is server-side and agnostic to the applied local debiasing thus allowing for flexible use of different local debiasing methods across clients. We evaluate FairFed empirically versus common baselines for fair ML and federated learning and demonstrate that it provides fairer models, particularly under highly heterogeneous data distributions across clients. We also demonstrate the benefits of FairFed in scenarios involving naturally distributed real-life data collected from different geographical locations or departments within an organization.},
  archive   = {C_AAAI},
  author    = {Yahya H. Ezzeldin and Shen Yan and Chaoyang He and Emilio Ferrara and A. Salman Avestimehr},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25911},
  pages     = {7494-7502},
  title     = {FairFed: Enabling group fairness in federated learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Popularizing fairness: Group fairness and individual
welfare. <em>AAAI</em>, 7485–7493. (<a
href="https://doi.org/10.1609/aaai.v37i6.25910">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Group-fair learning methods typically seek to ensure that some measure of prediction efficacy for (often historically) disadvantaged minority groups is comparable to that for the majority of the population. When a principal seeks to adopt a group-fair approach to replace another, the principal may face opposition from those who feel they may be harmed by the switch, and this, in turn, may deter adoption. We propose that a potential mitigation to this concern is to ensure that a group-fair model is also popular, in the sense that, for a majority of the target population, it yields a preferred distribution over outcomes compared with the conventional model. In this paper, we show that state of the art fair learning approaches are often unpopular in this sense. We propose several efficient algorithms for postprocessing an existing group-fair learning scheme to improve its popularity while retaining fairness. Through extensive experiments, we demonstrate that the proposed postprocessing approaches are highly effective in practice.},
  archive   = {C_AAAI},
  author    = {Andrew Estornell and Sanmay Das and Brendan Juba and Yevgeniy Vorobeychik},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25910},
  pages     = {7485-7493},
  title     = {Popularizing fairness: Group fairness and individual welfare},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Combining slow and fast: Complementary filtering for
dynamics learning. <em>AAAI</em>, 7476–7484. (<a
href="https://doi.org/10.1609/aaai.v37i6.25909">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Modeling an unknown dynamical system is crucial in order to predict the future behavior of the system. A standard approach is training recurrent models on measurement data. While these models typically provide exact short-term predictions, accumulating errors yield deteriorated long-term behavior. In contrast, models with reliable long-term predictions can often be obtained, either by training a robust but less detailed model, or by leveraging physics-based simulations. In both cases, inaccuracies in the models yield a lack of short-time details. Thus, different models with contrastive properties on different time horizons are available. This observation immediately raises the question: Can we obtain predictions that combine the best of both worlds? Inspired by sensor fusion tasks, we interpret the problem in the frequency domain and leverage classical methods from signal processing, in particular complementary filters. This filtering technique combines two signals by applying a high-pass filter to one signal, and low-pass filtering the other. Essentially, the high-pass filter extracts high-frequencies, whereas the low-pass filter extracts low frequencies. Applying this concept to dynamics model learning enables the construction of models that yield accurate long- and short-term predictions. Here, we propose two methods, one being purely learning-based and the other one being a hybrid model that requires an additional physics-based simulator.},
  archive   = {C_AAAI},
  author    = {Katharina Ensinger and Sebastian Ziesche and Barbara Rakitsch and Michael Tiemann and Sebastian Trimpe},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25909},
  pages     = {7476-7484},
  title     = {Combining slow and fast: Complementary filtering for dynamics learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Diffeomorphic information neural estimation. <em>AAAI</em>,
7468–7475. (<a href="https://doi.org/10.1609/aaai.v37i6.25908">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Mutual Information (MI) and Conditional Mutual Information (CMI) are multi-purpose tools from information theory that are able to naturally measure the statistical dependencies between random variables, thus they are usually of central interest in several statistical and machine learning tasks, such as conditional independence testing and representation learning. However, estimating CMI, or even MI, is infamously challenging due the intractable formulation. In this study, we introduce DINE (Diffeomorphic Information Neural Estimator)–a novel approach for estimating CMI of continuous random variables, inspired by the invariance of CMI over diffeomorphic maps. We show that the variables of interest can be replaced with appropriate surrogates that follow simpler distributions, allowing the CMI to be efficiently evaluated via analytical solutions. Additionally, we demonstrate the quality of the proposed estimator in comparison with state-of-the-arts in three important tasks, including estimating MI, CMI, as well as its application in conditional independence testing. The empirical evaluations show that DINE consistently outperforms competitors in all tasks and is able to adapt very well to complex and high-dimensional relationships.},
  archive   = {C_AAAI},
  author    = {Bao Duong and Thin Nguyen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25908},
  pages     = {7468-7475},
  title     = {Diffeomorphic information neural estimation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Graph anomaly detection via multi-scale contrastive learning
networks with augmented view. <em>AAAI</em>, 7459–7467. (<a
href="https://doi.org/10.1609/aaai.v37i6.25907">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph anomaly detection (GAD) is a vital task in graph-based machine learning and has been widely applied in many real-world applications. The primary goal of GAD is to capture anomalous nodes from graph datasets, which evidently deviate from the majority of nodes. Recent methods have paid attention to various scales of contrastive strategies for GAD, i.e., node-subgraph and node-node contrasts. However, they neglect the subgraph-subgraph comparison information which the normal and abnormal subgraph pairs behave differently in terms of embeddings and structures in GAD, resulting in sub-optimal task performance. In this paper, we fulfill the above idea in the proposed multi-view multi-scale contrastive learning framework with subgraph-subgraph contrast for the first practice. To be specific, we regard the original input graph as the first view and generate the second view by graph augmentation with edge modifications. With the guidance of maximizing the similarity of the subgraph pairs, the proposed subgraph-subgraph contrast contributes to more robust subgraph embeddings despite of the structure variation. Moreover, the introduced subgraph-subgraph contrast cooperates well with the widely-adopted node-subgraph and node-node contrastive counterparts for mutual GAD performance promotions. Besides, we also conduct sufficient experiments to investigate the impact of different graph augmentation approaches on detection performance. The comprehensive experimental results well demonstrate the superiority of our method compared with the state-of-the-art approaches and the effectiveness of the multi-view subgraph pair contrastive strategy for the GAD task. The source code is released at https://github.com/FelixDJC/GRADATE.},
  archive   = {C_AAAI},
  author    = {Jingcan Duan and Siwei Wang and Pei Zhang and En Zhu and Jingtao Hu and Hu Jin and Yue Liu and Zhibin Dong},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25907},
  pages     = {7459-7467},
  title     = {Graph anomaly detection via multi-scale contrastive learning networks with augmented view},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust and fast measure of information via low-rank
representation. <em>AAAI</em>, 7450–7458. (<a
href="https://doi.org/10.1609/aaai.v37i6.25906">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The matrix-based Rényi&#39;s entropy allows us to directly quantify information measures from given data, without explicit estimation of the underlying probability distribution. This intriguing property makes it widely applied in statistical inference and machine learning tasks. However, this information theoretical quantity is not robust against noise in the data, and is computationally prohibitive in large-scale applications. To address these issues, we propose a novel measure of information, termed low-rank matrix-based Rényi&#39;s entropy, based on low-rank representations of infinitely divisible kernel matrices. The proposed entropy functional inherits the specialty of of the original definition to directly quantify information from data, but enjoys additional advantages including robustness and effective calculation. Specifically, our low-rank variant is more sensitive to informative perturbations induced by changes in underlying distributions, while being insensitive to uninformative ones caused by noises. Moreover, low-rank Rényi&#39;s entropy can be efficiently approximated by random projection and Lanczos iteration techniques, reducing the overall complexity from O(n³) to O(n²s) or even O(ns²), where n is the number of data samples and s ≪ n. We conduct large-scale experiments to evaluate the effectiveness of this new information measure, demonstrating superior results compared to matrix-based Rényi&#39;s entropy in terms of both performance and computational efficiency.},
  archive   = {C_AAAI},
  author    = {Yuxin Dong and Tieliang Gong and Shujian Yu and Hong Chen and Chen Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25906},
  pages     = {7450-7458},
  title     = {Robust and fast measure of information via low-rank representation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Interpreting unfairness in graph neural networks via
training node attribution. <em>AAAI</em>, 7441–7449. (<a
href="https://doi.org/10.1609/aaai.v37i6.25905">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph Neural Networks (GNNs) have emerged as the leading paradigm for solving graph analytical problems in various real-world applications. Nevertheless, GNNs could potentially render biased predictions towards certain demographic subgroups. Understanding how the bias in predictions arises is critical, as it guides the design of GNN debiasing mechanisms. However, most existing works overwhelmingly focus on GNN debiasing, but fall short on explaining how such bias is induced. In this paper, we study a novel problem of interpreting GNN unfairness through attributing it to the influence of training nodes. Specifically, we propose a novel strategy named Probabilistic Distribution Disparity (PDD) to measure the bias exhibited in GNNs, and develop an algorithm to efficiently estimate the influence of each training node on such bias. We verify the validity of PDD and the effectiveness of influence estimation through experiments on real-world datasets. Finally, we also demonstrate how the proposed framework could be used for debiasing GNNs. Open-source code can be found at https://github.com/yushundong/BIND.},
  archive   = {C_AAAI},
  author    = {Yushun Dong and Song Wang and Jing Ma and Ninghao Liu and Jundong Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25905},
  pages     = {7441-7449},
  title     = {Interpreting unfairness in graph neural networks via training node attribution},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Can label-specific features help partial-label learning?
<em>AAAI</em>, 7432–7440. (<a
href="https://doi.org/10.1609/aaai.v37i6.25904">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Partial label learning (PLL) aims to learn from inexact data annotations where each training example is associated with a coarse candidate label set. Due to its practicability, many PLL algorithms have been proposed in recent literature. Most prior PLL works attempt to identify the ground-truth labels from candidate sets and the classifier is trained afterward by fitting the features of examples and their exact ground-truth labels. From a different perspective, we propose to enrich the feature space and raise the question ``Can label-specific features help PLL?&#39;&#39; rather than learning from examples with identical features for all classes. Despite its benefits, previous label-specific feature approaches rely on ground-truth labels to split positive and negative examples of each class and then conduct clustering analysis, which is not directly applicable in PLL. To remedy this problem, we propose an uncertainty-aware confidence region to accommodate false positive labels. We first employ graph-based label enhancement to yield smooth pseudo-labels and facilitate the confidence region split. After acquiring label-specific features, a family of binary classifiers is induced. Extensive experiments on both synthesized and real-world datasets are conducted and the results show that our method consistently outperforms eight baselines. Our code is released at https://github.com/meteoseeker/UCL},
  archive   = {C_AAAI},
  author    = {Ruo-Jing Dong and Jun-Yi Hang and Tong Wei and Min-Ling Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25904},
  pages     = {7432-7440},
  title     = {Can label-specific features help partial-label learning?},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Model-based offline reinforcement learning with local
misspecification. <em>AAAI</em>, 7423–7431. (<a
href="https://doi.org/10.1609/aaai.v37i6.25903">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present a model-based offline reinforcement learning policy performance lower bound that explicitly captures dynamics model misspecification and distribution mismatch and we propose an empirical algorithm for optimal offline policy selection. Theoretically, we prove a novel safe policy improvement theorem by establishing pessimism approximations to the value function. Our key insight is to jointly consider selecting over dynamics models and policies: as long as a dynamics model can accurately represent the dynamics of the state-action pairs visited by a given policy, it is possible to approximate the value of that particular policy. We analyze our lower bound in the LQR setting and also show competitive performance to previous lower bounds on policy selection across a set of D4RL tasks.},
  archive   = {C_AAAI},
  author    = {Kefan Dong and Yannis Flet-Berliac and Allen Nie and Emma Brunskill},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25903},
  pages     = {7423-7431},
  title     = {Model-based offline reinforcement learning with local misspecification},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SKDBERT: Compressing BERT via stochastic knowledge
distillation. <em>AAAI</em>, 7414–7422. (<a
href="https://doi.org/10.1609/aaai.v37i6.25902">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we propose Stochastic Knowledge Distillation (SKD) to obtain compact BERT-style language model dubbed SKDBERT. In each distillation iteration, SKD samples a teacher model from a pre-defined teacher team, which consists of multiple teacher models with multi-level capacities, to transfer knowledge into student model in an one-to-one manner. Sampling distribution plays an important role in SKD. We heuristically present three types of sampling distributions to assign appropriate probabilities for multi-level teacher models. SKD has two advantages: 1) it can preserve the diversities of multi-level teacher models via stochastically sampling single teacher model in each distillation iteration, and 2) it can also improve the efficacy of knowledge distillation via multi-level teacher models when large capacity gap exists between the teacher model and the student model. Experimental results on GLUE benchmark show that SKDBERT reduces the size of a BERT model by 40\% while retaining 99.5\% performances of language understanding and being 100\% faster.},
  archive   = {C_AAAI},
  author    = {Zixiang Ding and Guoqing Jiang and Shuai Zhang and Lin Guo and Wei Lin},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25902},
  pages     = {7414-7422},
  title     = {SKDBERT: Compressing BERT via stochastic knowledge distillation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Non-stationary risk-sensitive reinforcement learning:
Near-optimal dynamic regret, adaptive detection, and separation design.
<em>AAAI</em>, 7405–7413. (<a
href="https://doi.org/10.1609/aaai.v37i6.25901">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study risk-sensitive reinforcement learning (RL) based on an entropic risk measure in episodic non-stationary Markov decision processes (MDPs). Both the reward functions and the state transition kernels are unknown and allowed to vary arbitrarily over time with a budget on their cumulative variations. When this variation budget is known a prior, we propose two restart-based algorithms, namely Restart-RSMB and Restart-RSQ, and establish their dynamic regrets. Based on these results, we further present a meta-algorithm that does not require any prior knowledge of the variation budget and can adaptively detect the non-stationarity on the exponential value functions. A dynamic regret lower bound is then established for non-stationary risk-sensitive RL to certify the near-optimality of the proposed algorithms. Our results also show that the risk control and the handling of the non-stationarity can be separately designed in the algorithm if the variation budget is known a prior, while the non-stationary detection mechanism in the adaptive algorithm depends on the risk parameter. This work offers the first non-asymptotic theoretical analyses for the non-stationary risk-sensitive RL in the literature.},
  archive   = {C_AAAI},
  author    = {Yuhao Ding and Ming Jin and Javad Lavaei},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25901},
  pages     = {7405-7413},
  title     = {Non-stationary risk-sensitive reinforcement learning: Near-optimal dynamic regret, adaptive detection, and separation design},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Provably efficient primal-dual reinforcement learning for
CMDPs with non-stationary objectives and constraints. <em>AAAI</em>,
7396–7404. (<a href="https://doi.org/10.1609/aaai.v37i6.25900">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider primal-dual-based reinforcement learning (RL) in episodic constrained Markov decision processes (CMDPs) with non-stationary objectives and constraints, which plays a central role in ensuring the safety of RL in time-varying environments. In this problem, the reward/utility functions and the state transition functions are both allowed to vary arbitrarily over time as long as their cumulative variations do not exceed certain known variation budgets. Designing safe RL algorithms in time-varying environments is particularly challenging because of the need to integrate the constraint violation reduction, safe exploration, and adaptation to the non-stationarity. To this end, we identify two alternative conditions on the time-varying constraints under which we can guarantee the safety in the long run. We also propose the Periodically Restarted Optimistic Primal-Dual Proximal Policy Optimization (PROPD-PPO) algorithm that can coordinate with both two conditions. Furthermore, a dynamic regret bound and a constraint violation bound are established for the proposed algorithm in both the linear kernel CMDP function approximation setting and the tabular CMDP setting under two alternative conditions. This paper provides the first provably efficient algorithm for non-stationary CMDPs with safe exploration.},
  archive   = {C_AAAI},
  author    = {Yuhao Ding and Javad Lavaei},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25900},
  pages     = {7396-7404},
  title     = {Provably efficient primal-dual reinforcement learning for CMDPs with non-stationary objectives and constraints},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Incremental reinforcement learning with dual-adaptive
ε-greedy exploration. <em>AAAI</em>, 7387–7395. (<a
href="https://doi.org/10.1609/aaai.v37i6.25899">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Reinforcement learning (RL) has achieved impressive performance in various domains. However, most RL frameworks oversimplify the problem by assuming a fixed-yet-known environment and often have difficulty being generalized to real-world scenarios. In this paper, we address a new challenge with a more realistic setting, Incremental Reinforcement Learning, where the search space of the Markov Decision Process continually expands. While previous methods usually suffer from the lack of efficiency in exploring the unseen transitions, especially with increasing search space, we present a new exploration framework named Dual-Adaptive ϵ-greedy Exploration (DAE) to address the challenge of Incremental RL. Specifically, DAE employs a Meta Policy and an Explorer to avoid redundant computation on those sufficiently learned samples. Furthermore, we release a testbed based on a synthetic environment and the Atari benchmark to validate the effectiveness of any exploration algorithms under Incremental RL. Experimental results demonstrate that the proposed framework can efficiently learn the unseen transitions in new environments, leading to notable performance improvement, i.e., an average of more than 80\%, over eight baselines examined.},
  archive   = {C_AAAI},
  author    = {Wei Ding and Siyang Jiang and Hsi-Wen Chen and Ming-Syan Chen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25899},
  pages     = {7387-7395},
  title     = {Incremental reinforcement learning with dual-adaptive ε-greedy exploration},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Eliciting structural and semantic global knowledge in
unsupervised graph contrastive learning. <em>AAAI</em>, 7378–7386. (<a
href="https://doi.org/10.1609/aaai.v37i6.25898">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph Contrastive Learning (GCL) has recently drawn much research interest for learning generalizable node representations in a self-supervised manner. In general, the contrastive learning process in GCL is performed on top of the representations learned by a graph neural network (GNN) backbone, which transforms and propagates the node contextual information based on its local neighborhoods. However, nodes sharing similar characteristics may not always be geographically close, which poses a great challenge for unsupervised GCL efforts due to their inherent limitations in capturing such global graph knowledge. In this work, we address their inherent limitations by proposing a simple yet effective framework -- Simple Neural Networks with Structural and Semantic Contrastive Learning (S^3-CL). Notably, by virtue of the proposed structural and semantic contrastive learning algorithms, even a simple neural network can learn expressive node representations that preserve valuable global structural and semantic patterns. Our experiments demonstrate that the node representations learned by S^3-CL) achieve superior performance on different downstream tasks compared with the state-of-the-art unsupervised GCL methods. Implementation and more experimental details are publicly available at https://github.com/kaize0409/S-3-CL.},
  archive   = {C_AAAI},
  author    = {Kaize Ding and Yancheng Wang and Yingzhen Yang and Huan Liu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25898},
  pages     = {7378-7386},
  title     = {Eliciting structural and semantic global knowledge in unsupervised graph contrastive learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). C-NTPP: Learning cluster-aware neural temporal point
process. <em>AAAI</em>, 7369–7377. (<a
href="https://doi.org/10.1609/aaai.v37i6.25897">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Event sequences in continuous time space are ubiquitous across applications and have been intensively studied with both classic temporal point process (TPP) and its recent deep network variants. This work is motivated by an observation that many of event data exhibit inherent clustering patterns in terms of the sparse correlation among events, while such characteristics are seldom explicitly considered in existing neural TPP models whereby the history encoders are often embodied by RNNs or Transformers. In this work, we propose a c-NTPP (Cluster-Aware Neural Temporal Point Process) model, which leverages a sequential variational autoencoder framework to infer the latent cluster each event belongs to in the sequence. Specially, a novel event-clustered attention mechanism is devised to learn each cluster and then aggregate them together to obtain the final representation for each event. Extensive experiments show that c-NTPP achieves superior performance on both real-world and synthetic datasets, and it can also uncover the underlying clustering correlations.},
  archive   = {C_AAAI},
  author    = {Fangyu Ding and Junchi Yan and Haiyang Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25897},
  pages     = {7369-7377},
  title     = {C-NTPP: Learning cluster-aware neural temporal point process},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Black-box adversarial attack on time series classification.
<em>AAAI</em>, 7358–7368. (<a
href="https://doi.org/10.1609/aaai.v37i6.25896">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With the increasing use of deep neural network (DNN) in time series classification (TSC), recent work reveals the threat of adversarial attack, where the adversary can construct adversarial examples to cause model mistakes. However, existing researches on the adversarial attack of TSC typically adopt an unrealistic white-box setting with model details transparent to the adversary. In this work, we study a more rigorous black-box setting with attack detection applied, which restricts gradient access and requires the adversarial example to be also stealthy. Theoretical analyses reveal that the key lies in: estimating black-box gradient with diversity and non-convexity of TSC models resolved, and restricting the l0 norm of the perturbation to construct adversarial samples. Towards this end, we propose a new framework named BlackTreeS, which solves the hard optimization issue for adversarial example construction with two simple yet effective modules. In particular, we propose a tree search strategy to find influential positions in a sequence, and independently estimate the black-box gradients for these positions. Extensive experiments on three real-world TSC datasets and five DNN based models validate the effectiveness of BlackTreeS, e.g., it improves the attack success rate from 19.3\% to 27.3\%, and decreases the detection success rate from 90.9\% to 6.8\% for LSTM on the UWave dataset.},
  archive   = {C_AAAI},
  author    = {Daizong Ding and Mi Zhang and Fuli Feng and Yuanmin Huang and Erling Jiang and Min Yang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25896},
  pages     = {7358-7368},
  title     = {Black-box adversarial attack on time series classification},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Integer subspace differential privacy. <em>AAAI</em>,
7349–7357. (<a href="https://doi.org/10.1609/aaai.v37i6.25895">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose new differential privacy solutions for when external invariants and integer constraints are simultaneously enforced on the data product. These requirements arise in real world applications of private data curation, including the public release of the 2020 U.S. Decennial Census. They pose a great challenge to the production of provably private data products with adequate statistical usability. We propose integer subspace differential privacy to rigorously articulate the privacy guarantee when data products maintain both the invariants and integer characteristics, and demonstrate the composition and post-processing properties of our proposal. To address the challenge of sampling from a potentially highly restricted discrete space, we devise a pair of unbiased additive mechanisms, the generalized Laplace and the generalized Gaussian mechanisms, by solving the Diophantine equations as defined by the constraints. The proposed mechanisms have good accuracy, with errors exhibiting sub-exponential and sub-Gaussian tail probabilities respectively. To implement our proposal, we design an MCMC algorithm and supply empirical convergence assessment using estimated upper bounds on the total variation distance via L-lag coupling. We demonstrate the efficacy of our proposal with applications to a synthetic problem with intersecting invariants, a sensitive contingency table with known margins, and the 2010 Census county-level demonstration data with mandated fixed state population totals.},
  archive   = {C_AAAI},
  author    = {Prathamesh Dharangutte and Jie Gao and Ruobin Gong and Fang-Yi Yu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25895},
  pages     = {7349-7357},
  title     = {Integer subspace differential privacy},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Stability-based generalization analysis of the asynchronous
decentralized SGD. <em>AAAI</em>, 7340–7348. (<a
href="https://doi.org/10.1609/aaai.v37i6.25894">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The generalization ability often determines the success of machine learning algorithms in practice. Therefore, it is of great theoretical and practical importance to understand and bound the generalization error of machine learning algorithms. In this paper, we provide the first generalization results of the popular stochastic gradient descent (SGD) algorithm in the distributed asynchronous decentralized setting. Our analysis is based on the uniform stability tool, where stable means that the learned model does not change much in small variations of the training set. Under some mild assumptions, we perform a comprehensive generalizability analysis of the asynchronous decentralized SGD, including generalization error and excess generalization error bounds for the strongly convex, convex, and non-convex cases. Our theoretical results reveal the effects of the learning rate, training data size, training iterations, decentralized communication topology, and asynchronous delay on the generalization performance of the asynchronous decentralized SGD. We also study the optimization error regarding the objective function values and investigate how the initial point affects the excess generalization error. Finally, we conduct extensive experiments on MNIST, CIFAR-10, CIFAR-100, and Tiny-ImageNet datasets to validate the theoretical findings.},
  archive   = {C_AAAI},
  author    = {Xiaoge Deng and Tao Sun and Shengwei Li and Dongsheng Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25894},
  pages     = {7340-7348},
  title     = {Stability-based generalization analysis of the asynchronous decentralized SGD},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Non-reversible parallel tempering for deep posterior
approximation. <em>AAAI</em>, 7332–7339. (<a
href="https://doi.org/10.1609/aaai.v37i6.25893">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Parallel tempering (PT), also known as replica exchange, is the go-to workhorse for simulations of multi-modal distributions. The key to the success of PT is to adopt efficient swap schemes. The popular deterministic even-odd (DEO) scheme exploits the non-reversibility property and has successfully reduced the communication cost from quadratic to linear given the sufficiently many chains. However, such an innovation largely disappears in big data due to the limited chains and few bias-corrected swaps. To handle this issue, we generalize the DEO scheme to promote non-reversibility and propose a few solutions to tackle the underlying bias caused by the geometric stopping time. Notably, in big data scenarios, we obtain a nearly linear communication cost based on the optimal window size. In addition, we also adopt stochastic gradient descent (SGD) with large and constant learning rates as exploration kernels. Such a user-friendly nature enables us to conduct approximation tasks for complex posteriors without much tuning costs.},
  archive   = {C_AAAI},
  author    = {Wei Deng and Qian Zhang and Qi Feng and Faming Liang and Guang Lin},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25893},
  pages     = {7332-7339},
  title     = {Non-reversible parallel tempering for deep posterior approximation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CrysGNN: Distilling pre-trained knowledge to enhance
property prediction for crystalline materials. <em>AAAI</em>, 7323–7331.
(<a href="https://doi.org/10.1609/aaai.v37i6.25892">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In recent years, graph neural network (GNN) based approaches have emerged as a powerful technique to encode complex topological structure of crystal materials in an enriched repre- sentation space. These models are often supervised in nature and using the property-specific training data, learn relation- ship between crystal structure and different properties like formation energy, bandgap, bulk modulus, etc. Most of these methods require a huge amount of property-tagged data to train the system which may not be available for different prop- erties. However, there is an availability of a huge amount of crystal data with its chemical composition and structural bonds. To leverage these untapped data, this paper presents CrysGNN, a new pre-trained GNN framework for crystalline materials, which captures both node and graph level structural information of crystal graphs using a huge amount of unla- belled material data. Further, we extract distilled knowledge from CrysGNN and inject into different state of the art prop- erty predictors to enhance their property prediction accuracy. We conduct extensive experiments to show that with distilled knowledge from the pre-trained model, all the SOTA algo- rithms are able to outperform their own vanilla version with good margins. We also observe that the distillation process provides significant improvement over the conventional ap- proach of finetuning the pre-trained model. We will release the pre-trained model along with the large dataset of 800K crys- tal graph which we carefully curated; so that the pre-trained model can be plugged into any existing and upcoming models to enhance their prediction accuracy.},
  archive   = {C_AAAI},
  author    = {Kishalay Das and Bidisha Samanta and Pawan Goyal and Seung-Cheol Lee and Satadeep Bhattacharjee and Niloy Ganguly},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25892},
  pages     = {7323-7331},
  title     = {CrysGNN: Distilling pre-trained knowledge to enhance property prediction for crystalline materials},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Tackling data heterogeneity in federated learning with class
prototypes. <em>AAAI</em>, 7314–7322. (<a
href="https://doi.org/10.1609/aaai.v37i6.25891">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Data heterogeneity across clients in federated learning (FL) settings is a widely acknowledged challenge. In response, personalized federated learning (PFL) emerged as a framework to curate local models for clients&#39; tasks. In PFL, a common strategy is to develop local and global models jointly - the global model (for generalization) informs the local models, and the local models (for personalization) are aggregated to update the global model. A key observation is that if we can improve the generalization ability of local models, then we can improve the generalization of global models, which in turn builds better personalized models. In this work, we consider class imbalance, an overlooked type of data heterogeneity, in the classification setting. We propose FedNH, a novel method that improves the local models&#39; performance for both personalization and generalization by combining the uniformity and semantics of class prototypes. FedNH initially distributes class prototypes uniformly in the latent space and smoothly infuses the class semantics into class prototypes. We show that imposing uniformity helps to combat prototype collapse while infusing class semantics improves local models. Extensive experiments were conducted on popular classification datasets under the cross-device setting. Our results demonstrate the effectiveness and stability of our method over recent works.},
  archive   = {C_AAAI},
  author    = {Yutong Dai and Zeyuan Chen and Junnan Li and Shelby Heinecke and Lichao Sun and Ran Xu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25891},
  pages     = {7314-7322},
  title     = {Tackling data heterogeneity in federated learning with class prototypes},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Semi-supervised deep regression with uncertainty consistency
and variational model ensembling via bayesian neural networks.
<em>AAAI</em>, 7304–7313. (<a
href="https://doi.org/10.1609/aaai.v37i6.25890">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep regression is an important problem with numerous applications. These range from computer vision tasks such as age estimation from photographs, to medical tasks such as ejection fraction estimation from echocardiograms for disease tracking. Semi-supervised approaches for deep regression are notably under-explored compared to classification and segmentation tasks, however. Unlike classification tasks, which rely on thresholding functions for generating class pseudo-labels, regression tasks use real number target predictions directly as pseudo-labels, making them more sensitive to prediction quality. In this work, we propose a novel approach to semi-supervised regression, namely Uncertainty-Consistent Variational Model Ensembling (UCVME), which improves training by generating high-quality pseudo-labels and uncertainty estimates for heteroscedastic regression. Given that aleatoric uncertainty is only dependent on input data by definition and should be equal for the same inputs, we present a novel uncertainty consistency loss for co-trained models. Our consistency loss significantly improves uncertainty estimates and allows higher quality pseudo-labels to be assigned greater importance under heteroscedastic regression. Furthermore, we introduce a novel variational model ensembling approach to reduce prediction noise and generate more robust pseudo-labels. We analytically show our method generates higher quality targets for unlabeled data and further improves training. Experiments show that our method outperforms state-of-the-art alternatives on different tasks and can be competitive with supervised methods that use full labels. Code is available at https://github.com/xmed-lab/UCVME.},
  archive   = {C_AAAI},
  author    = {Weihang Dai and Xiaomeng Li and Kwang-Ting Cheng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25890},
  pages     = {7304-7313},
  title     = {Semi-supervised deep regression with uncertainty consistency and variational model ensembling via bayesian neural networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GradPU: Positive-unlabeled learning via gradient penalty and
positive upweighting. <em>AAAI</em>, 7296–7303. (<a
href="https://doi.org/10.1609/aaai.v37i6.25889">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Positive-unlabeled learning is an essential problem in many real-world applications with only labeled positive and unlabeled data, especially when the negative samples are difficult to identify. Most existing positive-unlabeled learning methods will inevitably overfit the positive class to some extent due to the existence of unidentified positive samples. This paper first analyzes the overfitting problem and proposes to bound the generalization errors via Wasserstein distances. Based on that, we develop a simple yet effective positive-unlabeled learning method, GradPU, which consists of two key ingredients: A gradient-based regularizer that penalizes the gradient norms in the interpolated data region, which improves the generalization of positive class; An unnormalized upweighting mechanism that assigns larger weights to those positive samples that are hard, not-well-fitted and less frequently labeled. It enforces the training error of each positive sample to be small and increases the robustness to the labeling bias. We evaluate our proposed GradPU on three datasets: MNIST, FashionMNIST, and CIFAR10. The results demonstrate that GradPU achieves state-of-the-art performance on both unbiased and biased positive labeling scenarios.},
  archive   = {C_AAAI},
  author    = {Songmin Dai and Xiaoqiang Li and Yue Zhou and Xichen Ye and Tong Liu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25889},
  pages     = {7296-7303},
  title     = {GradPU: Positive-unlabeled learning via gradient penalty and positive upweighting},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Augmented proximal policy optimization for safe
reinforcement learning. <em>AAAI</em>, 7288–7295. (<a
href="https://doi.org/10.1609/aaai.v37i6.25888">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Safe reinforcement learning considers practical scenarios that maximize the return while satisfying safety constraints. Current algorithms, which suffer from training oscillations or approximation errors, still struggle to update the policy efficiently with precise constraint satisfaction. In this article, we propose Augmented Proximal Policy Optimization (APPO), which augments the Lagrangian function of the primal constrained problem via attaching a quadratic deviation term. The constructed multiplier-penalty function dampens cost oscillation for stable convergence while being equivalent to the primal constrained problem to precisely control safety costs. APPO alternately updates the policy and the Lagrangian multiplier via solving the constructed augmented primal-dual problem, which can be easily implemented by any first-order optimizer. We apply our APPO methods in diverse safety-constrained tasks, setting a new state of the art compared with a comprehensive list of safe RL baselines. Extensive experiments verify the merits of our method in easy implementation, stable convergence, and precise cost control.},
  archive   = {C_AAAI},
  author    = {Juntao Dai and Jiaming Ji and Long Yang and Qian Zheng and Gang Pan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25888},
  pages     = {7288-7295},
  title     = {Augmented proximal policy optimization for safe reinforcement learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Contrastive learning with the feature reconstruction
amplifier. <em>AAAI</em>, 7279–7287. (<a
href="https://doi.org/10.1609/aaai.v37i6.25887">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Contrastive learning has emerged as one of the most promising self-supervised methods. It can efficiently learn the transferable representations of samples through the instance-level discrimination task. In general, the performance of the contrastive learning method can be further improved by projecting the transferable high-dimensional representations into the low-dimensional feature space. This is because the model can learn more abstract discriminative information. However, when low-dimensional features cannot provide sufficient discriminative information to the model (e.g., the samples are very similar to each other), the existing contrastive learning method will be limited to a great extent. Therefore, in this paper, we propose a general module called the Feature Reconstruction Amplifier (FRA) for adding additional high-dimensional feature information to the model. Specifically, FRA reconstructs the low-dimensional feature embeddings with Gaussian noise vectors and projects them to a high-dimensional reconstruction space. In this reconstruction space, we can add additional feature information through the designed loss. We have verified the effectiveness of the module itself through exhaustive ablation experiments. In addition, we perform linear evaluation and transfer learning on five common visual datasets, the experimental results demonstrate that our method is superior to recent advanced contrastive learning methods.},
  archive   = {C_AAAI},
  author    = {Wentao Cui and Liang Bai},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25887},
  pages     = {7279-7287},
  title     = {Contrastive learning with the feature reconstruction amplifier},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Opposite online learning via sequentially integrated
stochastic gradient descent estimators. <em>AAAI</em>, 7270–7278. (<a
href="https://doi.org/10.1609/aaai.v37i6.25886">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Stochastic gradient descent algorithm (SGD) has been popular in various fields of artificial intelligence as well as a prototype of online learning algorithms. This article proposes a novel and general framework of one-sided testing for streaming data based on SGD, which determines whether the unknown parameter is greater than a certain positive constant. We construct the online-updated test statistic sequentially by integrating the selected batch-specific estimator or its opposite, which is referred to opposite online learning. The batch-specific online estimators are chosen strategically according to the proposed sequential tactics designed by two-armed bandit process. Theoretical results prove the advantage of the strategy ensuring the distribution of test statistic to be optimal under the null hypothesis and also supply the theoretical evidence of power enhancement compared with classical test statistic. In application, the proposed method is appealing for statistical inference of one-sided testing because it is scalable for any model. Finally, the superior finite-sample performance is evaluated by simulation studies.},
  archive   = {C_AAAI},
  author    = {Wenhai Cui and Xiaoting Ji and Linglong Kong and Xiaodong Yan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25886},
  pages     = {7270-7278},
  title     = {Opposite online learning via sequentially integrated stochastic gradient descent estimators},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Practical parallel algorithms for submodular maximization
subject to a knapsack constraint with nearly optimal adaptivity.
<em>AAAI</em>, 7261–7269. (<a
href="https://doi.org/10.1609/aaai.v37i6.25885">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Submodular maximization has wide applications in machine learning and data mining, where massive datasets have brought the great need for designing efficient and parallelizable algorithms. One measure of the parallelizability of a submodular maximization algorithm is its adaptivity complexity, which indicates the number of sequential rounds where a polynomial number of queries to the objective function can be executed in parallel. In this paper, we study the problem of non-monotone submodular maximization subject to a knapsack constraint, and propose the first combinatorial algorithm achieving an (8+epsilon)-approximation under O(log n) adaptive complexity, which is optimal up to a factor of O(loglog n). Moreover, under slightly larger adaptivity, we also propose approximation algorithms with nearly optimal query complexity of O(n), while achieving better approximation ratios. We show that our algorithms can also be applied to the special case of submodular maximization subject to a cardinality constraint, and achieve performance bounds comparable with those of state-of-the-art algorithms. Finally, the effectiveness of our approach is demonstrated by extensive experiments on real-world applications.},
  archive   = {C_AAAI},
  author    = {Shuang Cui and Kai Han and Jing Tang and He Huang and Xueying Li and Aakas Zhiyuli},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25885},
  pages     = {7261-7269},
  title     = {Practical parallel algorithms for submodular maximization subject to a knapsack constraint with nearly optimal adaptivity},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). End-to-end learning for optimization via
constraint-enforcing approximators. <em>AAAI</em>, 7253–7260. (<a
href="https://doi.org/10.1609/aaai.v37i6.25884">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In many real-world applications, predictive methods are used to provide inputs for downstream optimization problems. It has been shown that using the downstream task-based objective to learn the intermediate predictive model is often better than using only intermediate task objectives, such as prediction error. The learning task in the former approach is referred to as end-to-end learning. The difficulty in end-to-end learning lies in differentiating through the optimization problem. Therefore, we propose a neural network architecture that can learn to approximately solve these optimization problems, particularly ensuring its output satisfies the feasibility constraints via alternate projections. We show these projections converge at a geometric rate to the exact projection. Our approach is more computationally efficient than existing methods as we do not need to solve the original optimization problem at each iteration. Furthermore, our approach can be applied to a wider range of optimization problems. We apply this to a shortest path problem for which the first stage forecasting problem is a computer vision task of predicting edge costs from terrain maps, a capacitated multi-product newsvendor problem, and a maximum matching problem. We show that this method out-performs existing approaches in terms of final task-based loss and training time.},
  archive   = {C_AAAI},
  author    = {Rares Cristian and Pavithra Harsha and Georgia Perakis and Brian L Quanz and Ioannis Spantidakis},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25884},
  pages     = {7253-7260},
  title     = {End-to-end learning for optimization via constraint-enforcing approximators},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Continuous mixtures of tractable probabilistic models.
<em>AAAI</em>, 7244–7252. (<a
href="https://doi.org/10.1609/aaai.v37i6.25883">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Probabilistic models based on continuous latent spaces, such as variational autoencoders, can be understood as uncountable mixture models where components depend continuously on the latent code. They have proven to be expressive tools for generative and probabilistic modelling, but are at odds with tractable probabilistic inference, that is, computing marginals and conditionals of the represented probability distribution. Meanwhile, tractable probabilistic models such as probabilistic circuits (PCs) can be understood as hierarchical discrete mixture models, and thus are capable of performing exact inference efficiently but often show subpar performance in comparison to continuous latent-space models. In this paper, we investigate a hybrid approach, namely continuous mixtures of tractable models with a small latent dimension. While these models are analytically intractable, they are well amenable to numerical integration schemes based on a finite set of integration points. With a large enough number of integration points the approximation becomes de-facto exact. Moreover, for a finite set of integration points, the integration method effectively compiles the continuous mixture into a standard PC. In experiments, we show that this simple scheme proves remarkably effective, as PCs learnt this way set new state of the art for tractable models on many standard density estimation benchmarks.},
  archive   = {C_AAAI},
  author    = {Alvaro H.C. Correia and Gennaro Gala and Erik Quaeghebeur and Cassio de Campos and Robert Peharz},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25883},
  pages     = {7244-7252},
  title     = {Continuous mixtures of tractable probabilistic models},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Tricking the hashing trick: A tight lower bound on the
robustness of CountSketch to adaptive inputs. <em>AAAI</em>, 7235–7243.
(<a href="https://doi.org/10.1609/aaai.v37i6.25882">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {CountSketch and Feature Hashing (the ``hashing trick&#39;&#39;) are popular randomized dimensionality reduction methods that support recovery of l2 -heavy hitters and approximate inner products. When the inputs are not adaptive (do not depend on prior outputs), classic estimators applied to a sketch of size O(l / epsilon) are accurate for a number of queries that is exponential in l. When inputs are adaptive, however, an adversarial input can be constructed after O(l) queries with the classic estimator and the best known robust estimator only supports ~O(l^2) queries. In this work we show that this quadratic dependence is in a sense inherent: We design an attack that after O(l^2) queries produces an adversarial input vector whose sketch is highly biased. Our attack uses ``natural&#39;&#39; non-adaptive inputs (only the final adversarial input is chosen adaptively) and universally applies with any correct estimator, including one that is unknown to the attacker. In that, we expose inherent vulnerability of this fundamental method.},
  archive   = {C_AAAI},
  author    = {Edith Cohen and Jelani Nelson and Tamas Sarlos and Uri Stemmer},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25882},
  pages     = {7235-7243},
  title     = {Tricking the hashing trick: A tight lower bound on the robustness of CountSketch to adaptive inputs},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploiting multiple abstractions in episodic RL via reward
shaping. <em>AAAI</em>, 7227–7234. (<a
href="https://doi.org/10.1609/aaai.v37i6.25881">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {One major limitation to the applicability of Reinforcement Learning (RL) to many practical domains is the large number of samples required to learn an optimal policy. To address this problem and improve learning efficiency, we consider a linear hierarchy of abstraction layers of the Markov Decision Process (MDP) underlying the target domain. Each layer is an MDP representing a coarser model of the one immediately below in the hierarchy. In this work, we propose a novel form of Reward Shaping where the solution obtained at the abstract level is used to offer rewards to the more concrete MDP, in such a way that the abstract solution guides the learning in the more complex domain. In contrast with other works in Hierarchical RL, our technique has few requirements in the design of the abstract models and it is also tolerant to modeling errors, thus making the proposed approach practical. We formally analyze the relationship between the abstract models and the exploration heuristic induced in the lower-level domain. Moreover, we prove that the method guarantees optimal convergence and we demonstrate its effectiveness experimentally.},
  archive   = {C_AAAI},
  author    = {Roberto Cipollone and Giuseppe De Giacomo and Marco Favorito and Luca Iocchi and Fabio Patrizi},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25881},
  pages     = {7227-7234},
  title     = {Exploiting multiple abstractions in episodic RL via reward shaping},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Scalable spatiotemporal graph neural networks.
<em>AAAI</em>, 7218–7226. (<a
href="https://doi.org/10.1609/aaai.v37i6.25880">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Neural forecasting of spatiotemporal time series drives both research and industrial innovation in several relevant application domains. Graph neural networks (GNNs) are often the core component of the forecasting architecture. However, in most spatiotemporal GNNs, the computational complexity scales up to a quadratic factor with the length of the sequence times the number of links in the graph, hence hindering the application of these models to large graphs and long temporal sequences. While methods to improve scalability have been proposed in the context of static graphs, few research efforts have been devoted to the spatiotemporal case. To fill this gap, we propose a scalable architecture that exploits an efficient encoding of both temporal and spatial dynamics. In particular, we use a randomized recurrent neural network to embed the history of the input time series into high-dimensional state representations encompassing multi-scale temporal dynamics. Such representations are then propagated along the spatial dimension using different powers of the graph adjacency matrix to generate node embeddings characterized by a rich pool of spatiotemporal features. The resulting node embeddings can be efficiently pre-computed in an unsupervised manner, before being fed to a feed-forward decoder that learns to map the multi-scale spatiotemporal representations to predictions. The training procedure can then be parallelized node-wise by sampling the node embeddings without breaking any dependency, thus enabling scalability to large networks. Empirical results on relevant datasets show that our approach achieves results competitive with the state of the art, while dramatically reducing the computational burden.},
  archive   = {C_AAAI},
  author    = {Andrea Cini and Ivan Marisca and Filippo Maria Bianchi and Cesare Alippi},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25880},
  pages     = {7218-7226},
  title     = {Scalable spatiotemporal graph neural networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Can bad teaching induce forgetting? Unlearning in deep
networks using an incompetent teacher. <em>AAAI</em>, 7210–7217. (<a
href="https://doi.org/10.1609/aaai.v37i6.25879">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Machine unlearning has become an important area of research due to an increasing need for machine learning (ML) applications to comply with the emerging data privacy regulations. It facilitates the provision for removal of certain set or class of data from an already trained ML model without requiring retraining from scratch. Recently, several efforts have been put in to make unlearning to be effective and efficient. We propose a novel machine unlearning method by exploring the utility of competent and incompetent teachers in a student-teacher framework to induce forgetfulness. The knowledge from the competent and incompetent teachers is selectively transferred to the student to obtain a model that doesn&#39;t contain any information about the forget data. We experimentally show that this method generalizes well, is fast and effective. Furthermore, we introduce the zero retrain forgetting (ZRF) metric to evaluate any unlearning method. Unlike the existing unlearning metrics, the ZRF score does not depend on the availability of the expensive retrained model. This makes it useful for analysis of the unlearned model after deployment as well. We present results of experiments conducted for random subset forgetting and class forgetting on various deep networks and across different application domains. Code is at: https://github.com/vikram2000b/bad-teaching- unlearning},
  archive   = {C_AAAI},
  author    = {Vikram S Chundawat and Ayush K Tarun and Murari Mandal and Mohan Kankanhalli},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25879},
  pages     = {7210-7217},
  title     = {Can bad teaching induce forgetting? unlearning in deep networks using an incompetent teacher},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On the complexity of PAC learning in hilbert spaces.
<em>AAAI</em>, 7202–7209. (<a
href="https://doi.org/10.1609/aaai.v37i6.25878">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the problem of binary classification from the point of view of learning convex polyhedra in Hilbert spaces, to which one can reduce any binary classification problem. The problem of learning convex polyhedra in finite-dimensional spaces is sufficiently well studied in the literature. We generalize this problem to that in a Hilbert space and propose an algorithm for learning a polyhedron which correctly classifies at least 1 − ε of the distribution, with a probability of at least 1 − δ, where ε and δ are given parameters. Also, as a corollary, we improve some previous bounds for polyhedral classification in finite-dimensional spaces.},
  archive   = {C_AAAI},
  author    = {Sergei Chubanov},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25878},
  pages     = {7202-7209},
  title     = {On the complexity of PAC learning in hilbert spaces},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Structured BFGS method for optimal doubly stochastic matrix
approximation. <em>AAAI</em>, 7193–7201. (<a
href="https://doi.org/10.1609/aaai.v37i6.25877">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Doubly stochastic matrix plays an essential role in several areas such as statistics and machine learning. In this paper we consider the optimal approximation of a square matrix in the set of doubly stochastic matrices. A structured BFGS method is proposed to solve the dual of the primal problem. The resulting algorithm builds curvature information into the diagonal components of the true Hessian, so that it takes only additional linear cost to obtain the descent direction based on the gradient information without having to explicitly store the inverse Hessian approximation. The cost is substantially fewer than quadratic complexity of the classical BFGS algorithm. Meanwhile, a Newton-based line search method is presented for finding a suitable step size, which in practice uses the existing knowledge and takes only one iteration. The global convergence of our algorithm is established. We verify the advantages of our approach on both synthetic data and real data sets. The experimental results demonstrate that our algorithm outperforms the state-of-the-art solvers and enjoys outstanding scalability.},
  archive   = {C_AAAI},
  author    = {Dejun Chu and Changshui Zhang and Shiliang Sun and Qing Tao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25877},
  pages     = {7193-7201},
  title     = {Structured BFGS method for optimal doubly stochastic matrix approximation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PrimeNet: Pre-training for irregular multivariate time
series. <em>AAAI</em>, 7184–7192. (<a
href="https://doi.org/10.1609/aaai.v37i6.25876">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Real-world applications often involve irregular time series, for which the time intervals between successive observations are non-uniform. Irregularity across multiple features in a multi-variate time series further results in a different subset of features at any given time (i.e., asynchronicity). Existing pre-training schemes for time-series, however, often assume regularity of time series and make no special treatment of irregularity. We argue that such irregularity offers insight about domain property of the data—for example, frequency of hospital visits may signal patient health condition—that can guide representation learning. In this work, we propose PrimeNet to learn a self-supervised representation for irregular multivariate time-series. Specifically, we design a time sensitive contrastive learning and data reconstruction task to pre-train a model. Irregular time-series exhibits considerable variations in sampling density over time. Hence, our triplet generation strategy follows the density of the original data points, preserving its native irregularity. Moreover, the sampling density variation over time makes data reconstruction difficult for different regions. Therefore, we design a data masking technique that always masks a constant time duration to accommodate reconstruction for regions of different sampling density. We learn with these tasks using unlabeled data to build a pre-trained model and fine-tune on a downstream task with limited labeled data, in contrast with existing fully supervised approach for irregular time-series, requiring large amounts of labeled data. Experiment results show that PrimeNet significantly outperforms state-of-the-art methods on naturally irregular and asynchronous data from Healthcare and IoT applications for several downstream tasks, including classification, interpolation, and regression.},
  archive   = {C_AAAI},
  author    = {Ranak Roy Chowdhury and Jiacheng Li and Xiyuan Zhang and Dezhi Hong and Rajesh K. Gupta and Jingbo Shang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25876},
  pages     = {7184-7192},
  title     = {PrimeNet: Pre-training for irregular multivariate time series},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning optimal features via partial invariance.
<em>AAAI</em>, 7175–7183. (<a
href="https://doi.org/10.1609/aaai.v37i6.25875">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Learning models that are robust to distribution shifts is a key concern in the context of their real-life applicability. Invariant Risk Minimization (IRM) is a popular framework that aims to learn robust models from multiple environments. The success of IRM requires an important assumption: the underlying causal mechanisms/features remain invariant across environments. When not satisfied, we show that IRM can over-constrain the predictor and to remedy this, we propose a relaxation via partial invariance. In this work, we theoretically highlight the sub-optimality of IRM and then demonstrate how learning from a partition of training domains can help improve invariant models. Several experiments, conducted both in linear settings as well as with deep neural networks on tasks over both language and image data, allow us to verify our conclusions.},
  archive   = {C_AAAI},
  author    = {Moulik Choraria and Ibtihal Ferwana and Ankur Mani and Lav R. Varshney},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25875},
  pages     = {7175-7183},
  title     = {Learning optimal features via partial invariance},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MobileTL: On-device transfer learning with inverted residual
blocks. <em>AAAI</em>, 7166–7174. (<a
href="https://doi.org/10.1609/aaai.v37i6.25874">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Transfer learning on edge is challenging due to on-device limited resources. Existing work addresses this issue by training a subset of parameters or adding model patches. Developed with inference in mind, Inverted Residual Blocks (IRBs) split a convolutional layer into depthwise and pointwise convolutions, leading to more stacking layers, e.g., convolution, normalization, and activation layers. Though they are efficient for inference, IRBs require that additional activation maps are stored in memory for training weights for convolution layers and scales for normalization layers. As a result, their high memory cost prohibits training IRBs on resource-limited edge devices, and making them unsuitable in the context of transfer learning. To address this issue, we present MobileTL, a memory and computationally efficient on-device transfer learning method for models built with IRBs. MobileTL trains the shifts for internal normalization layers to avoid storing activation maps for the backward pass. Also, MobileTL approximates the backward computation of the activation layer (e.g., Hard-Swish and ReLU6) as a signed function which enables storing a binary mask instead of activation maps for the backward pass. MobileTL fine-tunes a few top blocks (close to output) rather than propagating the gradient through the whole network to reduce the computation cost. Our method reduces memory usage by 46\% and 53\% for MobileNetV2 and V3 IRBs, respectively. For MobileNetV3, we observe a 36\% reduction in floating-point operations (FLOPs) when fine-tuning 5 blocks, while only incurring a 0.6\% accuracy reduction on CIFAR10. Extensive experiments on multiple datasets demonstrate that our method is Pareto-optimal (best accuracy under given hardware constraints) compared to prior work in transfer learning for edge devices.},
  archive   = {C_AAAI},
  author    = {Hung-Yueh Chiang and Natalia Frumkin and Feng Liang and Diana Marculescu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25874},
  pages     = {7166-7174},
  title     = {MobileTL: On-device transfer learning with inverted residual blocks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Variational wasserstein barycenters with c-cyclical
monotonicity regularization. <em>AAAI</em>, 7157–7165. (<a
href="https://doi.org/10.1609/aaai.v37i6.25873">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Wasserstein barycenter, built on the theory of Optimal Transport (OT), provides a powerful framework to aggregate probability distributions, and it has increasingly attracted great attention within the machine learning community. However, it is often intractable to precisely compute, especially for high dimensional and continuous settings. To alleviate this problem, we develop a novel regularization by using the fact that c-cyclical monotonicity is often necessary and sufficient conditions for optimality in OT problems, and incorporate it into the dual formulation of Wasserstein barycenters. For efficient computations, we adopt a variational distribution as the approximation of the true continuous barycenter, so as to frame the Wasserstein barycenters problem as an optimization problem with respect to variational parameters. Upon those ideas, we propose a novel end-to-end continuous approximation method, namely Variational Wasserstein Barycenters with c-Cyclical Monotonicity Regularization (VWB-CMR), given sample access to the input distributions. We show theoretical convergence analysis and demonstrate the superior performance of VWB-CMR on synthetic data and real applications of subset posterior aggregation.},
  archive   = {C_AAAI},
  author    = {Jinjin Chi and Zhiyao Yang and Ximing Li and Jihong Ouyang and Renchu Guan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25873},
  pages     = {7157-7165},
  title     = {Variational wasserstein barycenters with C-cyclical monotonicity regularization},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Offline quantum reinforcement learning in a conservative
manner. <em>AAAI</em>, 7148–7156. (<a
href="https://doi.org/10.1609/aaai.v37i6.25872">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, to reap the quantum advantage, empowering reinforcement learning (RL) with quantum computing has attracted much attention, which is dubbed as quantum RL (QRL). However, current QRL algorithms employ an online learning scheme, i.e., the policy that is run on a quantum computer needs to interact with the environment to collect experiences, which could be expensive and dangerous for practical applications. In this paper, we aim to solve this problem in an offline learning manner. To be more specific, we develop the first offline quantum RL (offline QRL) algorithm named CQ2L (Conservative Quantum Q-learning), which learns from offline samples and does not require any interaction with the environment. CQ2L utilizes variational quantum circuits (VQCs), which are improved with data re-uploading and scaling parameters, to represent Q-value functions of agents. To suppress the overestimation of Q-values resulting from offline data, we first employ a double Q-learning framework to reduce the overestimation bias; then a penalty term that encourages generating conservative Q-values is designed. We conduct abundant experiments to demonstrate that the proposed method CQ2L can successfully solve offline QRL tasks that the online counterpart could not.},
  archive   = {C_AAAI},
  author    = {Zhihao Cheng and Kaining Zhang and Li Shen and Dacheng Tao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25872},
  pages     = {7148-7156},
  title     = {Offline quantum reinforcement learning in a conservative manner},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Partial-label regression. <em>AAAI</em>, 7140–7147. (<a
href="https://doi.org/10.1609/aaai.v37i6.25871">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Partial-label learning is a popular weakly supervised learning setting that allows each training example to be annotated with a set of candidate labels. Previous studies on partial-label learning only focused on the classification setting where candidate labels are all discrete, which cannot handle continuous labels with real values. In this paper, we provide the first attempt to investigate partial-label regression, where each training example is annotated with a set of real-valued candidate labels. To solve this problem, we first propose a simple baseline method that takes the average loss incurred by candidate labels as the predictive loss. The drawback of this method lies in that the loss incurred by the true label may be overwhelmed by other false labels. To overcome this drawback, we propose an identification method that takes the least loss incurred by candidate labels as the predictive loss. We further improve it by proposing a progressive identification method to differentiate candidate labels using progressively updated weights for incurred losses. We prove that the latter two methods are model-consistent and provide convergence analysis showing the optimal parametric convergence rate. Our proposed methods are theoretically grounded and can be compatible with any models, optimizers, and losses. Experiments validate the effectiveness of our proposed methods.},
  archive   = {C_AAAI},
  author    = {Xin Cheng and Deng-Bao Wang and Lei Feng and Min-Ling Zhang and Bo An},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25871},
  pages     = {7140-7147},
  title     = {Partial-label regression},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Wiener graph deconvolutional network improves graph
self-supervised learning. <em>AAAI</em>, 7131–7139. (<a
href="https://doi.org/10.1609/aaai.v37i6.25870">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph self-supervised learning (SSL) has been vastly employed to learn representations from unlabeled graphs. Existing methods can be roughly divided into predictive learning and contrastive learning, where the latter one attracts more research attention with better empirical performance. We argue that, however, predictive models weaponed with powerful decoder could achieve comparable or even better representation power than contrastive models. In this work, we propose a Wiener Graph Deconvolutional Network (WGDN), an augmentation-adaptive decoder empowered by graph wiener filter to perform information reconstruction. Theoretical analysis proves the superior reconstruction ability of graph wiener filter. Extensive experimental results on various datasets demonstrate the effectiveness of our approach.},
  archive   = {C_AAAI},
  author    = {Jiashun Cheng and Man Li and Jia Li and Fugee Tsung},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25870},
  pages     = {7131-7139},
  title     = {Wiener graph deconvolutional network improves graph self-supervised learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Causal inference with conditional instruments using deep
generative models. <em>AAAI</em>, 7122–7130. (<a
href="https://doi.org/10.1609/aaai.v37i6.25869">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The instrumental variable (IV) approach is a widely used way to estimate the causal effects of a treatment on an outcome of interest from observational data with latent confounders. A standard IV is expected to be related to the treatment variable and independent of all other variables in the system. However, it is challenging to search for a standard IV from data directly due to the strict conditions. The conditional IV (CIV) method has been proposed to allow a variable to be an instrument conditioning on a set of variables, allowing a wider choice of possible IVs and enabling broader practical applications of the IV approach. Nevertheless, there is not a data-driven method to discover a CIV and its conditioning set directly from data. To fill this gap, in this paper, we propose to learn the representations of the information of a CIV and its conditioning set from data with latent confounders for average causal effect estimation. By taking advantage of deep generative models, we develop a novel data-driven approach for simultaneously learning the representation of a CIV from measured variables and generating the representation of its conditioning set given measured variables. Extensive experiments on synthetic and real-world datasets show that our method outperforms the existing IV methods.},
  archive   = {C_AAAI},
  author    = {Debo Cheng and Ziqi Xu and Jiuyong Li and Lin Liu and Jixue Liu and Thuc Duy Le},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25869},
  pages     = {7122-7130},
  title     = {Causal inference with conditional instruments using deep generative models},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TC-DWA: Text clustering with dual word-level augmentation.
<em>AAAI</em>, 7113–7121. (<a
href="https://doi.org/10.1609/aaai.v37i6.25868">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The pre-trained language models, e.g., ELMo and BERT, have recently achieved promising performance improvement in a wide range of NLP tasks, because they can output strong contextualized embedded features of words. Inspired by their great success, in this paper we target at fine-tuning them to effectively handle the text clustering task, i.e., a classic and fundamental challenge in machine learning. Accordingly, we propose a novel BERT-based method, namely Text Clustering with Dual Word-level Augmentation (TCDWA). To be specific, we formulate a self-training objective and enhance it with a dual word-level augmentation technique. First, we suppose that each text contains several most informative words, called anchor words, supporting the full text semantics. We use the embedded features of anchor words as augmented data, which are selected by ranking the norm-based attention weights of words. Second, we formulate an expectation form of word augmentation, which is equivalent to generating infinite augmented features, and further suggest a tractable approximation of Taylor expansion for efficient optimization. To evaluate the effectiveness of TCDWA, we conduct extensive experiments on several benchmark text datasets. The results demonstrate that TCDWA consistently outperforms the state-of-the-art baseline methods. Code available: https://github.com/BoCheng-96/TC-DWA.},
  archive   = {C_AAAI},
  author    = {Bo Cheng and Ximing Li and Yi Chang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25868},
  pages     = {7113-7121},
  title     = {TC-DWA: Text clustering with dual word-level augmentation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). Riemannian local mechanism for SPD neural networks.
<em>AAAI</em>, 7104–7112. (<a
href="https://doi.org/10.1609/aaai.v37i6.25867">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Symmetric Positive Definite (SPD) matrices have received wide attention for data representation in many scientific areas. Although there are many different attempts to develop effective deep architectures for data processing on the Riemannian manifold of SPD matrices, very few solutions explicitly mine the local geometrical information in deep SPD feature representations. Given the great success of local mechanisms in Euclidean methods, we argue that it is of utmost importance to ensure the preservation of local geometric information in the SPD networks. We first analyse the convolution operator commonly used for capturing local information in Euclidean deep networks from the perspective of a higher level of abstraction afforded by category theory. Based on this analysis, we define the local information in the SPD manifold and design a multi-scale submanifold block for mining local geometry. Experiments involving multiple visual tasks validate the effectiveness of our approach.},
  archive   = {C_AAAI},
  author    = {Ziheng Chen and Tianyang Xu and Xiao-Jun Wu and Rui Wang and Zhiwu Huang and Josef Kittler},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25867},
  pages     = {7104-7112},
  title     = {Riemannian local mechanism for SPD neural networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Topological pooling on graphs. <em>AAAI</em>, 7096–7103. (<a
href="https://doi.org/10.1609/aaai.v37i6.25866">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph neural networks (GNNs) have demonstrated a significant success in various graph learning tasks, from graph classification to anomaly detection. There recently has emerged a number of approaches adopting a graph pooling operation within GNNs, with a goal to preserve graph attributive and structural features during the graph representation learning. However, most existing graph pooling operations suffer from the limitations of relying on node-wise neighbor weighting and embedding, which leads to insufficient encoding of rich topological structures and node attributes exhibited by real-world networks. By invoking the machinery of persistent homology and the concept of landmarks, we propose a novel topological pooling layer and witness complex-based topological embedding mechanism that allow us to systematically integrate hidden topological information at both local and global levels. Specifically, we design new learnable local and global topological representations Wit-TopoPool which allow us to simultaneously extract rich discriminative topological information from graphs. Experiments on 11 diverse benchmark datasets against 18 baseline models in conjunction with graph classification tasks indicate that Wit-TopoPool significantly outperforms all competitors across all datasets.},
  archive   = {C_AAAI},
  author    = {Yuzhou Chen and Yulia R. Gel},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25866},
  pages     = {7096-7103},
  title     = {Topological pooling on graphs},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Global convergence of two-timescale actor-critic for solving
linear quadratic regulator. <em>AAAI</em>, 7087–7095. (<a
href="https://doi.org/10.1609/aaai.v37i6.25865">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The actor-critic (AC) reinforcement learning algorithms have been the powerhouse behind many challenging applications. Nevertheless, its convergence is fragile in general. To study its instability, existing works mostly consider the uncommon double-loop variant or basic models with finite state and action space. We investigate the more practical single-sample two-timescale AC for solving the canonical linear quadratic regulator (LQR) problem, where the actor and the critic update only once with a single sample in each iteration on an unbounded continuous state and action space. Existing analysis cannot conclude the convergence for such a challenging case. We develop a new analysis framework that allows establishing the global convergence to an epsilon-optimal solution with at most an order of epsilon to -2.5 sample complexity. To our knowledge, this is the first finite-time convergence analysis for the single sample two-timescale AC for solving LQR with global optimality. The sample complexity improves those of other variants by orders, which sheds light on the practical wisdom of single sample algorithms. We also further validate our theoretical findings via comprehensive simulation comparisons.},
  archive   = {C_AAAI},
  author    = {Xuyang Chen and Jingliang Duan and Yingbin Liang and Lin Zhao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25865},
  pages     = {7087-7095},
  title     = {Global convergence of two-timescale actor-critic for solving linear quadratic regulator},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The sufficiency of off-policyness and soft clipping: PPO is
still insufficient according to an off-policy measure. <em>AAAI</em>,
7078–7086. (<a href="https://doi.org/10.1609/aaai.v37i6.25864">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The popular Proximal Policy Optimization (PPO) algorithm approximates the solution in a clipped policy space. Does there exist better policies outside of this space? By using a novel surrogate objective that employs the sigmoid function (which provides an interesting way of exploration), we found that the answer is &quot;YES&quot;, and the better policies are in fact located very far from the clipped space. We show that PPO is insufficient in &quot;off-policyness&quot;, according to an off-policy metric called DEON. Our algorithm explores in a much larger policy space than PPO, and it maximizes the Conservative Policy Iteration (CPI) objective better than PPO during training. To the best of our knowledge, all current PPO methods have the clipping operation and optimize in the clipped policy space. Our method is the first of this kind, which advances the understanding of CPI optimization and policy gradient methods. Code is available at https://github.com/raincchio/P3O.},
  archive   = {C_AAAI},
  author    = {Xing Chen and Dongcui Diao and Hechang Chen and Hengshuai Yao and Haiyin Piao and Zhixiao Sun and Zhiwei Yang and Randy Goebel and Bei Jiang and Yi Chang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25864},
  pages     = {7078-7086},
  title     = {The sufficiency of off-policyness and soft clipping: PPO is still insufficient according to an off-policy measure},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Supervised contrastive few-shot learning for high-frequency
time series. <em>AAAI</em>, 7069–7077. (<a
href="https://doi.org/10.1609/aaai.v37i6.25863">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Significant progress has been made in representation learning, especially with recent success on self-supervised contrastive learning. However, for time series with less intuitive or semantic meaning, sampling bias may be inevitably encountered in unsupervised approaches. Although supervised contrastive learning has shown superior performance by leveraging label information, it may also suffer from class collapse. In this study, we consider a realistic scenario in industry with limited annotation information available. A supervised contrastive framework is developed for high-frequency time series representation and classification, wherein a novel variant of supervised contrastive loss is proposed to include multiple augmentations while induce spread within each class. Experiments on four mainstream public datasets as well as a series of sensitivity and ablation analyses demonstrate that the learned representations are effective and robust compared with the direct supervised learning and self-supervised learning, notably under the minimal few-shot situation.},
  archive   = {C_AAAI},
  author    = {Xi Chen and Cheng Ge and Ming Wang and Jin Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25863},
  pages     = {7069-7077},
  title     = {Supervised contrastive few-shot learning for high-frequency time series},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Min-max submodular ranking for multiple agents.
<em>AAAI</em>, 7061–7068. (<a
href="https://doi.org/10.1609/aaai.v37i6.25862">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the submodular ranking (SR) problem, the input consists of a set of submodular functions defined on a ground set of elements. The goal is to order elements for all the functions to have value above a certain threshold as soon on average as possible, assuming we choose one element per time. The problem is flexible enough to capture various applications in machine learning, including decision trees. This paper considers the min-max version of SR where multiple instances share the ground set. With the view of each instance being associated with an agent, the min-max problem is to order the common elements to minimize the maximum objective of all agents---thus, finding a fair solution for all agents. We give approximation algorithms for this problem and demonstrate their effectiveness in the application of finding a decision tree for multiple agents.},
  archive   = {C_AAAI},
  author    = {Qingyun Chen and Sungjin Im and Benjamin Moseley and Chenyang Xu and Ruilong Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25862},
  pages     = {7061-7068},
  title     = {Min-max submodular ranking for multiple agents},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Context-aware safe medication recommendations with
molecular graph and DDI graph embedding. <em>AAAI</em>, 7053–7060. (<a
href="https://doi.org/10.1609/aaai.v37i6.25861">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Molecular structures and Drug-Drug Interactions (DDI) are recognized as important knowledge to guide medication recommendation (MR) tasks, and medical concept embedding has been applied to boost their performance. Though promising performance has been achieved by leveraging Graph Neural Network (GNN) models to encode the molecular structures of medications or/and DDI, we observe that existing models are still defective: 1) to differentiate medications with similar molecules but different functionality; or/and 2) to properly capture the unintended reactions between drugs in the embedding space. To alleviate this limitation, we propose Carmen, a cautiously designed graph embedding-based MR framework. Carmen consists of four components, including patient representation learning, context information extraction, a context-aware GNN, and DDI encoding. Carmen incorporates the visit history into the representation learning of molecular graphs to distinguish molecules with similar topology but dissimilar activity. Its DDI encoding module is specially devised for the non-transitive interaction DDI graphs. The experiments on real-world datasets demonstrate that Carmen achieves remarkable performance improvement over state-of-the-art models and can improve the safety of recommended drugs with a proper DDI graph encoding.},
  archive   = {C_AAAI},
  author    = {Qianyu Chen and Xin Li and Kunnan Geng and Mingzhong Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25861},
  pages     = {7053-7060},
  title     = {Context-aware safe medication recommendations with molecular graph and DDI graph embedding},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CF-ViT: A general coarse-to-fine method for vision
transformer. <em>AAAI</em>, 7042–7052. (<a
href="https://doi.org/10.1609/aaai.v37i6.25860">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Vision Transformers (ViT) have made many breakthroughs in computer vision tasks. However, considerable redundancy arises in the spatial dimension of an input image, leading to massive computational costs. Therefore, We propose a coarse-to-fine vision transformer (CF-ViT) to relieve computational burden while retaining performance in this paper. Our proposed CF-ViT is motivated by two important observations in modern ViT models: (1) The coarse-grained patch splitting can locate informative regions of an input image. (2) Most images can be well recognized by a ViT model in a small-length token sequence. Therefore, our CF-ViT implements network inference in a two-stage manner. At coarse inference stage, an input image is split into a small-length patch sequence for a computationally economical classification. If not well recognized, the informative patches are identified and further re-split in a fine-grained granularity. Extensive experiments demonstrate the efficacy of our CF-ViT. For example, without any compromise on performance, CF-ViT reduces 53\% FLOPs of LV-ViT, and also achieves 2.01x throughput. Code of this project is at https://github.com/ChenMnZ/CF-V},
  archive   = {C_AAAI},
  author    = {Mengzhao Chen and Mingbao Lin and Ke Li and Yunhang Shen and Yongjian Wu and Fei Chao and Rongrong Ji},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25860},
  pages     = {7042-7052},
  title     = {CF-ViT: A general coarse-to-fine method for vision transformer},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). On the stability and generalization of triplet learning.
<em>AAAI</em>, 7033–7041. (<a
href="https://doi.org/10.1609/aaai.v37i6.25859">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Triplet learning, i.e. learning from triplet data, has attracted much attention in computer vision tasks with an extremely large number of categories, e.g., face recognition and person re-identification. Albeit with rapid progress in designing and applying triplet learning algorithms, there is a lacking study on the theoretical understanding of their generalization performance. To fill this gap, this paper investigates the generalization guarantees of triplet learning by leveraging the stability analysis. Specifically, we establish the first general high-probability generalization bound for the triplet learning algorithm satisfying the uniform stability, and then obtain the excess risk bounds of the order O(log(n)/(√n) ) for both stochastic gradient descent (SGD) and regularized risk minimization (RRM), where 2n is approximately equal to the number of training samples. Moreover, an optimistic generalization bound in expectation as fast as O(1/n) is derived for RRM in a low noise case via the on-average stability analysis. Finally, our results are applied to triplet metric learning to characterize its theoretical underpinning.},
  archive   = {C_AAAI},
  author    = {Jun Chen and Hong Chen and Xue Jiang and Bin Gu and Weifu Li and Tieliang Gong and Feng Zheng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25859},
  pages     = {7033-7041},
  title     = {On the stability and generalization of triplet learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Attribute and structure preserving graph contrastive
learning. <em>AAAI</em>, 7024–7032. (<a
href="https://doi.org/10.1609/aaai.v37i6.25858">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph Contrastive Learning (GCL) has drawn much research interest due to its strong ability to capture both graph structure and node attribute information in a self-supervised manner. Current GCL methods usually adopt Graph Neural Networks (GNNs) as the base encoder, which typically relies on the homophily assumption of networks and overlooks node similarity in the attribute space. There are many scenarios where such assumption cannot be satisfied, or node similarity plays a crucial role. In order to design a more robust mechanism, we develop a novel attribute and structure preserving graph contrastive learning framework, named ASP, which comprehensively and efficiently preserves node attributes while exploiting graph structure. Specifically, we consider three different graph views in our framework, i.e., original view, attribute view, and global structure view. Then, we perform contrastive learning across three views in a joint fashion, mining comprehensive graph information. We validate the effectiveness of the proposed framework on various real-world networks with different levels of homophily. The results demonstrate the superior performance of our model over the representative baselines.},
  archive   = {C_AAAI},
  author    = {Jialu Chen and Gang Kou},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25858},
  pages     = {7024-7032},
  title     = {Attribute and structure preserving graph contrastive learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Scalable and globally optimal generalized l₁ k-center
clustering via constraint generation in mixed integer linear
programming. <em>AAAI</em>, 7015–7023. (<a
href="https://doi.org/10.1609/aaai.v37i6.25857">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The k-center clustering algorithm, introduced over 35 years ago, is known to be robust to class imbalance prevalent in many clustering problems and has various applications such as data summarization, document clustering, and facility location determination. Unfortunately, existing k-center algorithms provide highly suboptimal solutions that can limit their practical application, reproducibility, and clustering quality. In this paper, we provide a novel scalable and globally optimal solution to a popular variant of the k-center problem known as generalized L_1 k-center clustering that uses L_1 distance and allows the selection of arbitrary vectors as cluster centers. We show that this clustering objective can be reduced to a mixed-integer linear program (MILP) that facilitates globally optimal clustering solutions. However, solving such a MILP may be intractable for large datasets; to remedy this, we present a scalable algorithm that leverages constraint generation to efficiently and provably converge to its global optimum. We further enhance outlier handling through a simple but elegant extension to our MILP objective. We first evaluate our algorithm on a variety of synthetic datasets to better understand its properties and then validate on 20 real benchmark datasets where we compare its performance to both traditional L_1 distance k-center and k-medians baselines. Our results demonstrate significant suboptimality of existing algorithms in comparison to our approach and further demonstrate that we can find optimal generalized L_1 k-center clustering solutions up to an unprecedented 1,000,000 data points.},
  archive   = {C_AAAI},
  author    = {Aravinth Chembu and Scott Sanner and Hassan Khurram and Akshat Kumar},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25857},
  pages     = {7015-7023},
  title     = {Scalable and globally optimal generalized l₁ K-center clustering via constraint generation in mixed integer linear programming},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Graph ordering attention networks. <em>AAAI</em>, 7006–7014.
(<a href="https://doi.org/10.1609/aaai.v37i6.25856">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph Neural Networks (GNNs) have been successfully used in many problems involving graph-structured data, achieving state-of-the-art performance. GNNs typically employ a message-passing scheme, in which every node aggregates information from its neighbors using a permutation-invariant aggregation function. Standard well-examined choices such as the mean or sum aggregation functions have limited capabilities, as they are not able to capture interactions among neighbors. In this work, we formalize these interactions using an information-theoretic framework that notably includes synergistic information. Driven by this definition, we introduce the Graph Ordering Attention (GOAT) layer, a novel GNN component that captures interactions between nodes in a neighborhood. This is achieved by learning local node orderings via an attention mechanism and processing the ordered representations using a recurrent neural network aggregator. This design allows us to make use of a permutation-sensitive aggregator while maintaining the permutation-equivariance of the proposed GOAT layer. The GOAT model demonstrates its increased performance in modeling graph metrics that capture complex information, such as the betweenness centrality and the effective size of a node. In practical use-cases, its superior modeling capability is confirmed through its success in several real-world node classification benchmarks.},
  archive   = {C_AAAI},
  author    = {Michail Chatzianastasis and Johannes Lutzeyer and George Dasoulas and Michalis Vazirgiannis},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25856},
  pages     = {7006-7014},
  title     = {Graph ordering attention networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Where will players move next? Dynamic graphs and
hierarchical fusion for movement forecasting in badminton.
<em>AAAI</em>, 6998–7005. (<a
href="https://doi.org/10.1609/aaai.v37i6.25855">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Sports analytics has captured increasing attention since analysis of the various data enables insights for training strategies, player evaluation, etc. In this paper, we focus on predicting what types of returning strokes will be made, and where players will move to based on previous strokes. As this problem has not been addressed to date, movement forecasting can be tackled through sequence-based and graph-based models by formulating as a sequence prediction task. However, existing sequence-based models neglect the effects of interactions between players, and graph-based models still suffer from multifaceted perspectives on the next movement. Moreover, there is no existing work on representing strategic relations among players&#39; shot types and movements. To address these challenges, we first introduce the procedure of the Player Movements (PM) graph to exploit the structural movements of players with strategic relations. Based on the PM graph, we propose a novel Dynamic Graphs and Hierarchical Fusion for Movement Forecasting model (DyMF) with interaction style extractors to capture the mutual interactions of players themselves and between both players within a rally, and dynamic players&#39; tactics across time. In addition, hierarchical fusion modules are designed to incorporate the style influence of both players and rally interactions. Extensive experiments show that our model empirically outperforms both sequence- and graph-based methods and demonstrate the practical usage of movement forecasting. Code is available at https://github.com/wywyWang/CoachAI-Projects/tree/main/Movement\%20Forecasting.},
  archive   = {C_AAAI},
  author    = {Kai-Shiang Chang and Wei-Yao Wang and Wen-Chih Peng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25855},
  pages     = {6998-7005},
  title     = {Where will players move next? dynamic graphs and hierarchical fusion for movement forecasting in badminton},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). NHITS: Neural hierarchical interpolation for time series
forecasting. <em>AAAI</em>, 6989–6997. (<a
href="https://doi.org/10.1609/aaai.v37i6.25854">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent progress in neural forecasting accelerated improvements in the performance of large-scale forecasting systems. Yet, long-horizon forecasting remains a very difficult task. Two common challenges afflicting the task are the volatility of the predictions and their computational complexity. We introduce NHITS, a model which addresses both challenges by incorporating novel hierarchical interpolation and multi-rate data sampling techniques. These techniques enable the proposed method to assemble its predictions sequentially, emphasizing components with different frequencies and scales while decomposing the input signal and synthesizing the forecast. We prove that the hierarchical interpolation technique can efficiently approximate arbitrarily long horizons in the presence of smoothness. Additionally, we conduct extensive large-scale dataset experiments from the long-horizon forecasting literature, demonstrating the advantages of our method over the state-of-the-art methods, where NHITS provides an average accuracy improvement of almost 20\% over the latest Transformer architectures while reducing the computation time by an order of magnitude (50 times). Our code is available at https://github.com/Nixtla/neuralforecast.},
  archive   = {C_AAAI},
  author    = {Cristian Challu and Kin G. Olivares and Boris N. Oreshkin and Federico Garza Ramirez and Max Mergenthaler Canseco and Artur Dubrawski},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25854},
  pages     = {6989-6997},
  title     = {NHITS: Neural hierarchical interpolation for time series forecasting},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Posterior coreset construction with kernelized stein
discrepancy for model-based reinforcement learning. <em>AAAI</em>,
6980–6988. (<a href="https://doi.org/10.1609/aaai.v37i6.25853">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Model-based approaches to reinforcement learning (MBRL) exhibit favorable performance in practice, but their theoretical guarantees in large spaces are mostly restricted to the setting when transition model is Gaussian or Lipschitz, and demands a posterior estimate whose representational complexity grows unbounded with time. In this work, we develop a novel MBRL method (i) which relaxes the assumptions on the target transition model to belong to a generic family of mixture models; (ii) is applicable to large-scale training by incorporating a compression step such that the posterior estimate consists of a Bayesian coreset of only statistically significant past state-action pairs; and (iii) exhibits a sublinear Bayesian regret. To achieve these results, we adopt an approach based upon Stein&#39;s method, which, under a smoothness condition on the constructed posterior and target, allows distributional distance to be evaluated in closed form as the kernelized Stein discrepancy (KSD). The aforementioned compression step is then computed in terms of greedily retaining only those samples which are more than a certain KSD away from the previous model estimate. Experimentally, we observe that this approach is competitive with several state-of-the-art RL methodologies, and can achieve up-to 50 percent reduction in wall clock time in some continuous control environments.},
  archive   = {C_AAAI},
  author    = {Souradip Chakraborty and Amrit Singh Bedi and Pratap Tokekar and Alec Koppel and Brian Sadler and Furong Huang and Dinesh Manocha},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25853},
  pages     = {6980-6988},
  title     = {Posterior coreset construction with kernelized stein discrepancy for model-based reinforcement learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning pessimism for reinforcement learning.
<em>AAAI</em>, 6971–6979. (<a
href="https://doi.org/10.1609/aaai.v37i6.25852">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Off-policy deep reinforcement learning algorithms commonly compensate for overestimation bias during temporal-difference learning by utilizing pessimistic estimates of the expected target returns. In this work, we propose Generalized Pessimism Learning (GPL), a strategy employing a novel learnable penalty to enact such pessimism. In particular, we propose to learn this penalty alongside the critic with dual TD-learning, a new procedure to estimate and minimize the magnitude of the target returns bias with trivial computational cost. GPL enables us to accurately counteract overestimation bias throughout training without incurring the downsides of overly pessimistic targets. By integrating GPL with popular off-policy algorithms, we achieve state-of-the-art results in both competitive proprioceptive and pixel-based benchmarks.},
  archive   = {C_AAAI},
  author    = {Edoardo Cetin and Oya Celiktutan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25852},
  pages     = {6971-6979},
  title     = {Learning pessimism for reinforcement learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Invariant representations with stochastically quantized
neural networks. <em>AAAI</em>, 6962–6970. (<a
href="https://doi.org/10.1609/aaai.v37i6.25851">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Representation learning algorithms offer the opportunity to learn invariant representations of the input data with regard to nuisance factors. Many authors have leveraged such strategies to learn fair representations, i.e., vectors where information about sensitive attributes is removed. These methods are attractive as they may be interpreted as minimizing the mutual information between a neural layer&#39;s activations and a sensitive attribute. However, the theoretical grounding of such methods relies either on the computation of infinitely accurate adversaries or on minimizing a variational upper bound of a mutual information estimate. In this paper, we propose a methodology for direct computation of the mutual information between neurons in a layer and a sensitive attribute. We employ stochastically-activated binary neural networks, which lets us treat neurons as random variables. Our method is therefore able to minimize an upper bound on the mutual information between the neural representations and a sensitive attribute. We show that this method compares favorably with the state of the art in fair representation learning and that the learned representations display a higher level of invariance compared to full-precision neural networks.},
  archive   = {C_AAAI},
  author    = {Mattia Cerrato and Marius Köppel and Roberto Esposito and Stefan Kramer},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25851},
  pages     = {6962-6970},
  title     = {Invariant representations with stochastically quantized neural networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Soft action priors: Towards robust policy transfer.
<em>AAAI</em>, 6953–6961. (<a
href="https://doi.org/10.1609/aaai.v37i6.25850">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Despite success in many challenging problems, reinforcement learning (RL) is still confronted with sample inefficiency, which can be mitigated by introducing prior knowledge to agents. However, many transfer techniques in reinforcement learning make the limiting assumption that the teacher is an expert. In this paper, we use the action prior from the Reinforcement Learning as Inference framework - that is, a distribution over actions at each state which resembles a teacher policy, rather than a Bayesian prior - to recover state-of-the-art policy distillation techniques. Then, we propose a class of adaptive methods that can robustly exploit action priors by combining reward shaping and auxiliary regularization losses. In contrast to prior work, we develop algorithms for leveraging suboptimal action priors that may nevertheless impart valuable knowledge - which we call soft action priors. The proposed algorithms adapt by adjusting the strength of teacher feedback according to an estimate of the teacher&#39;s usefulness in each state. We perform tabular experiments, which show that the proposed methods achieve state-of-the-art performance, surpassing it when learning from suboptimal priors. Finally, we demonstrate the robustness of the adaptive algorithms in continuous action deep RL problems, in which adaptive algorithms considerably improved stability when compared to existing policy distillation methods.},
  archive   = {C_AAAI},
  author    = {Matheus Centa and Philippe Preux},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25850},
  pages     = {6953-6961},
  title     = {Soft action priors: Towards robust policy transfer},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An equivalence analysis of binary quantification methods.
<em>AAAI</em>, 6944–6952. (<a
href="https://doi.org/10.1609/aaai.v37i6.25849">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Quantification (or prevalence estimation) algorithms aim at predicting the class distribution of unseen sets (or bags) of examples. These methods are useful for two main tasks: 1) quantification applications, for instance when we need to track the proportions of several groups of interest over time, and 2) domain adaptation problems, in which we usually need to adapt a previously trained classifier to a different --albeit related-- target distribution according to the estimated prevalences. This paper analyzes several binary quantification algorithms showing that not only do they share a common framework but are, in fact, equivalent. Inspired by this study, we propose a new method that extends one of the approaches analyzed. After an empirical evaluation of all these methods using synthetic and benchmark datasets, the paper concludes recommending three of them due to their precision, efficiency, and diversity.},
  archive   = {C_AAAI},
  author    = {Alberto Castaño and Jaime Alonso and Pablo González and Juan José del Coz},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25849},
  pages     = {6944-6952},
  title     = {An equivalence analysis of binary quantification methods},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Very fast, approximate counterfactual explanations for
decision forests. <em>AAAI</em>, 6935–6943. (<a
href="https://doi.org/10.1609/aaai.v37i6.25848">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider finding a counterfactual explanation for a classification or regression forest, such as a random forest. This requires solving an optimization problem to find the closest input instance to a given instance for which the forest outputs a desired value. Finding an exact solution has a cost that is exponential on the number of leaves in the forest. We propose a simple but very effective approach: we constrain the optimization to input space regions populated by actual data points. The problem reduces to a form of nearest-neighbor search using a certain distance on a certain dataset. This has two advantages: first, the solution can be found very quickly, scaling to large forests and high-dimensional data, and enabling interactive use. Second, the solution found is more likely to be realistic in that it is guided towards high-density areas of input space.},
  archive   = {C_AAAI},
  author    = {Miguel Á. Carreira-Perpinan and Suryabhan Singh Hada},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25848},
  pages     = {6935-6943},
  title     = {Very fast, approximate counterfactual explanations for decision forests},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unfooling perturbation-based post hoc explainers.
<em>AAAI</em>, 6925–6934. (<a
href="https://doi.org/10.1609/aaai.v37i6.25847">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Monumental advancements in artificial intelligence (AI) have lured the interest of doctors, lenders, judges, and other professionals. While these high-stakes decision-makers are optimistic about the technology, those familiar with AI systems are wary about the lack of transparency of its decision-making processes. Perturbation-based post hoc explainers offer a model agnostic means of interpreting these systems while only requiring query-level access. However, recent work demonstrates that these explainers can be fooled adversarially. This discovery has adverse implications for auditors, regulators, and other sentinels. With this in mind, several natural questions arise - how can we audit these black box systems? And how can we ascertain that the auditee is complying with the audit in good faith? In this work, we rigorously formalize this problem and devise a defense against adversarial attacks on perturbation-based explainers. We propose algorithms for the detection (CAD-Detect) and defense (CAD-Defend) of these attacks, which are aided by our novel conditional anomaly detection approach, KNN-CAD. We demonstrate that our approach successfully detects whether a black box system adversarially conceals its decision-making process and mitigates the adversarial attack on real-world data for the prevalent explainers, LIME and SHAP. The code for this work is available at https://github.com/craymichael/unfooling.},
  archive   = {C_AAAI},
  author    = {Zachariah Carmichael and Walter J. Scheirer},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25847},
  pages     = {6925-6934},
  title     = {Unfooling perturbation-based post hoc explainers},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Meta-sketch: A neural data structure for estimating item
frequencies of data streams. <em>AAAI</em>, 6916–6924. (<a
href="https://doi.org/10.1609/aaai.v37i6.25846">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {To estimate item frequencies of data streams with limited space, sketches are widely used in real applications, including real-time web analytics, network monitoring, and self-driving. Sketches can be viewed as a model which maps the identifier of a stream item to the corresponding frequency domain. Starting from the premise, we envision a neural data structure, which we term the meta-sketch, to go beyond the basic structure of conventional sketches. The meta-sketch learns basic sketching abilities from meta-tasks constituted with synthetic datasets following Zipf distributions in the pre-training phase, and can be fast adapted to real (skewed) distributions in the adaption phase. Extensive experiments demonstrate the performance gains of the meta-sketch and offer insights into our proposals.},
  archive   = {C_AAAI},
  author    = {Yukun Cao and Yuan Feng and Xike Xie},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25846},
  pages     = {6916-6924},
  title     = {Meta-sketch: A neural data structure for estimating item frequencies of data streams},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). InParformer: Evolutionary decomposition transformers with
interactive parallel attention for long-term time series forecasting.
<em>AAAI</em>, 6906–6915. (<a
href="https://doi.org/10.1609/aaai.v37i6.25845">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Long-term time series forecasting (LTSF) provides substantial benefits for numerous real-world applications, whereas places essential demands on the model capacity to capture long-range dependencies. Recent Transformer-based models have significantly improved LTSF performance. It is worth noting that Transformer with the self-attention mechanism was originally proposed to model language sequences whose tokens (i.e., words) are discrete and highly semantic. However, unlike language sequences, most time series are sequential and continuous numeric points. Time steps with temporal redundancy are weakly semantic, and only leveraging time-domain tokens is hard to depict the overall properties of time series (e.g., the overall trend and periodic variations). To address these problems, we propose a novel Transformer-based forecasting model named InParformer with an Interactive Parallel Attention (InPar Attention) mechanism. The InPar Attention is proposed to learn long-range dependencies comprehensively in both frequency and time domains. To improve its learning capacity and efficiency, we further design several mechanisms, including query selection, key-value pair compression, and recombination. Moreover, InParformer is constructed with evolutionary seasonal-trend decomposition modules to enhance intricate temporal pattern extraction. Extensive experiments on six real-world benchmarks show that InParformer outperforms the state-of-the-art forecasting Transformers.},
  archive   = {C_AAAI},
  author    = {Haizhou Cao and Zhenhao Huang and Tiechui Yao and Jue Wang and Hui He and Yangang Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25845},
  pages     = {6906-6915},
  title     = {InParformer: Evolutionary decomposition transformers with interactive parallel attention for long-term time series forecasting},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Estimating treatment effects from irregular time series
observations with hidden confounders. <em>AAAI</em>, 6897–6905. (<a
href="https://doi.org/10.1609/aaai.v37i6.25844">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Causal analysis for time series data, in particular estimating individualized treatment effect (ITE), is a key task in many real world applications, such as finance, retail, healthcare, etc. Real world time series, i.e., large-scale irregular or sparse and intermittent time series, raise significant challenges to existing work attempting to estimate treatment effects. Specifically, the existence of hidden confounders can lead to biased treatment estimates and complicate the causal inference process. In particular, anomaly hidden confounders which exceed the typical range can lead to high variance estimates. Moreover, in continuous time settings with irregular samples, it is challenging to directly handle the dynamics of causality. In this paper, we leverage recent advances in Lipschitz regularization and neural controlled differential equations (CDE) to develop an effective and scalable solution, namely LipCDE, to address the above challenges. LipCDE can directly model the dynamic causal relationships between historical data and outcomes with irregular samples by considering the boundary of hidden confounders given by Lipschitz constrained neural networks. Furthermore, we conduct extensive experiments on both synthetic and real world datasets to demonstrate the effectiveness and scalability of LipCDE.},
  archive   = {C_AAAI},
  author    = {Defu Cao and James Enouen and Yujing Wang and Xiangchen Song and Chuizheng Meng and Hao Niu and Yan Liu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25844},
  pages     = {6897-6905},
  title     = {Estimating treatment effects from irregular time series observations with hidden confounders},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FTM: A frame-level timeline modeling method for temporal
graph representation learning. <em>AAAI</em>, 6888–6896. (<a
href="https://doi.org/10.1609/aaai.v37i6.25843">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Learning representations for graph-structured data is essential for graph analytical tasks. While remarkable progress has been made on static graphs, researches on temporal graphs are still in its beginning stage. The bottleneck of the temporal graph representation learning approach is the neighborhood aggregation strategy, based on which graph attributes share and gather information explicitly. Existing neighborhood aggregation strategies fail to capture either the short-term features or the long-term features of temporal graph attributes, leading to unsatisfactory model performance and even poor robustness and domain generality of the representation learning method. To address this problem, we propose a Frame-level Timeline Modeling (FTM) method that helps to capture both short-term and long-term features and thus learns more informative representations on temporal graphs. In particular, we present a novel link-based framing technique to preserve the short-term features and then incorporate a timeline aggregator module to capture the intrinsic dynamics of graph evolution as long-term features. Our method can be easily assembled with most temporal GNNs. Extensive experiments on common datasets show that our method brings great improvements to the capability, robustness, and domain generality of backbone methods in downstream tasks. Our code can be found at https://github.com/yeeeqichen/FTM.},
  archive   = {C_AAAI},
  author    = {Bowen Cao and Qichen Ye and Weiyuan Xu and Yuexian Zou},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25843},
  pages     = {6888-6896},
  title     = {FTM: A frame-level timeline modeling method for temporal graph representation learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RePreM: Representation pre-training with masked model for
reinforcement learning. <em>AAAI</em>, 6879–6887. (<a
href="https://doi.org/10.1609/aaai.v37i6.25842">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Inspired by the recent success of sequence modeling in RL and the use of masked language model for pre-training, we propose a masked model for pre-training in RL, RePreM (Representation Pre-training with Masked Model), which trains the encoder combined with transformer blocks to predict the masked states or actions in a trajectory. RePreM is simple but effective compared to existing representation pre-training methods in RL. It avoids algorithmic sophistication (such as data augmentation or estimating multiple models) with sequence modeling and generates a representation that captures long-term dynamics well. Empirically, we demonstrate the effectiveness of RePreM in various tasks, including dynamic prediction, transfer learning, and sample-efficient RL with both value-based and actor-critic methods. Moreover, we show that RePreM scales well with dataset size, dataset quality, and the scale of the encoder, which indicates its potential towards big RL models.},
  archive   = {C_AAAI},
  author    = {Yuanying Cai and Chuheng Zhang and Wei Shen and Xuyun Zhang and Wenjie Ruan and Longbo Huang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25842},
  pages     = {6879-6887},
  title     = {RePreM: Representation pre-training with masked model for reinforcement learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Semantic-enhanced image clustering. <em>AAAI</em>,
6869–6878. (<a href="https://doi.org/10.1609/aaai.v37i6.25841">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Image clustering is an important and open challenging task in computer vision. Although many methods have been proposed to solve the image clustering task, they only explore images and uncover clusters according to the image features, thus being unable to distinguish visually similar but semantically different images. In this paper, we propose to investigate the task of image clustering with the help of visual-language pre-training model. Different from the zero-shot setting, in which the class names are known, we only know the number of clusters in this setting. Therefore, how to map images to a proper semantic space and how to cluster images from both image and semantic spaces are two key problems. To solve the above problems, we propose a novel image clustering method guided by the visual-language pre-training model CLIP, named Semantic-Enhanced Image Clustering (SIC). In this new method, we propose a method to map the given images to a proper semantic space first and efficient methods to generate pseudo-labels according to the relationships between images and semantics. Finally, we propose to perform clustering with consistency learning in both image space and semantic space, in a self-supervised learning fashion. The theoretical result of convergence analysis shows that our proposed method can converge at a sublinear speed. Theoretical analysis of expectation risk also shows that we can reduce the expectation risk by improving neighborhood consistency, increasing prediction confidence, or reducing neighborhood imbalance. Experimental results on five benchmark datasets clearly show the superiority of our new method.},
  archive   = {C_AAAI},
  author    = {Shaotian Cai and Liping Qiu and Xiaojun Chen and Qin Zhang and Longteng Chen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25841},
  pages     = {6869-6878},
  title     = {Semantic-enhanced image clustering},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Toward a perspectivist turn in ground truthing for
predictive computing. <em>AAAI</em>, 6860–6868. (<a
href="https://doi.org/10.1609/aaai.v37i6.25840">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Most current Artificial Intelligence applications are based on supervised Machine Learning (ML), which ultimately grounds on data annotated by small teams of experts or large ensemble of volunteers. The annotation process is often performed in terms of a majority vote, however this has been proved to be often problematic by recent evaluation studies. In this article, we describe and advocate for a different paradigm, which we call perspectivism: this counters the removal of disagreement and, consequently, the assumption of correctness of traditionally aggregated gold-standard datasets, and proposes the adoption of methods that preserve divergence of opinions and integrate multiple perspectives in the ground truthing process of ML development. Drawing on previous works which inspired it, mainly from the crowdsourcing and multi-rater labeling settings, we survey the state-of-the-art and describe the potential of our proposal for not only the more subjective tasks (e.g. those related to human language) but also those tasks commonly understood as objective (e.g. medical decision making). We present the main benefits of adopting a perspectivist stance in ML, as well as possible disadvantages, and various ways in which such a stance can be implemented in practice. Finally, we share a set of recommendations and outline a research agenda to advance the perspectivist stance in ML.},
  archive   = {C_AAAI},
  author    = {Federico Cabitza and Andrea Campagner and Valerio Basile},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25840},
  pages     = {6860-6868},
  title     = {Toward a perspectivist turn in ground truthing for predictive computing},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Scalable theory-driven regularization of scene graph
generation models. <em>AAAI</em>, 6850–6859. (<a
href="https://doi.org/10.1609/aaai.v37i6.25839">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Several techniques have recently aimed to improve the performance of deep learning models for Scene Graph Generation (SGG) by incorporating background knowledge. State-of-the-art techniques can be divided into two families: one where the background knowledge is incorporated into the model in a subsymbolic fashion, and another in which the background knowledge is maintained in symbolic form. Despite promising results, both families of techniques face several shortcomings: the first one requires ad-hoc, more complex neural architectures increasing the training or inference cost; the second one suffers from limited scalability w.r.t. the size of the background knowledge. Our work introduces a regularization technique for injecting symbolic background knowledge into neural SGG models that overcomes the limitations of prior art. Our technique is model-agnostic, does not incur any cost at inference time, and scales to previously unmanageable background knowledge sizes. We demonstrate that our technique can improve the accuracy of state-of-the-art SGG models, by up to 33\%.},
  archive   = {C_AAAI},
  author    = {Davide Buffelli and Efthymia Tsamoura},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25839},
  pages     = {6850-6859},
  title     = {Scalable theory-driven regularization of scene graph generation models},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fully-dynamic decision trees. <em>AAAI</em>, 6842–6849. (<a
href="https://doi.org/10.1609/aaai.v37i6.25838">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We develop the first fully dynamic algorithm that maintains a decision tree over an arbitrary sequence of insertions and deletions of labeled examples. Given ε&gt;0 our algorithm guarantees that, at every point in time, every node of the decision tree uses a split with Gini gain within an additive ε of the optimum. For real-valued features the algorithm has an amortized running time per insertion/deletion of O((d·log³n)/ε²), which improves to O((d·log²n)/ε) for binary or categorical features, while it uses space O(n·d), where n is the maximum number of examples at any point in time and d is the number of features. Our algorithm is nearly optimal, as we show that any algorithm with similar guarantees requires amortized running time Ω(d) and space Ω(n·d/polylog(nd)). We complement our theoretical results with an extensive experimental evaluation on real-world data, showing the effectiveness of our algorithm.},
  archive   = {C_AAAI},
  author    = {Marco Bressan and Gabriel Damay and Mauro Sozio},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25838},
  pages     = {6842-6849},
  title     = {Fully-dynamic decision trees},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A parameterized theory of PAC learning. <em>AAAI</em>,
6834–6841. (<a href="https://doi.org/10.1609/aaai.v37i6.25837">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Probably Approximately Correct (i.e., PAC) learning is a core concept of sample complexity theory, and efficient PAC learnability is often seen as a natural counterpart to the class P in classical computational complexity. But while the nascent theory of parameterized complexity has allowed us to push beyond the P-NP &quot;dichotomy&quot; in classical computational complexity and identify the exact boundaries of tractability for numerous problems, there is no analogue in the domain of sample complexity that could push beyond efficient PAC learnability. As our core contribution, we fill this gap by developing a theory of parameterized PAC learning which allows us to shed new light on several recent PAC learning results that incorporated elements of parameterized complexity. Within the theory, we identify not one but two notions of fixed-parameter learnability that both form distinct counterparts to the class FPT - the core concept at the center of the parameterized complexity paradigm - and develop the machinery required to exclude fixed-parameter learnability. We then showcase the applications of this theory to identify refined boundaries of tractability for CNF and DNF learning as well as for a range of learning problems on graphs.},
  archive   = {C_AAAI},
  author    = {Cornelius Brand and Robert Ganian and Kirill Simonov},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25837},
  pages     = {6834-6841},
  title     = {A parameterized theory of PAC learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AutoInit: Analytic signal-preserving weight initialization
for neural networks. <em>AAAI</em>, 6823–6833. (<a
href="https://doi.org/10.1609/aaai.v37i6.25836">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Neural networks require careful weight initialization to prevent signals from exploding or vanishing. Existing initialization schemes solve this problem in specific cases by assuming that the network has a certain activation function or topology. It is difficult to derive such weight initialization strategies, and modern architectures therefore often use these same initialization schemes even though their assumptions do not hold. This paper introduces AutoInit, a weight initialization algorithm that automatically adapts to different neural network architectures. By analytically tracking the mean and variance of signals as they propagate through the network, AutoInit appropriately scales the weights at each layer to avoid exploding or vanishing signals. Experiments demonstrate that AutoInit improves performance of convolutional, residual, and transformer networks across a range of activation function, dropout, weight decay, learning rate, and normalizer settings, and does so more reliably than data-dependent initialization methods. This flexibility allows AutoInit to initialize models for everything from small tabular tasks to large datasets such as ImageNet. Such generality turns out particularly useful in neural architecture search and in activation function discovery. In these settings, AutoInit initializes each candidate appropriately, making performance evaluations more accurate. AutoInit thus serves as an automatic configuration tool that makes design of new neural network architectures more robust. The AutoInit package provides a wrapper around TensorFlow models and is available at https://github.com/cognizant-ai-labs/autoinit.},
  archive   = {C_AAAI},
  author    = {Garrett Bingham and Risto Miikkulainen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25836},
  pages     = {6823-6833},
  title     = {AutoInit: Analytic signal-preserving weight initialization for neural networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An improved algorithm for online min-sum set cover.
<em>AAAI</em>, 6815–6822. (<a
href="https://doi.org/10.1609/aaai.v37i6.25835">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study a fundamental model of online preference aggregation, where an algorithm maintains an ordered list of n elements. An input is a stream of preferred sets R_1, R_2, ..., R_t, ... Upon seeing R_t and without knowledge of any future sets, an algorithm has to rerank elements (change the list ordering), so that at least one element of R_t is found near the list front. The incurred cost is a sum of the list update costs (the number of swaps of neighboring list elements) and access cost (the position of the first element of R_t on the list). This scenario occurs naturally in applications such as ordering items in an online shop using aggregated preferences of shop customers. The theoretical underpinning of this problem is known as Min-Sum Set Cover. Unlike previous work that mostly studied the performance of an online algorithm ALG in comparison to the static optimal solution (a single optimal list ordering), in this paper, we study an arguably harder variant where the benchmark is the provably stronger optimal dynamic solution OPT (that may also modify the list ordering). In terms of an online shop, this means that the aggregated preferences of its user base evolve with time. We construct a computationally efficient randomized algorithm whose competitive ratio (ALG-to-OPT cost ratio) is O(r^2) and prove the existence of a deterministic O(r^4)-competitive algorithm. Here, r is the maximum cardinality of sets R_t. This is the first algorithm whose ratio does not depend on n: the previously best algorithm for this problem was O(r^(3/2) * n^(1/2))-competitive and Ω(r) is a lower bound on the performance of any deterministic online algorithm.},
  archive   = {C_AAAI},
  author    = {Marcin Bienkowski and Marcin Mucha},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25835},
  pages     = {6815-6822},
  title     = {An improved algorithm for online min-sum set cover},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Normalizing flow ensembles for rich aleatoric and epistemic
uncertainty modeling. <em>AAAI</em>, 6806–6814. (<a
href="https://doi.org/10.1609/aaai.v37i6.25834">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this work, we demonstrate how to reliably estimate epistemic uncertainty while maintaining the flexibility needed to capture complicated aleatoric distributions. To this end, we propose an ensemble of Normalizing Flows (NF), which are state-of-the-art in modeling aleatoric uncertainty. The ensembles are created via sets of fixed dropout masks, making them less expensive than creating separate NF models. We demonstrate how to leverage the unique structure of NFs, base distributions, to estimate aleatoric uncertainty without relying on samples, provide a comprehensive set of baselines, and derive unbiased estimates for differential entropy. The methods were applied to a variety of experiments, commonly used to benchmark aleatoric and epistemic uncertainty estimation: 1D sinusoidal data, 2D windy grid-world (Wet Chicken), Pendulum, and Hopper. In these experiments, we setup an active learning framework and evaluate each model&#39;s capability at measuring aleatoric and epistemic uncertainty. The results show the advantages of using NF ensembles in capturing complicated aleatoric while maintaining accurate epistemic uncertainty estimates.},
  archive   = {C_AAAI},
  author    = {Lucas Berry and David Meger},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25834},
  pages     = {6806-6814},
  title     = {Normalizing flow ensembles for rich aleatoric and epistemic uncertainty modeling},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sustaining fairness via incremental learning. <em>AAAI</em>,
6797–6805. (<a href="https://doi.org/10.1609/aaai.v37i6.25833">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Machine learning systems are often deployed for making critical decisions like credit lending, hiring, etc. While making decisions, such systems often encode the user&#39;s demographic information (like gender, age) in their intermediate representations. This can lead to decisions that are biased towards specific demographics. Prior work has focused on debiasing intermediate representations to ensure fair decisions. However, these approaches fail to remain fair with changes in the task or demographic distribution. To ensure fairness in the wild, it is important for a system to adapt to such changes as it accesses new data in an incremental fashion. In this work, we propose to address this issue by introducing the problem of learning fair representations in an incremental learning setting. To this end, we present Fairness-aware Incremental Representation Learning (FaIRL), a representation learning system that can sustain fairness while incrementally learning new tasks. FaIRL is able to achieve fairness and learn new tasks by controlling the rate-distortion function of the learned representations. Our empirical evaluations show that FaIRL is able to make fair decisions while achieving high performance on the target task, outperforming several baselines.},
  archive   = {C_AAAI},
  author    = {Somnath Basu Roy Chowdhury and Snigdha Chaturvedi},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25833},
  pages     = {6797-6805},
  title     = {Sustaining fairness via incremental learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Equi-tuning: Group equivariant fine-tuning of pretrained
models. <em>AAAI</em>, 6788–6796. (<a
href="https://doi.org/10.1609/aaai.v37i6.25832">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We introduce equi-tuning, a novel fine-tuning method that transforms (potentially non-equivariant) pretrained models into group equivariant models while incurring minimum L_2 loss between the feature representations of the pretrained and the equivariant models. Large pretrained models can be equi-tuned for different groups to satisfy the needs of various downstream tasks. Equi-tuned models benefit from both group equivariance as an inductive bias and semantic priors from pretrained models. We provide applications of equi-tuning on three different tasks: image classification, compositional generalization in language, and fairness in natural language generation (NLG). We also provide a novel group-theoretic definition for fairness in NLG. The effectiveness of this definition is shown by testing it against a standard empirical method of fairness in NLG. We provide experimental results for equi-tuning using a variety of pretrained models: Alexnet, Resnet, VGG, and Densenet for image classification; RNNs, GRUs, and LSTMs for compositional generalization; and GPT2 for fairness in NLG. We test these models on benchmark datasets across all considered tasks to show the generality and effectiveness of the proposed method.},
  archive   = {C_AAAI},
  author    = {Sourya Basu and Prasanna Sattigeri and Karthikeyan Natesan Ramamurthy and Vijil Chenthamarakshan and Kush R. Varshney and Lav R. Varshney and Payel Das},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25832},
  pages     = {6788-6796},
  title     = {Equi-tuning: Group equivariant fine-tuning of pretrained models},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learnable spectral wavelets on dynamic graphs to capture
global interactions. <em>AAAI</em>, 6779–6787. (<a
href="https://doi.org/10.1609/aaai.v37i6.25831">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Learning on evolving(dynamic) graphs has caught the attention of researchers as static methods exhibit limited performance in this setting. The existing methods for dynamic graphs learn spatial features by local neighborhood aggregation, which essentially only captures the low pass signals and local interactions. In this work, we go beyond current approaches to incorporate global features for effectively learning representations of a dynamically evolving graph. We propose to do so by capturing the spectrum of the dynamic graph. Since static methods to learn the graph spectrum would not consider the history of the evolution of the spectrum as the graph evolves with time, we propose an approach to learn the graph wavelets to capture this evolving spectra. Further, we propose a framework that integrates the dynamically captured spectra in the form of these learnable wavelets into spatial features for incorporating local and global interactions. Experiments on eight standard datasets show that our method significantly outperforms related methods on various tasks for dynamic graphs.},
  archive   = {C_AAAI},
  author    = {Anson Bastos and Abhishek Nadgeri and Kuldeep Singh and Toyotaro Suzumura and Manish Singh},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25831},
  pages     = {6779-6787},
  title     = {Learnable spectral wavelets on dynamic graphs to capture global interactions},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Alternating layered variational quantum circuits can be
classically optimized efficiently using classical shadows.
<em>AAAI</em>, 6770–6778. (<a
href="https://doi.org/10.1609/aaai.v37i6.25830">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Variational quantum algorithms (VQAs) are the quantum analog of classical neural networks (NNs). A VQA consists of a parameterized quantum circuit (PQC) which is composed of multiple layers of ansatzes (simpler PQCs, which are an analogy of NN layers) that differ only in selections of parameters. Previous work has identified the alternating layered ansatz as potentially a new standard ansatz in near-term quantum computing. Indeed, shallow alternating layered VQAs are easy to implement and have been shown to be both trainable and expressive. In this work, we introduce a training algorithm with an exponential reduction in training cost of such VQAs. Moreover, our algorithm uses classical shadows of quantum input data, and can hence be run on a classical computer with rigorous performance guarantees. We demonstrate 2-3 orders of magnitude improvement in the training cost using our algorithm for the example problems of finding state preparation circuits and the quantum autoencoder.},
  archive   = {C_AAAI},
  author    = {Afrad Basheer and Yuan Feng and Christopher Ferrie and Sanjiang Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25830},
  pages     = {6770-6778},
  title     = {Alternating layered variational quantum circuits can be classically optimized efficiently using classical shadows},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fairness and welfare quantification for regret in
multi-armed bandits. <em>AAAI</em>, 6762–6769. (<a
href="https://doi.org/10.1609/aaai.v37i6.25829">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We extend the notion of regret with a welfarist perspective. Focussing on the classic multi-armed bandit (MAB) framework, the current work quantifies the performance of bandit algorithms by applying a fundamental welfare function, namely the Nash social welfare (NSW) function. This corresponds to equating algorithm&#39;s performance to the geometric mean of its expected rewards and leads us to the study of Nash regret, defined as the difference between the - a priori unknown - optimal mean (among the arms) and the algorithm&#39;s performance. Since NSW is known to satisfy fairness axioms, our approach complements the utilitarian considerations of average (cumulative) regret, wherein the algorithm is evaluated via the arithmetic mean of its expected rewards. This work develops an algorithm that, given the horizon of play T, achieves a Nash regret of O ( sqrt{(k log T)/T} ), here k denotes the number of arms in the MAB instance. Since, for any algorithm, the Nash regret is at least as much as its average regret (the AM-GM inequality), the known lower bound on average regret holds for Nash regret as well. Therefore, our Nash regret guarantee is essentially tight. In addition, we develop an anytime algorithm with a Nash regret guarantee of O( sqrt{(k log T)/T} log T ).},
  archive   = {C_AAAI},
  author    = {Siddharth Barman and Arindam Khan and Arnab Maiti and Ayush Sawarni},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25829},
  pages     = {6762-6769},
  title     = {Fairness and welfare quantification for regret in multi-armed bandits},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards efficient and domain-agnostic evasion attack with
high-dimensional categorical inputs. <em>AAAI</em>, 6753–6761. (<a
href="https://doi.org/10.1609/aaai.v37i6.25828">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Our work targets at searching feasible adversarial perturbation to attack a classifier with high-dimensional categorical inputs in a domain-agnostic setting. This is intrinsically a NP-hard knapsack problem where the exploration space becomes explosively larger as the feature dimension increases. Without the help of domain knowledge, solving this problem via heuristic method, such as Branch-and-Bound, suffers from exponential complexity, yet can bring arbitrarily bad attack results. We address the challenge via the lens of multi-armed bandit based combinatorial search. Our proposed method, namely FEAT, treats modifying each categorical feature as pulling an arm in multi-armed bandit programming. Our objective is to achieve highly efficient and effective attack using an Orthogonal Matching Pursuit (OMP)-enhanced Upper Confidence Bound (UCB) exploration strategy. Our theoretical analysis bounding the regret gap of FEAT guarantees its practical attack performance. In empirical analysis, we compare FEAT with other state-of-the-art domain-agnostic attack methods over various real-world categorical data sets of different applications. Substantial experimental observations confirm the expected efficiency and attack effectiveness of FEAT applied in different application scenarios. Our work further hints the applicability of FEAT for assessing the adversarial vulnerability of classification systems with high-dimensional categorical inputs.},
  archive   = {C_AAAI},
  author    = {Hongyan Bao and Yufei Han and Yujun Zhou and Xin Gao and Xiangliang Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25828},
  pages     = {6753-6761},
  title     = {Towards efficient and domain-agnostic evasion attack with high-dimensional categorical inputs},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal sparse recovery with decision stumps. <em>AAAI</em>,
6745–6752. (<a href="https://doi.org/10.1609/aaai.v37i6.25827">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Decision trees are widely used for their low computational cost, good predictive performance, and ability to assess the importance of features. Though often used in practice for feature selection, the theoretical guarantees of these methods are not well understood. We here obtain a tight finite sample bound for the feature selection problem in linear regression using single-depth decision trees. We examine the statistical properties of these &quot;decision stumps&quot; for the recovery of the s active features from p total features, where s},
  archive   = {C_AAAI},
  author    = {Kiarash Banihashem and Mohammad Hajiaghayi and Max Springer},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25827},
  pages     = {6745-6752},
  title     = {Optimal sparse recovery with decision stumps},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Achieving zero constraint violation for constrained
reinforcement learning via conservative natural policy gradient
primal-dual algorithm. <em>AAAI</em>, 6737–6744. (<a
href="https://doi.org/10.1609/aaai.v37i6.25826">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider the problem of constrained Markov decision process (CMDP) in continuous state actions spaces where the goal is to maximize the expected cumulative reward subject to some constraints. We propose a novel Conservative Natural Policy Gradient Primal Dual Algorithm (CNPGPD) to achieve zero constraint violation while achieving state of the art convergence results for the objective value function. For general policy parametrization, we prove convergence of value function to global optimal upto an approximation error due to restricted policy class. We improve the sample complexity of existing constrained NPGPD algorithm. To the best of our knowledge, this is the first work to establish zero constraint violation with Natural policy gradient style algorithms for infinite horizon discounted CMDPs. We demonstrate the merits of proposed algorithm via experimental evaluations.},
  archive   = {C_AAAI},
  author    = {Qinbo Bai and Amrit Singh Bedi and Vaneet Aggarwal},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25826},
  pages     = {6737-6744},
  title     = {Achieving zero constraint violation for constrained reinforcement learning via conservative natural policy gradient primal-dual algorithm},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PiCor: Multi-task deep reinforcement learning with policy
correction. <em>AAAI</em>, 6728–6736. (<a
href="https://doi.org/10.1609/aaai.v37i6.25825">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-task deep reinforcement learning (DRL) ambitiously aims to train a general agent that masters multiple tasks simultaneously. However, varying learning speeds of different tasks compounding with negative gradients interference makes policy learning inefficient. In this work, we propose PiCor, an efficient multi-task DRL framework that splits learning into policy optimization and policy correction phases. The policy optimization phase improves the policy by any DRL algothrim on the sampled single task without considering other tasks. The policy correction phase first constructs an adaptive adjusted performance constraint set. Then the intermediate policy learned by the first phase is constrained to the set, which controls the negative interference and balances the learning speeds across tasks. Empirically, we demonstrate that PiCor outperforms previous methods and significantly improves sample efficiency on simulated robotic manipulation and continuous control tasks. We additionally show that adaptive weight adjusting can further improve data efficiency and performance.},
  archive   = {C_AAAI},
  author    = {Fengshuo Bai and Hongming Zhang and Tianyang Tao and Zhiheng Wu and Yanna Wang and Bo Xu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25825},
  pages     = {6728-6736},
  title     = {PiCor: Multi-task deep reinforcement learning with policy correction},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generalizing downsampling from regular data to graphs.
<em>AAAI</em>, 6718–6727. (<a
href="https://doi.org/10.1609/aaai.v37i6.25824">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Downsampling produces coarsened, multi-resolution representations of data and it is used, for example, to produce lossy compression and visualization of large images, reduce computational costs, and boost deep neural representation learning. Unfortunately, due to their lack of a regular structure, there is still no consensus on how downsampling should apply to graphs and linked data. Indeed reductions in graph data are still needed for the goals described above, but reduction mechanisms do not have the same focus on preserving topological structures and properties, while allowing for resolution-tuning, as is the case in regular data downsampling. In this paper, we take a step in this direction, introducing a unifying interpretation of downsampling in regular and graph data. In particular, we define a graph coarsening mechanism which is a graph-structured counterpart of controllable equispaced coarsening mechanisms in regular data. We prove theoretical guarantees for distortion bounds on path lengths, as well as the ability to preserve key topological properties in the coarsened graphs. We leverage these concepts to define a graph pooling mechanism that we empirically assess in graph classification tasks, providing a greedy algorithm that allows efficient parallel implementation on GPUs, and showing that it compares favorably against pooling methods in literature.},
  archive   = {C_AAAI},
  author    = {Davide Bacciu and Alessio Conte and Francesco Landolfi},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25824},
  pages     = {6718-6727},
  title     = {Generalizing downsampling from regular data to graphs},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Meta-learning for simple regret minimization. <em>AAAI</em>,
6709–6717. (<a href="https://doi.org/10.1609/aaai.v37i6.25823">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We develop a meta-learning framework for simple regret minimization in bandits. In this framework, a learning agent interacts with a sequence of bandit tasks, which are sampled i.i.d. from an unknown prior distribution, and learns its meta-parameters to perform better on future tasks. We propose the first Bayesian and frequentist meta-learning algorithms for this setting. The Bayesian algorithm has access to a prior distribution over the meta-parameters and its meta simple regret over m bandit tasks with horizon n is mere O(m / √n). On the other hand, the meta simple regret of the frequentist algorithm is O(n√m + m/ √n). While its regret is worse, the frequentist algorithm is more general because it does not need a prior distribution over the meta-parameters. It can also be analyzed in more settings. We instantiate our algorithms for several classes of bandit problems. Our algorithms are general and we complement our theory by evaluating them empirically in several environments.},
  archive   = {C_AAAI},
  author    = {Javad Azizi and Branislav Kveton and Mohammad Ghavamzadeh and Sumeet Katariya},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25823},
  pages     = {6709-6717},
  title     = {Meta-learning for simple regret minimization},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Tree learning: Optimal sample complexity and algorithms.
<em>AAAI</em>, 6701–6708. (<a
href="https://doi.org/10.1609/aaai.v37i6.25822">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the problem of learning a hierarchical tree representation of data from labeled samples, taken from an arbitrary (and possibly adversarial) distribution. Consider a collection of data tuples labeled according to their hierarchical structure. The smallest number of such tuples required in order to be able to accurately label subsequent tuples is of interest for data collection in machine learning. We present optimal sample complexity bounds for this problem in several learning settings, including (agnostic) PAC learning and online learning. Our results are based on tight bounds of the Natarajan and Littlestone dimensions of the associated problem. The corresponding tree classifiers can be constructed efficiently in near-linear time.},
  archive   = {C_AAAI},
  author    = {Dmitrii Avdiukhin and Grigory Yaroslavtsev and Danny Vainstein and Orr Fischer and Sauman Das and Faraz Mirza},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25822},
  pages     = {6701-6708},
  title     = {Tree learning: Optimal sample complexity and algorithms},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fully dynamic online selection through online contention
resolution schemes. <em>AAAI</em>, 6693–6700. (<a
href="https://doi.org/10.1609/aaai.v37i6.25821">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study fully dynamic online selection problems in an adversarial/stochastic setting that includes Bayesian online selection, prophet inequalities, posted price mechanisms, and stochastic probing problems subject to combinatorial constraints. In the classical ``incremental&#39;&#39; version of the problem, selected elements remain active until the end of the input sequence. On the other hand, in the fully dynamic version of the problem, elements stay active for a limited time interval, and then leave. This models, for example, the online matching of tasks to workers with task/worker-dependent working times, and sequential posted pricing of perishable goods. A successful approach to online selection problems in the adversarial setting is given by the notion of Online Contention Resolution Scheme (OCRS), that uses a priori information to formulate a linear relaxation of the underlying optimization problem, whose optimal fractional solution is rounded online for any adversarial order of the input sequence. Our main contribution is providing a general method for constructing an OCRS for fully dynamic online selection problems. Then, we show how to employ such OCRS to construct no-regret algorithms in a partial information model with semi-bandit feedback and adversarial inputs.},
  archive   = {C_AAAI},
  author    = {Vashist Avadhanula and Andrea Celli and Riccardo Colini-Baldeschi and Stefano Leonardi and Matteo Russo},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25821},
  pages     = {6693-6700},
  title     = {Fully dynamic online selection through online contention resolution schemes},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Simulating network paths with recurrent buffering units.
<em>AAAI</em>, 6684–6692. (<a
href="https://doi.org/10.1609/aaai.v37i6.25820">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Simulating physical network paths (e.g., Internet) is a cornerstone research problem in the emerging sub-field of AI-for-networking. We seek a model that generates end-to-end packet delay values in response to the time-varying load offered by a sender, which is typically a function of the previously output delays. The problem setting is unique, and renders the state-of-the-art text and time-series generative models inapplicable or ineffective. We formulate an ML problem at the intersection of dynamical systems, sequential decision making, and time-series modeling. We propose a novel grey-box approach to network simulation that embeds the semantics of physical network path in a new RNN-style model called Recurrent Buffering Unit, providing the interpretability of standard network simulator tools, the power of neural models, the efficiency of SGD-based techniques for learning, and yielding promising results on synthetic and real-world network traces.},
  archive   = {C_AAAI},
  author    = {Divyam Anshumaan and Sriram Balasubramanian and Shubham Tiwari and Nagarajan Natarajan and Sundararajan Sellamanickam and Venkat N. Padmanabhan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25820},
  pages     = {6684-6692},
  title     = {Simulating network paths with recurrent buffering units},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Contrastive classification and representation learning with
probabilistic interpretation. <em>AAAI</em>, 6675–6683. (<a
href="https://doi.org/10.1609/aaai.v37i6.25819">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Cross entropy loss has served as the main objective function for classification-based tasks. Widely deployed for learning neural network classifiers, it shows both effectiveness and a probabilistic interpretation. Recently, after the success of self supervised contrastive representation learning methods, supervised contrastive methods have been proposed to learn representations and have shown superior and more robust performance, compared to solely training with cross entropy loss. However, cross entropy loss is still needed to train the final classification layer. In this work, we investigate the possibility of learning both the representation and the classifier using one objective function that combines the robustness of contrastive learning and the probabilistic interpretation of cross entropy loss. First, we revisit a previously proposed contrastive-based objective function that approximates cross entropy loss and present a simple extension to learn the classifier jointly. Second, we propose a new version of the supervised contrastive training that learns jointly the parameters of the classifier and the backbone of the network. We empirically show that these proposed objective functions demonstrate state-of-the-art performance and show a significant improvement over the standard cross entropy loss with more training stability and robustness in various challenging settings.},
  archive   = {C_AAAI},
  author    = {Rahaf Aljundi and Yash Patel and Milan Sulc and Nikolay Chumerin and Daniel Olmeda Reino},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25819},
  pages     = {6675-6683},
  title     = {Contrastive classification and representation learning with probabilistic interpretation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Clustering what matters: Optimal approximation for
clustering with outliers. <em>AAAI</em>, 6666–6674. (<a
href="https://doi.org/10.1609/aaai.v37i6.25818">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Clustering with outliers is one of the most fundamental problems in Computer Science. Given a set X of n points and two numbers k and m, the clustering with outliers aims to exclude m points from X, and partition the remaining points into k clusters that minimizes a certain cost function. In this paper, we give a general approach for solving clustering with outliers, which results in a fixed-parameter tractable (FPT) algorithm in k and m (i.e., an algorithm with running time of the form f(k, m) * poly(n) for some function f), that almost matches the approximation ratio for its outlier-free counterpart. As a corollary, we obtain FPT approximation algorithms with optimal approximation ratios for k-Median and k-Means with outliers in general and Euclidean metrics. We also exhibit more applications of our approach to other variants of the problem that impose additional constraints on the clustering, such as fairness or matroid constraints.},
  archive   = {C_AAAI},
  author    = {Akanksha Agrawal and Tanmay Inamdar and Saket Saurabh and Jie Xue},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25818},
  pages     = {6666-6674},
  title     = {Clustering what matters: Optimal approximation for clustering with outliers},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Utilizing prior solutions for reward shaping and composition
in entropy-regularized reinforcement learning. <em>AAAI</em>, 6658–6665.
(<a href="https://doi.org/10.1609/aaai.v37i6.25817">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In reinforcement learning (RL), the ability to utilize prior knowledge from previously solved tasks can allow agents to quickly solve new problems. In some cases, these new problems may be approximately solved by composing the solutions of previously solved primitive tasks (task composition). Otherwise, prior knowledge can be used to adjust the reward function for a new problem, in a way that leaves the optimal policy unchanged but enables quicker learning (reward shaping). In this work, we develop a general framework for reward shaping and task composition in entropy-regularized RL. To do so, we derive an exact relation connecting the optimal soft value functions for two entropy-regularized RL problems with different reward functions and dynamics. We show how the derived relation leads to a general result for reward shaping in entropy-regularized RL. We then generalize this approach to derive an exact relation connecting optimal value functions for the composition of multiple tasks in entropy-regularized RL. We validate these theoretical contributions with experiments showing that reward shaping and task composition lead to faster learning in various settings.},
  archive   = {C_AAAI},
  author    = {Jacob Adamczyk and Argenis Arriojas and Stas Tiomkin and Rahul V. Kulkarni},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25817},
  pages     = {6658-6665},
  title     = {Utilizing prior solutions for reward shaping and composition in entropy-regularized reinforcement learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Symbolic metamodels for interpreting black-boxes using
primitive functions. <em>AAAI</em>, 6649–6657. (<a
href="https://doi.org/10.1609/aaai.v37i6.25816">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {One approach for interpreting black-box machine learning models is to find a global approximation of the model using simple interpretable functions, which is called a metamodel (a model of the model). Approximating the black-box with a metamodel can be used to 1) estimate instance-wise feature importance; 2) understand the functional form of the model; 3) analyze feature interactions. In this work, we propose a new method for finding interpretable metamodels. Our approach utilizes Kolmogorov superposition theorem, which expresses multivariate functions as a composition of univariate functions (our primitive parameterized functions). This composition can be represented in the form of a tree. Inspired by symbolic regression, we use a modified form of genetic programming to search over different tree configurations. Gradient descent (GD) is used to optimize the parameters of a given configuration. Our method is a novel memetic algorithm that uses GD not only for training numerical constants but also for the training of building blocks. Using several experiments, we show that our method outperforms recent metamodeling approaches suggested for interpreting black-boxes.},
  archive   = {C_AAAI},
  author    = {Mahed Abroshan and Saumitra Mishra and Mohammad Mahdi Khalili},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25816},
  pages     = {6649-6657},
  title     = {Symbolic metamodels for interpreting black-boxes using primitive functions},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient distributed inference of deep neural networks via
restructuring and pruning. <em>AAAI</em>, 6640–6648. (<a
href="https://doi.org/10.1609/aaai.v37i6.25815">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we consider the parallel implementation of an already-trained deep model on multiple processing nodes (a.k.a. workers). Specifically, we investigate as to how a deep model should be divided into several parallel sub-models, each of which is executed efficiently by a worker. Since latency due to synchronization and data transfer among workers negatively impacts the performance of the parallel implementation, it is desirable to have minimum interdependency among parallel sub-models. To achieve this goal, we propose to rearrange the neurons in the neural network, partition them (without changing the general topology of the neural network), and modify the weights such that the interdependency among sub-models is minimized under the computations and communications constraints of the workers while minimizing its impact on the performance of the model. We propose RePurpose, a layer-wise model restructuring and pruning technique that guarantees the performance of the overall parallelized model. To efficiently apply RePurpose, we propose an approach based on L0 optimization and the Munkres assignment algorithm. We show that, compared to the existing methods, RePurpose significantly improves the efficiency of the distributed inference via parallel implementation, both in terms of communication and computational complexity.},
  archive   = {C_AAAI},
  author    = {Afshin Abdi and Saeed Rashidi and Faramarz Fekri and Tushar Krishna},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25815},
  pages     = {6640-6648},
  title     = {Efficient distributed inference of deep neural networks via restructuring and pruning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Approximating full conformal prediction at scale via
influence functions. <em>AAAI</em>, 6631–6639. (<a
href="https://doi.org/10.1609/aaai.v37i6.25814">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Conformal prediction (CP) is a wrapper around traditional machine learning models, giving coverage guarantees under the sole assumption of exchangeability; in classification problems, a CP guarantees that the error rate is at most a chosen significance level, irrespective of whether the underlying model is misspecified. However, the prohibitive computational costs of full CP led researchers to design scalable alternatives, which alas do not attain the same guarantees or statistical power of full CP. In this paper, we use influence functions to efficiently approximate full CP. We prove that our method is a consistent approximation of full CP, and empirically show that the approximation error becomes smaller as the training set increases; e.g., for 1,000 training points the two methods output p-values that are},
  archive   = {C_AAAI},
  author    = {Javier Abad Martinez and Umang Bhatt and Adrian Weller and Giovanni Cherubin},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i6.25814},
  pages     = {6631-6639},
  title     = {Approximating full conformal prediction at scale via influence functions},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). McOmet: Multimodal fusion transformer for physical
audiovisual commonsense reasoning. <em>AAAI</em>, 6621–6629. (<a
href="https://doi.org/10.1609/aaai.v37i5.25813">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Physical commonsense reasoning is essential for building reliable and interpretable AI systems, which involves a general understanding of the physical properties and affordances of everyday objects, how these objects can be manipulated, and how they interact with others. It is fundamentally a multi-modal task, as physical properties are manifested through multiple modalities, including vision and acoustics. In this work, we present a unified framework, named Multimodal Commonsense Transformer (MCOMET), for physical audiovisual commonsense reasoning. MCOMET has two intriguing properties: i) it fully mines higher-ordered temporal relationships across modalities (e.g., pairs, triplets, and quadruplets); and ii) it restricts the cross-modal flow through the feature collection and propagation mechanism along with tight fusion bottlenecks, forcing the model to attend the most relevant parts in each modality and suppressing the dissemination of noisy information. We evaluate our model on a very recent public benchmark, PACS. Results show that MCOMET significantly outperforms a variety of strong baselines, revealing powerful multi-modal commonsense reasoning capabilities.},
  archive   = {C_AAAI},
  author    = {Daoming Zong and Shiliang Sun},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25813},
  pages     = {6621-6629},
  title     = {McOmet: Multimodal fusion transformer for physical audiovisual commonsense reasoning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning to select prototypical parts for interpretable
sequential data modeling. <em>AAAI</em>, 6612–6620. (<a
href="https://doi.org/10.1609/aaai.v37i5.25812">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Prototype-based interpretability methods provide intuitive explanations of model prediction by comparing samples to a reference set of memorized exemplars or typical representatives in terms of similarity. In the field of sequential data modeling, similarity calculations of prototypes are usually based on encoded representation vectors. However, due to highly recursive functions, there is usually a non-negligible disparity between the prototype-based explanations and the original input. In this work, we propose a Self-Explaining Selective Model (SESM) that uses a linear combination of prototypical concepts to explain its own predictions. The model employs the idea of case-based reasoning by selecting sub-sequences of the input that mostly activate different concepts as prototypical parts, which users can compare to sub-sequences selected from different example inputs to understand model decisions. For better interpretability, we design multiple constraints including diversity, stability, and locality as training objectives. Extensive experiments in different domains demonstrate that our method exhibits promising interpretability and competitive accuracy.},
  archive   = {C_AAAI},
  author    = {Yifei Zhang and Neng Gao and Cunqing Ma},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25812},
  pages     = {6612-6620},
  title     = {Learning to select prototypical parts for interpretable sequential data modeling},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Quality-aware self-training on differentiable synthesis of
rare relational data. <em>AAAI</em>, 6602–6611. (<a
href="https://doi.org/10.1609/aaai.v37i5.25811">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Data scarcity is a very common real-world problem that poses a major challenge to data-driven analytics. Although a lot of data-balancing approaches have been proposed to mitigate this problem, they may drop some useful information or fall into the overfitting problem. Generative Adversarial Network (GAN) based data synthesis methods can alleviate such a problem but lack of quality control over the generated samples. Moreover, the latent associations between the attribute set and the class labels in a relational data cannot be easily captured by a vanilla GAN. In light of this, we introduce an end-to-end self-training scheme (namely, Quality-Aware Self-Training) for rare relational data synthesis, which generates labeled synthetic data via pseudo labeling on GAN-based synthesis. We design a semantic pseudo labeling module to first control the quality of the generated features/samples, then calibrate their semantic labels via a classifier committee consisting of multiple pre-trained shallow classifiers. The high-confident generated samples with calibrated pseudo labels are then fed into a semantic classification network as augmented samples for self-training. We conduct extensive experiments on 20 benchmark datasets of different domains, including 14 industrial datasets. The results show that our method significantly outperforms state-of-the-art methods, including two recent GAN-based data synthesis schemes. Codes are available at https://github.com/yaxinhou/QAST.},
  archive   = {C_AAAI},
  author    = {Chongsheng Zhang and Yaxin Hou and Ke Chen and Shuang Cao and Gaojuan Fan and Ji Liu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25811},
  pages     = {6602-6611},
  title     = {Quality-aware self-training on differentiable synthesis of rare relational data},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DNG: Taxonomy expansion by exploring the intrinsic directed
structure on non-gaussian space. <em>AAAI</em>, 6593–6601. (<a
href="https://doi.org/10.1609/aaai.v37i5.25810">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Taxonomy expansion is the process of incorporating a large number of additional nodes (i.e., &#39;&#39;queries&#39;&#39;) into an existing taxonomy (i.e., &#39;&#39;seed&#39;&#39;), with the most important step being the selection of appropriate positions for each query. Enormous efforts have been made by exploring the seed&#39;s structure. However, existing approaches are deficient in their mining of structural information in two ways: poor modeling of the hierarchical semantics and failure to capture directionality of the is-a relation. This paper seeks to address these issues by explicitly denoting each node as the combination of inherited feature (i.e., structural part) and incremental feature (i.e., supplementary part). Specifically, the inherited feature originates from &#39;&#39;parent&#39;&#39; nodes and is weighted by an inheritance factor. With this node representation, the hierarchy of semantics in taxonomies (i.e., the inheritance and accumulation of features from &#39;&#39;parent&#39;&#39; to &#39;&#39;child&#39;&#39;) could be embodied. Additionally, based on this representation, the directionality of the is-a relation could be easily translated into the irreversible inheritance of features. Inspired by the Darmois-Skitovich Theorem, we implement this irreversibility by a non-Gaussian constraint on the supplementary feature. A log-likelihood learning objective is further utilized to optimize the proposed model (dubbed DNG), whereby the required non-Gaussianity is also theoretically ensured. Extensive experimental results on two real-world datasets verify the superiority of DNG relative to several strong baselines.},
  archive   = {C_AAAI},
  author    = {Songlin Zhai and Weiqing Wang and Yuanfang Li and Yuan Meng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25810},
  pages     = {6593-6601},
  title     = {DNG: Taxonomy expansion by exploring the intrinsic directed structure on non-gaussian space},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Visually grounded commonsense knowledge acquisition.
<em>AAAI</em>, 6583–6592. (<a
href="https://doi.org/10.1609/aaai.v37i5.25809">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Large-scale commonsense knowledge bases empower a broad range of AI applications, where the automatic extraction of commonsense knowledge (CKE) is a fundamental and challenging problem. CKE from text is known for suffering from the inherent sparsity and reporting bias of commonsense in text. Visual perception, on the other hand, contains rich commonsense knowledge about real-world entities, e.g., (person, can_hold, bottle), which can serve as promising sources for acquiring grounded commonsense knowledge. In this work, we present CLEVER, which formulates CKE as a distantly supervised multi-instance learning problem, where models learn to summarize commonsense relations from a bag of images about an entity pair without any human annotation on image instances. To address the problem, CLEVER leverages vision-language pre-training models for deep understanding of each image in the bag, and selects informative instances from the bag to summarize commonsense entity relations via a novel contrastive attention mechanism. Comprehensive experimental results in held-out and human evaluation show that CLEVER can extract commonsense knowledge in promising quality, outperforming pre-trained language model-based methods by 3.9 AUC and 6.4 mAUC points. The predicted commonsense scores show strong correlation with human judgment with a 0.78 Spearman coefficient. Moreover, the extracted commonsense can also be grounded into images with reasonable interpretability. The data and codes can be obtained at https://github.com/thunlp/CLEVER.},
  archive   = {C_AAAI},
  author    = {Yuan Yao and Tianyu Yu and Ao Zhang and Mengdi Li and Ruobing Xie and Cornelius Weber and Zhiyuan Liu and Hai-Tao Zheng and Stefan Wermter and Tat-Seng Chua and Maosong Sun},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25809},
  pages     = {6583-6592},
  title     = {Visually grounded commonsense knowledge acquisition},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient extraction of EL-ontology deductive modules.
<em>AAAI</em>, 6575–6582. (<a
href="https://doi.org/10.1609/aaai.v37i5.25808">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Because widely used real-world ontologies are often complex and large, one important challenge has emerged: designing tools for users to focus on sub-ontologies corresponding to their specific interests. To this end, various modules have been introduced to provide concise ontology views. This work concentrates on extracting deductive modules that preserve logical entailment over a given vocabulary. Existing deductive module proposals are either inefficient from a computing point of view or unsatisfactory from a quality point of view because the modules extracted are not concise enough. For example, minimal modules guarantee the most concise results, but their computation is highly time-consuming, while ⊥⊤∗-modules are easy to compute but usually contain many redundant items. To overcome computation cost and lack of quality, we propose to compute two kinds of deductive modules called pseudo-minimal modules and complete modules for EL-ontology. Our deductive module definitions rely on associating a tree representation with an ontology, and their computation is based on SAT encoding. Our experiments on real-world ontologies show that our pseudo-minimal modules are indeed minimal modules in almost all cases (98.9\%), and computing pseudo-minimal modules is more efficient (99.79 times faster on average) than the state-of-the-art method Zoom for computing minimal modules. Also, our complete modules are more compact than ⊥⊤∗-modules, but their computation time remains comparable. Finally, note that our proposal applies to EL-ontologies while Zoom only works for EL-terminologies.},
  archive   = {C_AAAI},
  author    = {Hui Yang and Yue Ma and Nicole Bidoit},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25808},
  pages     = {6575-6582},
  title     = {Efficient extraction of EL-ontology deductive modules},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Materialisation-based reasoning in DatalogMTL with bounded
intervals. <em>AAAI</em>, 6566–6574. (<a
href="https://doi.org/10.1609/aaai.v37i5.25807">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {DatalogMTL is a powerful extension of Datalog with operators from metric temporal logic (MTL), which has received significant attention in recent years. In this paper, we investigate materialisation-based reasoning (a.k.a. forward chaining) in the context of DatalogMTL programs and datasets with bounded intervals, where partial representations of the canonical model are obtained through successive rounds of rule applications. Although materialisation does not naturally terminate in this setting, it is known that the structure of canonical models is ultimately periodic. Our first contribution in this paper is a detailed analysis of the periodic structure of canonical models; in particular, we formulate saturation conditions whose satisfaction by a partial materialisation implies an ability to recover the full canonical model via unfolding; this allows us to compute the actual periods describing the repeating parts of the canonical model as well as to establish concrete bounds on the number of rounds of rule applications required to achieve saturation. Based on these theoretical results, we propose a practical reasoning algorithm where saturation can be efficiently detected as materialisation progresses, and where the relevant periods used to evaluate entailment of queries via unfolding are efficiently computed. We have implemented our algorithm and our experiments suggest that our approach is both scalable and robust.},
  archive   = {C_AAAI},
  author    = {Przemysław A. Wałęga and Michał Zawidzki and Dingmin Wang and Bernardo Cuenca Grau},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25807},
  pages     = {6566-6574},
  title     = {Materialisation-based reasoning in DatalogMTL with bounded intervals},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Neurosymbolic reasoning and learning with restricted
boltzmann machines. <em>AAAI</em>, 6558–6565. (<a
href="https://doi.org/10.1609/aaai.v37i5.25806">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Knowledge representation and reasoning in neural networks has been a long-standing endeavour which has attracted much attention recently. The principled integration of reasoning and learning in neural networks is a main objective of the area of neurosymbolic Artificial Intelligence. In this paper, a neurosymbolic system is introduced that can represent any propositional logic formula. A proof of equivalence is presented showing that energy minimization in restricted Boltzmann machines corresponds to logical reasoning. We demonstrate the application of our approach empirically on logical reasoning and learning from data and knowledge. Experimental results show that reasoning can be performed effectively for a class of logical formulae. Learning from data and knowledge is also evaluated in comparison with learning of logic programs using neural networks. The results show that our approach can improve on state-of-the-art neurosymbolic systems. The theorems and empirical results presented in this paper are expected to reignite the research on the use of neural networks as massively-parallel models for logical reasoning and promote the principled integration of reasoning and learning in deep networks.},
  archive   = {C_AAAI},
  author    = {Son N. Tran and Artur d&#39;Avila Garcez},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25806},
  pages     = {6558-6565},
  title     = {Neurosymbolic reasoning and learning with restricted boltzmann machines},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On undisputed sets in abstract argumentation. <em>AAAI</em>,
6550–6557. (<a href="https://doi.org/10.1609/aaai.v37i5.25805">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We introduce the notion of an undisputed set for abstract argumentation frameworks, which is a conflict-free set of arguments, such that its reduct contains no non-empty admissible set. We show that undisputed sets, and the stronger notion of strongly undisputed sets, provide a meaningful approach to weaken admissibility and deal with the problem of attacks from self-attacking arguments, in a similar manner as the recently introduced notion of weak admissibility. We investigate the properties of our new semantical notions and show certain relationships to classical semantics, in particular that undisputed sets are a generalisation of preferred extensions and strongly undisputed sets are a generalisation of stable extensions. We also investigate the computational complexity of standard reasoning tasks with these new notions and show that they lie on the second and third level of the polynomial hierarchy, respectively.},
  archive   = {C_AAAI},
  author    = {Matthias Thimm},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25805},
  pages     = {6550-6557},
  title     = {On undisputed sets in abstract argumentation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning to break symmetries for efficient optimization in
answer set programming. <em>AAAI</em>, 6541–6549. (<a
href="https://doi.org/10.1609/aaai.v37i5.25804">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The ability to efficiently solve hard combinatorial optimization problems is a key prerequisite to various applications of declarative programming paradigms. Symmetries in solution candidates pose a significant challenge to modern optimization algorithms since the enumeration of such candidates might substantially reduce their performance. This paper proposes a novel approach using Inductive Logic Programming (ILP) to lift symmetry-breaking constraints for optimization problems modeled in Answer Set Programming (ASP). Given an ASP encoding with optimization statements and a set of small representative instances, our method augments ground ASP programs with auxiliary normal rules enabling the identification of symmetries using existing tools, like SBASS. Then, the obtained symmetries are lifted to first-order constraints with ILP. We prove the correctness of our method and evaluate it on real-world optimization problems from the domain of automated configuration. Our experiments show significant improvements of optimization performance due to the learned first-order constraints.},
  archive   = {C_AAAI},
  author    = {Alice Tarzariol and Martin Gebser and Konstantin Schekotihin and Mark Law},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25804},
  pages     = {6541-6549},
  title     = {Learning to break symmetries for efficient optimization in answer set programming},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-aspect explainable inductive relation prediction by
sentence transformer. <em>AAAI</em>, 6533–6540. (<a
href="https://doi.org/10.1609/aaai.v37i5.25803">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent studies on knowledge graphs (KGs) show that path-based methods empowered by pre-trained language models perform well in the provision of inductive and explainable relation predictions. In this paper, we introduce the concepts of relation path coverage and relation path confidence to filter out unreliable paths prior to model training to elevate the model performance. Moreover, we propose Knowledge Reasoning Sentence Transformer (KRST) to predict inductive relations in KGs. KRST is designed to encode the extracted reliable paths in KGs, allowing us to properly cluster paths and provide multi-aspect explanations. We conduct extensive experiments on three real-world datasets. The experimental results show that compared to SOTA models, KRST achieves the best performance in most transductive and inductive test cases (4 of 6), and in 11 of 12 few-shot test cases.},
  archive   = {C_AAAI},
  author    = {Zhixiang Su and Di Wang and Chunyan Miao and Lizhen Cui},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25803},
  pages     = {6533-6540},
  title     = {Multi-aspect explainable inductive relation prediction by sentence transformer},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Implementing bounded revision via lexicographic revision and
c-revision. <em>AAAI</em>, 6525–6532. (<a
href="https://doi.org/10.1609/aaai.v37i5.25802">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {New information in the context of real life settings usually is accompanied by some kind of supplementary information that indicates context, reliability, or expertise of the information&#39;s source. Bounded Revision (BR) displays an iterated belief revision mechanism that takes as input a new information accompanied by a reference sentence acting as supplementary information, which specifies the depth with which the new input shall be integrated in the posterior belief state. The reference sentence specifies which worlds in the prior belief state are affected by the change mechanism. We show that Bounded Revision can be characterized by three simple, yet elegant postulates and corresponds to a special case of a lexicographic revision, which inherits all relevant features of BR. Furthermore, we present methodological implementations of BR including conditional revision with c-revisions, making it directly usable for conditional revision tools.},
  archive   = {C_AAAI},
  author    = {Meliha Sezgin and Gabriele Kern-Isberner},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25802},
  pages     = {6525-6532},
  title     = {Implementing bounded revision via lexicographic revision and C-revision},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Editing boolean classifiers: A belief change perspective.
<em>AAAI</em>, 6516–6524. (<a
href="https://doi.org/10.1609/aaai.v37i5.25801">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper is about editing Boolean classifiers, i.e., determining how a Boolean classifier should be modified when new pieces of evidence must be incorporated. Our main goal is to delineate what are the rational ways of making such edits. This goes through a number of rationality postulates inspired from those considered so far for belief revision. We give a representation theorem and present some families of edit operators satisfying the postulates.},
  archive   = {C_AAAI},
  author    = {Nicolas Schwind and Katsumi Inoue and Pierre Marquis},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25801},
  pages     = {6516-6524},
  title     = {Editing boolean classifiers: A belief change perspective},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning interpretable temporal properties from positive
examples only. <em>AAAI</em>, 6507–6515. (<a
href="https://doi.org/10.1609/aaai.v37i5.25800">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider the problem of explaining the temporal behavior of black-box systems using human-interpretable models. Following recent research trends, we rely on the fundamental yet interpretable models of deterministic finite automata (DFAs) and linear temporal logic (LTL_f) formulas. In contrast to most existing works for learning DFAs and LTL_f formulas, we consider learning from only positive examples. Our motivation is that negative examples are generally difficult to observe, in particular, from black-box systems. To learn meaningful models from positive examples only, we design algorithms that rely on conciseness and language minimality of models as regularizers. Our learning algorithms are based on two approaches: a symbolic and a counterexample-guided one. The symbolic approach exploits an efficient encoding of language minimality as a constraint satisfaction problem, whereas the counterexample-guided one relies on generating suitable negative examples to guide the learning. Both approaches provide us with effective algorithms with minimality guarantees on the learned models. To assess the effectiveness of our algorithms, we evaluate them on a few practical case studies.},
  archive   = {C_AAAI},
  author    = {Rajarshi Roy and Jean-Raphaël Gaglione and Nasim Baharisangari and Daniel Neider and Zhe Xu and Ufuk Topcu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25800},
  pages     = {6507-6515},
  title     = {Learning interpretable temporal properties from positive examples only},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-level wavelet mapping correlation for statistical
dependence measurement: Methodology and performance. <em>AAAI</em>,
6499–6506. (<a href="https://doi.org/10.1609/aaai.v37i5.25799">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose a new criterion for measuring dependence between two real variables, namely, Multi-level Wavelet Mapping Correlation (MWMC). MWMC can capture the nonlinear dependencies between variables by measuring their correlation under different levels of wavelet mappings. We show that the empirical estimate of MWMC converges exponentially to its population quantity. To support independence test better with MWMC, we further design a permutation test based on MWMC and prove that our test can not only control the type I error rate (the rate of false positives) well but also ensure that the type II error rate (the rate of false negatives) is upper bounded by O(1/n) (n is the sample size) with finite permutations. By extensive experiments on (conditional) independence tests and causal discovery, we show that our method outperforms existing independence test methods.},
  archive   = {C_AAAI},
  author    = {Yixin Ren and Hao Zhang and Yewei Xia and Jihong Guan and Shuigeng Zhou},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25799},
  pages     = {6499-6506},
  title     = {Multi-level wavelet mapping correlation for statistical dependence measurement: Methodology and performance},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Distributed spectrum-based fault localization.
<em>AAAI</em>, 6491–6498. (<a
href="https://doi.org/10.1609/aaai.v37i5.25798">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Spectrum-Based Fault Localization (SFL) is a popular approach for diagnosing faulty systems. SFL algorithms are inherently centralized, where observations are collected and analyzed by a single diagnoser. Applying SFL to diagnose distributed systems is challenging, especially when communication is costly and there are privacy concerns. We propose two SFL-based algorithms that are designed for distributed systems: one for diagnosing a single faulty component and one for diagnosing multiple faults. We analyze these algorithms theoretically and empirically. Our analysis shows that the distributed SFL algorithms we developed output identical diagnoses to centralized SFL while preserving privacy.},
  archive   = {C_AAAI},
  author    = {Avraham Natan and Roni Stern and Meir Kalech},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25798},
  pages     = {6491-6498},
  title     = {Distributed spectrum-based fault localization},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient answer enumeration in description logics with
functional roles. <em>AAAI</em>, 6483–6490. (<a
href="https://doi.org/10.1609/aaai.v37i5.25797">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the enumeration of answers to ontology-mediated queries when the ontology is formulated in a description logic that supports functional roles and the query is a CQ. In particular, we show that enumeration is possible with linear preprocessing and constant delay when a certain extension of the CQ (pertaining to functional roles) is acyclic and free-connex acyclic. This holds both for complete answers and for partial answers. We provide matching lower bounds for the case where the query is self-join free.},
  archive   = {C_AAAI},
  author    = {Carsten Lutz and Marcin Przybyłko},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25797},
  pages     = {6483-6490},
  title     = {Efficient answer enumeration in description logics with functional roles},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automated verification of propositional agent abstraction
for classical planning via CTLK model checking. <em>AAAI</em>,
6475–6482. (<a href="https://doi.org/10.1609/aaai.v37i5.25796">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Abstraction has long been an effective mechanism to help find a solution in classical planning. Agent abstraction, based on the situation calculus, is a promising explainable framework for agent planning, yet its automation is still far from being tackled. In this paper, we focus on a propositional version of agent abstraction designed for finite-state systems. We investigate the automated verification of the existence of propositional agent abstraction, given a finite-state system and a mapping indicating an abstraction for it. By formalizing sound, complete and deterministic properties of abstractions in a general framework, we show that the verification task can be reduced to the task of model checking against CTLK specifications. We implemented a prototype system, and validated the viability of our approach through experimentation on several domains from classical planning.},
  archive   = {C_AAAI},
  author    = {Kailun Luo},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25796},
  pages     = {6475-6482},
  title     = {Automated verification of propositional agent abstraction for classical planning via CTLK model checking},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DHGE: Dual-view hyper-relational knowledge graph embedding
for link prediction and entity typing. <em>AAAI</em>, 6467–6474. (<a
href="https://doi.org/10.1609/aaai.v37i5.25795">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the field of representation learning on knowledge graphs (KGs), a hyper-relational fact consists of a main triple and several auxiliary attribute-value descriptions, which is considered more comprehensive and specific than a triple-based fact. However, currently available hyper-relational KG embedding methods in a single view are limited in application because they weaken the hierarchical structure that represents the affiliation between entities. To overcome this limitation, we propose a dual-view hyper-relational KG structure (DH-KG) that contains a hyper-relational instance view for entities and a hyper-relational ontology view for concepts that are abstracted hierarchically from the entities. This paper defines link prediction and entity typing tasks on DH-KG for the first time and constructs two DH-KG datasets, JW44K-6K, extracted from Wikidata, and HTDM based on medical data. Furthermore, we propose DHGE, a DH-KG embedding model based on GRAN encoders, HGNNs, and joint learning. DHGE outperforms baseline models on DH-KG, according to experimental results. Finally, we provide an example of how this technology can be used to treat hypertension. Our model and new datasets are publicly available.},
  archive   = {C_AAAI},
  author    = {Haoran Luo and Haihong E and Ling Tan and Gengxian Zhou and Tianyu Yao and Kaiyang Wan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25795},
  pages     = {6467-6474},
  title     = {DHGE: Dual-view hyper-relational knowledge graph embedding for link prediction and entity typing},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Copyright-certified distillation dataset: Distilling one
million coins into one bitcoin with your private key. <em>AAAI</em>,
6458–6466. (<a href="https://doi.org/10.1609/aaai.v37i5.25794">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The rapid development of neural network dataset distillation in recent years has provided new ideas in many areas such as continuous learning, neural network architecture search and privacy preservation. Dataset distillation is a very effective method to distill large training datasets into small data, thus ensuring that the test accuracy of models trained on their synthesized small datasets matches that of models trained on the full dataset. Thus, dataset distillation itself is commercially valuable, not only for reducing training costs, but also for compressing storage costs and significantly reducing the training costs of deep learning. However, copyright protection for dataset distillation has not been proposed yet, so we propose the first method to protect intellectual property by embedding watermarks in the dataset distillation process. Our approach not only popularizes the dataset distillation technique, but also authenticates the ownership of the distilled dataset by the models trained on that distilled dataset.},
  archive   = {C_AAAI},
  author    = {Tengjun Liu and Ying Chen and Wanxuan Gu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25794},
  pages     = {6458-6466},
  title     = {Copyright-certified distillation dataset: Distilling one million coins into one bitcoin with your private key},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Two views of constrained differential privacy: Belief
revision and update. <em>AAAI</em>, 6450–6457. (<a
href="https://doi.org/10.1609/aaai.v37i5.25793">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we provide two views of constrained differential private (DP) mechanisms. The first one is as belief revision. A constrained DP mechanism is obtained by standard probabilistic conditioning, and hence can be naturally implemented by Monte Carlo algorithms. The other is as belief update. A constrained DP is defined according to l2-distance minimization postprocessing or projection and hence can be naturally implemented by optimization algorithms. The main advantage of these two perspectives is that we can make full use of the machinery of belief revision and update to show basic properties for constrained differential privacy especially some important new composition properties. Within the framework established in this paper, constrained DP algorithms in the literature can be classified either as belief revision or belief update. At the end of the paper, we demonstrate their differences especially in utility on a couple of scenarios.},
  archive   = {C_AAAI},
  author    = {Likang Liu and Keke Sun and Chunlai Zhou and Yuan Feng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25793},
  pages     = {6450-6457},
  title     = {Two views of constrained differential privacy: Belief revision and update},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FASTDIAGP: An algorithm for parallelized direct diagnosis.
<em>AAAI</em>, 6442–6449. (<a
href="https://doi.org/10.1609/aaai.v37i5.25792">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Constraint-based applications attempt to identify a solution that meets all defined user requirements. If the requirements are inconsistent with the underlying constraint set, algorithms that compute diagnoses for inconsistent constraints should be implemented to help users resolve the “no solution could be found” dilemma. FastDiag is a typical direct diagnosis algorithm that supports diagnosis calculation without pre-determining conflicts. However, this approach faces runtime performance issues, especially when analyzing complex and large-scale knowledge bases. In this paper, we propose a novel algorithm, so-called FastDiagP, which is based on the idea of speculative programming. This algorithm extends FastDiag by integrating a parallelization mechanism that anticipates and pre-calculates consistency checks requested by FastDiag. This mechanism helps to provide consistency checks with fast answers and boosts the algorithm’s runtime performance. The performance improvements of our proposed algorithm have been shown through empirical results using the Linux-2.6.3.33 configuration knowledge base.},
  archive   = {C_AAAI},
  author    = {Viet-Man Le and Cristian Vidal Silva and Alexander Felfernig and David Benavides and José Galindo and Thi Ngoc Trang Tran},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25792},
  pages     = {6442-6449},
  title     = {FASTDIAGP: An algorithm for parallelized direct diagnosis},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Common knowledge of abstract groups. <em>AAAI</em>,
6434–6441. (<a href="https://doi.org/10.1609/aaai.v37i5.25791">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Epistemic logics typically talk about knowledge of individual agents or groups of explicitly listed agents. Often, however, one wishes to express knowledge of groups of agents specified by a given property, as in ‘it is common knowledge among economists’. We introduce such a logic of common knowledge, which we term abstract-group epistemic logic (AGEL). That is, AGEL features a common knowledge operator for groups of agents given by concepts in a separate agent logic that we keep generic, with one possible agent logic being ALC. We show that AGEL is EXPTIME-complete, with the lower bound established by reduction from standard group epistemic logic, and the upper bound by a satisfiability-preserving embedding into the full µ-calculus. Further main results include a finite model property (not enjoyed by the full µ-calculus) and a complete axiomatization.},
  archive   = {C_AAAI},
  author    = {Merlin Humml and Lutz Schröder},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25791},
  pages     = {6434-6441},
  title     = {Common knowledge of abstract groups},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Relational program synthesis with numerical reasoning.
<em>AAAI</em>, 6425–6433. (<a
href="https://doi.org/10.1609/aaai.v37i5.25790">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Learning programs with numerical values is fundamental to many AI applications, including bio-informatics and drug design. However, current program synthesis approaches struggle to learn programs with numerical values. An especially difficult problem is learning continuous values from multiple examples, such as intervals. To overcome this limitation, we introduce an inductive logic programming approach which combines relational learning with numerical reasoning. Our approach, which we call NumSynth, uses satisfiability modulo theories solvers to efficiently learn programs with numerical values. Our approach can identify numerical values in linear arithmetic fragments, such as real difference logic, and from infinite domains, such as real numbers or integers. Our experiments on four diverse domains, including game playing and program synthesis, show that our approach can (i) learn programs with numerical values from linear arithmetical reasoning, and (ii) outperform existing approaches in terms of predictive accuracies and learning times.},
  archive   = {C_AAAI},
  author    = {Céline Hocquette and Andrew Cropper},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25790},
  pages     = {6425-6433},
  title     = {Relational program synthesis with numerical reasoning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Conditional syntax splitting for non-monotonic inference
operators. <em>AAAI</em>, 6416–6424. (<a
href="https://doi.org/10.1609/aaai.v37i5.25789">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Syntax splitting is a property of inductive inference operators that ensures we can restrict our attention to parts of the conditional belief base that share atoms with a given query. To apply syntax splitting, a conditional belief base needs to consist of syntactically disjoint conditionals. This requirement is often too strong in practice, as conditionals might share atoms. In this paper we introduce the concept of conditional syntax splitting, inspired by the notion of conditional independence as known from probability theory. We show that lexicographic inference and system W satisfy conditional syntax splitting, and connect conditional syntax splitting to several known properties from the literature on non-monotonic reasoning, including the drowning effect.},
  archive   = {C_AAAI},
  author    = {Jesse Heyninck and Gabriele Kern-Isberner and Thomas Meyer and Jonas Philipp Haldimann and Christoph Beierle},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25789},
  pages     = {6416-6424},
  title     = {Conditional syntax splitting for non-monotonic inference operators},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Characterizing structural hardness of logic programs: What
makes cycles and reachability hard for treewidth? <em>AAAI</em>,
6407–6415. (<a href="https://doi.org/10.1609/aaai.v37i5.25788">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Answer Set Programming (ASP) is a problem modeling and solving framework for several problems in KR with growing industrial applications. Also for studies of computational complexity and deeper insights into the hardness and its sources, ASP has been attracting researchers for many years. These studies resulted in fruitful characterizations in terms of complexity classes, fine-grained insights in form of dichotomy-style results, as well as detailed parameterized complexity landscapes. Recently, this lead to a novel result establishing that for the measure treewidth, which captures structural density of a program, the evaluation of the well-known class of normal programs is expected to be slightly harder than deciding satisfiability (SAT). However, it is unclear how to utilize this structural power of ASP. This paper deals with a novel reduction from SAT to normal ASP that goes beyond well-known encodings: We explicitly utilize the structural power of ASP, whereby we sublinearly decrease the treewidth, which probably cannot be significantly improved. Then, compared to existing results, this characterizes hardness in a fine-grained way by establishing the required functional dependency of the dependency graph’s cycle length (SCC size) on the treewidth.},
  archive   = {C_AAAI},
  author    = {Markus Hecher},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25788},
  pages     = {6407-6415},
  title     = {Characterizing structural hardness of logic programs: What makes cycles and reachability hard for treewidth?},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MAPS-KB: A million-scale probabilistic simile knowledge
base. <em>AAAI</em>, 6398–6406. (<a
href="https://doi.org/10.1609/aaai.v37i5.25787">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The ability to understand and generate similes is an imperative step to realize human-level AI. However, there is still a considerable gap between machine intelligence and human cognition in similes, since deep models based on statistical distribution tend to favour high-frequency similes. Hence, a large-scale symbolic knowledge base of similes is required, as it contributes to the modeling of diverse yet unpopular similes while facilitating additional evaluation and reasoning. To bridge the gap, we propose a novel framework for large-scale simile knowledge base construction, as well as two probabilistic metrics which enable an improved understanding of simile phenomena in natural language. Overall, we construct MAPS-KB, a million-scale probabilistic simile knowledge base, covering 4.3 million triplets over 0.4 million terms from 70 GB corpora. We conduct sufficient experiments to justify the effectiveness and necessity of the methods of our framework. We also apply MAPS-KB on three downstream tasks to achieve state-of-the-art performance, further demonstrating the value of MAPS-KB. Resources of MAPS-KB are publicly available at https://github.com/Abbey4799/MAPS-KB.},
  archive   = {C_AAAI},
  author    = {Qianyu He and Xintao Wang and Jiaqing Liang and Yanghua Xiao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25787},
  pages     = {6398-6406},
  title     = {MAPS-KB: A million-scale probabilistic simile knowledge base},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Finite based contraction and expansion via models.
<em>AAAI</em>, 6389–6397. (<a
href="https://doi.org/10.1609/aaai.v37i5.25786">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose a new paradigm for Belief Change in which the new information is represented as sets of models, while the agent&#39;s body of knowledge is represented as a finite set of formulae, that is, a finite base. The focus on finiteness is crucial when we consider limited agents and reasoning algorithms. Moreover, having the input as arbitrary set of models is more general than the usual treatment of formulas as input. In this setting, we define new Belief Change operations akin to traditional expansion and contraction, and we identify the rationality postulates that emerge due to the finite representability requirement. We also analyse different logics concerning compatibility with our framework.},
  archive   = {C_AAAI},
  author    = {Ricardo Guimarães and Ana Ozaki and Jandson S. Ribeiro},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25786},
  pages     = {6389-6397},
  title     = {Finite based contraction and expansion via models},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GANTEE: Generative adversarial network for taxonomy
enterance evaluation. <em>AAAI</em>, 6380–6388. (<a
href="https://doi.org/10.1609/aaai.v37i5.25785">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Taxonomy is formulated as directed acyclic graphs or trees of concepts that support many downstream tasks. Many new coming concepts need to be added to an existing taxonomy. The traditional taxonomy expansion task aims only at finding the best position for new coming concepts in the existing taxonomy. However, they have two drawbacks when being applied to the real-scenarios. The previous methods suffer from low-efficiency since they waste much time when most of the new coming concepts are indeed noisy concepts. They also suffer from low-effectiveness since they collect training samples only from the existing taxonomy, which limits the ability of the model to mine more hypernym-hyponym relationships among real concepts. This paper proposes a pluggable framework called Generative Adversarial Network for Taxonomy Entering Evaluation (GANTEE) to alleviate these drawbacks. A generative adversarial network is designed in this framework by discriminative models to alleviate the first drawback and the generative model to alleviate the second drawback. Two discriminators are used in GANTEE to provide long-term and short-term rewards, respectively. Moreover, to further improve the efficiency, pre-trained language models are used to retrieve the representation of the concepts quickly. The experiments on three real-world large-scale datasets with two different languages show that GANTEE improves the performance of the existing taxonomy expansion methods in both effectiveness and efficiency.},
  archive   = {C_AAAI},
  author    = {Zhouhong Gu and Sihang Jiang and Jingping Liu and Yanghua Xiao and Hongwei Feng and Zhixu Li and Jiaqing Liang and Zhong Jian},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25785},
  pages     = {6380-6388},
  title     = {GANTEE: Generative adversarial network for taxonomy enterance evaluation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). General acyclicity and cyclicity notions for the disjunctive
skolem chase. <em>AAAI</em>, 6372–6379. (<a
href="https://doi.org/10.1609/aaai.v37i5.25784">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The disjunctive skolem chase is a sound, complete, and potentially non-terminating procedure for solving boolean conjunctive query entailment over knowledge bases of disjunctive existential rules. We develop novel acyclicity and cyclicity notions for this procedure; that is, we develop sufficient conditions to determine chase termination and non-termination. Our empirical evaluation shows that our novel notions are significantly more general than existing criteria.},
  archive   = {C_AAAI},
  author    = {Lukas Gerlach and David Carral},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25784},
  pages     = {6372-6379},
  title     = {General acyclicity and cyclicity notions for the disjunctive skolem chase},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Inconsistent cores for ASP: The perks and perils of
non-monotonicity. <em>AAAI</em>, 6363–6371. (<a
href="https://doi.org/10.1609/aaai.v37i5.25783">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Answer Set Programming (ASP) is a prominent modeling and solving framework. An inconsistent core (IC) of an ASP program is an inconsistent subset of rules. In the case of inconsistent programs, a smallest or subset-minimal IC contains crucial rules for the inconsistency. In this work, we study fnding minimal ICs of ASP programs and key fragments from a complexity-theoretic perspective. Interestingly, due to ASP’s non-monotonic behavior, also consistent programs admit ICs. It turns out that there is an entire landscape of problems involving ICs with a diverse range of complexities up to the fourth level of the Polynomial Hierarchy. Deciding the existence of an IC is, already for tight programs, on the second level of the Polynomial Hierarchy. Furthermore, we give encodings for IC-related problems on the fragment of tight programs and illustrate feasibility on small instance sets.},
  archive   = {C_AAAI},
  author    = {Johannes K. Fichte and Markus Hecher and Stefan Szeider},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25783},
  pages     = {6363-6371},
  title     = {Inconsistent cores for ASP: The perks and perils of non-monotonicity},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Untangled: A complete dynamic topological logic.
<em>AAAI</em>, 6355–6362. (<a
href="https://doi.org/10.1609/aaai.v37i5.25782">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Dynamical systems are general models of change or movement over time with a broad area of applicability to many branches of science, including computer science and AI. Dynamic topological logic (DTL) is a formal framework for symbolic reasoning about dynamical systems. DTL can express various liveness and reachability conditions on such systems, but has the drawback that the only known axiomatisation requires an extended language. In this paper, we consider dynamic topological logic restricted to the class of scattered spaces. Scattered spaces appear in the context of computational logic as they provide semantics for provability and enjoy definable fixed points. We exhibit the first sound and complete dynamic topological logic in the original language of DTL. In particular, we show that the version of DTL based on the class of scattered spaces is finitely axiomatisable, and that the natural axiomatisation is sound and complete.},
  archive   = {C_AAAI},
  author    = {David Fernández-Duque and Yoàv Montacute},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25782},
  pages     = {6355-6362},
  title     = {Untangled: A complete dynamic topological logic},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Monitoring arithmetic temporal properties on finite traces.
<em>AAAI</em>, 6346–6354. (<a
href="https://doi.org/10.1609/aaai.v37i5.25781">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study monitoring of linear-time arithmetic properties against finite traces generated by an unknown dynamic system. The monitoring state is determined by considering at once the trace prefix seen so far, and all its possible finite-length, future continuations. This makes monitoring at least as hard as satisfiability and validity. Traces consist of finite sequences of assignments of a fixed set of variables to numerical values. Properties are specified in a logic we call ALTLf, combining LTLf (LTL on finite traces) with linear arithmetic constraints that may carry lookahead, i.e., variables may be compared over multiple instants of the trace. While the monitoring problem for this setting is undecidable in general, we show decidability for (a) properties without lookahead, and (b) properties with lookahead that satisfy the abstract, semantic condition of finite summary, studied before in the context of model checking. We then single out concrete, practically relevant classes of constraints guaranteeing finite summary. Feasibility is witnessed by a prototype implementation.},
  archive   = {C_AAAI},
  author    = {Paolo Felli and Marco Montali and Fabio Patrizi and Sarah Winkler},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25781},
  pages     = {6346-6354},
  title     = {Monitoring arithmetic temporal properties on finite traces},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Splitting answer set programs with respect to intensionality
statements. <em>AAAI</em>, 6338–6345. (<a
href="https://doi.org/10.1609/aaai.v37i5.25780">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Splitting a logic program allows us to reduce the task of computing its stable models to similar tasks for its subprograms. This can be used to increase solving performance and to prove the correctness of programs. We generalize the conditions under which this technique is applicable, by considering not only dependencies between predicates but also their arguments and context. This allows splitting programs commonly used in practice to which previous results were not applicable.},
  archive   = {C_AAAI},
  author    = {Jorge Fandinno and Yuliya Lierler},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25780},
  pages     = {6338-6345},
  title     = {Splitting answer set programs with respect to intensionality statements},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reachability games modulo theories with a bounded safety
player. <em>AAAI</em>, 6330–6337. (<a
href="https://doi.org/10.1609/aaai.v37i5.25779">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Solving reachability games is a fundamental problem for the analysis, verification, and synthesis of reactive systems. We consider logical reachability games modulo theories (in short, GMTs), i.e., infinite-state games whose rules are defined by logical formulas over a multi-sorted first-order theory. Our games have an asymmetric constraint: the safety player has at most k possible moves from each game configuration, whereas the reachability player has no such limitation. Even though determining the winner of such a GMT is undecidable, it can be reduced to the well-studied problem of checking the satisfiability of a system of constrained Horn clauses (CHCs), for which many off-the-shelf solvers have been developed. Winning strategies for GMTs can also be computed by resorting to suitable CHC queries. We demonstrate that GMTs can model various relevant real-world games, and that our approach can effectively solve several problems from different domains, using Z3 as the backend CHC solver.},
  archive   = {C_AAAI},
  author    = {Marco Faella and Gennaro Parlato},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25779},
  pages     = {6330-6337},
  title     = {Reachability games modulo theories with a bounded safety player},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evaluating epistemic logic programs via answer set
programming with quantifiers. <em>AAAI</em>, 6322–6329. (<a
href="https://doi.org/10.1609/aaai.v37i5.25778">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper we introduce a simple way to evaluate epistemic logic programs by means of answer set programming with quantifiers, a recently proposed extension of answer set programming. The method can easily be adapted for most of the many semantics that were proposed for epistemic logic programs. We evaluate the proposed transformation on existing benchmarks using a recently proposed solver for answer set programming with quantifiers, which relies on QBF solvers.},
  archive   = {C_AAAI},
  author    = {Wolfgang Faber and Michael Morak},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25778},
  pages     = {6322-6329},
  title     = {Evaluating epistemic logic programs via answer set programming with quantifiers},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A structural complexity analysis of synchronous dynamical
systems. <em>AAAI</em>, 6313–6321. (<a
href="https://doi.org/10.1609/aaai.v37i5.25777">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Synchronous dynamical systems are well-established models that have been used to capture a range of phenomena in networks, including opinion diffusion, spread of disease and product adoption. We study the three most notable problems in synchronous dynamical systems: whether the system will transition to a target configuration from a starting configuration, whether the system will reach convergence from a starting configuration, and whether the system is guaranteed to converge from every possible starting configuration. While all three problems were known to be intractable in the classical sense, we initiate the study of their exact boundaries of tractability from the perspective of structural parameters of the network by making use of the more fine-grained parameterized complexity paradigm. As our first result, we consider treewidth - as the most prominent and ubiquitous structural parameter - and show that all three problems remain intractable even on instances of constant treewidth. We complement this negative finding with fixed-parameter algorithms for the former two problems parameterized by treedepth, a well-studied restriction of treewidth. While it is possible to rule out a similar algorithm for convergence guarantee under treedepth, we conclude with a fixed-parameter algorithm for this last problem when parameterized by treedepth and the maximum in-degree.},
  archive   = {C_AAAI},
  author    = {Eduard Eiben and Robert Ganian and Thekla Hamm and Viktoriia Korchemna},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25777},
  pages     = {6313-6321},
  title     = {A structural complexity analysis of synchronous dynamical systems},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Model-checking for ability-based logics with constrained
plans. <em>AAAI</em>, 6305–6312. (<a
href="https://doi.org/10.1609/aaai.v37i5.25776">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We investigate the complexity of the model-checking problem for a family of modal logics capturing the notion of “knowing how”. We consider the most standard ability-based knowing how logic, for which we show that model-checking is PSpace-complete. By contrast, a multi-agent variant based on an uncertainty relation between plans in which uncertainty is encoded by a regular language, is shown to admit a PTime model-checking problem. We extend with budgets the above-mentioned ability-logics, as done for ATL-like logics. We show that for the former logic enriched with budgets, the complexity increases to at least ExpSpace-hardness, whereas for the latter, the PTime bound is preserved. Other variant logics are discussed along the paper.},
  archive   = {C_AAAI},
  author    = {Stéphane Demri and Raul Fervari},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25776},
  pages     = {6305-6312},
  title     = {Model-checking for ability-based logics with constrained plans},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). From width-based model checking to width-based automated
theorem proving. <em>AAAI</em>, 6297–6304. (<a
href="https://doi.org/10.1609/aaai.v37i5.25775">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the field of parameterized complexity theory, the study of graph width measures has been intimately connected with the development of width-based model checking algorithms for combinatorial properties on graphs. In this work, we introduce a general framework to convert a large class of width-based model-checking algorithms into algorithms that can be used to test the validity of graph-theoretic conjectures on classes of graphs of bounded width. Our framework is modular and can be applied with respect to several well-studied width measures for graphs, including treewidth and cliquewidth. As a quantitative application of our framework, we prove analytically that for several long-standing graph-theoretic conjectures, there exists an algorithm that takes a number k as input and correctly determines in time double-exponential in a polynomial of k whether the conjecture is valid on all graphs of treewidth at most k. These upper bounds, which may be regarded as upper-bounds on the size of proofs/disproofs for these conjectures on the class of graphs of treewidth at most k, improve significantly on theoretical upper bounds obtained using previously available techniques.},
  archive   = {C_AAAI},
  author    = {Mateus de Oliveira Oliveira and Farhad Vadiee},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25775},
  pages     = {6297-6304},
  title     = {From width-based model checking to width-based automated theorem proving},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning logic programs by discovering where not to search.
<em>AAAI</em>, 6289–6296. (<a
href="https://doi.org/10.1609/aaai.v37i5.25774">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The goal of inductive logic programming (ILP) is to search for a hypothesis that generalises training examples and background knowledge (BK). To improve performance, we introduce an approach that, before searching for a hypothesis, first discovers &quot;where not to search&quot;. We use given BK to discover constraints on hypotheses, such as that a number cannot be both even and odd. We use the constraints to bootstrap a constraint-driven ILP system. Our experiments on multiple domains (including program synthesis and inductive general game playing) show that our approach can (i) substantially reduce learning times by up to 97\%, and (ii) can scale to domains with millions of facts.},
  archive   = {C_AAAI},
  author    = {Andrew Cropper and Céline Hocquette},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25774},
  pages     = {6289-6296},
  title     = {Learning logic programs by discovering where not to search},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Epistemic disjunctive datalog for querying knowledge bases.
<em>AAAI</em>, 6280–6288. (<a
href="https://doi.org/10.1609/aaai.v37i5.25773">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Datalog query language can express several powerful recursive properties, often crucial in real-world scenarios. While answering such queries is feasible over relational databases, the picture changes dramatically when data is enriched with intensional knowledge. It is indeed well-known that answering Datalog queries is undecidable already over lightweight knowledge bases (KBs) of the DL-Lite family. To overcome this issue, we propose a new query language based on Disjunctive Datalog rules combined with a modal epistemic operator. Rules in this language interact with the queried KB exclusively via the epistemic operator, thus extracting only the information true in every model of the KB. This form of interaction is crucial for not falling into undecidability. The contribution provided by this paper is threefold. First, we illustrate the syntax and the semantics of the novel query language. Second, we study the expressive power of different fragments of our new language and compare it with Disjunctive Datalog and its variants. Third, we outline the precise data complexity of answering queries in our new language over KBs expressed in various well-known formalisms.},
  archive   = {C_AAAI},
  author    = {Gianluca Cima and Marco Console and Maurizio Lenzerini and Antonella Poggi},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25773},
  pages     = {6280-6288},
  title     = {Epistemic disjunctive datalog for querying knowledge bases},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SMT safety verification of ontology-based processes.
<em>AAAI</em>, 6271–6279. (<a
href="https://doi.org/10.1609/aaai.v37i5.25772">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the context of verification of data-aware processes, a formal approach based on satisfiability modulo theories (SMT) has been considered to verify parameterised safety properties. This approach requires a combination of model-theoretic notions and algorithmic techniques based on backward reachability. We introduce here Ontology-Based Processes, which are a variant of one of the most investigated models in this spectrum, namely simple artifact systems (SASs), where, instead of managing a database, we operate over a description logic (DL) ontology. We prove that when the DL is expressed in (a slight extension of) RDFS, it enjoys suitable model-theoretic properties, and that by relying on such DL we can define Ontology-Based Processes to which backward reachability can still be applied. Relying on these results we are able to show that in this novel setting, verification of safety properties is decidable in PSPACE.},
  archive   = {C_AAAI},
  author    = {Diego Calvanese and Alessandro Gianola and Andrea Mazzullo and Marco Montali},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25772},
  pages     = {6271-6279},
  title     = {SMT safety verification of ontology-based processes},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The parameterized complexity of network microaggregation.
<em>AAAI</em>, 6262–6270. (<a
href="https://doi.org/10.1609/aaai.v37i5.25771">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Microaggregation is a classical statistical disclosure control technique which requires the input data to be partitioned into clusters while adhering to specified size constraints. We provide novel exact algorithms and lower bounds for the task of microaggregating a given network while considering both unrestricted and connected clusterings, and analyze these from the perspective of the parameterized complexity paradigm. Altogether, our results assemble a complete complexity-theoretic picture for the network microaggregation problem with respect to the most natural parameterizations of the problem, including input-specified parameters capturing the size and homogeneity of the clusters as well as the treewidth and vertex cover number of the network.},
  archive   = {C_AAAI},
  author    = {Václav Blažej and Robert Ganian and Dušan Knop and Jan Pokorný and Šimon Schierreich and Kirill Simonov},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25771},
  pages     = {6262-6270},
  title     = {The parameterized complexity of network microaggregation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The effect of preferences in abstract argumentation under a
claim-centric view. <em>AAAI</em>, 6253–6261. (<a
href="https://doi.org/10.1609/aaai.v37i5.25770">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we study the effect of preferences in abstract argumentation under a claim-centric perspective. Recent work has revealed that semantical and computational properties can change when reasoning is performed on claim-level rather than on the argument-level, while under certain natural restrictions (arguments with the same claims have the same outgoing attacks) these properties are conserved. We now investigate these effects when, in addition, preferences have to be taken into account and consider four prominent reductions to handle preferences between arguments. As we shall see, these reductions give rise to different classes of claim-augmented argumentation frameworks, and behave differently in terms of semantic properties and computational complexity. This strengthens the view that the actual choice for handling preferences has to be taken with care.},
  archive   = {C_AAAI},
  author    = {Michael Bernreiter and Wolfgang Dvorak and Anna Rapberger and Stefan Woltran},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25770},
  pages     = {6253-6261},
  title     = {The effect of preferences in abstract argumentation under a claim-centric view},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Automatically verifying expressive epistemic properties of
programs. <em>AAAI</em>, 6245–6252. (<a
href="https://doi.org/10.1609/aaai.v37i5.25769">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose a new approach to the verification of epistemic properties of programmes. First, we introduce the new ``program-epistemic&#39;&#39; logic L_PK, which is strictly richer and more general than similar formalisms appearing in the literature. To solve the verification problem in an efficient way, we introduce a translation from our language L_PK into first-order logic. Then, we show and prove correct a reduction from the model checking problem for program-epistemic formulas to the satisfiability of their first-order translation. Both our logic and our translation can handle richer specification w.r.t. the state of the art, allowing us to express the knowledge of agents about facts pertaining to programs (i.e., agents&#39; knowledge before a program is executed as well as after is has been executed). Furthermore, we implement our translation in Haskell in a general way (i.e., independently of the programs in the logical statements), and we use existing SMT-solvers to check satisfaction of L_PK formulas on a benchmark example in the AI/agency field.},
  archive   = {C_AAAI},
  author    = {Francesco Belardinelli and Ioana Boureanu and Vadim Malvone and Fortunat Rajaona},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25769},
  pages     = {6245-6252},
  title     = {Automatically verifying expressive epistemic properties of programs},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Complexity of safety and coSafety fragments of linear
temporal logic. <em>AAAI</em>, 6236–6244. (<a
href="https://doi.org/10.1609/aaai.v37i5.25768">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Linear Temporal Logic (LTL) is the de-facto standard temporal logic for system specification, whose foundational properties have been studied for over five decades. Safety and cosafety properties of LTL define notable fragments of LTL, where a prefix of a trace suffices to establish whether a formula is true or not over that trace. In this paper, we study the complexity of the problems of satisfiability, validity, and realizability over infinite and finite traces for the safety and cosafety fragments of LTL. As for satisfiability and validity over infinite traces, we prove that the majority of the fragments have the same complexity as full LTL, that is, they are PSPACE-complete. The picture is radically different for realizability: we find fragments with the same expressive power whose complexity varies from 2EXPTIME-complete (as full LTL) to EXPTIME-complete. Notably, for all cosafety fragments, the complexity of the three problems does not change passing from infinite to finite traces, while for all safety fragments the complexity of satisfiability (resp., realizability) over finite traces drops to NP-complete (resp., Πᴾ₂- complete).},
  archive   = {C_AAAI},
  author    = {Alessandro Artale and Luca Geatti and Nicola Gigante and Andrea Mazzullo and Angelo Montanari},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25768},
  pages     = {6236-6244},
  title     = {Complexity of safety and coSafety fragments of linear temporal logic},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reactive synthesis of dominant strategies. <em>AAAI</em>,
6228–6235. (<a href="https://doi.org/10.1609/aaai.v37i5.25767">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the synthesis under environment specifications problem for LTL/LTLf which, in particular, generalizes FOND (strong) planning with these temporal goals. We consider the case where the agent cannot enforce its goal --- for which the argument for using best-effort strategies has been made --- and study the intermediate ground, between enforcing and best-effort strategies, of dominant strategies. Intuitively, such strategies achieve the goal against any environment for which it is achievable. We show that dominant strategies may exist when enforcing ones do not, while still sharing with the latter many desirable properties such as being interchangeable with each other, and being monotone with respect to tightening of environment specifications. We give necessary and sufficient conditions for the existence of dominant strategies, and show that deciding if they exist is 2EXPTIME-complete --- the same as for enforcing strategies. Finally, we give a uniform, optimal, game-theoretic algorithm for simultaneously solving the three synthesis problems of enforcing, dominant, and best-effort strategies.},
  archive   = {C_AAAI},
  author    = {Benjamin Aminof and Giuseppe De Giacomo and Sasha Rubin},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25767},
  pages     = {6228-6235},
  title     = {Reactive synthesis of dominant strategies},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Abstract argumentation framework with conditional
preferences. <em>AAAI</em>, 6218–6227. (<a
href="https://doi.org/10.1609/aaai.v37i5.25766">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Dung&#39;s abstract Argumentation Framework (AF) has emerged as a central formalism in the area of knowledge representation and reasoning. Preferences in AF allow to represent the comparative strength of arguments in a simple yet expressive way. Preference-based AF (PAF) has been proposed to extend AF with preferences of the form a &gt; b, whose intuitive meaning is that argument a is better than b. In this paper we generalize PAF by introducing conditional preferences of the form a &gt; b \leftarrow body that informally state that a is better than b whenever the condition expressed by body is true. The resulting framework, namely Conditional Preference-based AF (CPAF), extends the PAF semantics under three well-known preference criteria, i.e. democratic, elitist, and KTV. After introducing CPAF, we study the complexity of the verification problem (deciding whether a set of arguments is a ``best&#39;&#39; extension) as well as of the credulous and skeptical acceptance problems (deciding whether a given argument belongs to any or all ``best&#39;&#39; extensions, respectively) under multiple-status semantics (that is, complete, preferred, stable, and semi-stable semantics) for the above-mentioned preference criteria.},
  archive   = {C_AAAI},
  author    = {Gianvincenzo Alfano and Sergio Greco and Francesco Parisi and Irina Trubitsyna},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25766},
  pages     = {6218-6227},
  title     = {Abstract argumentation framework with conditional preferences},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RobustLoc: Robust camera pose regression in challenging
driving environments. <em>AAAI</em>, 6209–6216. (<a
href="https://doi.org/10.1609/aaai.v37i5.25765">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Camera relocalization has various applications in autonomous driving. Previous camera pose regression models consider only ideal scenarios where there is little environmental perturbation. To deal with challenging driving environments that may have changing seasons, weather, illumination, and the presence of unstable objects, we propose RobustLoc, which derives its robustness against perturbations from neural differential equations. Our model uses a convolutional neural network to extract feature maps from multi-view images, a robust neural differential equation diffusion block module to diffuse information interactively, and a branched pose decoder with multi-layer training to estimate the vehicle poses. Experiments demonstrate that RobustLoc surpasses current state-of-the-art camera pose regression models and achieves robust performance in various environments. Our code is released at: https://github.com/sijieaaa/RobustLoc},
  archive   = {C_AAAI},
  author    = {Sijie Wang and Qiyu Kang and Rui She and Wee Peng Tay and Andreas Hartmannsgruber and Diego Navarro Navarro},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25765},
  pages     = {6209-6216},
  title     = {RobustLoc: Robust camera pose regression in challenging driving environments},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Co-imitation: Learning design and behaviour by imitation.
<em>AAAI</em>, 6200–6208. (<a
href="https://doi.org/10.1609/aaai.v37i5.25764">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The co-adaptation of robots has been a long-standing research endeavour with the goal of adapting both body and behaviour of a robot for a given task, inspired by the natural evolution of animals. Co-adaptation has the potential to eliminate costly manual hardware engineering as well as improve the performance of systems. The standard approach to co-adaptation is to use a reward function for optimizing behaviour and morphology. However, defining and constructing such reward functions is notoriously difficult and often a significant engineering effort. This paper introduces a new viewpoint on the co-adaptation problem, which we call co-imitation: finding a morphology and a policy that allow an imitator to closely match the behaviour of a demonstrator. To this end we propose a co-imitation methodology for adapting behaviour and morphology by matching state-distributions of the demonstrator. Specifically, we focus on the challenging scenario with mismatched state- and action-spaces between both agents. We find that co-imitation increases behaviour similarity across a variety of tasks and settings, and demonstrate co-imitation by transferring human walking, jogging and kicking skills onto a simulated humanoid.},
  archive   = {C_AAAI},
  author    = {Chang Rajani and Karol Arndt and David Blanco-Mulero and Kevin Sebastian Luck and Ville Kyrki},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25764},
  pages     = {6200-6208},
  title     = {Co-imitation: Learning design and behaviour by imitation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Improving robotic tactile localization super-resolution via
spatiotemporal continuity learning and overlapping air chambers.
<em>AAAI</em>, 6192–6199. (<a
href="https://doi.org/10.1609/aaai.v37i5.25763">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Human hand has amazing super-resolution ability in sensing the force and position of contact and this ability can be strengthened by practice. Inspired by this, we propose a method for robotic tactile super-resolution enhancement by learning spatiotemporal continuity of contact position and a tactile sensor composed of overlapping air chambers. Each overlapping air chamber is constructed of soft material and seals the barometer inside to mimic adapting receptors of human skin. Each barometer obtains the global receptive field of the contact surface with the pressure propagation in the hyperelastic seal overlapping air chambers. Neural networks with causal convolution are employed to resolve the pressure data sampled by barometers and to predict the contact position. The temporal consistency of spatial position contributes to the accuracy and stability of positioning. We obtain an average super-resolution (SR) factor of over 2500 with only four physical sensing nodes on the rubber surface (0.1 mm in the best case on 38 × 26 mm²), which outperforms the state-of-the-art. The effect of time series length on the location prediction accuracy of causal convolution is quantitatively analyzed in this article. We show that robots can accomplish challenging tasks such as haptic trajectory following, adaptive grasping, and human-robot interaction with the tactile sensor. This research provides new insight into tactile super-resolution sensing and could be beneficial to various applications in the robotics field.},
  archive   = {C_AAAI},
  author    = {Xuyang Li and Yipu Zhang and Xuemei Xie and Jiawei Li and Guangming Shi},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25763},
  pages     = {6192-6199},
  title     = {Improving robotic tactile localization super-resolution via spatiotemporal continuity learning and overlapping air chambers},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Periodic multi-agent path planning. <em>AAAI</em>,
6183–6191. (<a href="https://doi.org/10.1609/aaai.v37i5.25762">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-agent path planning (MAPP) is the problem of planning collision-free trajectories from start to goal locations for a team of agents. This work explores a relatively unexplored setting of MAPP where streams of agents have to go through the starts and goals with high throughput. We tackle this problem by formulating a new variant of MAPP called periodic MAPP in which the timing of agent appearances is periodic. The objective with periodic MAPP is to find a periodic plan, a set of collision-free trajectories that the agent streams can use repeatedly over periods, with periods that are as small as possible. To meet this objective, we propose a solution method that is based on constraint relaxation and optimization. We show that the periodic plans once found can be used for a more practical case in which agents in a stream can appear at random times. We confirm the effectiveness of our method compared with baseline methods in terms of throughput in several scenarios that abstract autonomous intersection management tasks.},
  archive   = {C_AAAI},
  author    = {Kazumi Kasaura and Ryo Yonetani and Mai Nishimura},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25762},
  pages     = {6183-6191},
  title     = {Periodic multi-agent path planning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Moving-landmark assisted distributed learning based
decentralized cooperative localization (DL-DCL) with fault tolerance.
<em>AAAI</em>, 6175–6182. (<a
href="https://doi.org/10.1609/aaai.v37i5.25761">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper considers the problem of cooperative localization of multiple robots under uncertainty, communicating over a partially connected, dynamic communication network and assisted by an agile landmark. Each robot owns an IMU and a relative pose sensing suite, which can get faulty due to system or environmental uncertainty, and therefore exhibit large bias in their estimation output. For the robots to localize accurately under sensor failure and system or environmental uncertainty, a novel Distributed Learning based Decentralized Cooperative Localization (DL-DCL) algorithm is proposed that involves real-time learning of an information fusion strategy by each robot for combining pose estimates from its own sensors as well as from those of its neighboring robots, and utilizing the moving landmark&#39;s pose information as a feedback to the learning process. Convergence analysis shows that the learning process converges exponentially under certain reasonable assumptions. Simulations involving sensor failures inducing around 40-60 times increase in the nominal bias show DL-DCL&#39;s estimation performance to be approximately 40\% better than the well-known covariance-based estimate fusion methods. For the evaluation of DL-DCL&#39;s implementability and fault-tolerance capability in practice, a high-fidelity simulation is carried out in Gazebo with ROS2.},
  archive   = {C_AAAI},
  author    = {Shubhankar Gupta and Suresh Sundaram},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25761},
  pages     = {6175-6182},
  title     = {Moving-landmark assisted distributed learning based decentralized cooperative localization (DL-DCL) with fault tolerance},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Meta-auxiliary learning for adaptive human pose prediction.
<em>AAAI</em>, 6166–6174. (<a
href="https://doi.org/10.1609/aaai.v37i5.25760">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Predicting high-fidelity future human poses, from a historically observed sequence, is crucial for intelligent robots to interact with humans. Deep end-to-end learning approaches, which typically train a generic pre-trained model on external datasets and then directly apply it to all test samples, emerge as the dominant solution to solve this issue. Despite encouraging progress, they remain non-optimal, as the unique properties (e.g., motion style, rhythm) of a specific sequence cannot be adapted. More generally, once encountering out-of-distributions, the predicted poses tend to be unreliable. Motivated by this observation, we propose a novel test-time adaptation framework that leverages two self-supervised auxiliary tasks to help the primary forecasting network adapt to the test sequence. In the testing phase, our model can adjust the model parameters by several gradient updates to improve the generation quality. However, due to catastrophic forgetting, both auxiliary tasks typically have a low ability to automatically present the desired positive incentives for the final prediction performance. For this reason, we also propose a meta-auxiliary learning scheme for better adaptation. Extensive experiments show that the proposed approach achieves higher accuracy and more realistic visualization.},
  archive   = {C_AAAI},
  author    = {Qiongjie Cui and Huaijiang Sun and Jianfeng Lu and Bin Li and Weiqing Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25760},
  pages     = {6166-6174},
  title     = {Meta-auxiliary learning for adaptive human pose prediction},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A set of control points conditioned pedestrian trajectory
prediction. <em>AAAI</em>, 6155–6165. (<a
href="https://doi.org/10.1609/aaai.v37i5.25759">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Predicting the trajectories of pedestrians in crowded conditions is an important task for applications like autonomous navigation systems. Previous studies have tackled this problem using two strategies. They (1) infer all future steps recursively, or (2) predict the potential destinations of pedestrians at once and interpolate the intermediate steps to arrive there. However, these strategies often suffer from the accumulated errors of the recursive inference, or restrictive assumptions about social relations in the intermediate path. In this paper, we present a graph convolutional network-based trajectory prediction. Firstly, we propose a control point prediction that divides the future path into three sections and infers the intermediate destinations of pedestrians to reduce the accumulated error. To do this, we construct multi-relational weighted graphs to account for their physical and complex social relations. We then introduce a trajectory refinement step based on a spatio-temporal and multi-relational graph. By considering the social interactions between neighbors, better prediction results are achievable. In experiments, the proposed network achieves state-of-the-art performance on various real-world trajectory prediction benchmarks.},
  archive   = {C_AAAI},
  author    = {Inhwan Bae and Hae-Gon Jeon},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25759},
  pages     = {6155-6165},
  title     = {A set of control points conditioned pedestrian trajectory prediction},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Maximum entropy population-based training for zero-shot
human-AI coordination. <em>AAAI</em>, 6145–6153. (<a
href="https://doi.org/10.1609/aaai.v37i5.25758">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the problem of training a Reinforcement Learning (RL) agent that is collaborative with humans without using human data. Although such agents can be obtained through self-play training, they can suffer significantly from the distributional shift when paired with unencountered partners, such as humans. In this paper, we propose Maximum Entropy Population-based training (MEP) to mitigate such distributional shift. In MEP, agents in the population are trained with our derived Population Entropy bonus to promote the pairwise diversity between agents and the individual diversity of agents themselves. After obtaining this diversified population, a common best agent is trained by paring with agents in this population via prioritized sampling, where the prioritization is dynamically adjusted based on the training progress. We demonstrate the effectiveness of our method MEP, with comparison to Self-Play PPO (SP), Population-Based Training (PBT), Trajectory Diversity (TrajeDi), and Fictitious Co-Play (FCP) in both matrix game and Overcooked game environments, with partners being human proxy models and real humans. A supplementary video showing experimental results is available at https://youtu.be/Xh-FKD0AAKE.},
  archive   = {C_AAAI},
  author    = {Rui Zhao and Jinming Song and Yufeng Yuan and Haifeng Hu and Yang Gao and Yi Wu and Zhongqian Sun and Wei Yang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25758},
  pages     = {6145-6153},
  title     = {Maximum entropy population-based training for zero-shot human-AI coordination},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Better peer grading through bayesian inference.
<em>AAAI</em>, 6137–6144. (<a
href="https://doi.org/10.1609/aaai.v37i5.25757">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Peer grading systems aggregate noisy reports from multiple students to approximate a &quot;true&quot; grade as closely as possible. Most current systems either take the mean or median of reported grades; others aim to estimate students’ grading accuracy under a probabilistic model. This paper extends the state of the art in the latter approach in three key ways: (1) recognizing that students can behave strategically (e.g., reporting grades close to the class average without doing the work); (2) appropriately handling censored data that arises from discrete-valued grading rubrics; and (3) using mixed integer programming to improve the interpretability of the grades assigned to students. We demonstrate how to make Bayesian inference practical in this model and evaluate our approach on both synthetic and real-world data obtained by using our implemented system in four large classes. These extensive experiments show that grade aggregation using our model accurately estimates true grades, students&#39; likelihood of submitting uninformative grades, and the variation in their inherent grading error; we also characterize our models&#39; robustness.},
  archive   = {C_AAAI},
  author    = {Hedayat Zarkoob and Greg d&#39;Eon and Lena Podina and Kevin Leyton-Brown},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25757},
  pages     = {6137-6144},
  title     = {Better peer grading through bayesian inference},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning to select pivotal samples for meta re-weighting.
<em>AAAI</em>, 6128–6136. (<a
href="https://doi.org/10.1609/aaai.v37i5.25756">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Sample re-weighting strategies provide a promising mechanism to deal with imperfect training data in machine learning, such as noisily labeled or class-imbalanced data. One such strategy involves formulating a bi-level optimization problem called the meta re-weighting problem, whose goal is to optimize performance on a small set of perfect pivotal samples, called meta samples. Many approaches have been proposed to efficiently solve this problem. However, all of them assume that a perfect meta sample set is already provided while we observe that the selections of meta sample set is performance-critical. In this paper, we study how to learn to identify such a meta sample set from a large, imperfect training set, that is subsequently cleaned and used to optimize performance in the meta re-weighting setting. We propose a learning framework which reduces the meta samples selection problem to a weighted K-means clustering problem through rigorously theoretical analysis. We propose two clustering methods within our learning framework, Representation-based clustering method (RBC) and Gradient-based clustering method (GBC), for balancing performance and computational efficiency. Empirical studies demonstrate the performance advantage of our methods over various baseline methods},
  archive   = {C_AAAI},
  author    = {Yinjun Wu and Adam Stein and Jacob Gardner and Mayur Naik},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25756},
  pages     = {6128-6136},
  title     = {Learning to select pivotal samples for meta re-weighting},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Collective intelligence in human-AI teams: A bayesian theory
of mind approach. <em>AAAI</em>, 6119–6127. (<a
href="https://doi.org/10.1609/aaai.v37i5.25755">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We develop a network of Bayesian agents that collectively model the mental states of teammates from the observed communication. Using a generative computational approach to cognition, we make two contributions. First, we show that our agent could generate interventions that improve the collective intelligence of a human-AI team beyond what humans alone would achieve. Second, we develop a real-time measure of human&#39;s theory of mind ability and test theories about human cognition. We use data collected from an online experiment in which 145 individuals in 29 human-only teams of five communicate through a chat-based system to solve a cognitive task. We find that humans (a) struggle to fully integrate information from teammates into their decisions, especially when communication load is high, and (b) have cognitive biases which lead them to underweight certain useful, but ambiguous, information. Our theory of mind ability measure predicts both individual- and team-level performance. Observing teams&#39; first 25\% of messages explains about 8\% of the variation in final team performance, a 170\% improvement compared to the current state of the art.},
  archive   = {C_AAAI},
  author    = {Samuel Westby and Christoph Riedl},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25755},
  pages     = {6119-6127},
  title     = {Collective intelligence in human-AI teams: A bayesian theory of mind approach},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Human joint kinematics diffusion-refinement for stochastic
motion prediction. <em>AAAI</em>, 6110–6118. (<a
href="https://doi.org/10.1609/aaai.v37i5.25754">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Stochastic human motion prediction aims to forecast multiple plausible future motions given a single pose sequence from the past. Most previous works focus on designing elaborate losses to improve the accuracy, while the diversity is typically characterized by randomly sampling a set of latent variables from the latent prior, which is then decoded into possible motions. This joint training of sampling and decoding, however, suffers from posterior collapse as the learned latent variables tend to be ignored by a strong decoder, leading to limited diversity. Alternatively, inspired by the diffusion process in nonequilibrium thermodynamics, we propose MotionDiff, a diffusion probabilistic model to treat the kinematics of human joints as heated particles, which will diffuse from original states to a noise distribution. This process not only offers a natural way to obtain the &quot;whitened&#39;&#39; latents without any trainable parameters, but also introduces a new noise in each diffusion step, both of which facilitate more diverse motions. Human motion prediction is then regarded as the reverse diffusion process that converts the noise distribution into realistic future motions conditioned on the observed sequence. Specifically, MotionDiff consists of two parts: a spatial-temporal transformer-based diffusion network to generate diverse yet plausible motions, and a flexible refinement network to further enable geometric losses and align with the ground truth. Experimental results on two datasets demonstrate that our model yields the competitive performance in terms of both diversity and accuracy.},
  archive   = {C_AAAI},
  author    = {Dong Wei and Huaijiang Sun and Bin Li and Jianfeng Lu and Weiqing Li and Xiaoning Sun and Shengxiang Hu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25754},
  pages     = {6110-6118},
  title     = {Human joint kinematics diffusion-refinement for stochastic motion prediction},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SwiftAvatar: Efficient auto-creation of parameterized
stylized character on arbitrary avatar engines. <em>AAAI</em>,
6101–6109. (<a href="https://doi.org/10.1609/aaai.v37i5.25753">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The creation of a parameterized stylized character involves careful selection of numerous parameters, also known as the &quot;avatar vectors&quot; that can be interpreted by the avatar engine. Existing unsupervised avatar vector estimation methods that auto-create avatars for users, however, often fail to work because of the domain gap between realistic faces and stylized avatar images. To this end, we propose SwiftAvatar, a novel avatar auto-creation framework that is evidently superior to previous works. SwiftAvatar introduces dual-domain generators to create pairs of realistic faces and avatar images using shared latent codes. The latent codes can then be bridged with the avatar vectors as pairs, by performing GAN inversion on the avatar images rendered from the engine using avatar vectors. Through this way, we are able to synthesize paired data in high-quality as many as possible, consisting of avatar vectors and their corresponding realistic faces. We also propose semantic augmentation to improve the diversity of synthesis. Finally, a light-weight avatar vector estimator is trained on the synthetic pairs to implement efficient auto-creation. Our experiments demonstrate the effectiveness and efficiency of SwiftAvatar on two different avatar engines. The superiority and advantageous flexibility of SwiftAvatar are also verified in both subjective and objective evaluations.},
  archive   = {C_AAAI},
  author    = {Shizun Wang and Weihong Zeng and Xu Wang and Hao Yang and Li Chen and Chuang Zhang and Ming Wu and Yi Yuan and Yunzhao Zeng and Min Zheng and Jing Liu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25753},
  pages     = {6101-6109},
  title     = {SwiftAvatar: Efficient auto-creation of parameterized stylized character on arbitrary avatar engines},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Multi-scale control signal-aware transformer for motion
synthesis without phase. <em>AAAI</em>, 6092–6100. (<a
href="https://doi.org/10.1609/aaai.v37i5.25752">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Synthesizing controllable motion for a character using deep learning has been a promising approach due to its potential to learn a compact model without laborious feature engineering. To produce dynamic motion from weak control signals such as desired paths, existing methods often require auxiliary information such as phases for alleviating motion ambiguity, which limits their generalisation capability. As past poses often contain useful auxiliary hints, in this paper, we propose a task-agnostic deep learning method, namely Multi-scale Control Signal-aware Transformer (MCS-T), with an attention based encoder-decoder architecture to discover the auxiliary information implicitly for synthesizing controllable motion without explicitly requiring auxiliary information such as phase. Specifically, an encoder is devised to adaptively formulate the motion patterns of a character&#39;s past poses with multi-scale skeletons, and a decoder driven by control signals to further synthesize and predict the character&#39;s state by paying context-specialised attention to the encoded past motion patterns. As a result, it helps alleviate the issues of low responsiveness and slow transition which often happen in conventional methods not using auxiliary information. Both qualitative and quantitative experimental results on an existing biped locomotion dataset, which involves diverse types of motion transitions, demonstrate the effectiveness of our method. In particular, MCS-T is able to successfully generate motions comparable to those generated by the methods using auxiliary information.},
  archive   = {C_AAAI},
  author    = {Lintao Wang and Kun Hu and Lei Bai and Yu Ding and Wanli Ouyang and Zhiyong Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25752},
  pages     = {6092-6100},
  title     = {Multi-scale control signal-aware transformer for motion synthesis without phase},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Beam search optimized batch bayesian active learning.
<em>AAAI</em>, 6084–6091. (<a
href="https://doi.org/10.1609/aaai.v37i5.25751">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Active Learning is an essential method for label-efficient deep learning. As a Bayesian active learning method, Bayesian Active Learning by Disagreement (BALD) successfully selects the most representative samples by maximizing the mutual information between the model prediction and model parameters. However, when applied to a batch acquisition mode, like batch construction with greedy search, BALD suffers from poor performance, especially with noises of near-duplicate data. To address this shortcoming, we propose a diverse beam search optimized batch active learning method, which explores a graph for every batch construction by expanding the highest-scored samples of a predetermined number. To avoid near duplicate beam branches (very similar beams generated from the same root and similar samples), which is undesirable for lacking diverse representations in the feature space, we design a self-adapted constraint within candidate beams. The proposed method is able to acquire data that can better represent the distribution of the unlabeled pool, and at the same time, be significantly different from existing beams. We observe that the proposed method achieves higher batch performance than the baseline methods on three benchmark datasets.},
  archive   = {C_AAAI},
  author    = {Jingyu Sun and Hongjie Zhai and Osamu Saisho and Susumu Takeuchi},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25751},
  pages     = {6084-6091},
  title     = {Beam search optimized batch bayesian active learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Frustratingly easy truth discovery. <em>AAAI</em>,
6074–6083. (<a href="https://doi.org/10.1609/aaai.v37i5.25750">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Truth discovery is a general name for a broad range of statistical methods aimed to extract the correct answers to questions, based on multiple answers coming from noisy sources. For example, workers in a crowdsourcing platform. In this paper, we consider an extremely simple heuristic for estimating workers&#39; competence using average proximity to other workers. We prove that this estimates well the actual competence level and enables separating high and low quality workers in a wide spectrum of domains and statistical models. Under Gaussian noise, this simple estimate is the unique solution to the MLE with a constant regularization factor. Finally, weighing workers according to their average proximity in a crowdsourcing setting, results in substantial improvement over unweighted aggregation and other truth discovery algorithms in practice.},
  archive   = {C_AAAI},
  author    = {Reshef Meir and Ofra Amir and Omer Ben-Porat and Tsviel Ben Shabat and Gal Cohensius and Lirong Xia},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25750},
  pages     = {6074-6083},
  title     = {Frustratingly easy truth discovery},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning deep hierarchical features with spatial
regularization for one-class facial expression recognition.
<em>AAAI</em>, 6065–6073. (<a
href="https://doi.org/10.1609/aaai.v37i5.25749">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Existing methods on facial expression recognition (FER) are mainly trained in the setting when multi-class data is available. However, to detect the alien expressions that are absent during training, this type of methods cannot work. To address this problem, we develop a Hierarchical Spatial One Class Facial Expression Recognition Network (HS-OCFER) which can construct the decision boundary of a given expression class (called normal class) by training on only one-class data. Specifically, HS-OCFER consists of three novel components. First, hierarchical bottleneck modules are proposed to enrich the representation power of the model and extract detailed feature hierarchy from different levels. Second, multi-scale spatial regularization with facial geometric information is employed to guide the feature extraction towards emotional facial representations and prevent the model from overfitting extraneous disturbing factors. Third, compact intra-class variation is adopted to separate the normal class from alien classes in the decision space. Extensive evaluations on 4 typical FER datasets from both laboratory and wild scenarios show that our method consistently outperforms state-of-the-art One-Class Classification (OCC) approaches.},
  archive   = {C_AAAI},
  author    = {Bingjun Luo and Junjie Zhu and Tianyu Yang and Sicheng Zhao and Chao Hu and Xibin Zhao and Yue Gao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25749},
  pages     = {6065-6073},
  title     = {Learning deep hierarchical features with spatial regularization for one-class facial expression recognition},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Modeling human trust and reliance in AI-assisted decision
making: A markovian approach. <em>AAAI</em>, 6056–6064. (<a
href="https://doi.org/10.1609/aaai.v37i5.25748">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The increased integration of artificial intelligence (AI) technologies in human workflows has resulted in a new paradigm of AI-assisted decision making, in which an AI model provides decision recommendations while humans make the final decisions. To best support humans in decision making, it is critical to obtain a quantitative understanding of how humans interact with and rely on AI. Previous studies often model humans&#39; reliance on AI as an analytical process, i.e., reliance decisions are made based on cost-benefit analysis. However, theoretical models in psychology suggest that the reliance decisions can often be driven by emotions like humans&#39; trust in AI models. In this paper, we propose a hidden Markov model to capture the affective process underlying the human-AI interaction in AI-assisted decision making, by characterizing how decision makers adjust their trust in AI over time and make reliance decisions based on their trust. Evaluations on real human behavior data collected from human-subject experiments show that the proposed model outperforms various baselines in accurately predicting humans&#39; reliance behavior in AI-assisted decision making. Based on the proposed model, we further provide insights into how humans&#39; trust and reliance dynamics in AI-assisted decision making is influenced by contextual factors like decision stakes and their interaction experiences.},
  archive   = {C_AAAI},
  author    = {Zhuoyan Li and Zhuoran Lu and Ming Yin},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25748},
  pages     = {6056-6064},
  title     = {Modeling human trust and reliance in AI-assisted decision making: A markovian approach},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). Human-in-the-loop vehicle ReID. <em>AAAI</em>, 6048–6055.
(<a href="https://doi.org/10.1609/aaai.v37i5.25747">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Vehicle ReID has been an active topic in computer vision, with a substantial number of deep neural models proposed as end-to-end solutions. In this paper, we solve the problem from a new perspective and present an interesting variant called human-in-the-loop vehicle ReID to leverage interactive (and possibly wrong) human feedback signal for performance enhancement. Such human-machine cooperation mode is orthogonal to existing ReID models. To avoid incremental training overhead, we propose an Interaction ReID Network (IRIN) that can directly accept the feedback signal as an input and adjust the embedding of query image in an online fashion. IRIN is offline trained by simulating the human interaction process, with multiple optimization strategies to fully exploit the feedback signal. Experimental results show that even by interacting with flawed feedback generated by non-experts, IRIN still outperforms state-of-the-art ReID models by a considerable margin. If the feedback contains no false positive, IRIN boosts the mAP in Veri776 from 81.6\% to 95.2\% with only 5 rounds of interaction per query image.},
  archive   = {C_AAAI},
  author    = {Zepeng Li and Dongxiang Zhang and Yanyan Shen and Gang Chen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25747},
  pages     = {6048-6055},
  title     = {Human-in-the-loop vehicle ReID},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Evaluating and improving interactions with hazy oracles.
<em>AAAI</em>, 6039–6047. (<a
href="https://doi.org/10.1609/aaai.v37i5.25746">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Many AI systems integrate sensor inputs, world knowledge, and human-provided information to perform inference. While such systems often treat the human input as flawless, humans are better thought of as hazy oracles whose input may be ambiguous or outside of the AI system&#39;s understanding. In such situations it makes sense for the AI system to defer its inference while it disambiguates the human-provided information by, for example, asking the human to rephrase the query. Though this approach has been considered in the past, current work is typically limited to application-specific methods and non-standardized human experiments. We instead introduce and formalize a general notion of deferred inference. Using this formulation, we then propose a novel evaluation centered around the Deferred Error Volume (DEV) metric, which explicitly considers the tradeoff between error reduction and the additional human effort required to achieve it. We demonstrate this new formalization and an innovative deferred inference method on the disparate tasks of Single-Target Video Object Tracking and Referring Expression Comprehension, ultimately reducing error by up to 48\% without any change to the underlying model or its parameters.},
  archive   = {C_AAAI},
  author    = {Stephan J. Lemmer and Jason J. Corso},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25746},
  pages     = {6039-6047},
  title     = {Evaluating and improving interactions with hazy oracles},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards voice reconstruction from EEG during imagined
speech. <em>AAAI</em>, 6030–6038. (<a
href="https://doi.org/10.1609/aaai.v37i5.25745">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Translating imagined speech from human brain activity into voice is a challenging and absorbing research issue that can provide new means of human communication via brain signals. Efforts to reconstruct speech from brain activity have shown their potential using invasive measures of spoken speech data, but have faced challenges in reconstructing imagined speech. In this paper, we propose NeuroTalk, which converts non-invasive brain signals of imagined speech into the user&#39;s own voice. Our model was trained with spoken speech EEG which was generalized to adapt to the domain of imagined speech, thus allowing natural correspondence between the imagined speech and the voice as a ground truth. In our framework, an automatic speech recognition decoder contributed to decomposing the phonemes of the generated speech, demonstrating the potential of voice reconstruction from unseen words. Our results imply the potential of speech synthesis from human EEG signals, not only from spoken speech but also from the brain signals of imagined speech.},
  archive   = {C_AAAI},
  author    = {Young-Eun Lee and Seo-Hyun Lee and Sang-Ho Kim and Seong-Whan Lee},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25745},
  pages     = {6030-6038},
  title     = {Towards voice reconstruction from EEG during imagined speech},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Incentive-boosted federated crowdsourcing. <em>AAAI</em>,
6021–6029. (<a href="https://doi.org/10.1609/aaai.v37i5.25744">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Crowdsourcing is a favorable computing paradigm for processing computer-hard tasks by harnessing human intelligence. However, generic crowdsourcing systems may lead to privacy-leakage through the sharing of worker data. To tackle this problem, we propose a novel approach, called iFedCrowd (incentive-boosted Federated Crowdsourcing), to manage the privacy and quality of crowdsourcing projects. iFedCrowd allows participants to locally process sensitive data and only upload encrypted training models, and then aggregates the model parameters to build a shared server model to protect data privacy. To motivate workers to build a high-quality global model in an efficacy way, we introduce an incentive mechanism that encourages workers to constantly collect fresh data to train accurate client models and boosts the global model training. We model the incentive-based interaction between the crowdsourcing platform and participating workers as a Stackelberg game, in which each side maximizes its own profit. We derive the Nash Equilibrium of the game to find the optimal solutions for the two sides. Experimental results confirm that iFedCrowd can complete secure crowdsourcing projects with high quality and efficiency.},
  archive   = {C_AAAI},
  author    = {Xiangping Kang and Guoxian Yu and Jun Wang and Wei Guo and Carlotta Domeniconi and Jinglin Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25744},
  pages     = {6021-6029},
  title     = {Incentive-boosted federated crowdsourcing},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SWL-adapt: An unsupervised domain adaptation model with
sample weight learning for cross-user wearable human activity
recognition. <em>AAAI</em>, 6012–6020. (<a
href="https://doi.org/10.1609/aaai.v37i5.25743">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In practice, Wearable Human Activity Recognition (WHAR) models usually face performance degradation on the new user due to user variance. Unsupervised domain adaptation (UDA) becomes the natural solution to cross-user WHAR under annotation scarcity. Existing UDA models usually align samples across domains without differentiation, which ignores the difference among samples. In this paper, we propose an unsupervised domain adaptation model with sample weight learning (SWL-Adapt) for cross-user WHAR. SWL-Adapt calculates sample weights according to the classification loss and domain discrimination loss of each sample with a parameterized network. We introduce the meta-optimization based update rule to learn this network end-to-end, which is guided by meta-classification loss on the selected pseudo-labeled target samples. Therefore, this network can fit a weighting function according to the cross-user WHAR task at hand, which is superior to existing sample differentiation rules fixed for special scenarios. Extensive experiments on three public WHAR datasets demonstrate that SWL-Adapt achieves the state-of-the-art performance on the cross-user WHAR task, outperforming the best baseline by an average of 3.1\% and 5.3\% in accuracy and macro F1 score, respectively.},
  archive   = {C_AAAI},
  author    = {Rong Hu and Ling Chen and Shenghuan Miao and Xing Tang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25743},
  pages     = {6012-6020},
  title     = {SWL-adapt: An unsupervised domain adaptation model with sample weight learning for cross-user wearable human activity recognition},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning to defer with limited expert predictions.
<em>AAAI</em>, 6002–6011. (<a
href="https://doi.org/10.1609/aaai.v37i5.25742">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent research suggests that combining AI models with a human expert can exceed the performance of either alone. The combination of their capabilities is often realized by learning to defer algorithms that enable the AI to learn to decide whether to make a prediction for a particular instance or defer it to the human expert. However, to accurately learn which instances should be deferred to the human expert, a large number of expert predictions that accurately reflect the expert&#39;s capabilities are required—in addition to the ground truth labels needed to train the AI. This requirement shared by many learning to defer algorithms hinders their adoption in scenarios where the responsible expert regularly changes or where acquiring a sufficient number of expert predictions is costly. In this paper, we propose a three-step approach to reduce the number of expert predictions required to train learning to defer algorithms. It encompasses (1) the training of an embedding model with ground truth labels to generate feature representations that serve as a basis for (2) the training of an expertise predictor model to approximate the expert&#39;s capabilities. (3) The expertise predictor generates artificial expert predictions for instances not yet labeled by the expert, which are required by the learning to defer algorithms. We evaluate our approach on two public datasets. One with &quot;synthetically&quot; generated human experts and another from the medical domain containing real-world radiologists&#39; predictions. Our experiments show that the approach allows the training of various learning to defer algorithms with a minimal number of human expert predictions. Furthermore, we demonstrate that even a small number of expert predictions per class is sufficient for these algorithms to exceed the performance the AI and the human expert can achieve individually.},
  archive   = {C_AAAI},
  author    = {Patrick Hemmer and Lukas Thede and Michael Vössing and Johannes Jakubik and Niklas Kühl},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25742},
  pages     = {6002-6011},
  title     = {Learning to defer with limited expert predictions},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The role of heuristics and biases during complex choices
with an AI teammate. <em>AAAI</em>, 5993–6001. (<a
href="https://doi.org/10.1609/aaai.v37i5.25741">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Behavioral scientists have classically documented aversion to algorithmic decision aids, from simple linear models to AI. Sentiment, however, is changing and possibly accelerating AI helper usage. AI assistance is, arguably, most valuable when humans must make complex choices. We argue that classic experimental methods used to study heuristics and biases are insufficient for studying complex choices made with AI helpers. We adapted an experimental paradigm designed for studying complex choices in such contexts. We show that framing and anchoring effects impact how people work with an AI helper and are predictive of choice outcomes. The evidence suggests that some participants, particularly those in a loss frame, put too much faith in the AI helper and experienced worse choice outcomes by doing so. The paradigm also generates computational modeling-friendly data allowing future studies of human-AI decision making.},
  archive   = {C_AAAI},
  author    = {Nikolos Gurney and John H. Miller and David V. Pynadath},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25741},
  pages     = {5993-6001},
  title     = {The role of heuristics and biases during complex choices with an AI teammate},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The effect of modeling human rationality level on learning
rewards from multiple feedback types. <em>AAAI</em>, 5983–5992. (<a
href="https://doi.org/10.1609/aaai.v37i5.25740">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {When inferring reward functions from human behavior (be it demonstrations, comparisons, physical corrections, or e-stops), it has proven useful to model the human as making noisy-rational choices, with a &quot;rationality coefficient&quot; capturing how much noise or entropy we expect to see in the human behavior. Prior work typically sets the rationality level to a constant value, regardless of the type, or quality, of human feedback. However, in many settings, giving one type of feedback (e.g. a demonstration) may be much more difficult than a different type of feedback (e.g. answering a comparison query). Thus, we expect to see more or less noise depending on the type of human feedback. In this work, we advocate that grounding the rationality coefficient in real data for each feedback type, rather than assuming a default value, has a significant positive effect on reward learning. We test this in both simulated experiments and in a user study with real human feedback. We find that overestimating human rationality can have dire effects on reward learning accuracy and regret. We also find that fitting the rationality coefficient to human data enables better reward learning, even when the human deviates significantly from the noisy-rational choice model due to systematic biases. Further, we find that the rationality level affects the informativeness of each feedback type: surprisingly, demonstrations are not always the most informative---when the human acts very suboptimally, comparisons actually become more informative, even when the rationality level is the same for both. Ultimately, our results emphasize the importance and advantage of paying attention to the assumed human-rationality-level, especially when agents actively learn from multiple types of human feedback.},
  archive   = {C_AAAI},
  author    = {Gaurav R. Ghosal and Matthew Zurek and Daniel S. Brown and Anca D. Dragan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25740},
  pages     = {5983-5992},
  title     = {The effect of modeling human rationality level on learning rewards from multiple feedback types},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Moral machine or tyranny of the majority? <em>AAAI</em>,
5974–5982. (<a href="https://doi.org/10.1609/aaai.v37i5.25739">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With artificial intelligence systems increasingly applied in consequential domains, researchers have begun to ask how AI systems ought to act in ethically charged situations where even humans lack consensus. In the Moral Machine project, researchers crowdsourced answers to &quot;Trolley Problems&quot; concerning autonomous vehicles. Subsequently, Noothigattu et al. (2018) proposed inferring linear functions that approximate each individual&#39;s preferences and aggregating these linear models by averaging parameters across the population. In this paper, we examine this averaging mechanism, focusing on fairness concerns and strategic effects. We investigate a simple setting where the population consists of two groups, the minority constitutes an α &lt; 0.5 share of the population, and within-group preferences are homogeneous. Focusing on the fraction of contested cases where the minority group prevails, we make the following observations: (a) even when all parties report their preferences truthfully, the fraction of disputes where the minority prevails is less than proportionate in α; (b) the degree of sub-proportionality grows more severe as the level of disagreement between the groups increases; (c) when parties report preferences strategically, pure strategy equilibria do not always exist; and (d) whenever a pure strategy equilibrium exists, the majority group prevails 100\% of the time. These findings raise concerns about stability and fairness of averaging as a mechanism for aggregating diverging voices. Finally, we discuss alternatives, including randomized dictatorship and median-based mechanisms.},
  archive   = {C_AAAI},
  author    = {Michael Feffer and Hoda Heidari and Zachary C. Lipton},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25739},
  pages     = {5974-5982},
  title     = {Moral machine or tyranny of the majority?},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Extracting semantic-dynamic features for long-term stable
brain computer interface. <em>AAAI</em>, 5965–5973. (<a
href="https://doi.org/10.1609/aaai.v37i5.25738">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Brain-computer Interface (BCI) builds a neural signal to the motor command pathway, which is a prerequisite for the realization of neural prosthetics. However, a long-term stable BCI suffers from the neural data drift across days while retraining the BCI decoder is expensive and restricts its application scenarios. Recent solutions of neural signal recalibration treat the continuous neural signals as discrete, which is less effective in temporal feature extraction. Inspired by the observation from biologists that low-dimensional dynamics could describe high-dimensional neural signals, we model the underlying neural dynamics and propose a semantic-dynamic feature that represents the semantics and dynamics in a shared feature space facilitating the BCI recalibration. Besides, we present the joint distribution alignment instead of the common used marginal alignment strategy, dealing with the various complex changes in neural data distribution. Our recalibration approach achieves state-of-the-art performance on the real neural data of two monkeys in both classification and regression tasks. Our approach is also evaluated on a simulated dataset, which indicates its robustness in dealing with various common causes of neural signal instability.},
  archive   = {C_AAAI},
  author    = {Tao Fang and Qian Zheng and Yu Qi and Gang Pan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25738},
  pages     = {5965-5973},
  title     = {Extracting semantic-dynamic features for long-term stable brain computer interface},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Local justice and machine learning: Modeling and inferring
dynamic ethical preferences toward allocations. <em>AAAI</em>,
5956–5964. (<a href="https://doi.org/10.1609/aaai.v37i5.25737">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider a setting in which a social planner has to make a sequence of decisions to allocate scarce resources in a high-stakes domain. Our goal is to understand stakeholders&#39; dynamic moral preferences toward such allocational policies. In particular, we evaluate the sensitivity of moral preferences to the history of allocations and their perceived future impact on various socially salient groups. We propose a mathematical model to capture and infer such dynamic moral preferences. We illustrate our model through small-scale human-subject experiments focused on the allocation of scarce medical resource distributions during a hypothetical viral epidemic. We observe that participants&#39; preferences are indeed history- and impact-dependent. Additionally, our preliminary experimental results reveal intriguing patterns specific to medical resources---a topic that is particularly salient against the backdrop of the global covid-19 pandemic.},
  archive   = {C_AAAI},
  author    = {Violet (Xinying) Chen and Joshua Williams and Derek Leben and Hoda Heidari},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25737},
  pages     = {5956-5964},
  title     = {Local justice and machine learning: Modeling and inferring dynamic ethical preferences toward allocations},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Interactive concept bottleneck models. <em>AAAI</em>,
5948–5955. (<a href="https://doi.org/10.1609/aaai.v37i5.25736">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Concept bottleneck models (CBMs) are interpretable neural networks that first predict labels for human-interpretable concepts relevant to the prediction task, and then predict the final label based on the concept label predictions. We extend CBMs to interactive prediction settings where the model can query a human collaborator for the label to some concepts. We develop an interaction policy that, at prediction time, chooses which concepts to request a label for so as to maximally improve the final prediction. We demonstrate that a simple policy combining concept prediction uncertainty and influence of the concept on the final prediction achieves strong performance and outperforms static approaches as well as active feature acquisition methods proposed in the literature. We show that the interactive CBM can achieve accuracy gains of 5-10\% with only 5 interactions over competitive baselines on the Caltech-UCSD Birds, CheXpert and OAI datasets.},
  archive   = {C_AAAI},
  author    = {Kushal Chauhan and Rishabh Tiwari and Jan Freyberg and Pradeep Shenoy and Krishnamurthy Dvijotham},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25736},
  pages     = {5948-5955},
  title     = {Interactive concept bottleneck models},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Teaching to learn: Sequential teaching of learners with
internal states. <em>AAAI</em>, 5939–5947. (<a
href="https://doi.org/10.1609/aaai.v37i5.25735">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In sequential machine teaching, a teacher’s objective is to provide the optimal sequence of inputs to sequential learners in order to guide them towards the best model. However, this teaching objective considers a restricted class of learners with fixed inductive biases. In this paper, we extend the machine teaching framework to learners that can improve their inductive biases, represented as latent internal states, in order to generalize to new datasets. We introduce a novel framework in which learners’ inductive biases may change with the teaching interaction, which affects the learning performance in future tasks. In order to teach such learners, we propose a multi-objective control approach that takes the future performance of the learner after teaching into account. This framework provides tools for modelling learners with internal states, humans and meta-learning algorithms alike. Furthermore, we distinguish manipulative teaching, which can be done by effectively hiding data and also used for indoctrination, from teaching to learn which aims to help the learner become better at learning from new datasets in the absence of a teacher. Our empirical results demonstrate that our framework is able to reduce the number of required tasks for online meta-learning, and increases independent learning performance of simulated human users in future tasks.},
  archive   = {C_AAAI},
  author    = {Mustafa Mert Çelikok and Pierre-Alexandre Murena and Samuel Kaski},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25735},
  pages     = {5939-5947},
  title     = {Teaching to learn: Sequential teaching of learners with internal states},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The value of AI guidance in human examination of
synthetically-generated faces. <em>AAAI</em>, 5930–5938. (<a
href="https://doi.org/10.1609/aaai.v37i5.25734">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Face image synthesis has progressed beyond the point at which humans can effectively distinguish authentic faces from synthetically-generated ones. Recently developed synthetic face image detectors boast ``better-than-human&#39;&#39; discriminative ability, especially those guided by human perceptual intelligence during the model&#39;s training process. In this paper, we investigate whether these human-guided synthetic face detectors can assist non-expert human operators in the task of synthetic image detection when compared to models trained without human-guidance. We conducted a large-scale experiment with more than 1,560 subjects classifying whether an image shows an authentic or synthetically-generated face, and annotating regions supporting their decisions. In total, 56,015 annotations across 3,780 unique face images were collected. All subjects first examined samples without any AI support, followed by samples given (a) the AI&#39;s decision (``synthetic&#39;&#39; or ``authentic&#39;&#39;), (b) class activation maps illustrating where the model deems salient for its decision, or (c) both the AI&#39;s decision and AI&#39;s saliency map. Synthetic faces were generated with six modern Generative Adversarial Networks. Interesting observations from this experiment include: (1) models trained with human-guidance, which are also more accurate in our experiments, offer better support to human examination of face images when compared to models trained traditionally using cross-entropy loss, (2) binary decisions presented to humans results in their better performance than when saliency maps are presented, (3) understanding the AI&#39;s accuracy helps humans to increase trust in a given model and thus increase their overall accuracy. This work demonstrates that although humans supported by machines achieve better-than-random accuracy of synthetic face detection, the approaches of supplying humans with AI support and of building trust are key factors determining high effectiveness of the human-AI tandem.},
  archive   = {C_AAAI},
  author    = {Aidan Boyd and Patrick Tinsley and Kevin Bowyer and Adam Czajka},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25734},
  pages     = {5930-5938},
  title     = {The value of AI guidance in human examination of synthetically-generated faces},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The perils of trial-and-error reward design: Misdesign
through overfitting and invalid task specifications. <em>AAAI</em>,
5920–5929. (<a href="https://doi.org/10.1609/aaai.v37i5.25733">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In reinforcement learning (RL), a reward function that aligns exactly with a task&#39;s true performance metric is often necessarily sparse. For example, a true task metric might encode a reward of 1 upon success and 0 otherwise. The sparsity of these true task metrics can make them hard to learn from, so in practice they are often replaced with alternative dense reward functions. These dense reward functions are typically designed by experts through an ad hoc process of trial and error. In this process, experts manually search for a reward function that improves performance with respect to the task metric while also enabling an RL algorithm to learn faster. This process raises the question of whether the same reward function is optimal for all algorithms, i.e., whether the reward function can be overfit to a particular algorithm. In this paper, we study the consequences of this wide yet unexamined practice of trial-and-error reward design. We first conduct computational experiments that confirm that reward functions can be overfit to learning algorithms and their hyperparameters. We then conduct a controlled observation study which emulates expert practitioners&#39; typical experiences of reward design, in which we similarly find evidence of reward function overfitting. We also find that experts&#39; typical approach to reward design---of adopting a myopic strategy and weighing the relative goodness of each state-action pair---leads to misdesign through invalid task specifications, since RL algorithms use cumulative reward rather than rewards for individual state-action pairs as an optimization target. Code, data: github.com/serenabooth/reward-design-perils},
  archive   = {C_AAAI},
  author    = {Serena Booth and W. Bradley Knox and Julie Shah and Scott Niekum and Peter Stone and Alessandro Allievi},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25733},
  pages     = {5920-5929},
  title     = {The perils of trial-and-error reward design: Misdesign through overfitting and invalid task specifications},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Probably approximate shapley fairness with applications in
machine learning. <em>AAAI</em>, 5910–5918. (<a
href="https://doi.org/10.1609/aaai.v37i5.25732">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Shapley value (SV) is adopted in various scenarios in machine learning (ML), including data valuation, agent valuation, and feature attribution, as it satisfies their fairness requirements. However, as exact SVs are infeasible to compute in practice, SV estimates are approximated instead. This approximation step raises an important question: do the SV estimates preserve the fairness guarantees of exact SVs? We observe that the fairness guarantees of exact SVs are too restrictive for SV estimates. Thus, we generalise Shapley fairness to probably approximate Shapley fairness and propose fidelity score, a metric to measure the variation of SV estimates, that determines how probable the fairness guarantees hold. Our last theoretical contribution is a novel greedy active estimation (GAE) algorithm that will maximise the lowest fidelity score and achieve a better fairness guarantee than the de facto Monte-Carlo estimation. We empirically verify GAE outperforms several existing methods in guaranteeing fairness while remaining competitive in estimation accuracy in various ML scenarios using real-world datasets.},
  archive   = {C_AAAI},
  author    = {Zijian Zhou and Xinyi Xu and Rachael Hwee Ling Sim and Chuan Sheng Foo and Bryan Kian Hsiang Low},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25732},
  pages     = {5910-5918},
  title     = {Probably approximate shapley fairness with applications in machine learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fisher markets with social influence. <em>AAAI</em>,
5900–5909. (<a href="https://doi.org/10.1609/aaai.v37i5.25731">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A Fisher market is an economic model of buyer and seller interactions in which each buyer’s utility depends only on the bundle of goods she obtains. Many people’s interests, however, are affected by their social interactions with others. In this paper, we introduce a generalization of Fisher markets, namely influence Fisher markets, which captures the impact of social influence on buyers’ utilities. We show that competitive equilibria in influence Fisher markets correspond to generalized Nash equilibria in an associated pseudo-game, which implies the existence of competitive equilibria in all influence Fisher markets with continuous and concave utility functions. We then construct a monotone pseudo-game, whose variational equilibria and their duals together characterize competitive equilibria in influence Fisher markets with continuous, jointly concave, and homogeneous utility functions. This observation implies that competitive equilibria in these markets can be computed in polynomial time under standard smoothness assumptions on the utility functions. The dual of this second pseudo-game enables us to interpret the competitive equilibria of influence CCH Fisher markets as the solutions to a system of simultaneous Stackelberg games. Finally, we derive a novel first-order method that solves this Stackelberg system in polynomial time, prove that it is equivalent to computing competitive equilibrium prices via tâtonnement, and run experiments that confirm our theoretical results.},
  archive   = {C_AAAI},
  author    = {Jiayi Zhao and Denizalp Goktas and Amy Greenwald},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25731},
  pages     = {5900-5909},
  title     = {Fisher markets with social influence},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Collusion-proof and sybil-proof reward mechanisms for query
incentive networks. <em>AAAI</em>, 5892–5899. (<a
href="https://doi.org/10.1609/aaai.v37i5.25730">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper explores reward mechanisms for a query incentive network in which agents seek information from social networks. In a query tree issued by the task owner, each agent is rewarded by the owner for contributing to the solution, for instance, solving the task or inviting others to solve it. The reward mechanism determines the reward for each agent and motivates all agents to propagate and report their information truthfully. In particular, the reward cannot exceed the budget set by the task owner. However, our impossibility results demonstrate that a reward mechanism cannot simultaneously achieve Sybil-proof (agents benefit from manipulating multiple fake identities), collusion-proof (multiple agents pretend as a single agent to improve the reward), and other essential properties. In order to address these issues, we propose two novel reward mechanisms. The first mechanism achieves Sybil-proof and collusion-proof, respectively; the second mechanism sacrifices Sybil-proof to achieve the approximate versions of Sybil-proof and collusion-proof. Additionally, we show experimentally that our second reward mechanism outperforms the existing ones.},
  archive   = {C_AAAI},
  author    = {Youjia Zhang and Pingzhong Tang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25730},
  pages     = {5892-5899},
  title     = {Collusion-proof and sybil-proof reward mechanisms for query incentive networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Truthful mechanisms for steiner tree problems.
<em>AAAI</em>, 5884–5891. (<a
href="https://doi.org/10.1609/aaai.v37i5.25729">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Consider an undirected graph G=(V,E) model for a communication network, where each edge is owned by a selfish agent, who reports the cost for offering the use of her edge. Note that each edge agent may misreport her own cost for the use of the edge for her own benefit. In such a non-cooperative setting, we aim at designing an approximately truthful mechanism for establishing a Steiner tree, a minimum cost tree spanning over all the terminals. We present a truthful-in-expectation mechanism that achieves the approximation ratio ln 4 + ε ≈ 1.39, which matches the current best algorithmic ratio for STP.},
  archive   = {C_AAAI},
  author    = {Jinshan Zhang and Zhengyang Liu and Xiaotie Deng and Jianwei Yin},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25729},
  pages     = {5884-5891},
  title     = {Truthful mechanisms for steiner tree problems},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Tournament fixing parameterized by feedback vertex set
number is FPT. <em>AAAI</em>, 5876–5883. (<a
href="https://doi.org/10.1609/aaai.v37i5.25728">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A knockout (or single-elimination) tournament is a format of a competition that is very popular in practice (particularly in sports, elections and decision making), and which has been extensively and intensively studied from a theoretical point of view for more than a decade. Particular attention has been devoted to the Tournament Fixing problem, where, roughly speaking, the objective is to determine whether we can conduct the knockout tournament in a way that makes our favorite player win. Here, part of the input is a tournament graph D that encodes the winner of each possible match. A sequence of papers has studied the parameterized complexity of Tournament Fixing with respect to the feedback arc set number (fas) of D Given that this parameter yielded tractability, it has been asked explicitly and repeatedly whether Tournament Fixing is FPT also with respect to the feedback vertex set number (fvs) of D. We answer this question positively. In fact, although fvs can be arbitrarily smaller than fas, we attain the same dependency on the parameter in the time complexity. So, additionally, our work subsumes the best known algorithm for Tournament Fixing with respect to as.},
  archive   = {C_AAAI},
  author    = {Meirav Zehavi},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25728},
  pages     = {5876-5883},
  title     = {Tournament fixing parameterized by feedback vertex set number is FPT},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Semi-random impossibilities of condorcet criterion.
<em>AAAI</em>, 5867–5875. (<a
href="https://doi.org/10.1609/aaai.v37i5.25727">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Condorcet criterion (CC) is a classical and well-accepted criterion for voting. Unfortunately, it is incompatible with many other desiderata including participation (PAR), half-way monotonicity (HM), Maskin monotonicity (MM), and strategy-proofness (SP). Such incompatibilities are often known as impossibility theorems, and are proved by worst-case analysis. Previous work has investigated the likelihood for these impossibilities to occur under certain models, which are often criticized of being unrealistic. We strengthen previous work by proving the first set of semi-random impossibilities for voting rules to satisfy CC and the more general, group versions of the four desiderata: for any sufficiently large number of voters n, any size of the group 1},
  archive   = {C_AAAI},
  author    = {Lirong Xia},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25727},
  pages     = {5867-5875},
  title     = {Semi-random impossibilities of condorcet criterion},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bayesian optimization-based combinatorial assignment.
<em>AAAI</em>, 5858–5866. (<a
href="https://doi.org/10.1609/aaai.v37i5.25726">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the combinatorial assignment domain, which includes combinatorial auctions and course allocation. The main challenge in this domain is that the bundle space grows exponentially in the number of items. To address this, several papers have recently proposed machine learning-based preference elicitation algorithms that aim to elicit only the most important information from agents. However, the main shortcoming of this prior work is that it does not model a mechanism&#39;s uncertainty over values for not yet elicited bundles. In this paper, we address this shortcoming by presenting a Bayesian optimization-based combinatorial assignment (BOCA) mechanism. Our key technical contribution is to integrate a method for capturing model uncertainty into an iterative combinatorial auction mechanism. Concretely, we design a new method for estimating an upper uncertainty bound that can be used to define an acquisition function to determine the next query to the agents. This enables the mechanism to properly explore (and not just exploit) the bundle space during its preference elicitation phase. We run computational experiments in several spectrum auction domains to evaluate BOCA&#39;s performance. Our results show that BOCA achieves higher allocative efficiency than state-of-the-art approaches.},
  archive   = {C_AAAI},
  author    = {Jakob Weissteiner and Jakob Heiss and Julien Siems and Sven Seuken},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25726},
  pages     = {5858-5866},
  title     = {Bayesian optimization-based combinatorial assignment},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-stage facility location problems with transient
agents. <em>AAAI</em>, 5850–5857. (<a
href="https://doi.org/10.1609/aaai.v37i5.25725">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study various models for the one-dimensional multi-stage facility location problems with transient agents, where a transient agent arrives in some stage and stays for a number of consecutive stages. In the problems, we need to serve each agent in one of their stages by determining the location of the facility at each stage. In the first model, we assume there is no cost for moving the facility across the stages. We focus on optimal algorithms to minimize both the social cost objective, defined as the total distance of all agents to the facility over all stages, and the maximum cost objective, defined as the max distance of any agent to the facility over all stages. For each objective, we give a slice-wise polynomial (XP) algorithm (i.e., solvable in m^f(k) for some fixed parameter k and computable function f, where m is the input size) and show that there is a polynomial-time algorithm when a natural first-come-first-serve (FCFS) order of agent serving is enforced. We then consider the mechanism design problem, where the agents&#39; locations and arrival stages are private, and design a group strategy-proof mechanism that achieves good approximation ratios for both objectives and settings with and without FCFS ordering. In the second model, we consider the facility&#39;s moving cost between adjacent stages under the social cost objective, which accounts for the total moving distance of the facility. Correspondingly, we design XP (and polynomial time) algorithms and a group strategy-proof mechanism for settings with or without the FCFS ordering.},
  archive   = {C_AAAI},
  author    = {Xuezhen Wang and Vincent Chau and Hau Chan and Ken C.K. Fong and Minming Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25725},
  pages     = {5850-5857},
  title     = {Multi-stage facility location problems with transient agents},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Ballot length in instant runoff voting. <em>AAAI</em>,
5841–5849. (<a href="https://doi.org/10.1609/aaai.v37i5.25724">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Instant runoff voting (IRV) is an increasingly-popular alternative to traditional plurality voting in which voters submit rankings over the candidates rather than single votes. In practice, elections using IRV often restrict the ballot length, the number of candidates a voter is allowed to rank on their ballot. We theoretically and empirically analyze how ballot length can influence the outcome of an election, given fixed voter preferences. We show that there exist preference profiles over k candidates such that up to k-1 different candidates win at different ballot lengths. We derive exact lower bounds on the number of voters required for such profiles and provide a construction matching the lower bound for unrestricted voter preferences. Additionally, we characterize which sequences of winners are possible over ballot lengths and provide explicit profile constructions achieving any feasible winner sequence. We also examine how classic preference restrictions influence our results—for instance, single-peakedness makes k-1 different winners impossible but still allows at least Ω(√k). Finally, we analyze a collection of 168 real-world elections, where we truncate rankings to simulate shorter ballots. We find that shorter ballots could have changed the outcome in one quarter of these elections. Our results highlight ballot length as a consequential degree of freedom in the design of IRV elections.},
  archive   = {C_AAAI},
  author    = {Kiran Tomlinson and Johan Ugander and Jon Kleinberg},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25724},
  pages     = {5841-5849},
  title     = {Ballot length in instant runoff voting},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fast and interpretable dynamics for fisher markets via
block-coordinate updates. <em>AAAI</em>, 5832–5840. (<a
href="https://doi.org/10.1609/aaai.v37i5.25723">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider the problem of large-scale Fisher market equilibrium computation through scalable first-order optimization methods. It is well-known that market equilibria can be captured using structured convex programs such as the Eisenberg-Gale and Shmyrev convex programs. Highly performant deterministic full-gradient first-order methods have been developed for these programs. In this paper, we develop new block-coordinate first-order methods for computing Fisher market equilibria, and show that these methods have interpretations as tâtonnement-style or proportional response-style dynamics where either buyers or items show up one at a time. We reformulate these convex programs and solve them using proximal block coordinate descent methods, a class of methods that update only a small number of coordinates of the decision variable in each iteration. Leveraging recent advances in the convergence analysis of these methods and structures of the equilibrium-capturing convex programs, we establish fast convergence rates of these methods.},
  archive   = {C_AAAI},
  author    = {Tianlong Nan and Yuan Gao and Christian Kroer},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25723},
  pages     = {5832-5840},
  title     = {Fast and interpretable dynamics for fisher markets via block-coordinate updates},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An efficient deep reinforcement learning algorithm for
solving imperfect information extensive-form games. <em>AAAI</em>,
5823–5831. (<a href="https://doi.org/10.1609/aaai.v37i5.25722">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {One of the most popular methods for learning Nash equilibrium (NE) in large-scale imperfect information extensive-form games (IIEFGs) is the neural variants of counterfactual regret minimization (CFR). CFR is a special case of Follow-The-Regularized-Leader (FTRL). At each iteration, the neural variants of CFR update the agent&#39;s strategy via the estimated counterfactual regrets. Then, they use neural networks to approximate the new strategy, which incurs an approximation error. These approximation errors will accumulate since the counterfactual regrets at iteration t are estimated using the agent&#39;s past approximated strategies. Such accumulated approximation error causes poor performance. To address this accumulated approximation error, we propose a novel FTRL algorithm called FTRL-ORW, which does not utilize the agent&#39;s past strategies to pick the next iteration strategy. More importantly, FTRL-ORW can update its strategy via the trajectories sampled from the game, which is suitable to solve large-scale IIEFGs since sampling multiple actions for each information set is too expensive in such games. However, it remains unclear which algorithm to use to compute the next iteration strategy for FTRL-ORW when only such sampled trajectories are revealed at iteration t. To address this problem and scale FTRL-ORW to large-scale games, we provide a model-free method called Deep FTRL-ORW, which computes the next iteration strategy using model-free Maximum Entropy Deep Reinforcement Learning. Experimental results on two-player zero-sum IIEFGs show that Deep FTRL-ORW significantly outperforms existing model-free neural methods and OS-MCCFR.},
  archive   = {C_AAAI},
  author    = {Linjian Meng and Zhenxing Ge and Pinzhuo Tian and Bo An and Yang Gao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25722},
  pages     = {5823-5831},
  title     = {An efficient deep reinforcement learning algorithm for solving imperfect information extensive-form games},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Differentially private fair division. <em>AAAI</em>,
5814–5822. (<a href="https://doi.org/10.1609/aaai.v37i5.25721">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Fairness and privacy are two important concerns in social decision-making processes such as resource allocation. We study privacy in the fair allocation of indivisible resources using the well-established framework of differential privacy. We present algorithms for approximate envy-freeness and proportionality when two instances are considered to be adjacent if they differ only on the utility of a single agent for a single item. On the other hand, we provide strong negative results for both fairness criteria when the adjacency notion allows the entire utility function of a single agent to change.},
  archive   = {C_AAAI},
  author    = {Pasin Manurangsi and Warut Suksompong},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25721},
  pages     = {5814-5822},
  title     = {Differentially private fair division},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Securing lifelines: Safe delivery of critical services in
areas with volatile security situation via a stackelberg game approach.
<em>AAAI</em>, 5805–5813. (<a
href="https://doi.org/10.1609/aaai.v37i5.25720">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Vaccine delivery in under-resourced locations with security risks is not just challenging but also life threatening. The COVID pandemic and the need to vaccinate added even more urgency to this issue. Motivated by this problem, we propose a general framework to set-up limited temporary (vaccination) centers that balance physical security and desired (vaccine) service coverage with limited resources. We set-up the problem as a Stackelberg game between the centers operator (defender) and an adversary, where the set of centers is not fixed a priori but is part of the decision output. This results in a mixed combinatorial and continuous optimization problem. As part of our scalable approximation solution, we provide a fundamental contribution by identifying general duality conditions of switching max and min when both discrete and continuous variables are involved. Via detailed experiments, we show that the solution proposed is scalable in practice.},
  archive   = {C_AAAI},
  author    = {Tien Mai and Arunesh Sinha},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25720},
  pages     = {5805-5813},
  title     = {Securing lifelines: Safe delivery of critical services in areas with volatile security situation via a stackelberg game approach},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Facility location games with entrance fees. <em>AAAI</em>,
5797–5804. (<a href="https://doi.org/10.1609/aaai.v37i5.25719">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The facility location game is an extensively studied problem in mechanism design. In the classical model, the cost of each agent is her distance to the nearest facility. In this paper, we consider a novel model where each facility charges an entrance fee, which is a function of the facility&#39;s location. Thus, in our model, the cost of each agent is the sum of the distance to the facility and the entrance fee of the facility. The generalized model captures more real-life scenarios. In our model, the entrance fee function can be an arbitrary function, and the corresponding preferences of agents may not be single-peaked anymore: this makes the problem complex and requires new techniques in the analysis. We systematically study the model and design strategyproof mechanisms with nice approximation ratios and also complement these with nearly-tight impossibility results. Specifically, for one-facility and two-facility games, we provide upper and lower bounds for the approximation ratios given by deterministic and randomized mechanisms, with respect to the utilitarian and egalitarian objectives. Most of our bounds are tight, and these bounds are independent of the entrance fee functions. Our results also match the results of the classical model.},
  archive   = {C_AAAI},
  author    = {Mengfan Ma and Mingyu Xiao and Tian Bai and Bakh Khoussainov},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25719},
  pages     = {5797-5804},
  title     = {Facility location games with entrance fees},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Utility maximizer or value maximizer: Mechanism design for
mixed bidders in online advertising. <em>AAAI</em>, 5789–5796. (<a
href="https://doi.org/10.1609/aaai.v37i5.25718">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Digital advertising constitutes one of the main revenue sources for online platforms. In recent years, some advertisers tend to adopt auto-bidding tools to facilitate advertising performance optimization, making the classical utility maximizer model in auction theory not fit well. Some recent studies proposed a new model, called value maximizer, for auto-bidding advertisers with return-on-investment (ROI) constraints. However, the model of either utility maximizer or value maximizer could only characterize partial advertisers in real-world advertising platforms. In a mixed environment where utility maximizers and value maximizers coexist, the truthful ad auction design would be challenging since bidders could manipulate both their values and affiliated classes, leading to a multi-parameter mechanism design problem. In this work, we address this issue by proposing a payment rule which combines the corresponding ones in classical VCG and GSP mechanisms in a novel way. Based on this payment rule, we propose a truthful auction mechanism with an approximation ratio of 2 on social welfare, which is close to the lower bound of at least 5/4 that we also prove. The designed auction mechanism is a generalization of VCG for utility maximizers and GSP for value maximizers.},
  archive   = {C_AAAI},
  author    = {Hongtao Lv and Zhilin Zhang and Zhenzhe Zheng and Jinghan Liu and Chuan Yu and Lei Liu and Lizhen Cui and Fan Wu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25718},
  pages     = {5789-5796},
  title     = {Utility maximizer or value maximizer: Mechanism design for mixed bidders in online advertising},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Approval-based voting with mixed goods. <em>AAAI</em>,
5781–5788. (<a href="https://doi.org/10.1609/aaai.v37i5.25717">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider a voting scenario in which the resource to be voted upon may consist of both indivisible and divisible goods. This generalizes both the well-studied model of multiwinner voting and the recently introduced model of cake sharing. Under approval votes, we propose two variants of the extended justified representation (EJR) notion from multiwinner voting, a stronger one called EJR for mixed goods (EJR-M) and a weaker one called EJR up to 1 (EJR-1). We extend three multiwinner voting rules to our setting—GreedyEJR, the method of equal shares (MES), and proportional approval voting (PAV)—and show that while all three generalizations satisfy EJR-1, only the first one provides EJR-M. In addition, we derive tight bounds on the proportionality degree implied by EJR-M and EJR-1, and investigate the proportionality degree of our proposed rules.},
  archive   = {C_AAAI},
  author    = {Xinhang Lu and Jannik Peters and Haris Aziz and Xiaohui Bei and Warut Suksompong},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25717},
  pages     = {5781-5788},
  title     = {Approval-based voting with mixed goods},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimal pricing schemes for identical items with
time-sensitive buyers. <em>AAAI</em>, 5773–5780. (<a
href="https://doi.org/10.1609/aaai.v37i5.25716">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Time or money? That is a question! In this paper, we consider this dilemma in the pricing regime, in which we try to find the optimal pricing scheme for identical items with heterogenous time-sensitive buyers. We characterize the revenue-optimal solution and propose an efficient algorithm to find it in a Bayesian setting. Our results also demonstrate the tight ratio between the value of wasted time and the seller&#39;s revenue, as well as that of two common-used pricing schemes, the k-step function and the fixed pricing. To explore the nature of the optimal scheme in the general setting, we present the closed forms over the product distribution and show by examples that positive correlation between the valuation of the item and the cost per unit time could help increase revenue. To the best of our knowledge, it is the first step towards understanding the impact of the time factor as a part of the buyer cost in pricing problems, in the computational view.},
  archive   = {C_AAAI},
  author    = {Zhengyang Liu and Liang Shan and Zihe Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25716},
  pages     = {5773-5780},
  title     = {Optimal pricing schemes for identical items with time-sensitive buyers},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Function approximation for solving stackelberg equilibrium
in large perfect information games. <em>AAAI</em>, 5764–5772. (<a
href="https://doi.org/10.1609/aaai.v37i5.25715">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Function approximation (FA) has been a critical component in solving large zero-sum games. Yet, little attention has been given towards FA in solving general-sum extensive-form games, despite them being widely regarded as being computationally more challenging than their fully competitive or cooperative counterparts. A key challenge is that for many equilibria in general-sum games, no simple analogue to the state value function used in Markov Decision Processes and zero-sum games exists. In this paper, we propose learning the Enforceable Payoff Frontier (EPF)---a generalization of the state value function for general-sum games. We approximate the optimal Stackelberg extensive-form correlated equilibrium by representing EPFs with neural networks and training them by using appropriate backup operations and loss functions. This is the first method that applies FA to the Stackelberg setting, allowing us to scale to much larger games while still enjoying performance guarantees based on FA error. Additionally, our proposed method guarantees incentive compatibility and is easy to evaluate without having to depend on self-play or approximate best-response oracles.},
  archive   = {C_AAAI},
  author    = {Chun Kai Ling and J. Zico Kolter and Fei Fang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25715},
  pages     = {5764-5772},
  title     = {Function approximation for solving stackelberg equilibrium in large perfect information games},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Differentially private condorcet voting. <em>AAAI</em>,
5755–5763. (<a href="https://doi.org/10.1609/aaai.v37i5.25714">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Designing private voting rules is an important and pressing problem for trustworthy democracy. In this paper, under the framework of differential privacy, we propose a novel famliy of randomized voting rules based on the well-known Condorcet method, and focus on three classes of voting rules in this family: Laplacian Condorcet method (CMLAP), exponential Condorcet method (CMEXP), and randomized response Condorcet method (CMRR), where λ represents the level of noise. We prove that all of our rules satisfy absolute monotonicity, lexi-participation, probabilistic Pareto efficiency, approximate probabilistic Condorcet criterion, and approximate SD-strategyproofness. In addition, CMRR satisfies (non-approximate) probabilistic Condorcet criterion, while CMLAP and CMEXP satisfy strong lexi-participation. Finally, we regard differential privacy as a voting axiom, and discuss its relations to other axioms.},
  archive   = {C_AAAI},
  author    = {Zhechen Li and Ao Liu and Lirong Xia and Yongzhi Cao and Hanpin Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25714},
  pages     = {5755-5763},
  title     = {Differentially private condorcet voting},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Partitioning friends fairly. <em>AAAI</em>, 5747–5754. (<a
href="https://doi.org/10.1609/aaai.v37i5.25713">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider the problem of partitioning n agents in an undirected social network into k almost equal in size (differing by at most one) groups, where the utility of an agent for a group is the number of her neighbors in the group. The core and envy-freeness are two compelling axiomatic fairness guarantees in such settings. The former demands that there be no coalition of agents such that each agent in the coalition has more utility for that coalition than for her own group, while the latter demands that no agent envy another agent for the group they are in. We provide (often tight) approximations to both fairness guarantees, and many of our positive results are obtained via efficient algorithms.},
  archive   = {C_AAAI},
  author    = {Lily Li and Evi Micha and Aleksandar Nikolov and Nisarg Shah},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25713},
  pages     = {5747-5754},
  title     = {Partitioning friends fairly},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). When congestion games meet mobile crowdsourcing: Selective
information disclosure. <em>AAAI</em>, 5739–5746. (<a
href="https://doi.org/10.1609/aaai.v37i5.25712">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In congestion games, users make myopic routing decisions to jam each other, and the social planner with the full information designs mechanisms on information or payment side to regulate. However, it is difficult to obtain time-varying traffic conditions, and emerging crowdsourcing platforms (e.g., Waze and Google Maps) provide a convenient way for mobile users travelling on the paths to learn and share the traffic conditions over time. When congestion games meet mobile crowdsourcing, it is critical to incentive selfish users to change their myopic routing policy and reach the best exploitation-exploration trade-off. By considering a simple but fundamental parallel routing network with one deterministic path and multiple stochastic paths for atomic users, we prove that the myopic routing policy&#39;s price of anarchy (PoA) can be arbitrarily large as the discount factor approaches 1. To remedy such huge efficiency loss, we propose a selective information disclosure (SID) mechanism: we only reveal the latest traffic information to users when they intend to over-explore the stochastic paths, while hiding such information when they want to under-explore. We prove that our mechanism reduces PoA to less than 2. Besides the worst-case performance, we further examine our mechanism&#39;s average-case performance by using extensive simulations.},
  archive   = {C_AAAI},
  author    = {Hongbo Li and Lingjie Duan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25712},
  pages     = {5739-5746},
  title     = {When congestion games meet mobile crowdsourcing: Selective information disclosure},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Multiagent MST cover: Pleasing all optimally via a simple
voting rule. <em>AAAI</em>, 5730–5738. (<a
href="https://doi.org/10.1609/aaai.v37i5.25711">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Given a connected graph on whose edges we can build roads to connect the nodes, a number of agents hold possibly different perspectives on which edges should be selected by assigning different edge weights. Our task is to build a minimum number of roads so that every agent has a spanning tree in the built subgraph whose weight is the same as a minimum spanning tree in the original graph. We first show that this problem is NP-hard and does not admit better than ((1-o(1)) ln k)-approximation polynomial-time algorithms unless P = NP, where k is the number of agents. We then give a simple voting algorithm with an optimal approximation ratio. Moreover, our algorithm only needs to access the agents&#39; rankings on the edges. Finally, we extend our problem to submodular objective functions and Matroid rank constraints.},
  archive   = {C_AAAI},
  author    = {Bo Li and Xiaowei Wu and Chenyang Xu and Ruilong Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25711},
  pages     = {5730-5738},
  title     = {Multiagent MST cover: Pleasing all optimally via a simple voting rule},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Proportional decisions in perpetual voting. <em>AAAI</em>,
5722–5729. (<a href="https://doi.org/10.1609/aaai.v37i5.25710">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Perpetual voting is a framework for long-term collective decision making. In this framework, we consider a sequence of subsequent approval-based elections and try to achieve a fair overall outcome. To achieve fairness over time, perpetual voting rules take the history of previous decisions into account and identify voters that were dissatisfied with previous decisions. In this paper, we look at perpetual voting rules from an axiomatic perspective. First, we define two classes of perpetual voting rules that are particularly easy to explain to voters and explore the bounds imposed by this simplicity. Second, we study proportionality in the perpetual setting and identify two rules with strong proportionality guarantees. However, both rules yield different guarantees and we prove them to be incompatible with each other.},
  archive   = {C_AAAI},
  author    = {Martin Lackner and Jan Maly},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25710},
  pages     = {5722-5729},
  title     = {Proportional decisions in perpetual voting},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Strategic facility location with clients that minimize total
waiting time. <em>AAAI</em>, 5714–5721. (<a
href="https://doi.org/10.1609/aaai.v37i5.25709">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study a non-cooperative two-sided facility location game in which facilities and clients behave strategically. This is in contrast to many other facility location games in which clients simply visit their closest facility. Facility agents select a location on a graph to open a facility to attract as much purchasing power as possible, while client agents choose which facilities to patronize by strategically distributing their purchasing power in order to minimize their total waiting time. Here, the waiting time of a facility depends on its received total purchasing power. We show that our client stage is an atomic splittable congestion game, which implies existence, uniqueness and efficient computation of a client equilibrium. Therefore, facility agents can efficiently predict client behavior and make strategic decisions accordingly. Despite that, we prove that subgame perfect equilibria do not exist in all instances of this game and that their existence is NP-hard to decide. On the positive side, we provide a simple and efficient algorithm to compute 3-approximate subgame perfect equilibria.},
  archive   = {C_AAAI},
  author    = {Simon Krogmann and Pascal Lenzner and Alexander Skopalik},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25709},
  pages     = {5714-5721},
  title     = {Strategic facility location with clients that minimize total waiting time},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Approximations for indivisible concave allocations with
applications to nash welfare maximization. <em>AAAI</em>, 5705–5713. (<a
href="https://doi.org/10.1609/aaai.v37i5.25708">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study a general allocation setting where agent valuations are concave additive. In this model, a collection of items must be uniquely distributed among a set of agents, where each agent-item pair has a specified utility. The objective is to maximize the sum of agent valuations, each of which is an arbitrary non-decreasing concave function of the agent&#39;s total additive utility. This setting was studied by Devanur and Jain (STOC 2012) in the online setting for divisible items. In this paper, we obtain both multiplicative and additive approximations in the offline setting for indivisible items. Our approximations depend on novel parameters that measure the local multiplicative/additive curvatures of each agent valuation, which we show correspond directly to the integrality gap of the natural assignment convex program of the problem. Furthermore, we extend our additive guarantees to obtain constant multiplicative approximations for Asymmetric Nash Welfare Maximization when agents have smooth valuations. This algorithm also yields an interesting tatonnement-style interpretation, where agents adjust uniform prices and items are assigned according to maximum weighted bang-per-buck ratios.},
  archive   = {C_AAAI},
  author    = {Nathaniel Kell and Kevin Sun},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25708},
  pages     = {5705-5713},
  title     = {Approximations for indivisible concave allocations with applications to nash welfare maximization},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Voting with preference intensities. <em>AAAI</em>,
5697–5704. (<a href="https://doi.org/10.1609/aaai.v37i5.25707">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {When an agent votes, she typically ranks the set of available alternatives. Occasionally, she may also wish to report the intensity of her preferences by indicating adjacent pairs of alternatives in her ranking between which her preference is acutely decisive; for instance, she may suggest that she likes alternative a more than b, but b much more than c. We design near-optimal voting rules which aggregate such preference rankings with intensities using the recently-popular distortion framework. We also show that traditional voting rules, which aggregate preference rankings while ignoring (or not eliciting) intensities, can incur significant welfare loss.},
  archive   = {C_AAAI},
  author    = {Anson Kahng and Mohamad Latifian and Nisarg Shah},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25707},
  pages     = {5697-5704},
  title     = {Voting with preference intensities},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Competition, alignment, and equilibria in digital
marketplaces. <em>AAAI</em>, 5689–5696. (<a
href="https://doi.org/10.1609/aaai.v37i5.25706">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Competition between traditional platforms is known to improve user utility by aligning the platform&#39;s actions with user preferences. But to what extent is alignment exhibited in data-driven marketplaces? To study this question from a theoretical perspective, we introduce a duopoly market where platform actions are bandit algorithms and the two platforms compete for user participation. A salient feature of this market is that the quality of recommendations depends on both the bandit algorithm and the amount of data provided by interactions from users. This interdependency between the algorithm performance and the actions of users complicates the structure of market equilibria and their quality in terms of user utility. Our main finding is that competition in this market does not perfectly align market outcomes with user utility. Interestingly, market outcomes exhibit misalignment not only when the platforms have separate data repositories, but also when the platforms have a shared data repository. Nonetheless, the data sharing assumptions impact what mechanism drives misalignment and also affect the specific form of misalignment (e.g. the quality of the best-case and worst-case market outcomes). More broadly, our work illustrates that competition in digital marketplaces has subtle consequences for user utility that merit further investigation.},
  archive   = {C_AAAI},
  author    = {Meena Jagadeesan and Michael I. Jordan and Nika Haghtalab},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25706},
  pages     = {5689-5696},
  title     = {Competition, alignment, and equilibria in digital marketplaces},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). How to cut a discrete cake fairly. <em>AAAI</em>, 5681–5688.
(<a href="https://doi.org/10.1609/aaai.v37i5.25705">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Cake-cutting is a fundamental model of dividing a heterogeneous resource, such as land, broadcast time, and advertisement space. In this study, we consider the problem of dividing indivisible goods fairly under the connectivity constraints of a path. We prove that a connected division of indivisible items satisfying a discrete counterpart of envy-freeness, called envy-freeness up to one good (EF1), always exists for any number of agents n with monotone valuations. Our result settles an open question raised by Bilò et al. (2019), who proved that an EF1 connected division always exists for four agents with monotone valuations. Moreover, the proof can be extended to show the following (1) ``secretive&quot; and (2) ``extra&quot; versions: (1) for n agents with monotone valuations, the path can be divided into n connected bundles such that an EF1 assignment of the remaining bundles can be made to the other agents for any selection made by the “secretive agent”; (2) for n+1 agents with monotone valuations, the path can be divided into n connected bundles such that when any ``extra agent” leaves, an EF1 assignment of the bundles can be made to the remaining agents.},
  archive   = {C_AAAI},
  author    = {Ayumi Igarashi},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25705},
  pages     = {5681-5688},
  title     = {How to cut a discrete cake fairly},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Class fairness in online matching. <em>AAAI</em>, 5673–5680.
(<a href="https://doi.org/10.1609/aaai.v37i5.25704">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We initiate the study of fairness among classes of agents in online bipartite matching where there is a given set of offline vertices (aka agents) and another set of vertices (aka items) that arrive online and must be matched irrevocably upon arrival. In this setting, agents are partitioned into a set of classes and the matching is required to be fair with respect to the classes. We adopt popular fairness notions (e.g. envy-freeness, proportionality, and maximin share) and their relaxations to this setting and study deterministic and randomized algorithms for matching indivisible items (leading to integral matchings) and for matching divisible items (leading to fractional matchings). For matching indivisible items, we propose an adaptive-priority-based algorithm, MATCH-AND-SHIFT, prove that it achieves (1/2)-approximation of both class envy-freeness up to one item and class maximin share fairness, and show that each guarantee is tight. For matching divisible items, we design a water-filling-based algorithm, EQUAL-FILLING, that achieves (1-1/e)-approximation of class envy-freeness and class proportionality; we prove (1-1/e) to be tight for class proportionality and establish a 3/4 upper bound on class envy-freeness.},
  archive   = {C_AAAI},
  author    = {Hadi Hosseini and Zhiyi Huang and Ayumi Igarashi and Nisarg Shah},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25704},
  pages     = {5673-5680},
  title     = {Class fairness in online matching},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Optimizing multiple simultaneous objectives for voting and
facility location. <em>AAAI</em>, 5665–5672. (<a
href="https://doi.org/10.1609/aaai.v37i5.25703">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the classic facility location setting, where we are given n clients and m possible facility locations in some arbitrary metric space, and want to choose a location to build a facility. The exact same setting also arises in spatial social choice, where voters are the clients and the goal is to choose a candidate or outcome, with the distance from a voter to an outcome representing the cost of this outcome for the voter (e.g., based on their ideological differences). Unlike most previous work, we do not focus on a single objective to optimize (e.g., the total distance from clients to the facility, or the maximum distance, etc.), but instead attempt to optimize several different objectives simultaneously. More specifically, we consider the l-centrum family of objectives, which includes the total distance, max distance, and many others. We present tight bounds on how well any pair of such objectives (e.g., max and sum) can be simultaneously approximated compared to their optimum outcomes. In particular, we show that for any such pair of objectives, it is always possible to choose an outcome which simultaneously approximates both objectives within a factor of 1 plus square root of 2, and give a precise characterization of how this factor improves as the two objectives being optimized become more similar. For q&gt;2 different centrum objectives, we show that it is always possible to approximate all q of these objectives within a small constant, and that this constant approaches 3 as q increases. Our results show that when optimizing only a few simultaneous objectives, it is always possible to form an outcome which is a significantly better than 3 approximation for all of these objectives.},
  archive   = {C_AAAI},
  author    = {Yue Han and Christopher Jerrett and Elliot Anshelevich},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25703},
  pages     = {5665-5672},
  title     = {Optimizing multiple simultaneous objectives for voting and facility location},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Representation with incomplete votes. <em>AAAI</em>,
5657–5664. (<a href="https://doi.org/10.1609/aaai.v37i5.25702">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Platforms for online civic participation rely heavily on methods for condensing thousands of comments into a relevant handful, based on whether participants agree or disagree with them. These methods should guarantee fair representation of the participants, as their outcomes may affect the health of the conversation and inform impactful downstream decisions. To that end, we draw on the literature on approval-based committee elections. Our setting is novel in that the approval votes are incomplete since participants will typically not vote on all comments. We prove that this complication renders non-adaptive algorithms impractical in terms of the amount of information they must gather. Therefore, we develop an adaptive algorithm that uses information more efficiently by presenting incoming participants with statements that appear promising based on votes by previous participants. We prove that this method satisfies commonly used notions of fair representation, even when participants only vote on a small fraction of comments. Finally, an empirical evaluation using real data shows that the proposed algorithm provides representative outcomes in practice.},
  archive   = {C_AAAI},
  author    = {Daniel Halpern and Gregory Kehne and Ariel D. Procaccia and Jamie Tucker-Foltz and Manuel Wüthrich},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25702},
  pages     = {5657-5664},
  title     = {Representation with incomplete votes},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Scalable edge blocking algorithms for defending active
directory style attack graphs. <em>AAAI</em>, 5649–5656. (<a
href="https://doi.org/10.1609/aaai.v37i5.25701">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Active Directory (AD) is the default security management system for Windows domain networks. An AD environment naturally describes an attack graph where nodes represent computers/accounts/security groups, and edges represent existing accesses/known exploits that allow the attacker to gain access from one node to another. Motivated by practical AD use cases, we study a Stackelberg game between one attacker and one defender. There are multiple entry nodes for the attacker to choose from and there is a single target (Domain Admin). Every edge has a failure rate. The attacker chooses the attack path with the maximum success rate. The defender can block a limited number of edges (i.e., revoke accesses) from a set of blockable edges, limited by budget. The defender&#39;s aim is to minimize the attacker&#39;s success rate. We exploit the tree-likeness of practical AD graphs to design scalable algorithms. We propose two novel methods that combine theoretical fixed parameter analysis and practical optimisation techniques. For graphs with small tree widths, we propose a tree decomposition based dynamic program. We then propose a general method for converting tree decomposition based dynamic programs to reinforcement learning environments, which leads to an anytime algorithm that scales better, but loses the optimality guarantee. For graphs with small numbers of non-splitting paths (a parameter we invent specifically for AD graphs), we propose a kernelization technique that significantly downsizes the model, which is then solved via mixed-integer programming. Experimentally, our algorithms scale to handle synthetic AD graphs with tens of thousands of nodes.},
  archive   = {C_AAAI},
  author    = {Mingyu Guo and Max Ward and Aneta Neumann and Frank Neumann and Hung Nguyen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25701},
  pages     = {5649-5656},
  title     = {Scalable edge blocking algorithms for defending active directory style attack graphs},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PAC learning and stabilizing hedonic games: Towards a
unifying approach. <em>AAAI</em>, 5641–5648. (<a
href="https://doi.org/10.1609/aaai.v37i5.25700">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study PAC learnability and PAC stabilizability of Hedonic Games (HGs), i.e., efficiently inferring preferences or core-stable partitions from samples. We first expand the known learnability/stabilizability landscape for some of the most prominent HGs classes, providing results for Friends and Enemies Games, Bottom Responsive, and Anonymous HGs. Then, having a broader view in mind, we attempt to shed light on the structural properties leading to learnability/stabilizability, or lack thereof, for specific HGs classes. Along this path, we focus on the fully expressive Hedonic Coalition Nets representation of HGs. We identify two sets of conditions that lead to efficient learnability, and which encompass all of the known positive learnability results. On the side of stability, we reveal that, while the freedom of choosing an ad hoc adversarial distribution is the most obvious hurdle to achieving PAC stability, it is not the only one. First, we show a distribution independent necessary condition for PAC stability. Then, we focus on W-games, where players have individual preferences over other players and evaluate coalitions based on the least preferred member. We prove that these games are PAC stabilizable under the class of bounded distributions, which assign positive probability mass to all coalitions. Finally, we discuss why such a result is not easily extendable to other HGs classes even in this promising scenario. Namely, we establish a purely computational property necessary for achieving PAC stability.},
  archive   = {C_AAAI},
  author    = {Simone Fioravanti and Michele Flammini and Bojana Kodric and Giovanna Varricchio},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25700},
  pages     = {5641-5648},
  title     = {PAC learning and stabilizing hedonic games: Towards a unifying approach.},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Participatory budgeting designs for the real world.
<em>AAAI</em>, 5633–5640. (<a
href="https://doi.org/10.1609/aaai.v37i5.25699">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Participatory budgeting engages the public in the process of allocating public money to different types of projects. PB designs differ in how voters are asked to express their preferences over candidate projects and how these preferences are aggregated to determine which projects to fund. This paper studies two fundamental questions in PB design. Which voting format and aggregation method to use, and how to evaluate the outcomes of these design decisions? We conduct an extensive empirical study in which 1 800 participants vote in four participatory budgeting elections in a controlled setting to evaluate the practical effects of the choice of voting format and aggregation rule.We find that k-approval leads to the best user experience. With respect to the aggregation rule, greedy aggregation leads to outcomes that are highly sensitive to the input format used and the fraction of the population that participates. The method of equal shares, in contrast, leads to outcomes that are not sensitive to the type of voting format used, and these outcomes are remarkably stable even when the majority of the population does not participate in the election. These results carry valuable insights for PB practitioners and social choice researchers.},
  archive   = {C_AAAI},
  author    = {Roy Fairstein and Gerdus Benadè and Kobi Gal},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25699},
  pages     = {5633-5640},
  title     = {Participatory budgeting designs for the real world},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Rawlsian fairness in online bipartite matching: Two-sided,
group, and individual. <em>AAAI</em>, 5624–5632. (<a
href="https://doi.org/10.1609/aaai.v37i5.25698">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Online bipartite-matching platforms are ubiquitous and find applications in important areas such as crowdsourcing and ridesharing. In the most general form, the platform consists of three entities: two sides to be matched and a platform operator that decides the matching. The design of algorithms for such platforms has traditionally focused on the operator’s (expected) profit. Since fairness has become an important consideration that was ignored in the existing algorithms a collection of online matching algorithms have been developed that give a fair treatment guarantee for one side of the market at the expense of a drop in the operator’s profit. In this paper, we generalize the existing work to offer fair treatment guarantees to both sides of the market simultaneously, at a calculated worst case drop to operator profit. We consider group and individual Rawlsian fairness criteria. Moreover, our algorithms have theoretical guarantees and have adjustable parameters that can be tuned as desired to balance the trade-off between the utilities of the three sides. We also derive hardness results that give clear upper bounds over the performance of any algorithm.},
  archive   = {C_AAAI},
  author    = {Seyed Esmaeili and Sharmila Duppala and Davidson Cheng and Vedant Nanda and Aravind Srinivasan and John P. Dickerson},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25698},
  pages     = {5624-5632},
  title     = {Rawlsian fairness in online bipartite matching: Two-sided, group, and individual},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Commitment games with conditional information disclosure.
<em>AAAI</em>, 5616–5623. (<a
href="https://doi.org/10.1609/aaai.v37i5.25697">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The conditional commitment abilities of mutually transparent computer agents have been studied in previous work on commitment games and program equilibrium. This literature has shown how these abilities can help resolve Prisoner’s Dilemmas and other failures of cooperation in complete information settings. But inefficiencies due to private information have been neglected thus far in this literature, despite the fact that these problems are pervasive and might also be addressed by greater mutual transparency. In this work, we introduce a framework for commitment games with a new kind of conditional commitment device, which agents can use to conditionally disclose private information. We prove a folk theorem for this setting that provides sufficient conditions for ex post efficiency, and thus represents a model of ideal cooperation between agents without a third-party mediator. Further, extending previous work on program equilibrium, we develop an implementation of conditional information disclosure. We show that this implementation forms program ε-Bayesian Nash equilibria corresponding to the Bayesian Nash equilibria of these commitment games.},
  archive   = {C_AAAI},
  author    = {Anthony DiGiovanni and Jesse Clifton},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25697},
  pages     = {5616-5623},
  title     = {Commitment games with conditional information disclosure},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). From monopoly to competition: Optimal contests prevail.
<em>AAAI</em>, 5608–5615. (<a
href="https://doi.org/10.1609/aaai.v37i5.25696">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study competition among contests in a general model that allows for an arbitrary and heterogeneous space of contest design and symmetric contestants. The goal of the contest designers is to maximize the contestants&#39; sum of efforts. Our main result shows that optimal contests in the monopolistic setting (i.e., those that maximize the sum of efforts in a model with a single contest) form an equilibrium in the model with competition among contests. Under a very natural assumption these contests are in fact dominant, and the equilibria that they form are unique. Moreover, equilibria with the optimal contests are Pareto-optimal even in cases where other equilibria emerge. In many natural cases, they also maximize the social welfare.},
  archive   = {C_AAAI},
  author    = {Xiaotie Deng and Yotam Gafni and Ron Lavi and Tao Lin and Hongyi Ling},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25696},
  pages     = {5608-5615},
  title     = {From monopoly to competition: Optimal contests prevail},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Tight inapproximability for graphical games. <em>AAAI</em>,
5600–5607. (<a href="https://doi.org/10.1609/aaai.v37i5.25695">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We provide a complete characterization for the computational complexity of finding approximate equilibria in two-action graphical games. We consider the two most well-studied approximation notions: ε-Nash equilibria (ε-NE) and ε-well-supported Nash equilibria (ε-WSNE), where ε is in [0,1]. We prove that computing an ε-NE is PPAD-complete for any constant ε smaller than 1/2, while a very simple algorithm (namely, letting all players mix uniformly between their two actions) yields a 1/2-NE. On the other hand, we show that computing an ε-WSNE is PPAD-complete for any constant ε smaller than 1, while a 1-WSNE is trivial to achieve, because any strategy profile is a 1-WSNE. All of our lower bounds immediately also apply to graphical games with more than two actions per player.},
  archive   = {C_AAAI},
  author    = {Argyrios Deligkas and John Fearnley and Alexandros Hollender and Themistoklis Melissourgos},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25695},
  pages     = {5600-5607},
  title     = {Tight inapproximability for graphical games},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Strategyproofness and proportionality in party-approval
multiwinner elections. <em>AAAI</em>, 5591–5599. (<a
href="https://doi.org/10.1609/aaai.v37i5.25694">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In party-approval multiwinner elections the goal is to allocate the seats of a fixed-size committee to parties based on the approval ballots of the voters over the parties. In particular, each voter can approve multiple parties and each party can be assigned multiple seats. Two central requirements in this setting are proportional representation and strategyproofness. Intuitively, proportional representation requires that every sufficiently large group of voters with similar preferences is represented in the committee. Strategyproofness demands that no voter can benefit by misreporting her true preferences. We show that these two axioms are incompatible for anonymous party-approval multiwinner voting rules, thus proving a far-reaching impossibility theorem. The proof of this result is obtained by formulating the problem in propositional logic and then letting a SAT solver show that the formula is unsatisfiable. Additionally, we demonstrate how to circumvent this impossibility by considering a weakening of strategyproofness which requires that only voters who do not approve any elected party cannot manipulate. While most common voting rules fail even this weak notion of strategyproofness, we characterize Chamberlin-Courant approval voting within the class of Thiele rules based on this strategyproofness notion.},
  archive   = {C_AAAI},
  author    = {Théo Delemazure and Tom Demeulemeester and Manuel Eberl and Jonas Israel and Patrick Lederer},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25694},
  pages     = {5591-5599},
  title     = {Strategyproofness and proportionality in party-approval multiwinner elections},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Combinatorial civic crowdfunding with budgeted agents:
Welfare optimality at equilibrium and optimal deviation. <em>AAAI</em>,
5582–5590. (<a href="https://doi.org/10.1609/aaai.v37i5.25693">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Civic Crowdfunding (CC) uses the ``power of the crowd&quot; to garner contributions towards public projects. As these projects are non-excludable, agents may prefer to ``free-ride,&quot; resulting in the project not being funded. Researchers introduce refunds for single project CC to incentivize agents to contribute, guaranteeing the project&#39;s funding. These funding guarantees are applicable only when agents have an unlimited budget. This paper focuses on a combinatorial setting, where multiple projects are available for CC and agents have a limited budget. We study specific conditions where funding can be guaranteed. Naturally, funding the optimal social welfare subset of projects is desirable when every available project cannot be funded due to budget restrictions. We prove the impossibility of achieving optimal welfare at equilibrium for any monotone refund scheme. Further, given the contributions of other agents, we prove that it is NP-Hard for an agent to determine its optimal strategy. That is, while profitable deviations may exist for agents instead of funding the optimal welfare subset, it is computationally hard for an agent to find its optimal deviation. Consequently, we study different heuristics agents can use to contribute to the projects in practice. We demonstrate the heuristics&#39; performance as the average-case trade-off between the welfare obtained and an agent&#39;s utility through simulations.},
  archive   = {C_AAAI},
  author    = {Sankarshan Damle and Manisha Padala and Sujit Gujar},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25693},
  pages     = {5582-5590},
  title     = {Combinatorial civic crowdfunding with budgeted agents: Welfare optimality at equilibrium and optimal deviation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Complexity of probabilistic inference in random dichotomous
hedonic games. <em>AAAI</em>, 5573–5581. (<a
href="https://doi.org/10.1609/aaai.v37i5.25692">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Hedonic games model cooperative games where agents desire to form coalitions, and only care about the composition of the coalitions of which they are members. Focusing on various classes of dichotomous hedonic games, where each agent either approves or disapproves a given coalition, we propose the random extension, where players have an independent participation probability. We initiate the research on the computational complexity of computing the probability that coalitions and partitions are optimal or stable. While some cases admit efficient algorithms (e.g., agents approve only few coalitions), they become computationally hard (#P-hard) in their complementary scenario. We then investigate the distribution of coalitions in perfect partitions and their performance in majority games, where an agent approves coalitions in which the agent is friends with the majority of its members. When friendships independently form with a constant probability, we prove that the number of coalitions of size 3 converges in distribution to a Poisson random variable.},
  archive   = {C_AAAI},
  author    = {Saar Cohen and Noa Agmon},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25692},
  pages     = {5573-5581},
  title     = {Complexity of probabilistic inference in random dichotomous hedonic games},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A pair-approximation method for modelling the dynamics of
multi-agent stochastic games. <em>AAAI</em>, 5565–5572. (<a
href="https://doi.org/10.1609/aaai.v37i5.25691">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Developing a dynamical model for learning in games has attracted much recent interest. In stochastic games, agents need to make decisions in multiple states, and transitions between states, in turn, influence the dynamics of strategies. While previous works typically focus either on 2-agent stochastic games or on normal form games under an infinite-agent setting, we aim at formally modelling the learning dynamics in stochastic games under the infinite-agent setting. With a novel use of pair-approximation method, we develop a formal model for myopic Q-learning in stochastic games with symmetric state transition. We verify the descriptive power of our model (a partial differential equation) across various games through comparisons with agent-based simulation results. Based on our proposed model, we can gain qualitative and quantitative insights into the influence of transition probabilities on the dynamics of strategies. In particular, we illustrate that a careful design of transition probabilities can help players overcome the social dilemmas and promote cooperation, even if agents are myopic learners.},
  archive   = {C_AAAI},
  author    = {Chen Chu and Zheng Yuan and Shuyue Hu and Chunjiang Mu and Zhen Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25691},
  pages     = {5565-5572},
  title     = {A pair-approximation method for modelling the dynamics of multi-agent stochastic games},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Game implementation: What are the obstructions?
<em>AAAI</em>, 5557–5564. (<a
href="https://doi.org/10.1609/aaai.v37i5.25690">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In many applications, we want to influence the decisions of independent agents by designing incentives for their actions. We revisit a fundamental problem in this area, called GAME IMPLEMENTATION: Given a game in standard form and a set of desired strategies, can we design a set of payment promises such that if the players take the payment promises into account, then all undominated strategies are desired? Furthermore, we aim to minimize the cost, that is, the worst-case amount of payments. We study the tractability of computing such payment promises and determine more closely what obstructions we may have to overcome in doing so. We show that GAME IMPLEMENTATION is NP-hard even for two players, solving in particular a long-standing open question and suggesting more restrictions are necessary to obtain tractability results. We thus study the regime in which players have only a small constant number of strategies and obtain the following. First, this case remains NP-hard even if each player’s utility depends only on three others. Second, we repair a flawed efficient algorithm for the case of both small number of strategies and small number of players. Among further results, we characterize sets of desired strategies that can be implemented at zero cost as a generalization of Nash equilibria.},
  archive   = {C_AAAI},
  author    = {Jiehua Chen and Seyedeh Negar Layegh Khavidaki and Sebastian Vincent Haydn and Sofia Simola and Manuel Sorge},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25690},
  pages     = {5557-5564},
  title     = {Game implementation: What are the obstructions?},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Topological distance games. <em>AAAI</em>, 5549–5556. (<a
href="https://doi.org/10.1609/aaai.v37i5.25689">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We introduce a class of strategic games in which agents are assigned to nodes of a topology graph and the utility of an agent depends on both the agent&#39;s inherent utilities for other agents as well as her distance from these agents on the topology graph. This model of topological distance games (TDGs) offers an appealing combination of important aspects of several prominent settings in coalition formation, including (additively separable) hedonic games, social distance games, and Schelling games. We study the existence and complexity of stable outcomes in TDGs—for instance, while a jump stable assignment may not exist in general, we show that the existence is guaranteed in several special cases. We also investigate the dynamics induced by performing beneficial jumps.},
  archive   = {C_AAAI},
  author    = {Martin Bullinger and Warut Suksompong},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25689},
  pages     = {5549-5556},
  title     = {Topological distance games},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fair division with prioritized agents. <em>AAAI</em>,
5540–5548. (<a href="https://doi.org/10.1609/aaai.v37i5.25688">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider the fair division problem of indivisible items. It is well-known that an envy-free allocation may not exist, and a relaxed version of envy-freeness, envy-freeness up to one item (EF1), has been widely considered. In an EF1 allocation, an agent may envy others&#39; allocated shares, but only up to one item. In many applications, we may wish to specify a subset of prioritized agents where strict envy-freeness needs to be guaranteed from these agents to the remaining agents, while ensuring the whole allocation is still EF1. Prioritized agents may be those agents who are envious in a previous EF1 allocation, those agents who belong to underrepresented groups, etc. Motivated by this, we propose a new fairness notion named envy-freeness with prioritized agents EFprior, and study the existence and the algorithmic aspects for the problem of computing an EFprior allocation. With additive valuations, the simple round-robin algorithm is able to compute an EFprior allocation. In this paper, we mainly focus on general valuations. In particular, we present a polynomial-time algorithm that outputs an EFprior allocation with most of the items allocated. When all the items need to be allocated, we also present polynomial-time algorithms for some well-motivated special cases.},
  archive   = {C_AAAI},
  author    = {Xiaolin Bu and Zihao Li and Shengxin Liu and Jiaxin Song and Biaoshuai Tao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25688},
  pages     = {5540-5548},
  title     = {Fair division with prioritized agents},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multiwinner voting with possibly unavailable candidates.
<em>AAAI</em>, 5532–5539. (<a
href="https://doi.org/10.1609/aaai.v37i5.25687">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Selecting a committee that meets diversity and proportionality criteria is a challenging endeavor that has been studied extensively in recent years. This task becomes even more challenging when some of the selected candidates decline the invitation to join the committee. Since the unavailability of one candidate may impact the rest of the selection, inviting all candidates at the same time may lead to a suboptimal committee. Instead, invitations should be sequential and conditional on which candidates invited so far accepted the invitation: the solution to the committee selection problem is a query policy. If invitation queries are binding, they should be safe: one should not query a candidate without being sure that whatever the set of available candidates possible at that stage, her inclusion will not jeopardize committee optimality. Assuming approval-based inputs, we characterize the set of rules for which a safe query exists at every stage. In order to parallelize the invitation process, we investigate the computation of safe parallel queries, and show that it is often hard. We also study the existence of safe parallel queries with respect to proportionality axioms such as extended justified representation.},
  archive   = {C_AAAI},
  author    = {Markus Brill and Hayrullah Dindar and Jonas Israel and Jérôme Lang and Jannik Peters and Ulrike Schmidt-Kraepelin},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25687},
  pages     = {5532-5539},
  title     = {Multiwinner voting with possibly unavailable candidates},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Proportionality in approval-based participatory budgeting.
<em>AAAI</em>, 5524–5531. (<a
href="https://doi.org/10.1609/aaai.v37i5.25686">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The ability to measure the satisfaction of (groups of) voters is a crucial prerequisite for formulating proportionality axioms in approval-based participatory budgeting elections. Two common -- but very different -- ways to measure the satisfaction of a voter consider (i) the number of approved projects and (ii) the total cost of approved projects, respectively. In general, it is difficult to decide which measure of satisfaction best reflects the voters&#39; true utilities. In this paper, we study proportionality axioms with respect to large classes of approval-based satisfaction functions. We establish logical implications among our axioms and related notions from the literature, and we ask whether outcomes can be achieved that are proportional with respect to more than one satisfaction function. We show that this is impossible for the two commonly used satisfaction functions when considering proportionality notions based on extended justified representation, but achievable for a notion based on proportional justified representation. For the latter result, we introduce a strengthening of priceability and show that it is satisfied by several polynomial-time computable rules, including the Method of Equal Shares and Phragmén&#39;s sequential rule.},
  archive   = {C_AAAI},
  author    = {Markus Brill and Stefan Forster and Martin Lackner and Jan Maly and Jannik Peters},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25686},
  pages     = {5524-5531},
  title     = {Proportionality in approval-based participatory budgeting},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Rank aggregation using scoring rules. <em>AAAI</em>,
5515–5523. (<a href="https://doi.org/10.1609/aaai.v37i5.25685">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {To aggregate rankings into a social ranking, one can use scoring systems such as Plurality, Veto, and Borda. We distinguish three types of methods: ranking by score, ranking by repeatedly choosing a winner that we delete and rank at the top, and ranking by repeatedly choosing a loser that we delete and rank at the bottom. The latter method captures the frequently studied voting rules Single Transferable Vote (aka Instant Runoff Voting), Coombs, and Baldwin. In an experimental analysis, we show that the three types of methods produce different rankings in practice. We also provide evidence that sequentially selecting winners is most suitable to detect the &quot;true&quot; ranking of candidates. For different rules in our classes, we then study the (parameterized) computational complexity of deciding in which positions a given candidate can appear in the chosen ranking. As part of our analysis, we also consider the Winner Determination problem for STV, Coombs, and Baldwin and determine their complexity when there are few voters or candidates.},
  archive   = {C_AAAI},
  author    = {Niclas Boehmer and Robert Bredereck and Dominik Peters},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25685},
  pages     = {5515-5523},
  title     = {Rank aggregation using scoring rules},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Properties of position matrices and their elections.
<em>AAAI</em>, 5507–5514. (<a
href="https://doi.org/10.1609/aaai.v37i5.25684">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the properties of elections that have a given position matrix (in such elections each candidate is ranked on each position by a number of voters specified in the matrix). We show that counting elections that generate a given position matrix is #P-complete. Consequently, sampling such elections uniformly at random seems challenging and we propose a simpler algorithm, without hard guarantees. Next, we consider the problem of testing if a given matrix can be implemented by an election with a certain structure (such as single-peakedness or group-separability). Finally, we consider the problem of checking if a given position matrix can be implemented by an election with a Condorcet winner. We complement our theoretical findings with experiments.},
  archive   = {C_AAAI},
  author    = {Niclas Boehmer and Jin-Yi Cai and Piotr Faliszewski and Austen Z. Fan and Łukasz Janeczko and Andrzej Kaczmarczyk and Tomasz Wąs},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25684},
  pages     = {5507-5514},
  title     = {Properties of position matrices and their elections},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Causes of stability in dynamic coalition formation.
<em>AAAI</em>, 5499–5506. (<a
href="https://doi.org/10.1609/aaai.v37i5.25683">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the formation of stable outcomes via simple dynamics in cardinal hedonic games, where the utilities of agents change over time depending on the history of the coalition formation process. Specifically, we analyze situations where members of a coalition decrease their utility for a leaving agent (resent) or increase their utility for a joining agent (appreciation). We show that in contrast to classical dynamics, for resentful or appreciative agents, dynamics are guaranteed to converge under mild conditions for various stability concepts. Thereby, we establish that both resent and appreciation are strong stability-driving forces.},
  archive   = {C_AAAI},
  author    = {Niclas Boehmer and Martin Bullinger and Anna Maria Kerkmann},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25683},
  pages     = {5499-5506},
  title     = {Causes of stability in dynamic coalition formation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Now we’re talking: Better deliberation groups through
submodular optimization. <em>AAAI</em>, 5490–5498. (<a
href="https://doi.org/10.1609/aaai.v37i5.25682">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Citizens’ assemblies are groups of randomly selected constituents who are tasked with providing recommendations on policy questions. Assembly members form their recommendations through a sequence of discussions in small groups (deliberation), in which group members exchange arguments and experiences. We seek to support this process through optimization, by studying how to assign participants to discussion groups over multiple sessions, in a way that maximizes interaction between participants and satisfies diversity constraints within each group. Since repeated meetings between a given pair of participants have diminishing marginal returns, we capture interaction through a submodular function, which is approximately optimized by a greedy algorithm making calls to an ILP solver. This framework supports different submodular objective functions, and we identify sensible options, but we also show it is not necessary to commit to a particular choice: Our main theoretical result is a (practically efficient) algorithm that simultaneously approximates every possible objective function of the form we are interested in. Experiments with data from real citizens&#39; assemblies demonstrate that our approach substantially outperforms the heuristic algorithm currently used by practitioners.},
  archive   = {C_AAAI},
  author    = {Jake Barrett and Kobi Gal and Paul Gölz and Rose M. Hong and Ariel D. Procaccia},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25682},
  pages     = {5490-5498},
  title     = {Now we’re talking: Better deliberation groups through submodular optimization},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Finding fair allocations under budget constraints.
<em>AAAI</em>, 5481–5489. (<a
href="https://doi.org/10.1609/aaai.v37i5.25681">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the fair allocation of indivisible goods among agents with identical, additive valuations but individual budget constraints. Here, the indivisible goods--each with a specific size and value--need to be allocated such that the bundle assigned to each agent is of total size at most the agent&#39;s budget. Since envy-free allocations do not necessarily exist in the indivisible goods context, compelling relaxations--in particular, the notion of envy-freeness up to k goods (EFk)--have received significant attention in recent years. In an EFk allocation, each agent prefers its own bundle over that of any other agent, up to the removal of k goods, and the agents have similarly bounded envy against the charity (which corresponds to the set of all unallocated goods). It has been shown in prior work that an allocation that satisfies the budget constraints and maximizes the Nash social welfare is 1/4-approximately EF1. However, the computation (or even existence) of exact EFk allocations remained an intriguing open problem. We make notable progress towards this by proposing a simple, greedy, polynomial-time algorithm that computes EF2 allocations under budget constraints. Our algorithmic result implies the universal existence of EF2 allocations in this fair division context. The analysis of the algorithm exploits intricate structural properties of envy-freeness. Interestingly, the same algorithm also provides EF1 guarantees for important special cases. Specifically, we settle the existence of EF1 allocations for instances in which: (i) the value of each good is proportional to its size, (ii) all the goods have the same size, or (iii) all the goods have the same value. Our EF2 result even extends to the setting wherein the goods&#39; sizes are agent specific.},
  archive   = {C_AAAI},
  author    = {Siddharth Barman and Arindam Khan and Sudarshan Shyam and K. V. N. Sreenivas},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25681},
  pages     = {5481-5489},
  title     = {Finding fair allocations under budget constraints},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fairness concepts for indivisible items with externalities.
<em>AAAI</em>, 5472–5480. (<a
href="https://doi.org/10.1609/aaai.v37i5.25680">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study a fair allocation problem of indivisible items under additive externalities in which each agent also receives utility from items that are assigned to other agents. This allows us to capture scenarios in which agents benefit from or compete against one another. We extend the well-studied properties of envy-freeness up to one item (EF1) and envy-freeness up to any item (EFX) to this setting, and we propose a new fairness concept called general fair share (GFS), which applies to a more general public decision making model. We undertake a detailed study and present algorithms for finding fair allocations.},
  archive   = {C_AAAI},
  author    = {Haris Aziz and Warut Suksompong and Zhaohong Sun and Toby Walsh},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25680},
  pages     = {5472-5480},
  title     = {Fairness concepts for indivisible items with externalities},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bidding graph games with partially-observable budgets.
<em>AAAI</em>, 5464–5471. (<a
href="https://doi.org/10.1609/aaai.v37i5.25679">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Two-player zero-sum &quot;graph games&quot; are central in logic, verification, and multi-agent systems. The game proceeds by placing a token on a vertex of a graph, and allowing the players to move it to produce an infinite path, which determines the winner or payoff of the game. Traditionally, the players alternate turns in moving the token. In &quot;bidding games&quot;, however, the players have budgets and in each turn, an auction (bidding) determines which player moves the token. So far, bidding games have only been studied as full-information games. In this work we initiate the study of partial-information bidding games: we study bidding games in which a player&#39;s initial budget is drawn from a known probability distribution. We show that while for some bidding mechanisms and objectives, it is straightforward to adapt the results from the full-information setting to the partial-information setting, for others, the analysis is significantly more challenging, requires new techniques, and gives rise to interesting results. Specifically, we study games with &quot;mean-payoff&quot; objectives in combination with &quot;poorman&quot; bidding. We construct optimal strategies for a partially-informed player who plays against a fully-informed adversary. We show that, somewhat surprisingly, the &quot;value&quot; under pure strategies does not necessarily exist in such games.},
  archive   = {C_AAAI},
  author    = {Guy Avni and Ismael Jecker and Đorđe Žikelić},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25679},
  pages     = {5464-5471},
  title     = {Bidding graph games with partially-observable budgets},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mediated cheap talk design. <em>AAAI</em>, 5456–5463. (<a
href="https://doi.org/10.1609/aaai.v37i5.25678">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study an information design problem with two informed senders and a receiver in which, in contrast to traditional Bayesian persuasion settings, senders do not have commitment power. In our setting, a trusted mediator/platform gathers data from the senders and recommends the receiver which action to play. We characterize the set of feasible action distributions that can be obtained in equilibrium, and provide an O(n log n) algorithm (where n is the number of states) that computes the optimal equilibrium for the senders. Additionally, we show that the optimal equilibrium for the receiver can be obtained by a simple revelation mechanism.},
  archive   = {C_AAAI},
  author    = {Itai Arieli and Ivan Geffner and Moshe Tennenholtz},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i5.25678},
  pages     = {5456-5463},
  title     = {Mediated cheap talk design},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Direct heterogeneous causal learning for resource
allocation problems in marketing. <em>AAAI</em>, 5446–5454. (<a
href="https://doi.org/10.1609/aaai.v37i4.25677">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Marketing is an important mechanism to increase user engagement and improve platform revenue, and heterogeneous causal learning can help develop more effective strategies. Most decision-making problems in marketing can be formulated as resource allocation problems and have been studied for decades. Existing works usually divide the solution procedure into two fully decoupled stages, i.e., machine learning (ML) and operation research (OR) --- the first stage predicts the model parameters and they are fed to the optimization in the second stage. However, the error of the predicted parameters in ML cannot be respected and a series of complex mathematical operations in OR lead to the increased accumulative errors. Essentially, the improved precision on the prediction parameters may not have a positive correlation on the final solution due to the side-effect from the decoupled design. In this paper, we propose a novel approach for solving resource allocation problems to mitigate the side-effects. Our key intuition is that we introduce the decision factor to establish a bridge between ML and OR such that the solution can be directly obtained in OR by only performing the sorting or comparison operations on the decision factor. Furthermore, we design a customized loss function that can conduct direct heterogeneous causal learning on the decision factor, an unbiased estimation of which can be guaranteed when the loss convergences. As a case study, we apply our approach to two crucial problems in marketing: the binary treatment assignment problem and the budget allocation problem with multiple treatments. Both large-scale simulations and online A/B Tests demonstrate that our approach achieves significant improvement compared with state-of-the-art.},
  archive   = {C_AAAI},
  author    = {Hao Zhou and Shaoming Li and Guibin Jiang and Jiaqi Zheng and Dong Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25677},
  pages     = {5446-5454},
  title     = {Direct heterogeneous causal learning for resource allocation problems in marketing},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Sparse maximum margin learning from multimodal human
behavioral patterns. <em>AAAI</em>, 5437–5445. (<a
href="https://doi.org/10.1609/aaai.v37i4.25676">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose a multimodal data fusion framework to systematically analyze human behavioral data from specialized domains that are inherently dynamic, sparse, and heterogeneous. We develop a two-tier architecture of probabilistic mixtures, where the lower tier leverages parametric distributions from the exponential family to extract significant behavioral patterns from each data modality. These patterns are then organized into a dynamic latent state space at the higher tier to fuse patterns from different modalities. In addition, our framework jointly performs pattern discovery and maximum-margin learning for downstream classification tasks by using a group-wise sparse prior that regularizes the coefficients of the maximum-margin classifier. Therefore, the discovered patterns are highly interpretable and discriminative to support downstream classification tasks. Experiments on real-world behavioral data from medical and psychological domains demonstrate that our framework discovers meaningful multimodal behavioral patterns with improved interpretability and prediction performance.},
  archive   = {C_AAAI},
  author    = {Ervine Zheng and Qi Yu and Zhi Zheng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25676},
  pages     = {5437-5445},
  title     = {Sparse maximum margin learning from multimodal human behavioral patterns},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Loan fraud users detection in online lending leveraging
multiple data views. <em>AAAI</em>, 5428–5436. (<a
href="https://doi.org/10.1609/aaai.v37i4.25675">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In recent years, online lending platforms have been becoming attractive for micro-financing and popular in financial industries. However, such online lending platforms face a high risk of failure due to the lack of expertise on borrowers&#39; creditworthness. Thus, risk forecasting is important to avoid economic loss. Detecting loan fraud users in advance is at the heart of risk forecasting. The purpose of fraud user (borrower) detection is to predict whether one user will fail to make required payments in the future. Detecting fraud users depend on historical loan records. However, a large proportion of users lack such information, especially for new users. In this paper, we attempt to detect loan fraud users from cross domain heterogeneous data views, including user attributes, installed app lists, app installation behaviors, and app-in logs, which compensate for the lack of historical loan records. However, it is difficult to effectively fuse the multiple heterogeneous data views. Moreover, some samples miss one or even more data views, increasing the difficulty in fusion. To address the challenges, we propose a novel end-to-end deep multiview learning approach, which encodes heterogeneous data views into homogeneous ones, generates the missing views based on the learned relationship among all the views, and then fuses all the views together to a comprehensive view for identifying fraud users. Our model is evaluated on a real-world large-scale dataset consisting of 401,978 loan records of 228,117 users from January 1, 2019, to September 30, 2019, achieving the state-of-the-art performance.},
  archive   = {C_AAAI},
  author    = {Sha Zhao and Yongrui Huang and Ling Chen and Chunping Wang and Shijian Li and Lei Chen and Gang Pan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25675},
  pages     = {5428-5436},
  title     = {Loan fraud users detection in online lending leveraging multiple data views},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Yet another traffic classifier: A masked autoencoder based
traffic transformer with multi-level flow representation. <em>AAAI</em>,
5420–5427. (<a href="https://doi.org/10.1609/aaai.v37i4.25674">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Traffic classification is a critical task in network security and management. Recent research has demonstrated the effectiveness of the deep learning-based traffic classification method. However, the following limitations remain: (1) the traffic representation is simply generated from raw packet bytes, resulting in the absence of important information; (2) the model structure of directly applying deep learning algorithms does not take traffic characteristics into account; and (3) scenario-specific classifier training usually requires a labor-intensive and time-consuming process to label data. In this paper, we introduce a masked autoencoder (MAE) based traffic transformer with multi-level flow representation to tackle these problems. To model raw traffic data, we design a formatted traffic representation matrix with hierarchical flow information. After that, we develop an efficient Traffic Transformer, in which packet-level and flow-level attention mechanisms implement more efficient feature extraction with lower complexity. At last, we utilize the MAE paradigm to pre-train our classifier with a large amount of unlabeled data, and perform fine-tuning with a few labeled data for a series of traffic classification tasks. Experiment findings reveal that our method outperforms state-of-the-art methods on five real-world traffic datasets by a large margin. The code is available at https://github.com/NSSL-SJTU/YaTC.},
  archive   = {C_AAAI},
  author    = {Ruijie Zhao and Mingwei Zhan and Xianwen Deng and Yanhao Wang and Yijun Wang and Guan Gui and Zhi Xue},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25674},
  pages     = {5420-5427},
  title     = {Yet another traffic classifier: A masked autoencoder based traffic transformer with multi-level flow representation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mining and applying composition knowledge of dance moves for
style-concentrated dance generation. <em>AAAI</em>, 5411–5419. (<a
href="https://doi.org/10.1609/aaai.v37i4.25673">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Choreography refers to creation of dance motions according to both music and dance knowledge, where the created dances should be style-specific and consistent. However, most of the existing methods generate dances using the given music as the only reference, lacking the stylized dancing knowledge, namely, the flag motion patterns contained in different styles. Without the stylized prior knowledge, these approaches are not promising to generate controllable style or diverse moves for each dance style, nor new dances complying with stylized knowledge. To address this issue, we propose a novel music-to-dance generation framework guided by style embedding, considering both input music and stylized dancing knowledge. These style embeddings are learnt representations of style-consistent kinematic abstraction of reference dance videos, which can act as controllable factors to impose style constraints on dance generation in a latent manner. Hence, we can make the style embedding fit into any given style while allowing the flexibility to generate new compatible dance moves by modifying the style embedding according to the learnt representations of a certain style. We are the first to achieve knowledge-driven style control in dance generation tasks. To support this study, we build a large multi-style music-to-dance dataset referred to as I-Dance. The qualitative and quantitative evaluations demonstrate the advantage of the proposed framework, as well as the ability to synthesize diverse moves under a dance style directed by style embedding.},
  archive   = {C_AAAI},
  author    = {Xinjian Zhang and Su Yang and Yi Xu and Weishan Zhang and Longwen Gao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25673},
  pages     = {5411-5419},
  title     = {Mining and applying composition knowledge of dance moves for style-concentrated dance generation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generalized cell type annotation and discovery for
single-cell RNA-seq data. <em>AAAI</em>, 5402–5410. (<a
href="https://doi.org/10.1609/aaai.v37i4.25672">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The rapid development of single-cell RNA sequencing (scRNA-seq) technology allows us to study gene expression heterogeneity at the cellular level. Cell annotation is the basis for subsequent downstream analysis in single-cell data mining. Existing methods rarely explore the fine-grained semantic knowledge of novel cell types absent from the reference data and usually susceptible to batch effects on the classification of seen cell types. Taking into consideration these limitations, this paper proposes a new and practical task called generalized cell type annotation and discovery for scRNA-seq data. In this task, cells of seen cell types are given class labels, while cells of novel cell types are given cluster labels instead of a unified “unassigned” label. To address this problem, we carefully design a comprehensive evaluation benchmark and propose a novel end-to-end algorithm framework called scGAD. Specifically, scGAD first builds the intrinsic correspondence across the reference and target data by retrieving the geometrically and semantically mutual nearest neighbors as anchor pairs. Then we introduce an anchor-based self-supervised learning module with a connectivity-aware attention mechanism to facilitate model prediction capability on unlabeled target data. To enhance the inter-type separation and intra-type compactness, we further propose a confidential prototypical self-supervised learning module to uncover the consensus category structure of the reference and target data. Extensive results on massive real datasets demonstrate the superiority of scGAD over various state-of-the-art clustering and annotation methods.},
  archive   = {C_AAAI},
  author    = {Yuyao Zhai and Liang Chen and Minghua Deng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25672},
  pages     = {5402-5410},
  title     = {Generalized cell type annotation and discovery for single-cell RNA-seq data},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Overcoming forgetting in fine-grained urban flow inference
via adaptive knowledge replay. <em>AAAI</em>, 5393–5401. (<a
href="https://doi.org/10.1609/aaai.v37i4.25671">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Fine-grained urban flow inference (FUFI) problem aims at inferring the high-resolution flow maps from the coarse-grained ones, which plays an important role in sustainable and economic urban computing and traffic management. Previous models addressed the FUFI problem from spatial constraint, external factors, and memory cost. However, utilizing the new urban flow maps to calibrate the learned model is very challenging due to the &quot;catastrophic forgetting&quot; problem and is still under-explored. In this paper, we make the first step in FUFI and present CUFAR -- Continual Urban Flow inference with Adaptive knowledge Replay -- a novel framework for inferring the fine-grained citywide traffic flows. Specifically, (1) we design a spatial-temporal inference network that can extract better flow map features from both local and global levels; (2) then we present an adaptive knowledge replay (AKR) training algorithm to selectively replay the learned knowledge to facilitate the learning process of the model on new knowledge without forgetting. In addition, we also propose a knowledge discriminator to avoid &quot;negative replaying&quot; issue introduced by noisy urban flow maps. Extensive experiments on four large-scale real-world FUFI datasets demonstrate that our proposed model consistently outperforms strong baselines and effectively mitigates the forgetting problem. Source code is available at: https://github.com/PattonYu/CUFAR.},
  archive   = {C_AAAI},
  author    = {Haoyang Yu and Xovee Xu and Ting Zhong and Fan Zhou},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25671},
  pages     = {5393-5401},
  title     = {Overcoming forgetting in fine-grained urban flow inference via adaptive knowledge replay},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bootstrapping multi-view representations for fake news
detection. <em>AAAI</em>, 5384–5392. (<a
href="https://doi.org/10.1609/aaai.v37i4.25670">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Previous researches on multimedia fake news detection include a series of complex feature extraction and fusion networks to gather useful information from the news. However, how cross-modal consistency relates to the fidelity of news and how features from different modalities affect the decision-making are still open questions. This paper presents a novel scheme of Bootstrapping Multi-view Representations (BMR) for fake news detection. Given a multi-modal news, we extract representations respectively from the views of the text, the image pattern and the image semantics. Improved Multi-gate Mixture-of-Expert networks (iMMoE) are proposed for feature refinement and fusion. Representations from each view are separately used to coarsely predict the fidelity of the whole news, and the multimodal representations are able to predict the cross-modal consistency. With the prediction scores, we reweigh each view of the representations and bootstrap them for fake news detection. Extensive experiments conducted on typical fake news detection datasets prove that BMR outperforms state-of-the-art schemes.},
  archive   = {C_AAAI},
  author    = {Qichao Ying and Xiaoxiao Hu and Yangming Zhou and Zhenxing Qian and Dan Zeng and Shiming Ge},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25670},
  pages     = {5384-5392},
  title     = {Bootstrapping multi-view representations for fake news detection},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DMIS: Dynamic mesh-based importance sampling for training
physics-informed neural networks. <em>AAAI</em>, 5375–5383. (<a
href="https://doi.org/10.1609/aaai.v37i4.25669">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Modeling dynamics in the form of partial differential equations (PDEs) is an effectual way to understand real-world physics processes. For complex physics systems, analytical solutions are not available and numerical solutions are widely-used. However, traditional numerical algorithms are computationally expensive and challenging in handling multiphysics systems. Recently, using neural networks to solve PDEs has made significant progress, called physics-informed neural networks (PINNs). PINNs encode physical laws into neural networks and learn the continuous solutions of PDEs. For the training of PINNs, existing methods suffer from the problems of inefficiency and unstable convergence, since the PDE residuals require calculating automatic differentiation. In this paper, we propose Dynamic Mesh-based Importance Sampling (DMIS) to tackle these problems. DMIS is a novel sampling scheme based on importance sampling, which constructs a dynamic triangular mesh to estimate sample weights efficiently. DMIS has broad applicability and can be easily integrated into existing methods. The evaluation of DMIS on three widely-used benchmarks shows that DMIS improves the convergence speed and accuracy in the meantime. Especially in solving the highly nonlinear Schrödinger Equation, compared with state-of-the-art methods, DMIS shows up to 46\% smaller root mean square error and five times faster convergence speed. Code is available at https://github.com/MatrixBrain/DMIS.},
  archive   = {C_AAAI},
  author    = {Zijiang Yang and Zhongwei Qiu and Dongmei Fu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25669},
  pages     = {5375-5383},
  title     = {DMIS: Dynamic mesh-based importance sampling for training physics-informed neural networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-label few-shot ICD coding as autoregressive generation
with prompt. <em>AAAI</em>, 5366–5374. (<a
href="https://doi.org/10.1609/aaai.v37i4.25668">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Automatic International Classification of Diseases (ICD) coding aims to assign multiple ICD codes to a medical note with an average of 3,000+ tokens. This task is challenging due to the high-dimensional space of multi-label assignment (155,000+ ICD code candidates) and the long-tail challenge - Many ICD codes are infrequently assigned yet infrequent ICD codes are important clinically. This study addresses the long-tail challenge by transforming this multi-label classification task into an autoregressive generation task. Specifically, we first introduce a novel pretraining objective to generate free text diagnosis and procedure descriptions using the SOAP structure, the medical logic physicians use for note documentation. Second, instead of directly predicting the high dimensional space of ICD codes, our model generates the lower dimension of text descriptions, which then infer ICD codes. Third, we designed a novel prompt template for multi-label classification. We evaluate our Generation with Prompt (GP) model with the benchmark of all code assignment (MIMIC-III-full) and few shot ICD code assignment evaluation benchmark (MIMIC-III-few). Experiments on MIMIC-III-few show that our model performs with a marco F1 30.2, which substantially outperforms the previous MIMIC-III-full SOTA model (marco F1 4.3) and the model specifically designed for few/zero shot setting (marco F1 18.7). Finally, we design a novel ensemble learner, a cross attention reranker with prompts, to integrate previous SOTA and our best few-shot coding predictions. Experiments on MIMIC-III-full show that our ensemble learner substantially improves both macro and micro F1, from 10.4 to 14.6 and from 58.2 to 59.1, respectively.},
  archive   = {C_AAAI},
  author    = {Zhichao Yang and Sunjae Kwon and Zonghai Yao and Hong Yu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25668},
  pages     = {5366-5374},
  title     = {Multi-label few-shot ICD coding as autoregressive generation with prompt},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). KerPrint: Local-global knowledge graph enhanced diagnosis
prediction for retrospective and prospective interpretations.
<em>AAAI</em>, 5357–5365. (<a
href="https://doi.org/10.1609/aaai.v37i4.25667">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {While recent developments of deep learning models have led to record-breaking achievements in many areas, the lack of sufficient interpretation remains a problem for many specific applications, such as the diagnosis prediction task in healthcare. The previous knowledge graph(KG) enhanced approaches mainly focus on learning clinically meaningful representations, the importance of medical concepts, and even the knowledge paths from inputs to labels. However, it is infeasible to interpret the diagnosis prediction, which needs to consider different medical concepts, various medical relationships, and the time-effectiveness of knowledge triples in different patient contexts. More importantly, the retrospective and prospective interpretations of disease processes are valuable to clinicians for the patients&#39; confounding diseases. We propose KerPrint, a novel KG enhanced approach for retrospective and prospective interpretations to tackle these problems. Specifically, we propose a time-aware KG attention method to solve the problem of knowledge decay over time for trustworthy retrospective interpretation. We also propose a novel element-wise attention method to select candidate global knowledge using comprehensive representations from the local KG for prospective interpretation. We validate the effectiveness of our KerPrint through an extensive experimental study on a real-world dataset and a public dataset. The results show that our proposed approach not only achieves significant improvement over knowledge-enhanced methods but also gives the interpretability of diagnosis prediction in both retrospective and prospective views.},
  archive   = {C_AAAI},
  author    = {Kai Yang and Yongxin Xu and Peinie Zou and Hongxin Ding and Junfeng Zhao and Yasha Wang and Bing Xie},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25667},
  pages     = {5357-5365},
  title     = {KerPrint: Local-global knowledge graph enhanced diagnosis prediction for retrospective and prospective interpretations},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Tighter robust upper bounds for options via no-regret
learning. <em>AAAI</em>, 5348–5356. (<a
href="https://doi.org/10.1609/aaai.v37i4.25666">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Classic option pricing models, such as the Black-Scholes formula, often depend on some rigid assumptions on the dynamics of the underlying asset prices. These assumptions are inevitably violated in practice and thus induce the model risk. To mitigate this, robust option pricing that only requires the no-arbitrage principle has attracted a great deal of attention among researchers. In this paper, we give new robust upper bounds for option prices based on a novel η-momentum trading strategy. Our bounds for European options are tighter for most common moneyness, volatility, and expiration date setups than those presented in the existing literature. Our bounds for average strike Asian options are the first closed-form robust upper bounds for those options. Numerical simulations demonstrate that our bounds significantly outperform the benchmarks for both European and Asian options.},
  archive   = {C_AAAI},
  author    = {Shan Xue and Ye Du and Liang Xu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25666},
  pages     = {5348-5356},
  title     = {Tighter robust upper bounds for options via no-regret learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-relational contrastive learning graph neural network
for drug-drug interaction event prediction. <em>AAAI</em>, 5339–5347.
(<a href="https://doi.org/10.1609/aaai.v37i4.25665">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Drug-drug interactions (DDIs) could lead to various unexpected adverse consequences, so-called DDI events. Predicting DDI events can reduce the potential risk of combinatorial therapy and improve the safety of medication use, and has attracted much attention in the deep learning community. Recently, graph neural network (GNN)-based models have aroused broad interest and achieved satisfactory results in the DDI event prediction. Most existing GNN-based models ignore either drug structural information or drug interactive information, but both aspects of information are important for DDI event prediction. Furthermore, accurately predicting rare DDI events is hindered by their inadequate labeled instances. In this paper, we propose a new method, Multi-Relational Contrastive learning Graph Neural Network, MRCGNN for brevity, to predict DDI events. Specifically, MRCGNN integrates the two aspects of information by deploying a GNN on the multi-relational DDI event graph attributed with the drug features extracted from drug molecular graphs. Moreover, we implement a multi-relational graph contrastive learning with a designed dual-view negative counterpart augmentation strategy, to capture implicit information about rare DDI events. Extensive experiments on two datasets show that MRCGNN outperforms the state-of-the-art methods. Besides, we observe that MRCGNN achieves satisfactory performance when predicting rare DDI events.},
  archive   = {C_AAAI},
  author    = {Zhankun Xiong and Shichao Liu and Feng Huang and Ziyan Wang and Xuan Liu and Zhongfei Zhang and Wen Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25665},
  pages     = {5339-5347},
  title     = {Multi-relational contrastive learning graph neural network for drug-drug interaction event prediction},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Retrosynthesis prediction with local template retrieval.
<em>AAAI</em>, 5330–5338. (<a
href="https://doi.org/10.1609/aaai.v37i4.25664">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Retrosynthesis, which predicts the reactants of a given target molecule, is an essential task for drug discovery. In recent years, the machine learing based retrosynthesis methods have achieved promising results. In this work, we introduce RetroKNN, a local reaction template retrieval method to further boost the performance of template-based systems with non-parametric retrieval. We first build an atom-template store and a bond-template store that contains the local templates in the training data, then retrieve from these templates with a k-nearest-neighbor (KNN) search during inference. The retrieved templates are combined with neural network predictions as the final output. Furthermore, we propose a lightweight adapter to adjust the weights when combing neural network and KNN predictions conditioned on the hidden representation and the retrieved templates. We conduct comprehensive experiments on two widely used benchmarks, the USPTO-50K and USPTO-MIT. Especially for the top-1 accuracy, we improved 7.1\% on the USPTO-50K dataset and 12.0\% on the USPTO-MIT dataset.These results demonstrate the effectiveness of our method.},
  archive   = {C_AAAI},
  author    = {Shufang Xie and Rui Yan and Junliang Guo and Yingce Xia and Lijun Wu and Tao Qin},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25664},
  pages     = {5330-5338},
  title     = {Retrosynthesis prediction with local template retrieval},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DiffMD: A geometric diffusion model for molecular dynamics
simulations. <em>AAAI</em>, 5321–5329. (<a
href="https://doi.org/10.1609/aaai.v37i4.25663">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Molecular dynamics (MD) has long been the de facto choice for simulating complex atomistic systems from first principles. Recently deep learning models become a popular way to accelerate MD. Notwithstanding, existing models depend on intermediate variables such as the potential energy or force fields to update atomic positions, which requires additional computations to perform back-propagation. To waive this requirement, we propose a novel model called DiffMD by directly estimating the gradient of the log density of molecular conformations. DiffMD relies on a score-based denoising diffusion generative model that perturbs the molecular structure with a conditional noise depending on atomic accelerations and treats conformations at previous timeframes as the prior distribution for sampling. Another challenge of modeling such a conformation generation process is that a molecule is kinetic instead of static, which no prior works have strictly studied. To solve this challenge, we propose an equivariant geometric Transformer as the score function in the diffusion process to calculate corresponding gradients. It incorporates the directions and velocities of atomic motions via 3D spherical Fourier-Bessel representations. With multiple architectural improvements, we outperform state-of-the-art baselines on MD17 and isomers of C7O2H10 datasets. This work contributes to accelerating material and drug discovery.},
  archive   = {C_AAAI},
  author    = {Fang Wu and Stan Z. Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25663},
  pages     = {5321-5329},
  title     = {DiffMD: A geometric diffusion model for molecular dynamics simulations},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Molformer: Motif-based transformer on 3D heterogeneous
molecular graphs. <em>AAAI</em>, 5312–5320. (<a
href="https://doi.org/10.1609/aaai.v37i4.25662">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Procuring expressive molecular representations underpins AI-driven molecule design and scientific discovery. The research mainly focuses on atom-level homogeneous molecular graphs, ignoring the rich information in subgraphs or motifs. However, it has been widely accepted that substructures play a dominant role in identifying and determining molecular properties. To address such issues, we formulate heterogeneous molecular graphs (HMGs) and introduce a novel architecture to exploit both molecular motifs and 3D geometry. Precisely, we extract functional groups as motifs for small molecules and employ reinforcement learning to adaptively select quaternary amino acids as motif candidates for proteins. Then HMGs are constructed with both atom-level and motif-level nodes. To better accommodate those HMGs, we introduce a variant of the Transformer named Molformer, which adopts a heterogeneous self-attention layer to distinguish the interactions between multi-level nodes. Besides, it is also coupled with a multi-scale mechanism to capture fine-grained local patterns with increasing contextual scales. An attentive farthest point sampling algorithm is also proposed to obtain the molecular representations. We validate Molformer across a broad range of domains, including quantum chemistry, physiology, and biophysics. Extensive experiments show that Molformer outperforms or achieves the comparable performance of several state-of-the-art baselines. Our work provides a promising way to utilize informative motifs from the perspective of multi-level graph construction. The code is available at https://github.com/smiles724/Molformer.},
  archive   = {C_AAAI},
  author    = {Fang Wu and Dragomir Radev and Stan Z. Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25662},
  pages     = {5312-5320},
  title     = {Molformer: Motif-based transformer on 3D heterogeneous molecular graphs},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Don’t predict counterfactual values, predict expected values
instead. <em>AAAI</em>, 5303–5311. (<a
href="https://doi.org/10.1609/aaai.v37i4.25661">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Counterfactual Regret Minimization algorithms are the most popular way of estimating the Nash Equilibrium in imperfect-information zero-sum games. In particular, DeepStack -- the state-of-the-art Poker bot -- employs the so-called Deep Counterfactual Value Network (DCVN) to learn the Counterfactual Values (CFVs) associated with various states in the game. Each CFV is a multiplication of two factors: (1) the probability that the opponent would reach a given state in a game, which can be explicitly calculated from the input data, and (2) the expected value (EV) of a payoff in that state, which is a complex function of the input data, hard to calculate. In this paper, we propose a simple yet powerful modification to the CFVs estimation process, which consists in utilizing a deep neural network to estimate only the EV factor of CFV. This new target setting significantly simplifies the learning problem and leads to much more accurate CFVs estimation. A direct comparison, in terms of CFVs prediction losses, shows a significant prediction accuracy improvement of the proposed approach (DEVN) over the original DCVN formulation (relatively by 9.18-15.70\% when using card abstraction, and by 3.37-8.39\% without card abstraction, depending on a particular setting). Furthermore, the application of DEVN improves the theoretical lower bound of the error by 29.05-31.83\% compared to the DCVN pipeline when card abstraction is applied. Additionally, DEVN is able to achieve the goal using significantly smaller, and faster to infer, networks. While the proposed modification may seem to be of a rather technical nature, it, in fact, presents a fundamentally different approach to the overall process of learning and estimating CFVs, since the distributions of the training signals differ significantly between DCVN and DEVN. The former estimates CFVs, which are biased by the probability of reaching a given game state, while training the latter relies on a direct EV estimation, regardless of the state probability. In effect, the learning signal of DEVN presents a better estimation of the true value of a given state, thus allowing more accurate CFVs estimation.},
  archive   = {C_AAAI},
  author    = {Jeremiasz Wołosiuk and Maciej Świechowski and Jacek Mańdziuk},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25661},
  pages     = {5303-5311},
  title     = {Don’t predict counterfactual values, predict expected values instead},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AdapSafe: Adaptive and safe-certified deep reinforcement
learning-based frequency control for carbon-neutral power systems.
<em>AAAI</em>, 5294–5302. (<a
href="https://doi.org/10.1609/aaai.v37i4.25660">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With the increasing penetration of inverter-based renewable energy resources, deep reinforcement learning (DRL) has been proposed as one of the most promising solutions to realize real-time and autonomous control for future carbon-neutral power systems. In particular, DRL-based frequency control approaches have been extensively investigated to overcome the limitations of model-based approaches, such as the computational cost and scalability for large-scale systems. Nevertheless, the real-world implementation of DRLbased frequency control methods is facing the following fundamental challenges: 1) safety guarantee during the learning and decision-making processes; 2) adaptability against the dynamic system operating conditions. To this end, this is the first work that proposes an Adaptive and Safe-Certified DRL (AdapSafe) algorithm for frequency control to simultaneously address the aforementioned challenges. In particular, a novel self-tuning control barrier function is designed to actively compensate the unsafe frequency control strategies under variational safety constraints and thus achieve guaranteed safety. Furthermore, the concept of meta-reinforcement learning is integrated to significantly enhance its adaptiveness in non-stationary power system environments without sacrificing the safety cost. Experiments are conducted based on GB 2030 power system, and the results demonstrate that the proposed AdapSafe exhibits superior performance in terms of its guaranteed safety in both training and test phases, as well as its considerable adaptability against the dynamics changes of system parameters.},
  archive   = {C_AAAI},
  author    = {Xu Wan and Mingyang Sun and Boli Chen and Zhongda Chu and Fei Teng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25660},
  pages     = {5294-5302},
  title     = {AdapSafe: Adaptive and safe-certified deep reinforcement learning-based frequency control for carbon-neutral power systems},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Contrastive attention networks for attribution of early
modern print. <em>AAAI</em>, 5285–5293. (<a
href="https://doi.org/10.1609/aaai.v37i4.25659">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we develop machine learning techniques to identify unknown printers in early modern (c.~1500--1800) English printed books. Specifically, we focus on matching uniquely damaged character type-imprints in anonymously printed books to works with known printers in order to provide evidence of their origins. Until now, this work has been limited to manual investigations by analytical bibliographers. We present a Contrastive Attention-based Metric Learning approach to identify similar damage across character image pairs, which is sensitive to very subtle differences in glyph shapes, yet robust to various confounding sources of noise associated with digitized historical books. To overcome the scarce amount of supervised data, we design a random data synthesis procedure that aims to simulate bends, fractures, and inking variations induced by the early printing process. Our method successfully improves downstream damaged type-imprint matching among printed works from this period, as validated by in-domain human experts. The results of our approach on two important philosophical works from the Early Modern period demonstrate potential to extend the extant historical research about the origins and content of these books.},
  archive   = {C_AAAI},
  author    = {Nikolai Vogler and Kartik Goyal and Kishore PV Reddy and Elizaveta Pertseva and Samuel V. Lemley and Christopher N. Warren and Max G&#39;Sell and Taylor Berg-Kirkpatrick},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25659},
  pages     = {5285-5293},
  title     = {Contrastive attention networks for attribution of early modern print},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deepfake video detection via facial action dependencies
estimation. <em>AAAI</em>, 5276–5284. (<a
href="https://doi.org/10.1609/aaai.v37i4.25658">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deepfake video detection has drawn significant attention from researchers due to the security issues induced by deepfake videos. Unfortunately, most of the existing deepfake detection approaches have not competently modeled the natural structures and movements of human faces. In this paper, we formulate the deepfake video detection problem into a graph classification task, and propose a novel paradigm named Facial Action Dependencies Estimation (FADE) for deepfake video detection. We propose a Multi-Dependency Graph Module (MDGM) to capture abundant dependencies among facial action units, and extracts subtle clues in these dependencies. MDGM can be easily integrated into the existing frame-level detection schemes to provide significant performance gains. Extensive experiments demonstrate the superiority of our method against the state-of-the-art methods.},
  archive   = {C_AAAI},
  author    = {Lingfeng Tan and Yunhong Wang and Junfu Wang and Liang Yang and Xunxun Chen and Yuanfang Guo},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25658},
  pages     = {5276-5284},
  title     = {Deepfake video detection via facial action dependencies estimation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GenéLive! Generating rhythm actions in love live!
<em>AAAI</em>, 5266–5275. (<a
href="https://doi.org/10.1609/aaai.v37i4.25657">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This article presents our generative model for rhythm action games together with applications in business operation. Rhythm action games are video games in which the player is challenged to issue commands at the right timings during a music session. The timings are rendered in the chart, which consists of visual symbols, called notes, flying through the screen. We introduce our deep generative model, GenéLive!, which outperforms the state-of-the-art model by taking into account musical structures through beats and temporal scales. Thanks to its favorable performance, GenéLive! was put into operation at KLab Inc., a Japan-based video game developer, and reduced the business cost of chart generation by as much as half. The application target included the phenomenal &quot;Love Live!&quot;, which has more than 10 million users across Asia and beyond, and is one of the few rhythm action franchises that has led the online era of the genre. In this article, we evaluate the generative performance of GenéLive! using production datasets at KLab as well as open datasets for reproducibility, while the model continues to operate in their business. Our code and the model, tuned and trained using a supercomputer, are publicly available.},
  archive   = {C_AAAI},
  author    = {Atsushi Takada and Daichi Yamazaki and Yudai Yoshida and Nyamkhuu Ganbat and Takayuki Shimotomai and Naoki Hamada and Likun Liu and Taiga Yamamoto and Daisuke Sakurai},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25657},
  pages     = {5266-5275},
  title     = {GenéLive! generating rhythm actions in love live!},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Defending against backdoor attacks in natural language
generation. <em>AAAI</em>, 5257–5265. (<a
href="https://doi.org/10.1609/aaai.v37i4.25656">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The frustratingly fragile nature of neural network models make current natural language generation (NLG) systems prone to backdoor attacks and generate malicious sequences that could be sexist or offensive. Unfortunately, little effort has been invested to how backdoor attacks can affect current NLG models and how to defend against these attacks. In this work, by giving a formal definition of backdoor attack and defense, we investigate this problem on two important NLG tasks, machine translation and dialog generation. Tailored to the inherent nature of NLG models (e.g., producing a sequence of coherent words given contexts), we design defending strategies against attacks. We find that testing the backward probability of generating sources given targets yields effective defense performance against all different types of attacks, and is able to handle the one-to-many issue in many NLG tasks such as dialog generation. We hope that this work can raise the awareness of backdoor risks concealed in deep NLG systems and inspire more future work (both attack and defense) towards this direction.},
  archive   = {C_AAAI},
  author    = {Xiaofei Sun and Xiaoya Li and Yuxian Meng and Xiang Ao and Lingjuan Lyu and Jiwei Li and Tianwei Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25656},
  pages     = {5257-5265},
  title     = {Defending against backdoor attacks in natural language generation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). HG-SL: Jointly learning of global and local user spreading
behavior for fake news early detection. <em>AAAI</em>, 5248–5256. (<a
href="https://doi.org/10.1609/aaai.v37i4.25655">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, fake news forgery technology has become more and more sophisticated, and even the profiles of participants may be faked, which challenges the robustness and effectiveness of traditional detection methods involving text or user identity. Most propagation-only approaches mainly rely on neural networks to learn the diffusion pattern of individual news, which is insufficient to describe the differences in news spread ability, and also ignores the valuable global connections of news and users, limiting the performance of detection. Therefore, we propose a joint learning model named HG-SL, which is blind to news content and user identities, but capable of catching the differences between true and fake news in the early stages of propagation through global and local user spreading behavior. Specifically, we innovatively design a Hypergraph-based Global interaction learning module to capture the global preferences of users from their co-spreading relationships, and introduce node centrality encoding to complement user influence in hypergraph learning. Moreover, the designed Self-attention-based Local context learning module first introduce spread status to highlight the propagation ability of news and users, thus providing additional signals for verifying news authenticity. Experiments on real-world datasets indicate that our HG-SL, which solely relies on user behavior, outperforms SOTA baselines utilizing multidimensional features in both fake news detection and early detection task.},
  archive   = {C_AAAI},
  author    = {Ling Sun and Yuan Rao and Yuqian Lan and Bingcan Xia and Yangyang Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25655},
  pages     = {5248-5256},
  title     = {HG-SL: Jointly learning of global and local user spreading behavior for fake news early detection},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MetaTPTrans: A meta learning approach for multilingual code
representation learning. <em>AAAI</em>, 5239–5247. (<a
href="https://doi.org/10.1609/aaai.v37i4.25654">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Representation learning of source code is essential for applying machine learning to software engineering tasks. Learning code representation from a multilingual source code dataset has been shown to be more effective than learning from single-language datasets separately, since more training data from multilingual dataset improves the model&#39;s ability to extract language-agnostic information from source code. However, existing multilingual training overlooks the language-specific information which is crucial for modeling source code across different programming languages, while only focusing on learning a unified model with shared parameters among different languages for language-agnostic information modeling. To address this problem, we propose MetaTPTrans, a meta learning approach for multilingual code representation learning. MetaTPTrans generates different parameters for the feature extractor according to the specific programming language type of the input code snippet, enabling the model to learn both language-agnostic and language-specific information with dynamic parameters in the feature extractor. We conduct experiments on the code summarization and code completion tasks to verify the effectiveness of our approach. The results demonstrate the superiority of our approach with significant improvements on state-of-the-art baselines.},
  archive   = {C_AAAI},
  author    = {Weiguo Pian and Hanyu Peng and Xunzhu Tang and Tiezhu Sun and Haoye Tian and Andrew Habib and Jacques Klein and Tegawendé F. Bissyandé},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25654},
  pages     = {5239-5247},
  title     = {MetaTPTrans: A meta learning approach for multilingual code representation learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Better context makes better code language models: A case
study on function call argument completion. <em>AAAI</em>, 5230–5238.
(<a href="https://doi.org/10.1609/aaai.v37i4.25653">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Pretrained code language models have enabled great progress towards program synthesis. However, common approaches only consider in-file local context and thus miss information and constraints imposed by other parts of the codebase and its external dependencies. Existing code completion benchmarks also lack such context. To resolve these restrictions we curate a new dataset of permissively licensed Python packages that includes full projects and their dependencies and provide tools to extract non-local information with the help of program analyzers. We then focus on the task of function call argument completion which requires predicting the arguments to function calls. We show that existing code completion models do not yield good results on our completion task. To better solve this task, we query a program analyzer for information relevant to a given function call, and consider ways to provide the analyzer results to different code completion models during inference and training. Our experiments show that providing access to the function implementation and function usages greatly improves the argument completion performance. Our ablation study provides further insights on how different types of information available from the program analyzer and different ways of incorporating the information affect the model performance.},
  archive   = {C_AAAI},
  author    = {Hengzhi Pei and Jinman Zhao and Leonard Lausen and Sheng Zha and George Karypis},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25653},
  pages     = {5230-5238},
  title     = {Better context makes better code language models: A case study on function call argument completion},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On manipulating weight predictions in signed weighted
networks. <em>AAAI</em>, 5222–5229. (<a
href="https://doi.org/10.1609/aaai.v37i4.25652">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Adversarial social network analysis studies how graphs can be rewired or otherwise manipulated to evade social network analysis tools. While there is ample literature on manipulating simple networks, more sophisticated network types are much less understood in this respect. In this paper, we focus on the problem of evading FGA---an edge weight prediction method for signed weighted networks by Kumar et al. 2016. Among others, this method can be used for trust prediction in reputation systems. We study the theoretical underpinnings of FGA and its computational properties in terms of manipulability. Our positive finding is that, unlike many other tools, this measure is not only difficult to manipulate optimally, but also it can be difficult to manipulate in practice.},
  archive   = {C_AAAI},
  author    = {Tomasz Lizurej and Tomasz Michalak and Stefan Dziembowski},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25652},
  pages     = {5222-5229},
  title     = {On manipulating weight predictions in signed weighted networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Zero-shot rumor detection with propagation structure via
prompt learning. <em>AAAI</em>, 5213–5221. (<a
href="https://doi.org/10.1609/aaai.v37i4.25651">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The spread of rumors along with breaking events seriously hinders the truth in the era of social media. Previous studies reveal that due to the lack of annotated resources, rumors presented in minority languages are hard to be detected. Furthermore, the unforeseen breaking events not involved in yesterday&#39;s news exacerbate the scarcity of data resources. In this work, we propose a novel zero-shot framework based on prompt learning to detect rumors falling in different domains or presented in different languages. More specifically, we firstly represent rumor circulated on social media as diverse propagation threads, then design a hierarchical prompt encoding mechanism to learn language-agnostic contextual representations for both prompts and rumor data. To further enhance domain adaptation, we model the domain-invariant structural features from the propagation threads, to incorporate structural position representations of influential community response. In addition, a new virtual response augmentation method is used to improve model training. Extensive experiments conducted on three real-world datasets demonstrate that our proposed model achieves much better performance than state-of-the-art methods and exhibits a superior capacity for detecting rumors at early stages.},
  archive   = {C_AAAI},
  author    = {Hongzhan Lin and Pengyao Yi and Jing Ma and Haiyun Jiang and Ziyang Luo and Shuming Shi and Ruifang Liu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25651},
  pages     = {5213-5221},
  title     = {Zero-shot rumor detection with propagation structure via prompt learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fine-grained position helps memorizing more, a novel music
compound transformer model with feature interaction fusion.
<em>AAAI</em>, 5203–5212. (<a
href="https://doi.org/10.1609/aaai.v37i4.25650">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Due to the particularity of the simultaneous occurrence of multiple events in music sequences, compound Transformer is proposed to deal with the challenge of long sequences. However, there are two deficiencies in the compound Transformer. First, since the order of events is more important for music than natural language, the information provided by the original absolute position embedding is not precise enough. Second, there is an important correlation between the tokens in the compound word, which is ignored by the current compound Transformer. Therefore, in this work, we propose an improved compound Transformer model for music understanding. Specifically, we propose an attribute embedding fusion module and a novel position encoding scheme with absolute-relative consideration. In the attribute embedding fusion module, different attributes are fused through feature permutation by using a multi-head self-attention mechanism in order to capture rich interactions between attributes. In the novel position encoding scheme, we propose RoAR position encoding, which realizes rotational absolute position encoding, relative position encoding, and absolute-relative position interactive encoding, providing clear and rich orders for musical events. Empirical study on four typical music understanding tasks shows that our attribute fusion approach and RoAR position encoding brings large performance gains. In addition, we further investigate the impact of masked language modeling and casual language modeling pre-training on music understanding.},
  archive   = {C_AAAI},
  author    = {Zuchao Li and Ruhan Gong and Yineng Chen and Kehua Su},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25650},
  pages     = {5203-5212},
  title     = {Fine-grained position helps memorizing more, a novel music compound transformer model with feature interaction fusion},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). Decision-making context interaction network for
click-through rate prediction. <em>AAAI</em>, 5195–5202. (<a
href="https://doi.org/10.1609/aaai.v37i4.25649">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Click-through rate (CTR) prediction is crucial in recommendation and online advertising systems. Existing methods usually model user behaviors, while ignoring the informative context which influences the user to make a click decision, e.g., click pages and pre-ranking candidates that inform inferences about user interests, leading to suboptimal performance. In this paper, we propose a Decision-Making Context Interaction Network (DCIN), which deploys a carefully designed Context Interaction Unit (CIU) to learn decision-making contexts and thus benefits CTR prediction. In addition, the relationship between different decision-making context sources is explored by the proposed Adaptive Interest Aggregation Unit (AIAU) to improve CTR prediction further. In the experiments on public and industrial datasets, DCIN significantly outperforms the state-of-the-art methods. Notably, the model has obtained the improvement of CTR+2.9\%/CPM+2.1\%/GMV+1.5\% for online A/B testing and served the main traffic of Meituan Waimai advertising system.},
  archive   = {C_AAAI},
  author    = {Xiang Li and Shuwei Chen and Jian Dong and Jin Zhang and Yongkang Wang and Xingxing Wang and Dong Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25649},
  pages     = {5195-5202},
  title     = {Decision-making context interaction network for click-through rate prediction},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PEN: Prediction-explanation network to forecast stock price
movement with better explainability. <em>AAAI</em>, 5187–5194. (<a
href="https://doi.org/10.1609/aaai.v37i4.25648">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Nowadays explainability in stock price movement prediction is attracting increasing attention in banks, hedge funds and asset managers, primarily due to audit or regulatory reasons. Text data such as financial news and social media posts can be part of the reasons for stock price movement. To this end, we propose a novel framework of Prediction-Explanation Network (PEN) jointly modeling text streams and price streams with alignment. The key component of the PEN model is an shared representation learning module that learns which texts are possibly associated with the stock price movement by modeling the interaction between the text data and stock price data with a salient vector characterizing their correlation. In this way, the PEN model is able to predict the stock price movement by identifying and utilizing abundant messages while on the other hand, the selected text messages also explain the stock price movement. Experiments on real-world datasets demonstrate that we are able to kill two birds with one stone: in terms of accuracy, the proposed PEN model outperforms the state-of-art baseline; on explainability, the PEN model are demonstrated to be far superior to attention mechanism, capable of picking out the crucial texts with a very high confidence.},
  archive   = {C_AAAI},
  author    = {Shuqi Li and Weiheng Liao and Yuhan Chen and Rui Yan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25648},
  pages     = {5187-5194},
  title     = {PEN: Prediction-explanation network to forecast stock price movement with better explainability},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Steganography of steganographic networks. <em>AAAI</em>,
5178–5186. (<a href="https://doi.org/10.1609/aaai.v37i4.25647">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Steganography is a technique for covert communication between two parties. With the rapid development of deep neural networks (DNN), more and more steganographic networks are proposed recently, which are shown to be promising to achieve good performance. Unlike the traditional handcrafted steganographic tools, a steganographic network is relatively large in size. It raises concerns on how to covertly transmit the steganographic network in public channels, which is a crucial stage in the pipeline of steganography in real world applications. To address such an issue, we propose a novel scheme for steganography of steganographic networks in this paper. Unlike the existing steganographic schemes which focus on the subtle modification of the cover data to accommodate the secrets. We propose to disguise a steganographic network (termed as the secret DNN model) into a stego DNN model which performs an ordinary machine learning task (termed as the stego task). During the model disguising, we select and tune a subset of filters in the secret DNN model to preserve its function on the secret task, where the remaining filters are reactivated according to a partial optimization strategy to disguise the whole secret DNN model into a stego DNN model. The secret DNN model can be recovered from the stego DNN model when needed. Various experiments have been conducted to demonstrate the advantage of our proposed method for covert communication of steganographic networks as well as general DNN models.},
  archive   = {C_AAAI},
  author    = {Guobiao Li and Sheng Li and Meiling Li and Xinpeng Zhang and Zhenxing Qian},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25647},
  pages     = {5178-5186},
  title     = {Steganography of steganographic networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). LagNet: Deep lagrangian mechanics for plug-and-play
molecular representation learning. <em>AAAI</em>, 5169–5177. (<a
href="https://doi.org/10.1609/aaai.v37i4.25646">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Molecular representation learning is a fundamental problem in the field of drug discovery and molecular science. Whereas incorporating molecular 3D information in the representations of molecule seems beneficial, which is related to computational chemistry with the basic task of predicting stable 3D structures (conformations) of molecules. Existing machine learning methods either rely on 1D and 2D molecular properties or simulate molecular force field to use additional 3D structure information via Hamiltonian network. The former has the disadvantage of ignoring important 3D structure features, while the latter has the disadvantage that existing Hamiltonian neural network must satisfy the “canonial” constraint, which is difficult to be obeyed in many cases. In this paper, we propose a novel plug-and-play architecture LagNet by simulating molecular force field only with parameterized position coordinates, which implements Lagrangian mechanics to learn molecular representation by preserving 3D conformation without obeying any additional restrictions. LagNet is designed to generate known conformations and generalize for unknown ones from molecular SMILES. Implicit positions in LagNet are learned iteratively using discrete-time Lagrangian equations. Experimental results show that LagNet can well learn 3D molecular structure features, and outperforms previous state-of-the-art baselines related molecular representation by a significant margin.},
  archive   = {C_AAAI},
  author    = {Chunyan Li and Junfeng Yao and Jinsong Su and Zhaoyang Liu and Xiangxiang Zeng and Chenxi Huang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25646},
  pages     = {5169-5177},
  title     = {LagNet: Deep lagrangian mechanics for plug-and-play molecular representation learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GRIP: Graph representation of immune repertoire using graph
neural network and transformer. <em>AAAI</em>, 5160–5168. (<a
href="https://doi.org/10.1609/aaai.v37i4.25645">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The immune repertoire is a collection of immune recep-tors that has emerged as an important biomarker for both diagnostic and therapeutic of cancer patients. In terms of deep learning, analyzing immune repertoire is a challeng-ing multiple-instance learning problem in which the im-mune repertoire of an individual is a bag, and the immune receptor is an instance. Although several deep learning methods for immune repertoire analysis are introduced, they consider the immune repertoire as a set-like struc-ture that doesn’t take account of the nature of the im-mune response. When the immune response occurs, mu-tations are introduced to the immune receptor sequence sequentially to optimize the immune response against the pathogens that enter our body. As a result, immune receptors for the specific pathogen have the lineage of evolution; thus, immune repertoire is better represented as a graph-like structure. In this work, we present our novel method graph representation of immune repertoire (GRIP), which analyzes the immune repertoire as a hier-archical graph structure and utilize the collection of graph neural network followed by graph pooling and transformer to efficiently represents the immune reper-toire as an embedding vector. We show that GRIP predict the survival probability of cancer patients better than the set-based methods and graph-based structure is critical for performance. Also, GRIP provides interpretable re-sults, which prove that GRIP adequately use the progno-sis-related immune receptor and give further possibility to use the GRIP as the novel biomarker searching tool},
  archive   = {C_AAAI},
  author    = {Yongju Lee and Hyunho Lee and Kyoungseob Shin and Sunghoon Kwon},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25645},
  pages     = {5160-5168},
  title     = {GRIP: Graph representation of immune repertoire using graph neural network and transformer},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Rolling horizon based temporal decomposition for the offline
pickup and delivery problem with time windows. <em>AAAI</em>, 5151–5159.
(<a href="https://doi.org/10.1609/aaai.v37i4.25644">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The offline pickup and delivery problem with time windows (PDPTW) is a classical combinatorial optimization problem in the transportation community, which has proven to be very challenging computationally. Due to the complexity of the problem, practical problem instances can be solved only via heuristics, which trade-off solution quality for computational tractability. Among the various heuristics, a common strategy is problem decomposition, that is, the reduction of a large-scale problem into a collection of smaller sub-problems, with spatial and temporal decompositions being two natural approaches. While spatial decomposition has been successful in certain settings, effective temporal decomposition has been challenging due to the difficulty of stitching together the sub-problem solutions across the decomposition boundaries. In this work, we introduce a novel temporal decomposition scheme for solving a class of PDPTWs that have narrow time windows, for which it is able to provide both fast and high-quality solutions. We utilize techniques that have been popularized recently in the context of online dial-a-ride problems along with the general idea of rolling horizon optimization. To the best of our knowledge, this is the first attempt to solve offline PDPTWs using such an approach. To show the performance and scalability of our framework, we use the optimization of paratransit services as a motivating example. Due to the lack of benchmark solvers similar to ours (i.e., temporal decomposition with an online solver), we compare our results with an offline heuristic algorithm using Google OR-Tools. In smaller problem instances (with an average of 129 requests per instance), the baseline approach is as competitive as our framework. However, in larger problem instances (approximately 2,500 requests per instance), our framework is more scalable and can provide good solutions to problem instances of varying degrees of difficulty, while the baseline algorithm often fails to find a feasible solution within comparable compute times.},
  archive   = {C_AAAI},
  author    = {Youngseo Kim and Danushka Edirimanna and Michael Wilbur and Philip Pugliese and Aron Laszka and Abhishek Dubey and Samitha Samaranayake},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25644},
  pages     = {5151-5159},
  title     = {Rolling horizon based temporal decomposition for the offline pickup and delivery problem with time windows},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Heterogeneous graph learning for multi-modal medical data
analysis. <em>AAAI</em>, 5141–5150. (<a
href="https://doi.org/10.1609/aaai.v37i4.25643">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Routine clinical visits of a patient produce not only image data, but also non-image data containing clinical information regarding the patient, i.e., medical data is multi-modal in nature. Such heterogeneous modalities offer different and complementary perspectives on the same patient, resulting in more accurate clinical decisions when they are properly combined. However, despite its significance, how to effectively fuse the multi-modal medical data into a unified framework has received relatively little attention. In this paper, we propose an effective graph-based framework called HetMed (Heterogeneous Graph Learning for Multi-modal Medical Data Analysis) for fusing the multi-modal medical data. Specifically, we construct a multiplex network that incorporates multiple types of non-image features of patients to capture the complex relationship between patients in a systematic way, which leads to more accurate clinical decisions. Extensive experiments on various real-world datasets demonstrate the superiority and practicality of HetMed. The source code for HetMed is available at https://github.com/Sein-Kim/Multimodal-Medical.},
  archive   = {C_AAAI},
  author    = {Sein Kim and Namkyeong Lee and Junseok Lee and Dongmin Hyun and Chanyoung Park},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25643},
  pages     = {5141-5150},
  title     = {Heterogeneous graph learning for multi-modal medical data analysis},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Repair is nearly generation: Multilingual program repair
with LLMs. <em>AAAI</em>, 5131–5140. (<a
href="https://doi.org/10.1609/aaai.v37i4.25642">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Most programmers make mistakes when writing code. Some of these mistakes are small and require few edits to the original program – a class of errors recently termed last mile mistakes. These errors break the flow for experienced developers and can stump novice programmers. Existing automated repair techniques targeting this class of errors are language-specific and do not easily carry over to new languages. Transferring symbolic approaches requires substantial engineering and neural approaches require data and retraining. We introduce RING, a multilingual repair engine powered by a large language model trained on code (LLMC) such as Codex. Such a multilingual engine enables a flipped model for programming assistance, one where the programmer writes code and the AI assistance suggests fixes, compared to traditional code suggestion technology. Taking inspiration from the way programmers manually fix bugs, we show that a prompt-based strategy that conceptualizes repair as localization, transformation, and candidate ranking, can successfully repair programs in multiple languages with minimal effort. We present the first results for such a multilingual repair engine by evaluating on 6 different languages and comparing performance to language-specific repair engines. We show that RING can outperform language-specific repair engines for three of these languages.},
  archive   = {C_AAAI},
  author    = {Harshit Joshi and José Cambronero Sanchez and Sumit Gulwani and Vu Le and Gust Verbruggen and Ivan Radiček},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25642},
  pages     = {5131-5140},
  title     = {Repair is nearly generation: Multilingual program repair with LLMs},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Online symbolic regression with informative query.
<em>AAAI</em>, 5122–5130. (<a
href="https://doi.org/10.1609/aaai.v37i4.25641">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Symbolic regression, the task of extracting mathematical expressions from the observed data, plays a crucial role in scientific discovery. Despite the promising performance of existing methods, most of them conduct symbolic regression in an offline setting. That is, they treat the observed data points as given ones that are simply sampled from uniform distributions without exploring the expressive potential of data. However, for real-world scientific problems, the data used for symbolic regression are usually actively obtained by doing experiments, which is an online setting. Thus, how to obtain informative data that can facilitate the symbolic regression process is an important problem that remains challenging. In this paper, we propose QUOSR, a query-based framework for online symbolic regression that can automatically obtain informative data in an iterative manner. Specifically, at each step, QUOSR receives historical data points, generates new x, and then queries the symbolic expression to get the corresponding y, where the (x, y) serves as new data points. This process repeats until the maximum number of query steps is reached. To make the generated data points informative, we implement the framework with a neural network and train it by maximizing the mutual information between generated data points and the target expression. Through comprehensive experiments, we show that QUOSR can facilitate modern symbolic regression methods by generating informative data.},
  archive   = {C_AAAI},
  author    = {Pengwei Jin and Di Huang and Rui Zhang and Xing Hu and Ziyuan Nan and Zidong Du and Qi Guo and Yunji Chen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25641},
  pages     = {5122-5130},
  title     = {Online symbolic regression with informative query},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning chemical rules of retrosynthesis with pre-training.
<em>AAAI</em>, 5113–5121. (<a
href="https://doi.org/10.1609/aaai.v37i4.25640">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Retrosynthesis aided by artificial intelligence has been a very active and bourgeoning area of research, for its critical role in drug discovery as well as material science. Three categories of solutions, i.e., template-based, template-free, and semi-template methods, constitute mainstream solutions to this problem. In this paper, we focus on template-free methods which are known to be less bothered by the template generalization issue and the atom mapping challenge. Among several remaining problems regarding template-free methods, failing to conform to chemical rules is pronounced. To address the issue, we seek for a pre-training solution to empower the pre-trained model with chemical rules encoded. Concretely, we enforce the atom conservation rule via a molecule reconstruction pre-training task, and the reaction rule that dictates reaction centers via a reaction type guided contrastive pre-training task. In our empirical evaluation, the proposed pre-training solution substantially improves the single-step retrosynthesis accuracies in three downstream datasets.},
  archive   = {C_AAAI},
  author    = {Yinjie Jiang and Ying WEI and Fei Wu and Zhengxing Huang and Kun Kuang and Zhihua Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25640},
  pages     = {5113-5121},
  title     = {Learning chemical rules of retrosynthesis with pre-training},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). MDM: Molecular diffusion model for 3D molecule generation.
<em>AAAI</em>, 5105–5112. (<a
href="https://doi.org/10.1609/aaai.v37i4.25639">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Molecule generation, especially generating 3D molecular geometries from scratch (i.e., 3D de novo generation), has become a fundamental task in drug design. Existing diffusion based 3D molecule generation methods could suffer from unsatisfactory performances, especially when generating large molecules. At the same time, the generated molecules lack enough diversity. This paper proposes a novel diffusion model to address those two challenges. First, interatomic relations are not included in molecules&#39; 3D point cloud representations. Thus, it is difficult for existing generative models to capture the potential interatomic forces and abundant local constraints. To tackle this challenge, we propose to augment the potential interatomic forces and further involve dual equivariant encoders to encode interatomic forces of different strengths. Second, existing diffusion-based models essentially shift elements in geometry along the gradient of data density. Such a process lacks enough exploration in the intermediate steps of the Langevin dynamics. To address this issue, we introduce a distributional controlling variable in each diffusion/reverse step to enforce thorough explorations and further improve generation diversity. Extensive experiments on multiple benchmarks demonstrate that the proposed model significantly outperforms existing methods for both unconditional and conditional generation tasks. We also conduct case studies to help understand the physicochemical properties of the generated molecules. The codes are available at https://github.com/tencent-ailab/MDM.},
  archive   = {C_AAAI},
  author    = {Lei Huang and Hengtong Zhang and Tingyang Xu and Ka-Chun Wong},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25639},
  pages     = {5105-5112},
  title     = {MDM: Molecular diffusion model for 3D molecule generation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MGTCF: Multi-generator tropical cyclone forecasting with
heterogeneous meteorological data. <em>AAAI</em>, 5096–5104. (<a
href="https://doi.org/10.1609/aaai.v37i4.25638">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Accurate forecasting of tropical cyclone (TC) plays a critical role in the prevention and defense of TC disasters. We must explore a more accurate method for TC prediction. Deep learning methods are increasingly being implemented to make TC prediction more accurate. However, most existing methods lack a generic framework for adapting heterogeneous meteorological data and do not focus on the importance of the environment. Therefore, we propose a Multi-Generator Tropical Cyclone Forecasting model (MGTCF), a generic, extensible, multi-modal TC prediction model with the key modules of Generator Chooser Network (GC-Net) and Environment Net (Env-Net). The proposed method can utilize heterogeneous meteorologic data efficiently and mine environmental factors. In addition, the Multi-generator with Generator Chooser Net is proposed to tackle the drawbacks of single-generator TC prediction methods: the prediction of undesired out-of-distribution samples and the problems stemming from insufficient learning ability. To prove the effectiveness of MGTCF, we conduct extensive experiments on the China Meteorological Administration Tropical Cyclone Best Track Dataset. MGTCF obtains better performance compared with other deep learning methods and outperforms the official prediction method of the China Central Meteorological Observatory in most indexes.},
  archive   = {C_AAAI},
  author    = {Cheng Huang and Cong Bai and Sixian Chan and Jinglin Zhang and YuQuan Wu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25638},
  pages     = {5096-5104},
  title     = {MGTCF: Multi-generator tropical cyclone forecasting with heterogeneous meteorological data},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Integrating reward maximization and population estimation:
Sequential decision-making for internal revenue service audit selection.
<em>AAAI</em>, 5087–5095. (<a
href="https://doi.org/10.1609/aaai.v37i4.25637">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We introduce a new setting, optimize-and-estimate structured bandits. Here, a policy must select a batch of arms, each characterized by its own context, that would allow it to both maximize reward and maintain an accurate (ideally unbiased) population estimate of the reward. This setting is inherent to many public and private sector applications and often requires handling delayed feedback, small data, and distribution shifts. We demonstrate its importance on real data from the United States Internal Revenue Service (IRS). The IRS performs yearly audits of the tax base. Two of its most important objectives are to identify suspected misreporting and to estimate the &quot;tax gap&quot; -- the global difference between the amount paid and true amount owed. Based on a unique collaboration with the IRS, we cast these two processes as a unified optimize-and-estimate structured bandit. We analyze optimize-and-estimate approaches to the IRS problem and propose a novel mechanism for unbiased population estimation that achieves rewards comparable to baseline approaches. This approach has the potential to improve audit efficacy, while maintaining policy-relevant estimates of the tax gap. This has important social consequences given that the current tax gap is estimated at nearly half a trillion dollars. We suggest that this problem setting is fertile ground for further research and we highlight its interesting challenges. The results of this and related research are currently being incorporated into the continual improvement of the IRS audit selection methods.},
  archive   = {C_AAAI},
  author    = {Peter Henderson and Ben Chugg and Brandon Anderson and Kristen Altenburger and Alex Turk and John Guyton and Jacob Goldin and Daniel E. Ho},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25637},
  pages     = {5087-5095},
  title     = {Integrating reward maximization and population estimation: Sequential decision-making for internal revenue service audit selection},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MSDC: Exploiting multi-state power consumption in
non-intrusive load monitoring based on a dual-CNN model. <em>AAAI</em>,
5078–5086. (<a href="https://doi.org/10.1609/aaai.v37i4.25636">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Non-intrusive load monitoring (NILM) aims to decompose aggregated electrical usage signal into appliance-specific power consumption and it amounts to a classical example of blind source separation tasks. Leveraging recent progress on deep learning techniques, we design a new neural NILM model {\em Multi-State Dual CNN} (MSDC). Different from previous models, MSDC explicitly extracts information about the appliance&#39;s multiple states and state transitions, which in turn regulates the prediction of signals for appliances. More specifically, we employ a dual-CNN architecture: one CNN for outputting state distributions and the other for predicting the power of each state. A new technique is invented that utilizes conditional random fields (CRF) to capture state transitions. Experiments on two real-world datasets REDD and UK-DALE demonstrate that our model significantly outperform state-of-the-art models while having good generalization capacity, achieving 6\%-10\% MAE gain and 33\%-51\% SAE gain to unseen appliances.},
  archive   = {C_AAAI},
  author    = {Jialing He and Jiamou Liu and Zijian Zhang and Yang Chen and Yiwei Liu and Bakh Khoussainov and Liehuang Zhu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25636},
  pages     = {5078-5086},
  title     = {MSDC: Exploiting multi-state power consumption in non-intrusive load monitoring based on a dual-CNN model},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A domain-knowledge-inspired music embedding space and a
novel attention mechanism for symbolic music modeling. <em>AAAI</em>,
5070–5077. (<a href="https://doi.org/10.1609/aaai.v37i4.25635">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Following the success of the transformer architecture in the natural language domain, transformer-like architectures have been widely applied to the domain of symbolic music recently. Symbolic music and text, however, are two different modalities. Symbolic music contains multiple attributes, both absolute attributes (e.g., pitch) and relative attributes (e.g., pitch interval). These relative attributes shape human perception of musical motifs. These important relative attributes, however, are mostly ignored in existing symbolic music modelling methods with the main reason being the lack of a musically-meaningful embedding space where both the absolute and relative embeddings of the symbolic music tokens can be efficiently represented. In this paper, we propose the Fundamental Music Embedding (FME) for symbolic music based on a bias-adjusted sinusoidal encoding within which both the absolute and the relative attributes can be embedded and the fundamental musical properties (e.g., translational invariance) are explicitly preserved. Taking advantage of the proposed FME, we further propose a novel attention mechanism based on the relative index, pitch and onset embeddings (RIPO attention) such that the musical domain knowledge can be fully utilized for symbolic music modelling. Experiment results show that our proposed model: RIPO transformer which utilizes FME and RIPO attention outperforms the state-of-the-art transformers (i.e., music transformer, linear transformer) in a melody completion task. Moreover, using the RIPO transformer in a downstream music generation task, we notice that the notorious degeneration phenomenon no longer exists and the music generated by the RIPO transformer outperforms the music generated by state-of-the-art transformer models in both subjective and objective evaluations. The code of the proposed method is available online: github.com/guozixunnicolas/FundamentalMusicEmbedding.},
  archive   = {C_AAAI},
  author    = {Zixun Guo and Jaeyong Kang and Dorien Herremans},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25635},
  pages     = {5070-5077},
  title     = {A domain-knowledge-inspired music embedding space and a novel attention mechanism for symbolic music modeling},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Identifying and eliminating majority illusion in social
networks. <em>AAAI</em>, 5062–5069. (<a
href="https://doi.org/10.1609/aaai.v37i4.25634">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Majority illusion occurs in a social network when the majority of the network vertices belong to a certain type but the majority of each vertex&#39;s neighbours belong to a different type, therefore creating the wrong perception, i.e., the illusion, that the majority type is different from the actual one. From a system engineering point of view, this motivates the search for algorithms to detect and, where possible, correct this undesirable phenomenon. In this paper we initiate the computational study of majority illusion in social networks, providing NP-hardness and parametrised complexity results for its occurrence and elimination.},
  archive   = {C_AAAI},
  author    = {Umberto Grandi and Lawqueen Kanesh and Grzegorz Lisowski and Ramanujan Sridharan and Paolo Turrini},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25634},
  pages     = {5062-5069},
  title     = {Identifying and eliminating majority illusion in social networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Flow-based robust watermarking with invertible noise layer
for black-box distortions. <em>AAAI</em>, 5054–5061. (<a
href="https://doi.org/10.1609/aaai.v37i4.25633">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep learning-based digital watermarking frameworks have been widely studied recently. Most existing methods adopt an ``encoder-noise layer-decoder&#39;&#39;-based architecture where the embedding and extraction processes are accomplished separately by the encoder and the decoder. However, one potential drawback of such a framework is that the encoder and the decoder may not be well coupled, resulting in the fact that the encoder may embed some redundant features into the host image thus influencing the invisibility and robustness of the whole algorithm. To address this limitation, this paper proposes a flow-based robust watermarking framework. The basic component of such framework is an invertible up-down-sampling neural block that can realize the embedding and extraction simultaneously. As a consequence, the encoded feature could keep high consistency with the feature that the decoder needed, which effectively avoids the embedding of redundant features. In addition, to ensure the robustness of black-box distortion, an invertible noise layer (INL) is designed to simulate the distortion and is served as a noise layer in the training stage. Benefiting from its reversibility, INL is also applied as a preprocessing before extraction to eliminate the distortion, which further improves the robustness of the algorithm. Extensive experiments demonstrate the superiority of the proposed framework in terms of visual quality and robustness. Compared with the state-of-the-art architecture, the visual quality (measured by PSNR) of the proposed framework improves by 2dB and the extraction accuracy after JPEG compression (QF=50) improves by more than 4\%. Besides, the robustness against black-box distortions can be greatly achieved with more than 95\% extraction accuracy.},
  archive   = {C_AAAI},
  author    = {Han Fang and Yupeng Qiu and Kejiang Chen and Jiyi Zhang and Weiming Zhang and Ee-Chien Chang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25633},
  pages     = {5054-5061},
  title     = {Flow-based robust watermarking with invertible noise layer for black-box distortions},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Constrained submodular optimization for vaccine design.
<em>AAAI</em>, 5045–5053. (<a
href="https://doi.org/10.1609/aaai.v37i4.25632">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Advances in machine learning have enabled the prediction of immune system responses to prophylactic and therapeutic vaccines. However, the engineering task of designing vaccines remains a challenge. In particular, the genetic variability of the human immune system makes it difficult to design peptide vaccines that provide widespread immunity in vaccinated populations. We introduce a framework for evaluating and designing peptide vaccines that uses probabilistic machine learning models, and demonstrate its ability to produce designs for a SARS-CoV-2 vaccine that outperform previous designs. We provide a theoretical analysis of the approximability, scalability, and complexity of our framework.},
  archive   = {C_AAAI},
  author    = {Zheng Dai and David K. Gifford},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25632},
  pages     = {5045-5053},
  title     = {Constrained submodular optimization for vaccine design},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unsupervised deep embedded fusion representation of
single-cell transcriptomics. <em>AAAI</em>, 5036–5044. (<a
href="https://doi.org/10.1609/aaai.v37i4.25631">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Cell clustering is a critical step in analyzing single-cell RNA sequencing (scRNA-seq) data, which allows us to characterize the cellular heterogeneity of transcriptional profiling at the single-cell level. Single-cell deep embedded representation models have recently become popular since they can learn feature representation and clustering simultaneously. However, the model still suffers from a variety of significant challenges, including the massive amount of data, pervasive dropout events, and complicated noise patterns in transcriptional profiling. Here, we propose a Single-Cell Deep Embedding Fusion Representation (scDEFR) model, which develop a deep embedded fusion representation to learn fused heterogeneous latent embedding that contains both the transcriptome gene-level information and the cell topology information. We first fuse them layer by layer to obtain compressed representations of intercellular relationships and transcriptome information. After that, the zero-inflated negative binomial model (ZINB)-based decoder is proposed to capture the global probabilistic structure of the data and reconstruct the final gene expression information and cell graph. Finally, by simultaneously integrating the clustering loss, crossentropy loss, ZINB loss, and the cell graph reconstruction loss, scDEFR can optimize clustering performance and learn the latent representation in fused information under a joint mutual supervised strategy. We conducted extensive and comprehensive experiments on 15 single-cell RNA-seq datasets from different sequencing platforms to demonstrate the superiority of scDEFR over a variety of state-of-the-art methods.},
  archive   = {C_AAAI},
  author    = {Yue Cheng and Yanchi Su and Zhuohan Yu and Yanchun Liang and Ka-Chun Wong and Xiangtao Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25631},
  pages     = {5036-5044},
  title     = {Unsupervised deep embedded fusion representation of single-cell transcriptomics},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Set-to-sequence ranking-based concept-aware learning path
recommendation. <em>AAAI</em>, 5027–5035. (<a
href="https://doi.org/10.1609/aaai.v37i4.25630">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With the development of the online education system, personalized education recommendation has played an essential role. In this paper, we focus on developing path recommendation systems that aim to generating and recommending an entire learning path to the given user in each session. Noticing that existing approaches fail to consider the correlations of concepts in the path, we propose a novel framework named Set-to-Sequence Ranking-based Concept-aware Learning Path Recommendation (SRC), which formulates the recommendation task under a set-to-sequence paradigm. Specifically, we first design a concept-aware encoder module which can capture the correlations among the input learning concepts. The outputs are then fed into a decoder module that sequentially generates a path through an attention mechanism that handles correlations between the learning and target concepts. Our recommendation policy is optimized by policy gradient. In addition, we also introduce an auxiliary module based on knowledge tracing to enhance the model’s stability by evaluating students’ learning effects on learning concepts. We conduct extensive experiments on two real-world public datasets and one industrial dataset, and the experimental results demonstrate the superiority and effectiveness of SRC. Code now is available at https://gitee.com/mindspore/models/tree/master/research/recommend/SRC.},
  archive   = {C_AAAI},
  author    = {Xianyu Chen and Jian Shen and Wei Xia and Jiarui Jin and Yakun Song and Weinan Zhang and Weiwen Liu and Menghui Zhu and Ruiming Tang and Kai Dong and Dingyin Xia and Yong Yu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25630},
  pages     = {5027-5035},
  title     = {Set-to-sequence ranking-based concept-aware learning path recommendation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). BETA-CD: A bayesian meta-learned cognitive diagnosis
framework for personalized learning. <em>AAAI</em>, 5018–5026. (<a
href="https://doi.org/10.1609/aaai.v37i4.25629">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Personalized learning is a promising educational approach that aims to provide high-quality personalized services for each student with minimum demands for practice data. The key to achieving that lies in the cognitive diagnosis task, which estimates the cognitive state of the student through his/her logged data of doing practice quizzes. Nevertheless, in the personalized learning scenario, existing cognitive diagnosis models suffer from the inability to (1) quickly adapt to new students using a small amount of data, and (2) measure the reliability of the diagnosis result to avoid improper services that mismatch the student&#39;s actual state. In this paper, we propose a general Bayesian mETA-learned Cognitive Diagnosis framework (BETA-CD), which addresses the two challenges by prior knowledge exploitation and model uncertainty quantification, respectively. Specifically, we firstly introduce Bayesian hierarchical modeling to associate each student&#39;s cognitive state with a shared prior distribution encoding prior knowledge and a personal posterior distribution indicating model uncertainty. Furthermore, we formulate a meta-learning objective to automatically exploit prior knowledge from historical students, and efficiently solve it with a gradient-based variational inference method. The code will be publicly available at https://github.com/AyiStar/pyat.},
  archive   = {C_AAAI},
  author    = {Haoyang Bi and Enhong Chen and Weidong He and Han Wu and Weihao Zhao and Shijin Wang and Jinze Wu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25629},
  pages     = {5018-5026},
  title     = {BETA-CD: A bayesian meta-learned cognitive diagnosis framework for personalized learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Principled data-driven decision support for cyber-forensic
investigations. <em>AAAI</em>, 5010–5017. (<a
href="https://doi.org/10.1609/aaai.v37i4.25628">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the wake of a cybersecurity incident, it is crucial to promptly discover how the threat actors breached security in order to assess the impact of the incident and to develop and deploy countermeasures that can protect against further attacks. To this end, defenders can launch a cyber-forensic investigation, which discovers the techniques that the threat actors used in the incident. A fundamental challenge in such an investigation is prioritizing the investigation of particular techniques since the investigation of each technique requires time and effort, but forensic analysts cannot know which ones were actually used before investigating them. To ensure prompt discovery, it is imperative to provide decision support that can help forensic analysts with this prioritization. A recent study demonstrated that data-driven decision support, based on a dataset of prior incidents, can provide state-of-the-art prioritization. However, this data-driven approach, called DISCLOSE, is based on a heuristic that utilizes only a subset of the available information and does not approximate optimal decisions. To improve upon this heuristic, we introduce a principled approach for data-driven decision support for cyber-forensic investigations. We formulate the decision-support problem using a Markov decision process, whose states represent the states of a forensic investigation. To solve the decision problem, we propose a Monte Carlo tree search based method, which relies on a k-NN regression over prior incidents to estimate state-transition probabilities. We evaluate our proposed approach on multiple versions of the MITRE ATT&amp;CK dataset, which is a knowledge base of adversarial techniques and tactics based on real-world cyber incidents, and demonstrate that our approach outperforms DISCLOSE in terms of techniques discovered per effort spent.},
  archive   = {C_AAAI},
  author    = {Soodeh Atefi and Sakshyam Panda and Emmanouil Panaousis and Aron Laszka},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25628},
  pages     = {5010-5017},
  title     = {Principled data-driven decision support for cyber-forensic investigations},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Anytime user engagement prediction in information cascades
for arbitrary observation periods. <em>AAAI</em>, 4999–5009. (<a
href="https://doi.org/10.1609/aaai.v37i4.25627">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Predicting user engagement -- whether a user will engage in a given information cascade -- is an important problem in the context of social media, as it is useful to online marketing and misinformation mitigation just to name a couple major applications. Based on split population multi-variate survival processes, we develop a discriminative approach that, unlike prior works, leads to a single model for predicting whether individual users of an information network will engage a given cascade for arbitrary forecast horizons and observation periods. Being probabilistic in nature, this model retains the interpretability of its generative counterpart and renders count prediction intervals in a disciplined manner. Our results indicate that our model is highly competitive, if not superior, to current approaches, when compared over varying observed cascade histories and forecast horizons.},
  archive   = {C_AAAI},
  author    = {Akshay Aravamudan and Xi Zhang and Georgios C. Anagnostopoulos},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25627},
  pages     = {4999-5009},
  title     = {Anytime user engagement prediction in information cascades for arbitrary observation periods},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Show me the way! Bilevel search for synthesizing
programmatic strategies. <em>AAAI</em>, 4991–4998. (<a
href="https://doi.org/10.1609/aaai.v37i4.25626">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The synthesis of programmatic strategies requires one to search in large non-differentiable spaces of computer programs. Current search algorithms use self-play approaches to guide this search. The issue with these approaches is that the guiding function often provides a weak search signal. This is because self-play functions only measure how well a program performs against other programs. Thus, while small changes to a losing program might not transform it into a winning one, such changes might represent steps in the direction of a winning program. In this paper we introduce a bilevel search algorithm that searches concurrently in the space of programs and in a space of state features. Each iteration of the search in the space of features defines a set of target features that the search in the program space attempts to achieve (i.e., features one observes while following the strategy encoded in a program). We hypothesize the combination of a self-play function and a feature-based one provides a stronger search signal for synthesis. While both functions are used to guide the search in the program space, the self-play function is used to guide the search in the feature space, to allow for the selection of target features that are more likely to lead to winning programs. We evaluated our bilevel algorithm in MicroRTS, a real-time strategy game. Our results show that the bilevel search synthesizes stronger strategies than methods that search only in the program space. Also, the strategies our method synthesizes obtained the highest winning rate in a simulated tournament with several baseline agents, including the best agents from the two latest MicroRTS competitions.},
  archive   = {C_AAAI},
  author    = {David S. Aleixo and Levi H.S. Lelis},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25626},
  pages     = {4991-4998},
  title     = {Show me the way! bilevel search for synthesizing programmatic strategies},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Heterogeneous region embedding with prompt learning.
<em>AAAI</em>, 4981–4989. (<a
href="https://doi.org/10.1609/aaai.v37i4.25625">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The prevalence of region-based urban data has opened new possibilities for exploring correlations among regions to improve urban planning and smart-city solutions. Region embedding, which plays a critical role in this endeavor, faces significant challenges related to the varying nature of city data and the effectiveness of downstream applications. In this paper, we propose a novel framework, HREP (Heterogeneous Region Embedding with Prompt learning), which addresses both intra-region and inter-region correlations through two key modules: Heterogeneous Region Embedding (HRE) and prompt learning for different downstream tasks. The HRE module constructs a heterogeneous region graph based on three categories of data, capturing inter-region contexts such as human mobility and geographic neighbors, and intraregion contexts such as POI (Point-of-Interest) information. We use relation-aware graph embedding to learn region and relation embeddings of edge types, and introduce selfattention to capture global correlations among regions. Additionally, we develop an attention-based fusion module to integrate shared information among different types of correlations. To enhance the effectiveness of region embedding in downstream tasks, we incorporate prompt learning, specifically prefix-tuning, which guides the learning of downstream tasks and results in better prediction performance. Our experiment results on real-world datasets demonstrate that our proposed model outperforms state-of-the-art methods.},
  archive   = {C_AAAI},
  author    = {Silin Zhou and Dan He and Lisi Chen and Shuo Shang and Peng Han},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25625},
  pages     = {4981-4989},
  title     = {Heterogeneous region embedding with prompt learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). GRLSTM: Trajectory similarity computation with graph-based
residual LSTM. <em>AAAI</em>, 4972–4980. (<a
href="https://doi.org/10.1609/aaai.v37i4.25624">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The computation of trajectory similarity is a crucial task in many spatial data analysis applications. However, existing methods have been designed primarily for trajectories in Euclidean space, which overlooks the fact that real-world trajectories are often generated on road networks. This paper addresses this gap by proposing a novel framework, called GRLSTM (Graph-based Residual LSTM). To jointly capture the properties of trajectories and road networks, the proposed framework incorporates knowledge graph embedding (KGE), graph neural network (GNN), and the residual network into the multi-layer LSTM (Residual-LSTM). Specifically, the framework constructs a point knowledge graph to study the multi-relation of points, as points may belong to both the trajectory and the road network. KGE is introduced to learn point embeddings and relation embeddings to build the point fusion graph, while GNN is used to capture the topology structure information of the point fusion graph. Finally, Residual-LSTM is used to learn the trajectory embeddings.To further enhance the accuracy and robustness of the final trajectory embeddings, we introduce two new neighbor-based point loss functions, namely, graph-based point loss function and trajectory-based point loss function. The GRLSTM is evaluated using two real-world trajectory datasets, and the experimental results demonstrate that GRLSTM outperforms all the state-of-the-art methods significantly.},
  archive   = {C_AAAI},
  author    = {Silin Zhou and Jing Li and Hao Wang and Shuo Shang and Peng Han},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25624},
  pages     = {4972-4980},
  title     = {GRLSTM: Trajectory similarity computation with graph-based residual LSTM},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Detecting multivariate time series anomalies with zero known
label. <em>AAAI</em>, 4963–4971. (<a
href="https://doi.org/10.1609/aaai.v37i4.25623">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multivariate time series anomaly detection has been extensively studied under the one-class classification setting, where a training dataset with all normal instances is required. However, preparing such a dataset is very laborious since each single data instance should be fully guaranteed to be normal. It is, therefore, desired to explore multivariate time series anomaly detection methods based on the dataset without any label knowledge. In this paper, we propose MTGFlow, an unsupervised anomaly detection approach forMultivariate Time series anomaly detection via dynamic Graph and entityaware normalizing Flow, leaning only on a widely accepted hypothesis that abnormal instances exhibit sparse densities than the normal. However, the complex interdependencies among entities and the diverse inherent characteristics of each entity pose significant challenges to density estimation, let alone to detect anomalies based on the estimated possibility distribution. To tackle these problems, we propose to learn the mutual and dynamic relations among entities via a graph structure learning model, which helps to model the accurate distribution of multivariate time series. Moreover, taking account of distinct characteristics of the individual entities, an entity-aware normalizing flow is developed to describe each entity into a parameterized normal distribution, thereby producing fine-grained density estimation. Incorporating these two strategies, MTGFlow achieves superior anomaly detection performance. Experiments on five public datasets with seven baselines are conducted, MTGFlow outperforms the SOTA methods by up to 5.0 AUROC\%.},
  archive   = {C_AAAI},
  author    = {Qihang Zhou and Jiming Chen and Haoyu Liu and Shibo He and Wenchao Meng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25623},
  pages     = {4963-4971},
  title     = {Detecting multivariate time series anomalies with zero known label},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GraphSR: A data augmentation algorithm for imbalanced node
classification. <em>AAAI</em>, 4954–4962. (<a
href="https://doi.org/10.1609/aaai.v37i4.25622">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph neural networks (GNNs) have achieved great success in node classification tasks. However, existing GNNs naturally bias towards the majority classes with more labelled data and ignore those minority classes with relatively few labelled ones. The traditional techniques often resort over-sampling methods, but they may cause overfitting problem. More recently, some works propose to synthesize additional nodes for minority classes from the labelled nodes, however, there is no any guarantee if those generated nodes really stand for the the corresponding minority classes. In fact, improperly synthesized nodes may result in insufficient generalization of the algorithm. To resolve the problem, in this paper we seek to automatically augment the minority classes from the massive unlabelled nodes of the graph. Specifically, we propose \textit{GraphSR}, a novel self-training strategy to augment the minority classes with significant diversity of unlabelled nodes, which is based on a Similarity-based selection module and a Reinforcement Learning(RL) selection module. The first module finds a subset of unlabelled nodes which are most similar to those labelled minority nodes, and the second one further determines the representative and reliable nodes from the subset via RL technique. Furthermore, the RL-based module can adaptively determine the sampling scale according to current training data. This strategy is general and can be easily combined with different GNNs models. Our experiments demonstrate the proposed approach outperforms the state-of-the-art baselines on various class-imbalanced datasets.},
  archive   = {C_AAAI},
  author    = {Mengting Zhou and Zhiguo Gong},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25622},
  pages     = {4954-4962},
  title     = {GraphSR: A data augmentation algorithm for imbalanced node classification},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A provable framework of learning graph embeddings via
summarization. <em>AAAI</em>, 4946–4953. (<a
href="https://doi.org/10.1609/aaai.v37i4.25621">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Given a large graph, can we learn its node embeddings from a smaller summary graph? What is the relationship between embeddings learned from original graphs and their summary graphs? Graph representation learning plays an important role in many graph mining applications, but learning em-beddings of large-scale graphs remains a challenge. Recent works try to alleviate it via graph summarization, which typ-ically includes the three steps: reducing the graph size by combining nodes and edges into supernodes and superedges,learning the supernode embedding on the summary graph and then restoring the embeddings of the original nodes. How-ever, the justification behind those steps is still unknown. In this work, we propose GELSUMM, a well-formulated graph embedding learning framework based on graph sum-marization, in which we show the theoretical ground of learn-ing from summary graphs and the restoration with the three well-known graph embedding approaches in a closed form.Through extensive experiments on real-world datasets, we demonstrate that our methods can learn graph embeddings with matching or better performance on downstream tasks.This work provides theoretical analysis for learning node em-beddings via summarization and helps explain and under-stand the mechanism of the existing works.},
  archive   = {C_AAAI},
  author    = {Houquan Zhou and Shenghua Liu and Danai Koutra and Huawei Shen and Xueqi Cheng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25621},
  pages     = {4946-4953},
  title     = {A provable framework of learning graph embeddings via summarization},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ADMoE: Anomaly detection with mixture-of-experts from noisy
labels. <em>AAAI</em>, 4937–4945. (<a
href="https://doi.org/10.1609/aaai.v37i4.25620">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Existing works on anomaly detection (AD) rely on clean labels from human annotators that are expensive to acquire in practice. In this work, we propose a method to leverage weak/noisy labels (e.g., risk scores generated by machine rules for detecting malware) that are cheaper to obtain for anomaly detection. Specifically, we propose ADMoE, the first framework for anomaly detection algorithms to learn from noisy labels. In a nutshell, ADMoE leverages mixture-of-experts (MoE) architecture to encourage specialized and scalable learning from multiple noisy sources. It captures the similarities among noisy labels by sharing most model parameters, while encouraging specialization by building &quot;expert&quot; sub-networks. To further juice out the signals from noisy labels, ADMoE uses them as input features to facilitate expert learning. Extensive results on eight datasets (including a proprietary enterprise security dataset) demonstrate the effectiveness of ADMoE, where it brings up to 34\% performance improvement over not using it. Also, it outperforms a total of 13 leading baselines with equivalent network parameters and FLOPS. Notably, ADMoE is model-agnostic to enable any neural network-based detection methods to handle noisy labels, where we showcase its results on both multiple-layer perceptron (MLP) and the leading AD method DeepSAD.},
  archive   = {C_AAAI},
  author    = {Yue Zhao and Guoqing Zheng and Subhabrata Mukherjee and Robert McCann and Ahmed Awadallah},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25620},
  pages     = {4937-4945},
  title     = {ADMoE: Anomaly detection with mixture-of-experts from noisy labels},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Causal conditional hidden markov model for multimodal
traffic prediction. <em>AAAI</em>, 4929–4936. (<a
href="https://doi.org/10.1609/aaai.v37i4.25619">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multimodal traffic flow can reflect the health of the transportation system, and its prediction is crucial to urban traffic management. Recent works overemphasize spatio-temporal correlations of traffic flow, ignoring the physical concepts that lead to the generation of observations and their causal relationship. Spatio-temporal correlations are considered unstable under the influence of different conditions, and spurious correlations may exist in observations. In this paper, we analyze the physical concepts affecting the generation of multimode traffic flow from the perspective of the observation generation principle and propose a Causal Conditional Hidden Markov Model (CCHMM) to predict multimodal traffic flow. In the latent variables inference stage, a posterior network disentangles the causal representations of the concepts of interest from conditional information and observations, and a causal propagation module mines their causal relationship. In the data generation stage, a prior network samples the causal latent variables from the prior distribution and feeds them into the generator to generate multimodal traffic flow. We use a mutually supervised training method for the prior and posterior to enhance the identifiability of the model. Experiments on real-world datasets show that CCHMM can effectively disentangle causal representations of concepts of interest and identify causality, and accurately predict multimodal traffic flow.},
  archive   = {C_AAAI},
  author    = {Yu Zhao and Pan Deng and Junting Liu and Xiaofeng Jia and Mulan Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25619},
  pages     = {4929-4936},
  title     = {Causal conditional hidden markov model for multimodal traffic prediction},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep graph structural infomax. <em>AAAI</em>, 4920–4928. (<a
href="https://doi.org/10.1609/aaai.v37i4.25618">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the scene of self-supervised graph learning, Mutual Information (MI) was recently introduced for graph encoding to generate robust node embeddings. A successful representative is Deep Graph Infomax (DGI), which essentially operates on the space of node features but ignores topological structures, and just considers global graph summary. In this paper, we present an effective model called Deep Graph Structural Infomax (DGSI) to learn node representation. We explore to derive the structural mutual information from the perspective of Information Bottleneck (IB), which defines a trade-off between the sufficiency and minimality of representation on the condition of the topological structure preservation. Intuitively, the derived constraints formally maximize the structural mutual information both edge-wise and local neighborhood-wise. Besides, we develop a general framework that incorporates the global representational mutual information, local representational mutual information, and sufficient structural information into the node representation. Essentially, our DGSI extends DGI and could capture more fine-grained semantic information as well as beneficial structural information in a self-supervised manner, thereby improving node representation and further boosting the learning performance. Extensive experiments on different types of datasets demonstrate the effectiveness and superiority of the proposed method.},
  archive   = {C_AAAI},
  author    = {Wenting Zhao and Gongping Xu and Zhen Cui and Siqiang Luo and Cheng Long and Tong Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25618},
  pages     = {4920-4928},
  title     = {Deep graph structural infomax},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fair representation learning for recommendation: A mutual
information perspective. <em>AAAI</em>, 4911–4919. (<a
href="https://doi.org/10.1609/aaai.v37i4.25617">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recommender systems have been widely used in recent years. By exploiting historical user-item interactions, recommender systems can model personalized potential interests of users and have been widely applied to a wide range of scenarios. Despite their impressive performance, most of them may be subject to unwanted biases related to sensitive attributes (e.g., race and gender), leading to unfairness. An intuitive idea to alleviate this problem is to ensure that there is no mutual information between recommendation results and sensitive attributes. However, keeping independence conditions solely achieves fairness improvement while causing an obvious degradation of recommendation accuracy, which is not a desired result. To this end, in this paper, we re-define recommendation fairness with a novel two-fold mutual information objective. In concerned details, we define fairness as mutual information minimization between embeddings and sensitive information, and mutual information maximization between embeddings and non-sensitive information. Then, a flexible Fair Mutual Information (FairMI) framework is designed to achieve this goal. FairMI first employs a sensitive attribute encoder to capture sensitive information in the data. Then, based on results from the sensitive attribute encoder, an interest encoder is developed to generate sensitive-free embeddings, which are expected to contain rich non-sensitive information of input data. Moreover, we propose novel mutual information (upper/lower) bounds with contrastive information estimation for model optimization. Extensive experiments over two real-world datasets demonstrate the effectiveness of our proposed FairMI in reducing unfairness and improving recommendation accuracy simultaneously.},
  archive   = {C_AAAI},
  author    = {Chen Zhao and Le Wu and Pengyang Shao and Kun Zhang and Richang Hong and Meng Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25617},
  pages     = {4911-4919},
  title     = {Fair representation learning for recommendation: A mutual information perspective},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AutoSTL: Automated spatio-temporal multi-task learning.
<em>AAAI</em>, 4902–4910. (<a
href="https://doi.org/10.1609/aaai.v37i4.25616">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Spatio-temporal prediction plays a critical role in smart city construction. Jointly modeling multiple spatio-temporal tasks can further promote an intelligent city life by integrating their inseparable relationship. However, existing studies fail to address this joint learning problem well, which generally solve tasks individually or a fixed task combination. The challenges lie in the tangled relation between different properties, the demand for supporting flexible combinations of tasks and the complex spatio-temporal dependency. To cope with the problems above, we propose an Automated Spatio-Temporal multi-task Learning (AutoSTL) method to handle multiple spatio-temporal tasks jointly. Firstly, we propose a scalable architecture consisting of advanced spatio-temporal operations to exploit the complicated dependency. Shared modules and feature fusion mechanism are incorporated to further capture the intrinsic relationship between tasks. Furthermore, our model automatically allocates the operations and fusion weight. Extensive experiments on benchmark datasets verified that our model achieves state-of-the-art performance. As we can know, AutoSTL is the first automated spatio-temporal multi-task learning method.},
  archive   = {C_AAAI},
  author    = {Zijian Zhang and Xiangyu Zhao and Hao Miao and Chunxu Zhang and Hongwei Zhao and Junbo Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25616},
  pages     = {4902-4910},
  title     = {AutoSTL: Automated spatio-temporal multi-task learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cross-domain few-shot graph classification with a reinforced
task coordinator. <em>AAAI</em>, 4893–4901. (<a
href="https://doi.org/10.1609/aaai.v37i4.25615">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Cross-domain graph few-shot learning attempts to address the prevalent data scarcity issue in graph mining problems. However, the utilization of cross-domain data induces another intractable domain shift issue which severely degrades the generalization ability of cross-domain graph few-shot learning models. The combat with the domain shift issue is hindered due to the coarse utilization of source domains and the ignorance of accessible prompts. To address these challenges, in this paper, we design a novel Cross-domain Task Coordinator to leverage a small set of labeled target domain data as prompt tasks, then model the association and discover the relevance between meta-tasks from the source domain and the prompt tasks. Based on the discovered relevance, our model achieves adaptive task selection and enables the optimization of a graph learner using the selected fine-grained meta-tasks. Extensive experiments conducted on molecular property prediction benchmarks validate the effectiveness of our proposed method by comparing it with state-of-the-art baselines.},
  archive   = {C_AAAI},
  author    = {Qiannan Zhang and Shichao Pei and Qiang Yang and Chuxu Zhang and Nitesh V. Chawla and Xiangliang Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25615},
  pages     = {4893-4901},
  title     = {Cross-domain few-shot graph classification with a reinforced task coordinator},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TOT：topology-aware optimal transport for multimodal hate
detection. <em>AAAI</em>, 4884–4892. (<a
href="https://doi.org/10.1609/aaai.v37i4.25614">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multimodal hate detection, which aims to identify the harmful content online such as memes, is crucial for building a wholesome internet environment. Previous work has made enlightening exploration in detecting explicit hate remarks. However, most of their approaches neglect the analysis of implicit harm, which is particularly challenging as explicit text markers and demographic visual cues are often twisted or missing. The leveraged cross-modal attention mechanisms also suffer from the distributional modality gap and lack logical interpretability. To address these semantic gap issues, we propose TOT: a topology-aware optimal transport framework to decipher the implicit harm in memes scenario, which formulates the cross-modal aligning problem as solutions for optimal transportation plans. Specifically, we leverage an optimal transport kernel method to capture complementary information from multiple modalities. The kernel embedding provides a non-linear transformation ability to reproduce a kernel Hilbert space (RKHS), which reflects significance for eliminating the distributional modality gap. Moreover, we perceive the topology information based on aligned representations to conduct bipartite graph path reasoning. The newly achieved state-of-the-art performance on two publicly available benchmark datasets, together with further visual analysis, demonstrate the superiority of TOT in capturing implicit cross-modal alignment.},
  archive   = {C_AAAI},
  author    = {Linhao Zhang and Li Jin and Xian Sun and Guangluan Xu and Zequn Zhang and Xiaoyu Li and Nayu Liu and Qing Liu and Shiyao Yan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25614},
  pages     = {4884-4892},
  title     = {TOT：Topology-aware optimal transport for multimodal hate detection},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Query-aware quantization for maximum inner product search.
<em>AAAI</em>, 4875–4883. (<a
href="https://doi.org/10.1609/aaai.v37i4.25613">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Maximum Inner Product Search (MIPS) plays an essential role in many applications ranging from information retrieval, recommender systems to natural language processing. However, exhaustive MIPS is often expensive and impractical when there are a large number of candidate items. The state-of-the-art quantization method of approximated MIPS is product quantization with a score-aware loss, developed by assuming that queries are uniformly distributed in the unit sphere. However, in real-world datasets, the above assumption about queries does not necessarily hold. To this end, we propose a quantization method based on the distribution of queries combined with sampled softmax. Further, we introduce a general framework encompassing the proposed method and multiple quantization methods, and we develop an effective optimization for the proposed general framework. The proposed method is evaluated on three real-world datasets. The experimental results show that it outperforms the state-of-the-art baselines.},
  archive   = {C_AAAI},
  author    = {Jin Zhang and Defu Lian and Haodi Zhang and Baoyun Wang and Enhong Chen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25613},
  pages     = {4875-4883},
  title     = {Query-aware quantization for maximum inner product search},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Practical cross-system shilling attacks with limited access
to data. <em>AAAI</em>, 4864–4874. (<a
href="https://doi.org/10.1609/aaai.v37i4.25612">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In shilling attacks, an adversarial party injects a few fake user profiles into a Recommender System (RS) so that the target item can be promoted or demoted. Although much effort has been devoted to developing shilling attack methods, we find that existing approaches are still far from practical. In this paper, we analyze the properties a practical shilling attack method should have and propose a new concept of Cross-system Attack. With the idea of Cross-system Attack, we design a Practical Cross-system Shilling Attack (PC-Attack) framework that requires little information about the victim RS model and the target RS data for conducting attacks. PC-Attack is trained to capture graph topology knowledge from public RS data in a self-supervised manner. Then, it is fine-tuned on a small portion of target data that is easy to access to construct fake profiles. Extensive experiments have demonstrated the superiority of PC-Attack over state-of-the-art baselines. Our implementation of PC-Attack is available at https://github.com/KDEGroup/PC-Attack.},
  archive   = {C_AAAI},
  author    = {Meifang Zeng and Ke Li and Bingchuan Jiang and Liujuan Cao and Hui Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25612},
  pages     = {4864-4874},
  title     = {Practical cross-system shilling attacks with limited access to data},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Untargeted attack against federated recommendation systems
via poisonous item embeddings and the defense. <em>AAAI</em>, 4854–4863.
(<a href="https://doi.org/10.1609/aaai.v37i4.25611">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Federated recommendation (FedRec) can train personalized recommenders without collecting user data, but the decentralized nature makes it susceptible to poisoning attacks. Most previous studies focus on the targeted attack to promote certain items, while the untargeted attack that aims to degrade the overall performance of the FedRec system remains less explored. In fact, untargeted attacks can disrupt the user experience and bring severe ﬁnancial loss to the service provider. However, existing untargeted attack methods are either inapplicable or ineffective against FedRec systems. In this paper, we delve into the untargeted attack and its defense for FedRec systems. (i) We propose ClusterAttack, a novel untargeted attack method. It uploads poisonous gradients that converge the item embeddings into several dense clusters, which make the recommender generate similar scores for these items in the same cluster and perturb the ranking order. (ii) We propose a uniformity-based defense mechanism (UNION) to protect FedRec systems from such attacks. We design a contrastive learning task that regularizes the item embeddings toward a uniform distribution. Then the server ﬁlters out these malicious gradients by estimating the uniformity of updated item embeddings. Experiments on two public datasets show that ClusterAttack can effectively degrade the performance of FedRec systems while circumventing many defense methods, and UNION can improve the resistance of the system against various untargeted attacks, including our ClusterAttack.},
  archive   = {C_AAAI},
  author    = {Yang Yu and Qi Liu and Likang Wu and Runlong Yu and Sanshi Lei Yu and Zaixi Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25611},
  pages     = {4854-4863},
  title     = {Untargeted attack against federated recommendation systems via poisonous item embeddings and the defense},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning to count isomorphisms with graph neural networks.
<em>AAAI</em>, 4845–4853. (<a
href="https://doi.org/10.1609/aaai.v37i4.25610">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Subgraph isomorphism counting is an important problem on graphs, as many graph-based tasks exploit recurring subgraph patterns. Classical methods usually boil down to a backtracking framework that needs to navigate a huge search space with prohibitive computational cost. Some recent studies resort to graph neural networks (GNNs) to learn a low-dimensional representation for both the query and input graphs, in order to predict the number of subgraph isomorphisms on the input graph. However, typical GNNs employ a node-centric message passing scheme that receives and aggregates messages on nodes, which is inadequate in complex structure matching for isomorphism counting. Moreover, on an input graph, the space of possible query graphs is enormous, and different parts of the input graph will be triggered to match different queries. Thus, expecting a fixed representation of the input graph to match diversely structured query graphs is unrealistic. In this paper, we propose a novel GNN called Count-GNN for subgraph isomorphism counting, to deal with the above challenges. At the edge level, given that an edge is an atomic unit of encoding graph structures, we propose an edge-centric message passing scheme, where messages on edges are propagated and aggregated based on the edge adjacency to preserve fine-grained structural information. At the graph level, we modulate the input graph representation conditioned on the query, so that the input graph can be adapted to each query individually to improve their matching. Finally, we conduct extensive experiments on a number of benchmark datasets to demonstrate the superior performance of Count-GNN.},
  archive   = {C_AAAI},
  author    = {Xingtong Yu and Zemin Liu and Yuan Fang and Xinming Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25610},
  pages     = {4845-4853},
  title     = {Learning to count isomorphisms with graph neural networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Predicting temporal sets with simplified fully connected
networks. <em>AAAI</em>, 4835–4844. (<a
href="https://doi.org/10.1609/aaai.v37i4.25609">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Given a sequence of sets, where each set contains an arbitrary number of elements, temporal sets prediction aims to predict which elements will appear in the subsequent set. Existing methods for temporal sets prediction are developed on sophisticated components (e.g., recurrent neural networks, attention or gating mechanisms, and graph neural networks), which inevitably increase the model complexity due to more trainable parameters and higher computational costs. Moreover, the involved nonlinear activation may contribute little or even degrade the performance. In this paper, we present a succinct architecture that is solely built on the Simplified Fully Connected Networks (SFCNs) for temporal sets prediction to bring both effectiveness and efficiency together. In particular, given a user&#39;s sequence of sets, we employ SFCNs to derive representations of the user by learning inter-set temporal dependencies, intra-set element relationships, and intra-embedding channel correlations. Two families of general functions are introduced to preserve the permutation-invariant property of each set and the permutation-equivariant property of elements in each set. Moreover, we design a user representations adaptive fusing module to aggregate user representations according to each element for improving the prediction performance. Experiments on four benchmarks show the superiority of our approach over the state-of-the-art under both transductive and inductive settings. We also theoretically and empirically demonstrate that our model has lower space and time complexity than baselines. Codes and datasets are available at https://github.com/yule-BUAA/SFCNTSP.},
  archive   = {C_AAAI},
  author    = {Le Yu and Zihang Liu and Tongyu Zhu and Leilei Sun and Bowen Du and Weifeng Lv},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25609},
  pages     = {4835-4844},
  title     = {Predicting temporal sets with simplified fully connected networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Next POI recommendation with dynamic graph and explicit
dependency. <em>AAAI</em>, 4827–4834. (<a
href="https://doi.org/10.1609/aaai.v37i4.25608">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Next Point-Of-Interest (POI) recommendation plays an important role in various location-based services. Its main objective is to predict the user&#39;s next interested POI based on her previous check-in information. Most existing methods directly use users&#39; historical check-in trajectories to construct various graphs to assist sequential models to complete this task. However, as users&#39; check-in data is extremely sparse, it is difficult to capture the potential relations between POIs by directly using these check-in data. To this end, we propose the Sequence-based Neighbour search and Prediction Model (SNPM) for next POI recommendation. In SNPM, the RotatE knowledge graph embedding and Eigenmap methods are used to extract POI relationships implied in check-in data, and build the POI similarity graph. Then, we enhance the model&#39;s generalized representations of POIs&#39; general features by aggregating similar POIs. As the context is typically rich and valuable when making Next POI predictions, the sequence model selects which POIs to aggregate not only depends on the current state, but also needs to consider the previous POI sequence. Therefore, we construct a Sequence-based, Dynamic Neighbor Graph (SDNG) to find the similarity neighbourhood and develop a Multi-Step Dependency Prediction model (MSDP) inspired by RotatE, which explicitly leverage information from previous states. We evaluate the proposed model on two real-world datasets, and the experimental results show that the proposed method significantly outperforms existing state-of-the-art POI recommendation methods.},
  archive   = {C_AAAI},
  author    = {Feiyu Yin and Yong Liu and Zhiqi Shen and Lisi Chen and Shuo Shang and Peng Han},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25608},
  pages     = {4827-4834},
  title     = {Next POI recommendation with dynamic graph and explicit dependency},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning from the wisdom of crowds: Exploiting similar
sessions for session search. <em>AAAI</em>, 4818–4826. (<a
href="https://doi.org/10.1609/aaai.v37i4.25607">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Search engines are essential internet services, enabling users to efficiently find the information they need. Session search employs users’ session logs of queries to solve complex retrieval tasks, in which users search multiple times until interested documents are found. Most existing session search models focus on the contextual information within the current search, ignoring the evidence from historical search sessions. Considering the fact that many ongoing retrieval tasks should have already been carried out by other users with a similar intent, we argue that historical sessions with similar intents can help improve the accuracy of the current search task. We propose a novel Similar Session-enhanced Ranking (SSR) model to improve the session search performance using historical sessions with similar intents. Specifically, the candidate historical sessions are matched by query-level and session-level semantic similarity, and then query-level neighbor behaviors are aggregated by a Query-guided GNN (QGNN) while session-level neighbor behaviors are aggregated using the attention mechanism. Finally, we integrate the refined and aggregated historical neighbor information into the current search session. Experimental results on AOL and Tiangong-ST datasets show that our SSR model significantly outperforms the state-of-the-art models.},
  archive   = {C_AAAI},
  author    = {Yuhang Ye and Zhonghua Li and Zhicheng Dou and Yutao Zhu and Changwang Zhang and Shangquan Wu and Zhao Cao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25607},
  pages     = {4818-4826},
  title     = {Learning from the wisdom of crowds: Exploiting similar sessions for session search},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A noise-tolerant differentiable learning approach for single
occurrence regular expression with interleaving. <em>AAAI</em>,
4809–4817. (<a href="https://doi.org/10.1609/aaai.v37i4.25606">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the problem of learning a single occurrence regular expression with interleaving (SOIRE) from a set of text strings possibly with noise. SOIRE fully supports interleaving and covers a large portion of regular expressions used in practice. Learning SOIREs is challenging because it requires heavy computation and text strings usually contain noise in practice. Most of the previous studies only learn restricted SOIREs and are not robust on noisy data. To tackle these issues, we propose a noise-tolerant differentiable learning approach SOIREDL for SOIRE. We design a neural network to simulate SOIRE matching and theoretically prove that certain assignments of the set of parameters learnt by the neural network, called faithful encodings, are one-to-one corresponding to SOIREs for a bounded size. Based on this correspondence, we interpret the target SOIRE from an assignment of the set of parameters of the neural network by exploring the nearest faithful encodings. Experimental results show that SOIREDL outperforms the state-of-the-art approaches, especially on noisy data.},
  archive   = {C_AAAI},
  author    = {Rongzhen Ye and Tianqu Zhuang and Hai Wan and Jianfeng Du and Weilin Luo and Pingjia Liang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25606},
  pages     = {4809-4817},
  title     = {A noise-tolerant differentiable learning approach for single occurrence regular expression with interleaving},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Analogical inference enhanced knowledge graph embedding.
<em>AAAI</em>, 4801–4808. (<a
href="https://doi.org/10.1609/aaai.v37i4.25605">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Knowledge graph embedding (KGE), which maps entities and relations in a knowledge graph into continuous vector spaces, has achieved great success in predicting missing links in knowledge graphs. However, knowledge graphs often contain incomplete triples that are difficult to inductively infer by KGEs. To address this challenge, we resort to analogical inference and propose a novel and general self-supervised framework AnKGE to enhance KGE models with analogical inference capability. We propose an analogical object retriever that retrieves appropriate analogical objects from entity-level, relation-level, and triple-level. And in AnKGE, we train an analogy function for each level of analogical inference with the original element embedding from a well-trained KGE model as input, which outputs the analogical object embedding. In order to combine inductive inference capability from the original KGE model and analogical inference capability enhanced by AnKGE, we interpolate the analogy score with the base model score and introduce the adaptive weights in the score function for prediction. Through extensive experiments on FB15k-237 and WN18RR datasets, we show that AnKGE achieves competitive results on link prediction task and well performs analogical inference.},
  archive   = {C_AAAI},
  author    = {Zhen Yao and Wen Zhang and Mingyang Chen and Yufeng Huang and Yi Yang and Huajun Chen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25605},
  pages     = {4801-4808},
  title     = {Analogical inference enhanced knowledge graph embedding},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). One-for-all: Proposal masked cross-class anomaly detection.
<em>AAAI</em>, 4792–4800. (<a
href="https://doi.org/10.1609/aaai.v37i4.25604">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {One of the most challenges for anomaly detection (AD) is how to learn one unified and generalizable model to adapt to multi-class especially cross-class settings: the model is trained with normal samples from seen classes with the objective to detect anomalies from both seen and unseen classes. In this work, we propose a novel Proposal Masked Anomaly Detection (PMAD) approach for such challenging multi- and cross-class anomaly detection. The proposed PMAD can be adapted to seen and unseen classes by two key designs: MAE-based patch-level reconstruction and prototype-guided proposal masking. First, motivated by MAE (Masked AutoEncoder), we develop a patch-level reconstruction model rather than the image-level reconstruction adopted in most AD methods for this reason: the masked patches in unseen classes can be reconstructed well by using the visible patches and the adaptive reconstruction capability of MAE. Moreover, we improve MAE by ViT encoder-decoder architecture, combinational masking, and visual tokens as reconstruction objectives to make it more suitable for anomaly detection. Second, we develop a two-stage anomaly detection manner during inference. In the proposal masking stage, the prototype-guided proposal masking module is utilized to generate proposals for suspicious anomalies as much as possible, then masked patches can be generated from the proposal regions. By masking most likely anomalous patches, the “shortcut reconstruction” issue (i.e., anomalous regions can be well reconstructed) can be mostly avoided. In the reconstruction stage, these masked patches are then reconstructed by the trained patch-level reconstruction model to determine if they are anomalies. Extensive experiments show that the proposed PMAD can outperform current state-of-the-art models significantly under the multi- and especially cross-class settings. Code will be publicly available at https://github.com/xcyao00/PMAD.},
  archive   = {C_AAAI},
  author    = {Xincheng Yao and Chongyang Zhang and Ruoqi Li and Jun Sun and Zhenyu Liu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25604},
  pages     = {4792-4800},
  title     = {One-for-all: Proposal masked cross-class anomaly detection},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unsupervised legal evidence retrieval via contrastive
learning with approximate aggregated positive. <em>AAAI</em>, 4783–4791.
(<a href="https://doi.org/10.1609/aaai.v37i4.25603">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Verifying the facts alleged by the prosecutors before the trial requires the judges to retrieve evidence within the massive materials accompanied. Existing Legal AI applications often assume the facts are already determined and fail to notice the difficulty of reconstructing them. To build a practical Legal AI application and free the judges from the manually searching work, we introduce the task of Legal Evidence Retrieval, which aims at automatically retrieving the precise fact-related verbal evidence within a single case. We formulate the task in a dense retrieval paradigm, and jointly learn the constrastive representations and alignments between facts and evidence. To get rid of the tedious annotations, we construct an approximated positive vector for a given fact by aggregating a set of evidence from the same case. An entropy-based denoise technique is further applied to mitigate the impact of false positive samples. We train our models on tens of thousands of unlabeled cases and evaluate them on a labeled dataset containing 919 cases and 4,336 queries. Experimental results indicate that our approach is effective and outperforms other state-of-the-art representation and retrieval models. The dataset and code are available at https://github.com/yaof20/LER.},
  archive   = {C_AAAI},
  author    = {Feng Yao and Jingyuan Zhang and Yating Zhang and Xiaozhong Liu and Changlong Sun and Yun Liu and Weixing Shen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25603},
  pages     = {4783-4791},
  title     = {Unsupervised legal evidence retrieval via contrastive learning with approximate aggregated positive},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SCI: A spectrum concentrated implicit neural compression for
biomedical data. <em>AAAI</em>, 4774–4782. (<a
href="https://doi.org/10.1609/aaai.v37i4.25602">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Massive collection and explosive growth of biomedical data, demands effective compression for efficient storage, transmission and sharing. Readily available visual data compression techniques have been studied extensively but tailored for natural images/videos, and thus show limited performance on biomedical data which are of different features and larger diversity. Emerging implicit neural representation (INR) is gaining momentum and demonstrates high promise for fitting diverse visual data in target-data-specific manner, but a general compression scheme covering diverse biomedical data is so far absent. To address this issue, we firstly derive a mathematical explanation for INR&#39;s spectrum concentration property and an analytical insight on the design of INR based compressor. Further, we propose a Spectrum Concentrated Implicit neural compression (SCI) which adaptively partitions the complex biomedical data into blocks matching INR&#39;s concentrated spectrum envelop, and design a funnel shaped neural network capable of representing each block with a small number of parameters. Based on this design, we conduct compression via optimization under given budget and allocate the available parameters with high representation accuracy. The experiments show SCI&#39;s superior performance to state-of-the-art methods including commercial compressors, data-driven ones, and INR based counterparts on diverse biomedical data. The source code can be found at https://github.com/RichealYoung/ImplicitNeuralCompression.git.},
  archive   = {C_AAAI},
  author    = {Runzhao Yang and Tingxiong Xiao and Yuxiao Cheng and Qianni Cao and Jinyuan Qu and Jinli Suo and Qionghai Dai},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25602},
  pages     = {4774-4782},
  title     = {SCI: A spectrum concentrated implicit neural compression for biomedical data},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Temporal knowledge graph reasoning with historical
contrastive learning. <em>AAAI</em>, 4765–4773. (<a
href="https://doi.org/10.1609/aaai.v37i4.25601">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Temporal knowledge graph, serving as an effective way to store and model dynamic relations, shows promising prospects in event forecasting. However, most temporal knowledge graph reasoning methods are highly dependent on the recurrence or periodicity of events, which brings challenges to inferring future events related to entities that lack historical interaction. In fact, the current moment is often the combined effect of a small part of historical information and those unobserved underlying factors. To this end, we propose a new event forecasting model called Contrastive Event Network (CENET), based on a novel training framework of historical contrastive learning. CENET learns both the historical and non-historical dependency to distinguish the most potential entities that can best match the given query. Simultaneously, it trains representations of queries to investigate whether the current moment depends more on historical or non-historical events by launching contrastive learning. The representations further help train a binary classifier whose output is a boolean mask to indicate related entities in the search space. During the inference process, CENET employs a mask-based strategy to generate the final results. We evaluate our proposed model on five benchmark graphs. The results demonstrate that CENET significantly outperforms all existing methods in most metrics, achieving at least 8.3\% relative improvement of Hits@1 over previous state-of-the-art baselines on event-based datasets.},
  archive   = {C_AAAI},
  author    = {Yi Xu and Junjie Ou and Hui Xu and Luoyi Fu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25601},
  pages     = {4765-4773},
  title     = {Temporal knowledge graph reasoning with historical contrastive learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Knowledge graph embedding by normalizing flows.
<em>AAAI</em>, 4756–4764. (<a
href="https://doi.org/10.1609/aaai.v37i4.25600">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A key to knowledge graph embedding (KGE) is to choose a proper representation space, e.g., point-wise Euclidean space and complex vector space. In this paper, we propose a unified perspective of embedding and introduce uncertainty into KGE from the view of group theory. Our model can incorporate existing models (i.e., generality), ensure the computation is tractable (i.e., efficiency) and enjoy the expressive power of complex random variables (i.e., expressiveness). The core idea is that we embed entities/relations as elements of a symmetric group, i.e., permutations of a set. Permutations of different sets can reflect different properties of embedding. And the group operation of symmetric groups is easy to compute. In specific, we show that the embedding of many existing models, point vectors, can be seen as elements of a symmetric group. To reflect uncertainty, we first embed entities/relations as permutations of a set of random variables. A permutation can transform a simple random variable into a complex random variable for greater expressiveness, called a normalizing flow. We then define scoring functions by measuring the similarity of two normalizing flows, namely NFE. We construct several instantiating models and prove that they are able to learn logical rules. Experimental results demonstrate the effectiveness of introducing uncertainty and our model. The code is available at https://github.com/changyi7231/NFE.},
  archive   = {C_AAAI},
  author    = {Changyi Xiao and Xiangnan He and Yixin Cao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25600},
  pages     = {4756-4764},
  title     = {Knowledge graph embedding by normalizing flows},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Jointly imputing multi-view data with optimal transport.
<em>AAAI</em>, 4747–4755. (<a
href="https://doi.org/10.1609/aaai.v37i4.25599">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The multi-view data with incomplete information hinder the effective data analysis. Existing multi-view imputation methods that learn the mapping between complete view and completely missing view are not able to deal with the common multi-view data with missing feature information. In this paper, we propose a generative imputation model named Git with optimal transport theory to jointly impute the missing features/values, conditional on all observed values from the multi-view data. Git consists of two modules, i.e., a multi-view joint generator (MJG) and a masking energy discriminator (MED). The generator MJG incorporates a joint autoencoder with the multiple imputation rule to learn the data distribution from all observed multi-view data. The discriminator MED leverages a new masking energy divergence function to make Git differentiable for imputation enhancement. Extensive experiments on several real-world multi-view data sets demonstrate that, Git yields over 35\% accuracy gain, compared to the state-of-the-art approaches.},
  archive   = {C_AAAI},
  author    = {Yangyang Wu and Xiaoye Miao and Xinyu Huang and Jianwei Yin},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25599},
  pages     = {4747-4755},
  title     = {Jointly imputing multi-view data with optimal transport},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ConTextual masked auto-encoder for dense passage retrieval.
<em>AAAI</em>, 4738–4746. (<a
href="https://doi.org/10.1609/aaai.v37i4.25598">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Dense passage retrieval aims to retrieve the relevant passages of a query from a large corpus based on dense representations (i.e., vectors) of the query and the passages. Recent studies have explored improving pre-trained language models to boost dense retrieval performance. This paper proposes CoT-MAE (ConTextual Masked Auto-Encoder), a simple yet effective generative pre-training method for dense passage retrieval. CoT-MAE employs an asymmetric encoder-decoder architecture that learns to compress the sentence semantics into a dense vector through self-supervised and context-supervised masked auto-encoding. Precisely, self-supervised masked auto-encoding learns to model the semantics of the tokens inside a text span, and context-supervised masked auto-encoding learns to model the semantical correlation between the text spans. We conduct experiments on large-scale passage retrieval benchmarks and show considerable improvements over strong baselines, demonstrating the high efficiency of CoT-MAE. Our code is available at https://github.com/caskcsg/ir/tree/main/cotmae.},
  archive   = {C_AAAI},
  author    = {Xing Wu and Guangyuan Ma and Meng Lin and Zijia Lin and Zhongyuan Wang and Songlin Hu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25598},
  pages     = {4738-4746},
  title     = {ConTextual masked auto-encoder for dense passage retrieval},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Few-shot composition learning for image retrieval with
prompt tuning. <em>AAAI</em>, 4729–4737. (<a
href="https://doi.org/10.1609/aaai.v37i4.25597">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the problem of composition learning for image retrieval, for which we learn to retrieve target images with search queries in the form of a composition of a reference image and a modification text that describes desired modifications of the image. Existing models of composition learning for image retrieval are generally built with large-scale datasets, demanding extensive training samples, i.e., query-target pairs, as supervision, which restricts their application for the scenario of few-shot learning with only few query-target pairs available. Recently, prompt tuning with frozen pretrained language models has shown remarkable performance when the amount of training data is limited. Inspired by this, we propose a prompt tuning mechanism with the pretrained CLIP model for the task of few-shot composition learning for image retrieval. Specifically, we regard the representation of the reference image as a trainable visual prompt, prefixed to the embedding of the text sequence. One challenge is to efficiently train visual prompt with few-shot samples. To deal with this issue, we further propose a self-upervised auxiliary task via ensuring that the reference image can retrieve itself when no modification information is given from the text, which facilitates training for the visual prompt, while not requiring additional annotations for query-target pairs. Experiments on multiple benchmarks show that our proposed model can yield superior performance when trained with only few query-target pairs.},
  archive   = {C_AAAI},
  author    = {Junda Wu and Rui Wang and Handong Zhao and Ruiyi Zhang and Chaochao Lu and Shuai Li and Ricardo Henao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25597},
  pages     = {4729-4737},
  title     = {Few-shot composition learning for image retrieval with prompt tuning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Online semi-supervised learning with mix-typed streaming
features. <em>AAAI</em>, 4720–4728. (<a
href="https://doi.org/10.1609/aaai.v37i4.25596">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Online learning with feature spaces that are not fixed but can vary over time renders a seemingly flexible learning paradigm thus has drawn much attention. Unfortunately, two restrictions prohibit a ubiquitous application of this learning paradigm in practice. First, whereas prior studies mainly assume a homogenous feature type, data streams generated from real applications can be heterogeneous in which Boolean, ordinal, and continuous co-exist. Existing methods that prescribe parametric distributions such as Gaussians would not suffice to model the correlation among such mixtyped features. Second, while full supervision seems to be a default setup, providing labels to all arriving data instances over a long time span is tangibly onerous, laborious, and economically unsustainable. Alas, a semi-supervised online learner that can deal with mix-typed, varying feature spaces is still missing. To fill the gap, this paper explores a novel problem, named Online Semi-supervised Learning with Mixtyped streaming Features (OSLMF), which strives to relax the restrictions on the feature type and supervision information. Our key idea to solve the new problem is to leverage copula model to align the data instances with different feature spaces so as to make their distance measurable. A geometric structure underlying data instances is then established in an online fashion based on their distances, through which the limited labeling information is propagated, from the scarce labeled instances to their close neighbors. Experimental results are documented to evidence the viability and effectiveness of our proposed approach. Code is released in https://github.com/wudi1989/OSLMF.},
  archive   = {C_AAAI},
  author    = {Di Wu and Shengda Zhuo and Yu Wang and Zhong Chen and Yi He},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25596},
  pages     = {4720-4728},
  title     = {Online semi-supervised learning with mix-typed streaming features},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Structure aware incremental learning with personalized
imitation weights for recommender systems. <em>AAAI</em>, 4711–4719. (<a
href="https://doi.org/10.1609/aaai.v37i4.25595">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recommender systems now consume large-scale data and play a significant role in improving user experience. Graph Neural Networks (GNNs) have emerged as one of the most effective recommender system models because they model the rich relational information. The ever-growing volume of data can make training GNNs prohibitively expensive. To address this, previous attempts propose to train the GNN models incrementally as new data blocks arrive. Feature and structure knowledge distillation techniques have been explored to allow the GNN model to train in a fast incremental fashion while alleviating the catastrophic forgetting problem. However, preserving the same amount of the historical information for all users is sub-optimal since it fails to take into account the dynamics of each user&#39;s change of preferences. For the users whose interests shift substantially, retaining too much of the old knowledge can overly constrain the model, preventing it from quickly adapting to the users’ novel interests. In contrast, for users who have static preferences, model performance can benefit greatly from preserving as much of the user&#39;s long-term preferences as possible. In this work, we propose a novel training strategy that adaptively learns personalized imitation weights for each user to balance the contribution from the recent data and the amount of knowledge to be distilled from previous time periods. We demonstrate the effectiveness of learning imitation weights via a comparison on five diverse datasets for three state-of-art structure distillation based recommender systems. The performance shows consistent improvement over competitive incremental learning techniques.},
  archive   = {C_AAAI},
  author    = {Yuening Wang and Yingxue Zhang and Antonios Valkanas and Ruiming Tang and Chen Ma and Jianye Hao and Mark Coates},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25595},
  pages     = {4711-4719},
  title     = {Structure aware incremental learning with personalized imitation weights for recommender systems},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Augmenting affective dependency graph via iterative
incongruity graph learning for sarcasm detection. <em>AAAI</em>,
4702–4710. (<a href="https://doi.org/10.1609/aaai.v37i4.25594">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, progress has been made towards improving automatic sarcasm detection in computer science. Among existing models, manually constructing static graphs for texts and then using graph neural networks (GNNs) is one of the most effective approaches for drawing long-range incongruity patterns. However, the manually constructed graph structure might be prone to errors (e.g., noisy or incomplete) and not optimal for the sarcasm detection task. Errors produced during the graph construction step cannot be remedied and may accrue to the following stages, resulting in poor performance. To surmount the above limitations, we explore a novel Iterative Augmenting Affective Graph and Dependency Graph (IAAD) framework to jointly and iteratively learn the incongruity graph structure. IAAD can alternatively update the incongruity graph structure and node representation until the learning graph structure is optimal for the metrics of sarcasm detection. More concretely, we begin with deriving an affective and a dependency graph for each instance, then an iterative incongruity graph learning module is employed to augment affective and dependency graphs for obtaining the optimal inconsistent semantic graph with the goal of optimizing the graph for the sarcasm detection task. Extensive experiments on three datasets demonstrate that the proposed model outperforms state-of-the-art baselines for sarcasm detection with significant margins.},
  archive   = {C_AAAI},
  author    = {Xiaobao Wang and Yiqi Dong and Di Jin and Yawen Li and Longbiao Wang and Jianwu Dang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25594},
  pages     = {4702-4710},
  title     = {Augmenting affective dependency graph via iterative incongruity graph learning for sarcasm detection},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Beyond graph convolutional network: An interpretable
regularizer-centered optimization framework. <em>AAAI</em>, 4693–4701.
(<a href="https://doi.org/10.1609/aaai.v37i4.25593">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph convolutional networks (GCNs) have been attracting widespread attentions due to their encouraging performance and powerful generalizations. However, few work provide a general view to interpret various GCNs and guide GCNs&#39; designs. In this paper, by revisiting the original GCN, we induce an interpretable regularizer-centerd optimization framework, in which by building appropriate regularizers we can interpret most GCNs, such as APPNP, JKNet, DAGNN, and GNN-LF/HF. Further, under the proposed framework, we devise a dual-regularizer graph convolutional network (dubbed tsGCN) to capture topological and semantic structures from graph data. Since the derived learning rule for tsGCN contains an inverse of a large matrix and thus is time-consuming, we leverage the Woodbury matrix identity and low-rank approximation tricks to successfully decrease the high computational complexity of computing infinite-order graph convolutions. Extensive experiments on eight public datasets demonstrate that tsGCN achieves superior performance against quite a few state-of-the-art competitors w.r.t. classification tasks.},
  archive   = {C_AAAI},
  author    = {Shiping Wang and Zhihao Wu and Yuhong Chen and Yong Chen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25593},
  pages     = {4693-4701},
  title     = {Beyond graph convolutional network: An interpretable regularizer-centered optimization framework},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). WSiP: Wave superposition inspired pooling for dynamic
interactions-aware trajectory prediction. <em>AAAI</em>, 4685–4692. (<a
href="https://doi.org/10.1609/aaai.v37i4.25592">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Predicting motions of surrounding vehicles is critically important to help autonomous driving systems plan a safe path and avoid collisions. Although recent social pooling based LSTM models have achieved significant performance gains by considering the motion interactions between vehicles close to each other, vehicle trajectory prediction still remains as a challenging research issue due to the dynamic and high-order interactions in the real complex driving scenarios. To this end, we propose a wave superposition inspired social pooling (Wave-pooling for short) method for dynamically aggregating the high-order interactions from both local and global neighbor vehicles. Through modeling each vehicle as a wave with the amplitude and phase, Wave-pooling can more effectively represent the dynamic motion states of vehicles and capture their high-order dynamic interactions by wave superposition. By integrating Wave-pooling, an encoder-decoder based learning framework named WSiP is also proposed. Extensive experiments conducted on two public highway datasets NGSIM and highD verify the effectiveness of WSiP by comparison with current state-of-the-art baselines. More importantly, the result of WSiP is more interpretable as the interaction strength between vehicles can be intuitively reflected by their phase difference. The code of the work is publicly available at https://github.com/Chopin0123/WSiP.},
  archive   = {C_AAAI},
  author    = {Renzhi Wang and Senzhang Wang and Hao Yan and Xiang Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25592},
  pages     = {4685-4692},
  title     = {WSiP: Wave superposition inspired pooling for dynamic interactions-aware trajectory prediction},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cross-domain graph anomaly detection via anomaly-aware
contrastive alignment. <em>AAAI</em>, 4676–4684. (<a
href="https://doi.org/10.1609/aaai.v37i4.25591">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Cross-domain graph anomaly detection (CD-GAD) describes the problem of detecting anomalous nodes in an unlabelled target graph using auxiliary, related source graphs with labelled anomalous and normal nodes. Although it presents a promising approach to address the notoriously high false positive issue in anomaly detection, little work has been done in this line of research. There are numerous domain adaptation methods in the literature, but it is difficult to adapt them for GAD due to the unknown distributions of the anomalies and the complex node relations embedded in graph data. To this end, we introduce a novel domain adaptation approach, namely Anomaly-aware Contrastive alignmenT (ACT), for GAD. ACT is designed to jointly optimise: (i) unsupervised contrastive learning of normal representations of nodes in the target graph, and (ii) anomaly-aware one-class alignment that aligns these contrastive node representations and the representations of labelled normal nodes in the source graph, while enforcing significant deviation of the representations of the normal nodes from the labelled anomalous nodes in the source graph. In doing so, ACT effectively transfers anomaly-informed knowledge from the source graph to learn the complex node relations of the normal class for GAD on the target graph without any specification of the anomaly distributions. Extensive experiments on eight CD-GAD settings demonstrate that our approach ACT achieves substantially improved detection performance over 10 state-of-the-art GAD methods. Code is available at https://github.com/QZ-WANG/ACT.},
  archive   = {C_AAAI},
  author    = {Qizhou Wang and Guansong Pang and Mahsa Salehi and Wray Buntine and Christopher Leckie},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25591},
  pages     = {4676-4684},
  title     = {Cross-domain graph anomaly detection via anomaly-aware contrastive alignment},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Easy begun is half done: Spatial-temporal graph modeling
with ST-curriculum dropout. <em>AAAI</em>, 4668–4675. (<a
href="https://doi.org/10.1609/aaai.v37i4.25590">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Spatial-temporal (ST) graph modeling, such as traffic speed forecasting and taxi demand prediction, is an important task in deep learning area. However, for the nodes in the graph, their ST patterns can vary greatly in difficulties for modeling, owning to the heterogeneous nature of ST data. We argue that unveiling the nodes to the model in a meaningful order, from easy to complex, can provide performance improvements over traditional training procedure. The idea has its root in Curriculum Learning, which suggests in the early stage of training models can be sensitive to noise and difficult samples. In this paper, we propose ST-Curriculum Dropout, a novel and easy-to-implement strategy for spatial-temporal graph modeling. Specifically, we evaluate the learning difficulty of each node in high-level feature space and drop those difficult ones out to ensure the model only needs to handle fundamental ST relations at the beginning, before gradually moving to hard ones. Our strategy can be applied to any canonical deep learning architecture without extra trainable parameters, and extensive experiments on a wide range of datasets are conducted to illustrate that, by controlling the difficulty level of ST relations as the training progresses, the model is able to capture better representation of the data and thus yields better generalization.},
  archive   = {C_AAAI},
  author    = {Hongjun Wang and Jiyuan Chen and Tong Pan and Zipei Fan and Xuan Song and Renhe Jiang and Lingyu Zhang and Yi Xie and Zhongyi Wang and Boyuan Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25590},
  pages     = {4668-4675},
  title     = {Easy begun is half done: Spatial-temporal graph modeling with ST-curriculum dropout},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Human-instructed deep hierarchical generative learning for
automated urban planning. <em>AAAI</em>, 4660–4667. (<a
href="https://doi.org/10.1609/aaai.v37i4.25589">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The essential task of urban planning is to generate the optimal land-use configuration of a target area. However, traditional urban planning is time-consuming and labor-intensive. Deep generative learning gives us hope that we can automate this planning process and come up with the ideal urban plans. While remarkable achievements have been obtained, they have exhibited limitations in lacking awareness of: 1) the hierarchical dependencies between functional zones and spatial grids; 2) the peer dependencies among functional zones; and 3) human regulations to ensure the usability of generated configurations. To address these limitations, we develop a novel human-instructed deep hierarchical generative model. We rethink the urban planning generative task from a unique functionality perspective, where we summarize planning requirements into different functionality projections for better urban plan generation. To this end, we develop a three-stage generation process from a target area to zones to grids. The first stage is to label the grids of a target area with latent functionalities to discover functional zones. The second stage is to perceive the planning requirements to form urban functionality projections. We propose a novel module: functionalizer to project the embedding of human instructions and geospatial contexts to the zone-level plan to obtain such projections. Each projection includes the information of land-use portfolios and the structural dependencies across spatial grids in terms of a specific urban function. The third stage is to leverage multi-attentions to model the zone-zone peer dependencies of the functionality projections to generate grid-level land-use configurations. Finally, we present extensive experiments to demonstrate the effectiveness of our framework.},
  archive   = {C_AAAI},
  author    = {Dongjie Wang and Lingfei Wu and Denghui Zhang and Jingbo Zhou and Leilei Sun and Yanjie Fu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25589},
  pages     = {4660-4667},
  title     = {Human-instructed deep hierarchical generative learning for automated urban planning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Efficient embeddings of logical variables for query
answering over incomplete knowledge graphs. <em>AAAI</em>, 4652–4659.
(<a href="https://doi.org/10.1609/aaai.v37i4.25588">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The problem of answering complex First-order Logic queries over incomplete knowledge graphs is receiving growing attention in the literature. A promising recent approach to this problem has been to exploit neural link predictors, which can be effective in identifying individual missing triples in the incomplete graph, in order to efficiently answer complex queries. A crucial advantage of this approach over other methods is that it does not require example answers to complex queries for training, as it relies only on the availability of a trained link predictor for the knowledge graph at hand. This approach, however, can be computationally expensive during inference, and cannot deal with queries involving negation. In this paper, we propose a novel approach that addresses all of these limitations. Experiments on established benchmark datasets demonstrate that our approach offers superior performance while significantly reducing inference times.},
  archive   = {C_AAAI},
  author    = {Dingmin Wang and Yeyuan Chen and Bernardo Cuenca Grau},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25588},
  pages     = {4652-4659},
  title     = {Efficient embeddings of logical variables for query answering over incomplete knowledge graphs},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-organization preserved graph structure learning with
principle of relevant information. <em>AAAI</em>, 4643–4651. (<a
href="https://doi.org/10.1609/aaai.v37i4.25587">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Most Graph Neural Networks follow the message-passing paradigm, assuming the observed structure depicts the ground-truth node relationships. However, this fundamental assumption cannot always be satisfied, as real-world graphs are always incomplete, noisy, or redundant. How to reveal the inherent graph structure in a unified way remains under-explored. We proposed PRI-GSL, a Graph Structure Learning framework guided by the Principle of Relevant Information, providing a simple and unified framework for identifying the self-organization and revealing the hidden structure. PRI-GSL learns a structure that contains the most relevant yet least redundant information quantified by von Neumann entropy and Quantum Jensen Shannon divergence. PRI-GSL incorporates the evolution of quantum continuous walk with graph wavelets to encode node structural roles, showing in which way the nodes interplay and self-organize with the graph structure. Extensive experiments demonstrate the superior effectiveness and robustness of PRI-GSL.},
  archive   = {C_AAAI},
  author    = {Qingyun Sun and Jianxin Li and Beining Yang and Xingcheng Fu and Hao Peng and Philip S. Yu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25587},
  pages     = {4643-4651},
  title     = {Self-organization preserved graph structure learning with principle of relevant information},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-supervised continual graph learning in adaptive
riemannian spaces. <em>AAAI</em>, 4633–4642. (<a
href="https://doi.org/10.1609/aaai.v37i4.25586">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Continual graph learning routinely finds its role in a variety of real-world applications where the graph data with different tasks come sequentially. Despite the success of prior works, it still faces great challenges. On the one hand, existing methods work with the zero-curvature Euclidean space, and largely ignore the fact that curvature varies over the com- ing graph sequence. On the other hand, continual learners in the literature rely on abundant labels, but labeling graph in practice is particularly hard especially for the continuously emerging graphs on-the-fly. To address the aforementioned challenges, we propose to explore a challenging yet practical problem, the self-supervised continual graph learning in adaptive Riemannian spaces. In this paper, we propose a novel self-supervised Riemannian Graph Continual Learner (RieGrace). In RieGrace, we first design an Adaptive Riemannian GCN (AdaRGCN), a unified GCN coupled with a neural curvature adapter, so that Riemannian space is shaped by the learnt curvature adaptive to each graph. Then, we present a Label-free Lorentz Distillation approach, in which we create teacher-student AdaRGCN for the graph sequence. The student successively performs intra-distillation from itself and inter-distillation from the teacher so as to consolidate knowledge without catastrophic forgetting. In particular, we propose a theoretically grounded Generalized Lorentz Projection for the contrastive distillation in Riemannian space. Extensive experiments on the benchmark datasets show the superiority of RieGrace, and additionally, we investigate on how curvature changes over the graph sequence.},
  archive   = {C_AAAI},
  author    = {Li Sun and Junda Ye and Hao Peng and Feiyang Wang and Philip S. Yu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25586},
  pages     = {4633-4642},
  title     = {Self-supervised continual graph learning in adaptive riemannian spaces},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Opinion optimization in directed social networks.
<em>AAAI</em>, 4623–4632. (<a
href="https://doi.org/10.1609/aaai.v37i4.25585">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Shifting social opinions has far-reaching implications in various aspects, such as public health campaigns, product marketing, and political candidates. In this paper, we study a problem of opinion optimization based on the popular Friedkin-Johnsen (FJ) model for opinion dynamics in an unweighted directed social network with n nodes and m edges. In the FJ model, the internal opinion of every node lies in the closed interval [0, 1], with 0 and 1 being polar opposites of opinions about a certain issue. Concretely, we focus on the problem of selecting a small number of k},
  archive   = {C_AAAI},
  author    = {Haoxin Sun and Zhongzhi Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25585},
  pages     = {4623-4632},
  title     = {Opinion optimization in directed social networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-supervised interest transfer network via prototypical
contrastive learning for recommendation. <em>AAAI</em>, 4614–4622. (<a
href="https://doi.org/10.1609/aaai.v37i4.25584">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Cross-domain recommendation has attracted increasing attention from industry and academia recently. However, most existing methods do not exploit the interest invariance between domains, which would yield sub-optimal solutions. In this paper, we propose a cross-domain recommendation method: Self-supervised Interest Transfer Network (SITN), which can effectively transfer invariant knowledge between domains via prototypical contrastive learning. Specifically, we perform two levels of cross-domain contrastive learning: 1) instance-to-instance contrastive learning, 2) instance-to-cluster contrastive learning. Not only that, we also take into account users&#39; multi-granularity and multi-view interests. With this paradigm, SITN can explicitly learn the invariant knowledge of interest clusters between domains and accurately capture users&#39; intents and preferences. We conducted extensive experiments on a public dataset and a large-scale industrial dataset collected from one of the world&#39;s leading e-commerce corporations. The experimental results indicate that SITN achieves significant improvements over state-of-the-art recommendation methods. Additionally, SITN has been deployed on a micro-video recommendation platform, and the online A/B testing results further demonstrate its practical value. Supplement is available at: https://github.com/fanqieCoffee/SITN-Supplement.},
  archive   = {C_AAAI},
  author    = {Guoqiang Sun and Yibin Shen and Sijin Zhou and Xiang Chen and Hongyan Liu and Chunming Wu and Chenyi Lei and Xianhui Wei and Fei Fang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25584},
  pages     = {4614-4622},
  title     = {Self-supervised interest transfer network via prototypical contrastive learning for recommendation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cross-domain adaptative learning for online advertisement
customer lifetime value prediction. <em>AAAI</em>, 4605–4613. (<a
href="https://doi.org/10.1609/aaai.v37i4.25583">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Accurate estimation of customer lifetime value (LTV), which reflects the potential consumption of a user over a period of time, is crucial for the revenue management of online advertising platforms. However, predicting LTV in real-world applications is not an easy task since the user consumption data is usually insufficient within a specific domain. To tackle this problem, we propose a novel cross-domain adaptative framework (CDAF) to leverage consumption data from different domains. The proposed method is able to simultaneously mitigate the data scarce problem and the distribution gap problem caused by data from different domains. To be specific, our method firstly learns a LTV prediction model from a different but related platform with sufficient data provision. Subsequently, we exploit domain-invariant information to mitigate data scarce problem by minimizing the Wasserstein discrepancy between the encoded user representations of two domains. In addition, we design a dual-predictor schema which not only enhances domain-invariant information in the semantic space but also preserves domain-specific information for accurate target prediction. The proposed framework is evaluated on five datasets collected from real historical data on the advertising platform of Tencent Games. Experimental results verify that the proposed framework is able to significantly improve the LTV prediction performance on this platform. For instance, our method can boost DCNv2 with the improvement of 13.7\% in terms of AUC on dataset G2. Code: https://github.com/TL-UESTC/CDAF.},
  archive   = {C_AAAI},
  author    = {Hongzu Su and Zhekai Du and Jingjing Li and Lei Zhu and Ke Lu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25583},
  pages     = {4605-4613},
  title     = {Cross-domain adaptative learning for online advertisement customer lifetime value prediction},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Scaling law for recommendation models: Towards
general-purpose user representations. <em>AAAI</em>, 4596–4604. (<a
href="https://doi.org/10.1609/aaai.v37i4.25582">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent advancement of large-scale pretrained models such as BERT, GPT-3, CLIP, and Gopher, has shown astonishing achievements across various task domains. Unlike vision recognition and language models, studies on general-purpose user representation at scale still remain underexplored. Here we explore the possibility of general-purpose user representation learning by training a universal user encoder at large scales. We demonstrate that the scaling law is present in user representation learning areas, where the training error scales as a power-law with the amount of computation. Our Contrastive Learning User Encoder (CLUE), optimizes task-agnostic objectives, and the resulting user embeddings stretch our expectation of what is possible to do in various downstream tasks. CLUE also shows great transferability to other domains and companies, as performances on an online experiment shows significant improvements in Click-Through-Rate (CTR). Furthermore, we also investigate how the model performance is influenced by the scale factors, such as training data size, model capacity, sequence length, and batch size. Finally, we discuss the broader impacts of CLUE in general.},
  archive   = {C_AAAI},
  author    = {Kyuyong Shin and Hanock Kwak and Su Young Kim and Max Nihlén Ramström and Jisu Jeong and Jung-Woo Ha and Kyung-Min Kim},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25582},
  pages     = {4596-4604},
  title     = {Scaling law for recommendation models: Towards general-purpose user representations},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Online random feature forests for learning in varying
feature spaces. <em>AAAI</em>, 4587–4595. (<a
href="https://doi.org/10.1609/aaai.v37i4.25581">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we propose a new online learning algorithm tailored for data streams described by varying feature spaces (VFS), wherein new features constantly emerge and old features may stop to be observed over various time spans. Our proposed algorithm, named Online Random Feature Forests for Feature space Variabilities (ORF3V), provides a strategy to respect such feature dynamics by generating, updating, pruning, as well as online re-weighing an ensemble of what we call feature forests, which are generated and updated based on a compressed and storage efficient representation for each observed feature. We benchmark our algorithm on 12 datasets, including one novel real-world dataset of government COVID-19 responses collected through a crowd-sensing program in Spain. The empirical results substantiate the viability and effectiveness of our ORF3V algorithm and its superior accuracy performance over the state-of-the-art rival models.},
  archive   = {C_AAAI},
  author    = {Christian Schreckenberger and Yi He and Stefan Lüdtke and Christian Bartelt and Heiner Stuckenschmidt},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25581},
  pages     = {4587-4595},
  title     = {Online random feature forests for learning in varying feature spaces},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Graph structure learning on user mobility data for social
relationship inference. <em>AAAI</em>, 4578–4586. (<a
href="https://doi.org/10.1609/aaai.v37i4.25580">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With the prevalence of smart mobile devices and location-based services, uncovering social relationships from human mobility data is of great value in real-world spatio-temporal applications ranging from friend recommendation, advertisement targeting to transportation scheduling. While a handful of sophisticated graph embedding techniques are developed for social relationship inference, they are significantly limited to the sparse and noisy nature of user mobility data, as they all ignore the essential problem of the existence of a large amount of noisy data unrelated to social activities in such mobility data. In this work, we present Social Relationship Inference Network (SRINet), a novel Graph Neural Network (GNN) framework, to improve inference performance by learning to remove noisy data. Specifically, we first construct a multiplex user meeting graph to model the spatial-temporal interactions among users in different semantic contexts. Our proposed SRINet tactfully combines the representation learning ability of Graph Convolutional Networks (GCNs) with the power of removing noisy edges of graph structure learning, which can learn effective user embeddings on the multiplex user meeting graph in a semi-supervised manner. Extensive experiments on three real-world datasets demonstrate the superiority of SRINet against state-of-the-art techniques in inferring social relationships from user mobility data. The source code of our method is available at https://github.com/qinguangming1999/SRINet.},
  archive   = {C_AAAI},
  author    = {Guangming Qin and Lexue Song and Yanwei Yu and Chao Huang and Wenzhe Jia and Yuan Cao and Junyu Dong},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25580},
  pages     = {4578-4586},
  title     = {Graph structure learning on user mobility data for social relationship inference},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Logic and commonsense-guided temporal knowledge graph
completion. <em>AAAI</em>, 4569–4577. (<a
href="https://doi.org/10.1609/aaai.v37i4.25579">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A temporal knowledge graph (TKG) stores the events derived from the data involving time. Predicting events is extremely challenging due to the time-sensitive property of events. Besides, the previous TKG completion (TKGC) approaches cannot represent both the timeliness and the causality properties of events, simultaneously. To address these challenges, we propose a Logic and Commonsense-Guided Embedding model (LCGE) to jointly learn the time-sensitive representation involving timeliness and causality of events, together with the time-independent representation of events from the perspective of commonsense. Specifically, we design a temporal rule learning algorithm to construct a rule-guided predicate embedding regularization strategy for learning the causality among events. Furthermore, we could accurately evaluate the plausibility of events via auxiliary commonsense knowledge. The experimental results of TKGC task illustrate the significant performance improvements of our model compared with the existing approaches. More interestingly, our model is able to provide the explainability of the predicted results in the view of causal inference. The appendix, source code and datasets of this paper are available at https://github.com/ngl567/LCGE.},
  archive   = {C_AAAI},
  author    = {Guanglin Niu and Bo Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25579},
  pages     = {4569-4577},
  title     = {Logic and commonsense-guided temporal knowledge graph completion},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GMDNet: A graph-based mixture density network for estimating
packages’ multimodal travel time distribution. <em>AAAI</em>, 4561–4568.
(<a href="https://doi.org/10.1609/aaai.v37i4.25578">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the logistics network, accurately estimating packages&#39; Travel Time Distribution (TTD) given the routes greatly benefits both consumers and platforms. Although recent works perform well in predicting an expected time or a time distribution in a road network, they could not be well applied to estimate TTD in logistics networks. Because TTD prediction in the logistics network requires modeling packages&#39; multimodal TTD (MTTD, i.e., there can be more than one likely output with a given input) while leveraging the complex correlations in the logistics network. To this end, this work opens appealing research opportunities in studying MTTD learning conditioned on graph-structure data by investigating packages&#39; travel time distribution in the logistics network. We propose a Graph-based Mixture Density Network, named GMDNet, which takes the benefits of both graph neural network and mixture density network for estimating MTTD conditioned on graph-structure data (i.e., the logistics network). Furthermore, we adopt the Expectation-Maximization (EM) framework in the training process to guarantee local convergence and thus obtain more stable results than gradient descent. Extensive experiments on two real-world datasets demonstrate the superiority of our proposed model.},
  archive   = {C_AAAI},
  author    = {Xiaowei Mao and Huaiyu Wan and Haomin Wen and Fan Wu and Jianbin Zheng and Yuting Qiang and Shengnan Guo and Lixia Wu and Haoyuan Hu and Youfang Lin},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25578},
  pages     = {4561-4568},
  title     = {GMDNet: A graph-based mixture density network for estimating packages’ multimodal travel time distribution},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FinalMLP: An enhanced two-stream MLP model for CTR
prediction. <em>AAAI</em>, 4552–4560. (<a
href="https://doi.org/10.1609/aaai.v37i4.25577">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Click-through rate (CTR) prediction is one of the fundamental tasks in online advertising and recommendation. Multi-layer perceptron (MLP) serves as a core component in many deep CTR prediction models, but it has been widely shown that applying a vanilla MLP network alone is ineffective in learning complex feature interactions. As such, many two-stream models (e.g., Wide&amp;Deep, DeepFM, and DCN) have recently been proposed, aiming to integrate two parallel sub-networks to learn feature interactions from two different views for enhanced CTR prediction. In addition to one MLP stream that learns feature interactions implicitly, most of the existing research focuses on designing another stream to complement the MLP stream with explicitly enhanced feature interactions. Instead, this paper presents a simple two-stream feature interaction model, namely FinalMLP, which employs only MLPs in both streams yet achieves surprisingly strong performance. In contrast to sophisticated network design in each stream, our work enhances CTR modeling through a feature selection module, which produces differentiated feature inputs to two streams, and a group-wise bilinear fusion module, which effectively captures stream-level interactions across two streams. We show that FinalMLP achieves competitive or even better performance against many existing two-stream CTR models on four open benchmark datasets and also brings significant CTR improvements during an online A/B test in our industrial news recommender system. We envision that the simple yet effective FinalMLP model could serve as a new strong baseline for future development of two-stream CTR models. Our source code will be available at MindSpore/models and FuxiCTR/model_zoo.},
  archive   = {C_AAAI},
  author    = {Kelong Mao and Jieming Zhu and Liangcai Su and Guohao Cai and Yuru Li and Zhenhua Dong},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25577},
  pages     = {4552-4560},
  title     = {FinalMLP: An enhanced two-stream MLP model for CTR prediction},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). NQE: N-ary query embedding for complex query answering over
hyper-relational knowledge graphs. <em>AAAI</em>, 4543–4551. (<a
href="https://doi.org/10.1609/aaai.v37i4.25576">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Complex query answering (CQA) is an essential task for multi-hop and logical reasoning on knowledge graphs (KGs). Currently, most approaches are limited to queries among binary relational facts and pay less attention to n-ary facts (n≥2) containing more than two entities, which are more prevalent in the real world. Moreover, previous CQA methods can only make predictions for a few given types of queries and cannot be flexibly extended to more complex logical queries, which significantly limits their applications. To overcome these challenges, in this work, we propose a novel N-ary Query Embedding (NQE) model for CQA over hyper-relational knowledge graphs (HKGs), which include massive n-ary facts. The NQE utilizes a dual-heterogeneous Transformer encoder and fuzzy logic theory to satisfy all n-ary FOL queries, including existential quantifiers (∃), conjunction (∧), disjunction (∨), and negation (¬). We also propose a parallel processing algorithm that can train or predict arbitrary n-ary FOL queries in a single batch, regardless of the kind of each query, with good flexibility and extensibility. In addition, we generate a new CQA dataset WD50K-NFOL, including diverse n-ary FOL queries over WD50K. Experimental results on WD50K-NFOL and other standard CQA datasets show that NQE is the state-of-the-art CQA method over HKGs with good generalization capability. Our code and dataset are publicly available.},
  archive   = {C_AAAI},
  author    = {Haoran Luo and Haihong E and Yuhao Yang and Gengxian Zhou and Yikai Guo and Tianyu Yao and Zichen Tang and Xueyuan Lin and Kaiyang Wan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25576},
  pages     = {4543-4551},
  title     = {NQE: N-ary query embedding for complex query answering over hyper-relational knowledge graphs},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Time series contrastive learning with information-aware
augmentations. <em>AAAI</em>, 4534–4542. (<a
href="https://doi.org/10.1609/aaai.v37i4.25575">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Various contrastive learning approaches have been proposed in recent years and achieve significant empirical success. While effective and prevalent, contrastive learning has been less explored for time series data. A key component of contrastive learning is to select appropriate augmentations imposing some priors to construct feasible positive samples, such that an encoder can be trained to learn robust and discriminative representations. Unlike image and language domains where &quot;desired&#39;&#39; augmented samples can be generated with the rule of thumb guided by prefabricated human priors, the ad-hoc manual selection of time series augmentations is hindered by their diverse and human-unrecognizable temporal structures. How to find the desired augmentations of time series data that are meaningful for given contrastive learning tasks and datasets remains an open question. In this work, we address the problem by encouraging both high fidelity and variety based on information theory. A theoretical analysis leads to the criteria for selecting feasible data augmentations. On top of that, we propose a new contrastive learning approach with information-aware augmentations, InfoTS, that adaptively selects optimal augmentations for time series representation learning. Experiments on various datasets show highly competitive performance with up to a 12.0\% reduction in MSE on forecasting tasks and up to 3.7\% relative improvement in accuracy on classification tasks over the leading baselines.},
  archive   = {C_AAAI},
  author    = {Dongsheng Luo and Wei Cheng and Yingheng Wang and Dongkuan Xu and Jingchao Ni and Wenchao Yu and Xuchao Zhang and Yanchi Liu and Yuncong Chen and Haifeng Chen and Xiang Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25575},
  pages     = {4534-4542},
  title     = {Time series contrastive learning with information-aware augmentations},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). On generalized degree fairness in graph neural networks.
<em>AAAI</em>, 4525–4533. (<a
href="https://doi.org/10.1609/aaai.v37i4.25574">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Conventional graph neural networks (GNNs) are often confronted with fairness issues that may stem from their input, including node attributes and neighbors surrounding a node. While several recent approaches have been proposed to eliminate the bias rooted in sensitive attributes, they ignore the other key input of GNNs, namely the neighbors of a node, which can introduce bias since GNNs hinge on neighborhood structures to generate node representations. In particular, the varying neighborhood structures across nodes, manifesting themselves in drastically different node degrees, give rise to the diverse behaviors of nodes and biased outcomes. In this paper, we first define and generalize the degree bias using a generalized definition of node degree as a manifestation and quantification of different multi-hop structures around different nodes. To address the bias in the context of node classification, we propose a novel GNN framework called Generalized Degree Fairness-centric Graph Neural Network (DegFairGNN). Specifically, in each GNN layer, we employ a learnable debiasing function to generate debiasing contexts, which modulate the layer-wise neighborhood aggregation to eliminate the degree bias originating from the diverse degrees among nodes. Extensive experiments on three benchmark datasets demonstrate the effectiveness of our model on both accuracy and fairness metrics.},
  archive   = {C_AAAI},
  author    = {Zemin Liu and Trung-Kien Nguyen and Yuan Fang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25574},
  pages     = {4525-4533},
  title     = {On generalized degree fairness in graph neural networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Beyond smoothing: Unsupervised graph representation learning
with edge heterophily discriminating. <em>AAAI</em>, 4516–4524. (<a
href="https://doi.org/10.1609/aaai.v37i4.25573">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Unsupervised graph representation learning (UGRL) has drawn increasing research attention and achieved promising results in several graph analytic tasks. Relying on the homophily assumption, existing UGRL methods tend to smooth the learned node representations along all edges, ignoring the existence of heterophilic edges that connect nodes with distinct attributes. As a result, current methods are hard to generalize to heterophilic graphs where dissimilar nodes are widely connected, and also vulnerable to adversarial attacks. To address this issue, we propose a novel unsupervised Graph Representation learning method with Edge hEterophily discriminaTing (GREET) which learns representations by discriminating and leveraging homophilic edges and heterophilic edges. To distinguish two types of edges, we build an edge discriminator that infers edge homophily/heterophily from feature and structure information. We train the edge discriminator in an unsupervised way through minimizing the crafted pivot-anchored ranking loss, with randomly sampled node pairs acting as pivots. Node representations are learned through contrasting the dual-channel encodings obtained from the discriminated homophilic and heterophilic edges. With an effective interplaying scheme, edge discriminating and representation learning can mutually boost each other during the training phase. We conducted extensive experiments on 14 benchmark datasets and multiple learning scenarios to demonstrate the superiority of GREET.},
  archive   = {C_AAAI},
  author    = {Yixin Liu and Yizhen Zheng and Daokun Zhang and Vincent CS Lee and Shirui Pan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25573},
  pages     = {4516-4524},
  title     = {Beyond smoothing: Unsupervised graph representation learning with edge heterophily discriminating},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023d). Low-resource personal attribute prediction from
conversations. <em>AAAI</em>, 4507–4515. (<a
href="https://doi.org/10.1609/aaai.v37i4.25572">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Personal knowledge bases (PKBs) are crucial for a broad range of applications such as personalized recommendation and Web-based chatbots. A critical challenge to build PKBs is extracting personal attribute knowledge from users&#39; conversation data. Given some users of a conversational system, a personal attribute and these users&#39; utterances, our goal is to predict the ranking of the given personal attribute values for each user. Previous studies often rely on a relative number of resources such as labeled utterances and external data, yet the attribute knowledge embedded in unlabeled utterances is underutilized and their performance of predicting some difficult personal attributes is still unsatisfactory. In addition, it is found that some text classification methods could be employed to resolve this task directly. However, they also perform not well over those difficult personal attributes. In this paper, we propose a novel framework PEARL to predict personal attributes from conversations by leveraging the abundant personal attribute knowledge from utterances under a low-resource setting in which no labeled utterances or external data are utilized. PEARL combines the biterm semantic information with the word co-occurrence information seamlessly via employing the updated prior attribute knowledge to refine the biterm topic model&#39;s Gibbs sampling process in an iterative manner. The extensive experimental results show that PEARL outperforms all the baseline methods not only on the task of personal attribute prediction from conversations over two data sets, but also on the more general weakly supervised text classification task over one data set.},
  archive   = {C_AAAI},
  author    = {Yinan Liu and Hu Chen and Wei Shen and Jiaoyan Chen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25572},
  pages     = {4507-4515},
  title     = {Low-resource personal attribute prediction from conversations},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Learning by applying: A general framework for mathematical
reasoning via enhancing explicit knowledge learning. <em>AAAI</em>,
4497–4506. (<a href="https://doi.org/10.1609/aaai.v37i4.25571">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Mathematical reasoning is one of the crucial abilities of general artificial intelligence, which requires machines to master mathematical logic and knowledge from solving problems. However, existing approaches are not transparent (thus not interpretable) in terms of what knowledge has been learned and applied in the reasoning process. In this paper, we propose a general Learning by Applying (LeAp) framework to enhance existing models (backbones) in a principled way by explicit knowledge learning. In LeAp, we perform knowledge learning in a novel problem-knowledge-expression paradigm, with a Knowledge Encoder to acquire knowledge from problem data and a Knowledge Decoder to apply knowledge for expression reasoning. The learned mathematical knowledge, including word-word relations and word-operator relations, forms an explicit knowledge graph, which bridges the knowledge “learning” and “applying” organically. Moreover, for problem solving, we design a semantics-enhanced module and a reasoning-enhanced module that apply knowledge to improve the problem comprehension and symbol reasoning abilities of any backbone, respectively. We theoretically prove the superiority of LeAp&#39;s autonomous learning mechanism. Experiments on three real-world datasets show that LeAp improves all backbones&#39; performances, learns accurate knowledge, and achieves a more interpretable reasoning process.},
  archive   = {C_AAAI},
  author    = {Jiayu Liu and Zhenya Huang and ChengXiang Zhai and Qi Liu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25571},
  pages     = {4497-4506},
  title     = {Learning by applying: A general framework for mathematical reasoning via enhancing explicit knowledge learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). IterDE: An iterative knowledge distillation framework for
knowledge graph embeddings. <em>AAAI</em>, 4488–4496. (<a
href="https://doi.org/10.1609/aaai.v37i4.25570">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Knowledge distillation for knowledge graph embedding (KGE) aims to reduce the KGE model size to address the challenges of storage limitations and knowledge reasoning efficiency. However, current work still suffers from the performance drops when compressing a high-dimensional original KGE model to a low-dimensional distillation KGE model. Moreover, most work focuses on the reduction of inference time but ignores the time-consuming training process of distilling KGE models. In this paper, we propose IterDE, a novel knowledge distillation framework for KGEs. First, IterDE introduces an iterative distillation way and enables a KGE model to alternately be a student model and a teacher model during the iterative distillation process. Consequently, knowledge can be transferred in a smooth manner between high-dimensional teacher models and low-dimensional student models, while preserving good KGE performances. Furthermore, in order to optimize the training process, we consider that different optimization objects between hard label loss and soft label loss can affect the efficiency of training, and then we propose a soft-label weighting dynamic adjustment mechanism that can balance the inconsistency of optimization direction between hard and soft label loss by gradually increasing the weighting of soft label loss. Our experimental results demonstrate that IterDE achieves a new state-of-the-art distillation performance for KGEs compared to strong baselines on the link prediction task. Significantly, IterDE can reduce the training time by 50\% on average. Finally, more exploratory experiments show that the soft-label weighting dynamic adjustment mechanism and more fine-grained iterations can improve distillation performance.},
  archive   = {C_AAAI},
  author    = {Jiajun Liu and Peng Wang and Ziyu Shang and Chenxiao Wu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25570},
  pages     = {4488-4496},
  title     = {IterDE: An iterative knowledge distillation framework for knowledge graph embeddings},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-domain generalized graph meta learning. <em>AAAI</em>,
4479–4487. (<a href="https://doi.org/10.1609/aaai.v37i4.25569">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph meta learning aims to learn historical knowledge from training graph neural networks (GNNs) models and adapt it to downstream learning tasks in a target graph, which has drawn increasing attention due to its ability of knowledge transfer and fast adaptation. While existing graph meta learning approaches assume the learning tasks are from the same graph domain but lack the solution for multi-domain adaptation. In this paper, we address the multi-domain generalized graph meta learning problem, which is challenging due to non-Euclidean data, inequivalent feature spaces, and heterogeneous distributions. To this end, we propose a novel solution called MD-Gram for multi-domain graph generalization. It introduces an empirical graph generalization method that uses empirical vectors to form a unified expression of non-Euclidean graph data. Then it proposes a multi-domain graphs transformation approach to transform the learning tasks from multiple source-domain graphs with inequivalent feature spaces into a common domain, where graph meta learning is conducted to learn generalized knowledge. It further adopts a domain-specific GNN enhancement method to learn a customized GNN model to achieve fast adaptation in the unseen target domain. Extensive experiments based on four real-world graph domain datasets show that the proposed method significantly outperforms the state-of-the-art in multi-domain graph meta learning tasks.},
  archive   = {C_AAAI},
  author    = {Mingkai Lin and Wenzhong Li and Ding Li and Yizhou Chen and Guohao Li and Sanglu Lu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25569},
  pages     = {4479-4487},
  title     = {Multi-domain generalized graph meta learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Scalable and effective conductance-based graph clustering.
<em>AAAI</em>, 4471–4478. (<a
href="https://doi.org/10.1609/aaai.v37i4.25568">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Conductance-based graph clustering has been recognized as a fundamental operator in numerous graph analysis applications. Despite the significant success of conductance-based graph clustering, existing algorithms are either hard to obtain satisfactory clustering qualities, or have high time and space complexity to achieve provable clustering qualities. To overcome these limitations, we devise a powerful peeling-based graph clustering framework PCon. We show that many existing solutions can be reduced to our framework. Namely, they first define a score function for each vertex, then iteratively remove the vertex with the smallest score. Finally, they output the result with the smallest conductance during the peeling process. Based on our framework, we propose two novel algorithms PCon_core and PCon_de with linear time and space complexity, which can efficiently and effectively identify clusters from massive graphs with more than a few billion edges. Surprisingly, we prove that PCon_de can identify clusters with near-constant approximation ratio, resulting in an important theoretical improvement over the well-known quadratic Cheeger bound. Empirical results on real-life and synthetic datasets show that our algorithms can achieve 5~42 times speedup with a high clustering accuracy, while using 1.4~7.8 times less memory than the baseline algorithms.},
  archive   = {C_AAAI},
  author    = {Longlong Lin and Ronghua Li and Tao Jia},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25568},
  pages     = {4471-4478},
  title     = {Scalable and effective conductance-based graph clustering},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). COLA: Improving conversational recommender systems by
collaborative augmentation. <em>AAAI</em>, 4462–4470. (<a
href="https://doi.org/10.1609/aaai.v37i4.25567">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Conversational recommender systems (CRS) aim to employ natural language conversations to suggest suitable products to users. Understanding user preferences for prospective items and learning efficient item representations are crucial for CRS. Despite various attempts, earlier studies mostly learned item representations based on individual conversations, ignoring item popularity embodied among all others. Besides, they still need support in efficiently capturing user preferences since the information reflected in a single conversation is limited. Inspired by collaborative filtering, we propose a collaborative augmentation (COLA) method to simultaneously improve both item representation learning and user preference modeling to address these issues. We construct an interactive user-item graph from all conversations, which augments item representations with user-aware information, i.e., item popularity. To improve user preference modeling, we retrieve similar conversations from the training corpus, where the involved items and attributes that reflect the user&#39;s potential interests are used to augment the user representation through gate control. Extensive experiments on two benchmark datasets demonstrate the effectiveness of our method. Our code and data are available at https://github.com/DongdingLin/COLA.},
  archive   = {C_AAAI},
  author    = {Dongding Lin and Jian Wang and Wenjie Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25567},
  pages     = {4462-4470},
  title     = {COLA: Improving conversational recommender systems by collaborative augmentation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PPGenCDR: A stable and robust framework for
privacy-preserving cross-domain recommendation. <em>AAAI</em>,
4453–4461. (<a href="https://doi.org/10.1609/aaai.v37i4.25566">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Privacy-preserving cross-domain recommendation (PPCDR) refers to preserving the privacy of users when transferring the knowledge from source domain to target domain for better performance, which is vital for the long-term development of recommender systems. Existing work on cross-domain recommendation (CDR) reaches advanced and satisfying recommendation performance, but mostly neglects preserving privacy. To fill this gap, we propose a privacy-preserving generative cross-domain recommendation (PPGenCDR) framework for PPCDR. PPGenCDR includes two main modules, i.e., stable privacy-preserving generator module, and robust cross-domain recommendation module. Specifically, the former isolates data from different domains with a generative adversarial network (GAN) based model, which stably estimates the distribution of private data in the source domain with ́Renyi differential privacy (RDP) technique. Then the latter aims to robustly leverage the perturbed but effective knowledge from the source domain with the raw data in target domain to improve recommendation performance. Three key modules, i.e., (1) selective privacy preserver, (2) GAN stabilizer, and (3) robustness conductor, guarantee the cost-effective trade-off between utility and privacy, the stability of GAN when using RDP, and the robustness of leveraging transferable knowledge accordingly. The extensive empirical studies on Douban and Amazon datasets demonstrate that PPGenCDR significantly outperforms the state-of-the-art recommendation models while preserving privacy.},
  archive   = {C_AAAI},
  author    = {Xinting Liao and Weiming Liu and Xiaolin Zheng and Binhui Yao and Chaochao Chen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25566},
  pages     = {4453-4461},
  title     = {PPGenCDR: A stable and robust framework for privacy-preserving cross-domain recommendation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Signed laplacian graph neural networks. <em>AAAI</em>,
4444–4452. (<a href="https://doi.org/10.1609/aaai.v37i4.25565">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper studies learning meaningful node representations for signed graphs, where both positive and negative links exist. This problem has been widely studied by meticulously designing expressive signed graph neural networks, as well as capturing the structural information of the signed graph through traditional structure decomposition methods, e.g., spectral graph theory. In this paper, we propose a novel signed graph representation learning framework, called Signed Laplacian Graph Neural Network (SLGNN), which combines the advantages of both. Specifically, based on spectral graph theory and graph signal processing, we first design different low-pass and high-pass graph convolution filters to extract low-frequency and high-frequency information on positive and negative links, respectively, and then combine them into a unified message passing framework. To effectively model signed graphs, we further propose a self-gating mechanism to estimate the impacts of low-frequency and high-frequency information during message passing. We mathematically establish the relationship between the aggregation process in SLGNN and signed Laplacian regularization in signed graphs, and theoretically analyze the expressiveness of SLGNN. Experimental results demonstrate that SLGNN outperforms various competitive baselines and achieves state-of-the-art performance.},
  archive   = {C_AAAI},
  author    = {Yu Li and Meng Qu and Jian Tang and Yi Chang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25565},
  pages     = {4444-4452},
  title     = {Signed laplacian graph neural networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive low-precision training for embeddings in
click-through rate prediction. <em>AAAI</em>, 4435–4443. (<a
href="https://doi.org/10.1609/aaai.v37i4.25564">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Embedding tables are usually huge in click-through rate (CTR) prediction models. To train and deploy the CTR models efficiently and economically, it is necessary to compress their embedding tables. To this end, we formulate a novel quantization training paradigm to compress the embeddings from the training stage, termed low-precision training (LPT). Also, we provide theoretical analysis on its convergence. The results show that stochastic weight quantization has a faster convergence rate and a smaller convergence error than deterministic weight quantization in LPT. Further, to reduce accuracy degradation, we propose adaptive low-precision training (ALPT) which learns the step size (i.e., the quantization resolution). Experiments on two real-world datasets confirm our analysis and show that ALPT can significantly improve the prediction accuracy, especially at extremely low bit width. For the first time in CTR models, we successfully train 8-bit embeddings without sacrificing prediction accuracy.},
  archive   = {C_AAAI},
  author    = {Shiwei Li and Huifeng Guo and Lu Hou and Wei Zhang and Xing Tang and Ruiming Tang and Rui Zhang and Ruixuan Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25564},
  pages     = {4435-4443},
  title     = {Adaptive low-precision training for embeddings in click-through rate prediction},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Anomaly segmentation for high-resolution remote sensing
images based on pixel descriptors. <em>AAAI</em>, 4426–4434. (<a
href="https://doi.org/10.1609/aaai.v37i4.25563">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Anomaly segmentation in high spatial resolution (HSR) remote sensing imagery is aimed at segmenting anomaly patterns of the earth deviating from normal patterns, which plays an important role in various Earth vision applications. However, it is a challenging task due to the complex distribution and the irregular shapes of objects, and the lack of abnormal samples. To tackle these problems, an anomaly segmentation model based on pixel descriptors (ASD) is proposed for anomaly segmentation in HSR imagery. Specifically, deep one-class classification is introduced for anomaly segmentation in the feature space with discriminative pixel descriptors. The ASD model incorporates the data argument for generating virtual abnormal samples, which can force the pixel descriptors to be compact for normal data and meanwhile to be diverse to avoid the model collapse problems when only positive samples participated in the training. In addition, the ASD introduced a multi-level and multi-scale feature extraction strategy for learning the low-level and semantic information to make the pixel descriptors feature-rich. The proposed ASD model was validated using four HSR datasets and compared with the recent state-of-the-art models, showing its potential value in Earth vision applications.},
  archive   = {C_AAAI},
  author    = {Jingtao Li and Xinyu Wang and Hengwei Zhao and Shaoyu Wang and Yanfei Zhong},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25563},
  pages     = {4426-4434},
  title     = {Anomaly segmentation for high-resolution remote sensing images based on pixel descriptors},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Multiple robust learning for recommendation. <em>AAAI</em>,
4417–4425. (<a href="https://doi.org/10.1609/aaai.v37i4.25562">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In recommender systems, a common problem is the presence of various biases in the collected data, which deteriorates the generalization ability of the recommendation models and leads to inaccurate predictions. Doubly robust (DR) learning has been studied in many tasks in RS, with the advantage that unbiased learning can be achieved when either a single imputation or a single propensity model is accurate. In this paper, we propose a multiple robust (MR) estimator that can take the advantage of multiple candidate imputation and propensity models to achieve unbiasedness. Specifically, the MR estimator is unbiased when any of the imputation or propensity models, or a linear combination of these models is accurate. Theoretical analysis shows that the proposed MR is an enhanced version of DR when only having a single imputation and propensity model, and has a smaller bias. Inspired by the generalization error bound of MR, we further propose a novel multiple robust learning approach with stabilization. We conduct extensive experiments on real-world and semi-synthetic datasets, which demonstrates the superiority of the proposed approach over state-of-the-art methods.},
  archive   = {C_AAAI},
  author    = {Haoxuan Li and Quanyu Dai and Yuru Li and Yan Lyu and Zhenhua Dong and Xiao-Hua Zhou and Peng Wu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25562},
  pages     = {4417-4425},
  title     = {Multiple robust learning for recommendation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards reliable item sampling for recommendation
evaluation. <em>AAAI</em>, 4409–4416. (<a
href="https://doi.org/10.1609/aaai.v37i4.25561">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Since Rendle and Krichene argued that commonly used sampling-based evaluation metrics are ``inconsistent&#39;&#39; with respect to the global metrics (even in expectation), there have been a few studies on the sampling-based recommender system evaluation. Existing methods try either mapping the sampling-based metrics to their global counterparts or more generally, learning the empirical rank distribution to estimate the top-K metrics. However, despite existing efforts, there is still a lack of rigorous theoretical understanding of the proposed metric estimators, and the basic item sampling also suffers from the ``blind spot&#39;&#39; issue, i.e., estimation accuracy to recover the top-K metrics when K is small can still be rather substantial. In this paper, we provide an in-depth investigation into these problems and make two innovative contributions. First, we propose a new item-sampling estimator that explicitly optimizes the error with respect to the ground truth, and theoretically highlights its subtle difference against prior work. Second, we propose a new adaptive sampling method that aims to deal with the ``blind spot&#39;&#39; problem and also demonstrate the expectation-maximization (EM) algorithm can be generalized for such a setting. Our experimental results confirm our statistical analysis and the superiority of the proposed works. This study helps lay the theoretical foundation for adopting item sampling metrics for recommendation evaluation and provides strong evidence for making item sampling a powerful and reliable tool for recommendation evaluation.},
  archive   = {C_AAAI},
  author    = {Dong Li and Ruoming Jin and Zhenming Liu and Bin Ren and Jing Gao and Zhi Liu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25561},
  pages     = {4409-4416},
  title     = {Towards reliable item sampling for recommendation evaluation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Parameterized algorithms for colored clustering.
<em>AAAI</em>, 4400–4408. (<a
href="https://doi.org/10.1609/aaai.v37i4.25560">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the Colored Clustering problem, one is asked to cluster edge-colored (hyper-)graphs whose colors represent interaction types. More specifically, the goal is to select as many edges as possible without choosing two edges that share an endpoint and are colored differently. Equivalently, the goal can also be described as assigning colors to the vertices in a way that fits the edge-coloring as well as possible. As this problem is NP-hard, we build on previous work by studying its parameterized complexity. We give a 2ᴼ⁽ᵏ⁾·nᴼ⁽¹⁾-time algorithm where k is the number of edges to be selected and n the number of vertices. We also prove the existence of a problem kernel of size O(k⁵ᐟ²), resolving an open problem posed in the literature. We consider parameters that are smaller than k, the number of edges to be selected, and r, the number of edges that can be deleted. Such smaller parameters are obtained by considering the difference between k or r and some lower bound on these values. We give both algorithms and lower bounds for Colored Clustering with such parameterizations. Finally, we settle the parameterized complexity of Colored Clustering with respect to structural graph parameters by showing that it is W[1]-hard with respect to both vertex cover number and tree-cut width, but fixed-parameter tractable with respect to local feedback edge number.},
  archive   = {C_AAAI},
  author    = {Leon Kellerhals and Tomohiro Koana and Pascal Kunz and Rolf Niedermeier},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25560},
  pages     = {4400-4408},
  title     = {Parameterized algorithms for colored clustering},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GLCC: A general framework for graph-level clustering.
<em>AAAI</em>, 4391–4399. (<a
href="https://doi.org/10.1609/aaai.v37i4.25559">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper studies the problem of graph-level clustering, which is a novel yet challenging task. This problem is critical in a variety of real-world applications such as protein clustering and genome analysis in bioinformatics. Recent years have witnessed the success of deep clustering coupled with graph neural networks (GNNs). However, existing methods focus on clustering among nodes given a single graph, while exploring clustering on multiple graphs is still under-explored. In this paper, we propose a general graph-level clustering framework named Graph-Level Contrastive Clustering (GLCC) given multiple graphs. Specifically, GLCC first constructs an adaptive affinity graph to explore instance- and cluster-level contrastive learning (CL). Instance-level CL leverages graph Laplacian based contrastive loss to learn clustering-friendly representations while cluster-level CL captures discriminative cluster representations incorporating neighbor information of each sample. Moreover, we utilize neighbor-aware pseudo-labels to reward the optimization of representation learning. The two steps can be alternatively trained to collaborate and benefit each other. Experiments on a range of well-known datasets demonstrate the superiority of our proposed GLCC over competitive baselines.},
  archive   = {C_AAAI},
  author    = {Wei Ju and Yiyang Gu and Binqi Chen and Gongbo Sun and Yifang Qin and Xingyuming Liu and Xiao Luo and Ming Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25559},
  pages     = {4391-4399},
  title     = {GLCC: A general framework for graph-level clustering},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Let graph be the go board: Gradient-free node injection
attack for graph neural networks via reinforcement learning.
<em>AAAI</em>, 4383–4390. (<a
href="https://doi.org/10.1609/aaai.v37i4.25558">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph Neural Networks (GNNs) have drawn significant attentions over the years and been broadly applied to essential applications requiring solid robustness or vigorous security standards, such as product recommendation and user behavior modeling. Under these scenarios, exploiting GNN&#39;s vulnerabilities and further downgrading its performance become extremely incentive for adversaries. Previous attackers mainly focus on structural perturbations or node injections to the existing graphs, guided by gradients from the surrogate models. Although they deliver promising results, several limitations still exist. For the structural perturbation attack, to launch a proposed attack, adversaries need to manipulate the existing graph topology, which is impractical in most circumstances. Whereas for the node injection attack, though being more practical, current approaches require training surrogate models to simulate a white-box setting, which results in significant performance downgrade when the surrogate architecture diverges from the actual victim model. To bridge these gaps, in this paper, we study the problem of black-box node injection attack, without training a potentially misleading surrogate model. Specifically, we model the node injection attack as a Markov decision process and propose Gradient-free Graph Advantage Actor Critic, namely G2A2C, a reinforcement learning framework in the fashion of advantage actor critic. By directly querying the victim model, G2A2C learns to inject highly malicious nodes with extremely limited attacking budgets, while maintaining a similar node feature distribution. Through our comprehensive experiments over eight acknowledged benchmark datasets with different characteristics, we demonstrate the superior performance of our proposed G2A2C over the existing state-of-the-art attackers. Source code is publicly available at: https://github.com/jumxglhf/G2A2C.},
  archive   = {C_AAAI},
  author    = {Mingxuan Ju and Yujie Fan and Chuxu Zhang and Yanfang Ye},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25558},
  pages     = {4383-4390},
  title     = {Let graph be the go board: Gradient-free node injection attack for graph neural networks via reinforcement learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Continuous trajectory generation based on two-stage GAN.
<em>AAAI</em>, 4374–4382. (<a
href="https://doi.org/10.1609/aaai.v37i4.25557">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Simulating the human mobility and generating large-scale trajectories are of great use in many real-world applications, such as urban planning, epidemic spreading analysis, and geographic privacy protect. Although many previous works have studied the problem of trajectory generation, the continuity of the generated trajectories has been neglected, which makes these methods useless for practical urban simulation scenarios. To solve this problem, we propose a novel two-stage generative adversarial framework to generate the continuous trajectory on the road network, namely TS-TrajGen, which efficiently integrates prior domain knowledge of human mobility with model-free learning paradigm. Specifically, we build the generator under the human mobility hypothesis of the A* algorithm to learn the human mobility behavior. For the discriminator, we combine the sequential reward with the mobility yaw reward to enhance the effectiveness of the generator. Finally, we propose a novel two-stage generation process to overcome the weak point of the existing stochastic generation process. Extensive experiments on two real-world datasets and two case studies demonstrate that our framework yields significant improvements over the state-of-the-art methods.},
  archive   = {C_AAAI},
  author    = {Wenjun Jiang and Wayne Xin Zhao and Jingyuan Wang and Jiawei Jiang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25557},
  pages     = {4374-4382},
  title     = {Continuous trajectory generation based on two-stage GAN},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PDFormer: Propagation delay-aware dynamic long-range
transformer for traffic flow prediction. <em>AAAI</em>, 4365–4373. (<a
href="https://doi.org/10.1609/aaai.v37i4.25556">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As a core technology of Intelligent Transportation System, traffic flow prediction has a wide range of applications. The fundamental challenge in traffic flow prediction is to effectively model the complex spatial-temporal dependencies in traffic data. Spatial-temporal Graph Neural Network (GNN) models have emerged as one of the most promising methods to solve this problem. However, GNN-based models have three major limitations for traffic prediction: i) Most methods model spatial dependencies in a static manner, which limits the ability to learn dynamic urban traffic patterns; ii) Most methods only consider short-range spatial information and are unable to capture long-range spatial dependencies; iii) These methods ignore the fact that the propagation of traffic conditions between locations has a time delay in traffic systems. To this end, we propose a novel Propagation Delay-aware dynamic long-range transFormer, namely PDFormer, for accurate traffic flow prediction. Specifically, we design a spatial self-attention module to capture the dynamic spatial dependencies. Then, two graph masking matrices are introduced to highlight spatial dependencies from short- and long-range views. Moreover, a traffic delay-aware feature transformation module is proposed to empower PDFormer with the capability of explicitly modeling the time delay of spatial information propagation. Extensive experimental results on six real-world public traffic datasets show that our method can not only achieve state-of-the-art performance but also exhibit competitive computational efficiency. Moreover, we visualize the learned spatial-temporal attention map to make our model highly interpretable.},
  archive   = {C_AAAI},
  author    = {Jiawei Jiang and Chengkai Han and Wayne Xin Zhao and Jingyuan Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25556},
  pages     = {4365-4373},
  title     = {PDFormer: Propagation delay-aware dynamic long-range transformer for traffic flow prediction},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spatio-temporal self-supervised learning for traffic flow
prediction. <em>AAAI</em>, 4356–4364. (<a
href="https://doi.org/10.1609/aaai.v37i4.25555">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Robust prediction of citywide traffic flows at different time periods plays a crucial role in intelligent transportation systems. While previous work has made great efforts to model spatio-temporal correlations, existing methods still suffer from two key limitations: i) Most models collectively predict all regions&#39; flows without accounting for spatial heterogeneity, i.e., different regions may have skewed traffic flow distributions. ii) These models fail to capture the temporal heterogeneity induced by time-varying traffic patterns, as they typically model temporal correlations with a shared parameterized space for all time periods. To tackle these challenges, we propose a novel Spatio-Temporal Self-Supervised Learning (ST-SSL) traffic prediction framework which enhances the traffic pattern representations to be reflective of both spatial and temporal heterogeneity, with auxiliary self-supervised learning paradigms. Specifically, our ST-SSL is built over an integrated module with temporal and spatial convolutions for encoding the information across space and time. To achieve the adaptive spatio-temporal self-supervised learning, our ST-SSL first performs the adaptive augmentation over the traffic flow graph data at both attribute- and structure-levels. On top of the augmented traffic graph, two SSL auxiliary tasks are constructed to supplement the main traffic prediction task with spatial and temporal heterogeneity-aware augmentation. Experiments on four benchmark datasets demonstrate that ST-SSL consistently outperforms various state-of-the-art baselines. Since spatio-temporal heterogeneity widely exists in practical datasets, the proposed framework may also cast light on other spatial-temporal applications. Model implementation is available at https://github.com/Echo-Ji/ST-SSL.},
  archive   = {C_AAAI},
  author    = {Jiahao Ji and Jingyuan Wang and Chao Huang and Junjie Wu and Boren Xu and Zhenhe Wu and Junbo Zhang and Yu Zheng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25555},
  pages     = {4356-4364},
  title     = {Spatio-temporal self-supervised learning for traffic flow prediction},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Detecting sources of healthcare associated infections.
<em>AAAI</em>, 4347–4355. (<a
href="https://doi.org/10.1609/aaai.v37i4.25554">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Healthcare acquired infections (HAIs) (e.g., Methicillin-resistant Staphylococcus aureus infection) have complex transmission pathways, spreading not just via direct person-to-person contacts, but also via contaminated surfaces. Prior work in mathematical epidemiology has led to a class of models – which we call load sharing models – that provide a discrete-time, stochastic formalization of HAI-spread on temporal contact networks. The focus of this paper is the source detection problem for the load sharing model. The source detection problem has been studied extensively in SEIR type models, but this prior work does not apply to load sharing models. We show that a natural formulation of the source detection problem for the load sharing model is computationally hard, even to approximate. We then present two alternate formulations that are much more tractable. The tractability of our problems depends crucially on the submodularity of the expected number of infections as a function of the source set. Prior techniques for showing submodularity, such as the &quot;live graph&quot; technique are not applicable for the load sharing model and our key technical contribution is to use a more sophisticated &quot;coupling&quot; technique to show the submodularity result. We propose algorithms for our two problem formulations by extending existing algorithmic results from submodular optimization and combining these with an expectation propagation heuristic for the load sharing model that leads to orders-of-magnitude speedup. We present experimental results on temporal contact networks based on fine-grained EMR data from three different hospitals. Our results on synthetic outbreaks on these networks show that our algorithms outperform baselines by up to 5.97 times. Furthermore, case studies based on hospital outbreaks of Clostridioides difficile infection show that our algorithms identify clinically meaningful sources.},
  archive   = {C_AAAI},
  author    = {Hankyu Jang and Andrew Fu and Jiaming Cui and Methun Kamruzzaman and B. Aditya Prakash and Anil Vullikanti and Bijaya Adhikari and Sriram V. Pemmaraju},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25554},
  pages     = {4347-4355},
  title     = {Detecting sources of healthcare associated infections},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). T2-GNN: Graph neural networks for graphs with incomplete
features and structure via teacher-student distillation. <em>AAAI</em>,
4339–4346. (<a href="https://doi.org/10.1609/aaai.v37i4.25553">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph Neural Networks (GNNs) have been a prevailing technique for tackling various analysis tasks on graph data. A key premise for the remarkable performance of GNNs relies on complete and trustworthy initial graph descriptions (i.e., node features and graph structure), which is often not satisfied since real-world graphs are often incomplete due to various unavoidable factors. In particular, GNNs face greater challenges when both node features and graph structure are incomplete at the same time. The existing methods either focus on feature completion or structure completion. They usually rely on the matching relationship between features and structure, or employ joint learning of node representation and feature (or structure) completion in the hope of achieving mutual benefit. However, recent studies confirm that the mutual interference between features and structure leads to the degradation of GNN performance. When both features and structure are incomplete, the mismatch between features and structure caused by the missing randomness exacerbates the interference between the two, which may trigger incorrect completions that negatively affect node representation. To this end, in this paper we propose a general GNN framework based on teacher-student distillation to improve the performance of GNNs on incomplete graphs, namely T2-GNN. To avoid the interference between features and structure, we separately design feature-level and structure-level teacher models to provide targeted guidance for student model (base GNNs, such as GCN) through distillation. Then we design two personalized methods to obtain well-trained feature and structure teachers. To ensure that the knowledge of the teacher model is comprehensively and effectively distilled to the student model, we further propose a dual distillation mode to enable the student to acquire as much expert knowledge as possible. Extensive experiments on eight benchmark datasets demonstrate the effectiveness and robustness of the new framework on graphs with incomplete features and structure.},
  archive   = {C_AAAI},
  author    = {Cuiying Huo and Di Jin and Yawen Li and Dongxiao He and Yu-Bin Yang and Lingfei Wu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25553},
  pages     = {4339-4346},
  title     = {T2-GNN: Graph neural networks for graphs with incomplete features and structure via teacher-student distillation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Constrained market share maximization by signal-guided
optimization. <em>AAAI</em>, 4330–4338. (<a
href="https://doi.org/10.1609/aaai.v37i4.25552">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With the rapid development of the airline industry, maximizing the market share with a constrained budget is an urgent econometric problem for an airline. We investigate the problem by adjusting flight frequencies on different flight routes. Owing to the large search space of solutions and the difficulty of predicting the market, this problem is in general daunting to solve. This paper proposes a novel two-stage optimization method to address the challenges. On the higher level, we use a signal to guide the optimization process toward a constrained satisfying solution. On the lower level, we consider the consecutive itineraries in real scenarios and model the unseen correlations between routes in itineraries for market share prediction. In theory, we prove the convergence of our optimization approach. In the experiment, we empirically verify the superiority of both our prediction model and optimization approach over existing works with large-scale real-world data. Our code has been released at: https://github.com/codingAndBS/AirlineMarket.},
  archive   = {C_AAAI},
  author    = {Bo Hui and Yuchen Fang and Tian Xia and Sarp Aykent and Wei-Shinn Ku},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25552},
  pages     = {4330-4338},
  title     = {Constrained market share maximization by signal-guided optimization},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learned distributed image compression with multi-scale patch
matching in feature domain. <em>AAAI</em>, 4322–4329. (<a
href="https://doi.org/10.1609/aaai.v37i4.25551">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Beyond achieving higher compression efficiency over classical image compression codecs, deep image compression is expected to be improved with additional side information, e.g., another image from a different perspective of the same scene. To better utilize the side information under the distributed compression scenario, the existing method only implements patch matching at the image domain to solve the parallax problem caused by the difference in viewing points. However, the patch matching at the image domain is not robust to the variance of scale, shape, and illumination caused by the different viewing angles, and can not make full use of the rich texture information of the side information image. To resolve this issue, we propose Multi-Scale Feature Domain Patch Matching (MSFDPM) to fully utilizes side information at the decoder of the distributed image compression model. Specifically, MSFDPM consists of a side information feature extractor, a multi-scale feature domain patch matching module, and a multi-scale feature fusion network. Furthermore, we reuse inter-patch correlation from the shallow layer to accelerate the patch matching of the deep layer. Finally, we find that our patch matching in a multi-scale feature domain further improves compression rate by about 20\% compared with the patch matching method at image domain.},
  archive   = {C_AAAI},
  author    = {Yujun Huang and Bin Chen and Shiyu Qin and Jiawei Li and Yaowei Wang and Tao Dai and Shu-Tao Xia},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25551},
  pages     = {4322-4329},
  title     = {Learned distributed image compression with multi-scale patch matching in feature domain},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). SAH: Shifting-aware asymmetric hashing for reverse k
maximum inner product search. <em>AAAI</em>, 4312–4321. (<a
href="https://doi.org/10.1609/aaai.v37i4.25550">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper investigates a new yet challenging problem called Reverse k-Maximum Inner Product Search (RkMIPS). Given a query (item) vector, a set of item vectors, and a set of user vectors, the problem of RkMIPS aims to find a set of user vectors whose inner products with the query vector are one of the k largest among the query and item vectors. We propose the first subquadratic-time algorithm, i.e., Shifting-aware Asymmetric Hashing (SAH), to tackle the RkMIPS problem. To speed up the Maximum Inner Product Search (MIPS) on item vectors, we design a shifting-invariant asymmetric transformation and develop a novel sublinear-time Shifting-Aware Asymmetric Locality Sensitive Hashing (SA-ALSH) scheme. Furthermore, we devise a new blocking strategy based on the Cone-Tree to effectively prune user vectors (in a batch). We prove that SAH achieves a theoretical guarantee for solving the RMIPS problem. Experimental results on five real-world datasets show that SAH runs 4~8x faster than the state-of-the-art methods for RkMIPS while achieving F1-scores of over 90\%. The code is available at https://github.com/HuangQiang/SAH.},
  archive   = {C_AAAI},
  author    = {Qiang Huang and Yanhao Wang and Anthony K. H. Tung},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25550},
  pages     = {4312-4321},
  title     = {SAH: Shifting-aware asymmetric hashing for reverse k maximum inner product search},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Conditional diffusion based on discrete graph structures for
molecular graph generation. <em>AAAI</em>, 4302–4311. (<a
href="https://doi.org/10.1609/aaai.v37i4.25549">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Learning the underlying distribution of molecular graphs and generating high-fidelity samples is a fundamental research problem in drug discovery and material science. However, accurately modeling distribution and rapidly generating novel molecular graphs remain crucial and challenging goals. To accomplish these goals, we propose a novel Conditional Diffusion model based on discrete Graph Structures (CDGS) for molecular graph generation. Specifically, we construct a forward graph diffusion process on both graph structures and inherent features through stochastic differential equations (SDE) and derive discrete graph structures as the condition for reverse generative processes. We present a specialized hybrid graph noise prediction model that extracts the global context and the local node-edge dependency from intermediate graph states. We further utilize ordinary differential equation (ODE) solvers for efficient graph sampling, based on the semi-linear structure of the probability flow ODE. We also combine the solvers with gradient guidance from the molecule property predictor for similarity-constrained molecule optimization. Experiments on diverse datasets validate the effectiveness of our framework. Particularly, the proposed method still generates high-quality molecular graphs in a limited number of steps.},
  archive   = {C_AAAI},
  author    = {Han Huang and Leilei Sun and Bowen Du and Weifeng Lv},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25549},
  pages     = {4302-4311},
  title     = {Conditional diffusion based on discrete graph structures for molecular graph generation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generic and dynamic graph representation learning for crowd
flow modeling. <em>AAAI</em>, 4293–4301. (<a
href="https://doi.org/10.1609/aaai.v37i4.25548">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Many deep spatio-temporal learning methods have been proposed for crowd flow modeling in recent years. However, most of them focus on designing a spatial and temporal convolution mechanism to aggregate information from nearby nodes and historical observations for a pre-defined prediction task. Different from the existing research, this paper aims to provide a generic and dynamic representation learning method for crowd flow modeling. The main idea of our method is to maintain a continuous-time representation for each node, and update the representations of all nodes continuously according to the streaming observed data. Along this line, a particular encoder-decoder architecture is proposed, where the encoder converts the newly happened transactions into a timestamped message, and then the representations of related nodes are updated according to the generated message. The role of the decoder is to guide the representation learning process by reconstructing the observed transactions based on the most recent node representations. Moreover, a number of virtual nodes are added to discover macro-level spatial patterns and also share the representations among spatially-interacted stations. Experiments have been conducted on two real-world datasets for four popular prediction tasks in crowd flow modeling. The result demonstrates that our method could achieve better prediction performance for all the tasks than baseline methods.},
  archive   = {C_AAAI},
  author    = {Liangzhe Han and Ruixing Zhang and Leilei Sun and Bowen Du and Yanjie Fu and Tongyu Zhu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25548},
  pages     = {4293-4301},
  title     = {Generic and dynamic graph representation learning for crowd flow modeling},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MA-GCL: Model augmentation tricks for graph contrastive
learning. <em>AAAI</em>, 4284–4292. (<a
href="https://doi.org/10.1609/aaai.v37i4.25547">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Contrastive learning (CL), which can extract the information shared between different contrastive views, has become a popular paradigm for vision representation learning. Inspired by the success in computer vision, recent work introduces CL into graph modeling, dubbed as graph contrastive learning (GCL). However, generating contrastive views in graphs is more challenging than that in images, since we have little prior knowledge on how to significantly augment a graph without changing its labels. We argue that typical data augmentation techniques (e.g., edge dropping) in GCL cannot generate diverse enough contrastive views to filter out noises. Moreover, previous GCL methods employ two view encoders with exactly the same neural architecture and tied parameters, which further harms the diversity of augmented views. To address this limitation, we propose a novel paradigm named model augmented GCL (MA-GCL), which will focus on manipulating the architectures of view encoders instead of perturbing graph inputs. Specifically, we present three easy-to-implement model augmentation tricks for GCL, namely asymmetric, random and shuffling, which can respectively help alleviate high-frequency noises, enrich training instances and bring safer augmentations. All three tricks are compatible with typical data augmentations. Experimental results show that MA-GCL can achieve state-of-the-art performance on node classification benchmarks by applying the three tricks on a simple base model. Extensive studies also validate our motivation and the effectiveness of each trick. (Code, data and appendix are available at https://github.com/GXM1141/MA-GCL. )},
  archive   = {C_AAAI},
  author    = {Xumeng Gong and Cheng Yang and Chuan Shi},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25547},
  pages     = {4284-4292},
  title     = {MA-GCL: Model augmentation tricks for graph contrastive learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Contrastive pre-training with adversarial perturbations for
check-in sequence representation learning. <em>AAAI</em>, 4276–4283. (<a
href="https://doi.org/10.1609/aaai.v37i4.25546">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A core step of mining human mobility data is to learn accurate representations for user-generated check-in sequences. The learned representations should be able to fully describe the spatial-temporal mobility patterns of users and the high-level semantics of traveling. However, existing check-in sequence representation learning is usually implicitly achieved by end-to-end models designed for specific downstream tasks, resulting in unsatisfactory generalizable abilities and poor performance. Besides, although the sequence representation learning models that follow the contrastive learning pre-training paradigm have achieved breakthroughs in many fields like NLP, they fail to simultaneously consider the unique spatial-temporal characteristics of check-in sequences and need manual adjustments on the data augmentation strategies. So, directly applying them to check-in sequences cannot yield a meaningful pretext task. To this end, in this paper we propose a contrastive pre-training model with adversarial perturbations for check-in sequence representation learning (CACSR). Firstly, we design a novel spatial-temporal augmentation block for disturbing the spatial-temporal features of check-in sequences in the latent space to relieve the stress of designing manual data augmentation strategies. Secondly, to construct an effective contrastive pretext task, we generate “hard” positive and negative pairs for the check-in sequence by adversarial training. These two designs encourage the model to capture the high-level spatial-temporal patterns and semantics of check-in sequences while ignoring the noisy and unimportant details. We demonstrate the effectiveness and versatility of CACSR on two kinds of downstream tasks using three real-world datasets. The results show that our model outperforms both the state-of-the-art pre-training methods and the end-to-end models.},
  archive   = {C_AAAI},
  author    = {Letian Gong and Youfang Lin and Shengnan Guo and Yan Lin and Tianyi Wang and Erwen Zheng and Zeyu Zhou and Huaiyu Wan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25546},
  pages     = {4276-4283},
  title     = {Contrastive pre-training with adversarial perturbations for check-in sequence representation learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DropMessage: Unifying random dropping for graph neural
networks. <em>AAAI</em>, 4267–4275. (<a
href="https://doi.org/10.1609/aaai.v37i4.25545">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph Neural Networks (GNNs) are powerful tools for graph representation learning. Despite their rapid development, GNNs also face some challenges, such as over-fitting, over-smoothing, and non-robustness. Previous works indicate that these problems can be alleviated by random dropping methods, which integrate augmented data into models by randomly masking parts of the input. However, some open problems of random dropping on GNNs remain to be solved. First, it is challenging to find a universal method that are suitable for all cases considering the divergence of different datasets and models. Second, augmented data introduced to GNNs causes the incomplete coverage of parameters and unstable training process. Third, there is no theoretical analysis on the effectiveness of random dropping methods on GNNs. In this paper, we propose a novel random dropping method called DropMessage, which performs dropping operations directly on the propagated messages during the message-passing process. More importantly, we find that DropMessage provides a unified framework for most existing random dropping methods, based on which we give theoretical analysis of their effectiveness. Furthermore, we elaborate the superiority of DropMessage: it stabilizes the training process by reducing sample variance; it keeps information diversity from the perspective of information theory, enabling it become a theoretical upper bound of other methods. To evaluate our proposed method, we conduct experiments that aims for multiple tasks on five public datasets and two industrial datasets with various backbone models. The experimental results show that DropMessage has the advantages of both effectiveness and generalization, and can significantly alleviate the problems mentioned above. A detailed version with full appendix can be found on arXiv: https://arxiv.org/abs/2204.10037.},
  archive   = {C_AAAI},
  author    = {Taoran Fang and Zhiqing Xiao and Chunping Wang and Jiarong Xu and Xuan Yang and Yang Yang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25545},
  pages     = {4267-4275},
  title     = {DropMessage: Unifying random dropping for graph neural networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Soft target-enhanced matching framework for deep entity
matching. <em>AAAI</em>, 4259–4266. (<a
href="https://doi.org/10.1609/aaai.v37i4.25544">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep Entity Matching (EM) is one of the core research topics in data integration. Typical existing works construct EM models by training deep neural networks (DNNs) based on the training samples with onehot labels. However, these sharp supervision signals of onehot labels harm the generalization of EM models, causing them to overfit the training samples and perform badly in unseen datasets. To solve this problem, we first propose that the challenge of training a well-generalized EM model lies in achieving the compromise between fitting the training samples and imposing regularization, i.e., the bias-variance tradeoff. Then, we propose a novel Soft Target-EnhAnced Matching (Steam) framework, which exploits the automatically generated soft targets as label-wise regularizers to constrain the model training. Specifically, Steam regards the EM model trained in previous iteration as a virtual teacher and takes its softened output as the extra regularizer to train the EM model in the current iteration. As such, Steam effectively calibrates the obtained EM model, achieving the bias-variance tradeoff without any additional computational cost. We conduct extensive experiments over open datasets and the results show that our proposed Steam outperforms the state-of-the-art EM approaches in terms of effectiveness and label efficiency.},
  archive   = {C_AAAI},
  author    = {Wenzhou Dou and Derong Shen and Xiangmin Zhou and Tiezheng Nie and Yue Kou and Hang Cui and Ge Yu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25544},
  pages     = {4259-4266},
  title     = {Soft target-enhanced matching framework for deep entity matching},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DAMix: Exploiting deep autoregressive model zoo for
improving lossless compression generalization. <em>AAAI</em>, 4250–4258.
(<a href="https://doi.org/10.1609/aaai.v37i4.25543">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep generative models have demonstrated superior performance in lossless compression on identically distributed data. However, in real-world scenarios, data to be compressed are of various distributions and usually cannot be known in advance. Thus, commercially expected neural compression must have strong Out-of-Distribution (OoD) generalization capabilities. Compared with traditional compression methods, deep learning methods have intrinsic flaws for OoD generalization. In this work, we make the attempt to tackle this challenge via exploiting a zoo of Deep Autoregressive models (DAMix). We build a model zoo consisting of autoregressive models trained on data from diverse distributions. In the test phase, we select useful expert models by a simple model evaluation score and adaptively aggregate the predictions of selected models. By assuming the outputs from each expert model are biased in favor of their training distributions, a von Mises-Fisher based filter is proposed to recover the value of unbiased predictions that provides more accurate density estimations than a single model. We derive the posterior of unbiased predictions as well as concentration parameters in the filter, and a novel temporal Stein variational gradient descent for sequential data is proposed to adaptively update the posterior distributions. We evaluate DAMix on 22 image datasets, including in-distribution and OoD data, and demonstrate that making use of unbiased predictions has up to 45.6\% improvement over the single model trained on ImageNet.},
  archive   = {C_AAAI},
  author    = {Qishi Dong and Fengwei Zhou and Ning Kang and Chuanlong Xie and Shifeng Zhang and Jiawei Li and Heng Peng and Zhenguo Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25543},
  pages     = {4250-4258},
  title     = {DAMix: Exploiting deep autoregressive model zoo for improving lossless compression generalization},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spatio-temporal neural structural causal models for bike
flow prediction. <em>AAAI</em>, 4242–4249. (<a
href="https://doi.org/10.1609/aaai.v37i4.25542">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As a representative of public transportation, the fundamental issue of managing bike-sharing systems is bike flow prediction. Recent methods overemphasize the spatio-temporal correlations in the data, ignoring the effects of contextual conditions on the transportation system and the inter-regional time-varying causality. In addition, due to the disturbance of incomplete observations in the data, random contextual conditions lead to spurious correlations between data and features, making the prediction of the model ineffective in special scenarios. To overcome this issue, we propose a Spatio-temporal Neural Structure Causal Model(STNSCM) from the perspective of causality. First, we build a causal graph to describe the traffic prediction, and further analyze the causal relationship between the input data, contextual conditions, spatio-temporal states, and prediction results. Second, we propose to apply the frontdoor criterion to eliminate confounding biases in the feature extraction process. Finally, we propose a counterfactual representation reasoning module to extrapolate the spatio-temporal state under the factual scenario to future counterfactual scenarios to improve the prediction performance. Experiments on real-world datasets demonstrate the superior performance of our model, especially its resistance to fluctuations caused by the external environment. The source code and data will be released.},
  archive   = {C_AAAI},
  author    = {Pan Deng and Yu Zhao and Junting Liu and Xiaofeng Jia and Mulan Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25542},
  pages     = {4242-4249},
  title     = {Spatio-temporal neural structural causal models for bike flow prediction},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Rule induction in knowledge graphs using linear programming.
<em>AAAI</em>, 4233–4241. (<a
href="https://doi.org/10.1609/aaai.v37i4.25541">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present a simple linear programming (LP) based method to learn compact and interpretable sets of rules encoding the facts in a knowledge graph (KG) and use these rules to solve the KG completion problem. Our LP model chooses a set of rules of bounded complexity from a list of candidate first-order logic rules and assigns weights to them. The complexity bound is enforced via explicit constraints. We combine simple rule generation heuristics with our rule selection LP to obtain predictions with accuracy comparable to state-of-the-art codes, even while generating much more compact rule sets. Furthermore, when we take as input rules generated by other codes, we often improve interpretability by reducing the number of chosen rules, while maintaining accuracy.},
  archive   = {C_AAAI},
  author    = {Sanjeeb Dash and Joao Goncalves},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25541},
  pages     = {4233-4241},
  title     = {Rule induction in knowledge graphs using linear programming},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Uniform sequence better: Time interval aware data
augmentation for sequential recommendation. <em>AAAI</em>, 4225–4232.
(<a href="https://doi.org/10.1609/aaai.v37i4.25540">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Sequential recommendation is an important task to predict the next-item to access based on a sequence of interacted items. Most existing works learn user preference as the transition pattern from the previous item to the next one, ignoring the time interval between these two items. However, we observe that the time interval in a sequence may vary significantly different, and thus result in the ineffectiveness of user modeling due to the issue of preference drift. In fact, we conducted an empirical study to validate this observation, and found that a sequence with uniformly distributed time interval (denoted as uniform sequence) is more beneficial for performance improvement than that with greatly varying time interval. Therefore, we propose to augment sequence data from the perspective of time interval, which is not studied in the literature. Specifically, we design five operators (Ti-Crop, Ti-Reorder, Ti-Mask, Ti-Substitute, Ti-Insert) to transform the original non-uniform sequence to uniform sequence with the consideration of variance of time intervals. Then, we devise a control strategy to execute data augmentation on item sequences in different lengths. Finally, we implement these improvements on a state-of-the-art model CoSeRec and validate our approach on four real datasets. The experimental results show that our approach reaches significantly better performance than the other 9 competing methods. Our implementation is available: https://github.com/KingGugu/TiCoSeRec.},
  archive   = {C_AAAI},
  author    = {Yizhou Dang and Enneng Yang and Guibing Guo and Linying Jiang and Xingwei Wang and Xiaoxiao Xu and Qinghui Sun and Hong Liu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25540},
  pages     = {4225-4232},
  title     = {Uniform sequence better: Time interval aware data augmentation for sequential recommendation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Lifelong embedding learning and transfer for growing
knowledge graphs. <em>AAAI</em>, 4217–4224. (<a
href="https://doi.org/10.1609/aaai.v37i4.25539">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Existing knowledge graph (KG) embedding models have primarily focused on static KGs. However, real-world KGs do not remain static, but rather evolve and grow in tandem with the development of KG applications. Consequently, new facts and previously unseen entities and relations continually emerge, necessitating an embedding model that can quickly learn and transfer new knowledge through growth. Motivated by this, we delve into an expanding field of KG embedding in this paper, i.e., lifelong KG embedding. We consider knowledge transfer and retention of the learning on growing snapshots of a KG without having to learn embeddings from scratch. The proposed model includes a masked KG autoencoder for embedding learning and update, with an embedding transfer strategy to inject the learned knowledge into the new entity and relation embeddings, and an embedding regularization method to avoid catastrophic forgetting. To investigate the impacts of different aspects of KG growth, we construct four datasets to evaluate the performance of lifelong KG embedding. Experimental results show that the proposed model outperforms the state-of-the-art inductive and lifelong embedding baselines.},
  archive   = {C_AAAI},
  author    = {Yuanning Cui and Yuxin Wang and Zequn Sun and Wenqiang Liu and Yiqiao Jiang and Kexin Han and Wei Hu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25539},
  pages     = {4217-4224},
  title     = {Lifelong embedding learning and transfer for growing knowledge graphs},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning representations of bi-level knowledge graphs for
reasoning beyond link prediction. <em>AAAI</em>, 4208–4216. (<a
href="https://doi.org/10.1609/aaai.v37i4.25538">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Knowledge graphs represent known facts using triplets. While existing knowledge graph embedding methods only consider the connections between entities, we propose considering the relationships between triplets. For example, let us consider two triplets T1 and T2 where T1 is (Academy_Awards, Nominates, Avatar) and T2 is (Avatar, Wins, Academy_Awards). Given these two base-level triplets, we see that T1 is a prerequisite for T2. In this paper, we define a higher-level triplet to represent a relationship between triplets, e.g., where PrerequisiteFor is a higher-level relation. We define a bi-level knowledge graph that consists of the base-level and the higher-level triplets. We also propose a data augmentation strategy based on the random walks on the bi-level knowledge graph to augment plausible triplets. Our model called BiVE learns embeddings by taking into account the structures of the base-level and the higher-level triplets, with additional consideration of the augmented triplets. We propose two new tasks: triplet prediction and conditional link prediction. Given a triplet T1 and a higher-level relation, the triplet prediction predicts a triplet that is likely to be connected to T1 by the higher-level relation, e.g., . The conditional link prediction predicts a missing entity in a triplet conditioned on another triplet, e.g., . Experimental results show that BiVE significantly outperforms all other methods in the two new tasks and the typical base-level link prediction in real-world bi-level knowledge graphs.},
  archive   = {C_AAAI},
  author    = {Chanyoung Chung and Joyce Jiyoung Whang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25538},
  pages     = {4208-4216},
  title     = {Learning representations of bi-level knowledge graphs for reasoning beyond link prediction},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dynamic multi-behavior sequence modeling for next item
recommendation. <em>AAAI</em>, 4199–4207. (<a
href="https://doi.org/10.1609/aaai.v37i4.25537">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Sequential Recommender Systems (SRSs) aim to predict the next item that users will consume, by modeling the user interests within their item sequences. While most existing SRSs focus on a single type of user behavior, only a few pay attention to multi-behavior sequences, although they are very common in real-world scenarios. It is challenging to effectively capture the user interests within multi-behavior sequences, because the information about user interests is entangled throughout the sequences in complex relationships. To this end, we first address the characteristics of multi-behavior sequences that should be considered in SRSs, and then propose novel methods for Dynamic Multi-behavior Sequence modeling named DyMuS, which is a light version, and DyMuS+, which is an improved version, considering the characteristics. DyMuS first encodes each behavior sequence independently, and then combines the encoded sequences using dynamic routing, which dynamically integrates information required in the final result from among many candidates, based on correlations between the sequences. DyMuS+, furthermore, applies the dynamic routing even to encoding each behavior sequence to further capture the correlations at item-level. Moreover, we release a new, large and up-to-date dataset for multi-behavior recommendation. Our experiments on DyMuS and DyMuS+ show their superiority and the significance of capturing the characteristics of multi-behavior sequences.},
  archive   = {C_AAAI},
  author    = {Junsu Cho and Dongmin Hyun and Dong won Lim and Hyeon jae Cheon and Hyoung-iel Park and Hwanjo Yu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25537},
  pages     = {4199-4207},
  title     = {Dynamic multi-behavior sequence modeling for next item recommendation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dual low-rank graph autoencoder for semantic and topological
networks. <em>AAAI</em>, 4191–4198. (<a
href="https://doi.org/10.1609/aaai.v37i4.25536">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Due to the powerful capability to gather the information of neighborhood nodes, Graph Convolutional Network (GCN) has become a widely explored hotspot in recent years. As a well-established extension, Graph AutoEncoder (GAE) succeeds in mining underlying node representations via evaluating the quality of adjacency matrix reconstruction from learned features. However, limited works on GAE were devoted to leveraging both semantic and topological graphs, and they only indirectly extracted the relationships between graphs via weights shared by features. To better capture the connections between nodes from these two types of graphs, this paper proposes a graph neural network dubbed Dual Low-Rank Graph AutoEncoder (DLR-GAE), which takes both semantic and topological homophily into consideration. Differing from prior works that share common weights between GCNs, the presented DLR-GAE conducts sustained exploration of low-rank information between two distinct graphs, and reconstructs adjacency matrices from learned latent factors and embeddings. In order to obtain valid adjacency matrices that meet certain conditions, we design some surrogates and projections to restrict the learned factor matrix. We compare the proposed model with state-of-the-art methods on several datasets, which demonstrates the superior accuracy of DLR-GAE in semi-supervised classification.},
  archive   = {C_AAAI},
  author    = {Zhaoliang Chen and Zhihao Wu and Shiping Wang and Wenzhong Guo},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25536},
  pages     = {4191-4198},
  title     = {Dual low-rank graph autoencoder for semantic and topological networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Entity-agnostic representation learning for
parameter-efficient knowledge graph embedding. <em>AAAI</em>, 4182–4190.
(<a href="https://doi.org/10.1609/aaai.v37i4.25535">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose an entity-agnostic representation learning method for handling the problem of inefficient parameter storage costs brought by embedding knowledge graphs. Conventional knowledge graph embedding methods map elements in a knowledge graph, including entities and relations, into continuous vector spaces by assigning them one or multiple specific embeddings (i.e., vector representations). Thus the number of embedding parameters increases linearly as the growth of knowledge graphs. In our proposed model, Entity-Agnostic Representation Learning (EARL), we only learn the embeddings for a small set of entities and refer to them as reserved entities. To obtain the embeddings for the full set of entities, we encode their distinguishable information from their connected relations, k-nearest reserved entities, and multi-hop neighbors. We learn universal and entity-agnostic encoders for transforming distinguishable information into entity embeddings. This approach allows our proposed EARL to have a static, efficient, and lower parameter count than conventional knowledge graph embedding methods. Experimental results show that EARL uses fewer parameters and performs better on link prediction tasks than baselines, reflecting its parameter efficiency.},
  archive   = {C_AAAI},
  author    = {Mingyang Chen and Wen Zhang and Zhen Yao and Yushan Zhu and Yang Gao and Jeff Z. Pan and Huajun Chen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25535},
  pages     = {4182-4190},
  title     = {Entity-agnostic representation learning for parameter-efficient knowledge graph embedding},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). End-to-end entity linking with hierarchical reinforcement
learning. <em>AAAI</em>, 4173–4181. (<a
href="https://doi.org/10.1609/aaai.v37i4.25534">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Entity linking (EL) is the task of linking the text segments to the referring entities in the knowledge graph, typically decomposed into mention detection, and entity disambiguation. Compared to traditional methods treating the two tasks separately, recent end-to-end entity linking methods exploit the mutual dependency between mentions and entities to achieve better performance. However, existing end-to-end EL methods have problems utilizing the dependency of mentions and entities in the task. To this end, we propose to model the EL task as a hierarchical decision-making process and design a hierarchical reinforcement learning algorithm to solve the problem. We conduct extensive experiments to show that the proposed method achieves state-of-the-art performance in several EL benchmark datasets. Our code is publicly available at https://github.com/lhlclhl/he2eel.},
  archive   = {C_AAAI},
  author    = {Lihan Chen and Tinghui Zhu and Jingping Liu and Jiaqing Liang and Yanghua Xiao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25534},
  pages     = {4173-4181},
  title     = {End-to-end entity linking with hierarchical reinforcement learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PaTeCon: A pattern-based temporal constraint mining method
for conflict detection on knowledge graphs. <em>AAAI</em>, 4166–4172.
(<a href="https://doi.org/10.1609/aaai.v37i4.25533">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Temporal facts, the facts for characterizing events that hold in specific time periods, are attracting rising attention in the knowledge graph (KG) research communities. In terms of quality management, the introduction of time restrictions brings new challenges to maintaining the temporal consistency of KGs and detecting potential temporal conflicts. Previous studies rely on manually enumerated temporal constraints to detect conflicts, which are labor-intensive and may have granularity issues. We start from the common pattern of temporal facts and constraints and propose a pattern-based temporal constraint mining method, PaTeCon. PaTeCon uses automatically determined graph patterns and their relevant statistical information over the given KG instead of human experts to generate time constraints. Specifically, PaTeCon dynamically attaches type restriction to candidate constraints according to their measuring scores. We evaluate PaTeCon on two large-scale datasets based on Wikidata and Freebase respectively, the experimental results show that pattern-based automatic constraint mining is powerful in generating valuable temporal constraints.},
  archive   = {C_AAAI},
  author    = {Jianhao Chen and Junyang Ren and Wentao Ding and Yuzhong Qu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25533},
  pages     = {4166-4172},
  title     = {PaTeCon: A pattern-based temporal constraint mining method for conflict detection on knowledge graphs},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Enhanced multi-relationships integration graph convolutional
network for inferring substitutable and complementary items.
<em>AAAI</em>, 4157–4165. (<a
href="https://doi.org/10.1609/aaai.v37i4.25532">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Understanding the relationships between items can improve the accuracy and interpretability of recommender systems. Among these relationships, the substitute and complement relationships attract the most attention in e-commerce platforms. The substitutable items are interchangeable and might be compared with each other before purchasing, while the complementary items are used in conjunction and are usually bought together with the query item. In this paper, we focus on two issues of inferring the substitutable and complementary items: 1) how to model their mutual influence to improve the performance of downstream tasks, 2) how to further discriminate them by considering the strength of relationship for different item pairs. We propose a novel multi-task learning framework named Enhanced Multi-Relationships Integration Graph Convolutional Network (EMRIGCN). We regard the relationship inference task as a link prediction task in heterogeneous graph with different types of edges between nodes (items). To model the mutual influence between substitute and complement, EMRIGCN adopts a two-level integration module, i.e., feature and structure integration, based on experts sharing mechanism during message passing. To obtain the strength of relationship for item pairs, we build an auxiliary loss function to further increase or decrease the distances between embeddings of items with weak or strong relation in latent space. Extensive experiments on both public and industrial datasets prove that EMRIGCN significantly outperforms the state-of-the-art solutions. We also conducted A/B tests on real world recommender systems of Meituan Maicai, an online supermarket platform in China, and obtained 15.3\% improvement on VBR and 15.34\% improvement on RPM.},
  archive   = {C_AAAI},
  author    = {Huajie Chen and Jiyuan He and Weisheng Xu and Tao Feng and Ming Liu and Tianyu Song and Runfeng Yao and Yuanyuan Qiao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25532},
  pages     = {4157-4165},
  title     = {Enhanced multi-relationships integration graph convolutional network for inferring substitutable and complementary items},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Win-win: A privacy-preserving federated framework for
dual-target cross-domain recommendation. <em>AAAI</em>, 4149–4156. (<a
href="https://doi.org/10.1609/aaai.v37i4.25531">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Cross-domain recommendation (CDR) aims to alleviate the data sparsity by transferring knowledge from an informative source domain to the target domain, which inevitably proposes stern challenges to data privacy and transferability during the transfer process. A small amount of recent CDR works have investigated privacy protection, while they still suffer from satisfying practical requirements (e.g., limited privacy-preserving ability) and preventing the potential risk of negative transfer. To address the above challenging problems, we propose a novel and unified privacy-preserving federated framework for dual-target CDR, namely P2FCDR. We design P2FCDR as peer-to-peer federated network architecture to ensure the local data storage and privacy protection of business partners. Specifically, for the special knowledge transfer process in CDR under federated settings, we initialize an optimizable orthogonal mapping matrix to learn the embedding transformation across domains and adopt the local differential privacy technique on the transformed embedding before exchanging across domains, which provides more reliable privacy protection. Furthermore, we exploit the similarity between in-domain and cross-domain embedding, and develop a gated selecting vector to refine the information fusion for more accurate dual transfer. Extensive experiments on three real-world datasets demonstrate that P2FCDR significantly outperforms the state-of-the-art methods and effectively protects data privacy.},
  archive   = {C_AAAI},
  author    = {Gaode Chen and Xinghua Zhang and Yijun Su and Yantong Lai and Ji Xiang and Junbo Zhang and Yu Zheng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25531},
  pages     = {4149-4156},
  title     = {Win-win: A privacy-preserving federated framework for dual-target cross-domain recommendation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). LANCER: A lifetime-aware news recommender system.
<em>AAAI</em>, 4141–4148. (<a
href="https://doi.org/10.1609/aaai.v37i4.25530">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {From the observation that users reading news tend to not click outdated news, we propose the notion of &#39;lifetime&#39; of news, with two hypotheses: (i) news has a shorter lifetime, compared to other types of items such as movies or e-commerce products; (ii) news only competes with other news whose lifetimes have not ended, and which has an overlapping lifetime (i.e., limited competitions). By further developing the characteristics of the lifetime of news, then we present a novel approach for news recommendation, namely, Lifetime-Aware News reCommEndeR System (LANCER) that carefully exploits the lifetime of news during training and recommendation. Using real-world news datasets (e.g., Adressa and MIND), we successfully demonstrate that state-of-the-art news recommendation models can get significantly benefited by integrating the notion of lifetime and LANCER, by up to about 40\% increases in recommendation accuracy.},
  archive   = {C_AAAI},
  author    = {Hong-Kyun Bae and Jeewon Ahn and Dongwon Lee and Sang-Wook Kim},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25530},
  pages     = {4141-4148},
  title     = {LANCER: A lifetime-aware news recommender system},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Farsighted probabilistic sampling: A general strategy for
boosting local search MaxSAT solvers. <em>AAAI</em>, 4132–4139. (<a
href="https://doi.org/10.1609/aaai.v37i4.25529">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Local search has been demonstrated as an efficient approach for two practical generalizations of the MaxSAT problem, namely Partial MaxSAT (PMS) and Weighted PMS (WPMS). In this work, we observe that most local search (W)PMS solvers usually flip a single variable per iteration. Such a mechanism may lead to relatively low-quality local optimal solutions, and may limit the diversity of search directions to escape from local optima. To address this issue, we propose a general strategy, called farsighted probabilistic sampling (FPS), to replace the single flipping mechanism so as to boost the local search (W)PMS algorithms. FPS considers the benefit of continuously flipping a pair of variables in order to find higher-quality local optimal solutions. Moreover, FPS proposes an effective approach to escape from local optima by preferring the best to flip among the best sampled single variable and the best sampled variable pair. Extensive experiments demonstrate that our proposed FPS strategy significantly improves the state-of-the-art (W)PMS solvers, and FPS has an excellent generalization capability to various local search MaxSAT solvers.},
  archive   = {C_AAAI},
  author    = {Jiongzhi Zheng and Kun He and Jianrong Zhou},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25529},
  pages     = {4132-4139},
  title     = {Farsighted probabilistic sampling: A general strategy for boosting local search MaxSAT solvers},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Eliminating the impossible, whatever remains must be true:
On extracting and applying background knowledge in the context of formal
explanations. <em>AAAI</em>, 4123–4131. (<a
href="https://doi.org/10.1609/aaai.v37i4.25528">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The rise of AI methods to make predictions and decisions has led to a pressing need for more explainable artificial intelligence (XAI) methods. One common approach for XAI is to produce a post-hoc explanation, explaining why a black box ML model made a certain prediction. Formal approaches to post-hoc explanations provide succinct reasons for why a prediction was made, as well as why not another prediction was made. But these approaches assume that features are independent and uniformly distributed. While this means that “why” explanations are correct, they may be longer than required. It also means the “why not” explanations may be suspect as the counterexamples they rely on may not be meaningful. In this paper, we show how one can apply background knowledge to give more succinct “why” formal explanations, that are presumably easier to interpret by humans, and give more accurate “why not” explanations. In addition, we show how to use existing rule induction techniques to efficiently extract background information from a dataset.},
  archive   = {C_AAAI},
  author    = {Jinqiang Yu and Alexey Ignatiev and Peter J. Stuckey and Nina Narodytska and Joao Marques-Silva},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25528},
  pages     = {4123-4131},
  title     = {Eliminating the impossible, whatever remains must be true: On extracting and applying background knowledge in the context of formal explanations},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Graphs, constraints, and search for the abstraction and
reasoning corpus. <em>AAAI</em>, 4115–4122. (<a
href="https://doi.org/10.1609/aaai.v37i4.25527">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Abstraction and Reasoning Corpus (ARC) aims at benchmarking the performance of general artificial intelligence algorithms. The ARC&#39;s focus on broad generalization and few-shot learning has made it difficult to solve using pure machine learning. A more promising approach has been to perform program synthesis within an appropriately designed Domain Specific Language (DSL). However, these too have seen limited success. We propose Abstract Reasoning with Graph Abstractions (ARGA), a new object-centric framework that first represents images using graphs and then performs a search for a correct program in a DSL that is based on the abstracted graph space. The complexity of this combinatorial search is tamed through the use of constraint acquisition, state hashing, and Tabu search. An extensive set of experiments demonstrates the promise of ARGA in tackling some of the complicated object-centric tasks of the ARC rather efficiently, producing programs that are correct and easy to understand.},
  archive   = {C_AAAI},
  author    = {Yudong Xu and Elias B. Khalil and Scott Sanner},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25527},
  pages     = {4115-4122},
  title     = {Graphs, constraints, and search for the abstraction and reasoning corpus},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The expressive power of ad-hoc constraints for modelling
CSPs. <em>AAAI</em>, 4104–4114. (<a
href="https://doi.org/10.1609/aaai.v37i4.25526">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Ad-hoc constraints (also called generic constraints) are important for modelling Constraint Satisfaction Problems (CSPs). Many representations have been proposed to define ad-hoc constraints, such as tables, decision diagrams, binary constraint trees, automata and context-free grammars. However, prior works mainly focus on efficient Generalized Arc Consistency (GAC) propagators of ad-hoc constraints using the representations. In this paper, we ask a more fundamental question which bears on modelling constraints in a CSP as ad-hoc constraints, how the choice of constraints and operations affect tractability. Rather than ad-hoc constraints and their GAC propagators, our focus is on their expressive power in terms of succinctness (polysize) and cost of operations/queries (polytime). We use a large set of constraint families to investigate the expressive power of 14 existing ad-hoc constraints. We show a complete map of the succinctness of the ad-hoc constraints. We also present results on the tractability of applying various operations and queries on the ad-hoc constraints. Finally, we give case studies illustrating how our results can be useful for questions in the modelling of CSPs.},
  archive   = {C_AAAI},
  author    = {Ruiwei Wang and Roland H.C. Yap},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25526},
  pages     = {4104-4114},
  title     = {The expressive power of ad-hoc constraints for modelling CSPs},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Probabilistic generalization of backdoor trees with
application to SAT. <em>AAAI</em>, 4095–4103. (<a
href="https://doi.org/10.1609/aaai.v37i4.25525">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The concept of Strong Backdoor Sets (SBS) for Constraint Satisfaction Problems is well known as one of the attempts to exploit structural peculiarities in hard instances. However, in practice, finding an SBS for a particular instance is often harder than solving it. Recently, a probabilistic weakened variant of the SBS was introduced: in the SBS, all subproblems must be polynomially solvable, whereas in the probabilistic SBS only a large fraction ρ of them should have this property. This new variant of backdoors called ρ-backdoors makes it possible to use the Monte Carlo method and metaheuristic optimization to find ρ-backdoors with ρ very close to 1, and relatively fast. Despite the fact that in a ρ-backdoor-based decomposition a portion of hard subproblems remain, in practice the narrowing of the search space often allows solving the problem faster with such a backdoor than without it. In this paper, we significantly improve on the concept of ρ-backdoors by extending this concept to backdoor trees: we introduce ρ-backdoor trees, show the interconnections between SBS, ρ-backdoors, and the corresponding backdoor trees, and establish some new theoretical properties of backdoor trees. In the experimental part of the paper, we show that moving from the metaheuristic search for ρ-backdoors to that of ρ-backdoor trees allows drastically reducing the time required to construct the required decompositions without compromising their quality.},
  archive   = {C_AAAI},
  author    = {Alexander Semenov and Daniil Chivilikhin and Stepan Kochemazov and Ibragim Dzhiblavi},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25525},
  pages     = {4095-4103},
  title     = {Probabilistic generalization of backdoor trees with application to SAT},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Circuit minimization with QBF-based exact synthesis.
<em>AAAI</em>, 4087–4094. (<a
href="https://doi.org/10.1609/aaai.v37i4.25524">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper presents a rewriting method for Boolean circuits that minimizes small subcircuits with exact synthesis. Individual synthesis tasks are encoded as Quantified Boolean Formulas (QBFs) that capture the full flexibility for implementing multi-output subcircuits. This is in contrast to SAT-based resynthesis, where &quot;don&#39;t cares&quot; are computed for an individual gate, and replacements are confined to the circuitry used exclusively by that gate. An implementation of our method achieved substantial size reductions compared to state-of-the-art methods across a wide range of benchmark circuits.},
  archive   = {C_AAAI},
  author    = {Franz-Xaver Reichl and Friedrich Slivovsky and Stefan Szeider},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25524},
  pages     = {4087-4094},
  title     = {Circuit minimization with QBF-based exact synthesis},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generalized confidence constraints. <em>AAAI</em>,
4078–4086. (<a href="https://doi.org/10.1609/aaai.v37i4.25523">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In robust optimization, finding a solution that solely respects the constraints is not enough. Usually, the uncertainty and unknown parameters of the model are represented by random variables. In such conditions, a good solution is a solution robust to most-likely assignments of these random variables. Recently, the Confidence constraint has been introduced by Mercier-Aubin et al. in order to enforce this type of robustness in constraint programming. Unfortunately, it is restricted to a conjunction of binary inequalities In this paper, we generalize the Confidence constraint to any constraint and propose an implementation based on Multi-valued Decision Diagrams (MDDs). The Confidence constraint is defined over a vector of random variables. For a given constraint C, and given a threshold, the Confidence constraint ensures that the probability for C to be satisfied by a sample of the random variables is greater than the threshold. We propose to use MDDs to represent the constraints on the random variables. MDDs are an efficient tool for representing combinatorial constraints, thanks to their exponential compression power. Here, both random and decision variables are stored in the MDD, and propagation rules are proposed for removing values of decision variables that cannot lead to robust solutions. Furthermore, for several constraints, we show that decision variables can be omitted from the MDD because lighter filtering algorithms are sufficient. This leads to gain an exponential factor in the MDD size. The experimental results obtained on a chemical deliveries problem in factories – where the chemicals consumption are uncertain – shows the efficiency of the proposed approach.},
  archive   = {C_AAAI},
  author    = {Guillaume Perez and Steve Malalel and Gael Glorian and Victor Jung and Alexandre Papadopoulos and Marie Pelleau and Wijnand Suijlen and Jean-Charles Régin and Arnaud Lallouet},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25523},
  pages     = {4078-4086},
  title     = {Generalized confidence constraints},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Constraint optimization over semirings. <em>AAAI</em>,
4070–4077. (<a href="https://doi.org/10.1609/aaai.v37i4.25522">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Interpretations of logical formulas over semirings (other than the Boolean semiring) have applications in various areas of computer science including logic, AI, databases, and security. Such interpretations provide richer information beyond the truth or falsity of a statement. Examples of such semirings include Viterbi semiring, min-max or access control semiring, tropical semiring, and fuzzy semiring. The present work investigates the complexity of constraint optimization problems over semirings. The generic optimization problem we study is the following: Given a propositional formula phi over n variable and a semiring (K,+, . ,0,1), find the maximum value over all possible interpretations of phi over K. This can be seen as a generalization of the well-known satisfiability problem (a propositional formula is satisfiable if and only if the maximum value over all interpretations/assignments over the Boolean semiring is 1). A related problem is to find an interpretation that achieves the maximum value. In this work, we first focus on these optimization problems over the Viterbi semiring, which we call optConfVal and optConf. We first show that for general propositional formulas in negation normal form, optConfVal and optConf are in FP^NP. We then investigate optConf when the input formula phi is represented in the conjunctive normal form. For CNF formulae, we first derive an upper bound on the value of optConf as a function of the number of maximum satisfiable clauses. In particular, we show that if r is the maximum number of satisfiable clauses in a CNF formula with m clauses, then its optConf value is at most 1/4^(m-r). Building on this we establish that optConf for CNF formulae is hard for the complexity class FP^NP[log]. We also design polynomial-time approximation algorithms and establish an inapproximability for optConfVal. We establish similar complexity results for these optimization problems over other semirings including tropical, fuzzy, and access control semirings.},
  archive   = {C_AAAI},
  author    = {A. Pavan and Kuldeep S. Meel and N. V. Vinodchandran and Arnab Bhattacharyya},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25522},
  pages     = {4070-4077},
  title     = {Constraint optimization over semirings},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reinforcement learning for branch-and-bound optimisation
using retrospective trajectories. <em>AAAI</em>, 4061–4069. (<a
href="https://doi.org/10.1609/aaai.v37i4.25521">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Combinatorial optimisation problems framed as mixed integer linear programmes (MILPs) are ubiquitous across a range of real-world applications. The canonical branch-and-bound algorithm seeks to exactly solve MILPs by constructing a search tree of increasingly constrained sub-problems. In practice, its solving time performance is dependent on heuristics, such as the choice of the next variable to constrain (&#39;branching&#39;). Recently, machine learning (ML) has emerged as a promising paradigm for branching. However, prior works have struggled to apply reinforcement learning (RL), citing sparse rewards, difficult exploration, and partial observability as significant challenges. Instead, leading ML methodologies resort to approximating high quality handcrafted heuristics with imitation learning (IL), which precludes the discovery of novel policies and requires expensive data labelling. In this work, we propose retro branching; a simple yet effective approach to RL for branching. By retrospectively deconstructing the search tree into multiple paths each contained within a sub-tree, we enable the agent to learn from shorter trajectories with more predictable next states. In experiments on four combinatorial tasks, our approach enables learning-to-branch without any expert guidance or pre-training. We outperform the current state-of-the-art RL branching algorithm by 3-5x and come within 20\% of the best IL method&#39;s performance on MILPs with 500 constraints and 1000 variables, with ablations verifying that our retrospectively constructed trajectories are essential to achieving these results.},
  archive   = {C_AAAI},
  author    = {Christopher W. F. Parsonson and Alexandre Laterre and Thomas D. Barrett},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25521},
  pages     = {4061-4069},
  title     = {Reinforcement learning for branch-and-bound optimisation using retrospective trajectories},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-supervised primal-dual learning for constrained
optimization. <em>AAAI</em>, 4052–4060. (<a
href="https://doi.org/10.1609/aaai.v37i4.25520">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper studies how to train machine-learning models that directly approximate the optimal solutions of constrained optimization problems. This is an empirical risk minimization under constraints, which is challenging as training must balance optimality and feasibility conditions. Supervised learning methods often approach this challenge by training the model on a large collection of pre-solved instances. This paper takes a different route and proposes the idea of Primal-Dual Learning (PDL), a self-supervised training method that does not require a set of pre-solved instances or an optimization solver for training and inference. Instead, PDL mimics the trajectory of an Augmented Lagrangian Method (ALM) and jointly trains primal and dual neural networks. Being a primal-dual method, PDL uses instance-specific penalties of the constraint terms in the loss function used to train the primal network. Experiments show that, on a set of nonlinear optimization benchmarks, PDL typically exhibits negligible constraint violations and minor optimality gaps, and is remarkably close to the ALM optimization. PDL also demonstrated improved or similar performance in terms of the optimality gaps, constraint violations, and training times compared to existing approaches.},
  archive   = {C_AAAI},
  author    = {Seonho Park and Pascal Van Hentenryck},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25520},
  pages     = {4052-4060},
  title     = {Self-supervised primal-dual learning for constrained optimization},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hybrid learning with new value function for the maximum
common induced subgraph problem. <em>AAAI</em>, 4044–4051. (<a
href="https://doi.org/10.1609/aaai.v37i4.25519">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Maximum Common Induced Subgraph (MCIS) is an important NP-hard problem with wide real-world applications. An efficient class of MCIS algorithms uses Branch-and-Bound (BnB), consisting in successively selecting vertices to match and pruning when it is discovered that a solution better than the best solution found so far does not exist. The method of selecting the vertices to match is essential for the performance of BnB. In this paper, we propose a new value function and a hybrid selection strategy used in reinforcement learning to define a new vertex selection method, and propose a new BnB algorithm, called McSplitDAL, for MCIS. Extensive experiments show that McSplitDAL significantly improves the current best BnB algorithms, McSplit+LL and McSplit+RL. An empirical analysis is also performed to illustrate why the new value function and the hybrid selection strategy are effective.},
  archive   = {C_AAAI},
  author    = {Yanli Liu and Jiming Zhao and Chu-Min Li and Hua Jiang and Kun He},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25519},
  pages     = {4044-4051},
  title     = {Hybrid learning with new value function for the maximum common induced subgraph problem},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Finding good partial assignments during restart-based branch
and bound search. <em>AAAI</em>, 4035–4043. (<a
href="https://doi.org/10.1609/aaai.v37i4.25518">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Restart-based Branch-and-Bound Search (BBS) is a standard algorithm for solving Constraint Optimization Problems (COPs). In this paper, we propose an approach to find good partial assignments to jumpstart search at each restart for general COPs, which are identified by comparing different best solutions found in different restart runs. We consider information extracted from historical solutions to evaluate the quality of the partial assignments. Thus the good partial assignments are dynamically updated as the current best solution evolves. Our approach makes restart-based BBS explore different promising sub-search-spaces to find high-quality solutions. Experiments on the MiniZinc benchmark suite show how our approach brings significant improvements to a black-box COP solver equipped with the state of the art search techniques. Our method finds better solutions and proves optimality for more instances.},
  archive   = {C_AAAI},
  author    = {Hongbo Li and Jimmy H.M. Lee},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25518},
  pages     = {4035-4043},
  title     = {Finding good partial assignments during restart-based branch and bound search},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fast converging anytime model counting. <em>AAAI</em>,
4025–4034. (<a href="https://doi.org/10.1609/aaai.v37i4.25517">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Model counting is a fundamental problem which has been influential in many applications, from artificial intelligence to formal verification. Due to the intrinsic hardness of model counting, approximate techniques have been developed to solve real-world instances of model counting. This paper designs a new anytime approach called PartialKC for approximate model counting. The idea is a form of partial knowledge compilation to provide an unbiased estimate of the model count which can converge to the exact count. Our empirical analysis demonstrates that PartialKC achieves significant scalability and accuracy over prior state-of-the-art approximate counters, including satss and STS. Interestingly, the empirical results show that PartialKC reaches convergence for many instances and therefore provides exact model counting performance comparable to state-of-the-art exact counters.},
  archive   = {C_AAAI},
  author    = {Yong Lai and Kuldeep S. Meel and Roland H.C. Yap},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25517},
  pages     = {4025-4034},
  title     = {Fast converging anytime model counting},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning markov random fields for combinatorial structures
via sampling through lovász local lemma. <em>AAAI</em>, 4016–4024. (<a
href="https://doi.org/10.1609/aaai.v37i4.25516">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Learning to generate complex combinatorial structures satisfying constraints will have transformative impacts in many application domains. However, it is beyond the capabilities of existing approaches due to the highly intractable nature of the embedded probabilistic inference. Prior works spend most of the training time learning to separate valid from invalid structures but do not learn the inductive biases of valid structures. We develop NEural Lovasz Sampler (NELSON), which embeds the sampler through Lovasz Local Lemma (LLL) as a fully differentiable neural network layer. Our NELSON-CD embeds this sampler into the contrastive divergence learning process of Markov random fields. NELSON allows us to obtain valid samples from the current model distribution. Contrastive divergence is then applied to separate these samples from those in the training set. NELSON is implemented as a fully differentiable neural net, taking advantage of the parallelism of GPUs. Experimental results on several real-world domains reveal that NELSON learns to generate 100\% valid structures, while baselines either time out or cannot ensure validity. NELSON also outperforms other approaches in running time, log-likelihood, and MAP scores.},
  archive   = {C_AAAI},
  author    = {Nan Jiang and Yi Gu and Yexiang Xue},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25516},
  pages     = {4016-4024},
  title     = {Learning markov random fields for combinatorial structures via sampling through lovász local lemma},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Second-order quantified boolean logic. <em>AAAI</em>,
4007–4015. (<a href="https://doi.org/10.1609/aaai.v37i4.25515">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Second-order quantified Boolean formulas (SOQBFs) generalize quantified Boolean formulas (QBFs) by admitting second-order quantifiers on function variables in addition to first-order quantifiers on atomic variables. Recent endeavors establish that the complexity of SOQBF satisfiability corresponds to the exponential-time hierarchy (EXPH), similar to that of QBF satisfiability corresponding to the polynomial-time hierarchy (PH). This fact reveals the succinct expression power of SOQBFs in encoding decision problems not efficiently doable by QBFs. In this paper, we investigate the second-order quantified Boolean logic with the following main results: First, we present a procedure of quantifier elimination converting SOQBFs to QBFs and a game interpretation of SOQBF semantics. Second, we devise a sound and complete refutation-proof system for SOQBF. Third, we develop an algorithm for countermodel extraction from a refutation proof. Finally, we show potential applications of SOQBFs in system design and multi-agent planning. With these advances, we anticipate practical tools for development.},
  archive   = {C_AAAI},
  author    = {Jie-Hong R. Jiang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25515},
  pages     = {4007-4015},
  title     = {Second-order quantified boolean logic},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Solving explainability queries with quantification: The case
of feature relevancy. <em>AAAI</em>, 3996–4006. (<a
href="https://doi.org/10.1609/aaai.v37i4.25514">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Trustable explanations of machine learning (ML) models are vital in high-risk uses of artificial intelligence (AI). Apart from the computation of trustable explanations, a number of explainability queries have been identified and studied in recent work. Some of these queries involve solving quantification problems, either in propositional or in more expressive logics. This paper investigates one of these quantification problems, namely the feature relevancy problem (FRP), i.e.\ to decide whether a (possibly sensitive) feature can occur in some explanation of a prediction. In contrast with earlier work, that studied FRP for specific classifiers, this paper proposes a novel algorithm for the \fprob quantification problem which is applicable to any ML classifier that meets minor requirements. Furthermore, the paper shows that the novel algorithm is efficient in practice. The experimental results, obtained using random forests (RFs) induced from well-known publicly available datasets, demonstrate that the proposed solution outperforms existing state-of-the-art solvers for Quantified Boolean Formulas (QBF) by orders of magnitude. Finally, the paper also identifies a novel family of formulas that are challenging for currently state-of-the-art QBF solvers.},
  archive   = {C_AAAI},
  author    = {Xuanxiang Huang and Yacine Izza and Joao Marques-Silva},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25514},
  pages     = {3996-4006},
  title     = {Solving explainability queries with quantification: The case of feature relevancy},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Predict+optimize for packing and covering LPs with unknown
parameters in constraints. <em>AAAI</em>, 3987–3995. (<a
href="https://doi.org/10.1609/aaai.v37i4.25513">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Predict+Optimize is a recently proposed framework which combines machine learning and constrained optimization, tackling optimization problems that contain parameters that are unknown at solving time. The goal is to predict the unknown parameters and use the estimates to solve for an estimated optimal solution to the optimization problem. However, all prior works have focused on the case where unknown parameters appear only in the optimization objective and not the constraints, for the simple reason that if the constraints were not known exactly, the estimated optimal solution might not even be feasible under the true parameters. The contributions of this paper are two-fold. First, we propose a novel and practically relevant framework for the Predict+Optimize setting, but with unknown parameters in both the objective and the constraints. We introduce the notion of a correction function, and an additional penalty term in the loss function, modelling practical scenarios where an estimated optimal solution can be modified into a feasible solution after the true parameters are revealed, but at an additional cost. Second, we propose a corresponding algorithmic approach for our framework, which handles all packing and covering linear programs. Our approach is inspired by the prior work of Mandi and Guns, though with crucial modifications and re-derivations for our very different setting. Experimentation demonstrates the superior empirical performance of our method over classical approaches.},
  archive   = {C_AAAI},
  author    = {Xinyi Hu and Jasper C.H. Lee and Jimmy H.M. Lee},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25513},
  pages     = {3987-3995},
  title     = {Predict+Optimize for packing and covering LPs with unknown parameters in constraints},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). An improved approximation algorithm for wage determination
and online task allocation in crowd-sourcing. <em>AAAI</em>, 3977–3986.
(<a href="https://doi.org/10.1609/aaai.v37i4.25512">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Crowd-sourcing has attracted much attention due to its growing importance to society, and numerous studies have been conducted on task allocation and wage determination. Recent works have focused on optimizing task allocation and workers&#39; wages, simultaneously. However, existing methods do not provide good solutions for real-world crowd-sourcing platforms due to the low approximation ratio or myopic problem settings. We tackle an optimization problem for wage determination and online task allocation in crowd-sourcing and propose a fast 1-1/(k+3)^(1/2)-approximation algorithm, where k is the minimum of tasks&#39; budgets (numbers of possible assignments). This approximation ratio is greater than or equal to the existing method. The proposed method reduces the tackled problem to a non-convex multi-period continuous optimization problem by approximating the objective function. Then, the method transforms the reduced problem into a minimum convex cost flow problem, which is a well-known combinatorial optimization problem, and solves it by the capacity scaling algorithm. Synthetic experiments and simulation experiments using real crowd-sourcing data show that the proposed method solves the problem faster and outputs higher objective values than existing methods.},
  archive   = {C_AAAI},
  author    = {Yuya Hikima and Yasunori Akagi and Hideaki Kim and Taichi Asami},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25512},
  pages     = {3977-3986},
  title     = {An improved approximation algorithm for wage determination and online task allocation in crowd-sourcing},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A framework to design approximation algorithms for finding
diverse solutions in combinatorial problems. <em>AAAI</em>, 3968–3976.
(<a href="https://doi.org/10.1609/aaai.v37i4.25511">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Finding a \emph{single} best solution is the most common objective in combinatorial optimization problems. However, such a single solution may not be applicable to real-world problems as objective functions and constraints are only ``approximately&#39;&#39; formulated for original real-world problems. To solve this issue, finding \emph{multiple} solutions is a natural direction, and diversity of solutions is an important concept in this context. Unfortunately, finding diverse solutions is much harder than finding a single solution. To cope with the difficulty, we investigate the approximability of finding diverse solutions. As a main result, we propose a framework to design approximation algorithms for finding diverse solutions, which yields several outcomes including constant-factor approximation algorithms for finding diverse matchings in graphs and diverse common bases in two matroids and PTASes for finding diverse minimum cuts and interval schedulings.},
  archive   = {C_AAAI},
  author    = {Tesshu Hanaka and Masashi Kiyomi and Yasuaki Kobayashi and Yusuke Kobayashi and Kazuhiro Kurita and Yota Otachi},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25511},
  pages     = {3968-3976},
  title     = {A framework to design approximation algorithms for finding diverse solutions in combinatorial problems},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Submodular maximization under the intersection of matroid
and knapsack constraints. <em>AAAI</em>, 3959–3967. (<a
href="https://doi.org/10.1609/aaai.v37i4.25510">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Submodular maximization arises in many applications, and has attracted a lot of research attentions from various areas such as artificial intelligence, finance and operations research. Previous studies mainly consider only one kind of constraint, while many real-world problems often involve several constraints. In this paper, we consider the problem of submodular maximization under the intersection of two commonly used constraints, i.e., k-matroid constraint and m-knapsack constraint, and propose a new algorithm SPROUT by incorporating partial enumeration into the simultaneous greedy framework. We prove that SPROUT can achieve a polynomial-time approximation guarantee better than the state-of-the-art algorithms. Then, we introduce the random enumeration and smooth techniques into SPROUT to improve its efficiency, resulting in the SPROUT++ algorithm, which can keep a similar approximation guarantee. Experiments on the applications of movie recommendation and weighted max-cut demonstrate the superiority of SPROUT++ in practice.},
  archive   = {C_AAAI},
  author    = {Yu-Ran Gu and Chao Bian and Chao Qian},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25510},
  pages     = {3959-3967},
  title     = {Submodular maximization under the intersection of matroid and knapsack constraints},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SharpSSAT: A witness-generating stochastic boolean
satisfiability solver. <em>AAAI</em>, 3949–3958. (<a
href="https://doi.org/10.1609/aaai.v37i4.25509">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Stochastic Boolean satisfiability (SSAT) is a formalism allowing decision-making for optimization under quantitative constraints. Although SSAT solvers are under active development, existing solvers do not provide Skolem-function witnesses, which are crucial for practical applications. In this work, we develop a new witness-generating SSAT solver, SharpSSAT, which integrates techniques, including component caching, clause learning, and pure literal detection. It can generate a set of Skolem functions witnessing the attained satisfying probability of a given SSAT formula. We also equip the solver ClauSSat with witness generation capability for comparison. Experimental results show that SharpSSAT outperforms current state-of-the-art solvers and can effectively generate compact Skolem-function witnesses. The new witness-generating solver may broaden the applicability of SSAT to practical applications.},
  archive   = {C_AAAI},
  author    = {Yu-Wei Fan and Jie-Hong R. Jiang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25509},
  pages     = {3949-3958},
  title     = {SharpSSAT: A witness-generating stochastic boolean satisfiability solver},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DASH: A distributed and parallelizable algorithm for
size-constrained submodular maximization. <em>AAAI</em>, 3941–3948. (<a
href="https://doi.org/10.1609/aaai.v37i4.25508">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {MapReduce (MR) algorithms for maximizing monotone, submodular functions subject to a cardinality constraint (SMCC) are currently restricted to the use of the linear-adaptive (non-parallelizable) algorithm GREEDY. Low-adaptive algorithms do not satisfy the requirements of these distributed MR frameworks, thereby limiting their performance. We study the SMCC problem in a distributed setting and propose the first MR algorithms with sublinear adaptive complexity. Our algorithms, R-DASH, T-DASH and G-DASH provide 0.316 - ε, 3/8 - ε , and (1 - 1/e - ε) approximation ratios, respectively, with nearly optimal adaptive complexity and nearly linear time complexity. Additionally, we provide a framework to increase, under some mild assumptions, the maximum permissible cardinality constraint from O( n / ℓ^2) of prior MR algorithms to O( n / ℓ ), where n is the data size and ℓ is the number of machines; under a stronger condition on the objective function, we increase the maximum constraint value to n. Finally, we provide empirical evidence to demonstrate that our sublinear-adaptive, distributed algorithms provide orders of magnitude faster runtime compared to current state-of-the-art distributed algorithms.},
  archive   = {C_AAAI},
  author    = {Tonmoy Dey and Yixin Chen and Alan Kuhnle},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25508},
  pages     = {3941-3948},
  title     = {DASH: A distributed and parallelizable algorithm for size-constrained submodular maximization},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Complexity of reasoning with cardinality minimality
conditions. <em>AAAI</em>, 3932–3940. (<a
href="https://doi.org/10.1609/aaai.v37i4.25507">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Many AI-related reasoning problems are based on the problem of satisfiability of propositional formulas with some cardinality-minimality condition. While the complexity of the satisfiability problem (SAT) is well understood when considering systematically all fragments of propositional logic within Schaefer’s framework, this is not the case when such minimality condition is added. We consider the CardMinSat problem, which asks, given a formula φ and an atom x, whether x is true in some cardinality-minimal model of φ. We completely classify the computational complexity of the CardMinSat problem within Schaefer’s framework, thus paving the way for a better understanding of the tractability frontier of many AI-related reasoning problems. To this end we use advanced algebraic tools.},
  archive   = {C_AAAI},
  author    = {Nadia Creignou and Frédéric Olive and Johannes Schmidt},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25507},
  pages     = {3932-3940},
  title     = {Complexity of reasoning with cardinality minimality conditions},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Separate but equal: Equality in belief propagation for
single cycle graphs. <em>AAAI</em>, 3924–3931. (<a
href="https://doi.org/10.1609/aaai.v37i4.25506">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Belief propagation is a widely used incomplete optimization algorithm, whose main theoretical properties hold only under the assumptions that beliefs are not equal. Nevertheless, there is much evidence that equality between beliefs does occur. A method to overcome belief equality by using unary function-nodes is assumed to resolve the problem. We focus on Min-sum, the belief propagation version for solving constraint optimization problems. We prove that on a single cycle graph, belief equality can be avoided only when the algorithm converges to the optimal solution. In any other case, the unary function methods will not prevent equality, rendering some existing results in need of reassessment. We differentiate between belief equality, which includes equal beliefs in a single message, and assignment equality, that prevents a coherent selection of assignments to variables. We show the necessary and satisfying conditions for both.},
  archive   = {C_AAAI},
  author    = {Erel Cohen and Omer Lev and Roie Zivan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25506},
  pages     = {3924-3931},
  title     = {Separate but equal: Equality in belief propagation for single cycle graphs},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). NuWLS: Improving local search for (weighted) partial MaxSAT
by new weighting techniques. <em>AAAI</em>, 3915–3923. (<a
href="https://doi.org/10.1609/aaai.v37i4.25505">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Maximum Satisfiability (MaxSAT) is a prototypical constraint optimization problem, and its generalized version is the (Weighted) Partial MaxSAT problem, denoted as (W)PMS, which deals with hard and soft clauses. Considerable progress has been made on stochastic local search (SLS) algorithms for solving (W)PMS, which mainly focus on clause weighting techniques. In this work, we identify two issues of existing clause weighting techniques for (W)PMS, and propose two ideas correspondingly. First, we observe that the initial values of soft clause weights have a big effect on the performance of the SLS solver for solving (W)PMS, and propose a weight initialization method. Second, we propose a new clause weighting scheme that for the first time employs different conditions for updating hard and soft clause weights. Based on these two ideas, we develop a new SLS solver for (W)PMS named NuWLS. Through extensive experiments, NuWLS performs much better than existing SLS solvers on all 6 benchmarks from the incomplete tracks of MaxSAT Evaluations (MSEs) 2019, 2020, and 2021. In terms of the number of winning instances, NuWLS outperforms state-of-the-art SAT-based incomplete solvers on all the 6 benchmarks. More encouragingly, a hybrid solver that combines NuWLS and an SAT-based solver won all four categories in the incomplete track of the MaxSAT Evaluation 2022.},
  archive   = {C_AAAI},
  author    = {Yi Chu and Shaowei Cai and Chuan Luo},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25505},
  pages     = {3915-3923},
  title     = {NuWLS: Improving local search for (Weighted) partial MaxSAT by new weighting techniques},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Lifting (d)QBF preprocessing and solving techniques to
(d)SSAT. <em>AAAI</em>, 3906–3914. (<a
href="https://doi.org/10.1609/aaai.v37i4.25504">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Dependency stochastic Boolean satisfiability (DSSAT) generalizes stochastic Boolean satisfiability (SSAT) in existential variables being Henkinized allowing their dependencies on randomized variables to be explicitly specified. It allows NEXPTIME problems of reasoning under uncertainty and partial information to be compactly encoded. To date, no decision procedure has been implemented for solving DSSAT formulas. This work provides the first such tool by converting DSSAT into SSAT with dependency elimination, similar to converting dependency quantified Boolean formula (DQBF) to quantified Boolean formula (QBF). Moreover, we extend (D)QBF preprocessing techniques and implement the first standalone (D)SSAT preprocessor. Experimental results show that solving DSSAT via dependency elimination is highly applicable and that existing SSAT solvers may benefit from preprocessing.},
  archive   = {C_AAAI},
  author    = {Che Cheng and Jie-Hong R. Jiang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25504},
  pages     = {3906-3914},
  title     = {Lifting (D)QBF preprocessing and solving techniques to (D)SSAT},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improved algorithms for maximum satisfiability and its
special cases. <em>AAAI</em>, 3898–3905. (<a
href="https://doi.org/10.1609/aaai.v37i4.25503">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Maximum Satisfiability (MAXSAT) problem is an optimization version of the Satisfiability problem (SAT) in which one is given a CNF formula with n variables and needs to find the maximum number of simultaneously satisfiable clauses. Recent works achieved significant progress in proving new upper bounds on the worst-case computational complexity of MAXSAT. All these works reduce general MAXSAT to a special case of MAXSAT where each variable appears a small number of times. So, it is important to design fast algorithms for (n,k)-MAXSAT to construct an efficient exact algorithm for MAXSAT. (n,k)-MAXSAT is a special case of MAXSAT where each variable appears at most k times in the input formula. For the (n,3)-MAXSAT problem, we design a O*(1.1749^n) algorithm improving on the previous record running time of O*(1.191^n). For the (n,4)-MAXSAT problem, we construct a O*(1.3803^n) algorithm improving on the previous best running time of O*(1.4254^n). Using the results, we develop a O*(1.0911^L) algorithm for the MAXSAT where L is a length of the input formula which improves previous algorithm with O*(1.0927^L) running time.},
  archive   = {C_AAAI},
  author    = {Kirill Brilliantov and Vasily Alferov and Ivan Bliznets},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i4.25503},
  pages     = {3898-3905},
  title     = {Improved algorithms for maximum satisfiability and its special cases},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generative image inpainting with segmentation confusion
adversarial training and contrastive learning. <em>AAAI</em>, 3888–3896.
(<a href="https://doi.org/10.1609/aaai.v37i3.25502">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper presents a new adversarial training framework for image inpainting with segmentation confusion adversarial training (SCAT) and contrastive learning. SCAT plays an adversarial game between an inpainting generator and a segmentation network, which provides pixel-level local training signals and can adapt to images with free-form holes. By combining SCAT with standard global adversarial training, the new adversarial training framework exhibits the following three advantages simultaneously: (1) the global consistency of the repaired image, (2) the local fine texture details of the repaired image, and (3) the flexibility of handling images with free-form holes. Moreover, we propose the textural and semantic contrastive learning losses to stabilize and improve our inpainting model&#39;s training by exploiting the feature representation space of the discriminator, in which the inpainting images are pulled closer to the ground truth images but pushed farther from the corrupted images. The proposed contrastive losses better guide the repaired images to move from the corrupted image data points to the real image data points in the feature representation space, resulting in more realistic completed images. We conduct extensive experiments on two benchmark datasets, demonstrating our model&#39;s effectiveness and superiority both qualitatively and quantitatively.},
  archive   = {C_AAAI},
  author    = {Zhiwen Zuo and Lei Zhao and Ailin Li and Zhizhong Wang and Zhanjie Zhang and Jiafu Chen and Wei Xing and Dongming Lu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25502},
  pages     = {3888-3896},
  title     = {Generative image inpainting with segmentation confusion adversarial training and contrastive learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learn more for food recognition via progressive
self-distillation. <em>AAAI</em>, 3879–3887. (<a
href="https://doi.org/10.1609/aaai.v37i3.25501">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Food recognition has a wide range of applications, such as health-aware recommendation and self-service restaurants. Most previous methods of food recognition firstly locate informative regions in some weakly-supervised manners and then aggregate their features. However, location errors of informative regions limit the effectiveness of these methods to some extent. Instead of locating multiple regions, we propose a Progressive Self-Distillation (PSD) method, which progressively enhances the ability of network to mine more details for food recognition. The training of PSD simultaneously contains multiple self-distillations, in which a teacher network and a student network share the same embedding network. Since the student network receives a modified image from its teacher network by masking some informative regions, the teacher network outputs stronger semantic representations than the student network. Guided by such teacher network with stronger semantics, the student network is encouraged to mine more useful regions from the modified image by enhancing its own ability. The ability of the teacher network is also enhanced with the shared embedding network. By using progressive training, the teacher network incrementally improves its ability to mine more discriminative regions. In inference phase, only the teacher network is used without the help of the student network. Extensive experiments on three datasets demonstrate the effectiveness of our proposed method and state-of-the-art performance.},
  archive   = {C_AAAI},
  author    = {Yaohui Zhu and Linhu Liu and Jiang Tian},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25501},
  pages     = {3879-3887},
  title     = {Learn more for food recognition via progressive self-distillation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RGBD1K: A large-scale dataset and benchmark for RGB-d object
tracking. <em>AAAI</em>, 3870–3878. (<a
href="https://doi.org/10.1609/aaai.v37i3.25500">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {RGB-D object tracking has attracted considerable attention recently, achieving promising performance thanks to the symbiosis between visual and depth channels. However, given a limited amount of annotated RGB-D tracking data, most state-of-the-art RGB-D trackers are simple extensions of high-performance RGB-only trackers, without fully exploiting the underlying potential of the depth channel in the offline training stage. To address the dataset deficiency issue, a new RGB-D dataset named RGBD1K is released in this paper. The RGBD1K contains 1,050 sequences with about 2.5M frames in total. To demonstrate the benefits of training on a larger RGB-D data set in general, and RGBD1K in particular, we develop a transformer-based RGB-D tracker, named SPT, as a baseline for future visual object tracking studies using the new dataset. The results, of extensive experiments using the SPT tracker demonstrate the potential of the RGBD1K dataset to improve the performance of RGB-D tracking, inspiring future developments of effective tracker designs. The dataset and codes will be available on the project homepage: https://github.com/xuefeng-zhu5/RGBD1K.},
  archive   = {C_AAAI},
  author    = {Xue-Feng Zhu and Tianyang Xu and Zhangyong Tang and Zucheng Wu and Haodong Liu and Xiao Yang and Xiao-Jun Wu and Josef Kittler},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25500},
  pages     = {3870-3878},
  title     = {RGBD1K: A large-scale dataset and benchmark for RGB-D object tracking},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Gradient-based graph attention for scene text image
super-resolution. <em>AAAI</em>, 3861–3869. (<a
href="https://doi.org/10.1609/aaai.v37i3.25499">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Scene text image super-resolution (STISR) in the wild has been shown to be beneficial to support improved vision-based text recognition from low-resolution imagery. An intuitive way to enhance STISR performance is to explore the well-structured and repetitive layout characteristics of text and exploit these as prior knowledge to guide model convergence. In this paper, we propose a novel gradient-based graph attention method to embed patch-wise text layout contexts into image feature representations for high-resolution text image reconstruction in an implicit and elegant manner. We introduce a non-local group-wise attention module to extract text features which are then enhanced by a cascaded channel attention module and a novel gradient-based graph attention module in order to obtain more effective representations by exploring correlations of regional and local patch-wise text layout properties. Extensive experiments on the benchmark TextZoom dataset convincingly demonstrate that our method supports excellent text recognition and outperforms the current state-of-the-art in STISR. The source code is available at https://github.com/xyzhu1/TSAN.},
  archive   = {C_AAAI},
  author    = {Xiangyuan Zhu and Kehua Guo and Hui Fang and Rui Ding and Zheng Wu and Gerald Schaefer},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25499},
  pages     = {3861-3869},
  title     = {Gradient-based graph attention for scene text image super-resolution},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SRoUDA: Meta self-training for robust unsupervised domain
adaptation. <em>AAAI</em>, 3852–3860. (<a
href="https://doi.org/10.1609/aaai.v37i3.25498">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As acquiring manual labels on data could be costly, unsupervised domain adaptation (UDA), which transfers knowledge learned from a rich-label dataset to the unlabeled target dataset, is gaining increasingly more popularity. While extensive studies have been devoted to improving the model accuracy on target domain, an important issue of model robustness is neglected. To make things worse, conventional adversarial training (AT) methods for improving model robustness are inapplicable under UDA scenario since they train models on adversarial examples that are generated by supervised loss function. In this paper, we present a new meta self-training pipeline, named SRoUDA, for improving adversarial robustness of UDA models. Based on self-training paradigm, SRoUDA starts with pre-training a source model by applying UDA baseline on source labeled data and taraget unlabeled data with a developed random masked augmentation (RMA), and then alternates between adversarial target model training on pseudo-labeled target data and fine-tuning source model by a meta step. While self-training allows the direct incorporation of AT in UDA, the meta step in SRoUDA further helps in mitigating error propagation from noisy pseudo labels. Extensive experiments on various benchmark datasets demonstrate the state-of-the-art performance of SRoUDA where it achieves significant model robustness improvement without harming clean accuracy.},
  archive   = {C_AAAI},
  author    = {Wanqing Zhu and Jia-Li Yin and Bo-Hao Chen and Ximeng Liu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25498},
  pages     = {3852-3860},
  title     = {SRoUDA: Meta self-training for robust unsupervised domain adaptation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving scene text image super-resolution via dual prior
modulation network. <em>AAAI</em>, 3843–3851. (<a
href="https://doi.org/10.1609/aaai.v37i3.25497">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Scene text image super-resolution (STISR) aims to simultaneously increase the resolution and legibility of the text images, and the resulting images will significantly affect the performance of downstream tasks. Although numerous progress has been made, existing approaches raise two crucial issues: (1) They neglect the global structure of the text, which bounds the semantic determinism of the scene text. (2) The priors, e.g., text prior or stroke prior, employed in existing works, are extracted from pre-trained text recognizers. That said, such priors suffer from the domain gap including low resolution and blurriness caused by poor imaging conditions, leading to incorrect guidance. Our work addresses these gaps and proposes a plug-and-play module dubbed Dual Prior Modulation Network (DPMN), which leverages dual image-level priors to bring performance gain over existing approaches. Specifically, two types of prior-guided refinement modules, each using the text mask or graphic recognition result of the low-quality SR image from the preceding layer, are designed to improve the structural clarity and semantic accuracy of the text, respectively. The following attention mechanism hence modulates two quality-enhanced images to attain a superior SR result. Extensive experiments validate that our method improves the image quality and boosts the performance of downstream tasks over five typical approaches on the benchmark. Substantial visualizations and ablation studies demonstrate the advantages of the proposed DPMN. Code is available at: https://github.com/jdfxzzy/DPMN.},
  archive   = {C_AAAI},
  author    = {Shipeng Zhu and Zuoyan Zhao and Pengfei Fang and Hui Xue},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25497},
  pages     = {3843-3851},
  title     = {Improving scene text image super-resolution via dual prior modulation network},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Debiased fine-tuning for vision-language models by prompt
regularization. <em>AAAI</em>, 3834–3842. (<a
href="https://doi.org/10.1609/aaai.v37i3.25496">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present a new paradigm for fine-tuning large-scale vision-language pre-trained models on downstream task, dubbed Prompt Regularization (ProReg). Different from traditional fine-tuning which easily overfits to the downstream task data, ProReg uses the prediction by prompting the pretrained model to regularize the fine-tuning. The motivation is: by prompting the large model “a photo of a [CLASS]”, the fill-in answer is only dependent on the pretraining encyclopedic knowledge while independent of the task data distribution, which is usually biased. Specifically, given a training sample prediction during fine-tuning, we first calculate its Kullback-Leibler loss of the prompt prediction and Cross-Entropy loss of the ground-truth label, and then combine them with a proposed sample-wise adaptive trade- off weight, which automatically adjusts the transfer between the pretrained and downstream domains. On various out-of-distribution benchmarks, we show the consistently strong performance of ProReg compared with conventional fine-tuning, zero-shot prompt, prompt tuning, and other state-of-the-art methods.},
  archive   = {C_AAAI},
  author    = {Beier Zhu and Yulei Niu and Saeil Lee and Minhoe Hur and Hanwang Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25496},
  pages     = {3834-3842},
  title     = {Debiased fine-tuning for vision-language models by prompt regularization},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-supervised action representation learning from partial
spatio-temporal skeleton sequences. <em>AAAI</em>, 3825–3833. (<a
href="https://doi.org/10.1609/aaai.v37i3.25495">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Self-supervised learning has demonstrated remarkable capability in representation learning for skeleton-based action recognition. Existing methods mainly focus on applying global data augmentation to generate different views of the skeleton sequence for contrastive learning. However, due to the rich action clues in the skeleton sequences, existing methods may only take a global perspective to learn to discriminate different skeletons without thoroughly leveraging the local relationship between different skeleton joints and video frames, which is essential for real-world applications. In this work, we propose a Partial Spatio-Temporal Learning (PSTL) framework to exploit the local relationship from a partial skeleton sequences built by a unique spatio-temporal masking strategy. Specifically, we construct a negative-sample-free triplet steam structure that is composed of an anchor stream without any masking, a spatial masking stream with Central Spatial Masking (CSM), and a temporal masking stream with Motion Attention Temporal Masking (MATM). The feature cross-correlation matrix is measured between the anchor stream and the other two masking streams, respectively. (1) Central Spatial Masking discards selected joints from the feature calculation process, where the joints with a higher degree of centrality have a higher possibility of being selected. (2) Motion Attention Temporal Masking leverages the motion of action and remove frames that move faster with a higher possibility. Our method achieves state-of-the-art performance on NTURGB+D 60, NTURGB+D 120 and PKU-MMD under various downstream tasks. Furthermore, to simulate the real-world scenarios, a practical evaluation is performed where some skeleton joints are lost in downstream tasks.In contrast to previous methods that suffer from large performance drops, our PSTL can still achieve remarkable results under this challenging setting, validating the robustness of our method.},
  archive   = {C_AAAI},
  author    = {Yujie Zhou and Haodong Duan and Anyi Rao and Bing Su and Jiaqi Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25495},
  pages     = {3825-3833},
  title     = {Self-supervised action representation learning from partial spatio-temporal skeleton sequences},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Tree-structured trajectory encoding for vision-and-language
navigation. <em>AAAI</em>, 3814–3824. (<a
href="https://doi.org/10.1609/aaai.v37i3.25494">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Over the past few years, the research on vision-and-language navigation (VLN) has made tremendous progress. Many previous works attempted to improve the performance from different aspects like training strategy, data augmentation, pre-training, etc. This work focuses on a rarely-explored aspect in VLN, namely the trajectory organization and encoding during the navigation. Most of existing state-of-the-art VLN models adopt a vanilla sequential strategy for encoding the trajectories. Such strategy takes the whole trajectory as a single sequence to estimate the current state, no matter whether the agent moved smoothly or perhaps made mistakes and backtracked in the past. We show that the sequential encoding may largely lose this kind of fine-grained structure in the trajectory, which could hamper the later state estimation and decision making. In order to solve this problem, this work proposes a novel tree-structured trajectory encoding strategy. The whole trajectory is organized as a tree rooted from the starting position, and encoded using our Tree-Transformer module to fully extract the fine-grained historical information. Besides, as the spatial topology could be easily embedded in the trajectory tree, we further design a tree-based action space to allow the agent making long-range error-correction in one decision. We implement the holistic agent based on cross-modal transformer and train it with a newly-proposed Tree-nDTW reward. On the benchmark dataset R2R, our model achieves a surpassing success rate (SR) of 68\% on val-unseen and 66\% on test. We further conduct extensive ablation studies and analyses to provide more insights for the effectiveness our designs.},
  archive   = {C_AAAI},
  author    = {Xinzhe Zhou and Yadong Mu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25494},
  pages     = {3814-3824},
  title     = {Tree-structured trajectory encoding for vision-and-language navigation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Video object of interest segmentation. <em>AAAI</em>,
3805–3813. (<a href="https://doi.org/10.1609/aaai.v37i3.25493">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this work, we present a new computer vision task named video object of interest segmentation (VOIS). Given a video and a target image of interest, our objective is to simultaneously segment and track all objects in the video that are relevant to the target image. This problem combines the traditional video object segmentation task with an additional image indicating the content that users are concerned with. Since no existing dataset is perfectly suitable for this new task, we specifically construct a large-scale dataset called LiveVideos, which contains 2418 pairs of target images and live videos with instance-level annotations. In addition, we propose a transformer-based method for this task. We revisit Swin Transformer and design a dual-path structure to fuse video and image features. Then, a transformer decoder is employed to generate object proposals for segmentation and tracking from the fused features. Extensive experiments on LiveVideos dataset show the superiority of our proposed method.},
  archive   = {C_AAAI},
  author    = {Siyuan Zhou and Chunru Zhan and Biao Wang and Tiezheng Ge and Yuning Jiang and Li Niu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25493},
  pages     = {3805-3813},
  title     = {Video object of interest segmentation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust feature rectification of pretrained vision models for
object recognition. <em>AAAI</em>, 3796–3804. (<a
href="https://doi.org/10.1609/aaai.v37i3.25492">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Pretrained vision models for object recognition often suffer a dramatic performance drop with degradations unseen during training. In this work, we propose a RObust FEature Rectification module (ROFER) to improve the performance of pretrained models against degradations. Specifically, ROFER first estimates the type and intensity of the degradation that corrupts the image features. Then, it leverages a Fully Convolutional Network (FCN) to rectify the features from the degradation by pulling them back to clear features. ROFER is a general-purpose module that can address various degradations simultaneously, including blur, noise, and low contrast. Besides, it can be plugged into pretrained models seamlessly to rectify the degraded features without retraining the whole model. Furthermore, ROFER can be easily extended to address composite degradations by adopting a beam search algorithm to find the composition order. Evaluations on CIFAR-10 and Tiny-ImageNet demonstrate that the accuracy of ROFER is 5\% higher than that of SOTA methods on different degradations. With respect to composite degradations, ROFER improves the accuracy of a pretrained CNN by 10\% and 6\% on CIFAR-10 and Tiny-ImageNet respectively.},
  archive   = {C_AAAI},
  author    = {Shengchao Zhou and Gaofeng Meng and Zhaoxiang Zhang and Richard Yi Da Xu and Shiming Xiang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25492},
  pages     = {3796-3804},
  title     = {Robust feature rectification of pretrained vision models for object recognition},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PASS: Patch automatic skip scheme for efficient real-time
video perception on edge devices. <em>AAAI</em>, 3787–3795. (<a
href="https://doi.org/10.1609/aaai.v37i3.25491">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Real-time video perception tasks are often challenging over the resource-constrained edge devices due to the concerns of accuracy drop and hardware overhead, where saving computations is the key to performance improvement. Existing methods either rely on domain-specific neural chips or priorly searched models, which require specialized optimization according to different task properties. In this work, we propose a general and task-independent Patch Automatic Skip Scheme (PASS), a novel end-to-end learning pipeline to support diverse video perception settings by decoupling acceleration and tasks. The gist is to capture the temporal similarity across video frames and skip the redundant computations at patch level, where the patch is a non-overlapping square block in visual. PASS equips each convolution layer with a learnable gate to selectively determine which patches could be safely skipped without degrading model accuracy. As to each layer, a desired gate needs to make flexible skip decisions based on intermediate features without any annotations, which cannot be achieved by conventional supervised learning paradigm. To address this challenge, we are the first to construct a tough self-supervisory procedure for optimizing these gates, which learns to extract contrastive representation, i.e., distinguishing similarity and difference, from frame sequence. These high-capacity gates can serve as a plug-and-play module for convolutional neural network (CNN) backbones to implement patch-skippable architectures, and automatically generate proper skip strategy to accelerate different video-based downstream tasks, e.g., outperforming the state-of-the-art MobileHumanPose (MHP) in 3D pose estimation and FairMOT in multiple object tracking, by up to 9.43 times and 12.19 times speedups, respectively. By directly processing the raw data of frames, PASS can generalize to real-time video streams on commodity edge devices, e.g., NVIDIA Jetson Nano, with efficient performance in realistic deployment.},
  archive   = {C_AAAI},
  author    = {Qihua Zhou and Song Guo and Jun Pan and Jiacheng Liang and Zhenda Xu and Jingren Zhou},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25491},
  pages     = {3787-3795},
  title     = {PASS: Patch automatic skip scheme for efficient real-time video perception on edge devices},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unsupervised hierarchical domain adaptation for adverse
weather optical flow. <em>AAAI</em>, 3778–3786. (<a
href="https://doi.org/10.1609/aaai.v37i3.25490">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Optical flow estimation has made great progress, but usually suffers from degradation under adverse weather. Although semi/full-supervised methods have made good attempts, the domain shift between the synthetic and real adverse weather images would deteriorate their performance. To alleviate this issue, our start point is to unsupervisedly transfer the knowledge from source clean domain to target degraded domain. Our key insight is that adverse weather does not change the intrinsic optical flow of the scene, but causes a significant difference for the warp error between clean and degraded images. In this work, we propose the first unsupervised framework for adverse weather optical flow via hierarchical motion-boundary adaptation. Specifically, we first employ image translation to construct the transformation relationship between clean and degraded domains. In motion adaptation, we utilize the flow consistency knowledge to align the cross-domain optical flows into a motion-invariance common space, where the optical flow from clean weather is used as the guidance-knowledge to obtain a preliminary optical flow for adverse weather. Furthermore, we leverage the warp error inconsistency which measures the motion misalignment of the boundary between the clean and degraded domains, and propose a joint intra- and inter-scene boundary contrastive adaptation to refine the motion boundary. The hierarchical motion and boundary adaptation jointly promotes optical flow in a unified framework. Extensive quantitative and qualitative experiments have been performed to verify the superiority of the proposed method.},
  archive   = {C_AAAI},
  author    = {Hanyu Zhou and Yi Chang and Gang Chen and Luxin Yan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25490},
  pages     = {3778-3786},
  title     = {Unsupervised hierarchical domain adaptation for adverse weather optical flow},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dual memory units with uncertainty regulation for weakly
supervised video anomaly detection. <em>AAAI</em>, 3769–3777. (<a
href="https://doi.org/10.1609/aaai.v37i3.25489">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Learning discriminative features for effectively separating abnormal events from normality is crucial for weakly supervised video anomaly detection (WS-VAD) tasks. Existing approaches, both video and segment level label oriented, mainly focus on extracting representations for anomaly data while neglecting the implication of normal data. We observe that such a scheme is sub-optimal, i.e., for better distinguishing anomaly one needs to understand what is a normal state, and may yield a higher false alarm rate. To address this issue, we propose an Uncertainty Regulated Dual Memory Units (UR-DMU) model to learn both the representations of normal data and discriminative features of abnormal data. To be specific, inspired by the traditional global and local structure on graph convolutional networks, we introduce a Global and Local Multi-Head Self Attention (GL-MHSA) module for the Transformer network to obtain more expressive embeddings for capturing associations in videos. Then, we use two memory banks, one additional abnormal memory for tackling hard samples, to store and separate abnormal and normal prototypes and maximize the margins between the two representations. Finally, we propose an uncertainty learning scheme to learn the normal data latent space, that is robust to noise from camera switching, object changing, scene transforming, etc. Extensive experiments on XD-Violence and UCF-Crime datasets demonstrate that our method outperforms the state-of-the-art methods by a sizable margin.},
  archive   = {C_AAAI},
  author    = {Hang Zhou and Junqing Yu and Wei Yang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25489},
  pages     = {3769-3777},
  title     = {Dual memory units with uncertainty regulation for weakly supervised video anomaly detection},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploratory inference learning for scribble supervised
semantic segmentation. <em>AAAI</em>, 3760–3768. (<a
href="https://doi.org/10.1609/aaai.v37i3.25488">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Scribble supervised semantic segmentation has achieved great advances in pseudo label exploitation, yet suffers insufficient label exploration for the mass of unannotated regions. In this work, we propose a novel exploratory inference learning (EIL) framework, which facilitates efficient probing on unlabeled pixels and promotes selecting confident candidates for boosting the evolved segmentation. The exploration of unannotated regions is formulated as an iterative decision-making process, where a policy searcher learns to infer in the unknown space and the reward to the exploratory policy is based on a contrastive measurement of candidates. In particular, we devise the contrastive reward with the intra-class attraction and the inter-class repulsion in the feature space w.r.t the pseudo labels. The unlabeled exploration and the labeled exploitation are jointly balanced to improve the segmentation, and framed in a close-looping end-to-end network. Comprehensive evaluations on the benchmark datasets (PASCAL VOC 2012 and PASCAL Context) demonstrate the superiority of our proposed EIL when compared with other state-of-the-art methods for the scribble-supervised semantic segmentation problem.},
  archive   = {C_AAAI},
  author    = {Chuanwei Zhou and Zhen Cui and Chunyan Xu and Cao Han and Jian Yang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25488},
  pages     = {3760-3768},
  title     = {Exploratory inference learning for scribble supervised semantic segmentation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Progressive bayesian inference for scribble-supervised
semantic segmentation. <em>AAAI</em>, 3751–3759. (<a
href="https://doi.org/10.1609/aaai.v37i3.25487">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The scribble-supervised semantic segmentation is an important yet challenging task in the field of computer vision. To deal with the pixel-wise sparse annotation problem, we propose a Progressive Bayesian Inference (PBI) framework to boost the performance of the scribble-supervised semantic segmentation, which can effectively infer the semantic distribution of these unlabeled pixels to guide the optimization of the segmentation network. The PBI dynamically improves the model learning from two aspects: the Bayesian inference module (i.e., semantic distribution learning) and the pixel-wise segmenter (i.e., model updating). Specifically, we effectively infer the semantic probability distribution of these unlabeled pixels with our designed Bayesian inference module, where its guidance is estimated through the Bayesian expectation maximization under the situation of partially observed data. The segmenter can be progressively improved under the joint guidance of the original scribble information and the learned semantic distribution. The segmenter optimization and semantic distribution promotion are encapsulated into a unified architecture where they could improve each other with mutual evolution in a progressive fashion. Comprehensive evaluations of several benchmark datasets demonstrate the effectiveness and superiority of our proposed PBI when compared with other state-of-the-art methods applied to the scribble-supervised semantic segmentation task.},
  archive   = {C_AAAI},
  author    = {Chuanwei Zhou and Chunyan Xu and Zhen Cui},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25487},
  pages     = {3751-3759},
  title     = {Progressive bayesian inference for scribble-supervised semantic segmentation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Polarization-aware low-light image enhancement.
<em>AAAI</em>, 3742–3750. (<a
href="https://doi.org/10.1609/aaai.v37i3.25486">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Polarization-based vision algorithms have found uses in various applications since polarization provides additional physical constraints. However, in low-light conditions, their performance would be severely degenerated since the captured polarized images could be noisy, leading to noticeable degradation in the degree of polarization (DoP) and the angle of polarization (AoP). Existing low-light image enhancement methods cannot handle the polarized images well since they operate in the intensity domain, without effectively exploiting the information provided by polarization. In this paper, we propose a Stokes-domain enhancement pipeline along with a dual-branch neural network to handle the problem in a polarization-aware manner. Two application scenarios (reflection removal and shape from polarization) are presented to show how our enhancement can improve their results.},
  archive   = {C_AAAI},
  author    = {Chu Zhou and Minggui Teng and Youwei Lyu and Si Li and Chao Xu and Boxin Shi},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25486},
  pages     = {3742-3750},
  title     = {Polarization-aware low-light image enhancement},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Aesthetically relevant image captioning. <em>AAAI</em>,
3733–3741. (<a href="https://doi.org/10.1609/aaai.v37i3.25485">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Image aesthetic quality assessment (AQA) aims to assign numerical aesthetic ratings to images whilst image aesthetic captioning (IAC) aims to generate textual descriptions of the aesthetic aspects of images. In this paper, we study image AQA and IAC together and present a new IAC method termed Aesthetically Relevant Image Captioning (ARIC). Based on the observation that most textual comments of an image are about objects and their interactions rather than aspects of aesthetics, we first introduce the concept of Aesthetic Relevance Score (ARS) of a sentence and have developed a model to automatically label a sentence with its ARS. We then use the ARS to design the ARIC model which includes an ARS weighted IAC loss function and an ARS based diverse aesthetic caption selector (DACS). We present extensive experimental results to show the soundness of the ARS concept and the effectiveness of the ARIC model by demonstrating that texts with higher ARS’s can predict the aesthetic ratings more accurately and that the new ARIC model can generate more accurate, aesthetically more relevant and more diverse image captions. Furthermore, a large new research database containing 510K images with over 5 million comments and 350K aesthetic scores, and code for implementing ARIC, are available at https://github.com/PengZai/ARIC},
  archive   = {C_AAAI},
  author    = {Zhipeng Zhong and Fei Zhou and Guoping Qiu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25485},
  pages     = {3733-3741},
  title     = {Aesthetically relevant image captioning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Refined semantic enhancement towards frequency diffusion for
video captioning. <em>AAAI</em>, 3724–3732. (<a
href="https://doi.org/10.1609/aaai.v37i3.25484">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Video captioning aims to generate natural language sentences that describe the given video accurately. Existing methods obtain favorable generation by exploring richer visual representations in encode phase or improving the decoding ability. However, the long-tailed problem hinders these attempts at low-frequency tokens, which rarely occur but carry critical semantics, playing a vital role in the detailed generation. In this paper, we introduce a novel Refined Semantic enhancement method towards Frequency Diffusion (RSFD), a captioning model that constantly perceives the linguistic representation of the infrequent tokens. Concretely, a Frequency-Aware Diffusion (FAD) module is proposed to comprehend the semantics of low-frequency tokens to break through generation limitations. In this way, the caption is refined by promoting the absorption of tokens with insufficient occurrence. Based on FAD, we design a Divergent Semantic Supervisor (DSS) module to compensate for the information loss of high-frequency tokens brought by the diffusion process, where the semantics of low-frequency tokens is further emphasized to alleviate the long-tailed problem. Extensive experiments indicate that RSFD outperforms the state-of-the-art methods on two benchmark datasets, i.e., MSR-VTT and MSVD, demonstrate that the enhancement of low-frequency tokens semantics can obtain a competitive generation effect. Code is available at https://github.com/lzp870/RSFD.},
  archive   = {C_AAAI},
  author    = {Xian Zhong and Zipeng Li and Shuqin Chen and Kui Jiang and Chen Chen and Mang Ye},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25484},
  pages     = {3724-3732},
  title     = {Refined semantic enhancement towards frequency diffusion for video captioning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). STOA-VLP: Spatial-temporal modeling of object and action for
video-language pre-training. <em>AAAI</em>, 3715–3723. (<a
href="https://doi.org/10.1609/aaai.v37i3.25483">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Although large-scale video-language pre-training models, which usually build a global alignment between the video and the text, have achieved remarkable progress on various downstream tasks, the idea of adopting fine-grained information during the pre-training stage is not well explored. In this work, we propose STOA-VLP, a pre-training framework that jointly models object and action information across spatial and temporal dimensions. More specifically, the model regards object trajectories across frames and multiple action features from the video as fine-grained features. Besides, We design two auxiliary tasks to better incorporate both kinds of information into the pre-training process of the video-language model. The first is the dynamic object-text alignment task, which builds a better connection between object trajectories and the relevant noun tokens. The second is the spatial-temporal action set prediction, which guides the model to generate consistent action features by predicting actions found in the text. Extensive experiments on three downstream tasks (video captioning, text-video retrieval, and video question answering) demonstrate the effectiveness of our proposed STOA-VLP (e.g. 3.7 Rouge-L improvements on MSR-VTT video captioning benchmark, 2.9\% accuracy improvements on MSVD video question answering benchmark, compared to previous approaches).},
  archive   = {C_AAAI},
  author    = {Weihong Zhong and Mao Zheng and Duyu Tang and Xuan Luo and Heng Gong and Xiaocheng Feng and Bing Qin},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25483},
  pages     = {3715-3723},
  title     = {STOA-VLP: Spatial-temporal modeling of object and action for video-language pre-training},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RSPT: Reconstruct surroundings and predict trajectory for
generalizable active object tracking. <em>AAAI</em>, 3705–3714. (<a
href="https://doi.org/10.1609/aaai.v37i3.25482">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Active Object Tracking (AOT) aims to maintain a specific relation between the tracker and object(s) by autonomously controlling the motion system of a tracker given observations. It is widely used in various applications such as mobile robots and autonomous driving. However, Building a generalizable active tracker that works robustly across various scenarios remains a challenge, particularly in unstructured environments with cluttered obstacles and diverse layouts. To realize this, we argue that the key is to construct a state representation that can model the geometry structure of the surroundings and the dynamics of the target. To this end, we propose a framework called RSPT to form a structure-aware motion representation by Reconstructing Surroundings and Predicting the target Trajectory. Moreover, we further enhance the generalization of the policy network by training in the asymmetric dueling mechanism. Empirical results show that RSPT outperforms existing methods in unseen environments, especially those with cluttered obstacles and diverse layouts. We also demonstrate good sim-to-real transfer when deploying RSPT in real-world scenarios.},
  archive   = {C_AAAI},
  author    = {Fangwei Zhong and Xiao Bi and Yudi Zhang and Wei Zhang and Yizhou Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25482},
  pages     = {3705-3714},
  title     = {RSPT: Reconstruct surroundings and predict trajectory for generalizable active object tracking},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MaskBooster: End-to-end self-training for sparsely
supervised instance segmentation. <em>AAAI</em>, 3696–3704. (<a
href="https://doi.org/10.1609/aaai.v37i3.25481">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The present paper introduces sparsely supervised instance segmentation, with the datasets being fully annotated bounding boxes and sparsely annotated masks. A direct solution to this task is self-training, which is not fully explored for instance segmentation yet. In this paper, we propose MaskBooster for sparsely supervised instance segmentation (SpSIS) with comprehensive usage of pseudo masks. MaskBooster is featured with (1) dynamic and progressive pseudo masks from an online updating teacher model, (2) refining binary pseudo masks with the help of bounding box prior, (3) learning inter-class prediction distribution via knowledge distillation for soft pseudo masks. As an end-to-end and universal self-training framework, MaskBooster can empower fully supervised algorithms and boost their segmentation performance on SpSIS. Abundant experiments are conducted on COCO and BDD100K datasets and validate the effectiveness of MaskBooster. Specifically, on different COCO protocols and BDD100K, we surpass sparsely supervised baseline by a large margin for both Mask RCNN and ShapeProp. MaskBooster on SpSIS also outperforms weakly and semi-supervised instance segmentation state-of-the-art on the datasets with similar annotation budgets.},
  archive   = {C_AAAI},
  author    = {Shida Zheng and Chenshu Chen and Xi Yang and Wenming Tan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25481},
  pages     = {3696-3704},
  title     = {MaskBooster: End-to-end self-training for sparsely supervised instance segmentation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Memory-aided contrastive consensus learning for co-salient
object detection. <em>AAAI</em>, 3687–3695. (<a
href="https://doi.org/10.1609/aaai.v37i3.25480">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Co-salient object detection (CoSOD) aims at detecting common salient objects within a group of relevant source images. Most of the latest works employ the attention mechanism for finding common objects. To achieve accurate CoSOD results with high-quality maps and high efficiency, we propose a novel Memory-aided Contrastive Consensus Learning (MCCL) framework, which is capable of effectively detecting co-salient objects in real time (∼150 fps). To learn better group consensus, we propose the Group Consensus Aggregation Module (GCAM) to abstract the common features of each image group; meanwhile, to make the consensus representation more discriminative, we introduce the Memory-based Contrastive Module (MCM), which saves and updates the consensus of images from different groups in a queue of memories. Finally, to improve the quality and integrity of the predicted maps, we develop an Adversarial Integrity Learning (AIL) strategy to make the segmented regions more likely composed of complete objects with less surrounding noise. Extensive experiments on all the latest CoSOD benchmarks demonstrate that our lite MCCL outperforms 13 cutting-edge models, achieving the new state of the art (∼5.9\% and ∼6.2\% improvement in S-measure on CoSOD3k and CoSal2015, respectively). Our source codes, saliency maps, and online demos are publicly available at https://github.com/ZhengPeng7/MCCL.},
  archive   = {C_AAAI},
  author    = {Peng Zheng and Jie Qin and Shuo Wang and Tian-Zhu Xiang and Huan Xiong},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25480},
  pages     = {3687-3695},
  title     = {Memory-aided contrastive consensus learning for co-salient object detection},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning semantic degradation-aware guidance for
recognition-driven unsupervised low-light image enhancement.
<em>AAAI</em>, 3678–3686. (<a
href="https://doi.org/10.1609/aaai.v37i3.25479">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Low-light images suffer severe degradation of low lightness and noise corruption, causing unsatisfactory visual quality and visual recognition performance. To solve this problem while meeting the unavailability of paired datasets in wide-range scenarios, unsupervised low-light image enhancement (ULLIE) techniques have been developed. However, these methods are primarily guided to alleviate the degradation effect on visual quality rather than semantic levels, hence limiting their performance in visual recognition tasks. To this end, we propose to learn a Semantic Degradation-Aware Guidance (SDAG) that perceives the low-light degradation effect on semantic levels in a self-supervised manner, which is further utilized to guide the ULLIE methods. The proposed SDAG utilizes the low-light degradation factors as augmented signals to degrade the low-light images, and then capture their degradation effect on semantic levels. Specifically, our SDAG employs the subsequent pre-trained recognition model extractor to extract semantic representations, and then learns to self-reconstruct the enhanced low-light image and its augmented degraded images. By constraining the relative reconstruction effect between the original enhanced image and the augmented formats, our SDAG learns to be aware of the degradation effect on semantic levels in a relative comparison manner. Moreover, our SDAG is general and can be plugged into the training paradigm of the existing ULLIE methods. Extensive experiments demonstrate its effectiveness for improving the ULLIE approaches on the downstream recognition tasks while maintaining a competitive visual quality. Code will be available at https://github.com/zheng980629/SDAG.},
  archive   = {C_AAAI},
  author    = {Naishan Zheng and Jie Huang and Man Zhou and Zizheng Yang and Qi Zhu and Feng Zhao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25479},
  pages     = {3678-3686},
  title     = {Learning semantic degradation-aware guidance for recognition-driven unsupervised low-light image enhancement},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Phrase-level temporal relationship mining for temporal
sentence localization. <em>AAAI</em>, 3669–3677. (<a
href="https://doi.org/10.1609/aaai.v37i3.25478">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we address the problem of video temporal sentence localization, which aims to localize a target moment from videos according to a given language query. We observe that existing models suffer from a sheer performance drop when dealing with simple phrases contained in the sentence. It reveals the limitation that existing models only capture the annotation bias of the datasets but lack sufficient understanding of the semantic phrases in the query. To address this problem, we propose a phrase-level Temporal Relationship Mining (TRM) framework employing the temporal relationship relevant to the phrase and the whole sentence to have a better understanding of each semantic entity in the sentence. Specifically, we use phrase-level predictions to refine the sentence-level prediction, and use Multiple Instance Learning to improve the quality of phrase-level predictions. We also exploit the consistency and exclusiveness constraints of phrase-level and sentence-level predictions to regularize the training process, thus alleviating the ambiguity of each phrase prediction. The proposed approach sheds light on how machines can understand detailed phrases in a sentence and their compositions in their generality rather than learning the annotation biases. Experiments on the ActivityNet Captions and Charades-STA datasets show the effectiveness of our method on both phrase and sentence temporal localization and enable better model interpretability and generalization when dealing with unseen compositions of seen concepts. Code can be found at https://github.com/minghangz/TRM.},
  archive   = {C_AAAI},
  author    = {Minghang Zheng and Sizhe Li and Qingchao Chen and Yuxin Peng and Yang Liu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25478},
  pages     = {3669-3677},
  title     = {Phrase-level temporal relationship mining for temporal sentence localization},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Attack can benefit: An adversarial approach to recognizing
facial expressions under noisy annotations. <em>AAAI</em>, 3660–3668.
(<a href="https://doi.org/10.1609/aaai.v37i3.25477">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The real-world Facial Expression Recognition (FER) datasets usually exhibit complex scenarios with coupled noise annotations and imbalanced classes distribution, which undoubtedly impede the development of FER methods. To address the aforementioned issues, in this paper, we propose a novel and flexible method to spot noisy labels by leveraging adversarial attack, termed as Geometry Aware Adversarial Vulnerability Estimation (GAAVE). Different from existing state-of-the-art methods of noisy label learning (NLL), our method has no reliance on additional information and is thus easy to generalize to the large-scale real-world FER datasets. Besides, the combination of Dataset Splitting module and Subset Refactoring module mitigates the impact of class imbalance, and the Self-Annotator module facilitates the sufficient use of all training data. Extensive experiments on RAF-DB, FERPlus, AffectNet, and CIFAR-10 datasets validate the effectiveness of our method. The stabilized enhancement based on different methods demonstrates the flexibility of our proposed GAAVE.},
  archive   = {C_AAAI},
  author    = {Jiawen Zheng and Bo Li and Shengchuan Zhang and Shuang Wu and Liujuan Cao and Shouhong Ding},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25477},
  pages     = {3660-3668},
  title     = {Attack can benefit: An adversarial approach to recognizing facial expressions under noisy annotations},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unsupervised deep video denoising with untrained network.
<em>AAAI</em>, 3651–3659. (<a
href="https://doi.org/10.1609/aaai.v37i3.25476">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep learning has become a prominent tool for video denoising. However, most existing deep video denoising methods require supervised training using noise-free videos. Collecting noise-free videos can be costly and challenging in many applications. Therefore, this paper aims to develop an unsupervised deep learning method for video denoising that only uses a single test noisy video for training. To achieve this, an unsupervised loss function is presented that provides an unbiased estimator of its supervised counterpart defined on noise-free video. Additionally, a temporal attention mechanism is proposed to exploit redundancy among frames. The experiments on video denoising demonstrate that the proposed unsupervised method outperforms existing unsupervised methods and remains competitive against recent supervised deep learning methods.},
  archive   = {C_AAAI},
  author    = {Huan Zheng and Tongyao Pang and Hui Ji},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25476},
  pages     = {3651-3659},
  title     = {Unsupervised deep video denoising with untrained network},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep equilibrium models for snapshot compressive imaging.
<em>AAAI</em>, 3642–3650. (<a
href="https://doi.org/10.1609/aaai.v37i3.25475">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The ability of snapshot compressive imaging (SCI) systems to efficiently capture high-dimensional (HD) data has led to an inverse problem, which consists of recovering the HD signal from the compressed and noisy measurement. While reconstruction algorithms grow fast to solve it with the recent advances of deep learning, the fundamental issue of accurate and stable recovery remains. To this end, we propose deep equilibrium models (DEQ) for video SCI, fusing data-driven regularization and stable convergence in a theoretically sound manner. Each equilibrium model implicitly learns a nonexpansive operator and analytically computes the fixed point, thus enabling unlimited iterative steps and infinite network depth with only a constant memory requirement in training and testing. Specifically, we demonstrate how DEQ can be applied to two existing models for video SCI reconstruction: recurrent neural networks (RNN) and Plug-and-Play (PnP) algorithms. On a variety of datasets and real data, both quantitative and qualitative evaluations of our results demonstrate the effectiveness and stability of our proposed method. The code and models are available at: https://github.com/IndigoPurple/DEQSCI.},
  archive   = {C_AAAI},
  author    = {Yaping Zhao and Siming Zheng and Xin Yuan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25475},
  pages     = {3642-3650},
  title     = {Deep equilibrium models for snapshot compressive imaging},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Occupancy planes for single-view RGB-d human
reconstruction. <em>AAAI</em>, 3633–3641. (<a
href="https://doi.org/10.1609/aaai.v37i3.25474">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Single-view RGB-D human reconstruction with implicit functions is often formulated as per-point classification. Specifically, a set of 3D locations within the view-frustum of the camera are first projected independently onto the image and a corresponding feature is subsequently extracted for each 3D location. The feature of each 3D location is then used to classify independently whether the corresponding 3D point is inside or outside the observed object. This procedure leads to sub-optimal results because correlations between predictions for neighboring locations are only taken into account implicitly via the extracted features. For more accurate results we propose the occupancy planes (OPlanes) representation, which enables to formulate single-view RGB-D human reconstruction as occupancy prediction on planes which slice through the camera&#39;s view frustum. Such a representation provides more flexibility than voxel grids and enables to better leverage correlations than per-point classification. On the challenging S3D data we observe a simple classifier based on the OPlanes representation to yield compelling results, especially in difficult situations with partial occlusions due to other objects and partial visibility, which haven&#39;t been addressed by prior work.},
  archive   = {C_AAAI},
  author    = {Xiaoming Zhao and Yuan-Ting Hu and Zhongzheng Ren and Alexander G. Schwing},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25474},
  pages     = {3633-3641},
  title     = {Occupancy planes for single-view RGB-D human reconstruction},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Style-content metric learning for multidomain remote sensing
object recognition. <em>AAAI</em>, 3624–3632. (<a
href="https://doi.org/10.1609/aaai.v37i3.25473">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Previous remote sensing recognition approaches predominantly perform well on the training-testing dataset. However, due to large style discrepancies not only among multidomain datasets but also within a single domain, they suffer from obvious performance degradation when applied to unseen domains. In this paper, we propose a style-content metric learning framework to address the generalizable remote sensing object recognition issue. Specifically, we firstly design an inter-class dispersion metric to encourage the model to make decision based on content rather than the style, which is achieved by dispersing predictions generated from the contents of both positive sample and negative sample and the style of input image. Secondly, we propose an intra-class compactness metric to force the model to be less style-biased by compacting classifier&#39;s predictions from the content of input image and the styles of positive sample and negative sample. Lastly, we design an intra-class interaction metric to improve model&#39;s recognition accuracy by pulling in classifier&#39;s predictions obtained from the input image and positive sample. Extensive experiments on four datasets show that our style-content metric learning achieves superior generalization performance against the state-of-the-art competitors. Code and model are available at: https://github.com/wdzhao123/TSCM.},
  archive   = {C_AAAI},
  author    = {Wenda Zhao and Ruikai Yang and Yu Liu and You He},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25473},
  pages     = {3624-3632},
  title     = {Style-content metric learning for multidomain remote sensing object recognition},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Grouped knowledge distillation for deep face recognition.
<em>AAAI</em>, 3615–3623. (<a
href="https://doi.org/10.1609/aaai.v37i3.25472">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Compared with the feature-based distillation methods, logits distillation can liberalize the requirements of consistent feature dimension between teacher and student networks, while the performance is deemed inferior in face recognition. One major challenge is that the light-weight student network has difficulty fitting the target logits due to its low model capacity, which is attributed to the significant number of identities in face recognition. Therefore, we seek to probe the target logits to extract the primary knowledge related to face identity, and discard the others, to make the distillation more achievable for the student network. Specifically, there is a tail group with near-zero values in the prediction, containing minor knowledge for distillation. To provide a clear perspective of its impact, we first partition the logits into two groups, i.e., Primary Group and Secondary Group, according to the cumulative probability of the softened prediction. Then, we reorganize the Knowledge Distillation (KD) loss of grouped logits into three parts, i.e., Primary-KD, Secondary-KD, and Binary-KD. Primary-KD refers to distilling the primary knowledge from the teacher, Secondary-KD aims to refine minor knowledge but increases the difficulty of distillation, and Binary-KD ensures the consistency of knowledge distribution between teacher and student. We experimentally found that (1) Primary-KD and Binary-KD are indispensable for KD, and (2) Secondary-KD is the culprit restricting KD at the bottleneck. Therefore, we propose a Grouped Knowledge Distillation (GKD) that retains the Primary-KD and Binary-KD but omits Secondary-KD in the ultimate KD loss calculation. Extensive experimental results on popular face recognition benchmarks demonstrate the superiority of proposed GKD over state-of-the-art methods.},
  archive   = {C_AAAI},
  author    = {Weisong Zhao and Xiangyu Zhu and Kaiwen Guo and Xiao-Yu Zhang and Zhen Lei},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25472},
  pages     = {3615-3623},
  title     = {Grouped knowledge distillation for deep face recognition},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). MulGT: Multi-task graph-transformer with task-aware
knowledge injection and domain knowledge-driven pooling for whole slide
image analysis. <em>AAAI</em>, 3606–3614. (<a
href="https://doi.org/10.1609/aaai.v37i3.25471">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Whole slide image (WSI) has been widely used to assist automated diagnosis under the deep learning fields. However, most previous works only discuss the SINGLE task setting which is not aligned with real clinical setting, where pathologists often conduct multiple diagnosis tasks simultaneously. Also, it is commonly recognized that the multi-task learning paradigm can improve learning efficiency by exploiting commonalities and differences across multiple tasks. To this end, we present a novel multi-task framework (i.e., MulGT) for WSI analysis by the specially designed Graph-Transformer equipped with Task-aware Knowledge Injection and Domain Knowledge-driven Graph Pooling modules. Basically, with the Graph Neural Network and Transformer as the building commons, our framework is able to learn task-agnostic low-level local information as well as task-specific high-level global representation. Considering that different tasks in WSI analysis depend on different features and properties, we also design a novel Task-aware Knowledge Injection module to transfer the task-shared graph embedding into task-specific feature spaces to learn more accurate representation for different tasks. Further, we elaborately design a novel Domain Knowledge-driven Graph Pooling module for each task to improve both the accuracy and robustness of different tasks by leveraging different diagnosis patterns of multiple tasks. We evaluated our method on two public WSI datasets from TCGA projects, i.e., esophageal carcinoma and kidney carcinoma. Experimental results show that our method outperforms single-task counterparts and the state-of-theart methods on both tumor typing and staging tasks.},
  archive   = {C_AAAI},
  author    = {Weiqin Zhao and Shujun Wang and Maximus Yeung and Tianye Niu and Lequan Yu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25471},
  pages     = {3606-3614},
  title     = {MulGT: Multi-task graph-transformer with task-aware knowledge injection and domain knowledge-driven pooling for whole slide image analysis},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). BEST: BERT pre-training for sign language recognition with
coupling tokenization. <em>AAAI</em>, 3597–3605. (<a
href="https://doi.org/10.1609/aaai.v37i3.25470">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this work, we are dedicated to leveraging the BERT pre-training success and modeling the domain-specific statistics to fertilize the sign language recognition~(SLR) model. Considering the dominance of hand and body in sign language expression, we organize them as pose triplet units and feed them into the Transformer backbone in a frame-wise manner. Pre-training is performed via reconstructing the masked triplet unit from the corrupted input sequence, which learns the hierarchical correlation context cues among internal and external triplet units. Notably, different from the highly semantic word token in BERT, the pose unit is a low-level signal originally locating in continuous space, which prevents the direct adoption of the BERT cross entropy objective. To this end, we bridge this semantic gap via coupling tokenization of the triplet unit. It adaptively extracts the discrete pseudo label from the pose triplet unit, which represents the semantic gesture / body state. After pre-training, we fine-tune the pre-trained encoder on the downstream SLR task, jointly with the newly added task-specific layer. Extensive experiments are conducted to validate the effectiveness of our proposed method, achieving new state-of-the-art performance on all four benchmarks with a notable gain.},
  archive   = {C_AAAI},
  author    = {Weichao Zhao and Hezhen Hu and Wengang Zhou and Jiaxin Shi and Houqiang Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25470},
  pages     = {3597-3605},
  title     = {BEST: BERT pre-training for sign language recognition with coupling tokenization},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TinyNeRF: Towards 100 x compression of voxel radiance
fields. <em>AAAI</em>, 3588–3596. (<a
href="https://doi.org/10.1609/aaai.v37i3.25469">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Voxel grid representation of 3D scene properties has been widely used to improve the training or rendering speed of the Neural Radiance Fields (NeRF) while at the same time achieving high synthesis quality. However, these methods accelerate the original NeRF at the expense of extra storage demand, which hinders their applications in many scenarios. To solve this limitation, we present TinyNeRF, a three-stage pipeline: frequency domain transformation, pruning and quantization that work together to reduce the storage demand of the voxel grids with little to no effects on their speed and synthesis quality. Based on the prior knowledge of visual signals sparsity in the frequency domain, we convert the original voxel grids in the frequency domain via block-wise discrete cosine transformation (DCT). Next, we apply pruning and quantization to enforce the DCT coefficients to be sparse and low-bit. Our method can be optimized from scratch in an end-to-end manner, and can typically compress the original models by 2 orders of magnitude with minimal sacrifice on speed and synthesis quality.},
  archive   = {C_AAAI},
  author    = {Tianli Zhao and Jiayuan Chen and Cong Leng and Jian Cheng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25469},
  pages     = {3588-3596},
  title     = {TinyNeRF: Towards 100 x compression of voxel radiance fields},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning to super-resolve dynamic scenes for neuromorphic
spike camera. <em>AAAI</em>, 3579–3587. (<a
href="https://doi.org/10.1609/aaai.v37i3.25468">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Spike camera is a kind of neuromorphic sensor that uses a novel ``integrate-and-fire&#39;&#39; mechanism to generate a continuous spike stream to record the dynamic light intensity at extremely high temporal resolution. However, as a trade-off for high temporal resolution, its spatial resolution is limited, resulting in inferior reconstruction details. To address this issue, this paper develops a network (SpikeSR-Net) to super-resolve a high-resolution image sequence from the low-resolution binary spike streams. SpikeSR-Net is designed based on the observation model of spike camera and exploits both the merits of model-based and learning-based methods. To deal with the limited representation capacity of binary data, a pixel-adaptive spike encoder is proposed to convert spikes to latent representation to infer clues on intensity and motion. Then, a motion-aligned super resolver is employed to exploit long-term correlation, so that the dense sampling in temporal domain can be exploited to enhance the spatial resolution without introducing motion blur. Experimental results show that SpikeSR-Net is promising in super-resolving higher-quality images for spike camera.},
  archive   = {C_AAAI},
  author    = {Jing Zhao and Ruiqin Xiong and Jian Zhang and Rui Zhao and Hangfan Liu and Tiejun Huang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25468},
  pages     = {3579-3587},
  title     = {Learning to super-resolve dynamic scenes for neuromorphic spike camera},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RLogist: Fast observation strategy on whole-slide images
with deep reinforcement learning. <em>AAAI</em>, 3570–3578. (<a
href="https://doi.org/10.1609/aaai.v37i3.25467">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Whole-slide images (WSI) in computational pathology have high resolution with gigapixel size, but are generally with sparse regions of interest, which leads to weak diagnostic relevance and data inefficiency for each area in the slide. Most of the existing methods rely on a multiple instance learning framework that requires densely sampling local patches at high magnification. The limitation is evident in the application stage as the heavy computation for extracting patch-level features is inevitable. In this paper, we develop RLogist, a benchmarking deep reinforcement learning (DRL) method for fast observation strategy on WSIs. Imitating the diagnostic logic of human pathologists, our RL agent learns how to find regions of observation value and obtain representative features across multiple resolution levels, without having to analyze each part of the WSI at the high magnification. We benchmark our method on two whole-slide level classification tasks, including detection of metastases in WSIs of lymph node sections, and subtyping of lung cancer. Experimental results demonstrate that RLogist achieves competitive classification performance compared to typical multiple instance learning algorithms, while having a significantly short observation path. In addition, the observation path given by RLogist provides good decision-making interpretability, and its ability of reading path navigation can potentially be used by pathologists for educational/assistive purposes. Our code is available at: https://github.com/tencent-ailab/RLogist.},
  archive   = {C_AAAI},
  author    = {Boxuan Zhao and Jun Zhang and Deheng Ye and Jian Cao and Xiao Han and Qiang Fu and Wei Yang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25467},
  pages     = {3570-3578},
  title     = {RLogist: Fast observation strategy on whole-slide images with deep reinforcement learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Combating unknown bias with effective bias-conflicting
scoring and gradient alignment. <em>AAAI</em>, 3561–3569. (<a
href="https://doi.org/10.1609/aaai.v37i3.25466">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Models notoriously suffer from dataset biases which are detrimental to robustness and generalization. The identify-emphasize paradigm shows a promising effect in dealing with unknown biases. However, we find that it is still plagued by two challenges: A, the quality of the identified bias-conflicting samples is far from satisfactory; B, the emphasizing strategies just yield suboptimal performance. In this work, for challenge A, we propose an effective bias-conflicting scoring method to boost the identification accuracy with two practical strategies --- peer-picking and epoch-ensemble. For challenge B, we point out that the gradient contribution statistics can be a reliable indicator to inspect whether the optimization is dominated by bias-aligned samples. Then, we propose gradient alignment, which employs gradient statistics to balance the contributions of the mined bias-aligned and bias-conflicting samples dynamically throughout the learning process, forcing models to leverage intrinsic features to make fair decisions. Experiments are conducted on multiple datasets in various settings, demonstrating that the proposed solution can alleviate the impact of unknown biases and achieve state-of-the-art performance.},
  archive   = {C_AAAI},
  author    = {Bowen Zhao and Chen Chen and Qian-Wei Wang and Anfeng He and Shu-Tao Xia},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25466},
  pages     = {3561-3569},
  title     = {Combating unknown bias with effective bias-conflicting scoring and gradient alignment},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ShiftDDPMs: Exploring conditional diffusion models by
shifting diffusion trajectories. <em>AAAI</em>, 3552–3560. (<a
href="https://doi.org/10.1609/aaai.v37i3.25465">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Diffusion models have recently exhibited remarkable abilities to synthesize striking image samples since the introduction of denoising diffusion probabilistic models (DDPMs). Their key idea is to disrupt images into noise through a fixed forward process and learn its reverse process to generate samples from noise in a denoising way. For conditional DDPMs, most existing practices relate conditions only to the reverse process and fit it to the reversal of unconditional forward process. We find this will limit the condition modeling and generation in a small time window. In this paper, we propose a novel and flexible conditional diffusion model by introducing conditions into the forward process. We utilize extra latent space to allocate an exclusive diffusion trajectory for each condition based on some shifting rules, which will disperse condition modeling to all timesteps and improve the learning capacity of model. We formulate our method, which we call ShiftDDPMs, and provide a unified point of view on existing related methods. Extensive qualitative and quantitative experiments on image synthesis demonstrate the feasibility and effectiveness of ShiftDDPMs.},
  archive   = {C_AAAI},
  author    = {Zijian Zhang and Zhou Zhao and Jun Yu and Qi Tian},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25465},
  pages     = {3552-3560},
  title     = {ShiftDDPMs: Exploring conditional diffusion models by shifting diffusion trajectories},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). DINet: Deformation inpainting network for realistic face
visually dubbing on high resolution video. <em>AAAI</em>, 3543–3551. (<a
href="https://doi.org/10.1609/aaai.v37i3.25464">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {For few-shot learning, it is still a critical challenge to realize photo-realistic face visually dubbing on high-resolution videos. Previous works fail to generate high-fidelity dubbing results. To address the above problem, this paper proposes a Deformation Inpainting Network (DINet) for high-resolution face visually dubbing. Different from previous works relying on multiple up-sample layers to directly generate pixels from latent embeddings, DINet performs spatial deformation on feature maps of reference images to better preserve high-frequency textural details. Specifically, DINet consists of one deformation part and one inpainting part. In the first part, five reference facial images adaptively perform spatial deformation to create deformed feature maps encoding mouth shapes at each frame, in order to align with input driving audio and also the head poses of input source images. In the second part, to produce face visually dubbing, a feature decoder is responsible for adaptively incorporating mouth movements from the deformed feature maps and other attributes (i.e., head pose and upper facial expression) from the source feature maps together. Finally, DINet achieves face visually dubbing with rich textural details. We conduct qualitative and quantitative comparisons to validate our DINet on high-resolution videos. The experimental results show that our method outperforms state-of-the-art works.},
  archive   = {C_AAAI},
  author    = {Zhimeng Zhang and Zhipeng Hu and Wenjin Deng and Changjie Fan and Tangjie Lv and Yu Ding},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25464},
  pages     = {3543-3551},
  title     = {DINet: Deformation inpainting network for realistic face visually dubbing on high resolution video},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TrEP: Transformer-based evidential prediction for pedestrian
intention with uncertainty. <em>AAAI</em>, 3534–3542. (<a
href="https://doi.org/10.1609/aaai.v37i3.25463">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With rapid development in hardware (sensors and processors) and AI algorithms, automated driving techniques have entered the public’s daily life and achieved great success in supporting human driving performance. However, due to the high contextual variations and temporal dynamics in pedestrian behaviors, the interaction between autonomous-driving cars and pedestrians remains challenging, impeding the development of fully autonomous driving systems. This paper focuses on predicting pedestrian intention with a novel transformer-based evidential prediction (TrEP) algorithm. We develop a transformer module towards the temporal correlations among the input features within pedestrian video sequences and a deep evidential learning model to capture the AI uncertainty under scene complexities. Experimental results on three popular pedestrian intent benchmarks have verified the effectiveness of our proposed model over the state-of-the-art. The algorithm performance can be further boosted by controlling the uncertainty level. We systematically compare human disagreements with AI uncertainty to further evaluate AI performance in confusing scenes. The code is released at https://github.com/zzmonlyyou/TrEP.git.},
  archive   = {C_AAAI},
  author    = {Zhengming Zhang and Renran Tian and Zhengming Ding},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25463},
  pages     = {3534-3542},
  title     = {TrEP: Transformer-based evidential prediction for pedestrian intention with uncertainty},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023d). Cross-category highlight detection via feature
decomposition and modality alignment. <em>AAAI</em>, 3525–3533. (<a
href="https://doi.org/10.1609/aaai.v37i3.25462">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Learning an autonomous highlight video detector with good transferability across video categories, called Cross-Category Video Highlight Detection(CC-VHD), is crucial for the practical application on video-based media platforms. To tackle this problem, we first propose a framework that treats the CC-VHD as learning category-independent highlight feature representation. Under this framework, we propose a novel module, named Multi-task Feature Decomposition Branch which jointly conducts label prediction, cyclic feature reconstruction, and adversarial feature reconstruction to decompose the video features into two independent components: highlight-related component and category-related component. Besides, we propose to align the visual and audio modalities to one aligned feature space before conducting modality fusion, which has not been considered in previous works. Finally, the extensive experimental results on three challenging public benchmarks validate the efficacy of our paradigm and the superiority over the existing state-of-the-art approaches to video highlight detection.},
  archive   = {C_AAAI},
  author    = {Zhenduo Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25462},
  pages     = {3525-3533},
  title     = {Cross-category highlight detection via feature decomposition and modality alignment},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Positional label for self-supervised vision transformer.
<em>AAAI</em>, 3516–3524. (<a
href="https://doi.org/10.1609/aaai.v37i3.25461">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Positional encoding is important for vision transformer (ViT) to capture the spatial structure of the input image. General effectiveness has been proven in ViT. In our work we propose to train ViT to recognize the positional label of patches of the input image, this apparently simple task actually yields a meaningful self-supervisory task. Based on previous work on ViT positional encoding, we propose two positional labels dedicated to 2D images including absolute position and relative position. Our positional labels can be easily plugged into various current ViT variants. It can work in two ways: (a) As an auxiliary training target for vanilla ViT for better performance. (b) Combine the self-supervised ViT to provide a more powerful self-supervised signal for semantic feature learning. Experiments demonstrate that with the proposed self-supervised methods, ViT-B and Swin-B gain improvements of 1.20\% (top-1 Acc) and 0.74\% (top-1 Acc) on ImageNet, respectively, and 6.15\% and 1.14\% improvement on Mini-ImageNet. The code is publicly available at: https://github.com/zhangzhemin/PositionalLabel.},
  archive   = {C_AAAI},
  author    = {Zhemin Zhang and Xun Gong},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25461},
  pages     = {3516-3524},
  title     = {Positional label for self-supervised vision transformer},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A simple baseline for multi-camera 3D object detection.
<em>AAAI</em>, 3507–3515. (<a
href="https://doi.org/10.1609/aaai.v37i3.25460">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {3D object detection with surrounding cameras has been a promising direction for autonomous driving. In this paper, we present SimMOD, a Simple baseline for Multi-camera Object Detection, to solve the problem. To incorporate multiview information as well as build upon previous efforts on monocular 3D object detection, the framework is built on sample-wise object proposals and designed to work in a twostage manner. First, we extract multi-scale features and generate the perspective object proposals on each monocular image. Second, the multi-view proposals are aggregated and then iteratively refined with multi-view and multi-scale visual features in the DETR3D-style. The refined proposals are endto-end decoded into the detection results. To further boost the performance, we incorporate the auxiliary branches alongside the proposal generation to enhance the feature learning. Also, we design the methods of target filtering and teacher forcing to promote the consistency of two-stage training. We conduct extensive experiments on the 3D object detection benchmark of nuScenes to demonstrate the effectiveness of SimMOD and achieve competitive performance. Code will be available at https://github.com/zhangyp15/SimMOD.},
  archive   = {C_AAAI},
  author    = {Yunpeng Zhang and Wenzhao Zheng and Zheng Zhu and Guan Huang and Jiwen Lu and Jie Zhou},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25460},
  pages     = {3507-3515},
  title     = {A simple baseline for multi-camera 3D object detection},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). MRCN: A novel modality restitution and compensation network
for visible-infrared person re-identification. <em>AAAI</em>, 3498–3506.
(<a href="https://doi.org/10.1609/aaai.v37i3.25459">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Visible-infrared person re-identification (VI-ReID), which aims to search identities across different spectra, is a challenging task due to large cross-modality discrepancy between visible and infrared images. The key to reduce the discrepancy is to filter out identity-irrelevant interference and effectively learn modality-invariant person representations. In this paper, we propose a novel Modality Restitution and Compensation Network (MRCN) to narrow the gap between the two modalities. Specifically, we first reduce the modality discrepancy by using two Instance Normalization (IN) layers. Next, to reduce the influence of IN layers on removing discriminative information and to reduce modality differences, we propose a Modality Restitution Module (MRM) and a Modality Compensation Module (MCM) to respectively distill modality-irrelevant and modality-relevant features from the removed information. Then, the modality-irrelevant features are used to restitute to the normalized visible and infrared features, while the modality-relevant features are used to compensate for the features of the other modality. Furthermore, to better disentangle the modality-relevant features and the modality-irrelevant features, we propose a novel Center-Quadruplet Causal (CQC) loss to encourage the network to effectively learn the modality-relevant features and the modality-irrelevant features. Extensive experiments are conducted to validate the superiority of our method on the challenging SYSU-MM01 and RegDB datasets. More remarkably, our method achieves 95.1\% in terms of Rank-1 and 89.2\% in terms of mAP on the RegDB dataset.},
  archive   = {C_AAAI},
  author    = {Yukang Zhang and Yan Yan and Jie Li and Hanzi Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25459},
  pages     = {3498-3506},
  title     = {MRCN: A novel modality restitution and compensation network for visible-infrared person re-identification},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Video compression artifact reduction by fusing motion
compensation and global context in a swin-CNN based parallel
architecture. <em>AAAI</em>, 3489–3497. (<a
href="https://doi.org/10.1609/aaai.v37i3.25458">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Video Compression Artifact Reduction aims to reduce the artifacts caused by video compression algorithms and improve the quality of compressed video frames. The critical challenge in this task is to make use of the redundant high-quality information in compressed frames for compensation as much as possible. Two important possible compensations: Motion compensation and global context, are not comprehensively considered in previous works, leading to inferior results. The key idea of this paper is to fuse the motion compensation and global context together to gain more compensation information to improve the quality of compressed videos. Here, we propose a novel Spatio-Temporal Compensation Fusion (STCF) framework with the Parallel Swin-CNN Fusion (PSCF) block, which can simultaneously learn and merge the motion compensation and global context to reduce the video compression artifacts. Specifically, a temporal self-attention strategy based on shifted windows is developed to capture the global context in an efficient way, for which we use the Swin transformer layer in the PSCF block. Moreover, an additional Ada-CNN layer is applied in the PSCF block to extract the motion compensation. Experimental results demonstrate that our proposed STCF framework outperforms the state-of-the-art methods up to 0.23dB (27\% improvement) on the MFQEv2 dataset.},
  archive   = {C_AAAI},
  author    = {Xinjian Zhang and Su Yang and Wuyang Luo and Longwen Gao and Weishan Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25458},
  pages     = {3489-3497},
  title     = {Video compression artifact reduction by fusing motion compensation and global context in a swin-CNN based parallel architecture},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023d). Cross-view geo-localization via learning disentangled
geometric layout correspondence. <em>AAAI</em>, 3480–3488. (<a
href="https://doi.org/10.1609/aaai.v37i3.25457">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Cross-view geo-localization aims to estimate the location of a query ground image by matching it to a reference geo-tagged aerial images database. As an extremely challenging task, its difficulties root in the drastic view changes and different capturing time between two views. Despite these difficulties, recent works achieve outstanding progress on cross-view geo-localization benchmarks. However, existing methods still suffer from poor performance on the cross-area benchmarks, in which the training and testing data are captured from two different regions. We attribute this deficiency to the lack of ability to extract the spatial configuration of visual feature layouts and models&#39; overfitting on low-level details from the training set. In this paper, we propose GeoDTR which explicitly disentangles geometric information from raw features and learns the spatial correlations among visual features from aerial and ground pairs with a novel geometric layout extractor module. This module generates a set of geometric layout descriptors, modulating the raw features and producing high-quality latent representations. In addition, we elaborate on two categories of data augmentations, (i) Layout simulation, which varies the spatial configuration while keeping the low-level details intact. (ii) Semantic augmentation, which alters the low-level details and encourages the model to capture spatial configurations. These augmentations help to improve the performance of the cross-view geo-localization models, especially on the cross-area benchmarks. Moreover, we propose a counterfactual-based learning process to benefit the geometric layout extractor in exploring spatial information. Extensive experiments show that GeoDTR not only achieves state-of-the-art results but also significantly boosts the performance on same-area and cross-area benchmarks. Our code can be found at https://gitlab.com/vail-uvm/geodtr.},
  archive   = {C_AAAI},
  author    = {Xiaohan Zhang and Xingyu Li and Waqas Sultani and Yi Zhou and Safwan Wshah},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25457},
  pages     = {3480-3488},
  title     = {Cross-view geo-localization via learning disentangled geometric layout correspondence},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ConvMatch: Rethinking network design for two-view
correspondence learning. <em>AAAI</em>, 3472–3479. (<a
href="https://doi.org/10.1609/aaai.v37i3.25456">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multilayer perceptron (MLP) has been widely used in two-view correspondence learning for only unordered correspondences provided, and it extracts deep features from individual correspondence effectively. However, the problem of lacking context information limits its performance and hence, many extra complex blocks are designed to capture such information in the follow-up studies. In this paper, from a novel perspective, we design a correspondence learning network called ConvMatch that for the first time can leverage convolutional neural network (CNN) as the backbone to capture better context, thus avoiding the complex design of extra blocks. Specifically, with the observation that sparse motion vectors and dense motion field can be converted into each other with interpolating and sampling, we regularize the putative motion vectors by estimating dense motion field implicitly, then rectify the errors caused by outliers in local areas with CNN, and finally obtain correct motion vectors from the rectified motion field. Extensive experiments reveal that ConvMatch with a simple CNN backbone consistently outperforms state-of-the-arts including MLP-based methods for relative pose estimation and homography estimation, and shows promising generalization ability to different datasets and descriptors. Our code is publicly available at https://github.com/SuhZhang/ConvMatch.},
  archive   = {C_AAAI},
  author    = {Shihua Zhang and Jiayi Ma},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25456},
  pages     = {3472-3479},
  title     = {ConvMatch: Rethinking network design for two-view correspondence learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mind the gap: Polishing pseudo labels for accurate
semi-supervised object detection. <em>AAAI</em>, 3463–3471. (<a
href="https://doi.org/10.1609/aaai.v37i3.25455">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Exploiting pseudo labels (e.g., categories and bounding boxes) of unannotated objects produced by a teacher detector have underpinned much of recent progress in semi-supervised object detection (SSOD). However, due to the limited generalization capacity of the teacher detector caused by the scarce annotations, the produced pseudo labels often deviate from ground truth, especially those with relatively low classification confidences, thus limiting the generalization performance of SSOD. To mitigate this problem, we propose a dual pseudo-label polishing framework for SSOD. Instead of directly exploiting the pseudo labels produced by the teacher detector, we take the first attempt at reducing their deviation from ground truth using dual polishing learning, where two differently structured polishing networks are elaborately developed and trained using synthesized paired pseudo labels and the corresponding ground truth for categories and bounding boxes on the given annotated objects, respectively. By doing this, both polishing networks can infer more accurate pseudo labels for unannotated objects through sufficiently exploiting their context knowledge based on the initially produced pseudo labels, and thus improve the generalization performance of SSOD. Moreover, such a scheme can be seamlessly plugged into the existing SSOD framework for joint end-to-end learning. In addition, we propose to disentangle the polished pseudo categories and bounding boxes of unannotated objects for separate category classification and bounding box regression in SSOD, which enables introducing more unannotated objects during model training and thus further improves the performance. Experiments on both PASCAL VOC and MS-COCO benchmarks demonstrate the superiority of the proposed method over existing state-of-the-art baselines. The code can be found at https://github.com/snowdusky/DualPolishLearning.},
  archive   = {C_AAAI},
  author    = {Lei Zhang and Yuxuan Sun and Wei Wei},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25455},
  pages     = {3463-3471},
  title     = {Mind the gap: Polishing pseudo labels for accurate semi-supervised object detection},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). IKOL: Inverse kinematics optimization layer for 3D human
pose and shape estimation via gauss-newton differentiation.
<em>AAAI</em>, 3454–3462. (<a
href="https://doi.org/10.1609/aaai.v37i3.25454">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper presents an inverse kinematic optimization layer (IKOL) for 3D human pose and shape estimation that leverages the strength of both optimization- and regression-based methods within an end-to-end framework. IKOL involves a nonconvex optimization that establishes an implicit mapping from an image’s 3D keypoints and body shapes to the relative body-part rotations. The 3D keypoints and the body shapes are the inputs and the relative body-part rotations are the solutions. However, this procedure is implicit and hard to make differentiable. So, to overcome this issue, we designed a Gauss-Newton differentiation (GN-Diff) procedure to differentiate IKOL. GN-Diff iteratively linearizes the nonconvex objective function to obtain Gauss-Newton directions with closed form solutions. Then, an automatic differentiation procedure is directly applied to generate a Jacobian matrix for end-to-end training. Notably, the GN-Diff procedure works fast because it does not rely on a time-consuming implicit differentiation procedure. The twist rotation and shape parameters are learned from the neural networks and, as a result, IKOL has a much lower computational overhead than most existing optimization-based methods. Additionally, compared to existing regression-based methods, IKOL provides a more accurate mesh-image correspondence. This is because it iteratively reduces the distance between the keypoints and also enhances the reliability of the pose structures. Extensive experiments demonstrate the superiority of our proposed framework over a wide range of 3D human pose and shape estimation methods. Code is available at https://github.com/Juzezhang/IKOL},
  archive   = {C_AAAI},
  author    = {Juze Zhang and Ye Shi and Yuexin Ma and Lan Xu and Jingyi Yu and Jingya Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25454},
  pages     = {3454-3462},
  title     = {IKOL: Inverse kinematics optimization layer for 3D human pose and shape estimation via gauss-newton differentiation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Language-assisted 3D feature learning for semantic scene
understanding. <em>AAAI</em>, 3445–3453. (<a
href="https://doi.org/10.1609/aaai.v37i3.25453">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Learning descriptive 3D features is crucial for understanding 3D scenes with diverse objects and complex structures. However, it is usually unknown whether important geometric attributes and scene context obtain enough emphasis in an end-to-end trained 3D scene understanding network. To guide 3D feature learning toward important geometric attributes and scene context, we explore the help of textual scene descriptions. Given some free-form descriptions paired with 3D scenes, we extract the knowledge regarding the object relationships and object attributes. We then inject the knowledge to 3D feature learning through three classification-based auxiliary tasks. This language-assisted training can be combined with modern object detection and instance segmentation methods to promote 3D semantic scene understanding, especially in a label-deficient regime. Moreover, the 3D feature learned with language assistance is better aligned with the language features, which can benefit various 3D-language multimodal tasks. Experiments on several benchmarks of 3D-only and 3D-language tasks demonstrate the effectiveness of our language-assisted 3D feature learning. Code is available at https://github.com/Asterisci/Language-Assisted-3D.},
  archive   = {C_AAAI},
  author    = {Junbo Zhang and Guofan Fan and Guanghan Wang and Zhengyuan Su and Kaisheng Ma and Li Yi},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25453},
  pages     = {3445-3453},
  title     = {Language-assisted 3D feature learning for semantic scene understanding},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ImageNet pre-training also transfers non-robustness.
<em>AAAI</em>, 3436–3444. (<a
href="https://doi.org/10.1609/aaai.v37i3.25452">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {ImageNet pre-training has enabled state-of-the-art results on many tasks. In spite of its recognized contribution to generalization, we observed in this study that ImageNet pre-training also transfers adversarial non-robustness from pre-trained model into fine-tuned model in the downstream classification tasks. We first conducted experiments on various datasets and network backbones to uncover the adversarial non-robustness in fine-tuned model. Further analysis was conducted on examining the learned knowledge of fine-tuned model and standard model, and revealed that the reason leading to the non-robustness is the non-robust features transferred from ImageNet pre-trained model. Finally, we analyzed the preference for feature learning of the pre-trained model, explored the factors influencing robustness, and introduced a simple robust ImageNet pre-training solution. Our code is available at https://github.com/jiamingzhang94/ImageNet-Pretraining-transfers-non-robustness.},
  archive   = {C_AAAI},
  author    = {Jiaming Zhang and Jitao Sang and Qi Yi and Yunfan Yang and Huiwen Dong and Jian Yu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25452},
  pages     = {3436-3444},
  title     = {ImageNet pre-training also transfers non-robustness},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hierarchical consistent contrastive learning for
skeleton-based action recognition with growing augmentations.
<em>AAAI</em>, 3427–3435. (<a
href="https://doi.org/10.1609/aaai.v37i3.25451">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Contrastive learning has been proven beneficial for self-supervised skeleton-based action recognition. Most contrastive learning methods utilize carefully designed augmentations to generate different movement patterns of skeletons for the same semantics. However, it is still a pending issue to apply strong augmentations, which distort the images/skeletons’ structures and cause semantic loss, due to their resulting unstable training. In this paper, we investigate the potential of adopting strong augmentations and propose a general hierarchical consistent contrastive learning framework (HiCLR) for skeleton-based action recognition. Specifically, we first design a gradual growing augmentation policy to generate multiple ordered positive pairs, which guide to achieve the consistency of the learned representation from different views. Then, an asymmetric loss is proposed to enforce the hierarchical consistency via a directional clustering operation in the feature space, pulling the representations from strongly augmented views closer to those from weakly augmented views for better generalizability. Meanwhile, we propose and evaluate three kinds of strong augmentations for 3D skeletons to demonstrate the effectiveness of our method. Extensive experiments show that HiCLR outperforms the state-of-the-art methods notably on three large-scale datasets, i.e., NTU60, NTU120, and PKUMMD. Our project is publicly available at: https://jhang2020.github.io/Projects/HiCLR/HiCLR.html.},
  archive   = {C_AAAI},
  author    = {Jiahang Zhang and Lilang Lin and Jiaying Liu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25451},
  pages     = {3427-3435},
  title     = {Hierarchical consistent contrastive learning for skeleton-based action recognition with growing augmentations},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PaRot: Patch-wise rotation-invariant network via feature
disentanglement and pose restoration. <em>AAAI</em>, 3418–3426. (<a
href="https://doi.org/10.1609/aaai.v37i3.25450">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent interest in point cloud analysis has led rapid progress in designing deep learning methods for 3D models. However, state-of-the-art models are not robust to rotations, which remains an unknown prior to real applications and harms the model performance. In this work, we introduce a novel Patch-wise Rotation-invariant network (PaRot), which achieves rotation invariance via feature disentanglement and produces consistent predictions for samples with arbitrary rotations. Specifically, we design a siamese training module which disentangles rotation invariance and equivariance from patches defined over different scales, e.g., the local geometry and global shape, via a pair of rotations. However, our disentangled invariant feature loses the intrinsic pose information of each patch. To solve this problem, we propose a rotation-invariant geometric relation to restore the relative pose with equivariant information for patches defined over different scales. Utilising the pose information, we propose a hierarchical module which implements intra-scale and inter-scale feature aggregation for 3D shape learning. Moreover, we introduce a pose-aware feature propagation process with the rotation-invariant relative pose information embedded. Experiments show that our disentanglement module extracts high-quality rotation-robust features and the proposed lightweight model achieves competitive results in rotated 3D object classification and part segmentation tasks.},
  archive   = {C_AAAI},
  author    = {Dingxin Zhang and Jianhui Yu and Chaoyi Zhang and Weidong Cai},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25450},
  pages     = {3418-3426},
  title     = {PaRot: Patch-wise rotation-invariant network via feature disentanglement and pose restoration},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Few-shot 3D point cloud semantic segmentation via stratified
class-specific attention based transformer network. <em>AAAI</em>,
3410–3417. (<a href="https://doi.org/10.1609/aaai.v37i3.25449">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {3D point cloud semantic segmentation aims to group all points into different semantic categories, which benefits important applications such as point cloud scene reconstruction and understanding. Existing supervised point cloud semantic segmentation methods usually require large-scale annotated point clouds for training and cannot handle new categories. While a few-shot learning method was proposed recently to address these two problems, it suffers from high computational complexity caused by graph construction and inability to learn fine-grained relationships among points due to the use of pooling operations. In this paper, we further address these problems by developing a new multi-layer transformer network for few-shot point cloud semantic segmentation. In the proposed network, the query point cloud features are aggregated based on the class-specific support features in different scales. Without using pooling operations, our method makes full use of all pixel-level features from the support samples. By better leveraging the support features for few-shot learning, the proposed method achieves the new state-of-the-art performance, with 15\% less inference time, over existing few-shot 3D point cloud segmentation models on the S3DIS dataset and the ScanNet dataset. Our code is available at https://github.com/czzhang179/SCAT.},
  archive   = {C_AAAI},
  author    = {Canyu Zhang and Zhenyao Wu and Xinyi Wu and Ziyu Zhao and Song Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25449},
  pages     = {3410-3417},
  title     = {Few-shot 3D point cloud semantic segmentation via stratified class-specific attention based transformer network},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Mx2M: Masked cross-modality modeling in domain adaptation
for 3D semantic segmentation. <em>AAAI</em>, 3401–3409. (<a
href="https://doi.org/10.1609/aaai.v37i3.25448">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Existing methods of cross-modal domain adaptation for 3D semantic segmentation predict results only via 2D-3D complementarity that is obtained by cross-modal feature matching. However, as lacking supervision in the target domain, the complementarity is not always reliable. The results are not ideal when the domain gap is large. To solve the problem of lacking supervision, we introduce masked modeling into this task and propose a method Mx2M, which utilizes masked cross-modality modeling to reduce the large domain gap. Our Mx2M contains two components. One is the core solution, cross-modal removal and prediction (xMRP), which makes the Mx2M adapt to various scenarios and provides cross-modal self-supervision. The other is a new way of cross-modal feature matching, the dynamic cross-modal filter (DxMF) that ensures the whole method dynamically uses more suitable 2D-3D complementarity. Evaluation of the Mx2M on three DA scenarios, including Day/Night, USA/Singapore, and A2D2/SemanticKITTI, brings large improvements over previous methods on many metrics.},
  archive   = {C_AAAI},
  author    = {Boxiang Zhang and Zunran Wang and Yonggen Ling and Yuanyuan Guan and Shenghao Zhang and Wenhui Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25448},
  pages     = {3401-3409},
  title     = {Mx2M: Masked cross-modality modeling in domain adaptation for 3D semantic segmentation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Darwinian model upgrades: Model evolving with selective
compatibility. <em>AAAI</em>, 3393–3400. (<a
href="https://doi.org/10.1609/aaai.v37i3.25447">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The traditional model upgrading paradigm for retrieval requires recomputing all gallery embeddings before deploying the new model (dubbed as &quot;backfilling&quot;), which is quite expensive and time-consuming considering billions of instances in industrial applications. BCT presents the first step towards backward-compatible model upgrades to get rid of backfilling. It is workable but leaves the new model in a dilemma between new feature discriminativeness and new-to-old compatibility due to the undifferentiated compatibility constraints. In this work, we propose Darwinian Model Upgrades (DMU), which disentangle the inheritance and variation in the model evolving with selective backward compatibility and forward adaptation, respectively. The old-to-new heritable knowledge is measured by old feature discriminativeness, and the gallery features, especially those of poor quality, are evolved in a lightweight manner to become more adaptive in the new latent space. We demonstrate the superiority of DMU through comprehensive experiments on large-scale landmark retrieval and face recognition benchmarks. DMU effectively alleviates the new-to-new degradation at the same time improving new-to-old compatibility, rendering a more proper model upgrading paradigm in large-scale retrieval systems.Code: https://github.com/TencentARC/OpenCompatible.},
  archive   = {C_AAAI},
  author    = {Binjie Zhang and Shupeng Su and Yixiao Ge and Xuyuan Xu and Yexin Wang and Chun Yuan and Mike Zheng Shou and Ying Shan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25447},
  pages     = {3393-3400},
  title     = {Darwinian model upgrades: Model evolving with selective compatibility},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learnable blur kernel for single-image defocus deblurring in
the wild. <em>AAAI</em>, 3384–3392. (<a
href="https://doi.org/10.1609/aaai.v37i3.25446">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent research showed that the dual-pixel sensor has made great progress in defocus map estimation and image defocus deblurring. However, extracting real-time dual-pixel views is troublesome and complex in algorithm deployment. Moreover, the deblurred image generated by the defocus deblurring network lacks high-frequency details, which is unsatisfactory in human perception. To overcome this issue, we propose a novel defocus deblurring method that uses the guidance of the defocus map to implement image deblurring. The proposed method consists of a learnable blur kernel to estimate the defocus map, which is an unsupervised method, and a single-image defocus deblurring generative adversarial network (DefocusGAN) for the first time. The proposed network can learn the deblurring of different regions and recover realistic details. We propose a defocus adversarial loss to guide this training process. Competitive experimental results confirm that with a learnable blur kernel, the generated defocus map can achieve results comparable to supervised methods. In the single-image defocus deblurring task, the proposed method achieves state-of-the-art results, especially significant improvements in perceptual quality, where PSNR reaches 25.56 dB and LPIPS reaches 0.111.},
  archive   = {C_AAAI},
  author    = {Jucai Zhai and Pengcheng Zeng and Chihao Ma and Jie Chen and Yong Zhao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25446},
  pages     = {3384-3392},
  title     = {Learnable blur kernel for single-image defocus deblurring in the wild},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-modal knowledge hypergraph for diverse image
retrieval. <em>AAAI</em>, 3376–3383. (<a
href="https://doi.org/10.1609/aaai.v37i3.25445">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The task of keyword-based diverse image retrieval has received considerable attention due to its wide demand in real-world scenarios. Existing methods either rely on a multi-stage re-ranking strategy based on human design to diversify results, or extend sub-semantics via an implicit generator, which either relies on manual labor or lacks explainability. To learn more diverse and explainable representations, we capture sub-semantics in an explicit manner by leveraging the multi-modal knowledge graph (MMKG) that contains richer entities and relations. However, the huge domain gap between the off-the-shelf MMKG and retrieval datasets, as well as the semantic gap between images and texts, make the fusion of MMKG difficult. In this paper, we pioneer a degree-free hypergraph solution that models many-to-many relations to address the challenge of heterogeneous sources and heterogeneous modalities. Specifically, a hyperlink-based solution, Multi-Modal Knowledge Hyper Graph (MKHG) is proposed, which bridges heterogeneous data via various hyperlinks to diversify sub-semantics. Among them, a hypergraph construction module first customizes various hyperedges to link the heterogeneous MMKG and retrieval databases. A multi-modal instance bagging module then explicitly selects instances to diversify the semantics. Meanwhile, a diverse concept aggregator flexibly adapts key sub-semantics. Finally, several losses are adopted to optimize the semantic space. Extensive experiments on two real-world datasets have well verified the effectiveness and explainability of our proposed method.},
  archive   = {C_AAAI},
  author    = {Yawen Zeng and Qin Jin and Tengfei Bao and Wenfeng Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25445},
  pages     = {3376-3383},
  title     = {Multi-modal knowledge hypergraph for diverse image retrieval},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FlowFace: Semantic flow-guided shape-aware face swapping.
<em>AAAI</em>, 3367–3375. (<a
href="https://doi.org/10.1609/aaai.v37i3.25444">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this work, we propose a semantic flow-guided two-stage framework for shape-aware face swapping, namely FlowFace. Unlike most previous methods that focus on transferring the source inner facial features but neglect facial contours, our FlowFace can transfer both of them to a target face, thus leading to more realistic face swapping. Concretely, our FlowFace consists of a face reshaping network and a face swapping network. The face reshaping network addresses the shape outline differences between the source and target faces. It first estimates a semantic flow (i.e. face shape differences) between the source and the target face, and then explicitly warps the target face shape with the estimated semantic flow. After reshaping, the face swapping network generates inner facial features that exhibit the identity of the source face. We employ a pre-trained face masked autoencoder (MAE) to extract facial features from both the source face and the target face. In contrast to previous methods that use identity embedding to preserve identity information, the features extracted by our encoder can better capture facial appearances and identity information. Then, we develop a cross-attention fusion module to adaptively fuse inner facial features from the source face with the target facial attributes, thus leading to better identity preservation. Extensive quantitative and qualitative experiments on in-the-wild faces demonstrate that our FlowFace outperforms the state-of-the-art significantly.},
  archive   = {C_AAAI},
  author    = {Hao Zeng and Wei Zhang and Changjie Fan and Tangjie Lv and Suzhen Wang and Zhimeng Zhang and Bowen Ma and Lincheng Li and Yu Ding and Xin Yu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25444},
  pages     = {3367-3375},
  title     = {FlowFace: Semantic flow-guided shape-aware face swapping},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cyclically disentangled feature translation for face
anti-spoofing. <em>AAAI</em>, 3358–3366. (<a
href="https://doi.org/10.1609/aaai.v37i3.25443">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Current domain adaptation methods for face anti-spoofing leverage labeled source domain data and unlabeled target domain data to obtain a promising generalizable decision boundary. However, it is usually difficult for these methods to achieve a perfect domain-invariant liveness feature disentanglement, which may degrade the final classification performance by domain differences in illumination, face category, spoof type, etc. In this work, we tackle cross-scenario face anti-spoofing by proposing a novel domain adaptation method called cyclically disentangled feature translation network (CDFTN). Specifically, CDFTN generates pseudo-labeled samples that possess: 1) source domain-invariant liveness features and 2) target domain-specific content features, which are disentangled through domain adversarial training. A robust classifier is trained based on the synthetic pseudo-labeled images under the supervision of source domain labels. We further extend CDFTN for multi-target domain adaptation by leveraging data from more unlabeled target domains. Extensive experiments on several public datasets demonstrate that our proposed approach significantly outperforms the state of the art. Code and models are available at https://github.com/vis-face/CDFTN.},
  archive   = {C_AAAI},
  author    = {Haixiao Yue and Keyao Wang and Guosheng Zhang and Haocheng Feng and Junyu Han and Errui Ding and Jingdong Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25443},
  pages     = {3358-3366},
  title     = {Cyclically disentangled feature translation for face anti-spoofing},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Pseudo label-guided model inversion attack via conditional
generative adversarial network. <em>AAAI</em>, 3349–3357. (<a
href="https://doi.org/10.1609/aaai.v37i3.25442">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Model inversion (MI) attacks have raised increasing concerns about privacy, which can reconstruct training data from public models. Indeed, MI attacks can be formalized as an optimization problem that seeks private data in a certain space. Recent MI attacks leverage a generative adversarial network (GAN) as an image prior to narrow the search space, and can successfully reconstruct even the high-dimensional data (e.g., face images). However, these generative MI attacks do not fully exploit the potential capabilities of the target model, still leading to a vague and coupled search space, i.e., different classes of images are coupled in the search space. Besides, the widely used cross-entropy loss in these attacks suffers from gradient vanishing. To address these problems, we propose Pseudo Label-Guided MI (PLG-MI) attack via conditional GAN (cGAN). At first, a top-n selection strategy is proposed to provide pseudo-labels for public data, and use pseudo-labels to guide the training of the cGAN. In this way, the search space is decoupled for different classes of images. Then a max-margin loss is introduced to improve the search process on the subspace of a target class. Extensive experiments demonstrate that our PLG-MI attack significantly improves the attack success rate and visual quality for various datasets and models, notably, 2 ∼ 3× better than state-of-the-art attacks under large distributional shifts. Our code is available at: https://github.com/LetheSec/PLG-MI-Attack.},
  archive   = {C_AAAI},
  author    = {Xiaojian Yuan and Kejiang Chen and Jie Zhang and Weiming Zhang and Nenghai Yu and Yang Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25442},
  pages     = {3349-3357},
  title     = {Pseudo label-guided model inversion attack via conditional generative adversarial network},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Structure flow-guided network for real depth
super-resolution. <em>AAAI</em>, 3340–3348. (<a
href="https://doi.org/10.1609/aaai.v37i3.25441">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Real depth super-resolution (DSR), unlike synthetic settings, is a challenging task due to the structural distortion and the edge noise caused by the natural degradation in real-world low-resolution (LR) depth maps. These defeats result in significant structure inconsistency between the depth map and the RGB guidance, which potentially confuses the RGB-structure guidance and thereby degrades the DSR quality. In this paper, we propose a novel structure flow-guided DSR framework, where a cross-modality flow map is learned to guide the RGB-structure information transferring for precise depth upsampling. Specifically, our framework consists of a cross-modality flow-guided upsampling network (CFUNet) and a flow-enhanced pyramid edge attention network (PEANet). CFUNet contains a trilateral self-attention module combining both the geometric and semantic correlations for reliable cross-modality flow learning. Then, the learned flow maps are combined with the grid-sampling mechanism for coarse high-resolution (HR) depth prediction. PEANet targets at integrating the learned flow map as the edge attention into a pyramid network to hierarchically learn the edge-focused guidance feature for depth edge refinement. Extensive experiments on real and synthetic DSR datasets verify that our approach achieves excellent performance compared to state-of-the-art methods. Our code is available at: https://github.com/Yuanjiayii/DSR-SFG.},
  archive   = {C_AAAI},
  author    = {Jiayi Yuan and Haobo Jiang and Xiang Li and Jianjun Qian and Jun Li and Jian Yang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25441},
  pages     = {3340-3348},
  title     = {Structure flow-guided network for real depth super-resolution},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Recurrent structure attention guidance for depth
super-resolution. <em>AAAI</em>, 3331–3339. (<a
href="https://doi.org/10.1609/aaai.v37i3.25440">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Image guidance is an effective strategy for depth super-resolution. Generally, most existing methods employ hand-crafted operators to decompose the high-frequency (HF) and low-frequency (LF) ingredients from low-resolution depth maps and guide the HF ingredients by directly concatenating them with image features. However, the hand-designed operators usually cause inferior HF maps (e.g., distorted or structurally missing) due to the diverse appearance of complex depth maps. Moreover, the direct concatenation often results in weak guidance because not all image features have a positive effect on the HF maps. In this paper, we develop a recurrent structure attention guided (RSAG) framework, consisting of two important parts. First, we introduce a deep contrastive network with multi-scale filters for adaptive frequency-domain separation, which adopts contrastive networks from large filters to small ones to calculate the pixel contrasts for adaptive high-quality HF predictions. Second, instead of the coarse concatenation guidance, we propose a recurrent structure attention block, which iteratively utilizes the latest depth estimation and the image features to jointly select clear patterns and boundaries, aiming at providing refined guidance for accurate depth recovery. In addition, we fuse the features of HF maps to enhance the edge structures in the decomposed LF maps. Extensive experiments show that our approach obtains superior performance compared with state-of-the-art depth super-resolution methods. Our code is available at: https://github.com/Yuanjiayii/DSR-RSAG.},
  archive   = {C_AAAI},
  author    = {Jiayi Yuan and Haobo Jiang and Xiang Li and Jianjun Qian and Jun Li and Jian Yang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25440},
  pages     = {3331-3339},
  title     = {Recurrent structure attention guidance for depth super-resolution},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Frame-level label refinement for skeleton-based
weakly-supervised action recognition. <em>AAAI</em>, 3322–3330. (<a
href="https://doi.org/10.1609/aaai.v37i3.25439">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In recent years, skeleton-based action recognition has achieved remarkable performance in understanding human motion from sequences of skeleton data, which is an important medium for synthesizing realistic human movement in various applications. However, existing methods assume that each action clip is manually trimmed to contain one specific action, which requires a significant amount of effort for annotation. To solve this problem, we consider a novel problem of skeleton-based weakly-supervised temporal action localization (S-WTAL), where we need to recognize and localize human action segments in untrimmed skeleton videos given only the video-level labels. Although this task is challenging due to the sparsity of skeleton data and the lack of contextual clues from interaction with other objects and the environment, we present a frame-level label refinement framework based on a spatio-temporal graph convolutional network (ST-GCN) to overcome these difficulties. We use multiple instance learning (MIL) with video-level labels to generate the frame-level predictions. Inspired by advances in handling the noisy label problem, we introduce a label cleaning strategy of the frame-level pseudo labels to guide the learning process. The network parameters and the frame-level predictions are alternately updated to obtain the final results. We extensively evaluate the effectiveness of our learning approach on skeleton-based action recognition benchmarks. The state-of-the-art experimental results demonstrate that the proposed method can recognize and localize action segments of the skeleton data.},
  archive   = {C_AAAI},
  author    = {Qing Yu and Kent Fujiwara},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25439},
  pages     = {3322-3330},
  title     = {Frame-level label refinement for skeleton-based weakly-supervised action recognition},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Rethinking rotation invariance with point cloud
registration. <em>AAAI</em>, 3313–3321. (<a
href="https://doi.org/10.1609/aaai.v37i3.25438">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent investigations on rotation invariance for 3D point clouds have been devoted to devising rotation-invariant feature descriptors or learning canonical spaces where objects are semantically aligned. Examinations of learning frameworks for invariance have seldom been looked into. In this work, we review rotation invariance (RI) in terms of point cloud registration (PCR) and propose an effective framework for rotation invariance learning via three sequential stages, namely rotation-invariant shape encoding, aligned feature integration, and deep feature registration. We first encode shape descriptors constructed with respect to reference frames defined over different scales, e.g., local patches and global topology, to generate rotation-invariant latent shape codes. Within the integration stage, we propose an Aligned Integration Transformer (AIT) to produce a discriminative feature representation by integrating point-wise self- and cross-relations established within the shape codes. Meanwhile, we adopt rigid transformations between reference frames to align the shape codes for feature consistency across different scales. Finally, the deep integrated feature is registered to both rotation-invariant shape codes to maximize their feature similarities, such that rotation invariance of the integrated feature is preserved and shared semantic information is implicitly extracted from shape codes. Experimental results on 3D shape classification, part segmentation, and retrieval tasks prove the feasibility of our framework. Our project page is released at: https://rotation3d.github.io/.},
  archive   = {C_AAAI},
  author    = {Jianhui Yu and Chaoyi Zhang and Weidong Cai},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25438},
  pages     = {3313-3321},
  title     = {Rethinking rotation invariance with point cloud registration},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generalizing multiple object tracking to unseen domains by
introducing natural language representation. <em>AAAI</em>, 3304–3312.
(<a href="https://doi.org/10.1609/aaai.v37i3.25437">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Although existing multi-object tracking (MOT) algorithms have obtained competitive performance on various benchmarks, almost all of them train and validate models on the same domain. The domain generalization problem of MOT is hardly studied. To bridge this gap, we first draw the observation that the high-level information contained in natural language is domain invariant to different tracking domains. Based on this observation, we propose to introduce natural language representation into visual MOT models for boosting the domain generalization ability. However, it is infeasible to label every tracking target with a textual description. To tackle this problem, we design two modules, namely visual context prompting (VCP) and visual-language mixing (VLM). Specifically, VCP generates visual prompts based on the input frames. VLM joints the information in the generated visual prompts and the textual prompts from a pre-defined Trackbook to obtain instance-level pseudo textual description, which is domain invariant to different tracking scenes. Through training models on MOT17 and validating them on MOT20, we observe that the pseudo textual descriptions generated by our proposed modules improve the generalization performance of query-based trackers by large margins.},
  archive   = {C_AAAI},
  author    = {En Yu and Songtao Liu and Zhuoling Li and Jinrong Yang and Zeming Li and Shoudong Han and Wenbing Tao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25437},
  pages     = {3304-3312},
  title     = {Generalizing multiple object tracking to unseen domains by introducing natural language representation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Lifelong person re-identification via knowledge refreshing
and consolidation. <em>AAAI</em>, 3295–3303. (<a
href="https://doi.org/10.1609/aaai.v37i3.25436">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Lifelong person re-identification (LReID) is in significant demand for real-world development as a large amount of ReID data is captured from diverse locations over time and cannot be accessed at once inherently. However, a key challenge for LReID is how to incrementally preserve old knowledge and gradually add new capabilities to the system. Unlike most existing LReID methods, which mainly focus on dealing with catastrophic forgetting, our focus is on a more challenging problem, which is, not only trying to reduce the forgetting on old tasks but also aiming to improve the model performance on both new and old tasks during the lifelong learning process. Inspired by the biological process of human cognition where the somatosensory neocortex and the hippocampus work together in memory consolidation, we formulated a model called Knowledge Refreshing and Consolidation (KRC) that achieves both positive forward and backward transfer. More specifically, a knowledge refreshing scheme is incorporated with the knowledge rehearsal mechanism to enable bi-directional knowledge transfer by introducing a dynamic memory model and an adaptive working model. Moreover, a knowledge consolidation scheme operating on the dual space further improves model stability over the long-term. Extensive evaluations show KRC’s superiority over the state-of-the-art LReID methods with challenging pedestrian benchmarks. Code is available at https://github.com/cly234/LReID-KRKC.},
  archive   = {C_AAAI},
  author    = {Chunlin Yu and Ye Shi and Zimo Liu and Shenghua Gao and Jingya Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25436},
  pages     = {3295-3303},
  title     = {Lifelong person re-identification via knowledge refreshing and consolidation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unbiased heterogeneous scene graph generation with
relation-aware message passing neural network. <em>AAAI</em>, 3285–3294.
(<a href="https://doi.org/10.1609/aaai.v37i3.25435">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent scene graph generation (SGG) frameworks have focused on learning complex relationships among multiple objects in an image. Thanks to the nature of the message passing neural network (MPNN) that models high-order interactions between objects and their neighboring objects, they are dominant representation learning modules for SGG. However, existing MPNN-based frameworks assume the scene graph as a homogeneous graph, which restricts the context-awareness of visual relations between objects. That is, they overlook the fact that the relations tend to be highly dependent on the objects with which the relations are associated. In this paper, we propose an unbiased heterogeneous scene graph generation (HetSGG) framework that captures relation-aware context using message passing neural networks. We devise a novel message passing layer, called relation-aware message passing neural network (RMP), that aggregates the contextual information of an image considering the predicate type between objects. Our extensive evaluations demonstrate that HetSGG outperforms state-of-the-art methods, especially outperforming on tail predicate classes. The source code for HetSGG is available at https://github.com/KanghoonYoon/hetsgg-torch},
  archive   = {C_AAAI},
  author    = {Kanghoon Yoon and Kibum Kim and Jinyoung Moon and Chanyoung Park},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25435},
  pages     = {3285-3294},
  title     = {Unbiased heterogeneous scene graph generation with relation-aware message passing neural network},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Class-independent regularization for learning with noisy
labels. <em>AAAI</em>, 3276–3284. (<a
href="https://doi.org/10.1609/aaai.v37i3.25434">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Training deep neural networks (DNNs) with noisy labels often leads to poorly generalized models as DNNs tend to memorize the noisy labels in training. Various strategies have been developed for improving sample selection precision and mitigating the noisy label memorization issue. However, most existing works adopt a class-dependent softmax classifier that is vulnerable to noisy labels by entangling the classification of multi-class features. This paper presents a class-independent regularization (CIR) method that can effectively alleviate the negative impact of noisy labels in DNN training. CIR regularizes the class-dependent softmax classifier by introducing multi-binary classifiers each of which takes care of one class only. Thanks to its class-independent nature, CIR is tolerant to noisy labels as misclassification by one binary classifier does not affect others. For effective training of CIR, we design a heterogeneous adaptive co-teaching strategy that forces the class-independent and class-dependent classifiers to focus on sample selection and image classification, respectively, in a cooperative manner. Extensive experiments show that CIR achieves superior performance consistently across multiple benchmarks with both synthetic and real images. Code is available at https://github.com/RumengYi/CIR.},
  archive   = {C_AAAI},
  author    = {Rumeng Yi and Dayan Guan and Yaping Huang and Shijian Lu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25434},
  pages     = {3276-3284},
  title     = {Class-independent regularization for learning with noisy labels},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Can we find strong lottery tickets in generative models?
<em>AAAI</em>, 3267–3275. (<a
href="https://doi.org/10.1609/aaai.v37i3.25433">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Yes. In this paper, we investigate strong lottery tickets in generative models, the subnetworks that achieve good generative performance without any weight update. Neural network pruning is considered the main cornerstone of model compression for reducing the costs of computation and memory. Unfortunately, pruning a generative model has not been extensively explored, and all existing pruning algorithms suffer from excessive weight-training costs, performance degradation, limited generalizability, or complicated training. To address these problems, we propose to find a strong lottery ticket via moment-matching scores. Our experimental results show that the discovered subnetwork can perform similarly or better than the trained dense model even when only 10\% of the weights remain. To the best of our knowledge, we are the first to show the existence of strong lottery tickets in generative models and provide an algorithm to find it stably. Our code and supplementary materials are publicly available at https://lait-cvlab.github.io/SLT-in-Generative-Models/.},
  archive   = {C_AAAI},
  author    = {Sangyeop Yeo and Yoojin Jang and Jy-yong Sohn and Dongyoon Han and Jaejun Yoo},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25433},
  pages     = {3267-3275},
  title     = {Can we find strong lottery tickets in generative models?},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Infusing definiteness into randomness: Rethinking
composition styles for deep image matting. <em>AAAI</em>, 3259–3266. (<a
href="https://doi.org/10.1609/aaai.v37i3.25432">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the composition style in deep image matting, a notion that characterizes a data generation flow on how to exploit limited foregrounds and random backgrounds to form a training dataset. Prior art executes this flow in a completely random manner by simply going through the foreground pool or by optionally combining two foregrounds before foreground-background composition. In this work, we first show that naive foreground combination can be problematic and therefore derive an alternative formulation to reasonably combine foregrounds. Our second contribution is an observation that matting performance can benefit from a certain occurrence frequency of combined foregrounds and their associated source foregrounds during training. Inspired by this, we introduce a novel composition style that binds the source and combined foregrounds in a definite triplet. In addition, we also find that different orders of foreground combination lead to different foreground patterns, which further inspires a quadruplet-based composition style. Results under controlled experiments on four matting baselines show that our composition styles outperform existing ones and invite consistent performance improvement on both composited and real-world datasets. Code is available at: https://github.com/coconuthust/composition_styles},
  archive   = {C_AAAI},
  author    = {Zixuan Ye and Yutong Dai and Chaoyi Hong and Zhiguo Cao and Hao Lu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25432},
  pages     = {3259-3266},
  title     = {Infusing definiteness into randomness: Rethinking composition styles for deep image matting},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning second-order attentive context for efficient
correspondence pruning. <em>AAAI</em>, 3250–3258. (<a
href="https://doi.org/10.1609/aaai.v37i3.25431">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Correspondence pruning aims to search consistent correspondences (inliers) from a set of putative correspondences. It is challenging because of the disorganized spatial distribution of numerous outliers, especially when putative correspondences are largely dominated by outliers. It&#39;s more challenging to ensure effectiveness while maintaining efficiency. In this paper, we propose an effective and efficient method for correspondence pruning. Inspired by the success of attentive context in correspondence problems, we first extend the attentive context to the first-order attentive context and then introduce the idea of attention in attention (ANA) to model second-order attentive context for correspondence pruning. Compared with first-order attention that focuses on feature-consistent context, second-order attention dedicates to attention weights itself and provides an additional source to encode consistent context from the attention map. For efficiency, we derive two approximate formulations for the naive implementation of second-order attention to optimize the cubic complexity to linear complexity, such that second-order attention can be used with negligible computational overheads. We further implement our formulations in a second-order context layer and then incorporate the layer in an ANA block. Extensive experiments demonstrate that our method is effective and efficient in pruning outliers, especially in high-outlier-ratio cases. Compared with the state-of-the-art correspondence pruning approach LMCNet, our method runs 14 times faster while maintaining a competitive accuracy.},
  archive   = {C_AAAI},
  author    = {Xinyi Ye and Weiyue Zhao and Hao Lu and Zhiguo Cao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25431},
  pages     = {3250-3258},
  title     = {Learning second-order attentive context for efficient correspondence pruning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DPText-DETR: Towards better scene text detection with
dynamic points in transformer. <em>AAAI</em>, 3241–3249. (<a
href="https://doi.org/10.1609/aaai.v37i3.25430">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, Transformer-based methods, which predict polygon points or Bezier curve control points for localizing texts, are popular in scene text detection. However, these methods built upon detection transformer framework might achieve sub-optimal training efficiency and performance due to coarse positional query modeling. In addition, the point label form exploited in previous works implies the reading order of humans, which impedes the detection robustness from our observation. To address these challenges, this paper proposes a concise Dynamic Point Text DEtection TRansformer network, termed DPText-DETR. In detail, DPText-DETR directly leverages explicit point coordinates to generate position queries and dynamically updates them in a progressive way. Moreover, to improve the spatial inductive bias of non-local self-attention in Transformer, we present an Enhanced Factorized Self-Attention module which provides point queries within each instance with circular shape guidance. Furthermore, we design a simple yet effective positional label form to tackle the side effect of the previous form. To further evaluate the impact of different label forms on the detection robustness in real-world scenario, we establish an Inverse-Text test set containing 500 manually labeled images. Extensive experiments prove the high training efficiency, robustness, and state-of-the-art performance of our method on popular benchmarks. The code and the Inverse-Text test set are available at https://github.com/ymy-k/DPText-DETR.},
  archive   = {C_AAAI},
  author    = {Maoyuan Ye and Jing Zhang and Shanshan Zhao and Juhua Liu and Bo Du and Dacheng Tao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25430},
  pages     = {3241-3249},
  title     = {DPText-DETR: Towards better scene text detection with dynamic points in transformer},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). LidarMultiNet: Towards a unified multi-task network for
LiDAR perception. <em>AAAI</em>, 3231–3240. (<a
href="https://doi.org/10.1609/aaai.v37i3.25429">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {LiDAR-based 3D object detection, semantic segmentation, and panoptic segmentation are usually implemented in specialized networks with distinctive architectures that are difficult to adapt to each other. This paper presents LidarMultiNet, a LiDAR-based multi-task network that unifies these three major LiDAR perception tasks. Among its many benefits, a multi-task network can reduce the overall cost by sharing weights and computation among multiple tasks. However, it typically underperforms compared to independently combined single-task models. The proposed LidarMultiNet aims to bridge the performance gap between the multi-task network and multiple single-task networks. At the core of LidarMultiNet is a strong 3D voxel-based encoder-decoder architecture with a Global Context Pooling (GCP) module extracting global contextual features from a LiDAR frame. Task-specific heads are added on top of the network to perform the three LiDAR perception tasks. More tasks can be implemented simply by adding new task-specific heads while introducing little additional cost. A second stage is also proposed to refine the first-stage segmentation and generate accurate panoptic segmentation results. LidarMultiNet is extensively tested on both Waymo Open Dataset and nuScenes dataset, demonstrating for the first time that major LiDAR perception tasks can be unified in a single strong network that is trained end-to-end and achieves state-of-the-art performance. Notably, LidarMultiNet reaches the official 1 place in the Waymo Open Dataset 3D semantic segmentation challenge 2022 with the highest mIoU and the best accuracy for most of the 22 classes on the test set, using only LiDAR points as input. It also sets the new state-of-the-art for a single model on the Waymo 3D object detection benchmark and three nuScenes benchmarks.},
  archive   = {C_AAAI},
  author    = {Dongqiangzi Ye and Zixiang Zhou and Weijia Chen and Yufei Xie and Yu Wang and Panqu Wang and Hassan Foroosh},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25429},
  pages     = {3231-3240},
  title     = {LidarMultiNet: Towards a unified multi-task network for LiDAR perception},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Semantics-aware dynamic localization and refinement for
referring image segmentation. <em>AAAI</em>, 3222–3230. (<a
href="https://doi.org/10.1609/aaai.v37i3.25428">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Referring image segmentation segments an image from a language expression. With the aim of producing high-quality masks, existing methods often adopt iterative learning approaches that rely on RNNs or stacked attention layers to refine vision-language features. Despite their complexity, RNN-based methods are subject to specific encoder choices, while attention-based methods offer limited gains. In this work, we introduce a simple yet effective alternative for progressively learning discriminative multi-modal features. The core idea of our approach is to leverage a continuously updated query as the representation of the target object and at each iteration, strengthen multi-modal features strongly correlated to the query while weakening less related ones. As the query is initialized by language features and successively updated by object features, our algorithm gradually shifts from being localization-centric to segmentation-centric. This strategy enables the incremental recovery of missing object parts and/or removal of extraneous parts through iteration. Compared to its counterparts, our method is more versatile—it can be plugged into prior arts straightforwardly and consistently bring improvements. Experimental results on the challenging datasets of RefCOCO, RefCOCO+, and G-Ref demonstrate its advantage with respect to the state-of-the-art methods.},
  archive   = {C_AAAI},
  author    = {Zhao Yang and Jiaqi Wang and Yansong Tang and Kai Chen and Hengshuang Zhao and Philip H.S. Torr},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25428},
  pages     = {3222-3230},
  title     = {Semantics-aware dynamic localization and refinement for referring image segmentation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Low-light image enhancement network based on multi-scale
feature complementation. <em>AAAI</em>, 3214–3221. (<a
href="https://doi.org/10.1609/aaai.v37i3.25427">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Images captured in low-light environments have problems of insufficient brightness and low contrast, which will affect subsequent image processing tasks. Although most current enhancement methods can obtain high-contrast images, they still suffer from noise amplification and color distortion. To address these issues, this paper proposes a low-light image enhancement network based on multi-scale feature complementation (LIEN-MFC), which is a U-shaped encoder-decoder network supervised by multiple images of different scales. In the encoder, four feature extraction branches are constructed to extract features of low-light images at different scales. In the decoder, to ensure the integrity of the learned features at each scale, a feature supplementary fusion module (FSFM) is proposed to complement and integrate features from different branches of the encoder and decoder. In addition, a feature restoration module (FRM) and an image reconstruction module (IRM) are built in each branch to reconstruct the restored features and output enhanced images. To better train the network, a joint loss function is defined, in which a discriminative loss term is designed to ensure that the enhanced results better meet the visual properties of the human eye. Extensive experiments on benchmark datasets show that the proposed method outperforms some state-of-the-art methods subjectively and objectively.},
  archive   = {C_AAAI},
  author    = {Yong Yang and Wenzhi Xu and Shuying Huang and Weiguo Wan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25427},
  pages     = {3214-3221},
  title     = {Low-light image enhancement network based on multi-scale feature complementation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Towards global video scene segmentation with context-aware
transformer. <em>AAAI</em>, 3206–3213. (<a
href="https://doi.org/10.1609/aaai.v37i3.25426">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Videos such as movies or TV episodes usually need to divide the long storyline into cohesive units, i.e., scenes, to facilitate the understanding of video semantics. The key challenge lies in finding the boundaries of scenes by comprehensively considering the complex temporal structure and semantic information. To this end, we introduce a novel Context-Aware Transformer (CAT) with a self-supervised learning framework to learn high-quality shot representations, for generating well-bounded scenes. More specifically, we design the CAT with local-global self-attentions, which can effectively consider both the long-term and short-term context to improve the shot encoding. For training the CAT, we adopt the self-supervised learning schema. Firstly, we leverage shot-to-scene level pretext tasks to facilitate the pre-training with pseudo boundary, which guides CAT to learn the discriminative shot representations that maximize intra-scene similarity and inter-scene discrimination in an unsupervised manner. Then, we transfer contextual representations for fine-tuning the CAT with supervised data, which encourages CAT to accurately detect the boundary for scene segmentation. As a result, CAT is able to learn the context-aware shot representations and provides global guidance for scene segmentation. Our empirical analyses show that CAT can achieve state-of-the-art performance when conducting the scene segmentation task on the MovieNet dataset, e.g., offering 2.15 improvements on AP.},
  archive   = {C_AAAI},
  author    = {Yang Yang and Yurui Huang and Weili Guo and Baohua Xu and Dingyin Xia},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25426},
  pages     = {3206-3213},
  title     = {Towards global video scene segmentation with context-aware transformer},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AutoStegaFont: Synthesizing vector fonts for hiding
information in documents. <em>AAAI</em>, 3198–3205. (<a
href="https://doi.org/10.1609/aaai.v37i3.25425">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Hiding information in text documents has been a hot topic recently, with the most typical schemes of utilizing fonts. By constructing several fonts with similar appearances, information can be effectively represented and embedded in documents. However, due to the unstructured characteristic, font vectors are more difficult to synthesize than font images. Existing methods mainly use handcrafted features to design the fonts manually, which is time-consuming and labor-intensive. Moreover, due to the diversity of fonts, handcrafted features are not generalizable to different fonts. Besides, in practice, since documents might be distorted through transmission, ensuring extractability under distortions is also an important requirement. Therefore, three requirements are imposed on vector font generation in this domain: automaticity, generalizability, and robustness. However, none of the existing methods can satisfy these requirements well and simultaneously. To satisfy the above requirements, we propose AutoStegaFont, an automatic vector font synthesis scheme for hiding information in documents. Specifically, we design a two-stage and dual-modality learning framework. In the first stage, we jointly train an encoder and a decoder to invisibly encode the font images with different information. To ensure robustness, we target designing a noise layer to work with the encoder and decoder during training. In the second stage, we employ a differentiable rasterizer to establish a connection between the image and the vector modality. Then, we design an optimization algorithm to convey the information from the encoded image to the corresponding vector. Thus the encoded font vectors can be automatically generated. Extensive experiments demonstrate the superior performance of our scheme in automatically synthesizing vector fonts for hiding information in documents, with robustness to distortions caused by low-resolution screenshots, printing, and photography. Besides, the proposed framework has better generalizability to fonts with diverse styles and languages.},
  archive   = {C_AAAI},
  author    = {Xi Yang and Jie Zhang and Han Fang and Chang Liu and Zehua Ma and Weiming Zhang and Nenghai Yu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25425},
  pages     = {3198-3205},
  title     = {AutoStegaFont: Synthesizing vector fonts for hiding information in documents},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Contrastive multi-task dense prediction. <em>AAAI</em>,
3190–3197. (<a href="https://doi.org/10.1609/aaai.v37i3.25424">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper targets the problem of multi-task dense prediction which aims to achieve simultaneous learning and inference on a bunch of multiple dense prediction tasks in a single framework. A core objective in design is how to effectively model cross-task interactions to achieve a comprehensive improvement on different tasks based on their inherent complementarity and consistency. Existing works typically design extra expensive distillation modules to perform explicit interaction computations among different task-specific features in both training and inference, bringing difficulty in adaptation for different task sets, and reducing efficiency due to clearly increased size of multi-task models. In contrast, we introduce feature-wise contrastive consistency into modeling the cross-task interactions for multi-task dense prediction. We propose a novel multi-task contrastive regularization method based on the consistency to effectively boost the representation learning of the different sub-tasks, which can also be easily generalized to different multi-task dense prediction frameworks, and costs no additional computation in the inference. Extensive experiments on two challenging datasets (i.e. NYUD-v2 and Pascal-Context) clearly demonstrate the superiority of the proposed multi-task contrastive learning approach for dense predictions, establishing new state-of-the-art performances.},
  archive   = {C_AAAI},
  author    = {Siwei Yang and Hanrong Ye and Dan Xu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25424},
  pages     = {3190-3197},
  title     = {Contrastive multi-task dense prediction},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spatiotemporal deformation perception for fisheye video
rectification. <em>AAAI</em>, 3181–3189. (<a
href="https://doi.org/10.1609/aaai.v37i3.25423">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Although the distortion correction of fisheye images has been extensively studied, the correction of fisheye videos is still an elusive challenge. For different frames of the fisheye video, the existing image correction methods ignore the correlation of sequences, resulting in temporal jitter in the corrected video. To solve this problem, we propose a temporal weighting scheme to get a plausible global optical flow, which mitigates the jitter effect by progressively reducing the weight of frames. Subsequently, we observe that the inter-frame optical flow of the video is facilitated to perceive the local spatial deformation of the fisheye video. Therefore, we derive the spatial deformation through the flows of fisheye and distorted-free videos, thereby enhancing the local accuracy of the predicted result. However, the independent correction for each frame disrupts the temporal correlation. Due to the property of fisheye video, a distorted moving object may be able to find its distorted-free pattern at another moment. To this end, a temporal deformation aggregator is designed to reconstruct the deformation correlation between frames and provide a reliable global feature. Our method achieves an end-to-end correction and demonstrates superiority in correction quality and stability compared with the SOTA correction methods.},
  archive   = {C_AAAI},
  author    = {Shangrong Yang and Chunyu Lin and Kang Liao and Yao Zhao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25423},
  pages     = {3181-3189},
  title     = {Spatiotemporal deformation perception for fisheye video rectification},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Local path integration for attribution. <em>AAAI</em>,
3173–3180. (<a href="https://doi.org/10.1609/aaai.v37i3.25422">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Path attribution methods are a popular tool to interpret a visual model&#39;s prediction on an input. They integrate model gradients for the input features over a path defined between the input and a reference, thereby satisfying certain desirable theoretical properties. However, their reliability hinges on the choice of the reference. Moreover, they do not exhibit weak dependence on the input, which leads to counter-intuitive feature attribution mapping. We show that path-based attribution can account for the weak dependence property by choosing the reference from the local distribution of the input. We devise a method to identify the local input distribution and propose a technique to stochastically integrate the model gradients over the paths defined by the references sampled from that distribution. Our local path integration (LPI) method is found to consistently outperform existing path attribution techniques when evaluated on deep visual models. Contributing to the ongoing search of reliable evaluation metrics for the interpretation methods, we also introduce DiffID metric that uses the relative difference between insertion and deletion games to alleviate the distribution shift problem faced by existing metrics. Our code is available at https://github.com/ypeiyu/LPI.},
  archive   = {C_AAAI},
  author    = {Peiyu Yang and Naveed Akhtar and Zeyi Wen and Ajmal Mian},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25422},
  pages     = {3173-3180},
  title     = {Local path integration for attribution},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Stop-gradient softmax loss for deep metric learning.
<em>AAAI</em>, 3164–3172. (<a
href="https://doi.org/10.1609/aaai.v37i3.25421">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep metric learning aims to learn a feature space that models the similarity between images, and feature normalization is a critical step for boosting performance. However directly optimizing L2-normalized softmax loss cause the network to fail to converge. Therefore some SOTA approaches appends a scale layer after the inner product to relieve the convergence problem, but it incurs a new problem that it&#39;s difficult to learn the best scaling parameters. In this letter, we look into the characteristic of softmax-based approaches and propose a novel learning objective function Stop-Gradient Softmax Loss (SGSL) to solve the convergence problem in softmax-based deep metric learning with L2-normalization. In addition, we found a useful trick named Remove the last BN-ReLU (RBR). It removes the last BN-ReLU in the backbone to reduce the learning burden of the model. Experimental results on four fine-grained image retrieval benchmarks show that our proposed approach outperforms most existing approaches, i.e., our approach achieves 75.9\% on CUB-200-2011, 94.7\% on CARS196 and 83.1\% on SOP which outperforms other approaches at least 1.7\%, 2.9\% and 1.7\% on Recall@1.},
  archive   = {C_AAAI},
  author    = {Lu Yang and Peng Wang and Yanning Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25421},
  pages     = {3164-3172},
  title     = {Stop-gradient softmax loss for deep metric learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-asymmetric invertible network for compression-aware
image rescaling. <em>AAAI</em>, 3155–3163. (<a
href="https://doi.org/10.1609/aaai.v37i3.25420">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {High-resolution (HR) images are usually downscaled to low-resolution (LR) ones for better display and afterward upscaled back to the original size to recover details. Recent work in image rescaling formulates downscaling and upscaling as a unified task and learns a bijective mapping between HR and LR via invertible networks. However, in real-world applications (e.g., social media), most images are compressed for transmission. Lossy compression will lead to irreversible information loss on LR images, hence damaging the inverse upscaling procedure and degrading the reconstruction accuracy. In this paper, we propose the Self-Asymmetric Invertible Network (SAIN) for compression-aware image rescaling. To tackle the distribution shift, we first develop an end-to-end asymmetric framework with two separate bijective mappings for high-quality and compressed LR images, respectively. Then, based on empirical analysis of this framework, we model the distribution of the lost information (including downscaling and compression) using isotropic Gaussian mixtures and propose the Enhanced Invertible Block to derive high-quality/compressed LR images in one forward pass. Besides, we design a set of losses to regularize the learned LR images and enhance the invertibility. Extensive experiments demonstrate the consistent improvements of SAIN across various image rescaling datasets in terms of both quantitative and qualitative evaluation under standard image compression formats (i.e., JPEG and WebP). Code is available at https://github.com/yang-jin-hai/SAIN.},
  archive   = {C_AAAI},
  author    = {Jinhai Yang and Mengxi Guo and Shijie Zhao and Junlin Li and Li Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25420},
  pages     = {3155-3163},
  title     = {Self-asymmetric invertible network for compression-aware image rescaling},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CoMAE: Single model hybrid pre-training on small-scale RGB-d
datasets. <em>AAAI</em>, 3145–3154. (<a
href="https://doi.org/10.1609/aaai.v37i3.25419">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Current RGB-D scene recognition approaches often train two standalone backbones for RGB and depth modalities with the same Places or ImageNet pre-training. However, the pre-trained depth network is still biased by RGB-based models which may result in a suboptimal solution. In this paper, we present a single-model self-supervised hybrid pre-training framework for RGB and depth modalities, termed as CoMAE. Our CoMAE presents a curriculum learning strategy to unify the two popular self-supervised representation learning algorithms: contrastive learning and masked image modeling. Specifically, we first build a patch-level alignment task to pre-train a single encoder shared by two modalities via cross-modal contrastive learning. Then, the pre-trained contrastive encoder is passed to a multi-modal masked autoencoder to capture the finer context features from a generative perspective. In addition, our single-model design without requirement of fusion module is very flexible and robust to generalize to unimodal scenario in both training and testing phases. Extensive experiments on SUN RGB-D and NYUDv2 datasets demonstrate the effectiveness of our CoMAE for RGB and depth representation learning. In addition, our experiment results reveal that CoMAE is a data-efficient representation learner. Although we only use the small-scale and unlabeled training set for pre-training, our CoMAE pre-trained models are still competitive to the state-of-the-art methods with extra large-scale and supervised RGB dataset pre-training. Code will be released at https://github.com/MCG-NJU/CoMAE.},
  archive   = {C_AAAI},
  author    = {Jiange Yang and Sheng Guo and Gangshan Wu and Limin Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25419},
  pages     = {3145-3154},
  title     = {CoMAE: Single model hybrid pre-training on small-scale RGB-D datasets},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Video event extraction via tracking visual states of
arguments. <em>AAAI</em>, 3136–3144. (<a
href="https://doi.org/10.1609/aaai.v37i3.25418">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Video event extraction aims to detect salient events from a video and identify the arguments for each event as well as their semantic roles. Existing methods focus on capturing the overall visual scene of each frame, ignoring fine-grained argument-level information. Inspired by the definition of events as changes of states, we propose a novel framework to detect video events by tracking the changes in the visual states of all involved arguments, which are expected to provide the most informative evidence for the extraction of video events. In order to capture the visual state changes of arguments, we decompose them into changes in pixels within objects, displacements of objects, and interactions among multiple arguments. We further propose Object State Embedding, Object Motion-aware Embedding and Argument Interaction Embedding to encode and track these changes respectively. Experiments on various video event extraction tasks demonstrate significant improvements compared to state-of-the-art models. In particular, on verb classification, we achieve 3.49\% absolute gains (19.53\% relative gains) in F1@5 on Video Situation Recognition. Our Code is publicly available at https://github.com/Shinetism/VStates for research purposes.},
  archive   = {C_AAAI},
  author    = {Guang Yang and Manling Li and Jiajie Zhang and Xudong Lin and Heng Ji and Shih-Fu Chang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25418},
  pages     = {3136-3144},
  title     = {Video event extraction via tracking visual states of arguments},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). One-shot replay: Boosting incremental object detection via
retrospecting one object. <em>AAAI</em>, 3127–3135. (<a
href="https://doi.org/10.1609/aaai.v37i3.25417">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Modern object detectors are ill-equipped to incrementally learn new emerging object classes over time due to the well-known phenomenon of catastrophic forgetting. Due to data privacy or limited storage, few or no images of the old data can be stored for replay. In this paper, we design a novel One-Shot Replay (OSR) method for incremental object detection, which is an augmentation-based method. Rather than storing original images, only one object-level sample for each old class is stored to reduce memory usage significantly, and we find that copy-paste is a harmonious way to replay for incremental object detection. In the incremental learning procedure, diverse augmented samples with co-occurrence of old and new objects to existing training data are generated. To introduce more variants for objects of old classes, we propose two augmentation modules. The object augmentation module aims to enhance the ability of the detector to perceive potential unknown objects. The feature augmentation module explores the relations between old and new classes and augments the feature space via analogy. Extensive experimental results on VOC2007 and COCO demonstrate that OSR can outperform the state-of-the-art incremental object detection methods without using extra wild data.},
  archive   = {C_AAAI},
  author    = {Dongbao Yang and Yu Zhou and Xiaopeng Hong and Aoting Zhang and Weiping Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25417},
  pages     = {3127-3135},
  title     = {One-shot replay: Boosting incremental object detection via retrospecting one object},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Self-supervised video representation learning via latent
time navigation. <em>AAAI</em>, 3118–3126. (<a
href="https://doi.org/10.1609/aaai.v37i3.25416">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Self-supervised video representation learning aimed at maximizing similarity between different temporal segments of one video, in order to enforce feature persistence over time. This leads to loss of pertinent information related to temporal relationships, rendering actions such as `enter&#39; and `leave&#39; to be indistinguishable. To mitigate this limitation, we propose Latent Time Navigation (LTN), a time parameterized contrastive learning strategy that is streamlined to capture fine-grained motions. Specifically, we maximize the representation similarity between different video segments from one video, while maintaining their representations time-aware along a subspace of the latent representation code including an orthogonal basis to represent temporal changes. Our extensive experimental analysis suggests that learning video representations by LTN consistently improves performance of action classification in fine-grained and human-oriented tasks (e.g., on Toyota Smarthome dataset). In addition, we demonstrate that our proposed model, when pre-trained on Kinetics-400, generalizes well onto the unseen real world video benchmark datasets UCF101 and HMDB51, achieving state-of-the-art performance in action recognition.},
  archive   = {C_AAAI},
  author    = {Di Yang and Yaohui Wang and Quan Kong and Antitza Dantcheva and Lorenzo Garattoni and Gianpiero Francesca and François Brémond},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25416},
  pages     = {3118-3126},
  title     = {Self-supervised video representation learning via latent time navigation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DesNet: Decomposed scale-consistent network for unsupervised
depth completion. <em>AAAI</em>, 3109–3117. (<a
href="https://doi.org/10.1609/aaai.v37i3.25415">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Unsupervised depth completion aims to recover dense depth from the sparse one without using the ground-truth annotation. Although depth measurement obtained from LiDAR is usually sparse, it contains valid and real distance information, i.e., scale-consistent absolute depth values. Meanwhile, scale-agnostic counterparts seek to estimate relative depth and have achieved impressive performance. To leverage both the inherent characteristics, we thus suggest to model scale-consistent depth upon unsupervised scale-agnostic frameworks. Specifically, we propose the decomposed scale-consistent learning (DSCL) strategy, which disintegrates the absolute depth into relative depth prediction and global scale estimation, contributing to individual learning benefits. But unfortunately, most existing unsupervised scale-agnostic frameworks heavily suffer from depth holes due to the extremely sparse depth input and weak supervisory signal. To tackle this issue, we introduce the global depth guidance (GDG) module, which attentively propagates dense depth reference into the sparse target via novel dense-to-sparse attention. Extensive experiments show the superiority of our method on outdoor KITTI, ranking 1st and outperforming the best KBNet more than 12\% in RMSE. Additionally, our approach achieves state-of-the-art performance on indoor NYUv2 benchmark as well.},
  archive   = {C_AAAI},
  author    = {Zhiqiang Yan and Kun Wang and Xiang Li and Zhenyu Zhang and Jun Li and Jian Yang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25415},
  pages     = {3109-3117},
  title     = {DesNet: Decomposed scale-consistent network for unsupervised depth completion},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Video-text pre-training with learned regions for retrieval.
<em>AAAI</em>, 3100–3108. (<a
href="https://doi.org/10.1609/aaai.v37i3.25414">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Video-Text pre-training aims at learning transferable representations from large-scale video-text pairs via aligning the semantics between visual and textual information. State-of-the-art approaches extract visual features from raw pixels in an end-to-end fashion. However, these methods operate at frame-level directly and thus overlook the spatio-temporal structure of objects in video, which yet has a strong synergy with nouns in textual descriptions. In this work, we propose a simple yet effective module for video-text representation learning, namely RegionLearner, which can take into account the structure of objects during pre-training on large-scale video-text pairs. Given a video, our module (1) first quantizes continuous visual features via clustering patch-features into the same cluster according to content similarity, then (2) generates learnable masks to aggregate fragmentary features into regions with complete semantics, and finally (3) models the spatio-temporal dependencies between different semantic regions. In contrast to using off-the-shelf object detectors, our proposed module does not require explicit supervision and is much more computationally efficient. We pre-train the proposed approach on the public WebVid2M and CC3M datasets. Extensive evaluations on four downstream video-text retrieval benchmarks clearly demonstrate the effectiveness of our RegionLearner.},
  archive   = {C_AAAI},
  author    = {Rui Yan and Mike Zheng Shou and Yixiao Ge and Jinpeng Wang and Xudong Lin and Guanyu Cai and Jinhui Tang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25414},
  pages     = {3100-3108},
  title     = {Video-text pre-training with learned regions for retrieval},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Rethinking disparity: A depth range free multi-view stereo
based on disparity. <em>AAAI</em>, 3091–3099. (<a
href="https://doi.org/10.1609/aaai.v37i3.25413">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Existing learning-based multi-view stereo (MVS) methods rely on the depth range to build the 3D cost volume and may fail when the range is too large or unreliable. To address this problem, we propose a disparity-based MVS method based on the epipolar disparity flow (E-flow), called DispMVS, which infers the depth information from the pixel movement between two views. The core of DispMVS is to construct a 2D cost volume on the image plane along the epipolar line between each pair (between the reference image and several source images) for pixel matching and fuse uncountable depths triangulated from each pair by multi-view geometry to ensure multi-view consistency. To be robust, DispMVS starts from a randomly initialized depth map and iteratively refines the depth map with the help of the coarse-to-fine strategy. Experiments on DTUMVS and Tanks\&amp;Temple datasets show that DispMVS is not sensitive to the depth range and achieves state-of-the-art results with lower GPU memory.},
  archive   = {C_AAAI},
  author    = {Qingsong Yan and Qiang Wang and Kaiyong Zhao and Bo Li and Xiaowen Chu and Fei Deng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25413},
  pages     = {3091-3099},
  title     = {Rethinking disparity: A depth range free multi-view stereo based on disparity},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). VLTinT: Visual-linguistic transformer-in-transformer for
coherent video paragraph captioning. <em>AAAI</em>, 3081–3090. (<a
href="https://doi.org/10.1609/aaai.v37i3.25412">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Video Paragraph Captioning aims to generate a multi-sentence description of an untrimmed video with multiple temporal event locations in a coherent storytelling. Following the human perception process, where the scene is effectively understood by decomposing it into visual (e.g. human, animal) and non-visual components (e.g. action, relations) under the mutual influence of vision and language, we first propose a visual-linguistic (VL) feature. In the proposed VL feature, the scene is modeled by three modalities including (i) a global visual environment; (ii) local visual main agents; (iii) linguistic scene elements. We then introduce an autoregressive Transformer-in-Transformer (TinT) to simultaneously capture the semantic coherence of intra- and inter-event contents within a video. Finally, we present a new VL contrastive loss function to guarantee the learnt embedding features are consistent with the captions semantics. Comprehensive experiments and extensive ablation studies on the ActivityNet Captions and YouCookII datasets show that the proposed Visual-Linguistic Transformer-in-Transform (VLTinT) outperforms previous state-of-the-art methods in terms of accuracy and diversity. The source code is made publicly available at: https://github.com/UARK-AICV/VLTinT.},
  archive   = {C_AAAI},
  author    = {Kashu Yamazaki and Khoa Vo and Quang Sang Truong and Bhiksha Raj and Ngan Le},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25412},
  pages     = {3081-3090},
  title     = {VLTinT: Visual-linguistic transformer-in-transformer for coherent video paragraph captioning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DeMT: Deformable mixer transformer for multi-task learning
of dense prediction. <em>AAAI</em>, 3072–3080. (<a
href="https://doi.org/10.1609/aaai.v37i3.25411">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Convolution neural networks (CNNs) and Transformers have their own advantages and both have been widely used for dense prediction in multi-task learning (MTL). Most of the current studies on MTL solely rely on CNN or Transformer. In this work, we present a novel MTL model by combining both merits of deformable CNN and query-based Transformer for multi-task learning of dense prediction. Our method, named DeMT, is based on a simple and effective encoder-decoder architecture (i.e., deformable mixer encoder and task-aware transformer decoder). First, the deformable mixer encoder contains two types of operators: the channel-aware mixing operator leveraged to allow communication among different channels (i.e., efficient channel location mixing), and the spatial-aware deformable operator with deformable convolution applied to efficiently sample more informative spatial locations (i.e., deformed features). Second, the task-aware transformer decoder consists of the task interaction block and task query block. The former is applied to capture task interaction features via self-attention. The latter leverages the deformed features and task-interacted features to generate the corresponding task-specific feature through a query-based Transformer for corresponding task predictions. Extensive experiments on two dense image prediction datasets, NYUD-v2 and PASCAL-Context, demonstrate that our model uses fewer GFLOPs and significantly outperforms current Transformer- and CNN-based competitive models on a variety of metrics. The code is available at https://github.com/yangyangxu0/DeMT.},
  archive   = {C_AAAI},
  author    = {Yangyang Xu and Yibo Yang and Lefei Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25411},
  pages     = {3072-3080},
  title     = {DeMT: Deformable mixer transformer for multi-task learning of dense prediction},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Inter-image contrastive consistency for multi-person pose
estimation. <em>AAAI</em>, 3063–3071. (<a
href="https://doi.org/10.1609/aaai.v37i3.25410">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-person pose estimation (MPPE) has achieved impressive progress in recent years. However, due to the large variance of appearances among images or occlusions, the model can hardly learn consistent patterns enough, which leads to severe location jitter and missing issues. In this study, we propose a novel framework, termed Inter-image Contrastive consistency (ICON), to strengthen the keypoint consistency among images for MPPE. Concretely, we consider two-fold consistency constraints, which include single keypoint contrastive consistency (SKCC) and pair relation contrastive consistency (PRCC). The SKCC learns to strengthen the consistency of individual keypoints across images in the same category to improve the category-specific robustness. Only with SKCC, the model can effectively reduce location errors caused by large appearance variations, but remains challenging with extreme postures (e.g., occlusions) due to lack of relational guidance. Therefore, PRCC is proposed to strengthen the consistency of pair-wise joint relation between images to preserve the instructive relation. Cooperating with SKCC, PRCC further improves structure aware robustness in handling extreme postures. Extensive experiments on kinds of architectures across three datasets (i.e., MS-COCO, MPII, CrowdPose) show the proposed ICON achieves substantial improvements over baselines. Furthermore, ICON under the semi-supervised setup can obtain comparable results with the fully-supervised methods using only 30\% labeled data.},
  archive   = {C_AAAI},
  author    = {Xixia Xu and Yingguo Gao and Xingjia Pan and Ke Yan and Xiaoyu Chen and Qi Zou},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25410},
  pages     = {3063-3071},
  title     = {Inter-image contrastive consistency for multi-person pose estimation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). Deep parametric 3D filters for joint video denoising and
illumination enhancement in video super resolution. <em>AAAI</em>,
3054–3062. (<a href="https://doi.org/10.1609/aaai.v37i3.25409">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Despite the quality improvement brought by the recent methods, video super-resolution (SR) is still very challenging, especially for videos that are low-light and noisy. The current best solution is to subsequently employ best models of video SR, denoising, and illumination enhancement, but doing so often lowers the image quality, due to the inconsistency between the models. This paper presents a new parametric representation called the Deep Parametric 3D Filters (DP3DF), which incorporates local spatiotemporal information to enable simultaneous denoising, illumination enhancement, and SR efficiently in a single encoder-and-decoder network. Also, a dynamic residual frame is jointly learned with the DP3DF via a shared backbone to further boost the SR quality. We performed extensive experiments, including a large-scale user study, to show our method&#39;s effectiveness. Our method consistently surpasses the best state-of-the-art methods on all the challenging real datasets with top PSNR and user ratings, yet having a very fast run time. The code is available at https://github.com/xiaogang00/DP3DF.},
  archive   = {C_AAAI},
  author    = {Xiaogang Xu and Ruixing Wang and Chi-Wing Fu and Jiaya Jia},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25409},
  pages     = {3054-3062},
  title     = {Deep parametric 3D filters for joint video denoising and illumination enhancement in video super resolution},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Self correspondence distillation for end-to-end
weakly-supervised semantic segmentation. <em>AAAI</em>, 3045–3053. (<a
href="https://doi.org/10.1609/aaai.v37i3.25408">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Efficiently training accurate deep models for weakly supervised semantic segmentation (WSSS) with image-level labels is challenging and important. Recently, end-to-end WSSS methods have become the focus of research due to their high training efficiency. However, current methods suffer from insufficient extraction of comprehensive semantic information, resulting in low-quality pseudo-labels and sub-optimal solutions for end-to-end WSSS. To this end, we propose a simple and novel Self Correspondence Distillation (SCD) method to refine pseudo-labels without introducing external supervision. Our SCD enables the network to utilize feature correspondence derived from itself as a distillation target, which can enhance the network&#39;s feature learning process by complementing semantic information. In addition, to further improve the segmentation accuracy, we design a Variation-aware Refine Module to enhance the local consistency of pseudo-labels by computing pixel-level variation. Finally, we present an efficient end-to-end Transformer-based framework (TSCD) via SCD and Variation-aware Refine Module for the accurate WSSS task. Extensive experiments on the PASCAL VOC 2012 and MS COCO 2014 datasets demonstrate that our method significantly outperforms other state-of-the-art methods. Our code is available at https://github.com/Rongtao-Xu/RepresentationLearning/tree/main/SCD-AAAI2023.},
  archive   = {C_AAAI},
  author    = {Rongtao Xu and Changwei Wang and Jiaxi Sun and Shibiao Xu and Weiliang Meng and Xiaopeng Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25408},
  pages     = {3045-3053},
  title     = {Self correspondence distillation for end-to-end weakly-supervised semantic segmentation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Class overwhelms: Mutual conditional blended-target domain
adaptation. <em>AAAI</em>, 3036–3044. (<a
href="https://doi.org/10.1609/aaai.v37i3.25407">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Current methods of blended targets domain adaptation (BTDA) usually infer or consider domain label information but underemphasize hybrid categorical feature structures of targets, which yields limited performance, especially under the label distribution shift. We demonstrate that domain labels are not directly necessary for BTDA if categorical distributions of various domains are sufficiently aligned even facing the imbalance of domains and the label distribution shift of classes. However, we observe that the cluster assumption in BTDA does not comprehensively hold. The hybrid categorical feature space hinders the modeling of categorical distributions and the generation of reliable pseudo labels for categorical alignment. To address these, we propose a categorical domain discriminator guided by uncertainty to explicitly model and directly align categorical distributions P(Z|Y). Simultaneously, we utilize the low-level features to augment the single source features with diverse target styles to rectify the biased classifier P(Y|Z) among diverse targets. Such a mutual conditional alignment of P(Z|Y) and P(Y|Z) forms a mutual reinforced mechanism. Our approach outperforms the state-of-the-art in BTDA even compared with methods utilizing domain labels, especially under the label distribution shift, and in single target DA on DomainNet.},
  archive   = {C_AAAI},
  author    = {Pengcheng Xu and Boyu Wang and Charles Ling},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25407},
  pages     = {3036-3044},
  title     = {Class overwhelms: Mutual conditional blended-target domain adaptation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning a generalized gaze estimator from gaze-consistent
feature. <em>AAAI</em>, 3027–3035. (<a
href="https://doi.org/10.1609/aaai.v37i3.25406">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Gaze estimator computes the gaze direction based on face images. Most existing gaze estimation methods perform well under within-dataset settings, but can not generalize to unseen domains. In particular, the ground-truth labels in unseen domain are often unavailable. In this paper, we propose a new domain generalization method based on gaze-consistent features. Our idea is to consider the gaze-irrelevant factors as unfavorable interference and disturb the training data against them, so that the model cannot fit to these gaze-irrelevant factors, instead, only fits to the gaze-consistent features. To this end, we first disturb the training data via adversarial attack or data augmentation based on the gaze-irrelevant factors, i.e., identity, expression, illumination and tone. Then we extract the gaze-consistent features by aligning the gaze features from disturbed data with non-disturbed gaze features. Experimental results show that our proposed method achieves state-of-the-art performance on gaze domain generalization task. Furthermore, our proposed method also improves domain adaption performance on gaze estimation. Our work provides new insight on gaze domain generalization task.},
  archive   = {C_AAAI},
  author    = {Mingjie Xu and Haofei Wang and Feng Lu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25406},
  pages     = {3027-3035},
  title     = {Learning a generalized gaze estimator from gaze-consistent feature},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). CasFusionNet: A cascaded network for point cloud semantic
scene completion by dense feature fusion. <em>AAAI</em>, 3018–3026. (<a
href="https://doi.org/10.1609/aaai.v37i3.25405">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Semantic scene completion (SSC) aims to complete a partial 3D scene and predict its semantics simultaneously. Most existing works adopt the voxel representations, thus suffering from the growth of memory and computation cost as the voxel resolution increases. Though a few works attempt to solve SSC from the perspective of 3D point clouds, they have not fully exploited the correlation and complementarity between the two tasks of scene completion and semantic segmentation. In our work, we present CasFusionNet, a novel cascaded network for point cloud semantic scene completion by dense feature fusion. Specifically, we design (i) a global completion module (GCM) to produce an upsampled and completed but coarse point set, (ii) a semantic segmentation module (SSM) to predict the per-point semantic labels of the completed points generated by GCM, and (iii) a local refinement module (LRM) to further refine the coarse completed points and the associated labels from a local perspective. We organize the above three modules via dense feature fusion in each level, and cascade a total of four levels, where we also employ feature fusion between each level for sufficient information usage. Both quantitative and qualitative results on our compiled two point-based datasets validate the effectiveness and superiority of our CasFusionNet compared to state-of-the-art methods in terms of both scene completion and semantic segmentation. The codes and datasets are available at: https://github.com/JinfengX/CasFusionNet.},
  archive   = {C_AAAI},
  author    = {Jinfeng Xu and Xianzhi Li and Yuan Tang and Qiao Yu and Yixue Hao and Long Hu and Min Chen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25405},
  pages     = {3018-3026},
  title     = {CasFusionNet: A cascaded network for point cloud semantic scene completion by dense feature fusion},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unsupervised multi-exposure image fusion breaking exposure
limits via contrastive learning. <em>AAAI</em>, 3010–3017. (<a
href="https://doi.org/10.1609/aaai.v37i3.25404">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper proposes an unsupervised multi-exposure image fusion (MEF) method via contrastive learning, termed as MEF-CL. It breaks exposure limits and performance bottleneck faced by existing methods. MEF-CL firstly designs similarity constraints to preserve contents in source images. It eliminates the need for ground truth (actually not exist and created artificially) and thus avoids negative impacts of inappropriate ground truth on performance and generalization. Moreover, we explore a latent feature space and apply contrastive learning in this space to guide fused image to approximate normal-light samples and stay away from inappropriately exposed ones. In this way, characteristics of fused images (e.g., illumination, colors) can be further improved without being subject to source images. Therefore, MEF-CL is applicable to image pairs of any multiple exposures rather than a pair of under-exposed and over-exposed images mandated by existing methods. By alleviating dependence on source images, MEF-CL shows better generalization for various scenes. Consequently, our results exhibit appropriate illumination, detailed textures, and saturated colors. Qualitative, quantitative, and ablation experiments validate the superiority and generalization of MEF-CL. Our code is publicly available at https://github.com/hanna-xu/MEF-CL.},
  archive   = {C_AAAI},
  author    = {Han Xu and Liang Haochen and Jiayi Ma},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25404},
  pages     = {3010-3017},
  title     = {Unsupervised multi-exposure image fusion breaking exposure limits via contrastive learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Revisiting the spatial and temporal modeling for few-shot
action recognition. <em>AAAI</em>, 3001–3009. (<a
href="https://doi.org/10.1609/aaai.v37i3.25403">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Spatial and temporal modeling is one of the most core aspects of few-shot action recognition. Most previous works mainly focus on long-term temporal relation modeling based on high-level spatial representations, without considering the crucial low-level spatial features and short-term temporal relations. Actually, the former feature could bring rich local semantic information, and the latter feature could represent motion characteristics of adjacent frames, respectively. In this paper, we propose SloshNet, a new framework that revisits the spatial and temporal modeling for few-shot action recognition in a finer manner. First, to exploit the low-level spatial features, we design a feature fusion architecture search module to automatically search for the best combination of the low-level and high-level spatial features. Next, inspired by the recent transformer, we introduce a long-term temporal modeling module to model the global temporal relations based on the extracted spatial appearance features. Meanwhile, we design another short-term temporal modeling module to encode the motion characteristics between adjacent frame representations. After that, the final predictions can be obtained by feeding the embedded rich spatial-temporal features to a common frame-level class prototype matcher. We extensively validate the proposed SloshNet on four few-shot action recognition datasets, including Something-Something V2, Kinetics, UCF101, and HMDB51. It achieves favorable results against state-of-the-art methods in all datasets.},
  archive   = {C_AAAI},
  author    = {Jiazheng Xing and Mengmeng Wang and Yong Liu and Boyu Mu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25403},
  pages     = {3001-3009},
  title     = {Revisiting the spatial and temporal modeling for few-shot action recognition},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). LORE: Logical location regression network for table
structure recognition. <em>AAAI</em>, 2992–3000. (<a
href="https://doi.org/10.1609/aaai.v37i3.25402">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Table structure recognition (TSR) aims at extracting tables in images into machine-understandable formats. Recent methods solve this problem by predicting the adjacency relations of detected cell boxes, or learning to generate the corresponding markup sequences from the table images. However, they either count on additional heuristic rules to recover the table structures, or require a huge amount of training data and time-consuming sequential decoders. In this paper, we propose an alternative paradigm. We model TSR as a logical location regression problem and propose a new TSR framework called LORE, standing for LOgical location REgression network, which for the first time combines logical location regression together with spatial location regression of table cells. Our proposed LORE is conceptually simpler, easier to train and more accurate than previous TSR models of other paradigms. Experiments on standard benchmarks demonstrate that LORE consistently outperforms prior arts. Code is available at https:// github.com/AlibabaResearch/AdvancedLiterateMachinery/tree/main/DocumentUnderstanding/LORE-TSR.},
  archive   = {C_AAAI},
  author    = {Hangdi Xing and Feiyu Gao and Rujiao Long and Jiajun Bu and Qi Zheng and Liangcheng Li and Cong Yao and Zhi Yu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25402},
  pages     = {2992-3000},
  title     = {LORE: Logical location regression network for table structure recognition},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ROIFormer: Semantic-aware region of interest transformer for
efficient self-supervised monocular depth estimation. <em>AAAI</em>,
2983–2991. (<a href="https://doi.org/10.1609/aaai.v37i3.25401">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The exploration of mutual-benefit cross-domains has shown great potential toward accurate self-supervised depth estimation. In this work, we revisit feature fusion between depth and semantic information and propose an efficient local adaptive attention method for geometric aware representation enhancement. Instead of building global connections or deforming attention across the feature space without restraint, we bound the spatial interaction within a learnable region of interest. In particular, we leverage geometric cues from semantic information to learn local adaptive bounding boxes to guide unsupervised feature aggregation. The local areas preclude most irrelevant reference points from attention space, yielding more selective feature learning and faster convergence. We naturally extend the paradigm into a multi-head and hierarchic way to enable the information distillation in different semantic levels and improve the feature discriminative ability for fine-grained depth estimation. Extensive experiments on the KITTI dataset show that our proposed method establishes a new state-of-the-art in self-supervised monocular depth estimation task, demonstrating the effectiveness of our approach over former Transformer variants.},
  archive   = {C_AAAI},
  author    = {Daitao Xing and Jinglin Shen and Chiuman Ho and Anthony Tzes},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25401},
  pages     = {2983-2991},
  title     = {ROIFormer: Semantic-aware region of interest transformer for efficient self-supervised monocular depth estimation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cross-modal contrastive learning for domain adaptation in 3D
semantic segmentation. <em>AAAI</em>, 2974–2982. (<a
href="https://doi.org/10.1609/aaai.v37i3.25400">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Domain adaptation for 3D point cloud has attracted a lot of interest since it can avoid the time-consuming labeling process of 3D data to some extent. A recent work named xMUDA leveraged multi-modal data to domain adaptation task of 3D semantic segmentation by mimicking the predictions between 2D and 3D modalities, and outperformed the previous single modality methods only using point clouds. Based on it, in this paper, we propose a novel cross-modal contrastive learning scheme to further improve the adaptation effects. By employing constraints from the correspondences between 2D pixel features and 3D point features, our method not only facilitates interaction between the two different modalities, but also boosts feature representations in both labeled source domain and unlabeled target domain. Meanwhile, to sufficiently utilize 2D context information for domain adaptation through cross-modal learning, we introduce a neighborhood feature aggregation module to enhance pixel features. The module employs neighborhood attention to aggregate nearby pixels in the 2D image, which relieves the mismatching between the two different modalities, arising from projecting relative sparse point cloud to dense image pixels. We evaluate our method on three unsupervised domain adaptation scenarios, including country-to-country, day-to-night, and dataset-to-dataset. Experimental results show that our approach outperforms existing methods, which demonstrates the effectiveness of the proposed method.},
  archive   = {C_AAAI},
  author    = {Bowei Xing and Xianghua Ying and Ruibin Wang and Jinfa Yang and Taiyan Chen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25400},
  pages     = {2974-2982},
  title     = {Cross-modal contrastive learning for domain adaptation in 3D semantic segmentation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Just noticeable visual redundancy forecasting: A deep
multimodal-driven approach. <em>AAAI</em>, 2965–2973. (<a
href="https://doi.org/10.1609/aaai.v37i3.25399">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Just noticeable difference (JND) refers to the maximum visual change that human eyes cannot perceive, and it has a wide range of applications in multimedia systems. However, most existing JND approaches only focus on a single modality, and rarely consider the complementary effects of multimodal information. In this article, we investigate the JND modeling from an end-to-end homologous multimodal perspective, namely hmJND-Net. Specifically, we explore three important visually sensitive modalities, including saliency, depth, and segmentation. To better utilize homologous multimodal information, we establish an effective fusion method via summation enhancement and subtractive offset, and align homologous multimodal features based on a self-attention driven encoder-decoder paradigm. Extensive experimental results on eight different benchmark datasets validate the superiority of our hmJND-Net over eight representative methods.},
  archive   = {C_AAAI},
  author    = {Wuyuan Xie and Shukang Wang and Sukun Tian and Lirong Huang and Ye Liu and Miaohui Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25399},
  pages     = {2965-2973},
  title     = {Just noticeable visual redundancy forecasting: A deep multimodal-driven approach},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mitigating artifacts in real-world video super-resolution
models. <em>AAAI</em>, 2956–2964. (<a
href="https://doi.org/10.1609/aaai.v37i3.25398">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The recurrent structure is a prevalent framework for the task of video super-resolution, which models the temporal dependency between frames via hidden states. When applied to real-world scenarios with unknown and complex degradations, hidden states tend to contain unpleasant artifacts and propagate them to restored frames. In this circumstance, our analyses show that such artifacts can be largely alleviated when the hidden state is replaced with a cleaner counterpart. Based on the observations, we propose a Hidden State Attention (HSA) module to mitigate artifacts in real-world video super-resolution. Specifically, we first adopt various cheap filters to produce a hidden state pool. For example, Gaussian blur filters are for smoothing artifacts while sharpening filters are for enhancing details. To aggregate a new hidden state that contains fewer artifacts from the hidden state pool, we devise a Selective Cross Attention (SCA) module, in which the attention between input features and each hidden state is calculated. Equipped with HSA, our proposed method, namely FastRealVSR, is able to achieve 2x speedup while obtaining better performance than Real-BasicVSR. Codes will be available at https://github.com/TencentARC/FastRealVSR.},
  archive   = {C_AAAI},
  author    = {Liangbin Xie and Xintao Wang and Shuwei Shi and Jinjin Gu and Chao Dong and Ying Shan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25398},
  pages     = {2956-2964},
  title     = {Mitigating artifacts in real-world video super-resolution models},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Less is more important: An attention module guided by
probability density function for convolutional neural networks.
<em>AAAI</em>, 2947–2955. (<a
href="https://doi.org/10.1609/aaai.v37i3.25397">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Attention modules, which adaptively weight and refine features according to the importance of the input, have become a critical technique to boost the capability of convolutional neural networks. However, most existing attention modules are heuristic without a sound interpretation, and thus, require empirical engineering to design structure and operators within the modules. To handle the above issue, based on our &#39;less is more important&#39; observation, we propose an Attention Module guided by Probability Density Function (PDF), dubbed PdfAM, which enjoys a rational motivation and requires few empirical structure designs. Concretely, we observe that pixels with less occurrence are prone to be textural details or foreground objects with much importance to aid vision tasks. Thus, with PDF values adopted as a smooth and anti-noise alternative to the pixel occurrence frequency, we design our PdfAM by first estimating the PDF based on some distribution assumption, and then predicting a 3D attention map via applying a negative correlation between the attention weights and the estimated PDF values. Furthermore, we develop learnable PDF-rescale parameters so as to adaptively transform the estimated PDF and predict a customized negative correlation. Experiments show that our PdfAM consistently boosts various networks under both high- and low-level vision tasks, and also performs favorably against other attention modules in terms of accuracy and convergence.},
  archive   = {C_AAAI},
  author    = {Jingfen Xie and Jian Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25397},
  pages     = {2947-2955},
  title     = {Less is more important: An attention module guided by probability density function for convolutional neural networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Boosting semi-supervised semantic segmentation with
probabilistic representations. <em>AAAI</em>, 2938–2946. (<a
href="https://doi.org/10.1609/aaai.v37i3.25396">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent breakthroughs in semi-supervised semantic segmentation have been developed through contrastive learning. In prevalent pixel-wise contrastive learning solutions, the model maps pixels to deterministic representations and regularizes them in the latent space. However, there exist inaccurate pseudo-labels which map the ambiguous representations of pixels to the wrong classes due to the limited cognitive ability of the model. In this paper, we define pixel-wise representations from a new perspective of probability theory and propose a Probabilistic Representation Contrastive Learning (PRCL) framework that improves representation quality by taking its probability into consideration. Through modelling the mapping from pixels to representations as the probability via multivariate Gaussian distributions, we can tune the contribution of the ambiguous representations to tolerate the risk of inaccurate pseudo-labels. Furthermore, we define prototypes in the form of distributions, which indicates the confidence of a class, while the point prototype cannot. More- over, we propose to regularize the distribution variance to enhance the reliability of representations. Taking advantage of these benefits, high-quality feature representations can be derived in the latent space, thereby the performance of se- mantic segmentation can be further improved. We conduct sufficient experiment to evaluate PRCL on Pascal VOC and CityScapes to demonstrate its superiority. The code is available at https://github.com/Haoyu-Xie/PRCL.},
  archive   = {C_AAAI},
  author    = {Haoyu Xie and Changqi Wang and Mingkai Zheng and Minjing Dong and Shan You and Chong Fu and Chang Xu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25396},
  pages     = {2938-2946},
  title     = {Boosting semi-supervised semantic segmentation with probabilistic representations},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Toward robust diagnosis: A contour attention preserving
adversarial defense for COVID-19 detection. <em>AAAI</em>, 2928–2937.
(<a href="https://doi.org/10.1609/aaai.v37i3.25395">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As the COVID-19 pandemic puts pressure on healthcare systems worldwide, the computed tomography image based AI diagnostic system has become a sustainable solution for early diagnosis. However, the model-wise vulnerability under adversarial perturbation hinders its deployment in practical situation. The existing adversarial training strategies are difficult to generalized into medical imaging field challenged by complex medical texture features. To overcome this challenge, we propose a Contour Attention Preserving (CAP) method based on lung cavity edge extraction. The contour prior features are injected to attention layer via a parameter regularization and we optimize the robust empirical risk with hybrid distance metric. We then introduce a new cross-nation CT scan dataset to evaluate the generalization capability of the adversarial robustness under distribution shift. Experimental results indicate that the proposed method achieves state-of-the-art performance in multiple adversarial defense and generalization tasks. The code and dataset are available at https://github.com/Quinn777/CAP.},
  archive   = {C_AAAI},
  author    = {Kun Xiang and Xing Zhang and Jinwen She and Jinpeng Liu and Haohan Wang and Shiqi Deng and Shancheng Jiang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25395},
  pages     = {2928-2937},
  title     = {Toward robust diagnosis: A contour attention preserving adversarial defense for COVID-19 detection},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FEditNet: Few-shot editing of latent semantics in GAN
spaces. <em>AAAI</em>, 2919–2927. (<a
href="https://doi.org/10.1609/aaai.v37i3.25394">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Generative Adversarial networks (GANs) have demonstrated their powerful capability of synthesizing high-resolution images, and great efforts have been made to interpret the semantics in the latent spaces of GANs. However, existing works still have the following limitations: (1) the majority of works rely on either pretrained attribute predictors or large-scale labeled datasets, which are difficult to collect in most cases, and (2) some other methods are only suitable for restricted cases, such as focusing on interpretation of human facial images using prior facial semantics. In this paper, we propose a GAN-based method called FEditNet, aiming to discover latent semantics using very few labeled data without any pretrained predictors or prior knowledge. Specifically, we reuse the knowledge from the pretrained GANs, and by doing so, avoid overfitting during the few-shot training of FEditNet. Moreover, our layer-wise objectives which take content consistency into account also ensure the disentanglement between attributes. Qualitative and quantitative results demonstrate that our method outperforms the state-of-the-art methods on various datasets. The code is available at https://github.com/THU-LYJ-Lab/FEditNet.},
  archive   = {C_AAAI},
  author    = {Mengfei Xia and Yezhi Shu and Yuji Wang and Yu-Kun Lai and Qiang Li and Pengfei Wan and Zhongyuan Wang and Yong-Jin Liu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25394},
  pages     = {2919-2927},
  title     = {FEditNet: Few-shot editing of latent semantics in GAN spaces},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SVFI: Spiking-based video frame interpolation for high-speed
motion. <em>AAAI</em>, 2910–2918. (<a
href="https://doi.org/10.1609/aaai.v37i3.25393">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Occlusion and motion blur make it challenging to interpolate video frame, since estimating complex motions between two frames is hard and unreliable, especially in highly dynamic scenes. This paper aims to address these issues by exploiting spike stream as auxiliary visual information between frames to synthesize target frames. Instead of estimating motions by optical flow from RGB frames, we present a new dual-modal pipeline adopting both RGB frames and the corresponding spike stream as inputs (SVFI). It extracts the scene structure and objects&#39; outline feature maps of the target frames from spike stream. Those feature maps are fused with the color and texture feature maps extracted from RGB frames to synthesize target frames. Benefited by the spike stream that contains consecutive information between two frames, SVFI can directly extract the information in occlusion and motion blur areas of target frames from spike stream, thus it is more robust than previous optical flow-based methods. Experiments show SVFI outperforms the SOTA methods on wide variety of datasets. For instance, in 7 and 15 frame skip evaluations, it shows up to 5.58 dB and 6.56 dB improvements in terms of PSNR over the corresponding second best methods BMBC and DAIN. SVFI also shows visually impressive performance in real-world scenes.},
  archive   = {C_AAAI},
  author    = {Lujie Xia and Jing Zhao and Ruiqin Xiong and Tiejun Huang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25393},
  pages     = {2910-2918},
  title     = {SVFI: Spiking-based video frame interpolation for high-speed motion},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Skating-mixer: Long-term sport audio-visual modeling with
MLPs. <em>AAAI</em>, 2901–2909. (<a
href="https://doi.org/10.1609/aaai.v37i3.25392">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Figure skating scoring is challenging because it requires judging players’ technical moves as well as coordination with the background music. Most learning-based methods struggle for two reasons: 1) each move in figure skating changes quickly, hence simply applying traditional frame sampling will lose a lot of valuable information, especially in 3 to 5 minutes lasting videos; 2) prior methods rarely considered the critical audio-visual relationship in their models. Due to these reasons, we introduce a novel architecture, named Skating-Mixer. It extends the MLP framework into a multimodal fashion and effectively learns long-term representations through our designed memory recurrent unit (MRU). Aside from the model, we collected a high-quality audio-visual FS1000 dataset, which contains over 1000 videos on 8 types of programs with 7 different rating metrics, overtaking other datasets in both quantity and diversity. Experiments show the proposed method achieves SOTAs over all major metrics on the public Fis-V and our FS1000 dataset. In addition, we include an analysis applying our method to the recent competitions in Beijing 2022 Winter Olympic Games, proving our method has strong applicability.},
  archive   = {C_AAAI},
  author    = {Jingfei Xia and Mingchen Zhuge and Tiantian Geng and Shun Fan and Yuantai Wei and Zhenyu He and Feng Zheng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25392},
  pages     = {2901-2909},
  title     = {Skating-mixer: Long-term sport audio-visual modeling with MLPs},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Attention-based depth distillation with 3D-aware positional
encoding for monocular 3D object detection. <em>AAAI</em>, 2892–2900.
(<a href="https://doi.org/10.1609/aaai.v37i3.25391">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Monocular 3D object detection is a low-cost but challenging task, as it requires generating accurate 3D localization solely from a single image input. Recent developed depth-assisted methods show promising results by using explicit depth maps as intermediate features, which are either precomputed by monocular depth estimation networks or jointly evaluated with 3D object detection. However, inevitable errors from estimated depth priors may lead to misaligned semantic information and 3D localization, hence resulting in feature smearing and suboptimal predictions. To mitigate this issue, we propose ADD, an Attention-based Depth knowledge Distillation framework with 3D-aware positional encoding. Unlike previous knowledge distillation frameworks that adopt stereo- or LiDAR-based teachers, we build up our teacher with identical architecture as the student but with extra ground-truth depth as input. Credit to our teacher design, our framework is seamless, domain-gap free, easily implementable, and is compatible with object-wise ground-truth depth. Specifically, we leverage intermediate features and responses for knowledge distillation. Considering long-range 3D dependencies, we propose 3D-aware self-attention and target-aware cross-attention modules for student adaptation. Extensive experiments are performed to verify the effectiveness of our framework on the challenging KITTI 3D object detection benchmark. We implement our framework on three representative monocular detectors, and we achieve state-of-the-art performance with no additional inference computational cost relative to baseline models. Our code is available at https://github.com/rockywind/ADD.},
  archive   = {C_AAAI},
  author    = {Zizhang Wu and Yunzhe Wu and Jian Pu and Xianzhi Li and Xiaoquan Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25391},
  pages     = {2892-2900},
  title     = {Attention-based depth distillation with 3D-aware positional encoding for monocular 3D object detection},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Pixel is all you need: Adversarial trajectory-ensemble
active learning for salient object detection. <em>AAAI</em>, 2883–2891.
(<a href="https://doi.org/10.1609/aaai.v37i3.25390">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Although weakly-supervised techniques can reduce the labeling effort, it is unclear whether a saliency model trained with weakly-supervised data (e.g., point annotation) can achieve the equivalent performance of its fully-supervised version. This paper attempts to answer this unexplored question by proving a hypothesis: there is a point-labeled dataset where saliency models trained on it can achieve equivalent performance when trained on the densely annotated dataset. To prove this conjecture, we proposed a novel yet effective adversarial trajectory-ensemble active learning (ATAL). Our contributions are three-fold: 1) Our proposed adversarial attack triggering uncertainty can conquer the overconfidence of existing active learning methods and accurately locate these uncertain pixels. 2) Our proposed trajectory-ensemble uncertainty estimation method maintains the advantages of the ensemble networks while significantly reducing the computational cost. 3) Our proposed relationship-aware diversity sampling algorithm can conquer oversampling while boosting performance. Experimental results show that our ATAL can find such a point-labeled dataset, where a saliency model trained on it obtained 97\%-99\% performance of its fully-supervised version with only 10 annotated points per image.},
  archive   = {C_AAAI},
  author    = {Zhenyu Wu and Lin Wang and Wei Wang and Qing Xia and Chenglizhao Chen and Aimin Hao and Shuo Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25390},
  pages     = {2883-2891},
  title     = {Pixel is all you need: Adversarial trajectory-ensemble active learning for salient object detection},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-stream representation learning for pedestrian
trajectory prediction. <em>AAAI</em>, 2875–2882. (<a
href="https://doi.org/10.1609/aaai.v37i3.25389">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Forecasting the future trajectory of pedestrians is an important task in computer vision with a range of applications, from security cameras to autonomous driving. It is very challenging because pedestrians not only move individually across time but also interact spatially, and the spatial and temporal information is deeply coupled with one another in a multi-agent scenario. Learning such complex spatio-temporal correlation is a fundamental issue in pedestrian trajectory prediction. Inspired by the procedure that the hippocampus processes and integrates spatio-temporal information to form memories, we propose a novel multi-stream representation learning module to learn complex spatio-temporal features of pedestrian trajectory. Specifically, we learn temporal, spatial and cross spatio-temporal correlation features in three respective pathways and then adaptively integrate these features with learnable weights by a gated network. Besides, we leverage the sparse attention gate to select informative interactions and correlations brought by complex spatio-temporal modeling and reduce complexity of our model. We evaluate our proposed method on two commonly used datasets, i.e. ETH-UCY and SDD, and the experimental results demonstrate our method achieves the state-of-the-art performance. Code: https://github.com/YuxuanIAIR/MSRL-master},
  archive   = {C_AAAI},
  author    = {Yuxuan Wu and Le Wang and Sanping Zhou and Jinghai Duan and Gang Hua and Wei Tang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25389},
  pages     = {2875-2882},
  title     = {Multi-stream representation learning for pedestrian trajectory prediction},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Synthetic data can also teach: Synthesizing effective data
for unsupervised visual representation learning. <em>AAAI</em>,
2866–2874. (<a href="https://doi.org/10.1609/aaai.v37i3.25388">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Contrastive learning (CL), a self-supervised learning approach, can effectively learn visual representations from unlabeled data. Given the CL training data, generative models can be trained to generate synthetic data to supplement the real data. Using both synthetic and real data for CL training has the potential to improve the quality of learned representations. However, synthetic data usually has lower quality than real data, and using synthetic data may not improve CL compared with using real data. To tackle this problem, we propose a data generation framework with two methods to improve CL training by joint sample generation and contrastive learning. The first approach generates hard samples for the main model. The generator is jointly learned with the main model to dynamically customize hard samples based on the training state of the main model. Besides, a pair of data generators are proposed to generate similar but distinct samples as positive pairs. In joint learning, the hardness of a positive pair is progressively increased by decreasing their similarity. Experimental results on multiple datasets show superior accuracy and data efficiency of the proposed data generation methods applied to CL. For example, about 4.0\%, 3.5\%, and 2.6\% accuracy improvements for linear classification are observed on ImageNet-100, CIFAR-100, and CIFAR-10, respectively. Besides, up to 2× data efficiency for linear classification and up to 5× data efficiency for transfer learning are achieved.},
  archive   = {C_AAAI},
  author    = {Yawen Wu and Zhepeng Wang and Dewen Zeng and Yiyu Shi and Jingtong Hu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25388},
  pages     = {2866-2874},
  title     = {Synthetic data can also teach: Synthesizing effective data for unsupervised visual representation learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Scene graph to image synthesis via knowledge consensus.
<em>AAAI</em>, 2856–2865. (<a
href="https://doi.org/10.1609/aaai.v37i3.25387">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we study graph-to-image generation conditioned exclusively on scene graphs, in which we seek to disentangle the veiled semantics between knowledge graphs and images. While most existing research resorts to laborious auxiliary information such as object layouts or segmentation masks, it is also of interest to unveil the generality of the model with limited supervision, moreover, avoiding extra cross-modal alignments. To tackle this challenge, we delve into the causality of the adversarial generation process, and reason out a new principle to realize a simultaneous semantic disentanglement with an alignment on target and model distributions. This principle is named knowledge consensus, which explicitly describes a triangle causal dependency among observed images, graph semantics and hidden visual representations. The consensus also determines a new graph-to-image generation framework, carried on several adversarial optimization objectives. Extensive experimental results demonstrate that, even conditioned only on scene graphs, our model surprisingly achieves superior performance on semantics-aware image generation, without losing the competence on manipulating the generation through knowledge graphs.},
  archive   = {C_AAAI},
  author    = {Yang Wu and Pengxu Wei and Liang Lin},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25387},
  pages     = {2856-2865},
  title     = {Scene graph to image synthesis via knowledge consensus},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Revisiting classifier: Transferring vision-language models
for video recognition. <em>AAAI</em>, 2847–2855. (<a
href="https://doi.org/10.1609/aaai.v37i3.25386">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Transferring knowledge from task-agnostic pre-trained deep models for downstream tasks is an important topic in computer vision research. Along with the growth of computational capacity, we now have open-source vision-language pre-trained models in large scales of the model architecture and amount of data. In this study, we focus on transferring knowledge for video classification tasks. Conventional methods randomly initialize the linear classifier head for vision classification, but they leave the usage of the text encoder for downstream visual recognition tasks undiscovered. In this paper, we revise the role of the linear classifier and replace the classifier with the different knowledge from pre-trained model. We utilize the well-pretrained language model to generate good semantic target for efficient transferring learning. The empirical study shows that our method improves both the performance and the training speed of video classification, with a negligible change in the model. Our simple yet effective tuning paradigm achieves state-of-the-art performance and efficient training on various video recognition scenarios, i.e., zero-shot, few-shot, general recognition. In particular, our paradigm achieves the state-of-the-art accuracy of 87.8\% on Kinetics-400, and also surpasses previous methods by 20~50\% absolute top-1 accuracy under zero-shot, few-shot settings on five video datasets. Code and models are available at https://github.com/whwu95/Text4Vis.},
  archive   = {C_AAAI},
  author    = {Wenhao Wu and Zhun Sun and Wanli Ouyang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25386},
  pages     = {2847-2855},
  title     = {Revisiting classifier: Transferring vision-language models for video recognition},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). End-to-end zero-shot HOI detection via vision and language
knowledge distillation. <em>AAAI</em>, 2839–2846. (<a
href="https://doi.org/10.1609/aaai.v37i3.25385">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Most existing Human-Object Interaction (HOI) Detection methods rely heavily on full annotations with predefined HOI categories, which is limited in diversity and costly to scale further. We aim at advancing zero-shot HOI detection to detect both seen and unseen HOIs simultaneously. The fundamental challenges are to discover potential human-object pairs and identify novel HOI categories. To overcome the above challenges, we propose a novel End-to-end zero-shot HOI Detection (EoID) framework via vision-language knowledge distillation. We first design an Interactive Score module combined with a Two-stage Bipartite Matching algorithm to achieve interaction distinguishment for human-object pairs in an action-agnostic manner. Then we transfer the distribution of action probability from the pretrained vision-language teacher as well as the seen ground truth to the HOI model to attain zero-shot HOI classification. Extensive experiments on HICO-Det dataset demonstrate that our model discovers potential interactive pairs and enables the recognition of unseen HOIs. Finally, our method outperforms the previous SOTA under various zero-shot settings. Moreover, our method is generalizable to large-scale object detection data to further scale up the action sets. The source code is available at: https://github.com/mrwu-mac/EoID.},
  archive   = {C_AAAI},
  author    = {Mingrui Wu and Jiaxin Gu and Yunhang Shen and Mingbao Lin and Chao Chen and Xiaoshuai Sun},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25385},
  pages     = {2839-2846},
  title     = {End-to-end zero-shot HOI detection via vision and language knowledge distillation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Preserving structural consistency in arbitrary artist and
artwork style transfer. <em>AAAI</em>, 2830–2838. (<a
href="https://doi.org/10.1609/aaai.v37i3.25384">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep generative models are effective in style transfer. Previous methods learn one or several specific artist-style from a collection of artworks. These methods not only homogenize the artist-style of different artworks of the same artist but also lack generalization for the unseen artists. To solve these challenges, we propose a double-style transferring module (DSTM). It extracts different artist-style and artwork-style from different artworks (even untrained) and preserves the intrinsic diversity between different artworks of the same artist. DSTM swaps the two styles in the adversarial training and encourages realistic image generation given arbitrary style combinations. However, learning style from single artwork can often cause over-adaption to it, resulting in the introduction of structural features of style image. We further propose an edge enhancing module (EEM) which derives edge information from multi-scale and multi-level features to enhance structural consistency. We broadly evaluate our method across six large-scale benchmark datasets. Empirical results show that our method achieves arbitrary artist-style and artwork-style extraction from a single artwork, and effectively avoids introducing the style image’s structural features. Our method improves the state-of-the-art deception rate from 58.9\% to 67.2\% and the average FID from 48.74 to 42.83.},
  archive   = {C_AAAI},
  author    = {Jingyu Wu and Lefan Hou and Zejian Li and Jun Liao and Li Liu and Lingyun Sun},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25384},
  pages     = {2830-2838},
  title     = {Preserving structural consistency in arbitrary artist and artwork style transfer},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bi-directional feature reconstruction network for
fine-grained few-shot image classification. <em>AAAI</em>, 2821–2829.
(<a href="https://doi.org/10.1609/aaai.v37i3.25383">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The main challenge for fine-grained few-shot image classification is to learn feature representations with higher inter-class and lower intra-class variations, with a mere few labelled samples. Conventional few-shot learning methods however cannot be naively adopted for this fine-grained setting -- a quick pilot study reveals that they in fact push for the opposite (i.e., lower inter-class variations and higher intra-class variations). To alleviate this problem, prior works predominately use a support set to reconstruct the query image and then utilize metric learning to determine its category. Upon careful inspection, we further reveal that such unidirectional reconstruction methods only help to increase inter-class variations and are not effective in tackling intra-class variations. In this paper, we for the first time introduce a bi-reconstruction mechanism that can simultaneously accommodate for inter-class and intra-class variations. In addition to using the support set to reconstruct the query set for increasing inter-class variations, we further use the query set to reconstruct the support set for reducing intra-class variations. This design effectively helps the model to explore more subtle and discriminative features which is key for the fine-grained problem in hand. Furthermore, we also construct a self-reconstruction module to work alongside the bi-directional module to make the features even more discriminative. Experimental results on three widely used fine-grained image classification datasets consistently show considerable improvements compared with other methods. Codes are available at: https://github.com/PRIS-CV/Bi-FRN.},
  archive   = {C_AAAI},
  author    = {Jijie Wu and Dongliang Chang and Aneeshan Sain and Xiaoxu Li and Zhanyu Ma and Jie Cao and Jun Guo and Yi-Zhe Song},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25383},
  pages     = {2821-2829},
  title     = {Bi-directional feature reconstruction network for fine-grained few-shot image classification},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ACL-net: Semi-supervised polyp segmentation via affinity
contrastive learning. <em>AAAI</em>, 2812–2820. (<a
href="https://doi.org/10.1609/aaai.v37i3.25382">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Automatic polyp segmentation from colonoscopy images is an essential prerequisite for the development of computer-assisted therapy. However, the complex semantic information and the blurred edges of polyps make segmentation extremely difficult. In this paper, we propose a novel semi-supervised polyp segmentation framework using affinity contrastive learning (ACL-Net), which is implemented between student and teacher networks to consistently refine the pseudo-labels for semi-supervised polyp segmentation. By aligning the affinity maps between the two branches, a better polyp region activation can be obtained to fully exploit the appearance-level context encoded in the feature maps, thereby improving the capability of capturing not only global localization and shape context, but also the local textural and boundary details. By utilizing the rich inter-image affinity context and establishing a global affinity context based on the memory bank, a cross-image affinity aggregation (CAA) module is also implemented to further refine the affinity aggregation between the two branches. By continuously and adaptively refining pseudo-labels with optimized affinity, we can improve the semi-supervised polyp segmentation based on the mutually reinforced knowledge interaction among contrastive learning and consistency learning iterations. Extensive experiments on five benchmark datasets, including Kvasir-SEG, CVC-ClinicDB, CVC-300, CVC-ColonDB and ETIS, demonstrate the effectiveness and superiority of our method. Codes are available at https://github.com/xiewende/ACL-Net.},
  archive   = {C_AAAI},
  author    = {Huisi Wu and Wende Xie and Jingyin Lin and Xinrong Guo},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25382},
  pages     = {2812-2820},
  title     = {ACL-net: Semi-supervised polyp segmentation via affinity contrastive learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Super-efficient echocardiography video segmentation via
proxy- and kernel-based semi-supervised learning. <em>AAAI</em>,
2803–2811. (<a href="https://doi.org/10.1609/aaai.v37i3.25381">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Automatic segmentation of left ventricular endocardium in echocardiography videos is critical for assessing various cardiac functions and improving the diagnosis of cardiac diseases. It is yet a challenging task due to heavy speckle noise, significant shape variability of cardiac structure, and limited labeled data. Particularly, the real-time demand in clinical practice makes this task even harder. In this paper, we propose a novel proxy- and kernel-based semi-supervised segmentation network (PKEcho-Net) to comprehensively address these challenges. We first propose a multi-scale region proxy (MRP) mechanism to model the region-wise contexts, in which a learnable region proxy with an arbitrary shape is developed in each layer of the encoder, allowing the network to identify homogeneous semantics and hence alleviate the influence of speckle noise on segmentation. To sufficiently and efficiently exploit temporal consistency, different from traditional methods which only utilize the temporal contexts of two neighboring frames via feature warping or self-attention mechanism, we formulate the semi-supervised segmentation with a group of learnable kernels, which can naturally and uniformly encode the appearances of left ventricular endocardium, as well as extracting the inter-frame contexts across the whole video to resist the fast shape variability of cardiac structures. Extensive experiments have been conducted on two famous public echocardiography video datasets, EchoNet-Dynamic and CAMUS. Our model achieves the best performance-efficiency trade-off when compared with other state-of-the-art approaches, attaining comparative accuracy with a much faster speed. The code is available at https://github.com/JingyinLin/PKEcho-Net.},
  archive   = {C_AAAI},
  author    = {Huisi Wu and Jingyin Lin and Wende Xie and Jing Qin},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25381},
  pages     = {2803-2811},
  title     = {Super-efficient echocardiography video segmentation via proxy- and kernel-based semi-supervised learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Transformation-equivariant 3D object detection for
autonomous driving. <em>AAAI</em>, 2795–2802. (<a
href="https://doi.org/10.1609/aaai.v37i3.25380">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {3D object detection received increasing attention in autonomous driving recently. Objects in 3D scenes are distributed with diverse orientations. Ordinary detectors do not explicitly model the variations of rotation and reflection transformations. Consequently, large networks and extensive data augmentation are required for robust detection. Recent equivariant networks explicitly model the transformation variations by applying shared networks on multiple transformed point clouds, showing great potential in object geometry modeling. However, it is difficult to apply such networks to 3D object detection in autonomous driving due to its large computation cost and slow reasoning speed. In this work, we present TED, an efficient Transformation-Equivariant 3D Detector to overcome the computation cost and speed issues. TED first applies a sparse convolution backbone to extract multi-channel transformation-equivariant voxel features; and then aligns and aggregates these equivariant features into lightweight and compact representations for high-performance 3D object detection. On the highly competitive KITTI 3D car detection leaderboard, TED ranked 1st among all submissions with competitive efficiency. Code is available at https://github.com/hailanyi/TED.},
  archive   = {C_AAAI},
  author    = {Hai Wu and Chenglu Wen and Wei Li and Xin Li and Ruigang Yang and Cheng Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25380},
  pages     = {2795-2802},
  title     = {Transformation-equivariant 3D object detection for autonomous driving},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Reject decoding via language-vision models for
text-to-image synthesis. <em>AAAI</em>, 2785–2794. (<a
href="https://doi.org/10.1609/aaai.v37i3.25379">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Transformer-based text-to-image synthesis generates images from abstractive textual conditions and achieves prompt results. Since transformer-based models predict visual tokens step by step in testing, where the early error is hard to be corrected and would be propagated. To alleviate this issue, the common practice is drawing multi-paths from the transformer-based models and re-ranking the multi-images decoded from multi-paths to find the best one and filter out others. Therefore, the computing procedure of excluding images may be inefficient. To improve the effectiveness and efficiency of decoding, we exploit a reject decoding algorithm with tiny multi-modal models to enlarge the searching space and exclude the useless paths as early as possible. Specifically, we build tiny multi-modal models to evaluate the similarities between the partial paths and the caption at multi scales. Then, we propose a reject decoding algorithm to exclude some lowest quality partial paths at the inner steps. Thus, under the same computing load as the original decoding, we could search across more multi-paths to improve the decoding efficiency and synthesizing quality. The experiments conducted on the MS-COCO dataset and large-scale datasets show that the proposed reject decoding algorithm can exclude the useless paths and enlarge the searching paths to improve the synthesizing quality by consuming less time.},
  archive   = {C_AAAI},
  author    = {Fuxiang Wu and Liu Liu and Fusheng Hao and Fengxiang He and Lei Wang and Jun Cheng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25379},
  pages     = {2785-2794},
  title     = {Reject decoding via language-vision models for text-to-image synthesis},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards good practices for missing modality robust action
recognition. <em>AAAI</em>, 2776–2784. (<a
href="https://doi.org/10.1609/aaai.v37i3.25378">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Standard multi-modal models assume the use of the same modalities in training and inference stages. However, in practice, the environment in which multi-modal models operate may not satisfy such assumption. As such, their performances degrade drastically if any modality is missing in the inference stage. We ask: how can we train a model that is robust to missing modalities? This paper seeks a set of good practices for multi-modal action recognition, with a particular interest in circumstances where some modalities are not available at an inference time. First, we show how to effectively regularize the model during training (e.g., data augmentation). Second, we investigate on fusion methods for robustness to missing modalities: we find that transformer-based fusion shows better robustness for missing modality than summation or concatenation. Third, we propose a simple modular network, ActionMAE, which learns missing modality predictive coding by randomly dropping modality features and tries to reconstruct them with the remaining modality features. Coupling these good practices, we build a model that is not only effective in multi-modal action recognition but also robust to modality missing. Our model achieves the state-of-the-arts on multiple benchmarks and maintains competitive performances even in missing modality scenarios.},
  archive   = {C_AAAI},
  author    = {Sangmin Woo and Sumin Lee and Yeonju Park and Muhammad Adi Nugroho and Changick Kim},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25378},
  pages     = {2776-2784},
  title     = {Towards good practices for missing modality robust action recognition},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploring non-target knowledge for improving ensemble
universal adversarial attacks. <em>AAAI</em>, 2768–2775. (<a
href="https://doi.org/10.1609/aaai.v37i3.25377">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The ensemble attack with average weights can be leveraged for increasing the transferability of universal adversarial perturbation (UAP) by training with multiple Convolutional Neural Networks (CNNs). However, after analyzing the Pearson Correlation Coefficients (PCCs) between the ensemble logits and individual logits of the crafted UAP trained by the ensemble attack, we find that one CNN plays a dominant role during the optimization. Consequently, this average weighted strategy will weaken the contributions of other CNNs and thus limit the transferability for other black-box CNNs. To deal with this bias issue, the primary attempt is to leverage the Kullback–Leibler (KL) divergence loss to encourage the joint contribution from different CNNs, which is still insufficient. After decoupling the KL loss into a target-class part and a non-target-class part, the main issue lies in that the non-target knowledge will be significantly suppressed due to the increasing logit of the target class. In this study, we simply adopt a KL loss that only considers the non-target classes for addressing the dominant bias issue. Besides, to further boost the transferability, we incorporate the min-max learning framework to self-adjust the ensemble weights for each CNN. Experiments results validate that considering the non-target KL loss can achieve superior transferability than the original KL loss by a large margin, and the min-max training can provide a mutual benefit in adversarial ensemble attacks. The source code is available at: https://github.com/WJJLL/ND-MM.},
  archive   = {C_AAAI},
  author    = {Juanjuan Weng and Zhiming Luo and Zhun Zhong and Dazhen Lin and Shaozi Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25377},
  pages     = {2768-2775},
  title     = {Exploring non-target knowledge for improving ensemble universal adversarial attacks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Active token mixer. <em>AAAI</em>, 2759–2767. (<a
href="https://doi.org/10.1609/aaai.v37i3.25376">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The three existing dominant network families, i.e., CNNs, Transformers and MLPs, differ from each other mainly in the ways of fusing spatial contextual information, leaving designing more effective token-mixing mechanisms at the core of backbone architecture development. In this work, we propose an innovative token-mixer, dubbed Active Token Mixer (ATM), to actively incorporate contextual information from other tokens in the global scope into the given query token. This fundamental operator actively predicts where to capture useful contexts and learns how to fuse the captured contexts with the query token at channel level. In this way, the spatial range of token-mixing can be expanded to a global scope with limited computational complexity, where the way of token-mixing is reformed. We take ATMs as the primary operators and assemble them into a cascade architecture, dubbed ATMNet. Extensive experiments demonstrate that ATMNet is generally applicable and comprehensively surpasses different families of SOTA vision backbones by a clear margin on a broad range of vision tasks, including visual recognition and dense prediction tasks. Code is available at https://github.com/microsoft/ActiveMLP.},
  archive   = {C_AAAI},
  author    = {Guoqiang Wei and Zhizheng Zhang and Cuiling Lan and Yan Lu and Zhibo Chen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25376},
  pages     = {2759-2767},
  title     = {Active token mixer},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Truncate-split-contrast: A framework for learning from
mislabeled videos. <em>AAAI</em>, 2751–2758. (<a
href="https://doi.org/10.1609/aaai.v37i3.25375">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Learning with noisy label is a classic problem that has been extensively studied for image tasks, but much less for video in the literature. A straightforward migration from images to videos without considering temporal semantics and computational cost is not a sound choice. In this paper, we propose two new strategies for video analysis with noisy labels: 1) a lightweight channel selection method dubbed as Channel Truncation for feature-based label noise detection. This method selects the most discriminative channels to split clean and noisy instances in each category. 2) A novel contrastive strategy dubbed as Noise Contrastive Learning, which constructs the relationship between clean and noisy instances to regularize model training. Experiments on three well-known benchmark datasets for video classification show that our proposed truNcatE-split-contrAsT (NEAT) significantly outperforms the existing baselines. By reducing the dimension to 10\% of it, our method achieves over 0.4 noise detection F1-score and 5\% classification accuracy improvement on Mini-Kinetics dataset under severe noise (symmetric-80\%). Thanks to Noise Contrastive Learning, the average classification accuracy improvement on Mini-Kinetics and Sth-Sth-V1 is over 1.6\%.},
  archive   = {C_AAAI},
  author    = {Zixiao Wang and Junwu Weng and Chun Yuan and Jue Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25375},
  pages     = {2751-2758},
  title     = {Truncate-split-contrast: A framework for learning from mislabeled videos},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). MicroAST: Towards super-fast ultra-resolution arbitrary
style transfer. <em>AAAI</em>, 2742–2750. (<a
href="https://doi.org/10.1609/aaai.v37i3.25374">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Arbitrary style transfer (AST) transfers arbitrary artistic styles onto content images. Despite the recent rapid progress, existing AST methods are either incapable or too slow to run at ultra-resolutions (e.g., 4K) with limited resources, which heavily hinders their further applications. In this paper, we tackle this dilemma by learning a straightforward and lightweight model, dubbed MicroAST. The key insight is to completely abandon the use of cumbersome pre-trained Deep Convolutional Neural Networks (e.g., VGG) at inference. Instead, we design two micro encoders (content and style encoders) and one micro decoder for style transfer. The content encoder aims at extracting the main structure of the content image. The style encoder, coupled with a modulator, encodes the style image into learnable dual-modulation signals that modulate both intermediate features and convolutional filters of the decoder, thus injecting more sophisticated and flexible style signals to guide the stylizations. In addition, to boost the ability of the style encoder to extract more distinct and representative style signals, we also introduce a new style signal contrastive loss in our model. Compared to the state of the art, our MicroAST not only produces visually superior results but also is 5-73 times smaller and 6-18 times faster, for the first time enabling super-fast (about 0.5 seconds) AST at 4K ultra-resolutions.},
  archive   = {C_AAAI},
  author    = {Zhizhong Wang and Lei Zhao and Zhiwen Zuo and Ailin Li and Haibo Chen and Wei Xing and Dongming Lu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25374},
  pages     = {2742-2750},
  title     = {MicroAST: Towards super-fast ultra-resolution arbitrary style transfer},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Contrastive masked autoencoders for self-supervised video
hashing. <em>AAAI</em>, 2733–2741. (<a
href="https://doi.org/10.1609/aaai.v37i3.25373">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Self-Supervised Video Hashing (SSVH) models learn to generate short binary representations for videos without ground-truth supervision, facilitating large-scale video retrieval efficiency and attracting increasing research attention. The success of SSVH lies in the understanding of video content and the ability to capture the semantic relation among unlabeled videos. Typically, state-of-the-art SSVH methods consider these two points in a two-stage training pipeline, where they firstly train an auxiliary network by instance-wise mask-and-predict tasks and secondly train a hashing model to preserve the pseudo-neighborhood structure transferred from the auxiliary network. This consecutive training strategy is inflexible and also unnecessary. In this paper, we propose a simple yet effective one-stage SSVH method called ConMH, which incorporates video semantic information and video similarity relationship understanding in a single stage. To capture video semantic information for better hashing learning, we adopt an encoder-decoder structure to reconstruct the video from its temporal-masked frames. Particularly, we find that a higher masking ratio helps video understanding. Besides, we fully exploit the similarity relationship between videos by maximizing agreement between two augmented views of a video, which contributes to more discriminative and robust hash codes. Extensive experiments on three large-scale video datasets (i.e., FCVID, ActivityNet and YFCC) indicate that ConMH achieves state-of-the-art results. Code is available at https://github.com/huangmozhi9527/ConMH.},
  archive   = {C_AAAI},
  author    = {Yuting Wang and Jinpeng Wang and Bin Chen and Ziyun Zeng and Shu-Tao Xia},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25373},
  pages     = {2733-2741},
  title     = {Contrastive masked autoencoders for self-supervised video hashing},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). GAN prior based null-space learning for consistent
super-resolution. <em>AAAI</em>, 2724–2732. (<a
href="https://doi.org/10.1609/aaai.v37i3.25372">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Consistency and realness have always been the two critical issues of image super-resolution. While the realness has been dramatically improved with the use of GAN prior, the state-of-the-art methods still suffer inconsistencies in local structures and colors (e.g., tooth and eyes). In this paper, we show that these inconsistencies can be analytically eliminated by learning only the null-space component while fixing the range-space part. Further, we design a pooling-based decomposition (PD), a universal range-null space decomposition for super-resolution tasks, which is concise, fast, and parameter-free. PD can be easily applied to state-of-the-art GAN Prior based SR methods to eliminate their inconsistencies, neither compromise the realness nor bring extra parameters or computational costs. Besides, our ablation studies reveal that PD can replace pixel-wise losses for training and achieve better generalization performance when facing unseen downsamplings or even real-world degradation. Experiments show that the use of PD refreshes state-of-the-art SR performance and speeds up the convergence of training up to 2~10 times.},
  archive   = {C_AAAI},
  author    = {Yinhuai Wang and Yujie Hu and Jiwen Yu and Jian Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25372},
  pages     = {2724-2732},
  title     = {GAN prior based null-space learning for consistent super-resolution},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). High-resolution GAN inversion for degraded images in large
diverse datasets. <em>AAAI</em>, 2716–2723. (<a
href="https://doi.org/10.1609/aaai.v37i3.25371">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The last decades are marked by massive and diverse image data, which shows increasingly high resolution and quality. However, some images we obtained may be corrupted, affecting the perception and the application of downstream tasks. A generic method for generating a high-quality image from the degraded one is in demand. In this paper, we present a novel GAN inversion framework that utilizes the powerful generative ability of StyleGAN-XL for this problem. To ease the inversion challenge with StyleGAN-XL, Clustering \&amp; Regularize Inversion (CRI) is proposed. Specifically, the latent space is firstly divided into finer-grained sub-spaces by clustering. Instead of initializing the inversion with the average latent vector, we approximate a centroid latent vector from the clusters, which generates an image close to the input image. Then, an offset with a regularization term is introduced to keep the inverted latent vector within a certain range. We validate our CRI scheme on multiple restoration tasks (i.e., inpainting, colorization, and super-resolution) of complex natural images, and show preferable quantitative and qualitative results. We further demonstrate our technique is robust in terms of data and different GAN models. To our best knowledge, we are the first to adopt StyleGAN-XL for generating high-quality natural images from diverse degraded inputs. Code is available at https://github.com/Booooooooooo/CRI.},
  archive   = {C_AAAI},
  author    = {Yanbo Wang and Chuming Lin and Donghao Luo and Ying Tai and Zhizhong Zhang and Yuan Xie},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25371},
  pages     = {2716-2723},
  title     = {High-resolution GAN inversion for degraded images in large diverse datasets},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SSDA3D: Semi-supervised domain adaptation for 3D object
detection from point cloud. <em>AAAI</em>, 2707–2715. (<a
href="https://doi.org/10.1609/aaai.v37i3.25370">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {LiDAR-based 3D object detection is an indispensable task in advanced autonomous driving systems. Though impressive detection results have been achieved by superior 3D detectors, they suffer from significant performance degeneration when facing unseen domains, such as different LiDAR configurations, different cities, and weather conditions. The mainstream approaches tend to solve these challenges by leveraging unsupervised domain adaptation (UDA) techniques. However, these UDA solutions just yield unsatisfactory 3D detection results when there is a severe domain shift, e.g., from Waymo (64-beam) to nuScenes (32-beam). To address this, we present a novel Semi-Supervised Domain Adaptation method for 3D object detection (SSDA3D), where only a few labeled target data is available, yet can significantly improve the adaptation performance. In particular, our SSDA3D includes an Inter-domain Adaptation stage and an Intra-domain Generalization stage. In the first stage, an Inter-domain Point-CutMix module is presented to efficiently align the point cloud distribution across domains. The Point-CutMix generates mixed samples of an intermediate domain, thus encouraging to learn domain-invariant knowledge. Then, in the second stage, we further enhance the model for better generalization on the unlabeled target set. This is achieved by exploring Intra-domain Point-MixUp in semi-supervised learning, which essentially regularizes the pseudo label distribution. Experiments from Waymo to nuScenes show that, with only 10\% labeled target data, our SSDA3D can surpass the fully-supervised oracle model with 100\% target label. Our code is available at https://github.com/yinjunbo/SSDA3D.},
  archive   = {C_AAAI},
  author    = {Yan Wang and Junbo Yin and Wei Li and Pascal Frossard and Ruigang Yang and Jianbing Shen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25370},
  pages     = {2707-2715},
  title     = {SSDA3D: Semi-supervised domain adaptation for 3D object detection from point cloud},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning continuous depth representation via geometric
spatial aggregator. <em>AAAI</em>, 2698–2706. (<a
href="https://doi.org/10.1609/aaai.v37i3.25369">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Depth map super-resolution (DSR) has been a fundamental task for 3D computer vision. While arbitrary scale DSR is a more realistic setting in this scenario, previous approaches predominantly suffer from the issue of inefficient real-numbered scale upsampling. To explicitly address this issue, we propose a novel continuous depth representation for DSR. The heart of this representation is our proposed Geometric Spatial Aggregator (GSA), which exploits a distance field modulated by arbitrarily upsampled target gridding, through which the geometric information is explicitly introduced into feature aggregation and target generation. Furthermore, bricking with GSA, we present a transformer-style backbone named GeoDSR, which possesses a principled way to construct the functional mapping between local coordinates and the high-resolution output results, empowering our model with the advantage of arbitrary shape transformation ready to help diverse zooming demand. Extensive experimental results on standard depth map benchmarks, e.g., NYU v2, have demonstrated that the proposed framework achieves significant restoration gain in arbitrary scale depth map super-resolution compared with the prior art. Our codes are available at https://github.com/nana01219/GeoDSR.},
  archive   = {C_AAAI},
  author    = {Xiaohang Wang and Xuanhong Chen and Bingbing Ni and Zhengyan Tong and Hang Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25369},
  pages     = {2698-2706},
  title     = {Learning continuous depth representation via geometric spatial aggregator},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Crafting monocular cues and velocity guidance for
self-supervised multi-frame depth learning. <em>AAAI</em>, 2689–2697.
(<a href="https://doi.org/10.1609/aaai.v37i3.25368">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Self-supervised monocular methods can efficiently learn depth information of weakly textured surfaces or reflective objects. However, the depth accuracy is limited due to the inherent ambiguity in monocular geometric modeling. In contrast, multi-frame depth estimation methods improve depth accuracy thanks to the success of Multi-View Stereo (MVS), which directly makes use of geometric constraints. Unfortunately, MVS often suffers from texture-less regions, non-Lambertian surfaces, and moving objects, especially in real-world video sequences without known camera motion and depth supervision. Therefore, we propose MOVEDepth, which exploits the MOnocular cues and VElocity guidance to improve multi-frame Depth learning. Unlike existing methods that enforce consistency between MVS depth and monocular depth, MOVEDepth boosts multi-frame depth learning by directly addressing the inherent problems of MVS. The key of our approach is to utilize monocular depth as a geometric priority to construct MVS cost volume, and adjust depth candidates of cost volume under the guidance of predicted camera velocity. We further fuse monocular depth and MVS depth by learning uncertainty in the cost volume, which results in a robust depth estimation against ambiguity in multi-view geometry. Extensive experiments show MOVEDepth achieves state-of-the-art performance: Compared with Monodepth2 and PackNet, our method relatively improves the depth accuracy by 20\% and 19.8\% on the KITTI benchmark. MOVEDepth also generalizes to the more challenging DDAD benchmark, relatively outperforming ManyDepth by 7.2\%. The code is available at https://github.com/JeffWang987/MOVEDepth.},
  archive   = {C_AAAI},
  author    = {Xiaofeng Wang and Zheng Zhu and Guan Huang and Xu Chi and Yun Ye and Ziwei Chen and Xingang Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25368},
  pages     = {2689-2697},
  title     = {Crafting monocular cues and velocity guidance for self-supervised multi-frame depth learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Revisiting unsupervised local descriptor learning.
<em>AAAI</em>, 2680–2688. (<a
href="https://doi.org/10.1609/aaai.v37i3.25367">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Constructing accurate training tuples is crucial for unsupervised local descriptor learning, yet challenging due to the absence of patch labels. The state-of-the-art approach constructs tuples with heuristic rules, which struggle to precisely depict real-world patch transformations, in spite of enabling fast model convergence. A possible solution to alleviate the problem is the clustering-based approach, which can capture realistic patch variations and learn more accurate class decision boundaries, but suffers from slow model convergence. This paper presents HybridDesc, an unsupervised approach that learns powerful local descriptor models with fast convergence speed by combining the rule-based and clustering-based approaches to construct training tuples. In addition, HybridDesc also contributes two concrete enhancing mechanisms: (1) a Differentiable Hyperparameter Search (DHS) strategy to find the optimal hyperparameter setting of the rule-based approach so as to provide accurate prior for the clustering-based approach, (2) an On-Demand Clustering (ODC) method to reduce the clustering overhead of the clustering-based approach without eroding its advantage. Extensive experimental results show that HybridDesc can efficiently learn local descriptors that surpass existing unsupervised local descriptors and even rival competitive supervised ones.},
  archive   = {C_AAAI},
  author    = {Wufan Wang and Lei Zhang and Hua Huang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25367},
  pages     = {2680-2688},
  title     = {Revisiting unsupervised local descriptor learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A benchmark and asymmetrical-similarity learning for
practical image copy detection. <em>AAAI</em>, 2672–2679. (<a
href="https://doi.org/10.1609/aaai.v37i3.25366">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Image copy detection (ICD) aims to determine whether a query image is an edited copy of any image from a reference set. Currently, there are very limited public benchmarks for ICD, while all overlook a critical challenge in real-world applications, i.e., the distraction from hard negative queries. Specifically, some queries are not edited copies but are inherently similar to some reference images. These hard negative queries are easily false recognized as edited copies, significantly compromising the ICD accuracy. This observation motivates us to build the first ICD benchmark featuring this characteristic. Based on existing ICD datasets, this paper constructs a new dataset by additionally adding 100,000 and 24, 252 hard negative pairs into the training and test set, respectively. Moreover, this paper further reveals a unique difficulty for solving the hard negative problem in ICD, i.e., there is a fundamental conflict between current metric learning and ICD. This conflict is: the metric learning adopts symmetric distance while the edited copy is an asymmetric (unidirectional) process, e.g., a partial crop is close to its holistic reference image and is an edited copy, while the latter cannot be the edited copy of the former (in spite the distance is equally small). This insight results in an Asymmetrical-Similarity Learning (ASL) method, which allows the similarity in two directions (the query ↔ the reference image) to be different from each other. Experimental results show that ASL outperforms state-of-the-art methods by a clear margin, confirming that solving the symmetric-asymmetric conflict is critical for ICD. The NDEC dataset and code are available at https://github.com/WangWenhao0716/ASL.},
  archive   = {C_AAAI},
  author    = {Wenhao Wang and Yifan Sun and Yi Yang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25366},
  pages     = {2672-2679},
  title     = {A benchmark and asymmetrical-similarity learning for practical image copy detection},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). 3D assembly completion. <em>AAAI</em>, 2663–2671. (<a
href="https://doi.org/10.1609/aaai.v37i3.25365">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Automatic assembly is a promising research topic in 3D computer vision and robotics. Existing works focus on generating assembly (e.g., IKEA furniture) from scratch with a set of parts, namely 3D part assembly. In practice, there are higher demands for the robot to take over and finish an incomplete assembly (e.g., a half-assembled IKEA furniture) with an off-the-shelf toolkit, especially in human-robot and multi-agent collaborations. Compared to 3D part assembly, it is more complicated in nature and remains unexplored yet. The robot must understand the incomplete structure, infer what parts are missing, single out the correct parts from the toolkit and finally, assemble them with appropriate poses to finish the incomplete assembly. Geometrically similar parts in the toolkit can interfere, and this problem will be exacerbated with more missing parts. To tackle this issue, we propose a novel task called 3D assembly completion. Given an incomplete assembly, it aims to find its missing parts from a toolkit and predict the 6-DoF poses to make the assembly complete. To this end, we propose FiT, a framework for Finishing the incomplete 3D assembly with Transformer. We employ the encoder to model the incomplete assembly into memories. Candidate parts interact with memories in a memory-query paradigm for final candidate classification and pose prediction. Bipartite part matching and symmetric transformation consistency are embedded to refine the completion. For reasonable evaluation and further reference, we design two standard toolkits of different difficulty, containing different compositions of candidate parts. We conduct extensive comparisons with several baseline methods and ablation studies, demonstrating the effectiveness of the proposed method.},
  archive   = {C_AAAI},
  author    = {Weihao Wang and Rufeng Zhang and Mingyu You and Hongjun Zhou and Bin He},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25365},
  pages     = {2663-2671},
  title     = {3D assembly completion},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Ultra-high-definition low-light image enhancement: A
benchmark and transformer-based method. <em>AAAI</em>, 2654–2662. (<a
href="https://doi.org/10.1609/aaai.v37i3.25364">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As the quality of optical sensors improves, there is a need for processing large-scale images. In particular, the ability of devices to capture ultra-high definition (UHD) images and video places new demands on the image processing pipeline. In this paper, we consider the task of low-light image enhancement (LLIE) and introduce a large-scale database consisting of images at 4K and 8K resolution. We conduct systematic benchmarking studies and provide a comparison of current LLIE algorithms. As a second contribution, we introduce LLFormer, a transformer-based low-light enhancement method. The core components of LLFormer are the axis-based multi-head self-attention and cross-layer attention fusion block, which significantly reduces the linear complexity. Extensive experiments on the new dataset and existing public datasets show that LLFormer outperforms state-of-the-art methods. We also show that employing existing LLIE methods trained on our benchmark as a pre-processing step significantly improves the performance of downstream tasks, e.g., face detection in low-light conditions. The source code and pre-trained models are available at https://github.com/TaoWangzj/LLFormer.},
  archive   = {C_AAAI},
  author    = {Tao Wang and Kaihao Zhang and Tianrun Shen and Wenhan Luo and Bjorn Stenger and Tong Lu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i3.25364},
  pages     = {2654-2662},
  title     = {Ultra-high-definition low-light image enhancement: A benchmark and transformer-based method},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fine-grained retrieval prompt tuning. <em>AAAI</em>,
2644–2652. (<a href="https://doi.org/10.1609/aaai.v37i2.25363">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Fine-grained object retrieval aims to learn discriminative representation to retrieve visually similar objects. However, existing top-performing works usually impose pairwise similarities on the semantic embedding spaces or design a localization sub-network to continually fine-tune the entire model in limited data scenarios, thus resulting in convergence to suboptimal solutions. In this paper, we develop Fine-grained Retrieval Prompt Tuning (FRPT), which steers a frozen pre-trained model to perform the fine-grained retrieval task from the perspectives of sample prompting and feature adaptation. Specifically, FRPT only needs to learn fewer parameters in the prompt and adaptation instead of fine-tuning the entire model, thus solving the issue of convergence to suboptimal solutions caused by fine-tuning the entire model. Technically, a discriminative perturbation prompt (DPP) is introduced and deemed as a sample prompting process, which amplifies and even exaggerates some discriminative elements contributing to category prediction via a content-aware inhomogeneous sampling operation. In this way, DPP can make the fine-grained retrieval task aided by the perturbation prompts close to the solved task during the original pre-training. Thereby, it preserves the generalization and discrimination of representation extracted from input samples. Besides, a category-specific awareness head is proposed and regarded as feature adaptation, which removes the species discrepancies in features extracted by the pre-trained model using category-guided instance normalization. And thus, it makes the optimized features only include the discrepancies among subcategories. Extensive experiments demonstrate that our FRPT with fewer learnable parameters achieves the state-of-the-art performance on three widely-used fine-grained datasets.},
  archive   = {C_AAAI},
  author    = {Shijie Wang and Jianlong Chang and Zhihui Wang and Haojie Li and Wanli Ouyang and Qi Tian},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25363},
  pages     = {2644-2652},
  title     = {Fine-grained retrieval prompt tuning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Global-local characteristic excited cross-modal attacks from
images to videos. <em>AAAI</em>, 2635–2643. (<a
href="https://doi.org/10.1609/aaai.v37i2.25362">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The transferability of adversarial examples is the key property in practical black-box scenarios. Currently, numerous methods improve the transferability across different models trained on the same modality of data. The investigation of generating video adversarial examples with imagebased substitute models to attack the target video models, i.e., cross-modal transferability of adversarial examples, is rarely explored. A few works on cross-modal transferability directly apply image attack methods for each frame and no factors especial for video data are considered, which limits the cross-modal transferability of adversarial examples. In this paper, we propose an effective cross-modal attack method which considers both the global and local characteristics of video data. Firstly, from the global perspective, we introduce inter-frame interaction into attack process to induce more diverse and stronger gradients rather than perturb each frame separately. Secondly, from the local perspective, we disrupt the inherently local correlation of frames within a video, which prevents black-box video model from capturing valuable temporal clues. Extensive experiments on the UCF-101 and Kinetics-400 validate the proposed method significantly improves cross-modal transferability and even surpasses strong baseline using video models as substitute model. Our source codes are available at https://github.com/lwmming/Cross-Modal-Attack.},
  archive   = {C_AAAI},
  author    = {Ruikui Wang and Yuanfang Guo and Yunhong Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25362},
  pages     = {2635-2643},
  title     = {Global-local characteristic excited cross-modal attacks from images to videos},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ECO-3D: Equivariant contrastive learning for pre-training on
perturbed 3D point cloud. <em>AAAI</em>, 2626–2634. (<a
href="https://doi.org/10.1609/aaai.v37i2.25361">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this work, we investigate contrastive learning on perturbed point clouds and find that the contrasting process may widen the domain gap caused by random perturbations, making the pre-trained network fail to generalize on testing data. To this end, we propose the Equivariant COntrastive framework which closes the domain gap before contrasting, further introduces the equivariance property, and enables pre-training networks under more perturbation types to obtain meaningful features. Specifically, to close the domain gap, a pre-trained VAE is adopted to convert perturbed point clouds into less perturbed point embedding of similar domains and separated perturbation embedding. The contrastive pairs can then be generated by mixing the point embedding with different perturbation embedding. Moreover, to pursue the equivariance property, a Vector Quantizer is adopted during VAE training, discretizing the perturbation embedding into one-hot tokens which indicate the perturbation labels. By correctly predicting the perturbation labels from the perturbed point cloud, the property of equivariance can be encouraged in the learned features. Experiments on synthesized and real-world perturbed datasets show that ECO-3D outperforms most existing pre-training strategies under various downstream tasks, achieving SOTA performance for lots of perturbations.},
  archive   = {C_AAAI},
  author    = {Ruibin Wang and Xianghua Ying and Bowei Xing and Jinfa Yang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25361},
  pages     = {2626-2634},
  title     = {ECO-3D: Equivariant contrastive learning for pre-training on perturbed 3D point cloud},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Controllable image captioning via prompting. <em>AAAI</em>,
2617–2625. (<a href="https://doi.org/10.1609/aaai.v37i2.25360">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Despite the remarkable progress of image captioning, existing captioners typically lack the controllable capability to generate desired image captions, e.g., describing the image in a rough or detailed manner, in a factual or emotional view, etc. In this paper, we show that a unified model is qualified to perform well in diverse domains and freely switch among multiple styles. Such a controllable capability is achieved by embedding the prompt learning into the image captioning framework. To be specific, we design a set of prompts to fine-tune the pre-trained image captioner. These prompts allow the model to absorb stylized data from different domains for joint training, without performance degradation in each domain. Furthermore, we optimize the prompts with learnable vectors in the continuous word embedding space, avoiding the heuristic prompt engineering and meanwhile exhibiting superior performance. In the inference stage, our model is able to generate desired stylized captions by choosing the corresponding prompts. Extensive experiments verify the controllable capability of the proposed method. Notably, we achieve outstanding performance on two diverse image captioning benchmarks including COCO Karpathy split and TextCaps using a unified model.},
  archive   = {C_AAAI},
  author    = {Ning Wang and Jiahao Xie and Jihao Wu and Mingbo Jia and Linlin Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25360},
  pages     = {2617-2625},
  title     = {Controllable image captioning via prompting},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient image captioning for edge devices. <em>AAAI</em>,
2608–2616. (<a href="https://doi.org/10.1609/aaai.v37i2.25359">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent years have witnessed the rapid progress of image captioning. However, the demands for large memory storage and heavy computational burden prevent these captioning models from being deployed on mobile devices. The main obstacles lie in the heavyweight visual feature extractors (i.e., object detectors) and complicated cross-modal fusion networks. To this end, we propose LightCap, a lightweight image captioner for resource-limited devices. The core design is built on the recent CLIP model for efficient image captioning. To be specific, on the one hand, we leverage the CLIP model to extract the compact grid features without relying on the time-consuming object detectors. On the other hand, we transfer the image-text retrieval design of CLIP to image captioning scenarios by devising a novel visual concept extractor and a cross-modal modulator. We further optimize the cross-modal fusion model and parallel prediction heads via sequential and ensemble distillations. With the carefully designed architecture, our model merely contains 40M parameters, saving the model size by more than 75\% and the FLOPs by more than 98\% in comparison with the current state-of-the-art methods. In spite of the low capacity, our model still exhibits state-of-the-art performance on prevalent datasets, e.g., 136.6 CIDEr on COCO Karpathy test split. Testing on the smartphone with only a single CPU, the proposed LightCap exhibits a fast inference speed of 188ms per image, which is ready for practical applications.},
  archive   = {C_AAAI},
  author    = {Ning Wang and Jiangrong Xie and Hang Luo and Qinglin Cheng and Jihao Wu and Mingbo Jia and Linlin Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25359},
  pages     = {2608-2616},
  title     = {Efficient image captioning for edge devices},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Flora: Dual-frequency LOss-compensated ReAl-time monocular
3D video reconstruction. <em>AAAI</em>, 2599–2607. (<a
href="https://doi.org/10.1609/aaai.v37i2.25358">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this work, we propose a real-time monocular 3D video reconstruction approach named Flora for reconstructing delicate and complete 3D scenes from RGB video sequences in an end-to-end manner. Specifically, we introduce a novel method with two main contributions. Firstly, the proposed feature aggregation module retains both color and reliability in a dual-frequency form. Secondly, the loss compensation module solves missing structure by correcting losses for falsely pruned voxels. The dual-frequency feature aggregation module enhances reconstruction quality in both precision and recall, and the loss compensation module benefits the recall. Notably, both proposed contributions achieve great results with negligible inferencing overhead. Our state-of-the-art experimental results on real-world datasets demonstrate Flora&#39;s leading performance in both effectiveness and efficiency. The code is available at https://github.com/NoOneUST/Flora.},
  archive   = {C_AAAI},
  author    = {Likang Wang and Yue Gong and Qirui Wang and Kaixuan Zhou and Lei Chen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25358},
  pages     = {2599-2607},
  title     = {Flora: Dual-frequency LOss-compensated ReAl-time monocular 3D video reconstruction},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Alignment-enriched tuning for patch-level pre-trained
document image models. <em>AAAI</em>, 2590–2598. (<a
href="https://doi.org/10.1609/aaai.v37i2.25357">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Alignment between image and text has shown promising improvements on patch-level pre-trained document image models. However, investigating more effective or finer-grained alignment techniques during pre-training requires a large amount of computation cost and time. Thus, a question naturally arises: Could we fine-tune the pre-trained models adaptive to downstream tasks with alignment objectives and achieve comparable or better performance? In this paper, we propose a new model architecture with alignment-enriched tuning (dubbed AETNet) upon pre-trained document image models, to adapt downstream tasks with the joint task-specific supervised and alignment-aware contrastive objective. Specifically, we introduce an extra visual transformer as the alignment-ware image encoder and an extra text transformer as the alignment-ware text encoder before multimodal fusion. We consider alignment in the following three aspects: 1) document-level alignment by leveraging the cross-modal and intra-modal contrastive loss; 2) global-local alignment for modeling localized and structural information in document images; and 3) local-level alignment for more accurate patch-level information. Experiments on various downstream tasks show that AETNet can achieve state-of-the-art performance on various downstream tasks. Notably, AETNet consistently outperforms state-of-the-art pre-trained models, such as LayoutLMv3 with fine-tuning techniques, on three different downstream tasks. Code is available at https://github.com/MAEHCM/AET.},
  archive   = {C_AAAI},
  author    = {Lei Wang and Jiabang He and Xing Xu and Ning Liu and Hui Liu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25357},
  pages     = {2590-2598},
  title     = {Alignment-enriched tuning for patch-level pre-trained document image models},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning to generate an unbiased scene graph by using
attribute-guided predicate features. <em>AAAI</em>, 2581–2589. (<a
href="https://doi.org/10.1609/aaai.v37i2.25356">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Scene Graph Generation (SGG) aims to capture the semantic information in an image and build a structured representation, which facilitates downstream tasks. The current challenge in SGG is to tackle the biased predictions caused by the long-tailed distribution of predicates. Since multiple predicates in SGG are coupled in an image, existing data re-balancing methods cannot completely balance the head and tail predicates. In this work, a decoupled learning framework is proposed for unbiased scene graph generation by using attribute-guided predicate features to construct a balanced training set. Specifically, the predicate recognition is decoupled into Predicate Feature Representation Learning (PFRL) and predicate classifier training with a class-balanced predicate feature set, which is constructed by our proposed Attribute-guided Predicate Feature Generation (A-PFG) model. In the A-PFG model, we first define the class labels of and corresponding visual feature as attributes to describe a predicate. Then the predicate feature and the attribute embedding are mapped into a shared hidden space by a dual Variational Auto-encoder (VAE), and finally the synthetic predicate features are forced to learn the contextual information in the attributes via cross reconstruction and distribution alignment. To demonstrate the effectiveness of our proposed method, our decoupled learning framework and A-PFG model are applied to various SGG models. The empirical results show that our method is substantially improved on all benchmarks and achieves new state-of-the-art performance for unbiased scene graph generation. Our code is available at https://github.com/wanglei0618/A-PFG.},
  archive   = {C_AAAI},
  author    = {Lei Wang and Zejian Yuan and Badong Chen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25356},
  pages     = {2581-2589},
  title     = {Learning to generate an unbiased scene graph by using attribute-guided predicate features},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). De-biased teacher: Rethinking IoU matching for
semi-supervised object detection. <em>AAAI</em>, 2573–2580. (<a
href="https://doi.org/10.1609/aaai.v37i2.25355">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Most of the recent research in semi-supervised object detection follows the pseudo-labeling paradigm evolved from the semi-supervised image classification task. However, the training paradigm of the two-stage object detector inevitably makes the pseudo-label learning process for unlabeled images full of bias. Specifically, the IoU matching scheme used for selecting and labeling candidate boxes is based on the assumption that the matching source~(ground truth) is accurate enough in terms of the number of objects, object position and object category. Obviously, pseudo-labels generated for unlabeled images cannot satisfy such a strong assumption, which makes the produced training proposals extremely unreliable and thus severely spoil the follow-up training. To de-bias the training proposals generated by the pseudo-label-based IoU matching, we propose a general framework -- De-biased Teacher, which abandons both the IoU matching and pseudo labeling processes by directly generating favorable training proposals for consistency regularization between the weak/strong augmented image pairs. Moreover, a distribution-based refinement scheme is designed to eliminate the scattered class predictions of significantly low values for higher efficiency. Extensive experiments demonstrate that the proposed De-biased Teacher consistently outperforms other state-of-the-art methods on the MS-COCO and PASCAL VOC benchmarks. Source codes are available at https://github.com/wkfdb/De-biased-Teracher.},
  archive   = {C_AAAI},
  author    = {Kuo Wang and Jingyu Zhuang and Guanbin Li and Chaowei Fang and Lechao Cheng and Liang Lin and Fan Zhou},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25355},
  pages     = {2573-2580},
  title     = {De-biased teacher: Rethinking IoU matching for semi-supervised object detection},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust video portrait reenactment via personalized
representation quantization. <em>AAAI</em>, 2564–2572. (<a
href="https://doi.org/10.1609/aaai.v37i2.25354">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {While progress has been made in the field of portrait reenactment, the problem of how to produce high-fidelity and robust videos remains. Recent studies normally find it challenging to handle rarely seen target poses due to the limitation of source data. This paper proposes the Video Portrait via Non-local Quantization Modeling (VPNQ) framework, which produces pose- and disturbance-robust reenactable video portraits. Our key insight is to learn position-invariant quantized local patch representations and build a mapping between simple driving signals and local textures with non-local spatial-temporal modeling. Specifically, instead of learning a universal quantized codebook, we identify that a personalized one can be trained to preserve desired position-invariant local details better. Then, a simple representation of projected landmarks can be used as sufficient driving signals to avoid 3D rendering. Following, we employ a carefully designed Spatio-Temporal Transformer to predict reasonable and temporally consistent quantized tokens from the driving signal. The predicted codes can be decoded back to robust and high-quality videos. Comprehensive experiments have been conducted to validate the effectiveness of our approach.},
  archive   = {C_AAAI},
  author    = {Kaisiyuan Wang and Changcheng Liang and Hang Zhou and Jiaxiang Tang and Qianyi Wu and Dongliang He and Zhibin Hong and Jingtuo Liu and Errui Ding and Ziwei Liu and Jingdong Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25354},
  pages     = {2564-2572},
  title     = {Robust video portrait reenactment via personalized representation quantization},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploring CLIP for assessing the look and feel of images.
<em>AAAI</em>, 2555–2563. (<a
href="https://doi.org/10.1609/aaai.v37i2.25353">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Measuring the perception of visual content is a long-standing problem in computer vision. Many mathematical models have been developed to evaluate the look or quality of an image. Despite the effectiveness of such tools in quantifying degradations such as noise and blurriness levels, such quantification is loosely coupled with human language. When it comes to more abstract perception about the feel of visual content, existing methods can only rely on supervised models that are explicitly trained with labeled data collected via laborious user study. In this paper, we go beyond the conventional paradigms by exploring the rich visual language prior encapsulated in Contrastive Language-Image Pre-training (CLIP) models for assessing both the quality perception (look) and abstract perception (feel) of images without explicit task-specific training. In particular, we discuss effective prompt designs and show an effective prompt pairing strategy to harness the prior. We also provide extensive experiments on controlled datasets and Image Quality Assessment (IQA) benchmarks. Our results show that CLIP captures meaningful priors that generalize well to different perceptual assessments.},
  archive   = {C_AAAI},
  author    = {Jianyi Wang and Kelvin C.K. Chan and Chen Change Loy},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25353},
  pages     = {2555-2563},
  title     = {Exploring CLIP for assessing the look and feel of images},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Defending black-box skeleton-based human activity
classifiers. <em>AAAI</em>, 2546–2554. (<a
href="https://doi.org/10.1609/aaai.v37i2.25352">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Skeletal motions have been heavily relied upon for human activity recognition (HAR). Recently, a universal vulnerability of skeleton-based HAR has been identified across a variety of classifiers and data, calling for mitigation. To this end, we propose the first black-box defense method for skeleton-based HAR to our best knowledge. Our method is featured by full Bayesian treatments of the clean data, the adversaries and the classifier, leading to (1) a new Bayesian Energy-based formulation of robust discriminative classifiers, (2) a new adversary sampling scheme based on natural motion manifolds, and (3) a new post-train Bayesian strategy for black-box defense. We name our framework Bayesian Energy-based Adversarial Training or BEAT. BEAT is straightforward but elegant, which turns vulnerable black-box classifiers into robust ones without sacrificing accuracy. It demonstrates surprising and universal effectiveness across a wide range of skeletal HAR classifiers and datasets, under various attacks. Appendix and code are available.},
  archive   = {C_AAAI},
  author    = {He Wang and Yunfeng Diao and Zichang Tan and Guodong Guo},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25352},
  pages     = {2546-2554},
  title     = {Defending black-box skeleton-based human activity classifiers},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). LeNo: Adversarial robust salient object detection networks
with learnable noise. <em>AAAI</em>, 2537–2545. (<a
href="https://doi.org/10.1609/aaai.v37i2.25351">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Pixel-wise prediction with deep neural network has become an effective paradigm for salient object detection (SOD) and achieved remarkable performance. However, very few SOD models are robust against adversarial attacks which are visually imperceptible for human visual attention. The previous work robust saliency (ROSA) shuffles the pre-segmented superpixels and then refines the coarse saliency map by the densely connected conditional random field (CRF). Different from ROSA that rely on various pre- and post-processings, this paper proposes a light-weight Learnable Noise (LeNo) to defend adversarial attacks for SOD models. LeNo preserves accuracy of SOD models on both adversarial and clean images, as well as inference speed. In general, LeNo consists of a simple shallow noise and noise estimation that embedded in the encoder and decoder of arbitrary SOD networks respectively. Inspired by the center prior of human visual attention mechanism, we initialize the shallow noise with a cross-shaped gaussian distribution for better defense against adversarial attacks. Instead of adding additional network components for post-processing, the proposed noise estimation modifies only one channel of the decoder. With the deeply-supervised noise-decoupled training on state-of-the-art RGB and RGB-D SOD networks, LeNo outperforms previous works not only on adversarial images but also on clean images, which contributes stronger robustness for SOD. Our code is available at https://github.com/ssecv/LeNo.},
  archive   = {C_AAAI},
  author    = {He Wang and Lin Wan and He Tang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25351},
  pages     = {2537-2545},
  title     = {LeNo: Adversarial robust salient object detection networks with learnable noise},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards real-time panoptic narrative grounding by an
end-to-end grounding network. <em>AAAI</em>, 2528–2536. (<a
href="https://doi.org/10.1609/aaai.v37i2.25350">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Panoptic Narrative Grounding (PNG) is an emerging cross-modal grounding task, which locates the target regions of an image corresponding to the text description. Existing approaches for PNG are mainly based on a two-stage paradigm, which is computationally expensive. In this paper, we propose a one-stage network for real-time PNG, termed End-to-End Panoptic Narrative Grounding network (EPNG), which directly generates masks for referents. Specifically, we propose two innovative designs, i.e., Locality-Perceptive Attention (LPA) and a bidirectional Semantic Alignment Loss (SAL), to properly handle the many-to-many relationship between textual expressions and visual objects. LPA embeds the local spatial priors into attention modeling, i.e., a pixel may belong to multiple masks at different scales, thereby improving segmentation. To help understand the complex semantic relationships, SAL proposes a bidirectional contrastive objective to regularize the semantic consistency inter modalities. Extensive experiments on the PNG benchmark dataset demonstrate the effectiveness and efficiency of our method. Compared to the single-stage baseline, our method achieves a significant improvement of up to 9.4\% accuracy. More importantly, our EPNG is 10 times faster than the two-stage model. Meanwhile, the generalization ability of EPNG is also validated by zero-shot experiments on other grounding tasks. The source codes and trained models for all our experiments are publicly available at https://github.com/Mr-Neko/EPNG.git.},
  archive   = {C_AAAI},
  author    = {Haowei Wang and Jiayi Ji and Yiyi Zhou and Yongjian Wu and Xiaoshuai Sun},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25350},
  pages     = {2528-2536},
  title     = {Towards real-time panoptic narrative grounding by an end-to-end grounding network},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Calibrated teacher for sparsely annotated object detection.
<em>AAAI</em>, 2519–2527. (<a
href="https://doi.org/10.1609/aaai.v37i2.25349">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Fully supervised object detection requires training images in which all instances are annotated. This is actually impractical due to the high labor and time costs and the unavoidable missing annotations. As a result, the incomplete annotation in each image could provide misleading supervision and harm the training. Recent works on sparsely annotated object detection alleviate this problem by generating pseudo labels for the missing annotations. Such a mechanism is sensitive to the threshold of the pseudo label score. However, the effective threshold is different in different training stages and among different object detectors. Therefore, the current methods with fixed thresholds have sub-optimal performance, and are difficult to be applied to other detectors. In order to resolve this obstacle, we propose a Calibrated Teacher, of which the confidence estimation of the prediction is well calibrated to match its real precision. In this way, different detectors in different training stages would share a similar distribution of the output confidence, so that multiple detectors could share the same fixed threshold and achieve better performance. Furthermore, we present a simple but effective Focal IoU Weight (FIoU) for the classification loss. FIoU aims at reducing the loss weight of false negative samples caused by the missing annotation, and thus works as the complement of the teacher-student paradigm. Extensive experiments show that our methods set new state-of-the-art under all different sparse settings in COCO. Code will be available at https://github.com/Whileherham/CalibratedTeacher.},
  archive   = {C_AAAI},
  author    = {Haohan Wang and Liang Liu and Boshen Zhang and Jiangning Zhang and Wuhao Zhang and Zhenye Gan and Yabiao Wang and Chengjie Wang and Haoqian Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25349},
  pages     = {2519-2527},
  title     = {Calibrated teacher for sparsely annotated object detection},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). UCoL: Unsupervised learning of discriminative facial
representations via uncertainty-aware contrast. <em>AAAI</em>,
2510–2518. (<a href="https://doi.org/10.1609/aaai.v37i2.25348">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper presents Uncertainty-aware Contrastive Learning (UCoL): a fully unsupervised framework for discriminative facial representation learning. Our UCoL is built upon a momentum contrastive network, referred to as Dual-path Momentum Network. Specifically, two flows of pairwise contrastive training are conducted simultaneously: one is formed with intra-instance self augmentation, and the other is to identify positive pairs collected by online pairwise prediction. We introduce a novel uncertainty-aware consistency K-nearest neighbors algorithm to generate predicted positive pairs, which enables efficient discriminative learning from large-scale open-world unlabeled data. Experiments show that UCoL significantly improves the baselines of unsupervised models and performs on par with the semi-supervised and supervised face representation learning methods.},
  archive   = {C_AAAI},
  author    = {Hao Wang and Min Li and Yangyang Song and Youjian Zhang and Liying Chi},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25348},
  pages     = {2510-2518},
  title     = {UCoL: Unsupervised learning of discriminative facial representations via uncertainty-aware contrast},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Text to point cloud localization with relation-enhanced
transformer. <em>AAAI</em>, 2501–2509. (<a
href="https://doi.org/10.1609/aaai.v37i2.25347">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Automatically localizing a position based on a few natural language instructions is essential for future robots to communicate and collaborate with humans. To approach this goal, we focus on a text-to-point-cloud cross-modal localization problem. Given a textual query, it aims to identify the described location from city-scale point clouds. The task involves two challenges. 1) In city-scale point clouds, similar ambient instances may exist in several locations. Searching each location in a huge point cloud with only instances as guidance may lead to less discriminative signals and incorrect results. 2) In textual descriptions, the hints are provided separately. In this case, the relations among those hints are not explicitly described, leaving the difficulties of learning relations to the agent itself. To alleviate the two challenges, we propose a unified Relation-Enhanced Transformer (RET) to improve representation discriminability for both point cloud and nature language queries. The core of the proposed RET is a novel Relation-enhanced Self-Attention (RSA) mechanism, which explicitly encodes instance (hint)-wise relations for the two modalities. Moreover, we propose a fine-grained cross-modal matching method to further refine the location predictions in a subsequent instance-hint matching stage. Experimental results on the KITTI360Pose dataset demonstrate that our approach surpasses the previous state-of-the-art method by large margins.},
  archive   = {C_AAAI},
  author    = {Guangzhi Wang and Hehe Fan and Mohan Kankanhalli},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25347},
  pages     = {2501-2509},
  title     = {Text to point cloud localization with relation-enhanced transformer},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dual memory aggregation network for event-based object
detection with learnable representation. <em>AAAI</em>, 2492–2500. (<a
href="https://doi.org/10.1609/aaai.v37i2.25346">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Event-based cameras are bio-inspired sensors that capture brightness change of every pixel in an asynchronous manner. Compared with frame-based sensors, event cameras have microsecond-level latency and high dynamic range, hence showing great potential for object detection under high-speed motion and poor illumination conditions. Due to sparsity and asynchronism nature with event streams, most of existing approaches resort to hand-crafted methods to convert event data into 2D grid representation. However, they are sub-optimal in aggregating information from event stream for object detection. In this work, we propose to learn an event representation optimized for event-based object detection. Specifically, event streams are divided into grids in the x-y-t coordinates for both positive and negative polarity, producing a set of pillars as 3D tensor representation. To fully exploit information with event streams to detect objects, a dual-memory aggregation network (DMANet) is proposed to leverage both long and short memory along event streams to aggregate effective information for object detection. Long memory is encoded in the hidden state of adaptive convLSTMs while short memory is modeled by computing spatial-temporal correlation between event pillars at neighboring time intervals. Extensive experiments on the recently released event-based automotive detection dataset demonstrate the effectiveness of the proposed method.},
  archive   = {C_AAAI},
  author    = {Dongsheng Wang and Xu Jia and Yang Zhang and Xinyu Zhang and Yaoyuan Wang and Ziyang Zhang and Dong Wang and Huchuan Lu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25346},
  pages     = {2492-2500},
  title     = {Dual memory aggregation network for event-based object detection with learnable representation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Controlling class layout for deep ordinal classification via
constrained proxies learning. <em>AAAI</em>, 2483–2491. (<a
href="https://doi.org/10.1609/aaai.v37i2.25345">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {For deep ordinal classification, learning a well-structured feature space specific to ordinal classification is helpful to properly capture the ordinal nature among classes. Intuitively, when Euclidean distance metric is used, an ideal ordinal layout in feature space would be that the sample clusters are arranged in class order along a straight line in space. However, enforcing samples to conform to a specific layout in the feature space is a challenging problem. To address this problem, in this paper, we propose a novel Constrained Proxies Learning (CPL) method, which can learn a proxy for each ordinal class and then adjusts the global layout of classes by constraining these proxies. Specifically, we propose two kinds of strategies: hard layout constraint and soft layout constraint. The hard layout constraint is realized by directly controlling the generation of proxies to force them to be placed in a strict linear layout or semicircular layout (i.e., two instantiations of strict ordinal layout). The soft layout constraint is realized by constraining that the proxy layout should always produce unimodal proxy-to-proxies similarity distribution for each proxy (i.e., to be a relaxed ordinal layout). Experiments show that the proposed CPL method outperforms previous deep ordinal classification methods under the same setting of feature extractor.},
  archive   = {C_AAAI},
  author    = {Cong Wang and Zhiwei Jiang and Yafeng Yin and Zifeng Cheng and Shiping Ge and Qing Gu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25345},
  pages     = {2483-2491},
  title     = {Controlling class layout for deep ordinal classification via constrained proxies learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Doodle to object: Practical zero-shot sketch-based 3D shape
retrieval. <em>AAAI</em>, 2474–2482. (<a
href="https://doi.org/10.1609/aaai.v37i2.25344">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Zero-shot (ZS) sketch-based three-dimensional (3D) shape retrieval (SBSR) is challenging due to the abstraction of sketches, cross-domain discrepancies between two-dimensional sketches and 3D shapes, and ZS-driven semantic knowledge transference from seen to unseen categories. Extant SBSR datasets suffer from lack of data, and no current SBSR methods consider ZS scenarios. In this paper, we contribute a new Doodle2Object (D2O) dataset consisting of 8,992 3D shapes and over 7M sketches spanning 50 categories. Then, we propose a novel prototype contrastive learning (PCL) method that effectively extracts features from different domains and adapts them to unseen categories. Specifically, our PCL method combines the ideas of contrastive and cluster-based prototype learning, and several randomly selected prototypes of different classes are assigned to each sample. By comparing these prototypes, a given sample can be moved closer to the same semantic class of samples while moving away from negative ones. Extensive experiments on two common SBSR benchmarks and our D2O dataset demonstrate the efficacy of the proposed PCL method for ZS-SBSR. Resource is available at https://github.com/yigohw/doodle2object.},
  archive   = {C_AAAI},
  author    = {Bingrui Wang and Yuan Zhou},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25344},
  pages     = {2474-2482},
  title     = {Doodle to object: Practical zero-shot sketch-based 3D shape retrieval},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Leveraging weighted cross-graph attention for visual and
semantic enhanced video captioning network. <em>AAAI</em>, 2465–2473.
(<a href="https://doi.org/10.1609/aaai.v37i2.25343">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Video captioning has become a broad and interesting research area. Attention-based encoder-decoder methods are extensively used for caption generation. However, these methods mostly utilize the visual attentive feature to highlight the video regions while overlooked the semantic features of the available captions. These semantic features contain significant information that helps to generate highly informative human description-like captions. Therefore, we propose a novel visual and semantic enhanced video captioning network, named as VSVCap, that efficiently utilizes multiple ground truth captions. We aim to generate captions that are visually and semantically enhanced by exploiting both video and text modalities. To achieve this, we propose a fine-grained cross-graph attention mechanism that captures detailed graph embedding correspondence between visual graphs and textual knowledge graphs. We have performed node-level matching and structure-level reasoning between the weighted regional graph and knowledge graph. The proposed network achieves promising results on three benchmark datasets, i.e., YouTube2Text, MSR-VTT, and VATEX. The experimental results show that our network accurately captures all key objects, relationships, and semantically enhanced events of a video to generate human annotation-like captions.},
  archive   = {C_AAAI},
  author    = {Deepali Verma and Arya Haldar and Tanima Dutta},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25343},
  pages     = {2465-2473},
  title     = {Leveraging weighted cross-graph attention for visual and semantic enhanced video captioning network},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning fractals by gradient descent. <em>AAAI</em>,
2456–2464. (<a href="https://doi.org/10.1609/aaai.v37i2.25342">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Fractals are geometric shapes that can display complex and self-similar patterns found in nature (e.g., clouds and plants). Recent works in visual recognition have leveraged this property to create random fractal images for model pre-training. In this paper, we study the inverse problem --- given a target image (not necessarily a fractal), we aim to generate a fractal image that looks like it. We propose a novel approach that learns the parameters underlying a fractal image via gradient descent. We show that our approach can find fractal parameters of high visual quality and be compatible with different loss functions, opening up several potentials, e.g., learning fractals for downstream tasks, scientific understanding, etc.},
  archive   = {C_AAAI},
  author    = {Cheng-Hao Tu and Hong-You Chen and David Carlyn and Wei-Lun Chao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25342},
  pages     = {2456-2464},
  title     = {Learning fractals by gradient descent},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TopicFM: Robust and interpretable topic-assisted feature
matching. <em>AAAI</em>, 2447–2455. (<a
href="https://doi.org/10.1609/aaai.v37i2.25341">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This study addresses an image-matching problem in challenging cases, such as large scene variations or textureless scenes. To gain robustness to such situations, most previous studies have attempted to encode the global contexts of a scene via graph neural networks or transformers. However, these contexts do not explicitly represent high-level contextual information, such as structural shapes or semantic instances; therefore, the encoded features are still not sufficiently discriminative in challenging scenes. We propose a novel image-matching method that applies a topic-modeling strategy to encode high-level contexts in images. The proposed method trains latent semantic instances called topics. It explicitly models an image as a multinomial distribution of topics, and then performs probabilistic feature matching. This approach improves the robustness of matching by focusing on the same semantic areas between the images. In addition, the inferred topics provide interpretability for matching the results, making our method explainable. Extensive experiments on outdoor and indoor datasets show that our method outperforms other state-of-the-art methods, particularly in challenging cases.},
  archive   = {C_AAAI},
  author    = {Khang Truong Giang and Soohwan Song and Sungho Jo},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25341},
  pages     = {2447-2455},
  title     = {TopicFM: Robust and interpretable topic-assisted feature matching},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning context-aware classifier for semantic segmentation.
<em>AAAI</em>, 2438–2446. (<a
href="https://doi.org/10.1609/aaai.v37i2.25340">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Semantic segmentation is still a challenging task for parsing diverse contexts in different scenes, thus the fixed classifier might not be able to well address varying feature distributions during testing. Different from the mainstream literature where the efficacy of strong backbones and effective decoder heads has been well studied, in this paper, additional contextual hints are instead exploited via learning a context-aware classifier whose content is data-conditioned, decently adapting to different latent distributions. Since only the classifier is dynamically altered, our method is model-agnostic and can be easily applied to generic segmentation models. Notably, with only negligible additional parameters and +2\% inference time, decent performance gain has been achieved on both small and large models with challenging benchmarks, manifesting substantial practical merits brought by our simple yet effective method. The implementation is available at https://github.com/tianzhuotao/CAC.},
  archive   = {C_AAAI},
  author    = {Zhuotao Tian and Jiequan Cui and Li Jiang and Xiaojuan Qi and Xin Lai and Yixin Chen and Shu Liu and Jiaya Jia},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25340},
  pages     = {2438-2446},
  title     = {Learning context-aware classifier for semantic segmentation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fair generative models via transfer learning. <em>AAAI</em>,
2429–2437. (<a href="https://doi.org/10.1609/aaai.v37i2.25339">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This work addresses fair generative models. Dataset biases have been a major cause of unfairness in deep generative models. Previous work had proposed to augment large, biased datasets with small, unbiased reference datasets. Under this setup, a weakly-supervised approach has been proposed, which achieves state-of-the-art quality and fairness in generated samples. In our work, based on this setup, we propose a simple yet effective approach. Specifically, first, we propose fairTL, a transfer learning approach to learn fair generative models. Under fairTL, we pre-train the generative model with the available large, biased datasets and subsequently adapt the model using the small, unbiased reference dataset. We find that our fairTL can learn expressive sample generation during pre-training, thanks to the large (biased) dataset. This knowledge is then transferred to the target model during adaptation, which also learns to capture the underlying fair distribution of the small reference dataset. Second, we propose fairTL++, where we introduce two additional innovations to improve upon fairTL: (i) multiple feedback and (ii) Linear-Probing followed by Fine-Tuning (LP-FT). Taking one step further, we consider an alternative, challenging setup when only a pre-trained (potentially biased) model is available but the dataset that was used to pre-train the model is inaccessible. We demonstrate that our proposed fairTL and fairTL++ remain very effective under this setup. We note that previous work requires access to the large, biased datasets and is incapable of handling this more challenging setup. Extensive experiments show that fairTL and fairTL++ achieve state-of-the-art in both quality and fairness of generated samples. The code and additional resources can be found at bearwithchris.github.io/fairTL/.},
  archive   = {C_AAAI},
  author    = {Christopher T.H. Teo and Milad Abdollahzadeh and Ngai-Man Cheung},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25339},
  pages     = {2429-2437},
  title     = {Fair generative models via transfer learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep manifold attack on point clouds via parameter plane
stretching. <em>AAAI</em>, 2420–2428. (<a
href="https://doi.org/10.1609/aaai.v37i2.25338">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Adversarial attack on point clouds plays a vital role in evaluating and improving the adversarial robustness of 3D deep learning models. Current attack methods are mainly applied by point perturbation in a non-manifold manner. In this paper, we formulate a novel manifold attack, which deforms the underlying 2-manifold surfaces via parameter plane stretching to generate adversarial point clouds. First, we represent the mapping between the parameter plane and underlying surface using generative-based networks. Second, the stretching is learned in the 2D parameter domain such that the generated 3D point cloud fools a pretrained classifier with minimal geometric distortion. Extensive experiments show that adversarial point clouds generated by manifold attack are smooth, undefendable and transferable, and outperform those samples generated by the state-of-the-art non-manifold ones.},
  archive   = {C_AAAI},
  author    = {Keke Tang and Jianpeng Wu and Weilong Peng and Yawen Shi and Peng Song and Zhaoquan Gu and Zhihong Tian and Wenping Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25338},
  pages     = {2420-2428},
  title     = {Deep manifold attack on point clouds via parameter plane stretching},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DENet: Disentangled embedding network for visible watermark
removal. <em>AAAI</em>, 2411–2419. (<a
href="https://doi.org/10.1609/aaai.v37i2.25337">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Adding visible watermark into image is a common copyright protection method of medias. Meanwhile, public research on watermark removal can be utilized as an adversarial technology to help the further development of watermarking. Existing watermark removal methods mainly adopt multi-task learning networks, which locate the watermark and restore the background simultaneously. However, these approaches view the task as an image-to-image reconstruction problem, where they only impose supervision after the final output, making the high-level semantic features shared between different tasks. To this end, inspired by the two-stage coarse-refinement network, we propose a novel contrastive learning mechanism to disentangle the high-level embedding semantic information of the images and watermarks, driving the respective network branch more oriented. Specifically, the proposed mechanism is leveraged for watermark image decomposition, which aims to decouple the clean image and watermark hints in the high-level embedding space. This can guarantee the learning representation of the restored image enjoy more task-specific cues. In addition, we introduce a self-attention-based enhancement module, which promotes the network&#39;s ability to capture semantic information among different regions, leading to further improvement on the contrastive learning mechanism. To validate the effectiveness of our proposed method, extensive experiments are conducted on different challenging benchmarks. Experimental evaluations show that our approach can achieve state-of-the-art performance and yield high-quality images. The code is available at: https://github.com/lianchengmingjue/DENet.},
  archive   = {C_AAAI},
  author    = {Ruizhou Sun and Yukun Su and Qingyao Wu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25337},
  pages     = {2411-2419},
  title     = {DENet: Disentangled embedding network for visible watermark removal},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Asynchronous event processing with local-shift graph
convolutional network. <em>AAAI</em>, 2402–2410. (<a
href="https://doi.org/10.1609/aaai.v37i2.25336">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Event cameras are bio-inspired sensors that produce sparse and asynchronous event streams instead of frame-based images at a high-rate. Recent works utilizing graph convolutional networks (GCNs) have achieved remarkable performance in recognition tasks, which model event stream as spatio-temporal graph. However, the computational mechanism of graph convolution introduces redundant computation when aggregating neighbor features, which limits the low-latency nature of the events. And they perform a synchronous inference process, which can not achieve a fast response to the asynchronous event signals. This paper proposes a local-shift graph convolutional network (LSNet), which utilizes a novel local-shift operation equipped with a local spatio-temporal attention component to achieve efficient and adaptive aggregation of neighbor features. To improve the efficiency of pooling operation in feature extraction, we design a node-importance based parallel pooling method (NIPooling) for sparse and low-latency event data. Based on the calculated importance of each node, NIPooling can efficiently obtain uniform sampling results in parallel, which retains the diversity of event streams. Furthermore, for achieving a fast response to asynchronous event signals, an asynchronous event processing procedure is proposed to restrict the network nodes which need to recompute activations only to those affected by the new arrival event. Experimental results show that the computational cost can be reduced by nearly 9 times through using local-shift operation and the proposed asynchronous procedure can further improve the inference efficiency, while achieving state-of-the-art performance on gesture recognition and object recognition.},
  archive   = {C_AAAI},
  author    = {Linhui Sun and Yifan Zhang and Jian Cheng and Hanqing Lu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25336},
  pages     = {2402-2410},
  title     = {Asynchronous event processing with local-shift graph convolutional network},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Superpoint transformer for 3D scene instance segmentation.
<em>AAAI</em>, 2393–2401. (<a
href="https://doi.org/10.1609/aaai.v37i2.25335">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Most existing methods realize 3D instance segmentation by extending those models used for 3D object detection or 3D semantic segmentation. However, these non-straightforward methods suffer from two drawbacks: 1) Imprecise bounding boxes or unsatisfactory semantic predictions limit the performance of the overall 3D instance segmentation framework. 2) Existing method requires a time-consuming intermediate step of aggregation. To address these issues, this paper proposes a novel end-to-end 3D instance segmentation method based on Superpoint Transformer, named as SPFormer. It groups potential features from point clouds into superpoints, and directly predicts instances through query vectors without relying on the results of object detection or semantic segmentation. The key step in this framework is a novel query decoder with transformers that can capture the instance information through the superpoint cross-attention mechanism and generate the superpoint masks of the instances. Through bipartite matching based on superpoint masks, SPFormer can implement the network training without the intermediate aggregation step, which accelerates the network. Extensive experiments on ScanNetv2 and S3DIS benchmarks verify that our method is concise yet efficient. Notably, SPFormer exceeds compared state-of-the-art methods by 4.3\% on ScanNetv2 hidden test set in terms of mAP and keeps fast inference speed (247ms per frame) simultaneously. Code is available at https://github.com/sunjiahao1999/SPFormer.},
  archive   = {C_AAAI},
  author    = {Jiahao Sun and Chunmei Qing and Junpeng Tan and Xiangmin Xu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25335},
  pages     = {2393-2401},
  title     = {Superpoint transformer for 3D scene instance segmentation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning event-relevant factors for video anomaly detection.
<em>AAAI</em>, 2384–2392. (<a
href="https://doi.org/10.1609/aaai.v37i2.25334">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Most video anomaly detection methods discriminate events that deviate from normal patterns as anomalies. However, these methods are prone to interferences from event-irrelevant factors, such as background textures and object scale variations, incurring an increased false detection rate. In this paper, we propose to explicitly learn event-relevant factors to eliminate the interferences from event-irrelevant factors on anomaly predictions. To this end, we introduce a causal generative model to separate the event-relevant factors and event-irrelevant ones in videos, and learn the prototypes of event-relevant factors in a memory augmentation module. We design a causal objective function to optimize the causal generative model and develop a counterfactual learning strategy to guide anomaly predictions, which increases the influence of the event-relevant factors. The extensive experiments show the effectiveness of our method for video anomaly detection.},
  archive   = {C_AAAI},
  author    = {Che Sun and Chenrui Shi and Yunde Jia and Yuwei Wu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25334},
  pages     = {2384-2392},
  title     = {Learning event-relevant factors for video anomaly detection},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hybrid pixel-unshuffled network for lightweight image
super-resolution. <em>AAAI</em>, 2375–2383. (<a
href="https://doi.org/10.1609/aaai.v37i2.25333">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Convolutional neural network (CNN) has achieved great success on image super-resolution (SR). However, most deep CNN-based SR models take massive computations to obtain high performance. Downsampling features for multi-resolution fusion is an efficient and effective way to improve the performance of visual recognition. Still, it is counter-intuitive in the SR task, which needs to project a low-resolution input to high-resolution. In this paper, we propose a novel Hybrid Pixel-Unshuffled Network (HPUN) by introducing an efficient and effective downsampling module into the SR task. The network contains pixel-unshuffled downsampling and Self-Residual Depthwise Separable Convolutions. Specifically, we utilize pixel-unshuffle operation to downsample the input features and use grouped convolution to reduce the channels. Besides, we enhance the depthwise convolution&#39;s performance by adding the input feature to its output. The comparison findings demonstrate that, with fewer parameters and computational costs, our HPUN achieves and surpasses the state-of-the-art performance on SISR. All results are provided in the github https://github.com/Sun1992/HPUN.},
  archive   = {C_AAAI},
  author    = {Bin Sun and Yulun Zhang and Songyao Jiang and Yun Fu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25333},
  pages     = {2375-2383},
  title     = {Hybrid pixel-unshuffled network for lightweight image super-resolution},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Rethinking data augmentation for single-source domain
generalization in medical image segmentation. <em>AAAI</em>, 2366–2374.
(<a href="https://doi.org/10.1609/aaai.v37i2.25332">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Single-source domain generalization (SDG) in medical image segmentation is a challenging yet essential task as domain shifts are quite common among clinical image datasets. Previous attempts most conduct global-only/random augmentation. Their augmented samples are usually insufficient in diversity and informativeness, thus failing to cover the possible target domain distribution. In this paper, we rethink the data augmentation strategy for SDG in medical image segmentation. Motivated by the class-level representation invariance and style mutability of medical images, we hypothesize that unseen target data can be sampled from a linear combination of C (the class number) random variables, where each variable follows a location-scale distribution at the class level. Accordingly, data augmented can be readily made by sampling the random variables through a general form. On the empirical front, we implement such strategy with constrained Bezier transformation on both global and local (i.e. class-level) regions, which can largely increase the augmentation diversity. A Saliency-balancing Fusion mechanism is further proposed to enrich the informativeness by engaging the gradient information, guiding augmentation with proper orientation and magnitude. As an important contribution, we prove theoretically that our proposed augmentation can lead to an upper bound of the generalization risk on the unseen target domain, thus confirming our hypothesis. Combining the two strategies, our Saliency-balancing Location-scale Augmentation (SLAug) exceeds the state-of-the-art works by a large margin in two challenging SDG tasks. Code is available at https://github.com/Kaiseem/SLAug.},
  archive   = {C_AAAI},
  author    = {Zixian Su and Kai Yao and Xi Yang and Kaizhu Huang and Qiufeng Wang and Jie Sun},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25332},
  pages     = {2366-2374},
  title     = {Rethinking data augmentation for single-source domain generalization in medical image segmentation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Referring expression comprehension using language adaptive
inference. <em>AAAI</em>, 2357–2365. (<a
href="https://doi.org/10.1609/aaai.v37i2.25331">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Different from universal object detection, referring expression comprehension (REC) aims to locate specific objects referred to by natural language expressions. The expression provides high-level concepts of relevant visual and contextual patterns, which vary significantly with different expressions and account for only a few of those encoded in the REC model. This leads us to a question: do we really need the entire network with a fixed structure for various referring expressions? Ideally, given an expression, only expression-relevant components of the REC model are required. These components should be small in number as each expression only contains very few visual and contextual clues. This paper explores the adaptation between expressions and REC models for dynamic inference. Concretely, we propose a neat yet efficient framework named Language Adaptive Dynamic Subnets (LADS), which can extract language-adaptive subnets from the REC model conditioned on the referring expressions. By using the compact subnet, the inference can be more economical and efficient. Extensive experiments on RefCOCO, RefCOCO+, RefCOCOg, and Referit show that the proposed method achieves faster inference speed and higher accuracy against state-of-the-art approaches.},
  archive   = {C_AAAI},
  author    = {Wei Su and Peihan Miao and Huanzhang Dou and Yongjian Fu and Xi Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25331},
  pages     = {2357-2365},
  title     = {Referring expression comprehension using language adaptive inference},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient edge-preserving multi-view stereo network for
depth estimation. <em>AAAI</em>, 2348–2356. (<a
href="https://doi.org/10.1609/aaai.v37i2.25330">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Over the years, learning-based multi-view stereo methods have achieved great success based on their coarse-to-fine depth estimation frameworks. However, 3D CNN-based cost volume regularization inevitably leads to over-smoothing problems at object boundaries due to its smooth properties. Moreover, discrete and sparse depth hypothesis sampling exacerbates the difficulty in recovering the depth of thin structures and object boundaries. To this end, we present an Efficient edge-Preserving multi-view stereo Network (EPNet) for practical depth estimation. To keep delicate estimation at details, a Hierarchical Edge-Preserving Residual learning (HEPR) module is proposed to progressively rectify the upsampling errors and help refine multi-scale depth estimation. After that, a Cross-view Photometric Consistency (CPC) is proposed to enhance the gradient flow for detailed structures, which further boosts the estimation accuracy. Last, we design a lightweight cascade framework and inject the above two strategies into it to achieve better efficiency and performance trade-offs. Extensive experiments show that our method achieves state-of-the-art performance with fast inference speed and low memory usage. Notably, our method tops the first place on challenging Tanks and Temples advanced dataset and ETH3D high-res benchmark among all published learning-based methods. Code will be available at https://github.com/susuwj/EPNet.},
  archive   = {C_AAAI},
  author    = {Wanjuan Su and Wenbing Tao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25330},
  pages     = {2348-2356},
  title     = {Efficient edge-preserving multi-view stereo network for depth estimation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PUPS: Point cloud unified panoptic segmentation.
<em>AAAI</em>, 2339–2347. (<a
href="https://doi.org/10.1609/aaai.v37i2.25329">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Point cloud panoptic segmentation is a challenging task that seeks a holistic solution for both semantic and instance segmentation to predict groupings of coherent points. Previous approaches treat semantic and instance segmentation as surrogate tasks, and they either use clustering methods or bounding boxes to gather instance groupings with costly computation and hand-craft designs in the instance segmentation task. In this paper, we propose a simple but effective point cloud unified panoptic segmentation (PUPS) framework, which use a set of point-level classifiers to directly predict semantic and instance groupings in an end-to-end manner. To realize PUPS, we introduce bipartite matching to our training pipeline so that our classifiers are able to exclusively predict groupings of instances, getting rid of hand-crafted designs, e.g. anchors and Non-Maximum Suppression (NMS). In order to achieve better grouping results, we utilize a transformer decoder to iteratively refine the point classifiers and develop a context-aware CutMix augmentation to overcome the class imbalance problem. As a result, PUPS achieves 1st place on the leader board of SemanticKITTI panoptic segmentation task and state-of-the-art results on nuScenes.},
  archive   = {C_AAAI},
  author    = {Shihao Su and Jianyun Xu and Huanyu Wang and Zhenwei Miao and Xin Zhan and Dayang Hao and Xi Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25329},
  pages     = {2339-2347},
  title     = {PUPS: Point cloud unified panoptic segmentation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Text-DIAE: A self-supervised degradation invariant
autoencoder for text recognition and document enhancement.
<em>AAAI</em>, 2330–2338. (<a
href="https://doi.org/10.1609/aaai.v37i2.25328">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we propose a Text-Degradation Invariant Auto Encoder (Text-DIAE), a self-supervised model designed to tackle two tasks, text recognition (handwritten or scene-text) and document image enhancement. We start by employing a transformer-based architecture that incorporates three pretext tasks as learning objectives to be optimized during pre-training without the usage of labelled data. Each of the pretext objectives is specifically tailored for the final downstream tasks. We conduct several ablation experiments that confirm the design choice of the selected pretext tasks. Importantly, the proposed model does not exhibit limitations of previous state-of-the-art methods based on contrastive losses, while at the same time requiring substantially fewer data samples to converge. Finally, we demonstrate that our method surpasses the state-of-the-art in existing supervised and self-supervised settings in handwritten and scene text recognition and document image enhancement. Our code and trained models will be made publicly available at https://github.com/dali92002/SSL-OCR},
  archive   = {C_AAAI},
  author    = {Mohamed Ali Souibgui and Sanket Biswas and Andres Mafla and Ali Furkan Biten and Alicia Fornés and Yousri Kessentini and Josep Lladós and Lluis Gomez and Dimosthenis Karatzas},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25328},
  pages     = {2330-2338},
  title     = {Text-DIAE: A self-supervised degradation invariant autoencoder for text recognition and document enhancement},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Compact transformer tracker with correlative masked
modeling. <em>AAAI</em>, 2321–2329. (<a
href="https://doi.org/10.1609/aaai.v37i2.25327">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Transformer framework has been showing superior performances in visual object tracking for its great strength in information aggregation across the template and search image with the well-known attention mechanism. Most recent advances focus on exploring attention mechanism variants for better information aggregation. We find these schemes are equivalent to or even just a subset of the basic self-attention mechanism. In this paper, we prove that the vanilla self-attention structure is sufficient for information aggregation, and structural adaption is unnecessary. The key is not the attention structure, but how to extract the discriminative feature for tracking and enhance the communication between the target and search image. Based on this finding, we adopt the basic vision transformer (ViT) architecture as our main tracker and concatenate the template and search image for feature embedding. To guide the encoder to capture the invariant feature for tracking, we attach a lightweight correlative masked decoder which reconstructs the original template and search image from the corresponding masked tokens. The correlative masked decoder serves as a plugin for the compact transformer tracker and is skipped in inference. Our compact tracker uses the most simple structure which only consists of a ViT backbone and a box head, and can run at 40 fps. Extensive experiments show the proposed compact transform tracker outperforms existing approaches, including advanced attention variants, and demonstrates the sufficiency of self-attention in tracking tasks. Our method achieves state-of-the-art performance on five challenging datasets, along with the VOT2020, UAV123, LaSOT, TrackingNet, and GOT-10k benchmarks. Our project is available at https://github.com/HUSTDML/CTTrack.},
  archive   = {C_AAAI},
  author    = {Zikai Song and Run Luo and Junqing Yu and Yi-Ping Phoebe Chen and Wei Yang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25327},
  pages     = {2321-2329},
  title     = {Compact transformer tracker with correlative masked modeling},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CLIPVG: Text-guided image manipulation using differentiable
vector graphics. <em>AAAI</em>, 2312–2320. (<a
href="https://doi.org/10.1609/aaai.v37i2.25326">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Considerable progress has recently been made in leveraging CLIP (Contrastive Language-Image Pre-Training) models for text-guided image manipulation. However, all existing works rely on additional generative models to ensure the quality of results, because CLIP alone cannot provide enough guidance information for fine-scale pixel-level changes. In this paper, we introduce CLIPVG, a text-guided image manipulation framework using differentiable vector graphics, which is also the first CLIP-based general image manipulation framework that does not require any additional generative models. We demonstrate that CLIPVG can not only achieve state-of-art performance in both semantic correctness and synthesis quality, but also is flexible enough to support various applications far beyond the capability of all existing methods.},
  archive   = {C_AAAI},
  author    = {Yiren Song and Xuning Shao and Kang Chen and Weidong Zhang and Zhongliang Jing and Minzhe Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25326},
  pages     = {2312-2320},
  title     = {CLIPVG: Text-guided image manipulation using differentiable vector graphics},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Siamese-discriminant deep reinforcement learning for solving
jigsaw puzzles with large eroded gaps. <em>AAAI</em>, 2303–2311. (<a
href="https://doi.org/10.1609/aaai.v37i2.25325">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Jigsaw puzzle solving has recently become an emerging research area. The developed techniques have been widely used in applications beyond puzzle solving. This paper focuses on solving Jigsaw Puzzles with Large Eroded Gaps (JPwLEG). We formulate the puzzle reassembly as a combinatorial optimization problem and propose a Siamese-Discriminant Deep Reinforcement Learning (SD2RL) to solve it. A Deep Q-network (DQN) is designed to visually understand the puzzles, which consists of two sets of Siamese Discriminant Networks, one set to perceive the pairwise relations between vertical neighbors and another set for horizontal neighbors. The proposed DQN considers not only the evidence from the incumbent fragment but also the support from its four neighbors. The DQN is trained using replay experience with carefully designed rewards to guide the search for a sequence of fragment swaps to reach the correct puzzle solution. Two JPwLEG datasets are constructed to evaluate the proposed method, and the experimental results show that the proposed SD2RL significantly outperforms state-of-the-art methods.},
  archive   = {C_AAAI},
  author    = {Xingke Song and Jiahuan Jin and Chenglin Yao and Shihe Wang and Jianfeng Ren and Ruibin Bai},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25325},
  pages     = {2303-2311},
  title     = {Siamese-discriminant deep reinforcement learning for solving jigsaw puzzles with large eroded gaps},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SHUNIT: Style harmonization for unpaired image-to-image
translation. <em>AAAI</em>, 2292–2302. (<a
href="https://doi.org/10.1609/aaai.v37i2.25324">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose a novel solution for unpaired image-to-image (I2I) translation. To translate complex images with a wide range of objects to a different domain, recent approaches often use the object annotations to perform per-class source-to-target style mapping. However, there remains a point for us to exploit in the I2I. An object in each class consists of multiple components, and all the sub-object components have different characteristics. For example, a car in CAR class consists of a car body, tires, windows and head and tail lamps, etc., and they should be handled separately for realistic I2I translation. The simplest solution to the problem will be to use more detailed annotations with sub-object component annotations than the simple object annotations, but it is not possible. The key idea of this paper is to bypass the sub-object component annotations by leveraging the original style of the input image because the original style will include the information about the characteristics of the sub-object components. Specifically, for each pixel, we use not only the per-class style gap between the source and target domains but also the pixel’s original style to determine the target style of a pixel. To this end, we present Style Harmonization for unpaired I2I translation (SHUNIT). Our SHUNIT generates a new style by harmonizing the target domain style retrieved from a class memory and an original source image style. Instead of direct source-to-target style mapping, we aim for source and target styles harmonization. We validate our method with extensive experiments and achieve state-of-the-art performance on the latest benchmark sets. The source code is available online: https://github.com/bluejangbaljang/SHUNIT.},
  archive   = {C_AAAI},
  author    = {Seokbeom Song and Suhyeon Lee and Hongje Seong and Kyoungwon Min and Euntai Kim},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25324},
  pages     = {2292-2302},
  title     = {SHUNIT: Style harmonization for unpaired image-to-image translation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Diversified and realistic 3D augmentation via iterative
construction, random placement, and HPR occlusion. <em>AAAI</em>,
2282–2291. (<a href="https://doi.org/10.1609/aaai.v37i2.25323">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In autonomous driving, data augmentation is commonly used for improving 3D object detection. The most basic methods include insertion of copied objects and rotation and scaling of the entire training frame. Numerous variants have been developed as well. The existing methods, however, are considerably limited when compared to the variety of the real world possibilities. In this work, we develop a diversified and realistic augmentation method that can flexibly construct a whole-body object, freely locate and rotate the object, and apply self-occlusion and external-occlusion accordingly. To improve the diversity of the whole-body object construction, we develop an iterative method that stochastically combines multiple objects observed from the real world into a single object. Unlike the existing augmentation methods, the constructed objects can be randomly located and rotated in the training frame because proper occlusions can be reflected to the whole-body objects in the final step. Finally, proper self-occlusion at each local object level and external-occlusion at the global frame level are applied using the Hidden Point Removal (HPR) algorithm that is computationally efficient. HPR is also used for adaptively controlling the point density of each object according to the object&#39;s distance from the LiDAR. Experiment results show that the proposed DR.CPO algorithm is data-efficient and model-agnostic without incurring any computational overhead. Also, DR.CPO can improve mAP performance by 2.08\% when compared to the best 3D detection result known for KITTI dataset.},
  archive   = {C_AAAI},
  author    = {Jungwook Shin and Jaeill Kim and Kyungeun Lee and Hyunghun Cho and Wonjong Rhee},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25323},
  pages     = {2282-2291},
  title     = {Diversified and realistic 3D augmentation via iterative construction, random placement, and HPR occlusion},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Task-specific scene structure representations.
<em>AAAI</em>, 2272–2281. (<a
href="https://doi.org/10.1609/aaai.v37i2.25322">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Understanding the informative structures of scenes is essential for low-level vision tasks. Unfortunately, it is difficult to obtain a concrete visual definition of the informative structures because influences of visual features are task-specific. In this paper, we propose a single general neural network architecture for extracting task-specific structure guidance for scenes. To do this, we first analyze traditional spectral clustering methods, which computes a set of eigenvectors to model a segmented graph forming small compact structures on image domains. We then unfold the traditional graph-partitioning problem into a learnable network, named Scene Structure Guidance Network (SSGNet), to represent the task-specific informative structures. The SSGNet yields a set of coefficients of eigenvectors that produces explicit feature representations of image structures. In addition, our SSGNet is light-weight (56K parameters), and can be used as a plug-and-play module for off-the-shelf architectures. We optimize the SSGNet without any supervision by proposing two novel training losses that enforce task-specific scene structure generation during training. Our main contribution is to show that such a simple network can achieve state-of-the-art results for several low-level vision applications including joint upsampling and image denoising. We also demonstrate that our SSGNet generalizes well on unseen datasets, compared to existing methods which use structural embedding frameworks. Our source codes are available at https://github.com/jsshin98/SSGNet.},
  archive   = {C_AAAI},
  author    = {Jisu Shin and Seunghyun Shin and Hae-Gon Jeon},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25322},
  pages     = {2272-2281},
  title     = {Task-specific scene structure representations},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FeedFormer: Revisiting transformer decoder for efficient
semantic segmentation. <em>AAAI</em>, 2263–2271. (<a
href="https://doi.org/10.1609/aaai.v37i2.25321">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With the success of Vision Transformer (ViT) in image classification, its variants have yielded great success in many downstream vision tasks. Among those, the semantic segmentation task has also benefited greatly from the advance of ViT variants. However, most studies of the transformer for semantic segmentation only focus on designing efficient transformer encoders, rarely giving attention to designing the decoder. Several studies make attempts in using the transformer decoder as the segmentation decoder with class-wise learnable query. Instead, we aim to directly use the encoder features as the queries. This paper proposes the Feature Enhancing Decoder transFormer (FeedFormer) that enhances structural information using the transformer decoder. Our goal is to decode the high-level encoder features using the lowest-level encoder feature. We do this by formulating high-level features as queries, and the lowest-level feature as the key and value. This enhances the high-level features by collecting the structural information from the lowest-level feature. Additionally, we use a simple reformation trick of pushing the encoder blocks to take the place of the existing self-attention module of the decoder to improve efficiency. We show the superiority of our decoder with various light-weight transformer-based decoders on popular semantic segmentation datasets. Despite the minute computation, our model has achieved state-of-the-art performance in the performance computation trade-off. Our model FeedFormer-B0 surpasses SegFormer-B0 with 1.8\% higher mIoU and 7.1\% less computation on ADE20K, and 1.7\% higher mIoU and 14.4\% less computation on Cityscapes, respectively. Code will be released at: https://github.com/jhshim1995/FeedFormer.},
  archive   = {C_AAAI},
  author    = {Jae-hun Shim and Hyunwoo Yu and Kyeongbo Kong and Suk-Ju Kang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25321},
  pages     = {2263-2271},
  title     = {FeedFormer: Revisiting transformer decoder for efficient semantic segmentation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). YOLOV: Making still image object detectors great at video
object detection. <em>AAAI</em>, 2254–2262. (<a
href="https://doi.org/10.1609/aaai.v37i2.25320">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Video object detection (VID) is challenging because of the high variation of object appearance as well as the diverse deterioration in some frames. On the positive side, the detection in a certain frame of a video, compared with that in a still image, can draw support from other frames. Hence, how to aggregate features across different frames is pivotal to VID problem. Most of existing aggregation algorithms are customized for two-stage detectors. However, these detectors are usually computationally expensive due to their two-stage nature. This work proposes a simple yet effective strategy to address the above concerns, which costs marginal overheads with significant gains in accuracy. Concretely, different from traditional two-stage pipeline, we select important regions after the one-stage detection to avoid processing massive low-quality candidates. Besides, we evaluate the relationship between a target frame and reference frames to guide the aggregation. We conduct extensive experiments and ablation studies to verify the efficacy of our design, and reveal its superiority over other state-of-the-art VID approaches in both effectiveness and efficiency. Our YOLOX-based model can achieve promising performance (e.g., 87.5\% AP50 at over 30 FPS on the ImageNet VID dataset on a single 2080Ti GPU), making it attractive for large-scale or real-time applications. The implementation is simple, we have made the demo codes and models available at https://github.com/YuHengsss/YOLOV.},
  archive   = {C_AAAI},
  author    = {Yuheng Shi and Naiyan Wang and Xiaojie Guo},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25320},
  pages     = {2254-2262},
  title     = {YOLOV: Making still image object detectors great at video object detection},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Memory-oriented structural pruning for efficient image
restoration. <em>AAAI</em>, 2245–2253. (<a
href="https://doi.org/10.1609/aaai.v37i2.25319">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep learning (DL) based methods have significantly pushed forward the state-of-the-art for image restoration (IR) task. Nevertheless, DL-based IR models are highly computation- and memory-intensive. The surging demands for processing higher-resolution images and multi-task paralleling in practical mobile usage further add to their computation and memory burdens. In this paper, we reveal the overlooked memory redundancy of the IR models and propose a Memory-Oriented Structural Pruning (MOSP) method. To properly compress the long-range skip connections (a major source of the memory burden), we introduce a compactor module onto each skip connection to decouple the pruning of the skip connections and the main branch. MOSP progressively prunes the original model layers and the compactors to cut down the peak memory while maintaining high IR quality. Experiments on real image denoising, image super-resolution and low-light image enhancement show that MOSP can yield models with higher memory efficiency while better preserving performance compared with baseline pruning methods.},
  archive   = {C_AAAI},
  author    = {Xiangsheng Shi and Xuefei Ning and Lidong Guo and Tianchen Zhao and Enshu Liu and Yi Cai and Yuhan Dong and Huazhong Yang and Yu Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25319},
  pages     = {2245-2253},
  title     = {Memory-oriented structural pruning for efficient image restoration},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Edge structure learning via low rank residuals for robust
image classification. <em>AAAI</em>, 2236–2244. (<a
href="https://doi.org/10.1609/aaai.v37i2.25318">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Traditional low-rank methods overlook residuals as corruptions, but we discovered that low-rank residuals actually keep image edges together with corrupt components. Therefore, filtering out such structural information could hamper the discriminative details in images, especially in heavy corruptions. In order to address this limitation, this paper proposes a novel method named ESL-LRR, which preserves image edges by finding image projections from low-rank residuals. Specifically, our approach is built in a manifold learning framework where residuals are regarded as another view of image data. Edge preserved image projections are then pursued using a dynamic affinity graph regularization to capture the more accurate similarity between residuals while suppressing the influence of corrupt ones. With this adaptive approach, the proposed method can also find image intrinsic low-rank representation, and much discriminative edge preserved projections. As a result, a new classification strategy is introduced, aligning both modalities to enhance accuracy. Experiments are conducted on several benchmark image datasets, including MNIST, LFW, and COIL100. The results show that the proposed method has clear advantages over compared state-of-the-art (SOTA) methods, such as Low-Rank Embedding (LRE), Low-Rank Preserving Projection via Graph Regularized Reconstruction (LRPP_GRR), and Feature Selective Projection (FSP) with more than 2\% improvement, particularly in corrupted cases.},
  archive   = {C_AAAI},
  author    = {Xiang-Jun Shen and Stanley Ebhohimhen Abhadiomhen and Yang Yang and Zhifeng Liu and Sirui Tian},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25318},
  pages     = {2236-2244},
  title     = {Edge structure learning via low rank residuals for robust image classification},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive dynamic filtering network for image denoising.
<em>AAAI</em>, 2227–2235. (<a
href="https://doi.org/10.1609/aaai.v37i2.25317">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In image denoising networks, feature scaling is widely used to enlarge the receptive field size and reduce computational costs. This practice, however, also leads to the loss of high-frequency information and fails to consider within-scale characteristics. Recently, dynamic convolution has exhibited powerful capabilities in processing high-frequency information (e.g., edges, corners, textures), but previous works lack sufficient spatial contextual information in filter generation. To alleviate these issues, we propose to employ dynamic convolution to improve the learning of high-frequency and multi-scale features. Specifically, we design a spatially enhanced kernel generation (SEKG) module to improve dynamic convolution, enabling the learning of spatial context information with a very low computational complexity. Based on the SEKG module, we propose a dynamic convolution block (DCB) and a multi-scale dynamic convolution block (MDCB). The former enhances the high-frequency information via dynamic convolution and preserves low-frequency information via skip connections. The latter utilizes shared adaptive dynamic kernels and the idea of dilated convolution to achieve efficient multi-scale feature extraction. The proposed multi-dimension feature integration (MFI) mechanism further fuses the multi-scale features, providing precise and contextually enriched feature representations. Finally, we build an efficient denoising network with the proposed DCB and MDCB, named ADFNet. It achieves better performance with low computational complexity on real-world and synthetic Gaussian noisy datasets. The source code is available at https://github.com/it-hao/ADFNet.},
  archive   = {C_AAAI},
  author    = {Hao Shen and Zhong-Qiu Zhao and Wandi Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25317},
  pages     = {2227-2235},
  title     = {Adaptive dynamic filtering network for image denoising},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Channel regeneration: Improving channel utilization for
compact DNNs. <em>AAAI</em>, 2218–2226. (<a
href="https://doi.org/10.1609/aaai.v37i2.25316">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Overparameterized deep neural networks have redundant neurons that do not contribute to the network&#39;s accuracy. In this paper, we introduce a novel channel regeneration technique that reinvigorates these redundant channels by re-initializing its batch normalization scaling factor gamma. This re-initialization of BN gamma promotes regular weight updates during training. Furthermore, we show that channel regeneration encourages the channels to contribute equally to the learned representation and further boosts the generalization accuracy. We apply our technique at regular intervals of the training cycle to improve channel utilization. The solutions proposed in previous works either raise the total computational cost or increase the model complexity. Integrating the proposed channel regeneration technique into the training methodology of efficient architectures requires minimal effort and comes at no additional cost in size or memory. Extensive experiments on several image classification and semantic segmentation benchmarks demonstrate the effectiveness of applying the channel regeneration technique to compact architectures.},
  archive   = {C_AAAI},
  author    = {Ankit Sharma and Hassan Foroosh},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25316},
  pages     = {2218-2226},
  title     = {Channel regeneration: Improving channel utilization for compact DNNs},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). HVTSurv: Hierarchical vision transformer for patient-level
survival prediction from whole slide image. <em>AAAI</em>, 2209–2217.
(<a href="https://doi.org/10.1609/aaai.v37i2.25315">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Survival prediction based on whole slide images (WSIs) is a challenging task for patient-level multiple instance learning (MIL). Due to the vast amount of data for a patient (one or multiple gigapixels WSIs) and the irregularly shaped property of WSI, it is difficult to fully explore spatial, contextual, and hierarchical interaction in the patient-level bag. Many studies adopt random sampling pre-processing strategy and WSI-level aggregation models, which inevitably lose critical prognostic information in the patient-level bag. In this work, we propose a hierarchical vision Transformer framework named HVTSurv, which can encode the local-level relative spatial information, strengthen WSI-level context-aware communication, and establish patient-level hierarchical interaction. Firstly, we design a feature pre-processing strategy, including feature rearrangement and random window masking. Then, we devise three layers to progressively obtain patient-level representation, including a local-level interaction layer adopting Manhattan distance, a WSI-level interaction layer employing spatial shuffle, and a patient-level interaction layer using attention pooling. Moreover, the design of hierarchical network helps the model become more computationally efficient. Finally, we validate HVTSurv with 3,104 patients and 3,752 WSIs across 6 cancer types from The Cancer Genome Atlas (TCGA). The average C-Index is 2.50-11.30\% higher than all the prior weakly supervised methods over 6 TCGA datasets. Ablation study and attention visualization further verify the superiority of the proposed HVTSurv. Implementation is available at: https://github.com/szc19990412/HVTSurv.},
  archive   = {C_AAAI},
  author    = {Zhuchen Shao and Yang Chen and Hao Bian and Jian Zhang and Guojun Liu and Yongbing Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25315},
  pages     = {2209-2217},
  title     = {HVTSurv: Hierarchical vision transformer for patient-level survival prediction from whole slide image},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). JR2Net: Joint monocular 3D face reconstruction and
reenactment. <em>AAAI</em>, 2200–2208. (<a
href="https://doi.org/10.1609/aaai.v37i2.25314">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Face reenactment and reconstruction benefit various applications in self-media, VR, etc. Recent face reenactment methods use 2D facial landmarks to implicitly retarget facial expressions and poses from driving videos to source images, while they suffer from pose and expression preservation issues for cross-identity scenarios, i.e., when the source and the driving subjects are different. Current self-supervised face reconstruction methods also demonstrate impressive results. However, these methods do not handle large expressions well, since their training data lacks samples of large expressions, and 2D facial attributes are inaccurate on such samples. To mitigate the above problems, we propose to explore the inner connection between the two tasks, i.e., using face reconstruction to provide sufficient 3D information for reenactment, and synthesizing videos paired with captured face model parameters through face reenactment to enhance the expression module of face reconstruction. In particular, we propose a novel cascade framework named JR2Net for Joint Face Reconstruction and Reenactment, which begins with the training of a coarse reconstruction network, followed by a 3D-aware face reenactment network based on the coarse reconstruction results. In the end, we train an expression tracking network based on our synthesized videos composed by image-face model parameter pairs. Such an expression tracking network can further enhance the coarse face reconstruction. Extensive experiments show that our JR2Net outperforms the state-of-the-art methods on several face reconstruction and reenactment benchmarks.},
  archive   = {C_AAAI},
  author    = {Jiaxiang Shang and Yu Zeng and Xin Qiao and Xin Wang and Runze Zhang and Guangyuan Sun and Vishal Patel and Hongbo Fu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25314},
  pages     = {2200-2208},
  title     = {JR2Net: Joint monocular 3D face reconstruction and reenactment},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MIDMs: Matching interleaved diffusion models for
exemplar-based image translation. <em>AAAI</em>, 2191–2199. (<a
href="https://doi.org/10.1609/aaai.v37i2.25313">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present a novel method for exemplar-based image translation, called matching interleaved diffusion models (MIDMs). Most existing methods for this task were formulated as GAN-based matching-then-generation framework. However, in this framework, matching errors induced by the difficulty of semantic matching across cross-domain, e.g., sketch and photo, can be easily propagated to the generation step, which in turn leads to the degenerated results. Motivated by the recent success of diffusion models, overcoming the shortcomings of GANs, we incorporate the diffusion models to overcome these limitations. Specifically, we formulate a diffusion-based matching-and-generation framework that interleaves cross-domain matching and diffusion steps in the latent space by iteratively feeding the intermediate warp into the noising process and denoising it to generate a translated image. In addition, to improve the reliability of diffusion process, we design confidence-aware process using cycle-consistency to consider only confident regions during translation. Experimental results show that our MIDMs generate more plausible images than state-of-the-art methods.},
  archive   = {C_AAAI},
  author    = {Junyoung Seo and Gyuseong Lee and Seokju Cho and Jiyoung Lee and Seungryong Kim},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25313},
  pages     = {2191-2199},
  title     = {MIDMs: Matching interleaved diffusion models for exemplar-based image translation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Domain generalised faster r-CNN. <em>AAAI</em>, 2180–2190.
(<a href="https://doi.org/10.1609/aaai.v37i2.25312">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Domain generalisation (i.e. out-of-distribution generalisation) is an open problem in machine learning, where the goal is to train a model via one or more source domains, that will generalise well to unknown target domains. While the topic is attracting increasing interest, it has not been studied in detail in the context of object detection. The established approaches all operate under the covariate shift assumption, where the conditional distributions are assumed to be approximately equal across source domains. This is the first paper to address domain generalisation in the context of object detection, with a rigorous mathematical analysis of domain shift, without the covariate shift assumption. We focus on improving the generalisation ability of object detection by proposing new regularisation terms to address the domain shift that arises due to both classification and bounding box regression. Also, we include an additional consistency regularisation term to align the local and global level predictions. The proposed approach is implemented as a Domain Generalised Faster R-CNN and evaluated using four object detection datasets which provide domain metadata (GWHD, Cityscapes, BDD100K, Sim10K) where it exhibits a consistent performance improvement over the baselines. All the codes for replicating the results in this paper can be found at https://github.com/karthikiitm87/domain-generalisation.git},
  archive   = {C_AAAI},
  author    = {Karthik Seemakurthy and Charles Fox and Erchan Aptoula and Petra Bosilj},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25312},
  pages     = {2180-2190},
  title     = {Domain generalised faster R-CNN},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MAGIC: Mask-guided image synthesis by inverting a
quasi-robust classifier. <em>AAAI</em>, 2172–2179. (<a
href="https://doi.org/10.1609/aaai.v37i2.25311">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We offer a method for one-shot mask-guided image synthesis that allows controlling manipulations of a single image by inverting a quasi-robust classifier equipped with strong regularizers. Our proposed method, entitled MAGIC, leverages structured gradients from a pre-trained quasi-robust classifier to better preserve the input semantics while preserving its classification accuracy, thereby guaranteeing credibility in the synthesis. Unlike current methods that use complex primitives to supervise the process or use attention maps as a weak supervisory signal, MAGIC aggregates gradients over the input, driven by a guide binary mask that enforces a strong, spatial prior. MAGIC implements a series of manipulations with a single framework achieving shape and location control, intense non-rigid shape deformations, and copy/move operations in the presence of repeating objects and gives users firm control over the synthesis by requiring to simply specify binary guide masks. Our study and findings are supported by various qualitative comparisons with the state-of-the-art on the same images sampled from ImageNet and quantitative analysis using machine perception along with a user survey of 100+ participants that endorse our synthesis quality.},
  archive   = {C_AAAI},
  author    = {Mozhdeh Rouhsedaghat and Masoud Monajatipoor and C.-C. Jay Kuo and Iacopo Masi},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25311},
  pages     = {2172-2179},
  title     = {MAGIC: Mask-guided image synthesis by inverting a quasi-robust classifier},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Two heads are better than one: Image-point cloud network for
depth-based 3D hand pose estimation. <em>AAAI</em>, 2163–2171. (<a
href="https://doi.org/10.1609/aaai.v37i2.25310">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Depth images and point clouds are the two most commonly used data representations for depth-based 3D hand pose estimation. Benefiting from the structuring of image data and the inherent inductive biases of the 2D Convolutional Neural Network (CNN), image-based methods are highly efficient and effective. However, treating the depth data as a 2D image inevitably ignores the 3D nature of depth data. Point cloud-based methods can better mine the 3D geometric structure of depth data. However, these methods suffer from the disorder and non-structure of point cloud data, which is computationally inefficient. In this paper, we propose an Image-Point cloud Network (IPNet) for accurate and robust 3D hand pose estimation. IPNet utilizes 2D CNN to extract visual representations in 2D image space and performs iterative correction in 3D point cloud space to exploit the 3D geometry information of depth data. In particular, we propose a sparse anchor-based &quot;aggregation-interaction-propagation&#39;&#39; paradigm to enhance point cloud features and refine the hand pose, which reduces irregular data access. Furthermore, we introduce a 3D hand model to the iterative correction process, which significantly improves the robustness of IPNet to occlusion and depth holes. Experiments show that IPNet outperforms state-of-the-art methods on three challenging hand datasets.},
  archive   = {C_AAAI},
  author    = {Pengfei Ren and Yuchen Chen and Jiachang Hao and Haifeng Sun and Qi Qi and Jingyu Wang and Jianxin Liao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25310},
  pages     = {2163-2171},
  title     = {Two heads are better than one: Image-point cloud network for depth-based 3D hand pose estimation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Mean-shifted contrastive loss for anomaly detection.
<em>AAAI</em>, 2155–2162. (<a
href="https://doi.org/10.1609/aaai.v37i2.25309">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep anomaly detection methods learn representations that separate between normal and anomalous images. Although self-supervised representation learning is commonly used, small dataset sizes limit its effectiveness. It was previously shown that utilizing external, generic datasets (e.g. ImageNet classification) can significantly improve anomaly detection performance. One approach is outlier exposure, which fails when the external datasets do not resemble the anomalies. We take the approach of transferring representations pre-trained on external datasets for anomaly detection. Anomaly detection performance can be significantly improved by fine-tuning the pre-trained representations on the normal training images. In this paper, we first demonstrate and analyze that contrastive learning, the most popular self-supervised learning paradigm cannot be naively applied to pre-trained features. The reason is that pre-trained feature initialization causes poor conditioning for standard contrastive objectives, resulting in bad optimization dynamics. Based on our analysis, we provide a modified contrastive objective, the Mean-Shifted Contrastive Loss. Our method is highly effective and achieves a new state-of-the-art anomaly detection performance including 98.6\% ROC-AUC on the CIFAR-10 dataset.},
  archive   = {C_AAAI},
  author    = {Tal Reiss and Yedid Hoshen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25309},
  pages     = {2155-2162},
  title     = {Mean-shifted contrastive loss for anomaly detection},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Action-conditioned generation of bimanual object
manipulation sequences. <em>AAAI</em>, 2146–2154. (<a
href="https://doi.org/10.1609/aaai.v37i2.25308">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The generation of bimanual object manipulation sequences given a semantic action label has broad applications in collaborative robots or augmented reality. This relatively new problem differs from existing works that generate whole-body motions without any object interaction as it now requires the model to additionally learn the spatio-temporal relationship that exists between the human joints and object motion given said label. To tackle this task, we leverage the varying degree each muscle or joint is involved during object manipulation. For instance, the wrists act as the prime movers for the objects while the finger joints are angled to provide a firm grip. The remaining body joints are the least involved in that they are positioned as naturally and comfortably as possible. We thus design an architecture that comprises 3 main components: (i) a graph recurrent network that generates the wrist and object motion, (ii) an attention-based recurrent network that estimates the required finger joint angles given the graph configuration, and (iii) a recurrent network that reconstructs the body pose given the locations of the wrist. We evaluate our approach on the KIT Motion Capture and KIT RGBD Bimanual Manipulation datasets and show improvements over a simplified approach that treats the entire body as a single entity, and existing whole-body-only methods.},
  archive   = {C_AAAI},
  author    = {Haziq Razali and Yiannis Demiris},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25308},
  pages     = {2146-2154},
  title     = {Action-conditioned generation of bimanual object manipulation sequences},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A learnable radial basis positional embedding for
coordinate-MLPs. <em>AAAI</em>, 2137–2145. (<a
href="https://doi.org/10.1609/aaai.v37i2.25307">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose a novel method to enhance the performance of coordinate-MLPs (also referred to as neural fields) by learning instance-specific positional embeddings. End-to-end optimization of positional embedding parameters along with network weights leads to poor generalization performance. Instead, we develop a generic framework to learn the positional embedding based on the classic graph-Laplacian regularization, which can implicitly balance the trade-off between memorization and generalization. This framework is then used to propose a novel positional embedding scheme, where the hyperparameters are learned per coordinate (i.e instance) to deliver optimal performance. We show that the proposed embedding achieves better performance with higher stability compared to the well-established random Fourier features (RFF). Further, we demonstrate that the proposed embedding scheme yields stable gradients, enabling seamless integration into deep architectures as intermediate layers.},
  archive   = {C_AAAI},
  author    = {Sameera Ramasinghe and Simon Lucey},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25307},
  pages     = {2137-2145},
  title     = {A learnable radial basis positional embedding for coordinate-MLPs},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unsupervised deep learning for phase retrieval via
teacher-student distillation. <em>AAAI</em>, 2128–2136. (<a
href="https://doi.org/10.1609/aaai.v37i2.25306">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Phase retrieval (PR) is a challenging nonlinear inverse problem in scientific imaging that involves reconstructing the phase of a signal from its intensity measurements. Recently, there has been an increasing interest in deep learning-based PR. Motivated by the challenge of collecting ground-truth (GT) images in many domains, this paper proposes a fully-unsupervised learning approach for PR, which trains an end-to-end deep model via a GT-free teacher-student online distillation framework. Specifically, a teacher model is trained using a self-expressive loss with noise resistance, while a student model is trained with a consistency loss on augmented data to exploit the teacher&#39;s dark knowledge. Additionally, we develop an enhanced unfolding network for both the teacher and student models. Extensive experiments show that our proposed approach outperforms existing unsupervised PR methods with higher computational efficiency and performs competitively against supervised methods.},
  archive   = {C_AAAI},
  author    = {Yuhui Quan and Zhile Chen and Tongyao Pang and Hui Ji},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25306},
  pages     = {2128-2136},
  title     = {Unsupervised deep learning for phase retrieval via teacher-student distillation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploring stroke-level modifications for scene text editing.
<em>AAAI</em>, 2119–2127. (<a
href="https://doi.org/10.1609/aaai.v37i2.25305">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Scene text editing (STE) aims to replace text with the desired one while preserving background and styles of the original text. However, due to the complicated background textures and various text styles, existing methods fall short in generating clear and legible edited text images. In this study, we attribute the poor editing performance to two problems: 1) Implicit decoupling structure. Previous methods of editing the whole image have to learn different translation rules of background and text regions simultaneously. 2) Domain gap. Due to the lack of edited real scene text images, the network can only be well trained on synthetic pairs and performs poorly on real-world images. To handle the above problems, we propose a novel network by MOdifying Scene Text image at strokE Level (MOSTEL). Firstly, we generate stroke guidance maps to explicitly indicate regions to be edited. Different from the implicit one by directly modifying all the pixels at image level, such explicit instructions filter out the distractions from background and guide the network to focus on editing rules of text regions. Secondly, we propose a Semi-supervised Hybrid Learning to train the network with both labeled synthetic images and unpaired real scene text images. Thus, the STE model is adapted to real-world datasets distributions. Moreover, two new datasets (Tamper-Syn2k and Tamper-Scene) are proposed to fill the blank of public evaluation datasets. Extensive experiments demonstrate that our MOSTEL outperforms previous methods both qualitatively and quantitatively. Datasets and code will be available at https://github.com/qqqyd/MOSTEL.},
  archive   = {C_AAAI},
  author    = {Yadong Qu and Qingfeng Tan and Hongtao Xie and Jianjun Xu and YuXin Wang and Yongdong Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25305},
  pages     = {2119-2127},
  title     = {Exploring stroke-level modifications for scene text editing},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exposing the self-supervised space-time correspondence
learning via graph kernels. <em>AAAI</em>, 2110–2118. (<a
href="https://doi.org/10.1609/aaai.v37i2.25304">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Self-supervised space-time correspondence learning is emerging as a promising way of leveraging unlabeled video. Currently, most methods adapt contrastive learning with mining negative samples or reconstruction adapted from the image domain, which requires dense affinity across multiple frames or optical flow constraints. Moreover, video correspondence predictive models require mining more inherent properties in videos, such as structural information. In this work, we propose the VideoHiGraph, a space-time correspondence framework based on a learnable graph kernel. Concerning the video as the spatial-temporal graph, the learning objectives of VideoHiGraph are emanated in a self-supervised manner for predicting unobserved hidden graphs via graph kernel manner. We learn a representation of the temporal coherence across frames in which pairwise similarity defines the structured hidden graph, such that a biased random walk graph kernel along the sub-graph can predict long-range correspondence. Then, we learn a refined representation across frames on the node-level via a dense graph kernel. The self-supervision of the model training is formed by the structural and temporal consistency of the graph. VideoHiGraph achieves superior performance and demonstrates its robustness across the benchmark of label propagation tasks involving objects, semantic parts, keypoints, and instances. Our algorithm implementations have been made publicly available at https://github.com/zyqin19/VideoHiGraph.},
  archive   = {C_AAAI},
  author    = {Zheyun Qin and Xiankai Lu and Xiushan Nie and Yilong Yin and Jianbing Shen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25304},
  pages     = {2110-2118},
  title     = {Exposing the self-supervised space-time correspondence learning via graph kernels},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FoPro: Few-shot guided robust webly-supervised prototypical
learning. <em>AAAI</em>, 2101–2109. (<a
href="https://doi.org/10.1609/aaai.v37i2.25303">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, webly supervised learning (WSL) has been studied to leverage numerous and accessible data from the Internet. Most existing methods focus on learning noise-robust models from web images while neglecting the performance drop caused by the differences between web domain and real-world domain. However, only by tackling the performance gap above can we fully exploit the practical value of web datasets. To this end, we propose a Few-shot guided Prototypical (FoPro) representation learning method, which only needs a few labeled examples from reality and can significantly improve the performance in the real-world domain. Specifically, we initialize each class center with few-shot real-world data as the ``realistic&quot; prototype. Then, the intra-class distance between web instances and ``realistic&quot; prototypes is narrowed by contrastive learning. Finally, we measure image-prototype distance with a learnable metric. Prototypes are polished by adjacent high-quality web images and involved in removing distant out-of-distribution samples. In experiments, FoPro is trained on web datasets with a few real-world examples guided and evaluated on real-world datasets. Our method achieves the state-of-the-art performance on three fine-grained datasets and two large-scale datasets. Compared with existing WSL methods under the same few-shot settings, FoPro still excels in real-world generalization. Code is available at https://github.com/yuleiqin/fopro.},
  archive   = {C_AAAI},
  author    = {Yulei Qin and Xingyu Chen and Chao Chen and Yunhang Shen and Bo Ren and Yun Gu and Jie Yang and Chunhua Shen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25303},
  pages     = {2101-2109},
  title     = {FoPro: Few-shot guided robust webly-supervised prototypical learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Data-efficient image quality assessment with attention-panel
decoder. <em>AAAI</em>, 2091–2100. (<a
href="https://doi.org/10.1609/aaai.v37i2.25302">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Blind Image Quality Assessment (BIQA) is a fundamental task in computer vision, which however remains unresolved due to the complex distortion conditions and diversified image contents. To confront this challenge, we in this paper propose a novel BIQA pipeline based on the Transformer architecture, which achieves an efficient quality-aware feature representation with much fewer data. More specifically, we consider the traditional fine-tuning in BIQA as an interpretation of the pre-trained model. In this way, we further introduce a Transformer decoder to refine the perceptual information of the CLS token from different perspectives. This enables our model to establish the quality-aware feature manifold efficiently while attaining a strong generalization capability. Meanwhile, inspired by the subjective evaluation behaviors of human, we introduce a novel attention panel mechanism, which improves the model performance and reduces the prediction uncertainty simultaneously. The proposed BIQA method maintains a light-weight design with only one layer of the decoder, yet extensive experiments on eight standard BIQA datasets (both synthetic and authentic) demonstrate its superior performance to the state-of-the-art BIQA methods, i.e., achieving the SRCC values of 0.875 (vs. 0.859 in LIVEC) and 0.980 (vs. 0.969 in LIVE). Checkpoints, logs and code will be available at https://github.com/narthchin/DEIQT.},
  archive   = {C_AAAI},
  author    = {Guanyi Qin and Runze Hu and Yutao Liu and Xiawu Zheng and Haotian Liu and Xiu Li and Yan Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25302},
  pages     = {2091-2100},
  title     = {Data-efficient image quality assessment with attention-panel decoder},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Context-aware transformer for 3D point cloud automatic
annotation. <em>AAAI</em>, 2082–2090. (<a
href="https://doi.org/10.1609/aaai.v37i2.25301">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {3D automatic annotation has received increased attention since manually annotating 3D point clouds is laborious. However, existing methods are usually complicated, e.g., pipelined training for 3D foreground/background segmentation, cylindrical object proposals, and point completion. Furthermore, they often overlook the inter-object feature correlation that is particularly informative to hard samples for 3D annotation. To this end, we propose a simple yet effective end-to-end Context-Aware Transformer (CAT) as an automated 3D-box labeler to generate precise 3D box annotations from 2D boxes, trained with a small number of human annotations. We adopt the general encoder-decoder architecture, where the CAT encoder consists of an intra-object encoder (local) and an inter-object encoder (global), performing self-attention along the sequence and batch dimensions, respectively. The former models intra-object interactions among points and the latter extracts feature relations among different objects, thus boosting scene-level understanding. Via local and global encoders, CAT can generate high-quality 3D box annotations with a streamlined workflow, allowing it to outperform existing state-of-the-arts by up to 1.79\% 3D AP on the hard task of the KITTI test set.},
  archive   = {C_AAAI},
  author    = {Xiaoyan Qian and Chang Liu and Xiaojuan Qi and Siew-Chong Tan and Edmund Lam and Ngai Wong},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25301},
  pages     = {2082-2090},
  title     = {Context-aware transformer for 3D point cloud automatic annotation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploring stochastic autoregressive image modeling for
visual representation. <em>AAAI</em>, 2074–2081. (<a
href="https://doi.org/10.1609/aaai.v37i2.25300">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Autoregressive language modeling (ALM) has been successfully used in self-supervised pre-training in Natural language processing (NLP). However, this paradigm has not achieved comparable results with other self-supervised approaches in computer vision (e.g., contrastive learning, masked image modeling). In this paper, we try to find the reason why autoregressive modeling does not work well on vision tasks. To tackle this problem, we fully analyze the limitation of visual autoregressive methods and proposed a novel stochastic autoregressive image modeling (named SAIM) by the two simple designs. First, we serialize the image into patches. Second, we employ the stochastic permutation strategy to generate an effective and robust image context which is critical for vision tasks. To realize this task, we create a parallel encoder-decoder training process in which the encoder serves a similar role to the standard vision transformer focusing on learning the whole contextual information, and meanwhile the decoder predicts the content of the current position so that the encoder and decoder can reinforce each other. Our method significantly improves the performance of autoregressive image modeling and achieves the best accuracy (83.9\%) on the vanilla ViT-Base model among methods using only ImageNet-1K data. Transfer performance in downstream tasks also shows that our model achieves competitive performance. Code is available at https://github.com/qiy20/SAIM.},
  archive   = {C_AAAI},
  author    = {Yu Qi and Fan Yang and Yousong Zhu and Yufei Liu and Liwei Wu and Rui Zhao and Wei Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25300},
  pages     = {2074-2081},
  title     = {Exploring stochastic autoregressive image modeling for visual representation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CSTAR: Towards compact and structured deep neural networks
with adversarial robustness. <em>AAAI</em>, 2065–2073. (<a
href="https://doi.org/10.1609/aaai.v37i2.25299">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Model compression and model defense for deep neural networks (DNNs) have been extensively and individually studied. Considering the co-importance of model compactness and robustness in practical applications, several prior works have explored to improve the adversarial robustness of the sparse neural networks. However, the structured sparse models obtained by the existing works suffer severe performance degradation for both benign and robust accuracy, thereby causing a challenging dilemma between robustness and structuredness of compact DNNs. To address this problem, in this paper, we propose CSTAR, an efficient solution that simultaneously impose Compactness, high STructuredness and high Adversarial Robustness on the target DNN models. By formulating the structuredness and robustness requirement within the same framework, the compressed DNNs can simultaneously achieve high compression performance and strong adversarial robustness. Evaluations for various DNN models on different datasets demonstrate the effectiveness of CSTAR. Compared with the state-of-the-art robust structured pruning, CSTAR shows consistently better performance. For instance, when compressing ResNet-18 on CIFAR-10, CSTAR achieves up to 20.07\% and 11.91\% improvement for benign accuracy and robust accuracy, respectively. For compressing ResNet-18 with 16x compression ratio on Imagenet, CSTAR obtains 8.58\% benign accuracy gain and 4.27\% robust accuracy gain compared to the existing robust structured pruning.},
  archive   = {C_AAAI},
  author    = {Huy Phan and Miao Yin and Yang Sui and Bo Yuan and Saman Zonouz},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25299},
  pages     = {2065-2073},
  title     = {CSTAR: Towards compact and structured deep neural networks with adversarial robustness},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Better and faster: Adaptive event conversion for event-based
object detection. <em>AAAI</em>, 2056–2064. (<a
href="https://doi.org/10.1609/aaai.v37i2.25298">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Event cameras are a kind of bio-inspired imaging sensor, which asynchronously collect sparse event streams with many advantages. In this paper, we focus on building better and faster event-based object detectors. To this end, we first propose a computationally efficient event representation Hyper Histogram, which adequately preserves both the polarity and temporal information of events. Then we devise an Adaptive Event Conversion module, which converts events into Hyper Histograms according to event density via an adaptive queue. Moreover, we introduce a novel event-based augmentation method Shadow Mosaic, which significantly improves the event sample diversity and enhances the generalization ability of detection models. We equip our proposed modules on three representative object detection models: YOLOv5, Deformable-DETR, and RetinaNet. Experimental results on three event-based detection datasets (1Mpx, Gen1, and MVSEC-NIGHTL21) demonstrate that our proposed approach outperforms other state-of-the-art methods by a large margin, while achieving a much faster running speed (&lt; 14 ms and &lt; 4 ms for 50 ms event data on the 1Mpx and Gen1 datasets).},
  archive   = {C_AAAI},
  author    = {Yansong Peng and Yueyi Zhang and Peilin Xiao and Xiaoyan Sun and Feng Wu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25298},
  pages     = {2056-2064},
  title     = {Better and faster: Adaptive event conversion for event-based object detection},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CL3D: Unsupervised domain adaptation for cross-LiDAR 3D
detection. <em>AAAI</em>, 2047–2055. (<a
href="https://doi.org/10.1609/aaai.v37i2.25297">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Domain adaptation for Cross-LiDAR 3D detection is challenging due to the large gap on the raw data representation with disparate point densities and point arrangements. By exploring domain-invariant 3D geometric characteristics and motion patterns, we present an unsupervised domain adaptation method that overcomes above difficulties. First, we propose the Spatial Geometry Alignment module to extract similar 3D shape geometric features of the same object class to align two domains, while eliminating the effect of distinct point distributions. Second, we present Temporal Motion Alignment module to utilize motion features in sequential frames of data to match two domains. Prototypes generated from two modules are incorporated into the pseudo-label reweighting procedure and contribute to our effective self-training framework for the target domain. Extensive experiments show that our method achieves state-of-the-art performance on cross-device datasets, especially for the datasets with large gaps captured by mechanical scanning LiDARs and solid-state LiDARs in various scenes. Project homepage is at https://github.com/4DVLab/CL3D.git.},
  archive   = {C_AAAI},
  author    = {Xidong Peng and Xinge Zhu and Yuexin Ma},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25297},
  pages     = {2047-2055},
  title     = {CL3D: Unsupervised domain adaptation for cross-LiDAR 3D detection},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient end-to-end video question answering with pyramidal
multimodal transformer. <em>AAAI</em>, 2038–2046. (<a
href="https://doi.org/10.1609/aaai.v37i2.25296">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper presents a new method for end-to-end Video Question Answering (VideoQA), aside from the current popularity of using large-scale pre-training with huge feature extractors. We achieve this with a pyramidal multimodal transformer (PMT) model, which simply incorporates a learnable word embedding layer, a few convolutional and transformer layers. We use the anisotropic pyramid to fulfill video-language interactions across different spatio-temporal scales. In addition to the canonical pyramid, which includes both bottom-up and top-down pathways with lateral connections, novel strategies are proposed to decompose the visual feature stream into spatial and temporal sub-streams at different scales and implement their interactions with the linguistic semantics while preserving the integrity of local and global semantics. We demonstrate better or on-par performances with high computational efficiency against state-of-the-art methods on five VideoQA benchmarks. Our ablation study shows the scalability of our model that achieves competitive results for text-to-video retrieval by leveraging feature extractors with reusable pre-trained weights, and also the effectiveness of the pyramid. Code available at: https://github.com/Trunpm/PMT-AAAI23.},
  archive   = {C_AAAI},
  author    = {Min Peng and Chongyang Wang and Yu Shi and Xiang-Dong Zhou},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25296},
  pages     = {2038-2046},
  title     = {Efficient end-to-end video question answering with pyramidal multimodal transformer},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PDRF: Progressively deblurring radiance field for fast scene
reconstruction from blurry images. <em>AAAI</em>, 2029–2037. (<a
href="https://doi.org/10.1609/aaai.v37i2.25295">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present Progressively Deblurring Radiance Field (PDRF), a novel approach to efficiently reconstruct high quality radiance fields from blurry images. While current State-of-The-Art (SoTA) scene reconstruction methods achieve photo-realistic renderings from clean source views, their performances suffer when the source views are affected by blur, which is commonly observed in the wild. Previous deblurring methods either do not account for 3D geometry, or are computationally intense. To addresses these issues, PDRF uses a progressively deblurring scheme for radiance field modeling, which can accurately model blur with 3D scene context. PDRF further uses an efficient importance sampling scheme that results in fast scene optimization. We perform extensive experiments and show that PDRF is 15X faster than previous SoTA while achieving better performance on both synthetic and real scenes.},
  archive   = {C_AAAI},
  author    = {Cheng Peng and Rama Chellappa},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25295},
  pages     = {2029-2037},
  title     = {PDRF: Progressively deblurring radiance field for fast scene reconstruction from blurry images},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Domain decorrelation with potential energy ranking.
<em>AAAI</em>, 2020–2028. (<a
href="https://doi.org/10.1609/aaai.v37i2.25294">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Machine learning systems, especially the methods based on deep learning, enjoy great success in modern computer vision tasks under ideal experimental settings. Generally, these classic deep learning methods are built on the i.i.d. assumption, supposing the training and test data are drawn from the same distribution independently and identically. However, the aforementioned i.i.d. assumption is, in general, unavailable in the real-world scenarios, and as a result, leads to sharp performance decay of deep learning algorithms. Behind this, domain shift is one of the primary factors to be blamed. In order to tackle this problem, we propose using Potential Energy Ranking (PoER) to decouple the object feature and the domain feature in given images, promoting the learning of label-discriminative representations while filtering out the irrelevant correlations between the objects and the background. PoER employs the ranking loss in shallow layers to make features with identical category and domain labels close to each other and vice versa. This makes the neural networks aware of both objects and background characteristics, which is vital for generating domain-invariant features. Subsequently, with the stacked convolutional blocks, PoER further uses the contrastive loss to make features within the same categories distribute densely no matter domains, filtering out the domain information progressively for feature alignment. PoER reports superior performance on domain generalization benchmarks, improving the average top-1 accuracy by at least 1.20\% compared to the existing methods. Moreover, we use PoER in the ECCV 2022 NICO Challenge, achieving top place with only a vanilla ResNet-18 and winning the jury award. The code has been made publicly available at: https://github.com/ForeverPs/PoER.},
  archive   = {C_AAAI},
  author    = {Sen Pei and Jiaxi Sun and Richard Yi Da Xu and Shiming Xiang and Gaofeng Meng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25294},
  pages     = {2020-2028},
  title     = {Domain decorrelation with potential energy ranking},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Find beauty in the rare: Contrastive composition feature
clustering for nontrivial cropping box regression. <em>AAAI</em>,
2011–2019. (<a href="https://doi.org/10.1609/aaai.v37i2.25293">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Automatic image cropping algorithms aim to recompose images like human-being photographers by generating the cropping boxes with improved composition quality. Cropping box regression approaches learn the beauty of composition from annotated cropping boxes. However, the bias of annotations leads to quasi-trivial recomposing results, which has an obvious tendency to the average location of training samples. The crux of this predicament is that the task is naively treated as a box regression problem, where rare samples might be dominated by normal samples, and the composition patterns of rare samples are not well exploited. Observing that similar composition patterns tend to be shared by the cropping boundaries annotated nearly, we argue to find the beauty of composition from the rare samples by clustering the samples with similar cropping boundary annotations, i.e., similar composition patterns. We propose a novel Contrastive Composition Clustering (C2C) to regularize the composition features by contrasting dynamically established similar and dissimilar pairs. In this way, common composition patterns of multiple images can be better summarized, which especially benefits the rare samples and endows our model with better generalizability to render nontrivial results. Extensive experimental results show the superiority of our model compared with prior arts. We also illustrate the philosophy of our design with an interesting analytical visualization.},
  archive   = {C_AAAI},
  author    = {Zhiyu Pan and Yinpeng Chen and Jiale Zhang and Hao Lu and Zhiguo Cao and Weicai Zhong},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25293},
  pages     = {2011-2019},
  title     = {Find beauty in the rare: Contrastive composition feature clustering for nontrivial cropping box regression},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Coarse2Fine: Local consistency aware re-prediction for
weakly supervised object localization. <em>AAAI</em>, 2002–2010. (<a
href="https://doi.org/10.1609/aaai.v37i2.25292">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Weakly supervised object localization aims to localize objects of interest by using only image-level labels. Existing methods generally segment activation map by threshold to obtain mask and generate bounding box. However, the activation map is locally inconsistent, i.e., similar neighboring pixels of the same object are not equally activated, which leads to the blurred boundary issue: the localization result is sensitive to the threshold, and the mask obtained directly from the activation map loses the fine contours of the object, making it difficult to obtain a tight bounding box. In this paper, we introduce the Local Consistency Aware Re-prediction (LCAR) framework, which aims to recover the complete fine object mask from locally inconsistent activation map and hence obtain a tight bounding box. To this end, we propose the self-guided re-prediction module (SGRM), which employs a novel superpixel aggregation network to replace the post-processing of threshold segmentation. In order to derive more reliable pseudo label from the activation map to supervise the SGRM, we further design an affinity refinement module (ARM) that utilizes the original image feature to better align the activation map with the image appearance, and design a self-distillation CAM (SD-CAM) to alleviate the locator dependence on saliency. Experiments demonstrate that our LCAR outperforms the state-of-the-art on both the CUB-200-2011 and ILSVRC datasets, achieving 95.89\% and 70.72\% of GT-Know localization accuracy, respectively.},
  archive   = {C_AAAI},
  author    = {Yixuan Pan and Yao Yao and Yichao Cao and Chongjin Chen and Xiaobo Lu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25292},
  pages     = {2002-2010},
  title     = {Coarse2Fine: Local consistency aware re-prediction for weakly supervised object localization},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust image denoising of no-flash images guided by
consistent flash images. <em>AAAI</em>, 1993–2001. (<a
href="https://doi.org/10.1609/aaai.v37i2.25291">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Images taken in low light conditions typically contain distracting noise, and eliminating such noise is a crucial computer vision problem. Additional photos captured with a camera flash can guide an image denoiser to preserve edges since the flash images often contain fine details with reduced noise. Nonetheless, a denoiser can be misled by inconsistent flash images, which have image structures (e.g., edges) that do not exist in no-flash images. Unfortunately, this disparity frequently occurs as the flash/no-flash pairs are taken in different light conditions. We propose a learning-based technique that robustly fuses the image pairs while considering their inconsistency. Our framework infers consistent flash image patches locally, which have similar image structures with the ground truth, and denoises no-flash images using the inferred ones via a combination model. We demonstrate that our technique can produce more robust results than state-of-the-art methods, given various flash/no-flash pairs with inconsistent image structures. The source code is available at https://github.com/CGLab-GIST/RIDFnF.},
  archive   = {C_AAAI},
  author    = {Geunwoo Oh and Jonghee Back and Jae-Pil Heo and Bochang Moon},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25291},
  pages     = {1993-2001},
  title     = {Robust image denoising of no-flash images guided by consistent flash images},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Universe points representation learning for partial
multi-graph matching. <em>AAAI</em>, 1984–1992. (<a
href="https://doi.org/10.1609/aaai.v37i2.25290">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Many challenges from natural world can be formulated as a graph matching problem. Previous deep learning-based methods mainly consider a full two-graph matching setting. In this work, we study the more general partial matching problem with multi-graph cycle consistency guarantees. Building on a recent progress in deep learning on graphs, we propose a novel data-driven method (URL) for partial multi-graph matching, which uses an object-to-universe formulation and learns latent representations of abstract universe points. The proposed approach advances the state of the art in semantic keypoint matching problem, evaluated on Pascal VOC, CUB, and Willow datasets. Moreover, the set of controlled experiments on a synthetic graph matching dataset demonstrates the scalability of our method to graphs with large number of nodes and its robustness to high partiality.},
  archive   = {C_AAAI},
  author    = {Zhakshylyk Nurlanov and Frank R. Schmidt and Florian Bernard},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25290},
  pages     = {1984-1992},
  title     = {Universe points representation learning for partial multi-graph matching},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MIMO is all you need：a strong multi-in-multi-out baseline
for video prediction. <em>AAAI</em>, 1975–1983. (<a
href="https://doi.org/10.1609/aaai.v37i2.25289">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The mainstream of the existing approaches for video prediction builds up their models based on a Single-In-Single-Out (SISO) architecture, which takes the current frame as input to predict the next frame in a recursive manner. This way often leads to severe performance degradation when they try to extrapolate a longer period of future, thus limiting the practical use of the prediction model. Alternatively, a Multi-In-Multi-Out (MIMO) architecture that outputs all the future frames at one shot naturally breaks the recursive manner and therefore prevents error accumulation. However, only a few MIMO models for video prediction are proposed and they only achieve inferior performance due to the date. The real strength of the MIMO model in this area is not well noticed and is largely under-explored. Motivated by that, we conduct a comprehensive investigation in this paper to thoroughly exploit how far a simple MIMO architecture can go. Surprisingly, our empirical studies reveal that a simple MIMO model can outperform the state-of-the-art work with a large margin much more than expected, especially in dealing with long-term error accumulation. After exploring a number of ways and designs, we propose a new MIMO architecture based on extending the pure Transformer with local spatio-temporal blocks and a new multi-output decoder, namely MIMO-VP, to establish a new standard in video prediction. We evaluate our model in four highly competitive benchmarks. Extensive experiments show that our model wins 1st place on all the benchmarks with remarkable performance gains and surpasses the best SISO model in all aspects including efficiency, quantity, and quality. A dramatic error reduction is achieved when predicting 10 frames on Moving MNIST and Weather datasets respectively. We believe our model can serve as a new baseline to facilitate the future research of video prediction tasks. The code will be released.},
  archive   = {C_AAAI},
  author    = {Shuliang Ning and Mengcheng Lan and Yanran Li and Chaofeng Chen and Qian Chen and Xunlai Chen and Xiaoguang Han and Shuguang Cui},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25289},
  pages     = {1975-1983},
  title     = {MIMO is all you Need：A strong multi-in-multi-out baseline for video prediction},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adapting object size variance and class imbalance for
semi-supervised object detection. <em>AAAI</em>, 1966–1974. (<a
href="https://doi.org/10.1609/aaai.v37i2.25288">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Semi-supervised object detection (SSOD) attracts extensive research interest due to its great significance in reducing the data annotation effort. Collecting high-quality and category-balanced pseudo labels for unlabeled images is critical to addressing the SSOD problem. However, most of the existing pseudo-labeling-based methods depend on a large and fixed threshold to select high-quality pseudo labels from the predictions of a teacher model. Considering different object classes usually have different detection difficulty levels due to scale variance and data distribution imbalance, conventional pseudo-labeling-based methods are arduous to explore the value of unlabeled data sufficiently. To address these issues, we propose an adaptive pseudo labeling strategy, which can assign thresholds to classes with respect to their “hardness”. This is beneficial for ensuring the high quality of easier classes and increasing the quantity of harder classes simultaneously. Besides, label refinement modules are set up based on box jittering for guaranteeing the localization quality of pseudo labels. To further improve the algorithm’s robustness against scale variance and make the most of pseudo labels, we devise a joint feature-level and prediction-level consistency learning pipeline for transferring the information of the teacher model to the student model. Extensive experiments on COCO and VOC datasets indicate that our method achieves state-of-the-art performance. Especially, it brings mean average precision gains of 2.08 and 1.28 on MS-COCO dataset with 5\% and 10\% labeled images, respectively.},
  archive   = {C_AAAI},
  author    = {Yuxiang Nie and Chaowei Fang and Lechao Cheng and Liang Lin and Guanbin Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25288},
  pages     = {1966-1974},
  title     = {Adapting object size variance and class imbalance for semi-supervised object detection},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GLT-t: Global-local transformer voting for 3D single object
tracking in point clouds. <em>AAAI</em>, 1957–1965. (<a
href="https://doi.org/10.1609/aaai.v37i2.25287">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Current 3D single object tracking methods are typically based on VoteNet, a 3D region proposal network. Despite the success, using a single seed point feature as the cue for offset learning in VoteNet prevents high-quality 3D proposals from being generated. Moreover, seed points with different importance are treated equally in the voting process, aggravating this defect. To address these issues, we propose a novel global-local transformer voting scheme to provide more informative cues and guide the model pay more attention on potential seed points, promoting the generation of high-quality 3D proposals. Technically, a global-local transformer (GLT) module is employed to integrate object- and patch-aware prior into seed point features to effectively form strong feature representation for geometric positions of the seed points, thus providing more robust and accurate cues for offset learning. Subsequently, a simple yet effective training strategy is designed to train the GLT module. We develop an importance prediction branch to learn the potential importance of the seed points and treat the output weights vector as a training constraint term. By incorporating the above components together, we exhibit a superior tracking method GLT-T. Extensive experiments on challenging KITTI and NuScenes benchmarks demonstrate that GLT-T achieves state-of-the-art performance in the 3D single object tracking task. Besides, further ablation studies show the advantages of the proposed global-local transformer voting scheme over the original VoteNet. Code and models will be available at https://github.com/haooozi/GLT-T.},
  archive   = {C_AAAI},
  author    = {Jiahao Nie and Zhiwei He and Yuxiang Yang and Mingyu Gao and Jing Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25287},
  pages     = {1957-1965},
  title     = {GLT-T: Global-local transformer voting for 3D single object tracking in point clouds},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TaCo: Textual attribute recognition via contrastive
learning. <em>AAAI</em>, 1949–1956. (<a
href="https://doi.org/10.1609/aaai.v37i2.25286">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As textual attributes like font are core design elements of document format and page style, automatic attributes recognition favor comprehensive practical applications. Existing approaches already yield satisfactory performance in differentiating disparate attributes, but they still suffer in distinguishing similar attributes with only subtle difference. Moreover, their performance drop severely in real-world scenarios where unexpected and obvious imaging distortions appear. In this paper, we aim to tackle these problems by proposing TaCo, a contrastive framework for textual attribute recognition tailored toward the most common document scenes. Specifically, TaCo leverages contrastive learning to dispel the ambiguity trap arising from vague and open-ended attributes. To realize this goal, we design the learning paradigm from three perspectives: 1) generating attribute views, 2) extracting subtle but crucial details, and 3) exploiting valued view pairs for learning, to fully unlock the pre-training potential. Extensive experiments show that TaCo surpasses the supervised counterparts and advances the state-of-the-art remarkably on multiple attribute recognition tasks. Online services of TaCo will be made available.},
  archive   = {C_AAAI},
  author    = {Chang Nie and Yiqing Hu and Yanqiu Qu and Hao Liu and Deqiang Jiang and Bo Ren},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25286},
  pages     = {1949-1956},
  title     = {TaCo: Textual attribute recognition via contrastive learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Show, interpret and tell: Entity-aware contextualised image
captioning in wikipedia. <em>AAAI</em>, 1940–1948. (<a
href="https://doi.org/10.1609/aaai.v37i2.25285">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Humans exploit prior knowledge to describe images, and are able to adapt their explanation to specific contextual information given, even to the extent of inventing plausible explanations when contextual information and images do not match. In this work, we propose the novel task of captioning Wikipedia images by integrating contextual knowledge. Specifically, we produce models that jointly reason over Wikipedia articles, Wikimedia images and their associated descriptions to produce contextualized captions. The same Wikimedia image can be used to illustrate different articles, and the produced caption needs to be adapted to the specific context allowing us to explore the limits of the model to adjust captions to different contextual information. Dealing with out-of-dictionary words and Named Entities is a challenging task in this domain. To address this, we propose a pre-training objective, Masked Named Entity Modeling (MNEM), and show that this pretext task results to significantly improved models. Furthermore, we verify that a model pre-trained in Wikipedia generalizes well to News Captioning datasets. We further define two different test splits according to the difficulty of the captioning task. We offer insights on the role and the importance of each modality and highlight the limitations of our model.},
  archive   = {C_AAAI},
  author    = {Khanh Nguyen and Ali Furkan Biten and Andres Mafla and Lluis Gomez and Dimosthenis Karatzas},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25285},
  pages     = {1940-1948},
  title     = {Show, interpret and tell: Entity-aware contextualised image captioning in wikipedia},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Minority-oriented vicinity expansion with attentive
aggregation for video long-tailed recognition. <em>AAAI</em>, 1931–1939.
(<a href="https://doi.org/10.1609/aaai.v37i2.25284">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A dramatic increase in real-world video volume with extremely diverse and emerging topics naturally forms a long-tailed video distribution in terms of their categories, and it spotlights the need for Video Long-Tailed Recognition (VLTR). In this work, we summarize the challenges in VLTR and explore how to overcome them. The challenges are: (1) it is impractical to re-train the whole model for high-quality features, (2) acquiring frame-wise labels requires extensive cost, and (3) long-tailed data triggers biased training. Yet, most existing works for VLTR unavoidably utilize image-level features extracted from pretrained models which are task-irrelevant, and learn by video-level labels. Therefore, to deal with such (1) task-irrelevant features and (2) video-level labels, we introduce two complementary learnable feature aggregators. Learnable layers in each aggregator are to produce task-relevant representations, and each aggregator is to assemble the snippet-wise knowledge into a video representative. Then, we propose Minority-Oriented Vicinity Expansion (MOVE) that explicitly leverages the class frequency into approximating the vicinity distributions to alleviate (3) biased training. By combining these solutions, our approach achieves state-of-the-art results on large-scale VideoLT and synthetically induced Imbalanced-MiniKinetics200. With VideoLT features from ResNet-50, it attains 18\% and 58\% relative improvements on head and tail classes over the previous state-of-the-art method, respectively. Code and dataset are available at https://github.com/wjun0830/MOVE.},
  archive   = {C_AAAI},
  author    = {WonJun Moon and Hyun Seok Seong and Jae-Pil Heo},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25284},
  pages     = {1931-1939},
  title     = {Minority-oriented vicinity expansion with attentive aggregation for video long-tailed recognition},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Progressive few-shot adaptation of generative model with
align-free spatial correlation. <em>AAAI</em>, 1923–1930. (<a
href="https://doi.org/10.1609/aaai.v37i2.25283">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In few-shot generative model adaptation, the model for target domain is prone to the mode-collapse. Recent studies attempted to mitigate the problem by matching the relationship among samples generated from the same latent codes in source and target domains. The objective is further extended to image patch-level to transfer the spatial correlation within an instance. However, the patch-level approach assumes the consistency of spatial structure between source and target domains. For example, the positions of eyes in two domains are almost identical. Thus, it can bring visual artifacts if source and target domain images are not nicely aligned. In this paper, we propose a few-shot generative model adaptation method free from such assumption, based on a motivation that generative models are progressively adapting from the source domain to the target domain. Such progressive changes allow us to identify semantically coherent image regions between instances generated by models at a neighboring training iteration to consider the spatial correlation. We also propose an importance-based patch selection strategy to reduce the complexity of patch-level correlation matching. Our method shows the state-of-the-art few-shot domain adaptation performance in the qualitative and quantitative evaluations.},
  archive   = {C_AAAI},
  author    = {Jongbo Moon and Hyunjun Kim and Jae-Pil Heo},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25283},
  pages     = {1923-1930},
  title     = {Progressive few-shot adaptation of generative model with align-free spatial correlation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DocEdit: Language-guided document editing. <em>AAAI</em>,
1914–1922. (<a href="https://doi.org/10.1609/aaai.v37i2.25282">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Professional document editing tools require a certain level of expertise to perform complex edit operations. To make editing tools accessible to increasingly novice users, we investigate intelligent document assistant systems that can make or suggest edits based on a user&#39;s natural language request. Such a system should be able to understand the user&#39;s ambiguous requests and contextualize them to the visual cues and textual content found in a document image to edit localized unstructured text and structured layouts. To this end, we propose a new task of language-guided localized document editing, where the user provides a document and an open vocabulary editing request, and the intelligent system produces a command that can be used to automate edits in real-world document editing software. In support of this task, we curate the DocEdit dataset, a collection of approximately 28K instances of user edit requests over PDF and design templates along with their corresponding ground truth software executable commands. To our knowledge, this is the first dataset that provides a diverse mix of edit operations with direct and indirect references to the embedded text and visual objects such as paragraphs, lists, tables, etc. We also propose DocEditor, a Transformer-based localization-aware multimodal (textual, spatial, and visual) model that performs the new task. The model attends to both document objects and related text contents which may be referred to in a user edit request, generating a multimodal embedding that is used to predict an edit command and associated bounding box localizing it. Our proposed model empirically outperforms other baseline deep learning approaches by 15-18\%, providing a strong starting point for future work.},
  archive   = {C_AAAI},
  author    = {Puneet Mathur and Rajiv Jain and Jiuxiang Gu and Franck Dernoncourt and Dinesh Manocha and Vlad I. Morariu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25282},
  pages     = {1914-1922},
  title     = {DocEdit: Language-guided document editing},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Intriguing findings of frequency selection for image
deblurring. <em>AAAI</em>, 1905–1913. (<a
href="https://doi.org/10.1609/aaai.v37i2.25281">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Blur was naturally analyzed in the frequency domain, by estimating the latent sharp image and the blur kernel given a blurry image. Recent progress on image deblurring always designs end-to-end architectures and aims at learning the difference between blurry and sharp image pairs from pixel-level, which inevitably overlooks the importance of blur kernels. This paper reveals an intriguing phenomenon that simply applying ReLU operation on the frequency domain of a blur image followed by inverse Fourier transform, i.e., frequency selection, provides faithful information about the blur pattern (e.g., the blur direction and blur level, implicitly shows the kernel pattern). Based on this observation, we attempt to leverage kernel-level information for image deblurring networks by inserting Fourier transform, ReLU operation, and inverse Fourier transform to the standard ResBlock. 1 × 1 convolution is further added to let the network modulate flexible thresholds for frequency selection. We term our newly built block as Res FFT-ReLU Block, which takes advantages of both kernel-level and pixel-level features via learning frequency-spatial dual-domain representations. Extensive experiments are conducted to acquire a thorough analysis on the insights of the method. Moreover, after plugging the proposed block into NAFNet, we can achieve 33.85 dB in PSNR on GoPro dataset. Our method noticeably improves backbone architectures without introducing many parameters, while maintaining low computational complexity. Code is available at https://github.com/DeepMed-Lab/DeepRFT-AAAI2023.},
  archive   = {C_AAAI},
  author    = {Xintian Mao and Yiming Liu and Fengze Liu and Qingli Li and Wei Shen and Yan Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25281},
  pages     = {1905-1913},
  title     = {Intriguing findings of frequency selection for image deblurring},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). StyleTalk: One-shot talking head generation with
controllable speaking styles. <em>AAAI</em>, 1896–1904. (<a
href="https://doi.org/10.1609/aaai.v37i2.25280">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Different people speak with diverse personalized speaking styles. Although existing one-shot talking head methods have made significant progress in lip sync, natural facial expressions, and stable head motions, they still cannot generate diverse speaking styles in the final talking head videos. To tackle this problem, we propose a one-shot style-controllable talking face generation framework. In a nutshell, we aim to attain a speaking style from an arbitrary reference speaking video and then drive the one-shot portrait to speak with the reference speaking style and another piece of audio. Specifically, we first develop a style encoder to extract dynamic facial motion patterns of a style reference video and then encode them into a style code. Afterward, we introduce a style-controllable decoder to synthesize stylized facial animations from the speech content and style code. In order to integrate the reference speaking style into generated videos, we design a style-aware adaptive transformer, which enables the encoded style code to adjust the weights of the feed-forward layers accordingly. Thanks to the style-aware adaptation mechanism, the reference speaking style can be better embedded into synthesized videos during decoding. Extensive experiments demonstrate that our method is capable of generating talking head videos with diverse speaking styles from only one portrait image and an audio clip while achieving authentic visual effects. Project Page: https://github.com/FuxiVirtualHuman/styletalk.},
  archive   = {C_AAAI},
  author    = {Yifeng Ma and Suzhen Wang and Zhipeng Hu and Changjie Fan and Tangjie Lv and Yu Ding and Zhidong Deng and Xin Yu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25280},
  pages     = {1896-1904},
  title     = {StyleTalk: One-shot talking head generation with controllable speaking styles},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CFFT-GAN: Cross-domain feature fusion transformer for
exemplar-based image translation. <em>AAAI</em>, 1887–1895. (<a
href="https://doi.org/10.1609/aaai.v37i2.25279">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Exemplar-based image translation refers to the task of generating images with the desired style, while conditioning on certain input image. Most of the current methods learn the correspondence between two input domains and lack the mining of information within the domain. In this paper, we propose a more general learning approach by considering two domain features as a whole and learning both inter-domain correspondence and intra-domain potential information interactions. Specifically, we propose a Cross-domain Feature Fusion Transformer (CFFT) to learn inter- and intra-domain feature fusion. Based on CFFT, the proposed CFFT-GAN works well on exemplar-based image translation. Moreover, CFFT-GAN is able to decouple and fuse features from multiple domains by cascading CFFT modules. We conduct rich quantitative and qualitative experiments on several image translation tasks, and the results demonstrate the superiority of our approach compared to state-of-the-art methods. Ablation studies show the importance of our proposed CFFT. Application experimental results reflect the potential of our method.},
  archive   = {C_AAAI},
  author    = {Tianxiang Ma and Bingchuan Li and Wei Liu and Miao Hua and Jing Dong and Tieniu Tan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25279},
  pages     = {1887-1895},
  title     = {CFFT-GAN: Cross-domain feature fusion transformer for exemplar-based image translation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Semantic 3D-aware portrait synthesis and manipulation based
on compositional neural radiance field. <em>AAAI</em>, 1878–1886. (<a
href="https://doi.org/10.1609/aaai.v37i2.25278">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently 3D-aware GAN methods with neural radiance field have developed rapidly. However, current methods model the whole image as an overall neural radiance field, which limits the partial semantic editability of synthetic results. Since NeRF renders an image pixel by pixel, it is possible to split NeRF in the spatial dimension. We propose a Compositional Neural Radiance Field (CNeRF) for semantic 3D-aware portrait synthesis and manipulation. CNeRF divides the image by semantic regions and learns an independent neural radiance field for each region, and finally fuses them and renders the complete image. Thus we can manipulate the synthesized semantic regions independently, while fixing the other parts unchanged. Furthermore, CNeRF is also designed to decouple shape and texture within each semantic region. Compared to state-of-the-art 3D-aware GAN methods, our approach enables fine-grained semantic region manipulation, while maintaining high-quality 3D-consistent synthesis. The ablation studies show the effectiveness of the structure and loss function used by our method. In addition real image inversion and cartoon portrait 3D editing experiments demonstrate the application potential of our method.},
  archive   = {C_AAAI},
  author    = {Tianxiang Ma and Bingchuan Li and Qian He and Jing Dong and Tieniu Tan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25278},
  pages     = {1878-1886},
  title     = {Semantic 3D-aware portrait synthesis and manipulation based on compositional neural radiance field},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). HRDoc: Dataset and baseline method toward hierarchical
reconstruction of document structures. <em>AAAI</em>, 1870–1877. (<a
href="https://doi.org/10.1609/aaai.v37i2.25277">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The problem of document structure reconstruction refers to converting digital or scanned documents into corresponding semantic structures. Most existing works mainly focus on splitting the boundary of each element in a single document page, neglecting the reconstruction of semantic structure in multi-page documents. This paper introduces hierarchical reconstruction of document structures as a novel task suitable for NLP and CV fields. To better evaluate the system performance on the new task, we built a large-scale dataset named HRDoc, which consists of 2,500 multi-page documents with nearly 2 million semantic units. Every document in HRDoc has line-level annotations including categories and relations obtained from rule-based extractors and human annotators. Moreover, we proposed an encoder-decoder-based hierarchical document structure parsing system (DSPS) to tackle this problem. By adopting a multi-modal bidirectional encoder and a structure-aware GRU decoder with soft-mask operation, the DSPS model surpass the baseline method by a large margin. All scripts and datasets will be made publicly available at https://github.com/jfma-USTC/HRDoc.},
  archive   = {C_AAAI},
  author    = {Jiefeng Ma and Jun Du and Pengfei Hu and Zhenrong Zhang and Jianshu Zhang and Huihui Zhu and Cong Liu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25277},
  pages     = {1870-1877},
  title     = {HRDoc: Dataset and baseline method toward hierarchical reconstruction of document structures},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Robust one-shot segmentation of brain tissues via
image-aligned style transformation. <em>AAAI</em>, 1861–1869. (<a
href="https://doi.org/10.1609/aaai.v37i2.25276">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {One-shot segmentation of brain tissues is typically a dual-model iterative learning: a registration model (reg-model) warps a carefully-labeled atlas onto unlabeled images to initialize their pseudo masks for training a segmentation model (seg-model); the seg-model revises the pseudo masks to enhance the reg-model for a better warping in the next iteration. However, there is a key weakness in such dual-model iteration that the spatial misalignment inevitably caused by the reg-model could misguide the seg-model, which makes it converge on an inferior segmentation performance eventually. In this paper, we propose a novel image-aligned style transformation to reinforce the dual-model iterative learning for robust one-shot segmentation of brain tissues. Specifically, we first utilize the reg-model to warp the atlas onto an unlabeled image, and then employ the Fourier-based amplitude exchange with perturbation to transplant the style of the unlabeled image into the aligned atlas. This allows the subsequent seg-model to learn on the aligned and style-transferred copies of the atlas instead of unlabeled images, which naturally guarantees the correct spatial correspondence of an image-mask training pair, without sacrificing the diversity of intensity patterns carried by the unlabeled images. Furthermore, we introduce a feature-aware content consistency in addition to the image-level similarity to constrain the reg-model for a promising initialization, which avoids the collapse of image-aligned style transformation in the first iteration. Experimental results on two public datasets demonstrate 1) a competitive segmentation performance of our method compared to the fully-supervised method, and 2) a superior performance over other state-of-the-art with an increase of average Dice by up to 4.67\%. The source code is available at: https://github.com/JinxLv/One-shot-segmentation-via-IST.},
  archive   = {C_AAAI},
  author    = {Jinxin Lv and Xiaoyu Zeng and Sheng Wang and Ran Duan and Zhiwei Wang and Qiang Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25276},
  pages     = {1861-1869},
  title     = {Robust one-shot segmentation of brain tissues via image-aligned style transformation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ParaFormer: Parallel attention transformer for efficient
feature matching. <em>AAAI</em>, 1853–1860. (<a
href="https://doi.org/10.1609/aaai.v37i2.25275">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Heavy computation is a bottleneck limiting deep-learning-based feature matching algorithms to be applied in many real-time applications. However, existing lightweight networks optimized for Euclidean data cannot address classical feature matching tasks, since sparse keypoint based descriptors are expected to be matched. This paper tackles this problem and proposes two concepts: 1) a novel parallel attention model entitled ParaFormer and 2) a graph based U-Net architecture with attentional pooling. First, ParaFormer fuses features and keypoint positions through the concept of amplitude and phase, and integrates self- and cross-attention in a parallel manner which achieves a win-win performance in terms of accuracy and efficiency. Second, with U-Net architecture and proposed attentional pooling, the ParaFormer-U variant significantly reduces computational complexity, and minimize performance loss caused by downsampling. Sufficient experiments on various applications, including homography estimation, pose estimation, and image matching, demonstrate that ParaFormer achieves state-of-the-art performance while maintaining high efficiency. The efficient ParaFormer-U variant achieves comparable performance with less than 50\% FLOPs of the existing attention-based models.},
  archive   = {C_AAAI},
  author    = {Xiaoyong Lu and Yaping Yan and Bin Kang and Songlin Du},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25275},
  pages     = {1853-1860},
  title     = {ParaFormer: Parallel attention transformer for efficient feature matching},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Breaking immutable: Information-coupled prototype
elaboration for few-shot object detection. <em>AAAI</em>, 1844–1852. (<a
href="https://doi.org/10.1609/aaai.v37i2.25274">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Few-shot object detection, expecting detectors to detect novel classes with a few instances, has made conspicuous progress. However, the prototypes extracted by existing meta-learning based methods still suffer from insufficient representative information and lack awareness of query images, which cannot be adaptively tailored to different query images. Firstly, only the support images are involved for extracting prototypes, resulting in scarce perceptual information of query images. Secondly, all pixels of all support images are treated equally when aggregating features into prototype vectors, thus the salient objects are overwhelmed by the cluttered background. In this paper, we propose an Information-Coupled Prototype Elaboration (ICPE) method to generate specific and representative prototypes for each query image. Concretely, a conditional information coupling module is introduced to couple information from the query branch to the support branch, strengthening the query-perceptual information in support features. Besides, we design a prototype dynamic aggregation module that dynamically adjusts intra-image and inter-image aggregation weights to highlight the salient information useful for detecting query images. Experimental results on both Pascal VOC and MS COCO demonstrate that our method achieves state-of-the-art performance in almost all settings. Code will be available at: https://github.com/lxn96/ICPE.},
  archive   = {C_AAAI},
  author    = {Xiaonan Lu and Wenhui Diao and Yongqiang Mao and Junxi Li and Peijin Wang and Xian Sun and Kun Fu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25274},
  pages     = {1844-1852},
  title     = {Breaking immutable: Information-coupled prototype elaboration for few-shot object detection},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning progressive modality-shared transformers for
effective visible-infrared person re-identification. <em>AAAI</em>,
1835–1843. (<a href="https://doi.org/10.1609/aaai.v37i2.25273">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Visible-Infrared Person Re-Identification (VI-ReID) is a challenging retrieval task under complex modality changes. Existing methods usually focus on extracting discriminative visual features while ignoring the reliability and commonality of visual features between different modalities. In this paper, we propose a novel deep learning framework named Progressive Modality-shared Transformer (PMT) for effective VI-ReID. To reduce the negative effect of modality gaps, we first take the gray-scale images as an auxiliary modality and propose a progressive learning strategy. Then, we propose a Modality-Shared Enhancement Loss (MSEL) to guide the model to explore more reliable identity information from modality-shared features. Finally, to cope with the problem of large intra-class differences and small inter-class differences, we propose a Discriminative Center Loss (DCL) combined with the MSEL to further improve the discrimination of reliable features. Extensive experiments on SYSU-MM01 and RegDB datasets show that our proposed framework performs better than most state-of-the-art methods. For model reproduction, we release the source code at https://github.com/hulu88/PMT.},
  archive   = {C_AAAI},
  author    = {Hu Lu and Xuezhang Zou and Pingping Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25273},
  pages     = {1835-1843},
  title     = {Learning progressive modality-shared transformers for effective visible-infrared person re-identification},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). See your emotion from gait using unlabeled skeleton data.
<em>AAAI</em>, 1826–1834. (<a
href="https://doi.org/10.1609/aaai.v37i2.25272">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper focuses on contrastive learning for gait-based emotion recognition. The existing contrastive learning approaches are rarely suitable for learning skeleton-based gait representations, which suffer from limited gait diversity and inconsistent semantics. In this paper, we propose a Cross-coordinate contrastive learning framework utilizing Ambiguity samples for self-supervised Gait-based Emotion representation (CAGE). First, we propose ambiguity transform to push positive samples into ambiguous semantic space. By learning similarities between ambiguity samples and positive samples, our model can learn higher-level semantics of the gait sequences and maintain semantic diversity. Second, to encourage learning the semantic invariance, we uniquely propose cross-coordinate contrastive learning between the Cartesian coordinate and the Spherical coordinate, which brings rich supervisory signals to learn the intrinsic semantic consistency information. Exhaustive experiments show that CAGE improves existing self-supervised methods by 5\%–10\% accuracy, and it achieves comparable or even superior performance to supervised methods.},
  archive   = {C_AAAI},
  author    = {Haifeng Lu and Xiping Hu and Bin Hu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25272},
  pages     = {1826-1834},
  title     = {See your emotion from gait using unlabeled skeleton data},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CRIN: Rotation-invariant point cloud analysis and rotation
estimation via centrifugal reference frame. <em>AAAI</em>, 1817–1825.
(<a href="https://doi.org/10.1609/aaai.v37i2.25271">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Various recent methods attempt to implement rotation-invariant 3D deep learning by replacing the input coordinates of points with relative distances and angles. Due to the incompleteness of these low-level features, they have to undertake the expense of losing global information. In this paper, we propose the CRIN, namely Centrifugal Rotation-Invariant Network. CRIN directly takes the coordinates of points as input and transforms local points into rotation-invariant representations via centrifugal reference frames. Aided by centrifugal reference frames, each point corresponds to a discrete rotation so that the information of rotations can be implicitly stored in point features. Unfortunately, discrete points are far from describing the whole rotation space. We further introduce a continuous distribution for 3D rotations based on points. Furthermore, we propose an attention-based down-sampling strategy to sample points invariant to rotations. A relation module is adopted at last for reinforcing the long-range dependencies between sampled points and predicts the anchor point for unsupervised rotation estimation. Extensive experiments show that our method achieves rotation invariance, accurately estimates the object rotation, and obtains state-of-the-art results on rotation-augmented classification and part segmentation. Ablation studies validate the effectiveness of the network design.},
  archive   = {C_AAAI},
  author    = {Yujing Lou and Zelin Ye and Yang You and Nianjuan Jiang and Jiangbo Lu and Weiming Wang and Lizhuang Ma and Cewu Lu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25271},
  pages     = {1817-1825},
  title     = {CRIN: Rotation-invariant point cloud analysis and rotation estimation via centrifugal reference frame},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RADIANT: Radar-image association network for 3D object
detection. <em>AAAI</em>, 1808–1816. (<a
href="https://doi.org/10.1609/aaai.v37i2.25270">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As a direct depth sensor, radar holds promise as a tool to improve monocular 3D object detection, which suffers from depth errors, due in part to the depth-scale ambiguity. On the other hand, leveraging radar depths is hampered by difficulties in precisely associating radar returns with 3D estimates from monocular methods, effectively erasing its benefits. This paper proposes a fusion network that addresses this radar-camera association challenge. We train our network to predict the 3D offsets between radar returns and object centers, enabling radar depths to enhance the accuracy of 3D monocular detection. By using parallel radar and camera backbones, our network fuses information at both the feature level and detection level, while at the same time leveraging a state-of-the-art monocular detection technique without retraining it. Experimental results show significant improvement in mean average precision and translation error on the nuScenes dataset over monocular counterparts. Our source code is available at https://github.com/longyunf/radiant.},
  archive   = {C_AAAI},
  author    = {Yunfei Long and Abhinav Kumar and Daniel Morris and Xiaoming Liu and Marcos Castro and Punarjay Chakravarty},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25270},
  pages     = {1808-1816},
  title     = {RADIANT: Radar-image association network for 3D object detection},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Good helper is around you: Attention-driven masked image
modeling. <em>AAAI</em>, 1799–1807. (<a
href="https://doi.org/10.1609/aaai.v37i2.25269">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {It has been witnessed that masked image modeling (MIM) has shown a huge potential in self-supervised learning in the past year. Benefiting from the universal backbone vision transformer, MIM learns self-supervised visual representations through masking a part of patches of the image while attempting to recover the missing pixels. Most previous works mask patches of the image randomly, which underutilizes the semantic information that is beneficial to visual representation learning. On the other hand, due to the large size of the backbone, most previous works have to spend much time on pre-training. In this paper, we propose Attention-driven Masking and Throwing Strategy (AMT), which could solve both problems above. We first leverage the self-attention mechanism to obtain the semantic information of the image during the training process automatically without using any supervised methods. Masking strategy can be guided by that information to mask areas selectively, which is helpful for representation learning. Moreover, a redundant patch throwing strategy is proposed, which makes learning more efficient. As a plug-and-play module for masked image modeling, AMT improves the linear probing accuracy of MAE by 2.9\% ~ 5.9\% on CIFAR-10/100, STL-10, Tiny ImageNet, and ImageNet-1K, and obtains an improved performance with respect to fine-tuning accuracy of MAE and SimMIM. Moreover, this design also achieves superior performance on downstream detection and segmentation tasks.},
  archive   = {C_AAAI},
  author    = {Zhengqi Liu and Jie Gui and Hao Luo},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25269},
  pages     = {1799-1807},
  title     = {Good helper is around you: Attention-driven masked image modeling},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). StereoDistill: Pick the cream from LiDAR for distilling
stereo-based 3D object detection. <em>AAAI</em>, 1790–1798. (<a
href="https://doi.org/10.1609/aaai.v37i2.25268">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we propose a cross-modal distillation method named StereoDistill to narrow the gap between the stereo and LiDAR-based approaches via distilling the stereo detectors from the superior LiDAR model at the response level, which is usually overlooked in 3D object detection distillation. The key designs of StereoDistill are: the X-component Guided Distillation~(XGD) for regression and the Cross-anchor Logit Distillation~(CLD) for classification. In XGD, instead of empirically adopting a threshold to select the high-quality teacher predictions as soft targets, we decompose the predicted 3D box into sub-components and retain the corresponding part for distillation if the teacher component pilot is consistent with ground truth to largely boost the number of positive predictions and alleviate the mimicking difficulty of the student model. For CLD, we aggregate the probability distribution of all anchors at the same position to encourage the highest probability anchor rather than individually distill the distribution at the anchor level. Finally, our StereoDistill achieves state-of-the-art results for stereo-based 3D detection on the KITTI test benchmark and extensive experiments on KITTI and Argoverse Dataset validate the effectiveness.},
  archive   = {C_AAAI},
  author    = {Zhe Liu and Xiaoqing Ye and Xiao Tan and Errui Ding and Xiang Bai},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25268},
  pages     = {1790-1798},
  title     = {StereoDistill: Pick the cream from LiDAR for distilling stereo-based 3D object detection},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Token mixing: Parameter-efficient transfer learning from
image-language to video-language. <em>AAAI</em>, 1781–1789. (<a
href="https://doi.org/10.1609/aaai.v37i2.25267">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Applying large scale pre-trained image-language model to video-language tasks has recently become a trend, which brings two challenges. One is how to effectively transfer knowledge from static images to dynamic videos, and the other is how to deal with the prohibitive cost of fully fine-tuning due to growing model size. Existing works that attempt to realize parameter-efficient image-language to video-language transfer learning can be categorized into two types: 1) appending a sequence of temporal transformer blocks after the 2D Vision Transformer (ViT), and 2) inserting a temporal block into the ViT architecture. While these two types of methods only require fine-tuning the newly added components, there are still many parameters to update, and they are only validated on a single video-language task. In this work, based on our analysis of the core ideas of different temporal modeling components in existing approaches, we propose a token mixing strategy to enable cross-frame interactions, which enables transferring from the pre-trained image-language model to video-language tasks through selecting and mixing a key set and a value set from the input video samples. As token mixing does not require the addition of any components or modules, we can directly partially fine-tune the pre-trained image-language model to achieve parameter-efficiency. We carry out extensive experiments to compare our proposed token mixing method with other parameter-efficient transfer learning methods. Our token mixing method outperforms other methods on both understanding tasks and generation tasks. Besides, our method achieves new records on multiple video-language tasks. The code is available at https://github.com/yuqi657/video_language_model.},
  archive   = {C_AAAI},
  author    = {Yuqi Liu and Luhui Xu and Pengfei Xiong and Qin Jin},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25267},
  pages     = {1781-1789},
  title     = {Token mixing: Parameter-efficient transfer learning from image-language to video-language},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). Self-decoupling and ensemble distillation for efficient
segmentation. <em>AAAI</em>, 1772–1780. (<a
href="https://doi.org/10.1609/aaai.v37i2.25266">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Knowledge distillation (KD) is a promising teacher-student learning paradigm that transfers information from a cumbersome teacher to a student network. To avoid the training cost of a large teacher network, the recent studies propose to distill knowledge from the student itself, called Self-KD. However, due to the limitations of the performance and capacity of the student, the soft-labels or features distilled by the student barely provide reliable guidance. Moreover, most of the Self-KD algorithms are specific to classification tasks based on soft-labels, and not suitable for semantic segmentation. To alleviate these contradictions, we revisit the label and feature distillation problem in segmentation, and propose Self-Decoupling and Ensemble Distillation for Efficient Segmentation (SDES). Specifically, we design a decoupled prediction ensemble distillation (DPED) algorithm that generates reliable soft-labels with multiple expert decoders, and a decoupled feature ensemble distillation (DFED) mechanism to utilize more important channel-wise feature maps for encoder learning. The extensive experiments on three public segmentation datasets demonstrate the superiority of our approach and the efficacy of each component in the framework through the ablation study.},
  archive   = {C_AAAI},
  author    = {Yuang Liu and Wei Zhang and Jun Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25266},
  pages     = {1772-1780},
  title     = {Self-decoupling and ensemble distillation for efficient segmentation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). Counterfactual dynamics forecasting – a new setting of
quantitative reasoning. <em>AAAI</em>, 1764–1771. (<a
href="https://doi.org/10.1609/aaai.v37i2.25265">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Rethinking and introspection are important elements of human intelligence. To mimic these capabilities, counterfactual reasoning has attracted attention of AI researchers recently, which aims to forecast the alternative outcomes for hypothetical scenarios (“what-if”). However, most existing approaches focused on qualitative reasoning (e.g., casual-effect relationship). It lacks a well-defined description of the differences between counterfactuals and facts, as well as how these differences evolve over time. This paper defines a new problem formulation - counterfactual dynamics forecasting - which is described in middle-level abstraction under the structural causal models (SCM) framework and derived as ordinary differential equations (ODEs) as low-level quantitative computation. Based on it, we propose a method to infer counterfactual dynamics considering the factual dynamics as demonstration. Moreover, the evolution of differences between facts and counterfactuals are modelled by an explicit temporal component. The experimental results on two dynamical systems demonstrate the effectiveness of the proposed method.},
  archive   = {C_AAAI},
  author    = {Yanzhu Liu and Ying Sun and Joo-Hwee Lim},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25265},
  pages     = {1764-1771},
  title     = {Counterfactual dynamics forecasting – a new setting of quantitative reasoning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CCQ: Cross-class query network for partially labeled organ
segmentation. <em>AAAI</em>, 1755–1763. (<a
href="https://doi.org/10.1609/aaai.v37i2.25264">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Learning multi-organ segmentation from multiple partially-labeled datasets attracts increasing attention. It can be a promising solution for the scarcity of large-scale, fully labeled 3D medical image segmentation datasets. However, existing algorithms of multi-organ segmentation on partially-labeled datasets neglect the semantic relations and anatomical priors between different categories of organs, which is crucial for partially-labeled multi-organ segmentation. In this paper, we tackle the limitations above by proposing the Cross-Class Query Network (CCQ). CCQ consists of an image encoder, a cross-class query learning module, and an attentive refinement segmentation module. More specifically, the image encoder captures the long-range dependency of a single image via the transformer encoder. Cross-class query learning module first generates query vectors that represent semantic concepts of different categories and then utilizes these query vectors to find the class-relevant features of image representation for segmentation. The attentive refinement segmentation module with an attentive skip connection incorporates the high-resolution image details and eliminates the class-irrelevant noise. Extensive experiment results demonstrate that CCQ outperforms all the state-of-the-art models on the MOTS dataset, which consists of seven organ and tumor segmentation tasks. Code is available at https://github.com/Yang-007/CCQ.git.},
  archive   = {C_AAAI},
  author    = {Xuyang Liu and Bingbing Wen and Sibei Yang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25264},
  pages     = {1755-1763},
  title     = {CCQ: Cross-class query network for partially labeled organ segmentation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CoordFill: Efficient high-resolution image inpainting via
parameterized coordinate querying. <em>AAAI</em>, 1746–1754. (<a
href="https://doi.org/10.1609/aaai.v37i2.25263">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Image inpainting aims to fill the missing hole of the input. It is hard to solve this task efficiently when facing high-resolution images due to two reasons: (1) Large reception field needs to be handled for high-resolution image inpainting. (2) The general encoder and decoder network synthesizes many background pixels synchronously due to the form of the image matrix. In this paper, we try to break the above limitations for the first time thanks to the recent development of continuous implicit representation. In detail, we down-sample and encode the degraded image to produce the spatial-adaptive parameters for each spatial patch via an attentional Fast Fourier Convolution (FFC)-based parameter generation network. Then, we take these parameters as the weights and biases of a series of multi-layer perceptron (MLP), where the input is the encoded continuous coordinates and the output is the synthesized color value. Thanks to the proposed structure, we only encode the high-resolution image in a relatively low resolution for larger reception field capturing. Then, the continuous position encoding will be helpful to synthesize the photo-realistic high-frequency textures by re-sampling the coordinate in a higher resolution. Also, our framework enables us to query the coordinates of missing pixels only in parallel, yielding a more efficient solution than the previous methods. Experiments show that the proposed method achieves real-time performance on the 2048X2048 images using a single GTX 2080 Ti GPU and can handle 4096X4096 images, with much better performance than existing state-of-the-art methods visually and numerically. The code is available at: https://github.com/NiFangBaAGe/CoordFill.},
  archive   = {C_AAAI},
  author    = {Weihuang Liu and Xiaodong Cun and Chi-Man Pun and Menghan Xia and Yong Zhang and Jue Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25263},
  pages     = {1746-1754},
  title     = {CoordFill: Efficient high-resolution image inpainting via parameterized coordinate querying},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Progressive neighborhood aggregation for semantic
segmentation refinement. <em>AAAI</em>, 1737–1745. (<a
href="https://doi.org/10.1609/aaai.v37i2.25262">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-scale features from backbone networks have been widely applied to recover object details in segmentation tasks. Generally, the multi-level features are fused in a certain manner for further pixel-level dense prediction. Whereas, the spatial structure information is not fully explored, that is similar nearby pixels can be used to complement each other. In this paper, we investigate a progressive neighborhood aggregation (PNA) framework to refine the semantic segmentation prediction, resulting in an end-to-end solution that can perform the coarse prediction and refinement in a unified network. Specifically, we first present a neighborhood aggregation module, the neighborhood similarity matrices for each pixel are estimated on multi-scale features, which are further used to progressively aggregate the high-level feature for recovering the spatial structure. In addition, to further integrate the high-resolution details into the aggregated feature, we apply a self-aggregation module on the low-level features to emphasize important semantic information for complementing losing spatial details. Extensive experiments on five segmentation datasets, including Pascal VOC 2012, CityScapes, COCO-Stuff 10k, DeepGlobe, and Trans10k, demonstrate that the proposed framework can be cascaded into existing segmentation models providing consistent improvements. In particular, our method achieves new state-of-the-art performances on two challenging datasets, DeepGlobe and Trans10k. The code is available at https://github.com/liutinglt/PNA.},
  archive   = {C_AAAI},
  author    = {Ting Liu and Yunchao Wei and Yanning Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25262},
  pages     = {1737-1745},
  title     = {Progressive neighborhood aggregation for semantic segmentation refinement},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). DQ-DETR: Dual query detection transformer for phrase
extraction and grounding. <em>AAAI</em>, 1728–1736. (<a
href="https://doi.org/10.1609/aaai.v37i2.25261">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we study the problem of visual grounding by considering both phrase extraction and grounding (PEG). In contrast to the previous phrase-known-at-test setting, PEG requires a model to extract phrases from text and locate objects from image simultaneously, which is a more practical setting in real applications. As phrase extraction can be regarded as a 1D text segmentation problem, we formulate PEG as a dual detection problem and propose a novel DQ-DETR model, which introduces dual queries to probe different features from image and text for object prediction and phrase mask prediction. Each pair of dual queries are designed to have shared positional parts but different content parts. Such a design effectively alleviates the difficulty of modality alignment between image and text (in contrast to a single query design) and empowers Transformer decoder to leverage phrase mask-guided attention to improve the performance. To evaluate the performance of PEG, we also propose a new metric CMAP (cross-modal average precision), analogous to the AP metric in object detection. The new metric overcomes the ambiguity of Recall@1 in many-box-to-one-phrase cases in phrase grounding. As a result, our PEG pre-trained DQ-DETR establishes new state-of-the-art results on all visual grounding benchmarks with a ResNet-101 backbone. For example, it achieves 91.04\% and 83.51\% in terms of recall rate on RefCOCO testA and testB with a ResNet-101 backbone.},
  archive   = {C_AAAI},
  author    = {Shilong Liu and Shijia Huang and Feng Li and Hao Zhang and Yaoyuan Liang and Hang Su and Jun Zhu and Lei Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25261},
  pages     = {1728-1736},
  title     = {DQ-DETR: Dual query detection transformer for phrase extraction and grounding},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reducing domain gap in frequency and spatial domain for
cross-modality domain adaptation on medical image segmentation.
<em>AAAI</em>, 1719–1727. (<a
href="https://doi.org/10.1609/aaai.v37i2.25260">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Unsupervised domain adaptation (UDA) aims to learn a model trained on source domain and performs well on unlabeled target domain. In medical image segmentation field, most existing UDA methods depend on adversarial learning to address the domain gap between different image modalities, which is ineffective due to its complicated training process. In this paper, we propose a simple yet effective UDA method based on frequency and spatial domain transfer under multi-teacher distillation framework. In the frequency domain, we first introduce non-subsampled contourlet transform for identifying domain-invariant and domain-variant frequency components (DIFs and DVFs), and then keep the DIFs unchanged while replacing the DVFs of the source domain images with that of the target domain images to narrow the domain gap. In the spatial domain, we propose a batch momentum update-based histogram matching strategy to reduce the domain-variant image style bias. Experiments on two commonly used cross-modality medical image segmentation datasets show that our proposed method achieves superior performance compared to state-of-the-art methods.},
  archive   = {C_AAAI},
  author    = {Shaolei Liu and Siqi Yin and Linhao Qu and Manning Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25260},
  pages     = {1719-1727},
  title     = {Reducing domain gap in frequency and spatial domain for cross-modality domain adaptation on medical image segmentation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). EMEF: Ensemble multi-exposure image fusion. <em>AAAI</em>,
1710–1718. (<a href="https://doi.org/10.1609/aaai.v37i2.25259">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Although remarkable progress has been made in recent years, current multi-exposure image fusion (MEF) research is still bounded by the lack of real ground truth, objective evaluation function, and robust fusion strategy. In this paper, we study the MEF problem from a new perspective. We don’t utilize any synthesized ground truth, design any loss function, or develop any fusion strategy. Our proposed method EMEF takes advantage of the wisdom of multiple imperfect MEF contributors including both conventional and deep learning-based methods. Specifically, EMEF consists of two main stages: pre-train an imitator network and tune the imitator in the runtime. In the first stage, we make a unified network imitate different MEF targets in a style modulation way. In the second stage, we tune the imitator network by optimizing the style code, in order to find an optimal fusion result for each input pair. In the experiment, we construct EMEF from four state-of-the-art MEF methods and then make comparisons with the individuals and several other competitive methods on the latest released MEF benchmark dataset. The promising experimental results demonstrate that our ensemble framework can “get the best of all worlds”. The code is available at https://github.com/medalwill/EMEF.},
  archive   = {C_AAAI},
  author    = {Renshuai Liu and Chengyang Li and Haitao Cao and Yinglin Zheng and Ming Zeng and Xuan Cheng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25259},
  pages     = {1710-1718},
  title     = {EMEF: Ensemble multi-exposure image fusion},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Novel motion patterns matter for practical skeleton-based
action recognition. <em>AAAI</em>, 1701–1709. (<a
href="https://doi.org/10.1609/aaai.v37i2.25258">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Most skeleton-based action recognition methods assume that the same type of action samples in the training set and the test set share similar motion patterns. However, action samples in real scenarios usually contain novel motion patterns which are not involved in the training set. As it is laborious to collect sufficient training samples to enumerate various types of novel motion patterns, this paper presents a practical skeleton-based action recognition task where the training set contains common motion patterns of action samples and the test set contains action samples that suffer from novel motion patterns. For this task, we present a Mask Graph Convolutional Network (Mask-GCN) to focus on learning action-specific skeleton joints that mainly convey action information meanwhile masking action-agnostic skeleton joints that convey rare action information and suffer more from novel motion patterns. Specifically, we design a policy network to learn layer-wise body masks to construct masked adjacency matrices, which guide a GCN-based backbone to learn stable yet informative action features from dynamic graph structure. Extensive experiments on our newly collected dataset verify that Mask-GCN outperforms most GCN-based methods when testing with various novel motion patterns.},
  archive   = {C_AAAI},
  author    = {Mengyuan Liu and Fanyang Meng and Chen Chen and Songtao Wu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25258},
  pages     = {1701-1709},
  title     = {Novel motion patterns matter for practical skeleton-based action recognition},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Low-light video enhancement with synthetic event guidance.
<em>AAAI</em>, 1692–1700. (<a
href="https://doi.org/10.1609/aaai.v37i2.25257">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Low-light video enhancement (LLVE) is an important yet challenging task with many applications such as photographing and autonomous driving. Unlike single image low-light enhancement, most LLVE methods utilize temporal information from adjacent frames to restore the color and remove the noise of the target frame. However, these algorithms, based on the framework of multi-frame alignment and enhancement, may produce multi-frame fusion artifacts when encountering extreme low light or fast motion. In this paper, inspired by the low latency and high dynamic range of events, we use synthetic events from multiple frames to guide the enhancement and restoration of low-light videos. Our method contains three stages: 1) event synthesis and enhancement, 2) event and image fusion, and 3) low-light enhancement. In this framework, we design two novel modules (event-image fusion transform and event-guided dual branch) for the second and third stages, respectively. Extensive experiments show that our method outperforms existing low-light video or single image enhancement approaches on both synthetic and real LLVE datasets. Our code will be available at https://gitee.com/mindspore/models/tree/master/research/cv/LLVE-SEG.},
  archive   = {C_AAAI},
  author    = {Lin Liu and Junfeng An and Jianzhuang Liu and Shanxin Yuan and Xiangyu Chen and Wengang Zhou and Houqiang Li and Yan Feng Wang and Qi Tian},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25257},
  pages     = {1692-1700},
  title     = {Low-light video enhancement with synthetic event guidance},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TransLO: A window-based masked point transformer framework
for large-scale LiDAR odometry. <em>AAAI</em>, 1683–1691. (<a
href="https://doi.org/10.1609/aaai.v37i2.25256">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, transformer architecture has gained great success in the computer vision community, such as image classification, object detection, etc. Nonetheless, its application for 3D vision remains to be explored, given that point cloud is inherently sparse, irregular, and unordered. Furthermore, existing point transformer frameworks usually feed raw point cloud of N×3 dimension into transformers, which limits the point processing scale because of their quadratic computational costs to the input size N. In this paper, we rethink the structure of point transformer. Instead of directly applying transformer to points, our network (TransLO) can process tens of thousands of points simultaneously by projecting points onto a 2D surface and then feeding them into a local transformer with linear complexity. Specifically, it is mainly composed of two components: Window-based Masked transformer with Self Attention (WMSA) to capture long-range dependencies; Masked Cross-Frame Attention (MCFA) to associate two frames and predict pose estimation. To deal with the sparsity issue of point cloud, we propose a binary mask to remove invalid and dynamic points. To our knowledge, this is the first transformer-based LiDAR odometry network. The experiment results on the KITTI odometry dataset show that our average rotation and translation RMSE achieves 0.500°/100m and 0.993\% respectively. The performance of our network surpasses all recent learning-based methods and even outperforms LOAM on most evaluation sequences.Codes will be released on https://github.com/IRMVLab/TransLO.},
  archive   = {C_AAAI},
  author    = {Jiuming Liu and Guangming Wang and Chaokang Jiang and Zhe Liu and Hesheng Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25256},
  pages     = {1683-1691},
  title     = {TransLO: A window-based masked point transformer framework for large-scale LiDAR odometry},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fast fluid simulation via dynamic multi-scale gridding.
<em>AAAI</em>, 1675–1682. (<a
href="https://doi.org/10.1609/aaai.v37i2.25255">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent works on learning-based frameworks for Lagrangian (i.e., particle-based) fluid simulation, though bypassing iterative pressure projection via efficient convolution operators, are still time-consuming due to excessive amount of particles. To address this challenge, we propose a dynamic multi-scale gridding method to reduce the magnitude of elements that have to be processed, by observing repeated particle motion patterns within certain consistent regions. Specifically, we hierarchically generate multi-scale micelles in Euclidean space by grouping particles that share similar motion patterns/characteristics based on super-light motion and scale estimation modules. With little internal motion variation, each micelle is modeled as a single rigid body with convolution only applied to a single representative particle. In addition, a distance-based interpolation is conducted to propagate relative motion message among micelles. With our efficient design, the network produces high visual fidelity fluid simulations with the inference time to be only 4.24 ms/frame (with 6K fluid particles), hence enables real-time human-computer interaction and animation. Experimental results on multiple datasets show that our work achieves great simulation acceleration with negligible prediction error increase.},
  archive   = {C_AAAI},
  author    = {Jinxian Liu and Ye Chen and Bingbing Ni and Wei Ren and Zhenbo Yu and Xiaoyang Huang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25255},
  pages     = {1675-1682},
  title     = {Fast fluid simulation via dynamic multi-scale gridding},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). From coarse to fine: Hierarchical pixel integration for
lightweight image super-resolution. <em>AAAI</em>, 1666–1674. (<a
href="https://doi.org/10.1609/aaai.v37i2.25254">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Image super-resolution (SR) serves as a fundamental tool for the processing and transmission of multimedia data. Recently, Transformer-based models have achieved competitive performances in image SR. They divide images into fixed-size patches and apply self-attention on these patches to model long-range dependencies among pixels. However, this architecture design is originated for high-level vision tasks, which lacks design guideline from SR knowledge. In this paper, we aim to design a new attention block whose insights are from the interpretation of Local Attribution Map (LAM) for SR networks. Specifically, LAM presents a hierarchical importance map where the most important pixels are located in a fine area of a patch and some less important pixels are spread in a coarse area of the whole image. To access pixels in the coarse area, instead of using a very large patch size, we propose a lightweight Global Pixel Access (GPA) module that applies cross-attention with the most similar patch in an image. In the fine area, we use an Intra-Patch Self-Attention (IPSA) module to model long-range pixel dependencies in a local patch, and then a spatial convolution is applied to process the finest details. In addition, a Cascaded Patch Division (CPD) strategy is proposed to enhance perceptual quality of recovered images. Extensive experiments suggest that our method outperforms state-of-the-art lightweight SR methods by a large margin. Code is available at https://github.com/passerer/HPINet.},
  archive   = {C_AAAI},
  author    = {Jie Liu and Chao Chen and Jie Tang and Gangshan Wu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25254},
  pages     = {1666-1674},
  title     = {From coarse to fine: Hierarchical pixel integration for lightweight image super-resolution},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). M3AE: Multimodal representation learning for brain tumor
segmentation with missing modalities. <em>AAAI</em>, 1657–1665. (<a
href="https://doi.org/10.1609/aaai.v37i2.25253">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multimodal magnetic resonance imaging (MRI) provides complementary information for sub-region analysis of brain tumors. Plenty of methods have been proposed for automatic brain tumor segmentation using four common MRI modalities and achieved remarkable performance. In practice, however, it is common to have one or more modalities missing due to image corruption, artifacts, acquisition protocols, allergy to contrast agents, or simply cost. In this work, we propose a novel two-stage framework for brain tumor segmentation with missing modalities. In the first stage, a multimodal masked autoencoder (M3AE) is proposed, where both random modalities (i.e., modality dropout) and random patches of the remaining modalities are masked for a reconstruction task, for self-supervised learning of robust multimodal representations against missing modalities. To this end, we name our framework M3AE. Meanwhile, we employ model inversion to optimize a representative full-modal image at marginal extra cost, which will be used to substitute for the missing modalities and boost performance during inference. Then in the second stage, a memory-efficient self distillation is proposed to distill knowledge between heterogenous missing-modal situations while fine-tuning the model for supervised segmentation. Our M3AE belongs to the ‘catch-all’ genre where a single model can be applied to all possible subsets of modalities, thus is economic for both training and deployment. Extensive experiments on BraTS 2018 and 2020 datasets demonstrate its superior performance to existing state-of-the-art methods with missing modalities, as well as the efficacy of its components. Our code is available at: https://github.com/ccarliu/m3ae.},
  archive   = {C_AAAI},
  author    = {Hong Liu and Dong Wei and Donghuan Lu and Jinghan Sun and Liansheng Wang and Yefeng Zheng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25253},
  pages     = {1657-1665},
  title     = {M3AE: Multimodal representation learning for brain tumor segmentation with missing modalities},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). The devil is in the frequency: Geminated gestalt autoencoder
for self-supervised visual pre-training. <em>AAAI</em>, 1649–1656. (<a
href="https://doi.org/10.1609/aaai.v37i2.25252">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The self-supervised Masked Image Modeling (MIM) schema, following &quot;mask-and-reconstruct&quot; pipeline of recovering contents from masked image, has recently captured the increasing interest in the community, owing to the excellent ability of learning visual representation from unlabeled data. Aiming at learning representations with high semantics abstracted, a group of works attempts to reconstruct non-semantic pixels with large-ratio masking strategy, which may suffer from &quot;over-smoothing&quot; problem, while others directly infuse semantics into targets in off-line way requiring extra data. Different from them, we shift the perspective to the Fourier domain which naturally has global perspective and present a new Masked Image Modeling (MIM), termed Geminated Gestalt Autoencoder (Ge^2-AE) for visual pre-training. Specifically, we equip our model with geminated decoders in charge of reconstructing image contents from both pixel and frequency space, where each other serves as not only the complementation but also the reciprocal constraints. Through this way, more robust representations can be learned in the pre-trained encoders, of which the effectiveness is confirmed by the juxtaposing experimental results on downstream recognition tasks. We also conduct several quantitative and qualitative experiments to investigate the learning behavior of our method. To our best knowledge, this is the first MIM work to solve the visual pre-training through the lens of frequency domain.},
  archive   = {C_AAAI},
  author    = {Hao Liu and Xinghua Jiang and Xin Li and Antai Guo and Yiqing Hu and Deqiang Jiang and Bo Ren},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25252},
  pages     = {1649-1656},
  title     = {The devil is in the frequency: Geminated gestalt autoencoder for self-supervised visual pre-training},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hypotheses tree building for one-shot temporal sentence
localization. <em>AAAI</em>, 1640–1648. (<a
href="https://doi.org/10.1609/aaai.v37i2.25251">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Given an untrimmed video, temporal sentence localization (TSL) aims to localize a specific segment according to a given sentence query. Though respectable works have made decent achievements in this task, they severely rely on dense video frame annotations, which require a tremendous amount of human effort to collect. In this paper, we target another more practical and challenging setting: one-shot temporal sentence localization (one-shot TSL), which learns to retrieve the query information among the entire video with only one annotated frame. Particularly, we propose an effective and novel tree-structure baseline for one-shot TSL, called Multiple Hypotheses Segment Tree (MHST), to capture the query-aware discriminative frame-wise information under the insufficient annotations. Each video frame is taken as the leaf-node, and the adjacent frames sharing the same visual-linguistic semantics will be merged into the upper non-leaf node for tree building. At last, each root node is an individual segment hypothesis containing the consecutive frames of its leaf-nodes. During the tree construction, we also introduce a pruning strategy to eliminate the interference of query-irrelevant nodes. With our designed self-supervised loss functions, our MHST is able to generate high-quality segment hypotheses for ranking and selection with the query. Experiments on two challenging datasets demonstrate that MHST achieves competitive performance compared to existing methods.},
  archive   = {C_AAAI},
  author    = {Daizong Liu and Xiang Fang and Pan Zhou and Xing Di and Weining Lu and Yu Cheng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25251},
  pages     = {1640-1648},
  title     = {Hypotheses tree building for one-shot temporal sentence localization},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cross-modality earth mover’s distance for visible thermal
person re-identification. <em>AAAI</em>, 1631–1639. (<a
href="https://doi.org/10.1609/aaai.v37i2.25250">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Visible thermal person re-identification (VT-ReID) suffers from inter-modality discrepancy and intra-identity variations. Distribution alignment is a popular solution for VT-ReID, however, it is usually restricted to the influence of the intra-identity variations. In this paper, we propose the Cross-Modality Earth Mover&#39;s Distance (CM-EMD) that can alleviate the impact of the intra-identity variations during modality alignment. CM-EMD selects an optimal transport strategy and assigns high weights to pairs that have a smaller intra-identity variation. In this manner, the model will focus on reducing the inter-modality discrepancy while paying less attention to intra-identity variations, leading to a more effective modality alignment. Moreover, we introduce two techniques to improve the advantage of CM-EMD. First, Cross-Modality Discrimination Learning (CM-DL) is designed to overcome the discrimination degradation problem caused by modality alignment. By reducing the ratio between intra-identity and inter-identity variances, CM-DL leads the model to learn more discriminative representations. Second, we construct the Multi-Granularity Structure (MGS), enabling us to align modalities from both coarse- and fine-grained levels with the proposed CM-EMD. Extensive experiments show the benefits of the proposed CM-EMD and its auxiliary techniques (CM-DL and MGS). Our method achieves state-of-the-art performance on two VT-ReID benchmarks.},
  archive   = {C_AAAI},
  author    = {Yongguo Ling and Zhun Zhong and Zhiming Luo and Fengxiang Yang and Donglin Cao and Yaojin Lin and Shaozi Li and Nicu Sebe},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25250},
  pages     = {1631-1639},
  title     = {Cross-modality earth mover’s distance for visible thermal person re-identification},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SEPT: Towards scalable and efficient visual pre-training.
<em>AAAI</em>, 1622–1630. (<a
href="https://doi.org/10.1609/aaai.v37i2.25249">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, the self-supervised pre-training paradigm has shown great potential in leveraging large-scale unlabeled data to improve downstream task performance. However, increasing the scale of unlabeled pre-training data in real-world scenarios requires prohibitive computational costs and faces the challenge of uncurated samples. To address these issues, we build a task-specific self-supervised pre-training framework from a data selection perspective based on a simple hypothesis that pre-training on the unlabeled samples with similar distribution to the target task can bring substantial performance gains. Buttressed by the hypothesis, we propose the first yet novel framework for Scalable and Efficient visual Pre-Training (SEPT) by introducing a retrieval pipeline for data selection. SEPT first leverage a self-supervised pre-trained model to extract the features of the entire unlabeled dataset for retrieval pipeline initialization. Then, for a specific target task, SEPT retrievals the most similar samples from the unlabeled dataset based on feature similarity for each target instance for pre-training. Finally, SEPT pre-trains the target model with the selected unlabeled samples in a self-supervised manner for target data finetuning. By decoupling the scale of pre-training and available upstream data for a target task, SEPT achieves high scalability of the upstream dataset and high efficiency of pre-training, resulting in high model architecture flexibility. Results on various downstream tasks demonstrate that SEPT can achieve competitive or even better performance compared with ImageNet pre-training while reducing the size of training samples by one magnitude without resorting to any extra annotations.},
  archive   = {C_AAAI},
  author    = {Yiqi Lin and Huabin Zheng and Huaping Zhong and Jinjing Zhu and Weijia Li and Conghui He and Lin Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25249},
  pages     = {1622-1630},
  title     = {SEPT: Towards scalable and efficient visual pre-training},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AdaCM: Adaptive ColorMLP for real-time universal
photo-realistic style transfer. <em>AAAI</em>, 1613–1621. (<a
href="https://doi.org/10.1609/aaai.v37i2.25248">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Photo-realistic style transfer aims at migrating the artistic style from an exemplar style image to a content image, producing a result image without spatial distortions or unrealistic artifacts. Impressive results have been achieved by recent deep models. However, deep neural network based methods are too expensive to run in real-time. Meanwhile, bilateral grid based methods are much faster but still contain artifacts like overexposure. In this work, we propose the Adaptive ColorMLP (AdaCM), an effective and efficient framework for universal photo-realistic style transfer. First, we find the complex non-linear color mapping between input and target domain can be efficiently modeled by a small multi-layer perceptron (ColorMLP) model. Then, in AdaCM, we adopt a CNN encoder to adaptively predict all parameters for the ColorMLP conditioned on each input content and style image pair. Experimental results demonstrate that AdaCM can generate vivid and high-quality stylization results. Meanwhile, our AdaCM is ultrafast and can process a 4K resolution image in 6ms on one V100 GPU.},
  archive   = {C_AAAI},
  author    = {Tianwei Lin and Honglin Lin and Fu Li and Dongliang He and Wenhao Wu and Meiling Wang and Xin Li and Yong Liu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25248},
  pages     = {1613-1621},
  title     = {AdaCM: Adaptive ColorMLP for real-time universal photo-realistic style transfer},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SelectAugment: Hierarchical deterministic sample selection
for data augmentation. <em>AAAI</em>, 1604–1612. (<a
href="https://doi.org/10.1609/aaai.v37i2.25247">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Data augmentation (DA) has been extensively studied to facilitate model optimization in many tasks. Prior DA works focus on designing augmentation operations themselves, while leaving selecting suitable samples for augmentation out of consideration. This might incur visual ambiguities and further induce training biases. In this paper, we propose an effective approach, dubbed SelectAugment, to select samples for augmentation in a deterministic and online manner based on the sample contents and the network training status. To facilitate the policy learning, in each batch, we exploit the hierarchy of this task by first determining the augmentation ratio and then deciding whether to augment each training sample under this ratio. We model this process as two-step decision-making and adopt Hierarchical Reinforcement Learning (HRL) to learn the selection policy. In this way, the negative effects of the randomness in selecting samples to augment can be effectively alleviated and the effectiveness of DA is improved. Extensive experiments demonstrate that our proposed SelectAugment significantly improves various off-the-shelf DA methods on image classification and fine-grained image recognition.},
  archive   = {C_AAAI},
  author    = {Shiqi Lin and Zhizheng Zhang and Xin Li and Zhibo Chen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25247},
  pages     = {1604-1612},
  title     = {SelectAugment: Hierarchical deterministic sample selection for data augmentation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Accelerating the training of video super-resolution models.
<em>AAAI</em>, 1595–1603. (<a
href="https://doi.org/10.1609/aaai.v37i2.25246">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Despite that convolution neural networks (CNN) have recently demonstrated high-quality reconstruction for video super-resolution (VSR), efficiently training competitive VSR models remains a challenging problem. It usually takes an order of magnitude more time than training their counterpart image models, leading to long research cycles. Existing VSR methods typically train models with fixed spatial and temporal sizes from beginning to end. The fixed sizes are usually set to large values for good performance, resulting to slow training. However, is such a rigid training strategy necessary for VSR? In this work, we show that it is possible to gradually train video models from small to large spatial/temporal sizes, \ie, in an easy-to-hard manner. In particular, the whole training is divided into several stages and the earlier stage has smaller training spatial shape. Inside each stage, the temporal size also varies from short to long while the spatial size remains unchanged. Training is accelerated by such a multigrid training strategy, as most of computation is performed on smaller spatial and shorter temporal shapes. For further acceleration with GPU parallelization, we also investigate the large minibatch training without the loss in accuracy. Extensive experiments demonstrate that our method is capable of largely speeding up training (up to $6.2\times$ speedup in wall-clock training time) without performance drop for various VSR models.},
  archive   = {C_AAAI},
  author    = {Lijian Lin and Xintao Wang and Zhongang Qi and Ying Shan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25246},
  pages     = {1595-1603},
  title     = {Accelerating the training of video super-resolution models},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-supervised image denoising using implicit deep denoiser
prior. <em>AAAI</em>, 1586–1594. (<a
href="https://doi.org/10.1609/aaai.v37i2.25245">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We devise a new regularization for denoising with self-supervised learning. The regularization uses a deep image prior learned by the network, rather than a traditional predefined prior. Specifically, we treat the output of the network as a ``prior&#39;&#39; that we again denoise after ``re-noising.&#39;&#39; The network is updated to minimize the discrepancy between the twice-denoised image and its prior. We demonstrate that this regularization enables the network to learn to denoise even if it has not seen any clean images. The effectiveness of our method is based on the fact that CNNs naturally tend to capture low-level image statistics. Since our method utilizes the image prior implicitly captured by the deep denoising CNN to guide denoising, we refer to this training strategy as an Implicit Deep Denoiser Prior (IDDP). IDDP can be seen as a mixture of learning-based methods and traditional model-based denoising methods, in which regularization is adaptively formulated using the output of the network. We apply IDDP to various denoising tasks using only observed corrupted data and show that it achieves better denoising results than other self-supervised denoising methods.},
  archive   = {C_AAAI},
  author    = {Huangxing Lin and Yihong Zhuang and Xinghao Ding and Delu Zeng and Yue Huang and Xiaotong Tu and John Paisley},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25245},
  pages     = {1586-1594},
  title     = {Self-supervised image denoising using implicit deep denoiser prior},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Probability guided loss for long-tailed multi-label image
classification. <em>AAAI</em>, 1577–1585. (<a
href="https://doi.org/10.1609/aaai.v37i2.25244">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Long-tailed learning has attracted increasing attention in very recent years. Long-tailed multi-label image classification is one subtask and remains challenging and poorly researched. In this paper, we provide a fresh perspective from probability to tackle this problem. More specifically, we find that existing cost-sensitive learning methods for long-tailed multi-label classification will affect the predicted probability of positive and negative labels in varying degrees during training, and different processes of probability will affect the final performance in turn. We thus propose a probability guided loss which contains two components to control this process. One is the probability re-balancing which can flexibly adjust the process of training probability. And the other is the adaptive probability-aware focal which can further reduce the probability gap between positive and negative labels. We conduct extensive experiments on two long-tailed multi-label image classification datasets: VOC-LT and COCO-LT. The results demonstrate the rationality and superiority of our strategy.},
  archive   = {C_AAAI},
  author    = {Dekun Lin},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25244},
  pages     = {1577-1585},
  title     = {Probability guided loss for long-tailed multi-label image classification},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Actional atomic-concept learning for demystifying
vision-language navigation. <em>AAAI</em>, 1568–1576. (<a
href="https://doi.org/10.1609/aaai.v37i2.25243">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Vision-Language Navigation (VLN) is a challenging task which requires an agent to align complex visual observations to language instructions to reach the goal position. Most existing VLN agents directly learn to align the raw directional features and visual features trained using one-hot labels to linguistic instruction features. However, the big semantic gap among these multi-modal inputs makes the alignment difficult and therefore limits the navigation performance. In this paper, we propose Actional Atomic-Concept Learning (AACL), which maps visual observations to actional atomic concepts for facilitating the alignment. Specifically, an actional atomic concept is a natural language phrase containing an atomic action and an object, e.g., ``go up stairs&#39;&#39;. These actional atomic concepts, which serve as the bridge between observations and instructions, can effectively mitigate the semantic gap and simplify the alignment. AACL contains three core components: 1) a concept mapping module to map the observations to the actional atomic concept representations through the VLN environment and the recently proposed Contrastive Language-Image Pretraining (CLIP) model, 2) a concept refining adapter to encourage more instruction-oriented object concept extraction by re-ranking the predicted object concepts by CLIP, and 3) an observation co-embedding module which utilizes concept representations to regularize the observation representations. Our AACL establishes new state-of-the-art results on both fine-grained (R2R) and high-level (REVERIE and R2R-Last) VLN benchmarks. Moreover, the visualization shows that AACL significantly improves the interpretability in action decision. Code will be available at https://gitee.com/mindspore/models/tree/master/research/cv/VLN-AACL.},
  archive   = {C_AAAI},
  author    = {Bingqian Lin and Yi Zhu and Xiaodan Liang and Liang Lin and Jianzhuang Liu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25243},
  pages     = {1568-1576},
  title     = {Actional atomic-concept learning for demystifying vision-language navigation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Only a few classes confusing: Pixel-wise candidate labels
disambiguation for foggy scene understanding. <em>AAAI</em>, 1558–1567.
(<a href="https://doi.org/10.1609/aaai.v37i2.25242">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Not all semantics become confusing when deploying a semantic segmentation model for real-world scene understanding of adverse weather. The true semantics of most pixels have a high likelihood of appearing in the few top classes according to confidence ranking. In this paper, we replace the one-hot pseudo label with a candidate label set (CLS) that consists of only a few ambiguous classes and exploit its effects on self-training-based unsupervised domain adaptation. Specifically, we formulate the problem as a coarse-to-fine process. In the coarse-level process, adaptive CLS selection is proposed to pick a minimal set of confusing candidate labels based on the reliability of label predictions. Then, representation learning and label rectification are iteratively performed to facilitate feature clustering in an embedding space and to disambiguate the confusing semantics. Experimentally, our method outperforms the state-of-the-art methods on three realistic foggy benchmarks.},
  archive   = {C_AAAI},
  author    = {Liang Liao and Wenyi Chen and Zhen Zhang and Jing Xiao and Yan Yang and Chia-Wen Lin and Shin&#39;ichi Satoh},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25242},
  pages     = {1558-1567},
  title     = {Only a few classes confusing: Pixel-wise candidate labels disambiguation for foggy scene understanding},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Global dilated attention and target focusing network for
robust tracking. <em>AAAI</em>, 1549–1557. (<a
href="https://doi.org/10.1609/aaai.v37i2.25241">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Self Attention has shown the excellent performance in tracking due to its global modeling capability. However, it brings two challenges: First, its global receptive field has less attention on local structure and inter-channel associations, which limits the semantics to distinguish objects and backgrounds; Second, its feature fusion with linear process cannot avoid the interference of non-target semantic objects. To solve the above issues, this paper proposes a robust tracking method named GdaTFT by defining the Global Dilated Attention (GDA) and Target Focusing Network (TFN). The GDA provides a new global semantics modeling approach to enhance the semantic objects while eliminating the background. It is defined via the local focusing module, dilated attention and channel adaption module. Thus, it promotes semantics by focusing local key information, building long-range dependencies and enhancing the semantics of channels. Subsequently, to distinguish the target and non-target objects both with rich semantics, the TFN is proposed to accurately focus the target region. Different from the present feature fusion, it uses the template as the query to build a point-to-point correlation between the template and search region, and finally achieves part-level augmentation of target feature in the search region. Thus, the TFN efficiently augments the target embedding while weakening the non-target objects. Experiments on challenging benchmarks (LaSOT, TrackingNet, GOT-10k, OTB-100) demonstrate that the GdaTFT outperforms many state-of-the-art trackers and achieves leading performance. Code will be available.},
  archive   = {C_AAAI},
  author    = {Yun Liang and Qiaoqiao Li and Fumian Long},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25241},
  pages     = {1549-1557},
  title     = {Global dilated attention and target focusing network for robust tracking},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). HybridCap: Inertia-aid monocular capture of challenging
human motions. <em>AAAI</em>, 1539–1548. (<a
href="https://doi.org/10.1609/aaai.v37i2.25240">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Monocular 3D motion capture (mocap) is beneficial to many applications. The use of a single camera, however, often fails to handle occlusions of different body parts and hence it is limited to capture relatively simple movements. We present a light-weight, hybrid mocap technique called HybridCap that augments the camera with only 4 Inertial Measurement Units (IMUs) in a novel learning-and-optimization framework. We first employ a weakly-supervised and hierarchical motion inference module based on cooperative pure residual recurrent blocks that serve as limb, body and root trackers as well as an inverse kinematics solver. Our network effectively narrows the search space of plausible motions via coarse-to-fine pose estimation and manages to tackle challenging movements with high efficiency. We further develop a hybrid optimization scheme that combines inertial feedback and visual cues to improve tracking accuracy. Extensive experiments on various datasets demonstrate HybridCap can robustly handle challenging movements ranging from fitness actions to Latin dance. It also achieves real-time performance up to 60 fps with state-of-the-art accuracy.},
  archive   = {C_AAAI},
  author    = {Han Liang and Yannan He and Chengfeng Zhao and Mutian Li and Jingya Wang and Jingyi Yu and Lan Xu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25240},
  pages     = {1539-1548},
  title     = {HybridCap: Inertia-aid monocular capture of challenging human motions},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). CDTA: A cross-domain transfer-based attack with contrastive
learning. <em>AAAI</em>, 1530–1538. (<a
href="https://doi.org/10.1609/aaai.v37i2.25239">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Despite the excellent performance, deep neural networks (DNNs) have been shown to be vulnerable to adversarial examples. Besides, these examples are often transferable among different models. In other words, the same adversarial example can fool multiple models with different architectures at the same time. Based on this property, many black-box transfer-based attack techniques have been developed. However, current transfer-based attacks generally focus on the cross-architecture setting, where the attacker has access to the training data of the target model, which is not guaranteed in realistic situations. In this paper, we design a Cross-Domain Transfer-Based Attack (CDTA), which works in the cross-domain scenario. In this setting, attackers have no information about the target model, such as its architecture and training data. Specifically, we propose a contrastive spectral training method to train a feature extractor on a source domain (e.g., ImageNet) and use it to craft adversarial examples on target domains (e.g., Oxford 102 Flower). Our method corrupts the semantic information of the benign image by scrambling the outputs of both the intermediate feature layers and the final layer of the feature extractor. We evaluate CDTA with 16 target deep models on four datasets with widely varying styles. The results confirm that, in terms of the attack success rate, our approach can consistently outperform the state-of-the-art baselines by an average of 11.45\% across all target models. Our code is available at https://github.com/LiulietLee/CDTA.},
  archive   = {C_AAAI},
  author    = {Zihan Li and Weibin Wu and Yuxin Su and Zibin Zheng and Michael R. Lyu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25239},
  pages     = {1530-1538},
  title     = {CDTA: A cross-domain transfer-based attack with contrastive learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). READ: Large-scale neural scene rendering for autonomous
driving. <em>AAAI</em>, 1522–1529. (<a
href="https://doi.org/10.1609/aaai.v37i2.25238">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With the development of advanced driver assistance systems~(ADAS) and autonomous vehicles, conducting experiments in various scenarios becomes an urgent need. Although having been capable of synthesizing photo-realistic street scenes, conventional image-to-image translation methods cannot produce coherent scenes due to the lack of 3D information. In this paper, a large-scale neural rendering method is proposed to synthesize the autonomous driving scene~(READ), which makes it possible to generate large-scale driving scenes in real time on a PC through a variety of sampling schemes. In order to effectively represent driving scenarios, we propose an ω-net rendering network to learn neural descriptors from sparse point clouds. Our model can not only synthesize photo-realistic driving scenes but also stitch and edit them. The promising experimental results show that our model performs well in large-scale driving scenarios.},
  archive   = {C_AAAI},
  author    = {Zhuopeng Li and Lu Li and Jianke Zhu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25238},
  pages     = {1522-1529},
  title     = {READ: Large-scale neural scene rendering for autonomous driving},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Actionness inconsistency-guided contrastive learning for
weakly-supervised temporal action localization. <em>AAAI</em>,
1513–1521. (<a href="https://doi.org/10.1609/aaai.v37i2.25237">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Weakly-supervised temporal action localization (WTAL) aims to detect action instances given only video-level labels. To address the challenge, recent methods commonly employ a two-branch framework, consisting of a class-aware branch and a class-agnostic branch. In principle, the two branches are supposed to produce the same actionness activation. However, we observe that there are actually many inconsistent activation regions. These inconsistent regions usually contain some challenging segments whose semantic information (action or background) is ambiguous. In this work, we propose a novel Actionness Inconsistency-guided Contrastive Learning (AICL) method which utilizes the consistent segments to boost the representation learning of the inconsistent segments. Specifically, we first define the consistent and inconsistent segments by comparing the predictions of two branches and then construct positive and negative pairs between consistent segments and inconsistent segments for contrastive learning. In addition, to avoid the trivial case where there is no consistent sample, we introduce an action consistency constraint to control the difference between the two branches. We conduct extensive experiments on THUMOS14, ActivityNet v1.2, and ActivityNet v1.3 datasets, and the results show the effectiveness of AICL with state-of-the-art performance. Our code is available at https://github.com/lizhilin-ustc/AAAI2023-AICL.},
  archive   = {C_AAAI},
  author    = {Zhilin Li and Zilei Wang and Qinying Liu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25237},
  pages     = {1513-1521},
  title     = {Actionness inconsistency-guided contrastive learning for weakly-supervised temporal action localization},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Curriculum temperature for knowledge distillation.
<em>AAAI</em>, 1504–1512. (<a
href="https://doi.org/10.1609/aaai.v37i2.25236">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Most existing distillation methods ignore the flexible role of the temperature in the loss function and fix it as a hyper-parameter that can be decided by an inefficient grid search. In general, the temperature controls the discrepancy between two distributions and can faithfully determine the difficulty level of the distillation task. Keeping a constant temperature, i.e., a fixed level of task difficulty, is usually sub-optimal for a growing student during its progressive learning stages. In this paper, we propose a simple curriculum-based technique, termed Curriculum Temperature for Knowledge Distillation (CTKD), which controls the task difficulty level during the student&#39;s learning career through a dynamic and learnable temperature. Specifically, following an easy-to-hard curriculum, we gradually increase the distillation loss w.r.t. the temperature, leading to increased distillation difficulty in an adversarial manner. As an easy-to-use plug-in technique, CTKD can be seamlessly integrated into existing knowledge distillation frameworks and brings general improvements at a negligible additional computation cost. Extensive experiments on CIFAR-100, ImageNet-2012, and MS-COCO demonstrate the effectiveness of our method.},
  archive   = {C_AAAI},
  author    = {Zheng Li and Xiang Li and Lingfeng Yang and Borui Zhao and Renjie Song and Lei Luo and Jun Li and Jian Yang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25236},
  pages     = {1504-1512},
  title     = {Curriculum temperature for knowledge distillation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Learning single image defocus deblurring with misaligned
training pairs. <em>AAAI</em>, 1495–1503. (<a
href="https://doi.org/10.1609/aaai.v37i2.25235">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {By adopting popular pixel-wise loss, existing methods for defocus deblurring heavily rely on well aligned training image pairs. Although training pairs of ground-truth and blurry images are carefully collected, e.g., DPDD dataset, misalignment is inevitable between training pairs, making existing methods possibly suffer from deformation artifacts. In this paper, we propose a joint deblurring and reblurring learning (JDRL) framework for single image defocus deblurring with misaligned training pairs. Generally, JDRL consists of a deblurring module and a spatially invariant reblurring module, by which deblurred result can be adaptively supervised by ground-truth image to recover sharp textures while maintaining spatial consistency with the blurry image. First, in the deblurring module, a bi-directional optical flow-based deformation is introduced to tolerate spatial misalignment between deblurred and ground-truth images. Second, in the reblurring module, deblurred result is reblurred to be spatially aligned with blurry image, by predicting a set of isotropic blur kernels and weighting maps. Moreover, we establish a new single image defocus deblurring (SDD) dataset, further validating our JDRL and also benefiting future research. Our JDRL can be applied to boost defocus deblurring networks in terms of both quantitative metrics and visual quality on DPDD, RealDOF and our SDD datasets.},
  archive   = {C_AAAI},
  author    = {Yu Li and Dongwei Ren and Xinya Shu and Wangmeng Zuo},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25235},
  pages     = {1495-1503},
  title     = {Learning single image defocus deblurring with misaligned training pairs},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). BEVStereo: Enhancing depth estimation in multi-view 3D
object detection with temporal stereo. <em>AAAI</em>, 1486–1494. (<a
href="https://doi.org/10.1609/aaai.v37i2.25234">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Restricted by the ability of depth perception, all Multi-view 3D object detection methods fall into the bottleneck of depth accuracy. By constructing temporal stereo, depth estimation is quite reliable in indoor scenarios. However, there are two difficulties in directly integrating temporal stereo into outdoor multi-view 3D object detectors: 1) The construction of temporal stereos for all views results in high computing costs. 2) Unable to adapt to challenging outdoor scenarios. In this study, we propose an effective method for creating temporal stereo by dynamically determining the center and range of the temporal stereo. The most confident center is found using the EM algorithm. Numerous experiments on nuScenes have shown the BEVStereo&#39;s ability to deal with complex outdoor scenarios that other stereo-based methods are unable to handle. For the first time, a stereo-based approach shows superiority in scenarios like a static ego vehicle and moving objects. BEVStereo achieves the new state-of-the-art in the camera-only track of nuScenes dataset while maintaining memory efficiency. Codes have been released.},
  archive   = {C_AAAI},
  author    = {Yinhao Li and Han Bao and Zheng Ge and Jinrong Yang and Jianjian Sun and Zeming Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25234},
  pages     = {1486-1494},
  title     = {BEVStereo: Enhancing depth estimation in multi-view 3D object detection with temporal stereo},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). BEVDepth: Acquisition of reliable depth for multi-view 3D
object detection. <em>AAAI</em>, 1477–1485. (<a
href="https://doi.org/10.1609/aaai.v37i2.25233">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this research, we propose a new 3D object detector with a trustworthy depth estimation, dubbed BEVDepth, for camera-based Bird&#39;s-Eye-View~(BEV) 3D object detection. Our work is based on a key observation -- depth estimation in recent approaches is surprisingly inadequate given the fact that depth is essential to camera 3D detection. Our BEVDepth resolves this by leveraging explicit depth supervision. A camera-awareness depth estimation module is also introduced to facilitate the depth predicting capability. Besides, we design a novel Depth Refinement Module to counter the side effects carried by imprecise feature unprojection. Aided by customized Efficient Voxel Pooling and multi-frame mechanism, BEVDepth achieves the new state-of-the-art 60.9\% NDS on the challenging nuScenes test set while maintaining high efficiency. For the first time, the NDS score of a camera model reaches 60\%. Codes have been released.},
  archive   = {C_AAAI},
  author    = {Yinhao Li and Zheng Ge and Guanyi Yu and Jinrong Yang and Zengran Wang and Yukang Shi and Jianjian Sun and Zeming Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25233},
  pages     = {1477-1485},
  title     = {BEVDepth: Acquisition of reliable depth for multi-view 3D object detection},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Towards real-time segmentation on the edge. <em>AAAI</em>,
1468–1476. (<a href="https://doi.org/10.1609/aaai.v37i2.25232">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The research in real-time segmentation mainly focuses on desktop GPUs. However, autonomous driving and many other applications rely on real-time segmentation on the edge, and current arts are far from the goal. In addition, recent advances in vision transformers also inspire us to re-design the network architecture for dense prediction task. In this work, we propose to combine the self attention block with lightweight convolutions to form new building blocks, and employ latency constraints to search an efficient sub-network. We train an MLP latency model based on generated architecture configurations and their latency measured on mobile devices, so that we can predict the latency of subnets during search phase. To the best of our knowledge, we are the first to achieve over 74\% mIoU on Cityscapes with semi-real-time inference (over 15 FPS) on mobile GPU from an off-the-shelf phone.},
  archive   = {C_AAAI},
  author    = {Yanyu Li and Changdi Yang and Pu Zhao and Geng Yuan and Wei Niu and Jiexiong Guan and Hao Tang and Minghai Qin and Qing Jin and Bin Ren and Xue Lin and Yanzhi Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25232},
  pages     = {1468-1476},
  title     = {Towards real-time segmentation on the edge},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Gradient corner pooling for keypoint-based object
detection. <em>AAAI</em>, 1460–1467. (<a
href="https://doi.org/10.1609/aaai.v37i2.25231">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Detecting objects as multiple keypoints is an important approach in the anchor-free object detection methods while corner pooling is an effective feature encoding method for corner positioning. The corners of the bounding box are located by summing the feature maps which are max-pooled in the x and y directions respectively by corner pooling. In the unidirectional max pooling operation, the features of the densely arranged objects of the same class are prone to occlusion. To this end, we propose a method named Gradient Corner Pooling. The spatial distance information of objects on the feature map is encoded during the unidirectional pooling process, which effectively alleviates the occlusion of the homogeneous object features. Further, the computational complexity of gradient corner pooling is the same as traditional corner pooling and hence it can be implemented efficiently. Gradient corner pooling obtains consistent improvements for various keypoint-based methods by directly replacing corner pooling. We verify the gradient corner pooling algorithm on the dataset and in real scenarios, respectively. The networks with gradient corner pooling located the corner points earlier in the training process and achieve an average accuracy improvement of 0.2\%-1.6\% on the MS-COCO dataset. The detectors with gradient corner pooling show better angle adaptability for arrayed objects in the actual scene test.},
  archive   = {C_AAAI},
  author    = {Xuyang Li and Xuemei Xie and Mingxuan Yu and Jiakai Luo and Chengwei Rao and Guangming Shi},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25231},
  pages     = {1460-1467},
  title     = {Gradient corner pooling for keypoint-based object detection},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MEID: Mixture-of-experts with internal distillation for
long-tailed video recognition. <em>AAAI</em>, 1451–1459. (<a
href="https://doi.org/10.1609/aaai.v37i2.25230">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The long-tailed video recognition problem is especially challenging, as videos tend to be long and untrimmed, and each video may contain multiple classes, causing frame-level class imbalance. The previous method tackles the long-tailed video recognition only through frame-level sampling for class re-balance without distinguishing the frame-level feature representation between head and tail classes. To improve the frame-level feature representation of tail classes, we modulate the frame-level features with an auxiliary distillation loss to reduce the distribution distance between head and tail classes. Moreover, we design a mixture-of-experts framework with two different expert designs, i.e., the first expert with an attention-based classification network handling the original long-tailed distribution, and the second expert dealing with the re-balanced distribution from class-balanced sampling. Notably, in the second expert, we specifically focus on the frames unsolved by the first expert through designing a complementary frame selection module, which inherits the attention weights from the first expert and selects frames with low attention weights, and we also enhance the motion feature representation for these selected frames. To highlight the multi-label challenge in long-tailed video recognition, we create two additional benchmarks based on Charades and CharadesEgo videos with the multi-label property, called CharadesLT and CharadesEgoLT. Extensive experiments are conducted on the existing long-tailed video benchmark VideoLT and the two new benchmarks to verify the effectiveness of our proposed method with state-of-the-art performance. The code and proposed benchmarks are released at https://github.com/VisionLanguageLab/MEID.},
  archive   = {C_AAAI},
  author    = {Xinjie Li and Huijuan Xu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25230},
  pages     = {1451-1459},
  title     = {MEID: Mixture-of-experts with internal distillation for long-tailed video recognition},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adaptive texture filtering for single-domain generalized
segmentation. <em>AAAI</em>, 1442–1450. (<a
href="https://doi.org/10.1609/aaai.v37i2.25229">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Domain generalization in semantic segmentation aims to alleviate the performance degradation on unseen domains through learning domain-invariant features. Existing methods diversify images in the source domain by adding complex or even abnormal textures to reduce the sensitivity to domain-specific features. However, these approaches depends heavily on the richness of the texture bank and training them can be time-consuming. In contrast to importing textures arbitrarily or augmenting styles randomly, we focus on the single source domain itself to achieve the generalization. In this paper, we present a novel adaptive texture filtering mechanism to suppress the influence of texture without using augmentation, thus eliminating the interference of domain-specific features. Further, we design a hierarchical guidance generalization network equipped with structure-guided enhancement modules, which purpose to learn the domain-invariant generalized knowledge. Extensive experiments together with ablation studies on widely-used datasets are conducted to verify the effectiveness of the proposed model, and reveal its superiority over other state-of-the-art alternatives.},
  archive   = {C_AAAI},
  author    = {Xinhui Li and Mingjia Li and Yaxing Wang and Chuan-Xian Ren and Xiaojie Guo},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25229},
  pages     = {1442-1450},
  title     = {Adaptive texture filtering for single-domain generalized segmentation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). LWSIS: LiDAR-guided weakly supervised instance segmentation
for autonomous driving. <em>AAAI</em>, 1433–1441. (<a
href="https://doi.org/10.1609/aaai.v37i2.25228">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Image instance segmentation is a fundamental research topic in autonomous driving, which is crucial for scene understanding and road safety. Advanced learning-based approaches often rely on the costly 2D mask annotations for training. In this paper, we present a more artful framework, LiDAR-guided Weakly Supervised Instance Segmentation (LWSIS), which leverages the off-the-shelf 3D data, i.e., Point Cloud, together with the 3D boxes, as natural weak supervisions for training the 2D image instance segmentation models. Our LWSIS not only exploits the complementary information in multimodal data during training but also significantly reduces the annotation cost of the dense 2D masks. In detail, LWSIS consists of two crucial modules, Point Label Assignment (PLA) and Graph-based Consistency Regularization (GCR). The former module aims to automatically assign the 3D point cloud as 2D point-wise labels, while the atter further refines the predictions by enforcing geometry and appearance consistency of the multimodal data. Moreover, we conduct a secondary instance segmentation annotation on the nuScenes, named nuInsSeg, to encourage further research on multimodal perception tasks. Extensive experiments on the nuInsSeg, as well as the large-scale Waymo, show that LWSIS can substantially improve existing weakly supervised segmentation models by only involving 3D data during training. Additionally, LWSIS can also be incorporated into 3D object detectors like PointPainting to boost the 3D detection performance for free. The code and dataset are available at https://github.com/Serenos/LWSIS.},
  archive   = {C_AAAI},
  author    = {Xiang Li and Junbo Yin and Botian Shi and Yikang Li and Ruigang Yang and Jianbing Shen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25228},
  pages     = {1433-1441},
  title     = {LWSIS: LiDAR-guided weakly supervised instance segmentation for autonomous driving},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Panoramic video salient object detection with ambisonic
audio guidance. <em>AAAI</em>, 1424–1432. (<a
href="https://doi.org/10.1609/aaai.v37i2.25227">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Video salient object detection (VSOD), as a fundamental computer vision problem, has been extensively discussed in the last decade. However, all existing works focus on addressing the VSOD problem in 2D scenarios. With the rapid development of VR devices, panoramic videos have been a promising alternative to 2D videos to provide immersive feelings of the real world. In this paper, we aim to tackle the video salient object detection problem for panoramic videos, with their corresponding ambisonic audios. A multimodal fusion module equipped with two pseudo-siamese audio-visual context fusion (ACF) blocks is proposed to effectively conduct audio-visual interaction. The ACF block equipped with spherical positional encoding enables the fusion in the 3D context to capture the spatial correspondence between pixels and sound sources from the equirectangular frames and ambisonic audios. Experimental results verify the effectiveness of our proposed components and demonstrate that our method achieves state-of-the-art performance on the ASOD60K dataset.},
  archive   = {C_AAAI},
  author    = {Xiang Li and Haoyuan Cao and Shijie Zhao and Junlin Li and Li Zhang and Bhiksha Raj},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25227},
  pages     = {1424-1432},
  title     = {Panoramic video salient object detection with ambisonic audio guidance},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DC-former: Diverse and compact transformer for person
re-identification. <em>AAAI</em>, 1415–1423. (<a
href="https://doi.org/10.1609/aaai.v37i2.25226">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In person re-identification (ReID) task, it is still challenging to learn discriminative representation by deep learning, due to limited data. Generally speaking, the model will get better performance when increasing the amount of data. The addition of similar classes strengthens the ability of the classifier to identify similar identities, thereby improving the discrimination of representation. In this paper, we propose a Diverse and Compact Transformer (DC-Former) that can achieve a similar effect by splitting embedding space into multiple diverse and compact subspaces. Compact embedding subspace helps model learn more robust and discriminative embedding to identify similar classes. And the fusion of these diverse embeddings containing more fine-grained information can further improve the effect of ReID. Specifically, multiple class tokens are used in vision transformer to represent multiple embedding spaces. Then, a self-diverse constraint (SDC) is applied to these spaces to push them away from each other, which makes each embedding space diverse and compact. Further, a dynamic weight controller (DWC) is further designed for balancing the relative importance among them during training. The experimental results of our method are promising, which surpass previous state-of-the-art methods on several commonly used person ReID benchmarks. Our code is available at https://github.com/ant-research/Diverse-and-Compact-Transformer.},
  archive   = {C_AAAI},
  author    = {Wen Li and Cheng Zou and Meng Wang and Furong Xu and Jianan Zhao and Ruobing Zheng and Yuan Cheng and Wei Chu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i2.25226},
  pages     = {1415-1423},
  title     = {DC-former: Diverse and compact transformer for person re-identification},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CLIP-ReID: Exploiting vision-language model for image
re-identification without concrete text labels. <em>AAAI</em>,
1405–1413. (<a href="https://doi.org/10.1609/aaai.v37i1.25225">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Pre-trained vision-language models like CLIP have recently shown superior performances on various downstream tasks, including image classification and segmentation. However, in fine-grained image re-identification (ReID), the labels are indexes, lacking concrete text descriptions. Therefore, it remains to be determined how such models could be applied to these tasks. This paper first finds out that simply fine-tuning the visual model initialized by the image encoder in CLIP, has already obtained competitive performances in various ReID tasks. Then we propose a two-stage strategy to facilitate a better visual representation. The key idea is to fully exploit the cross-modal description ability in CLIP through a set of learnable text tokens for each ID and give them to the text encoder to form ambiguous descriptions. In the first training stage, image and text encoders from CLIP keep fixed, and only the text tokens are optimized from scratch by the contrastive loss computed within a batch. In the second stage, the ID-specific text tokens and their encoder become static, providing constraints for fine-tuning the image encoder. With the help of the designed loss in the downstream task, the image encoder is able to represent data as vectors in the feature embedding accurately. The effectiveness of the proposed strategy is validated on several datasets for the person or vehicle ReID tasks. Code is available at https://github.com/Syliz517/CLIP-ReID.},
  archive   = {C_AAAI},
  author    = {Siyuan Li and Li Sun and Qingli Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25225},
  pages     = {1405-1413},
  title     = {CLIP-ReID: Exploiting vision-language model for image re-identification without concrete text labels},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). NeAF: Learning neural angle fields for point normal
estimation. <em>AAAI</em>, 1396–1404. (<a
href="https://doi.org/10.1609/aaai.v37i1.25224">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Normal estimation for unstructured point clouds is an important task in 3D computer vision. Current methods achieve encouraging results by mapping local patches to normal vectors or learning local surface fitting using neural networks. However, these methods are not generalized well to unseen scenarios and are sensitive to parameter settings. To resolve these issues, we propose an implicit function to learn an angle field around the normal of each point in the spherical coordinate system, which is dubbed as Neural Angle Fields (NeAF). Instead of directly predicting the normal of an input point, we predict the angle offset between the ground truth normal and a randomly sampled query normal. This strategy pushes the network to observe more diverse samples, which leads to higher prediction accuracy in a more robust manner. To predict normals from the learned angle fields at inference time, we randomly sample query vectors in a unit spherical space and take the vectors with minimal angle values as the predicted normals. To further leverage the prior learned by NeAF, we propose to refine the predicted normal vectors by minimizing the angle offsets. The experimental results with synthetic data and real scans show significant improvements over the state-of-the-art under widely used benchmarks. Project page: https://lisj575.github.io/NeAF/.},
  archive   = {C_AAAI},
  author    = {Shujuan Li and Junsheng Zhou and Baorui Ma and Yu-Shen Liu and Zhizhong Han},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25224},
  pages     = {1396-1404},
  title     = {NeAF: Learning neural angle fields for point normal estimation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). Layout-aware dreamer for embodied visual referring
expression grounding. <em>AAAI</em>, 1386–1395. (<a
href="https://doi.org/10.1609/aaai.v37i1.25223">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this work, we study the problem of Embodied Referring Expression Grounding, where an agent needs to navigate in a previously unseen environment and localize a remote object described by a concise high-level natural language instruction. When facing such a situation, a human tends to imagine what the destination may look like and to explore the environment based on prior knowledge of the environmental layout, such as the fact that a bathroom is more likely to be found near a bedroom than a kitchen. We have designed an autonomous agent called Layout-aware Dreamer (LAD), including two novel modules, that is, the Layout Learner and the Goal Dreamer to mimic this cognitive decision process. The Layout Learner learns to infer the room category distribution of neighboring unexplored areas along the path for coarse layout estimation, which effectively introduces layout common sense of room-to-room transitions to our agent. To learn an effective exploration of the environment, the Goal Dreamer imagines the destination beforehand. Our agent achieves new state-of-the-art performance on the public leaderboard of REVERIE dataset in challenging unseen test environments with improvement on navigation success rate (SR) by 4.02\% and remote grounding success (RGS) by 3.43\% comparing to previous previous state of the art. The code is released at https://github.com/zehao-wang/LAD.},
  archive   = {C_AAAI},
  author    = {Mingxiao Li and Zehao Wang and Tinne Tuytelaars and Marie-Francine Moens},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25223},
  pages     = {1386-1395},
  title     = {Layout-aware dreamer for embodied visual referring expression grounding},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Learning semantic alignment with global modality
reconstruction for video-language pre-training towards retrieval.
<em>AAAI</em>, 1377–1385. (<a
href="https://doi.org/10.1609/aaai.v37i1.25222">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Video-language pre-training for text-based video retrieval tasks is vitally important. Previous pre-training methods suffer from the semantic misalignments. The reason is that these methods ignore sequence alignments but focusing on critical token alignment. To alleviate the problem, we propose a video-language pre-training framework, termed videolanguage pre-training For lEarning sEmantic aLignments (FEEL), to learn semantic alignments at the sequence level. Specifically, the global modality reconstruction and the cross- modal self-contrasting method is utilized to learn the alignments at the sequence level better. Extensive experimental results demonstrate the effectiveness of FEEL on text-based video retrieval and text-based video corpus moment retrieval.},
  archive   = {C_AAAI},
  author    = {Mingchao Li and Xiaoming Shi and Haitao Leng and Wei Zhou and Hai-Tao Zheng and Kuncai Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25222},
  pages     = {1377-1385},
  title     = {Learning semantic alignment with global modality reconstruction for video-language pre-training towards retrieval},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Spatial-spectral transformer for hyperspectral image
denoising. <em>AAAI</em>, 1368–1376. (<a
href="https://doi.org/10.1609/aaai.v37i1.25221">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Hyperspectral image (HSI) denoising is a crucial preprocessing procedure for the subsequent HSI applications. Unfortunately, though witnessing the development of deep learning in HSI denoising area, existing convolution-based methods face the trade-off between computational efficiency and capability to model non-local characteristics of HSI. In this paper, we propose a Spatial-Spectral Transformer (SST) to alleviate this problem. To fully explore intrinsic similarity characteristics in both spatial dimension and spectral dimension, we conduct non-local spatial self-attention and global spectral self-attention with Transformer architecture. The window-based spatial self-attention focuses on the spatial similarity beyond the neighboring region. While, the spectral self-attention exploits the long-range dependencies between highly correlative bands. Experimental results show that our proposed method outperforms the state-of-the-art HSI denoising methods in quantitative quality and visual results. The code is released at https://github.com/MyuLi/SST.},
  archive   = {C_AAAI},
  author    = {Miaoyu Li and Ying Fu and Yulun Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25221},
  pages     = {1368-1376},
  title     = {Spatial-spectral transformer for hyperspectral image denoising},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). Stroke extraction of chinese character based on deep
structure deformable image registration. <em>AAAI</em>, 1360–1367. (<a
href="https://doi.org/10.1609/aaai.v37i1.25220">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Stroke extraction of Chinese characters plays an important role in the field of character recognition and generation. The most existing character stroke extraction methods focus on image morphological features. These methods usually lead to errors of cross strokes extraction and stroke matching due to rarely using stroke semantics and prior information. In this paper, we propose a deep learning-based character stroke extraction method that takes semantic features and prior information of strokes into consideration. This method consists of three parts: image registration-based stroke registration that establishes the rough registration of the reference strokes and the target as prior information; image semantic segmentation-based stroke segmentation that preliminarily separates target strokes into seven categories; and high-precision extraction of single strokes. In the stroke registration, we propose a structure deformable image registration network to achieve structure-deformable transformation while maintaining the stable morphology of single strokes for character images with complex structures. In order to verify the effectiveness of the method, we construct two datasets respectively for calligraphy characters and regular handwriting characters. The experimental results show that our method strongly outperforms the baselines. Code is available at https://github.com/MengLi-l1/StrokeExtraction.},
  archive   = {C_AAAI},
  author    = {Meng Li and Yahan Yu and Yi Yang and Guanghao Ren and Jian Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25220},
  pages     = {1360-1367},
  title     = {Stroke extraction of chinese character based on deep structure deformable image registration},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning polysemantic spoof trace: A multi-modal
disentanglement network for face anti-spoofing. <em>AAAI</em>,
1351–1359. (<a href="https://doi.org/10.1609/aaai.v37i1.25219">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Along with the widespread use of face recognition systems, their vulnerability has become highlighted. While existing face anti-spoofing methods can be generalized between attack types, generic solutions are still challenging due to the diversity of spoof characteristics. Recently, the spoof trace disentanglement framework has shown great potential for coping with both seen and unseen spoof scenarios, but the performance is largely restricted by the single-modal input. This paper focuses on this issue and presents a multi-modal disentanglement model which targetedly learns polysemantic spoof traces for more accurate and robust generic attack detection. In particular, based on the adversarial learning mechanism, a two-stream disentangling network is designed to estimate spoof patterns from the RGB and depth inputs, respectively. In this case, it captures complementary spoofing clues inhering in different attacks. Furthermore, a fusion module is exploited, which recalibrates both representations at multiple stages to promote the disentanglement in each individual modality. It then performs cross-modality aggregation to deliver a more comprehensive spoof trace representation for prediction. Extensive evaluations are conducted on multiple benchmarks, demonstrating that learning polysemantic spoof traces favorably contributes to anti-spoofing with more perceptible and interpretable results.},
  archive   = {C_AAAI},
  author    = {Kaicheng Li and Hongyu Yang and Binghui Chen and Pengyu Li and Biao Wang and Di Huang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25219},
  pages     = {1351-1359},
  title     = {Learning polysemantic spoof trace: A multi-modal disentanglement network for face anti-spoofing},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). FSR: A general frequency-oriented framework to accelerate
image super-resolution networks. <em>AAAI</em>, 1343–1350. (<a
href="https://doi.org/10.1609/aaai.v37i1.25218">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep neural networks (DNNs) have witnessed remarkable achievement in image super-resolution (SR), and plenty of DNN-based SR models with elaborated network designs have recently been proposed. However, existing methods usually require substantial computations by operating in spatial domain. To address this issue, we propose a general frequency-oriented framework (FSR) to accelerate SR networks by considering data characteristics in frequency domain. Our FSR mainly contains dual feature aggregation module (DFAM) to extract informative features in both spatial and transform domains, followed by a four-path SR-Module with different capacities to super-resolve in the frequency domain. Specifically, DFAM further consists of a transform attention block (TABlock) and a spatial context block (SCBlock) to extract global spectral information and local spatial information, respectively, while SR-Module is a parallel network container that contains four to-be-accelerated branches. Furthermore, we propose an adaptive weight strategy for a trade-off between image details recovery and visual quality. Extensive experiments show that our FSR can save FLOPs by almost 40\% while reducing inference time by 50\% for other SR methods (e.g., FSRCNN, CARN, SRResNet and RCAN). Code is available at https://github.com/THU-Kingmin/FSR.},
  archive   = {C_AAAI},
  author    = {Jinmin Li and Tao Dai and Mingyan Zhu and Bin Chen and Zhi Wang and Shu-Tao Xia},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25218},
  pages     = {1343-1350},
  title     = {FSR: A general frequency-oriented framework to accelerate image super-resolution networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning motion-robust remote photoplethysmography through
arbitrary resolution videos. <em>AAAI</em>, 1334–1342. (<a
href="https://doi.org/10.1609/aaai.v37i1.25217">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Remote photoplethysmography (rPPG) enables non-contact heart rate (HR) estimation from facial videos which gives significant convenience compared with traditional contact-based measurements. In the real-world long-term health monitoring scenario, the distance of the participants and their head movements usually vary by time, resulting in the inaccurate rPPG measurement due to the varying face resolution and complex motion artifacts. Different from the previous rPPG models designed for a constant distance between camera and participants, in this paper, we propose two plug-and-play blocks (i.e., physiological signal feature extraction block (PFE) and temporal face alignment block (TFA)) to alleviate the degradation of changing distance and head motion. On one side, guided with representative-area information, PFE adaptively encodes the arbitrary resolution facial frames to the fixed-resolution facial structure features. On the other side, leveraging the estimated optical flow, TFA is able to counteract the rPPG signal confusion caused by the head movement thus benefit the motion-robust rPPG signal recovery. Besides, we also train the model with a cross-resolution constraint using a two-stream dual-resolution framework, which further helps PFE learn resolution-robust facial rPPG features. Extensive experiments on three benchmark datasets (UBFC-rPPG, COHFACE and PURE) demonstrate the superior performance of the proposed method. One highlight is that with PFE and TFA, the off-the-shelf spatio-temporal rPPG models can predict more robust rPPG signals under both varying face resolution and severe head movement scenarios. The codes are available at https://github.com/LJWGIT/Arbitrary_Resolution_rPPG.},
  archive   = {C_AAAI},
  author    = {Jianwei Li and Zitong Yu and Jingang Shi},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25217},
  pages     = {1334-1342},
  title     = {Learning motion-robust remote photoplethysmography through arbitrary resolution videos},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Disentangle and remerge: Interventional knowledge
distillation for few-shot object detection from a conditional causal
perspective. <em>AAAI</em>, 1323–1333. (<a
href="https://doi.org/10.1609/aaai.v37i1.25216">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Few-shot learning models learn representations with limited human annotations, and such a learning paradigm demonstrates practicability in various tasks, e.g., image classification, object detection, etc. However, few-shot object detection methods suffer from an intrinsic defect that the limited training data makes the model cannot sufficiently explore semantic information. To tackle this, we introduce knowledge distillation to the few-shot object detection learning paradigm. We further run a motivating experiment, which demonstrates that in the process of knowledge distillation, the empirical error of the teacher model degenerates the prediction performance of the few-shot object detection model as the student. To understand the reasons behind this phenomenon, we revisit the learning paradigm of knowledge distillation on the few-shot object detection task from the causal theoretic standpoint, and accordingly, develop a Structural Causal Model. Following the theoretical guidance, we propose a backdoor adjustment-based knowledge distillation method for the few-shot object detection task, namely Disentangle and Remerge (D&amp;R), to perform conditional causal intervention toward the corresponding Structural Causal Model. Empirically, the experiments on benchmarks demonstrate that D&amp;R can yield significant performance boosts in few-shot object detection. Code is available at https://github.com/ZYN-1101/DandR.git.},
  archive   = {C_AAAI},
  author    = {Jiangmeng Li and Yanan Zhang and Wenwen Qiang and Lingyu Si and Chengbo Jiao and Xiaohui Hu and Changwen Zheng and Fuchun Sun},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25216},
  pages     = {1323-1333},
  title     = {Disentangle and remerge: Interventional knowledge distillation for few-shot object detection from a conditional causal perspective},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Real-world deep local motion deblurring. <em>AAAI</em>,
1314–1322. (<a href="https://doi.org/10.1609/aaai.v37i1.25215">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Most existing deblurring methods focus on removing global blur caused by camera shake, while they cannot well handle local blur caused by object movements. To fill the vacancy of local deblurring in real scenes, we establish the first real local motion blur dataset (ReLoBlur), which is captured by a synchronized beam-splitting photographing system and corrected by a post-progressing pipeline. Based on ReLoBlur, we propose a Local Blur-Aware Gated network (LBAG) and several local blur-aware techniques to bridge the gap between global and local deblurring: 1) a blur detection approach based on background subtraction to localize blurred regions; 2) a gate mechanism to guide our network to focus on blurred regions; and 3) a blur-aware patch cropping strategy to address data imbalance problem. Extensive experiments prove the reliability of ReLoBlur dataset, and demonstrate that LBAG achieves better performance than state-of-the-art global deblurring methods and our proposed local blur-aware techniques are effective.},
  archive   = {C_AAAI},
  author    = {Haoying Li and Ziran Zhang and Tingting Jiang and Peng Luo and Huajun Feng and Zhihai Xu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25215},
  pages     = {1314-1322},
  title     = {Real-world deep local motion deblurring},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CEE-net: Complementary end-to-end network for 3D human pose
generation and estimation. <em>AAAI</em>, 1305–1313. (<a
href="https://doi.org/10.1609/aaai.v37i1.25214">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The limited number of actors and actions in existing datasets make 3D pose estimators tend to overfit, which can be seen from the performance degradation of the algorithm on cross-datasets, especially for rare and complex poses. Although previous data augmentation works have increased the diversity of the training set, the changes in camera viewpoint and position play a dominant role in improving the accuracy of the estimator, while the generated 3D poses are limited and still heavily rely on the source dataset. In addition, these works do not consider the adaptability of the pose estimator to generated data, and complex poses will cause training collapse. In this paper, we propose the CEE-Net, a Complementary End-to-End Network for 3D human pose generation and estimation. The generator extremely expands the distribution of each joint-angle in the existing dataset and limits them to a reasonable range. By learning the correlations within and between the torso and limbs, the estimator can combine different body-parts more effectively and weaken the influence of specific joint-angle changes on the global pose, improving the generalization ability. Extensive ablation studies show that our pose generator greatly strengthens the joint-angle distribution, and our pose estimator can utilize these poses positively. Compared with the state-of-the-art methods, our method can achieve much better performance on various cross-datasets, rare and complex poses.},
  archive   = {C_AAAI},
  author    = {Haolun Li and Chi-Man Pun},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25214},
  pages     = {1305-1313},
  title     = {CEE-net: Complementary end-to-end network for 3D human pose generation and estimation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Pose-oriented transformer with uncertainty-guided
refinement for 2D-to-3D human pose estimation. <em>AAAI</em>, 1296–1304.
(<a href="https://doi.org/10.1609/aaai.v37i1.25213">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {There has been a recent surge of interest in introducing transformers to 3D human pose estimation (HPE) due to their powerful capabilities in modeling long-term dependencies. However, existing transformer-based methods treat body joints as equally important inputs and ignore the prior knowledge of human skeleton topology in the self-attention mechanism. To tackle this issue, in this paper, we propose a Pose-Oriented Transformer (POT) with uncertainty guided refinement for 3D HPE. Specifically, we first develop novel pose-oriented self-attention mechanism and distance-related position embedding for POT to explicitly exploit the human skeleton topology. The pose-oriented self-attention mechanism explicitly models the topological interactions between body joints, whereas the distance-related position embedding encodes the distance of joints to the root joint to distinguish groups of joints with different difficulties in regression. Furthermore, we present an Uncertainty-Guided Refinement Network (UGRN) to refine pose predictions from POT, especially for the difficult joints, by considering the estimated uncertainty of each joint with uncertainty-guided sampling strategy and self-attention mechanism. Extensive experiments demonstrate that our method significantly outperforms the state-of-the-art methods with reduced model parameters on 3D HPE benchmarks such as Human3.6M and MPI-INF-3DHP.},
  archive   = {C_AAAI},
  author    = {Han Li and Bowen Shi and Wenrui Dai and Hongwei Zheng and Botao Wang and Yu Sun and Min Guo and Chenglin Li and Junni Zou and Hongkai Xiong},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25213},
  pages     = {1296-1304},
  title     = {Pose-oriented transformer with uncertainty-guided refinement for 2D-to-3D human pose estimation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Frequency domain disentanglement for arbitrary neural style
transfer. <em>AAAI</em>, 1287–1295. (<a
href="https://doi.org/10.1609/aaai.v37i1.25212">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Arbitrary neural style transfer has been a popular research topic due to its rich application scenarios. Effective disentanglement of content and style is the critical factor for synthesizing an image with arbitrary style. The existing methods focus on disentangling feature representations of content and style in the spatial domain where the content and style components are innately entangled and difficult to be disentangled clearly. Therefore, these methods always suffer from low-quality results because of the sub-optimal disentanglement. To address such a challenge, this paper proposes the frequency mixer (FreMixer) module that disentangles and re-entangles the frequency spectrum of content and style components in the frequency domain. Since content and style components have different frequency-domain characteristics (frequency bands and frequency patterns), the FreMixer could well disentangle these two components. Based on the FreMixer module, we design a novel Frequency Domain Disentanglement (FDD) framework for arbitrary neural style transfer. Qualitative and quantitative experiments verify that the proposed method can render better stylized results compared to the state-of-the-art methods.},
  archive   = {C_AAAI},
  author    = {Dongyang Li and Hao Luo and Pichao Wang and Zhibin Wang and Shang Liu and Fan Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25212},
  pages     = {1287-1295},
  title     = {Frequency domain disentanglement for arbitrary neural style transfer},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SWBNet: A stable white balance network for sRGB images.
<em>AAAI</em>, 1278–1286. (<a
href="https://doi.org/10.1609/aaai.v37i1.25211">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The white balance methods for sRGB images (sRGB-WB) aim to directly remove their color temperature shifts. Despite achieving promising white balance (WB) performance, the existing methods suffer from WB instability, i.e., their results are inconsistent for images with different color temperatures. We propose a stable white balance network (SWBNet) to alleviate this problem. It learns the color temperature-insensitive features to generate white-balanced images, resulting in consistent WB results. Specifically, the color temperatureinsensitive features are learned by implicitly suppressing lowfrequency information sensitive to color temperatures. Then, a color temperature contrastive loss is introduced to facilitate the most information shared among features of the same scene and different color temperatures. This way, features from the same scene are more insensitive to color temperatures regardless of the inputs. We also present a color temperature sensitivity-oriented transformer that globally perceives multiple color temperature shifts within an image and corrects them by different weights. It helps to improve the accuracy of stabilized SWBNet, especially for multiillumination sRGB images. Experiments indicate that our SWBNet achieves stable and remarkable WB performance.},
  archive   = {C_AAAI},
  author    = {Chunxiao Li and Xuejing Kang and Zhifeng Zhang and Anlong Ming},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25211},
  pages     = {1278-1286},
  title     = {SWBNet: A stable white balance network for sRGB images},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ReGANIE: Rectifying GAN inversion errors for accurate real
image editing. <em>AAAI</em>, 1269–1277. (<a
href="https://doi.org/10.1609/aaai.v37i1.25210">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The StyleGAN family succeed in high-fidelity image generation and allow for flexible and plausible editing of generated images by manipulating the semantic-rich latent style space. However, projecting a real image into its latent space encounters an inherent trade-off between inversion quality and editability. Existing encoder-based or optimization-based StyleGAN inversion methods attempt to mitigate the trade-off but see limited performance. To fundamentally resolve this problem, we propose a novel two-phase framework by designating two separate networks to tackle editing and reconstruction respectively, instead of balancing the two. Specifically, in Phase I, a W-space-oriented StyleGAN inversion network is trained and used to perform image inversion and edit- ing, which assures the editability but sacrifices reconstruction quality. In Phase II, a carefully designed rectifying network is utilized to rectify the inversion errors and perform ideal reconstruction. Experimental results show that our approach yields near-perfect reconstructions without sacrificing the editability, thus allowing accurate manipulation of real images. Further, we evaluate the performance of our rectifying net- work, and see great generalizability towards unseen manipulation types and out-of-domain images.},
  archive   = {C_AAAI},
  author    = {Bingchuan Li and Tianxiang Ma and Peng Zhang and Miao Hua and Wei Liu and Qian He and Zili Yi},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25210},
  pages     = {1269-1277},
  title     = {ReGANIE: Rectifying GAN inversion errors for accurate real image editing},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Linking people across text and images based on social
relation reasoning. <em>AAAI</em>, 1260–1268. (<a
href="https://doi.org/10.1609/aaai.v37i1.25209">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As a sub-task of visual grounding, linking people across text and images aims to localize target people in images with corresponding sentences. Existing approaches tend to capture superficial features of people (e.g., dress and location) that suffer from the incompleteness information across text and images. We observe that humans are adept at exploring social relations to assist identifying people. Therefore, we propose a Social Relation Reasoning (SRR) model to address the aforementioned issues. Firstly, we design a Social Relation Extraction (SRE) module to extract social relations between people in the input sentence. Specially, the SRE module based on zero-shot learning is able to extract social relations even though they are not defined in the existing datasets. A Reasoning based Cross-modal Matching (RCM) module is further used to generate matching matrices by reasoning on the social relations and visual features. Experimental results show that the accuracy of our proposed SRR model outperforms the state-of-the-art models on the challenging datasets Who&#39;s Waldo and FL: MSRE, by more than 5\% and 7\%, respectively. Our source code is available at https://github.com/VILAN-Lab/SRR.},
  archive   = {C_AAAI},
  author    = {Yang Lei and Peizhi Zhao and Pijian Li and Yi Cai and Qingbao Huang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25209},
  pages     = {1260-1268},
  title     = {Linking people across text and images based on social relation reasoning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Symbolic replay: Scene graph as prompt for continual
learning on VQA task. <em>AAAI</em>, 1250–1259. (<a
href="https://doi.org/10.1609/aaai.v37i1.25208">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {VQA is an ambitious task aiming to answer any image-related question. However, in reality, it is hard to build such a system once for all since the needs of users are continuously updated, and the system has to implement new functions. Thus, Continual Learning (CL) ability is a must in developing advanced VQA systems. Recently, a pioneer work split a VQA dataset into disjoint answer sets to study this topic. However, CL on VQA involves not only the expansion of label sets (new Answer sets). It is crucial to study how to answer questions when deploying VQA systems to new environments (new Visual scenes) and how to answer questions requiring new functions (new Question types). Thus, we propose CLOVE, a benchmark for Continual Learning On Visual quEstion answering, which contains scene- and function-incremental settings for the two aforementioned CL scenarios. In terms of methodology, the main difference between CL on VQA and classification is that the former additionally involves expanding and preventing forgetting of reasoning mechanisms, while the latter focusing on class representation. Thus, we propose a real-data-free replay-based method tailored for CL on VQA, named Scene Graph as Prompt for Symbolic Replay. Using a piece of scene graph as a prompt, it replays pseudo scene graphs to represent the past images, along with correlated QA pairs. A unified VQA model is also proposed to utilize the current and replayed data to enhance its QA ability. Finally, experimental results reveal challenges in CLOVE and demonstrate the effectiveness of our method. Code and data are available at https://github.com/showlab/CLVQA.},
  archive   = {C_AAAI},
  author    = {Stan Weixian Lei and Difei Gao and Jay Zhangjie Wu and Yuxuan Wang and Wei Liu and Mengmi Zhang and Mike Zheng Shou},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25208},
  pages     = {1250-1259},
  title     = {Symbolic replay: Scene graph as prompt for continual learning on VQA task},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Not all neighbors matter: Point distribution-aware pruning
for 3D point cloud. <em>AAAI</em>, 1240–1249. (<a
href="https://doi.org/10.1609/aaai.v37i1.25207">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Applying deep neural networks to 3D point cloud processing has demonstrated a rapid pace of advancement in those domains where 3D geometry information can greatly boost task performance, such as AR/VR, robotics, and autonomous driving. However, as the size of both the neural network model and 3D point cloud continues to scale, reducing the entailed computation and memory access overhead is a primary challenge to meet strict latency and energy constraints of practical applications. This paper proposes a new weight pruning technique for 3D point cloud based on spatial point distribution. We identify that particular groups of neighborhood voxels in 3D point cloud contribute more frequently to actual output features than others. Based on this observation, we propose to selectively prune less contributing groups of neighborhood voxels first to reduce the computation overhead while minimizing the impact on model accuracy. We apply our proposal to three representative sparse 3D convolution libraries. Our proposal reduces the inference latency by 1.60× on average and energy consumption by 1.74× on NVIDIA GV100 GPU with no loss in accuracy metric},
  archive   = {C_AAAI},
  author    = {Yejin Lee and Donghyun Lee and JungUk Hong and Jae W. Lee and Hongil Yoon},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25207},
  pages     = {1240-1249},
  title     = {Not all neighbors matter: Point distribution-aware pruning for 3D point cloud},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MultiAct: Long-term 3D human motion generation from multiple
action labels. <em>AAAI</em>, 1231–1239. (<a
href="https://doi.org/10.1609/aaai.v37i1.25206">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We tackle the problem of generating long-term 3D human motion from multiple action labels. Two main previous approaches, such as action- and motion-conditioned methods, have limitations to solve this problem. The action-conditioned methods generate a sequence of motion from a single action. Hence, it cannot generate long-term motions composed of multiple actions and transitions between actions. Meanwhile, the motion-conditioned methods generate future motions from initial motion. The generated future motions only depend on the past, so they are not controllable by the user&#39;s desired actions. We present MultiAct, the first framework to generate long-term 3D human motion from multiple action labels. MultiAct takes account of both action and motion conditions with a unified recurrent generation system. It repetitively takes the previous motion and action label; then, it generates a smooth transition and the motion of the given action. As a result, MultiAct produces realistic long-term motion controlled by the given sequence of multiple action labels. The code is publicly available in https://github.com/TaeryungLee/MultiAct RELEASE.},
  archive   = {C_AAAI},
  author    = {Taeryung Lee and Gyeongsik Moon and Kyoung Mu Lee},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25206},
  pages     = {1231-1239},
  title     = {MultiAct: Long-term 3D human motion generation from multiple action labels},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Weakly supervised 3D segmentation via receptive-driven
pseudo label consistency and structural consistency. <em>AAAI</em>,
1222–1230. (<a href="https://doi.org/10.1609/aaai.v37i1.25205">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As manual point-wise label is time and labor-intensive for fully supervised large-scale point cloud semantic segmentation, weakly supervised method is increasingly active. However, existing methods fail to generate high-quality pseudo labels effectively, leading to unsatisfactory results. In this paper, we propose a weakly supervised point cloud semantic segmentation framework via receptive-driven pseudo label consistency and structural consistency to mine potential knowledge. Specifically, we propose three consistency contrains: pseudo label consistency among different scales, semantic structure consistency between intra-class features and class-level relation structure consistency between pair-wise categories. Three consistency constraints are jointly used to effectively prepares and utilizes pseudo labels simultaneously for stable training. Finally, extensive experimental results on three challenging datasets demonstrate that our method significantly outperforms state-of-the-art weakly supervised methods and even achieves comparable performance to the fully supervised methods.},
  archive   = {C_AAAI},
  author    = {Yuxiang Lan and Yachao Zhang and Yanyun Qu and Cong Wang and Chengyang Li and Jia Cai and Yuan Xie and Zongze Wu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25205},
  pages     = {1222-1230},
  title     = {Weakly supervised 3D segmentation via receptive-driven pseudo label consistency and structural consistency},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Curriculum multi-negative augmentation for debiased video
grounding. <em>AAAI</em>, 1213–1221. (<a
href="https://doi.org/10.1609/aaai.v37i1.25204">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Video Grounding (VG) aims to locate the desired segment from a video given a sentence query. Recent studies have found that current VG models are prone to over-rely the groundtruth moment annotation distribution biases in the training set. To discourage the standard VG model&#39;s behavior of exploiting such temporal annotation biases and improve the model generalization ability, we propose multiple negative augmentations in a hierarchical way, including cross-video augmentations from clip-/video-level, and self-shuffled augmentations with masks. These augmentations can effectively diversify the data distribution so that the model can make more reasonable predictions instead of merely fitting the temporal biases. However, directly adopting such data augmentation strategy may inevitably carry some noise shown in our cases, since not all of the handcrafted augmentations are semantically irrelevant to the groundtruth video. To further denoise and improve the grounding accuracy, we design a multi-stage curriculum strategy to adaptively train the standard VG model from easy to hard negative augmentations. Experiments on newly collected Charades-CD and ActivityNet-CD datasets demonstrate our proposed strategy can improve the performance of the base model on both i.i.d and o.o.d scenarios.},
  archive   = {C_AAAI},
  author    = {Xiaohan Lan and Yitian Yuan and Hong Chen and Xin Wang and Zequn Jie and Lin Ma and Zhi Wang and Wenwu Zhu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25204},
  pages     = {1213-1221},
  title     = {Curriculum multi-negative augmentation for debiased video grounding},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning to learn better for video object segmentation.
<em>AAAI</em>, 1205–1212. (<a
href="https://doi.org/10.1609/aaai.v37i1.25203">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, the joint learning framework (JOINT) integrates matching based transductive reasoning and online inductive learning to achieve accurate and robust semi-supervised video object segmentation (SVOS). However, using the mask embedding as the label to guide the generation of target features in the two branches may result in inadequate target representation and degrade the performance. Besides, how to reasonably fuse the target features in the two different branches rather than simply adding them together to avoid the adverse effect of one dominant branch has not been investigated. In this paper, we propose a novel framework that emphasizes Learning to Learn Better (LLB) target features for SVOS, termed LLB, where we design the discriminative label generation module (DLGM) and the adaptive fusion module to address these issues. Technically, the DLGM takes the background-filtered frame instead of the target mask as input and adopts a lightweight encoder to generate the target features, which serves as the label of the online few-shot learner and the value of the decoder in the transformer to guide the two branches to learn more discriminative target representation. The adaptive fusion module maintains a learnable gate for each branch, which reweighs the element-wise feature representation and allows an adaptive amount of target information in each branch flowing to the fused target feature, thus preventing one branch from being dominant and making the target feature more robust to distractor. Extensive experiments on public benchmarks show that our proposed LLB method achieves state-of-the-art performance.},
  archive   = {C_AAAI},
  author    = {Meng Lan and Jing Zhang and Lefei Zhang and Dacheng Tao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25203},
  pages     = {1205-1212},
  title     = {Learning to learn better for video object segmentation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Pixel-wise warping for deep image stitching. <em>AAAI</em>,
1196–1204. (<a href="https://doi.org/10.1609/aaai.v37i1.25202">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Existing image stitching approaches based on global or local homography estimation are not free from the parallax problem and suffer from undesired artifacts. In this paper, instead of relying on the homography-based warp, we propose a novel deep image stitching framework exploiting the pixel-wise warp field to handle the large-parallax problem. The proposed deep image stitching framework consists of a Pixel-wise Warping Module (PWM) and a Stitched Image Generating Module (SIGMo). For PWM, we obtain pixel-wise warp in a similar manner as estimating an optical flow (OF). In the stitching scenario, the input images usually include non-overlap (NOV) regions of which warp cannot be directly estimated, unlike the overlap (OV) regions. To help the PWM predict a reasonable warp on the NOV region, we impose two geometrical constraints: an epipolar loss and a line-preservation loss. With the obtained warp field, we relocate the pixels of the target image using forward warping. Finally, the SIGMo is trained by the proposed multi-branch training framework to generate a stitched image from a reference image and a warped target image. For training and evaluating the proposed framework, we build and publish a novel dataset including image pairs with corresponding pixel-wise ground truth warp and stitched result images. We show that the results of the proposed framework are quantitatively and qualitatively superior to those of the conventional methods.},
  archive   = {C_AAAI},
  author    = {Hyeokjun Kweon and Hyeonseong Kim and Yoonsu Kang and Youngho Yoon and WooSeong Jeong and Kuk-Jin Yoon},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25202},
  pages     = {1196-1204},
  title     = {Pixel-wise warping for deep image stitching},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). InstanceFormer: An online video instance segmentation
framework. <em>AAAI</em>, 1188–1195. (<a
href="https://doi.org/10.1609/aaai.v37i1.25201">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent transformer-based offline video instance segmentation (VIS) approaches achieve encouraging results and significantly outperform online approaches. However, their reliance on the whole video and the immense computational complexity caused by full Spatio-temporal attention limit them in real-life applications such as processing lengthy videos. In this paper, we propose a single-stage transformer-based efficient online VIS framework named InstanceFormer, which is especially suitable for long and challenging videos. We propose three novel components to model short-term and long-term dependency and temporal coherence. First, we propagate the representation, location, and semantic information of prior instances to model short-term changes. Second, we propose a novel memory cross-attention in the decoder, which allows the network to look into earlier instances within a certain temporal window. Finally, we employ a temporal contrastive loss to impose coherence in the representation of an instance across all frames. Memory attention and temporal coherence are particularly beneficial to long-range dependency modeling, including challenging scenarios like occlusion. The proposed InstanceFormer outperforms previous online benchmark methods by a large margin across multiple datasets. Most importantly, InstanceFormer surpasses offline approaches for challenging and long datasets such as YouTube-VIS-2021 and OVIS. Code is available at https://github.com/rajatkoner08/InstanceFormer.},
  archive   = {C_AAAI},
  author    = {Rajat Koner and Tanveer Hannan and Suprosanna Shit and Sahand Sharifzadeh and Matthias Schubert and Thomas Seidl and Volker Tresp},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25201},
  pages     = {1188-1195},
  title     = {InstanceFormer: An online video instance segmentation framework},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MGTANet: Encoding sequential LiDAR points using long
short-term motion-guided temporal attention for 3D object detection.
<em>AAAI</em>, 1179–1187. (<a
href="https://doi.org/10.1609/aaai.v37i1.25200">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Most scanning LiDAR sensors generate a sequence of point clouds in real-time. While conventional 3D object detectors use a set of unordered LiDAR points acquired over a fixed time interval, recent studies have revealed that substantial performance improvement can be achieved by exploiting the spatio-temporal context present in a sequence of LiDAR point sets. In this paper, we propose a novel 3D object detection architecture, which can encode LiDAR point cloud sequences acquired by multiple successive scans. The encoding process of the point cloud sequence is performed on two different time scales. We first design a short-term motion-aware voxel encoding that captures the short-term temporal changes of point clouds driven by the motion of objects in each voxel. We also propose long-term motion-guided bird’s eye view (BEV) feature enhancement that adaptively aligns and aggregates the BEV feature maps obtained by the short-term voxel encoding by utilizing the dynamic motion context inferred from the sequence of the feature maps. The experiments conducted on the public nuScenes benchmark demonstrate that the proposed 3D object detector offers significant improvements in performance compared to the baseline methods and that it sets a state-of-the-art performance for certain 3D object detection categories. Code is available at https://github.com/HYjhkoh/MGTANet.git.},
  archive   = {C_AAAI},
  author    = {Junho Koh and Junhyung Lee and Youngwoo Lee and Jaekyum Kim and Jun Won Choi},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25200},
  pages     = {1179-1187},
  title     = {MGTANet: Encoding sequential LiDAR points using long short-term motion-guided temporal attention for 3D object detection},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Simple and effective synthesis of indoor 3D scenes.
<em>AAAI</em>, 1169–1178. (<a
href="https://doi.org/10.1609/aaai.v37i1.25199">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the problem of synthesizing immersive 3D indoor scenes from one or a few images. Our aim is to generate high-resolution images and videos from novel viewpoints, including viewpoints that extrapolate far beyond the input images while maintaining 3D consistency. Existing approaches are highly complex, with many separately trained stages and components. We propose a simple alternative: an image-to-image GAN that maps directly from reprojections of incomplete point clouds to full high-resolution RGB-D images. On the Matterport3D and RealEstate10K datasets, our approach significantly outperforms prior work when evaluated by humans, as well as on FID scores. Further, we show that our model is useful for generative data augmentation. A vision-and-language navigation (VLN) agent trained with trajectories spatially-perturbed by our model improves success rate by up to 1.5\% over a state of the art baseline on the mature R2R benchmark. Our code will be made available to facilitate generative data augmentation and applications to downstream robotics and embodied AI tasks.},
  archive   = {C_AAAI},
  author    = {Jing Yu Koh and Harsh Agrawal and Dhruv Batra and Richard Tucker and Austin Waters and Honglak Lee and Yinfei Yang and Jason Baldridge and Peter Anderson},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25199},
  pages     = {1169-1178},
  title     = {Simple and effective synthesis of indoor 3D scenes},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). CRAFT: Camera-radar 3D object detection with
spatio-contextual fusion transformer. <em>AAAI</em>, 1160–1168. (<a
href="https://doi.org/10.1609/aaai.v37i1.25198">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Camera and radar sensors have significant advantages in cost, reliability, and maintenance compared to LiDAR. Existing fusion methods often fuse the outputs of single modalities at the result-level, called the late fusion strategy. This can benefit from using off-the-shelf single sensor detection algorithms, but late fusion cannot fully exploit the complementary properties of sensors, thus having limited performance despite the huge potential of camera-radar fusion. Here we propose a novel proposal-level early fusion approach that effectively exploits both spatial and contextual properties of camera and radar for 3D object detection. Our fusion framework first associates image proposal with radar points in the polar coordinate system to efficiently handle the discrepancy between the coordinate system and spatial properties. Using this as a first stage, following consecutive cross-attention based feature fusion layers adaptively exchange spatio-contextual information between camera and radar, leading to a robust and attentive fusion. Our camera-radar fusion approach achieves the state-of-the-art 41.1\% mAP and 52.3\% NDS on the nuScenes test set, which is 8.7 and 10.8 points higher than the camera-only baseline, as well as yielding competitive performance on the LiDAR method.},
  archive   = {C_AAAI},
  author    = {Youngseok Kim and Sanmin Kim and Jun Won Choi and Dongsuk Kum},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25198},
  pages     = {1160-1168},
  title     = {CRAFT: Camera-radar 3D object detection with spatio-contextual fusion transformer},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multispectral invisible coating: Laminated visible-thermal
physical attack against multispectral object detectors using transparent
low-e films. <em>AAAI</em>, 1151–1159. (<a
href="https://doi.org/10.1609/aaai.v37i1.25197">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multispectral object detection plays a vital role in safety-critical vision systems that require an around-the-clock operation and encounter dynamic real-world situations(e.g., self-driving cars and autonomous surveillance systems). Despite its crucial competence in safety-related applications, its security against physical attacks is severely understudied. We investigate the vulnerability of multispectral detectors against physical attacks by proposing a new physical method: Multispectral Invisible Coating. Utilizing transparent Low-e films, we realize a laminated visible-thermal physical attack by attaching Low-e films over a visible attack printing. Moreover, we apply our physical method to manufacture a Multispectral Invisible Suit that hides persons from the multiple view angles of Multispectral detectors. To simulate our attack under various surveillance scenes, we constructed a large-scale multispectral pedestrian dataset which we will release in public. Extensive experiments show that our proposed method effectively attacks the state-of-the-art multispectral detector both in the digital space and the physical world.},
  archive   = {C_AAAI},
  author    = {Taeheon Kim and Youngjoon Yu and Yong Man Ro},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25197},
  pages     = {1151-1159},
  title     = {Multispectral invisible coating: Laminated visible-thermal physical attack against multispectral object detectors using transparent low-E films},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Semantic-aware superpixel for weakly supervised semantic
segmentation. <em>AAAI</em>, 1142–1150. (<a
href="https://doi.org/10.1609/aaai.v37i1.25196">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Weakly-supervised semantic segmentation aims to train a semantic segmentation network using weak labels. Among weak labels, image-level label has been the most popular choice due to its simplicity. However, since image-level labels lack accurate object region information, additional modules such as saliency detector have been exploited in weakly supervised semantic segmentation, which requires pixel-level label for training. In this paper, we explore a self-supervised vision transformer to mitigate the heavy efforts on generation of pixel-level annotations. By exploiting the features obtained from self-supervised vision transformer, our superpixel discovery method finds out the semantic-aware superpixels based on the feature similarity in an unsupervised manner. Once we obtain the superpixels, we train the semantic segmentation network using superpixel-guided seeded region growing method. Despite its simplicity, our approach achieves the competitive result with the state-of-the-arts on PASCAL VOC 2012 and MS-COCO 2014 semantic segmentation datasets for weakly supervised semantic segmentation. Our code is available at https://github.com/st17kim/semantic-aware-superpixel.},
  archive   = {C_AAAI},
  author    = {Sangtae Kim and Daeyoung Park and Byonghyo Shim},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25196},
  pages     = {1142-1150},
  title     = {Semantic-aware superpixel for weakly supervised semantic segmentation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Pose-guided 3D human generation in indoor scene.
<em>AAAI</em>, 1133–1141. (<a
href="https://doi.org/10.1609/aaai.v37i1.25195">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this work, we address the problem of scene-aware 3D human avatar generation based on human-scene interactions. In particular, we pay attention to the fact that physical contact between a 3D human and a scene (i.e., physical human-scene interactions) requires a geometrical alignment to generate natural 3D human avatar. Motivated by this fact, we present a new 3D human generation framework that considers geometric alignment on potential contact areas between 3D human avatars and their surroundings. In addition, we introduce a compact yet effective human pose classifier that classifies the human pose and provides potential contact areas of the 3D human avatar. It allows us to adaptively use geometric alignment loss according to the classified human pose. Compared to state-of-the-art method, our method can generate physically and semantically plausible 3D humans that interact naturally with 3D scenes without additional post-processing. In our evaluations, we achieve the improvements with more plausible interactions and more variety of poses than prior research in qualitative and quantitative analysis. Project page: https://bupyeonghealer.github.io/phin/.},
  archive   = {C_AAAI},
  author    = {Minseok Kim and Changwoo Kang and Jeongin Park and Kyungdon Joo},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25195},
  pages     = {1133-1141},
  title     = {Pose-guided 3D human generation in indoor scene},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Frequency selective augmentation for video representation
learning. <em>AAAI</em>, 1124–1132. (<a
href="https://doi.org/10.1609/aaai.v37i1.25194">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent self-supervised video representation learning methods focus on maximizing the similarity between multiple augmented views from the same video and largely rely on the quality of generated views. However, most existing methods lack a mechanism to prevent representation learning from bias towards static information in the video. In this paper, we propose frequency augmentation (FreqAug), a spatio-temporal data augmentation method in the frequency domain for video representation learning. FreqAug stochastically removes specific frequency components from the video so that learned representation captures essential features more from the remaining information for various downstream tasks. Specifically, FreqAug pushes the model to focus more on dynamic features rather than static features in the video via dropping spatial or temporal low-frequency components. To verify the generality of the proposed method, we experiment with FreqAug on multiple self-supervised learning frameworks along with standard augmentations. Transferring the improved representation to five video action recognition and two temporal action localization downstream tasks shows consistent improvements over baselines.},
  archive   = {C_AAAI},
  author    = {Jinhyung Kim and Taeoh Kim and Minho Shim and Dongyoon Han and Dongyoon Wee and Junmo Kim},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25194},
  pages     = {1124-1132},
  title     = {Frequency selective augmentation for video representation learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Bidirectional domain mixup for domain adaptive semantic
segmentation. <em>AAAI</em>, 1114–1123. (<a
href="https://doi.org/10.1609/aaai.v37i1.25193">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Mixup provides interpolated training samples and allows the model to obtain smoother decision boundaries for better generalization. The idea can be naturally applied to the domain adaptation task, where we can mix the source and target samples to obtain domain-mixed samples for better adaptation. However, the extension of the idea from classification to segmentation (i.e., structured output) is nontrivial. This paper systematically studies the impact of mixup under the domain adaptive semantic segmentation task and presents a simple yet effective mixup strategy called Bidirectional Domain Mixup (BDM). In specific, we achieve domain mixup in two-step: cut and paste. Given the warm-up model trained from any adaptation techniques, we forward the source and target samples and perform a simple threshold-based cut out of the unconfident regions (cut). After then, we fill-in the dropped regions with the other domain region patches (paste). In doing so, we jointly consider class distribution, spatial structure, and pseudo label confidence. Based on our analysis, we found that BDM leaves domain transferable regions by cutting, balances the dataset-level class distribution while preserving natural scene context by pasting. We coupled our proposal with various state-of-the-art adaptation models and observe significant improvement consistently. We also provide extensive ablation experiments to empirically verify our main components of the framework. Visit our project page with the code at https://sites.google.com/view/bidirectional-domain-mixup},
  archive   = {C_AAAI},
  author    = {Daehan Kim and Minseok Seo and Kwanyong Park and Inkyu Shin and Sanghyun Woo and In So Kweon and Dong-Geol Choi},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25193},
  pages     = {1114-1123},
  title     = {Bidirectional domain mixup for domain adaptive semantic segmentation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). 3D human pose lifting with grid convolution. <em>AAAI</em>,
1105–1113. (<a href="https://doi.org/10.1609/aaai.v37i1.25192">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Existing lifting networks for regressing 3D human poses from 2D single-view poses are typically constructed with linear layers based on graph-structured representation learning. In sharp contrast to them, this paper presents Grid Convolution (GridConv), mimicking the wisdom of regular convolution operations in image space. GridConv is based on a novel Semantic Grid Transformation (SGT) which leverages a binary assignment matrix to map the irregular graph-structured human pose onto a regular weave-like grid pose representation joint by joint, enabling layer-wise feature learning with GridConv operations. We provide two ways to implement SGT, including handcrafted and learnable designs. Surprisingly, both designs turn out to achieve promising results and the learnable one is better, demonstrating the great potential of this new lifting representation learning formulation. To improve the ability of GridConv to encode contextual cues, we introduce an attention module over the convolutional kernel, making grid convolution operations input-dependent, spatial-aware and grid-specific. We show that our fully convolutional grid lifting network outperforms state-of-the-art methods with noticeable margins under (1) conventional evaluation on Human3.6M and (2) cross-evaluation on MPI-INF-3DHP. Code is available at https://github.com/OSVAI/GridConv.},
  archive   = {C_AAAI},
  author    = {Yangyuxuan Kang and Yuyang Liu and Anbang Yao and Shandong Wang and Enhua Wu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25192},
  pages     = {1105-1113},
  title     = {3D human pose lifting with grid convolution},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GuidedMixup: An efficient mixup strategy guided by saliency
maps. <em>AAAI</em>, 1096–1104. (<a
href="https://doi.org/10.1609/aaai.v37i1.25191">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Data augmentation is now an essential part of the image training process, as it effectively prevents overfitting and makes the model more robust against noisy datasets. Recent mixing augmentation strategies have advanced to generate the mixup mask that can enrich the saliency information, which is a supervisory signal. However, these methods incur a significant computational burden to optimize the mixup mask. From this motivation, we propose a novel saliency-aware mixup method, GuidedMixup, which aims to retain the salient regions in mixup images with low computational overhead. We develop an efficient pairing algorithm that pursues to minimize the conflict of salient regions of paired images and achieve rich saliency in mixup images. Moreover, GuidedMixup controls the mixup ratio for each pixel to better preserve the salient region by interpolating two paired images smoothly. The experiments on several datasets demonstrate that GuidedMixup provides a good trade-off between augmentation overhead and generalization performance on classification datasets. In addition, our method shows good performance in experiments with corrupted or reduced datasets.},
  archive   = {C_AAAI},
  author    = {Minsoo Kang and Suhyun Kim},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25191},
  pages     = {1096-1104},
  title     = {GuidedMixup: An efficient mixup strategy guided by saliency maps},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Correlation loss: Enforcing correlation between
classification and localization. <em>AAAI</em>, 1087–1095. (<a
href="https://doi.org/10.1609/aaai.v37i1.25190">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Object detectors are conventionally trained by a weighted sum of classification and localization losses. Recent studies (e.g., predicting IoU with an auxiliary head, Generalized Focal Loss, Rank &amp; Sort Loss) have shown that forcing these two loss terms to interact with each other in non-conventional ways creates a useful inductive bias and improves performance. Inspired by these works, we focus on the correlation between classification and localization and make two main contributions: (i) We provide an analysis about the effects of correlation between classification and localization tasks in object detectors. We identify why correlation affects the performance of various NMS-based and NMS-free detectors, and we devise measures to evaluate the effect of correlation and use them to analyze common detectors. (ii) Motivated by our observations, e.g., that NMS-free detectors can also benefit from correlation, we propose Correlation Loss, a novel plug-in loss function that improves the performance of various object detectors by directly optimizing correlation coefficients: E.g., Correlation Loss on Sparse R-CNN, an NMS-free method, yields 1.6 AP gain on COCO and 1.8 AP gain on Cityscapes dataset. Our best model on Sparse R-CNN reaches 51.0 AP without test-time augmentation on COCO test-dev, reaching state-of-the-art. Code is available at: https://github.com/fehmikahraman/CorrLoss.},
  archive   = {C_AAAI},
  author    = {Fehmi Kahraman and Kemal Oksuz and Sinan Kalkan and Emre Akbas},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25190},
  pages     = {1087-1095},
  title     = {Correlation loss: Enforcing correlation between classification and localization},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Weakly-guided self-supervised pretraining for temporal
activity detection. <em>AAAI</em>, 1078–1086. (<a
href="https://doi.org/10.1609/aaai.v37i1.25189">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Temporal Activity Detection aims to predict activity classes per frame, in contrast to video-level predictions in Activity Classification (i.e., Activity Recognition). Due to the expensive frame-level annotations required for detection, the scale of detection datasets is limited. Thus, commonly, previous work on temporal activity detection resorts to fine-tuning a classification model pretrained on large-scale classification datasets (e.g., Kinetics-400). However, such pretrained models are not ideal for downstream detection, due to the disparity between the pretraining and the downstream fine-tuning tasks. In this work, we propose a novel weakly-guided self-supervised pretraining method for detection. We leverage weak labels (classification) to introduce a self-supervised pretext task (detection) by generating frame-level pseudo labels, multi-action frames, and action segments. Simply put, we design a detection task similar to downstream, on large-scale classification data, without extra annotations. We show that the models pretrained with the proposed weakly-guided self-supervised detection task outperform prior work on multiple challenging activity detection benchmarks, including Charades and MultiTHUMOS. Our extensive ablations further provide insights on when and how to use the proposed models for activity detection. Code is available at github.com/kkahatapitiya/SSDet.},
  archive   = {C_AAAI},
  author    = {Kumara Kahatapitiya and Zhou Ren and Haoxiang Li and Zhenyu Wu and Michael S. Ryoo and Gang Hua},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25189},
  pages     = {1078-1086},
  title     = {Weakly-guided self-supervised pretraining for temporal activity detection},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Estimating reflectance layer from a single image:
Integrating reflectance guidance and shadow/specular aware learning.
<em>AAAI</em>, 1069–1077. (<a
href="https://doi.org/10.1609/aaai.v37i1.25188">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Estimating the reflectance layer from a single image is a challenging task. It becomes more challenging when the input image contains shadows or specular highlights, which often render an inaccurate estimate of the reflectance layer. Therefore, we propose a two-stage learning method, including reflectance guidance and a Shadow/Specular-Aware (S-Aware) network to tackle the problem. In the first stage, an initial reflectance layer free from shadows and specularities is obtained with the constraint of novel losses that are guided by prior-based shadow-free and specular-free images. To further enforce the reflectance layer to be independent of shadows and specularities in the second-stage refinement, we introduce an S-Aware network that distinguishes the reflectance image from the input image. Our network employs a classifier to categorize shadow/shadow-free, specular/specular-free classes, enabling the activation features to function as attention maps that focus on shadow/specular regions. Our quantitative and qualitative evaluations show that our method outperforms the state-of-the-art methods in the reflectance layer estimation that is free from shadows and specularities.},
  archive   = {C_AAAI},
  author    = {Yeying Jin and Ruoteng Li and Wenhan Yang and Robby T. Tan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25188},
  pages     = {1069-1077},
  title     = {Estimating reflectance layer from a single image: Integrating reflectance guidance and Shadow/Specular aware learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FacT: Factor-tuning for lightweight adaptation on vision
transformer. <em>AAAI</em>, 1060–1068. (<a
href="https://doi.org/10.1609/aaai.v37i1.25187">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent work has explored the potential to adapt a pre-trained vision transformer (ViT) by updating only a few parameters so as to improve storage efficiency, called parameter-efficient transfer learning (PETL). Current PETL methods have shown that by tuning only 0.5\% of the parameters, ViT can be adapted to downstream tasks with even better performance than full fine-tuning. In this paper, we aim to further promote the efficiency of PETL to meet the extreme storage constraint in real-world applications. To this end, we propose a tensorization-decomposition framework to store the weight increments, in which the weights of each ViT are tensorized into a single 3D tensor, and their increments are then decomposed into lightweight factors. In the fine-tuning process, only the factors need to be updated and stored, termed Factor-Tuning (FacT). On VTAB-1K benchmark, our method performs on par with NOAH, the state-of-the-art PETL method, while being 5x more parameter-efficient. We also present a tiny version that only uses 8K (0.01\% of ViT&#39;s parameters) trainable parameters but outperforms full fine-tuning and many other PETL methods such as VPT and BitFit. In few-shot settings, FacT also beats all PETL baselines using the fewest parameters, demonstrating its strong capability in the low-data regime.},
  archive   = {C_AAAI},
  author    = {Shibo Jie and Zhi-Hong Deng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25187},
  pages     = {1060-1068},
  title     = {FacT: Factor-tuning for lightweight adaptation on vision transformer},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). 3D-TOGO: Towards text-guided cross-category 3D object
generation. <em>AAAI</em>, 1051–1059. (<a
href="https://doi.org/10.1609/aaai.v37i1.25186">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This article has been updated and an error has been fixed in published paper. An Erratum to this article was published on 6 September 2023. Text-guided 3D object generation aims to generate 3D objects described by user-defined captions, which paves a flexible way to visualize what we imagined. Although some works have been devoted to solving this challenging task, these works either utilize some explicit 3D representations (e.g., mesh), which lack texture and require post-processing for rendering photo-realistic views; or require individual time-consuming optimization for every single case. Here, we make the first attempt to achieve generic text-guided cross-category 3D object generation via a new 3D-TOGO model, which integrates a text-to-views generation module and a views-to-3D generation module. The text-to-views generation module is designed to generate different views of the target 3D object given an input caption. prior-guidance, caption-guidance and view contrastive learning are proposed for achieving better view-consistency and caption similarity. Meanwhile, a pixelNeRF model is adopted for the views-to-3D generation module to obtain the implicit 3D neural representation from the previously-generated views. Our 3D-TOGO model generates 3D objects in the form of the neural radiance field with good texture and requires no time-cost optimization for every single caption. Besides, 3D-TOGO can control the category, color and shape of generated 3D objects with the input caption. Extensive experiments on the largest 3D object dataset (i.e., ABO) are conducted to verify that 3D-TOGO can better generate high-quality 3D objects according to the input captions across 98 different categories, in terms of PSNR, SSIM, LPIPS and CLIP-score, compared with text-NeRF and Dreamfields.},
  archive   = {C_AAAI},
  author    = {Zutao Jiang and Guansong Lu and Xiaodan Liang and Jihua Zhu and Wei Zhang and Xiaojun Chang and Hang Xu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25186},
  pages     = {1051-1059},
  title     = {3D-TOGO: Towards text-guided cross-category 3D object generation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PolarFormer: Multi-camera 3D object detection with polar
transformer. <em>AAAI</em>, 1042–1050. (<a
href="https://doi.org/10.1609/aaai.v37i1.25185">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {3D object detection in autonomous driving aims to reason “what” and “where” the objects of interest present in a 3D world. Following the conventional wisdom of previous 2D object detection, existing methods often adopt the canonical Cartesian coordinate system with perpendicular axis. However, we conjugate that this does not fit the nature of the ego car’s perspective, as each onboard camera perceives the world in shape of wedge intrinsic to the imaging geometry with radical (non perpendicular) axis. Hence, in this paper we advocate the exploitation of the Polar coordinate system and propose a new Polar Transformer (PolarFormer) for more accurate 3D object detection in the bird’s-eye-view (BEV) taking as input only multi-camera 2D images. Specifically, we design a cross-attention based Polar detection head without restriction to the shape of input structure to deal with irregular Polar grids. For tackling the unconstrained object scale variations along Polar’s distance dimension, we further introduce a multi-scale Polar representation learning strategy. As a result, our model can make best use of the Polar representation rasterized via attending to the corresponding image observation in a sequence-to-sequence fashion subject to the geometric constraints. Thorough experiments on the nuScenes dataset demonstrate that our PolarFormer outperforms significantly state-of-the-art 3D object detection alternatives.},
  archive   = {C_AAAI},
  author    = {Yanqin Jiang and Li Zhang and Zhenwei Miao and Xiatian Zhu and Jin Gao and Weiming Hu and Yu-Gang Jiang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25185},
  pages     = {1042-1050},
  title     = {PolarFormer: Multi-camera 3D object detection with polar transformer},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-modality deep network for extreme learned image
compression. <em>AAAI</em>, 1033–1041. (<a
href="https://doi.org/10.1609/aaai.v37i1.25184">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Image-based single-modality compression learning approaches have demonstrated exceptionally powerful encoding and decoding capabilities in the past few years , but suffer from blur and severe semantics loss at extremely low bitrates. To address this issue, we propose a multimodal machine learning method for text-guided image compression, in which the semantic information of text is used as prior information to guide image compression for better compression performance. We fully study the role of text description in different components of the codec, and demonstrate its effectiveness. In addition, we adopt the image-text attention module and image-request complement module to better fuse image and text features, and propose an improved multimodal semantic-consistent loss to produce semantically complete reconstructions. Extensive experiments, including a user study, prove that our method can obtain visually pleasing results at extremely low bitrates, and achieves a comparable or even better performance than state-of-the-art methods, even though these methods are at 2x to 4x bitrates of ours.},
  archive   = {C_AAAI},
  author    = {Xuhao Jiang and Weimin Tan and Tian Tan and Bo Yan and Liquan Shen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25184},
  pages     = {1033-1041},
  title     = {Multi-modality deep network for extreme learned image compression},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Semi-supervised deep large-baseline homography estimation
with progressive equivalence constraint. <em>AAAI</em>, 1024–1032. (<a
href="https://doi.org/10.1609/aaai.v37i1.25183">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Homography estimation is erroneous in the case of large-baseline due to the low image overlay and limited receptive field. To address it, we propose a progressive estimation strategy by converting large-baseline homography into multiple intermediate ones, cumulatively multiplying these intermediate items can reconstruct the initial homography. Meanwhile, a semi-supervised homography identity loss, which consists of two components: a supervised objective and an unsupervised objective, is introduced. The first supervised loss is acting to optimize intermediate homographies, while the second unsupervised one helps to estimate a large-baseline homography without photometric losses. To validate our method, we propose a large-scale dataset that covers regular and challenging scenes. Experiments show that our method achieves state-of-the-art performance in large-baseline scenes while keeping competitive performance in small-baseline scenes. Code and dataset are available at https://github.com/megvii-research/LBHomo.},
  archive   = {C_AAAI},
  author    = {Hai Jiang and Haipeng Li and Yuhang Lu and Songchen Han and Shuaicheng Liu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25183},
  pages     = {1024-1032},
  title     = {Semi-supervised deep large-baseline homography estimation with progressive equivalence constraint},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fourier-net: Fast image registration with band-limited
deformation. <em>AAAI</em>, 1015–1023. (<a
href="https://doi.org/10.1609/aaai.v37i1.25182">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Unsupervised image registration commonly adopts U-Net style networks to predict dense displacement fields in the full-resolution spatial domain. For high-resolution volumetric image data, this process is however resource-intensive and time-consuming. To tackle this problem, we propose the Fourier-Net, replacing the expansive path in a U-Net style network with a parameter-free model-driven decoder. Specifically, instead of our Fourier-Net learning to output a full-resolution displacement field in the spatial domain, we learn its low-dimensional representation in a band-limited Fourier domain. This representation is then decoded by our devised model-driven decoder (consisting of a zero padding layer and an inverse discrete Fourier transform layer) to the dense, full-resolution displacement field in the spatial domain. These changes allow our unsupervised Fourier-Net to contain fewer parameters and computational operations, resulting in faster inference speeds. Fourier-Net is then evaluated on two public 3D brain datasets against various state-of-the-art approaches. For example, when compared to a recent transformer-based method, named TransMorph, our Fourier-Net, which only uses 2.2\% of its parameters and 6.66\% of the multiply-add operations, achieves a 0.5\% higher Dice score and an 11.48 times faster inference speed. Code is available at https://github.com/xi-jia/Fourier-Net.},
  archive   = {C_AAAI},
  author    = {Xi Jia and Joseph Bartlett and Wei Chen and Siyang Song and Tianyang Zhang and Xinxing Cheng and Wenqi Lu and Zhaowen Qiu and Jinming Duan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25182},
  pages     = {1015-1023},
  title     = {Fourier-net: Fast image registration with band-limited deformation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Fast online hashing with multi-label projection.
<em>AAAI</em>, 1007–1014. (<a
href="https://doi.org/10.1609/aaai.v37i1.25181">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Hashing has been widely researched to solve the large-scale approximate nearest neighbor search problem owing to its time and storage superiority. In recent years, a number of online hashing methods have emerged, which can update the hash functions to adapt to the new stream data and realize dynamic retrieval. However, existing online hashing methods are required to update the whole database with the latest hash functions when a query arrives, which leads to low retrieval efficiency with the continuous increase of the stream data. On the other hand, these methods ignore the supervision relationship among the examples, especially in the multi-label case. In this paper, we propose a novel Fast Online Hashing (FOH) method which only updates the binary codes of a small part of the database. To be specific, we first build a query pool in which the nearest neighbors of each central point are recorded. When a new query arrives, only the binary codes of the corresponding potential neighbors are updated. In addition, we create a similarity matrix which takes the multi-label supervision information into account and bring in the multi-label projection loss to further preserve the similarity among the multi-label data. The experimental results on two common benchmarks show that the proposed FOH can achieve dramatic superiority on query time up to 6.28 seconds less than state-of-the-art baselines with competitive retrieval accuracy.},
  archive   = {C_AAAI},
  author    = {Wenzhe Jia and Yuan Cao and Junwei Liu and Jie Gui},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25181},
  pages     = {1007-1014},
  title     = {Fast online hashing with multi-label projection},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Semi-attention partition for occluded person
re-identification. <em>AAAI</em>, 998–1006. (<a
href="https://doi.org/10.1609/aaai.v37i1.25180">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper proposes a Semi-Attention Partition (SAP) method to learn well-aligned part features for occluded person re-identification (re-ID). Currently, the mainstream methods employ either external semantic partition or attention-based partition, and the latter manner is usually better than the former one. Under this background, this paper explores a potential that the weak semantic partition can be a good teacher for the strong attention-based partition. In other words, the attention-based student can substantially surpass its noisy semantic-based teacher, contradicting the common sense that the student usually achieves inferior (or comparable) accuracy. A key to this effect is: the proposed SAP encourages the attention-based partition of the (transformer) student to be partially consistent with the semantic-based teacher partition through knowledge distillation, yielding the so-called semi-attention. Such partial consistency allows the student to have both consistency and reasonable conflict with the noisy teacher. More specifically, on the one hand, the attention is guided by the semantic partition from the teacher. On the other hand, the attention mechanism itself still has some degree of freedom to comply with the inherent similarity between different patches, thus gaining resistance against noisy supervision. Moreover, we integrate a battery of well-engineered designs into SAP to reinforce their cooperation (e.g., multiple forms of teacher-student consistency), as well as to promote reasonable conflict (e.g., mutual absorbing partition refinement and a supervision signal dropout strategy). Experimental results confirm that the transformer student achieves substantial improvement after this semi-attention learning scheme, and produces new state-of-the-art accuracy on several standard re-ID benchmarks.},
  archive   = {C_AAAI},
  author    = {Mengxi Jia and Yifan Sun and Yunpeng Zhai and Xinhua Cheng and Yi Yang and Ying Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25180},
  pages     = {998-1006},
  title     = {Semi-attention partition for occluded person re-identification},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Delving deep into pixel alignment feature for accurate
multi-view human mesh recovery. <em>AAAI</em>, 989–997. (<a
href="https://doi.org/10.1609/aaai.v37i1.25179">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Regression-based methods have shown high efficiency and effectiveness for multi-view human mesh recovery. The key components of a typical regressor lie in the feature extraction of input views and the fusion of multi-view features. In this paper, we present Pixel-aligned Feedback Fusion (PaFF) for accurate yet efficient human mesh recovery from multi-view images. PaFF is an iterative regression framework that performs feature extraction and fusion alternately. At each iteration, PaFF extracts pixel-aligned feedback features from each input view according to the reprojection of the current estimation and fuses them together with respect to each vertex of the downsampled mesh. In this way, our regressor can not only perceive the misalignment status of each view from the feedback features but also correct the mesh parameters more effectively based on the feature fusion on mesh vertices. Additionally, our regressor disentangles the global orientation and translation of the body mesh from the estimation of mesh parameters such that the camera parameters of input views can be better utilized in the regression process. The efficacy of our method is validated in the Human3.6M dataset via comprehensive ablation experiments, where PaFF achieves 33.02 MPJPE and brings significant improvements over the previous best solutions by more than 29\%. The project page with code and video results can be found at https://kairobo.github.io/PaFF/.},
  archive   = {C_AAAI},
  author    = {Kai Jia and Hongwen Zhang and Liang An and Yebin Liu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25179},
  pages     = {989-997},
  title     = {Delving deep into pixel alignment feature for accurate multi-view human mesh recovery},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unifying vision-language representation space with
single-tower transformer. <em>AAAI</em>, 980–988. (<a
href="https://doi.org/10.1609/aaai.v37i1.25178">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Contrastive learning is a form of distance learning that aims to learn invariant features from two related representations. In this work, we explore the hypothesis that an image and caption can be regarded as two different views of the underlying mutual information, and train a model to learn a unified vision-language representation space that encodes both modalities at once in a modality-agnostic manner. We first identify difficulties in learning a one-tower model for vision-language pretraining (VLP), and propose One Representation (OneR) as a simple yet effective framework for our goal. We discover intriguing properties that distinguish OneR from the previous works that have modality-specific representation spaces such as zero-shot localization, text-guided visual reasoning and multi-modal retrieval, and present analyses to provide insights into this new form of multi-modal representation learning. Thorough evaluations demonstrate the potential of a unified modality-agnostic VLP framework.},
  archive   = {C_AAAI},
  author    = {Jiho Jang and Chaerin Kong and DongHyeon Jeon and Seonhoon Kim and Nojun Kwak},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25178},
  pages     = {980-988},
  title     = {Unifying vision-language representation space with single-tower transformer},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PATRON: Perspective-aware multitask model for referring
expression grounding using embodied multimodal cues. <em>AAAI</em>,
971–979. (<a href="https://doi.org/10.1609/aaai.v37i1.25177">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Humans naturally use referring expressions with verbal utterances and nonverbal gestures to refer to objects and events. As these referring expressions can be interpreted differently from the speaker&#39;s or the observer&#39;s perspective, people effectively decide on the perspective in comprehending the expressions. However, existing models do not explicitly learn perspective grounding, which often causes the models to perform poorly in understanding embodied referring expressions. To make it exacerbate, these models are often trained on datasets collected in non-embodied settings without nonverbal gestures and curated from an exocentric perspective. To address these issues, in this paper, we present a perspective-aware multitask learning model, called PATRON, for relation and object grounding tasks in embodied settings by utilizing verbal utterances and nonverbal cues. In PATRON, we have developed a guided fusion approach, where a perspective grounding task guides the relation and object grounding task. Through this approach, PATRON learns disentangled task-specific and task-guidance representations, where task-guidance representations guide the extraction of salient multimodal features to ground the relation and object accurately. Furthermore, we have curated a synthetic dataset of embodied referring expressions with multimodal cues, called CAESAR-PRO. The experimental results suggest that PATRON outperforms the evaluated state-of-the-art visual-language models. Additionally, the results indicate that learning to ground perspective helps machine learning models to improve the performance of the relation and object grounding task. Furthermore, the insights from the extensive experimental results and the proposed dataset will enable researchers to evaluate visual-language models&#39; effectiveness in understanding referring expressions in other embodied settings.},
  archive   = {C_AAAI},
  author    = {Md Mofijul Islam and Alexi Gladstone and Tariq Iqbal},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25177},
  pages     = {971-979},
  title     = {PATRON: Perspective-aware multitask model for referring expression grounding using embodied multimodal cues},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). FreeEnricher: Enriching face landmarks without additional
cost. <em>AAAI</em>, 962–970. (<a
href="https://doi.org/10.1609/aaai.v37i1.25176">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent years have witnessed significant growth of face alignment. Though dense facial landmark is highly demanded in various scenarios, e.g., cosmetic medicine and facial beautification, most works only consider sparse face alignment. To address this problem, we present a framework that can enrich landmark density by existing sparse landmark datasets, e.g., 300W with 68 points and WFLW with 98 points. Firstly, we observe that the local patches along each semantic contour are highly similar in appearance. Then, we propose a weakly-supervised idea of learning the refinement ability on original sparse landmarks and adapting this ability to enriched dense landmarks. Meanwhile, several operators are devised and organized together to implement the idea. Finally, the trained model is applied as a plug-and-play module to the existing face alignment networks. To evaluate our method, we manually label the dense landmarks on 300W testset. Our method yields state-of-the-art accuracy not only in newly-constructed dense 300W testset but also in the original sparse 300W and WFLW testsets without additional cost.},
  archive   = {C_AAAI},
  author    = {Yangyu Huang and Xi Chen and Jongyoo Kim and Hao Yang and Chong Li and Jiaolong Yang and Dong Chen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25176},
  pages     = {962-970},
  title     = {FreeEnricher: Enriching face landmarks without additional cost},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). Boosting point clouds rendering via radiance mapping.
<em>AAAI</em>, 953–961. (<a
href="https://doi.org/10.1609/aaai.v37i1.25175">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent years we have witnessed rapid development in NeRF-based image rendering due to its high quality. However, point clouds rendering is somehow less explored. Compared to NeRF-based rendering which suffers from dense spatial sampling, point clouds rendering is naturally less computation intensive, which enables its deployment in mobile computing device. In this work, we focus on boosting the image quality of point clouds rendering with a compact model design. We first analyze the adaption of the volume rendering formulation on point clouds. Based on the analysis, we simplify the NeRF representation to a spatial mapping function which only requires single evaluation per pixel. Further, motivated by ray marching, we rectify the the noisy raw point clouds to the estimated intersection between rays and surfaces as queried coordinates, which could avoid spatial frequency collapse and neighbor point disturbance. Composed of rasterization, spatial mapping and the refinement stages, our method achieves the state-of-the-art performance on point clouds rendering, outperforming prior works by notable margins, with a smaller model size. We obtain a PSNR of 31.74 on NeRF-Synthetic, 25.88 on ScanNet and 30.81 on DTU. Code and data are publicly available in https://github.com/seanywang0408/RadianceMapping.},
  archive   = {C_AAAI},
  author    = {Xiaoyang Huang and Yi Zhang and Bingbing Ni and Teng Li and Kai Chen and Wenjun Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25175},
  pages     = {953-961},
  title     = {Boosting point clouds rendering via radiance mapping},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). AudioEar: Single-view ear reconstruction for personalized
spatial audio. <em>AAAI</em>, 944–952. (<a
href="https://doi.org/10.1609/aaai.v37i1.25174">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Spatial audio, which focuses on immersive 3D sound rendering, is widely applied in the acoustic industry. One of the key problems of current spatial audio rendering methods is the lack of personalization based on different anatomies of individuals, which is essential to produce accurate sound source positions. In this work, we address this problem from an interdisciplinary perspective. The rendering of spatial audio is strongly correlated with the 3D shape of human bodies, particularly ears. To this end, we propose to achieve personalized spatial audio by reconstructing 3D human ears with single-view images. First, to benchmark the ear reconstruction task, we introduce AudioEar3D, a high-quality 3D ear dataset consisting of 112 point cloud ear scans with RGB images. To self-supervisedly train a reconstruction model, we further collect a 2D ear dataset composed of 2,000 images, each one with manual annotation of occlusion and 55 landmarks, named AudioEar2D. To our knowledge, both datasets have the largest scale and best quality of their kinds for public use. Further, we propose AudioEarM, a reconstruction method guided by a depth estimation network that is trained on synthetic data, with two loss functions tailored for ear data. Lastly, to fill the gap between the vision and acoustics community, we develop a pipeline to integrate the reconstructed ear mesh with an off-the-shelf 3D human body and simulate a personalized Head-Related Transfer Function (HRTF), which is the core of spatial audio rendering. Code and data are publicly available in https://github.com/seanywang0408/AudioEar.},
  archive   = {C_AAAI},
  author    = {Xiaoyang Huang and Yanjun Wang and Yang Liu and Bingbing Ni and Wenjun Zhang and Jinxian Liu and Teng Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25174},
  pages     = {944-952},
  title     = {AudioEar: Single-view ear reconstruction for personalized spatial audio},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Symmetry-aware transformer-based mirror detection.
<em>AAAI</em>, 935–943. (<a
href="https://doi.org/10.1609/aaai.v37i1.25173">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Mirror detection aims to identify the mirror regions in the given input image. Existing works mainly focus on integrating the semantic features and structural features to mine specific relations between mirror and non-mirror regions, or introducing mirror properties like depth or chirality to help analyze the existence of mirrors. In this work, we observe that a real object typically forms a loose symmetry relationship with its corresponding reflection in the mirror, which is beneficial in distinguishing mirrors from real objects. Based on this observation, we propose a dual-path Symmetry-Aware Transformer-based mirror detection Network (SATNet), which includes two novel modules: Symmetry-Aware Attention Module (SAAM) and Contrast and Fusion Decoder Module (CFDM). Specifically, we first adopt a transformer backbone to model global information aggregation in images, extracting multi-scale features in two paths. We then feed the high-level dual-path features to SAAMs to capture the symmetry relations. Finally, we fuse the dual-path features and refine our prediction maps progressively with CFDMs to obtain the final mirror mask. Experimental results show that SATNet outperforms both RGB and RGB-D mirror detection methods on all available mirror detection datasets.},
  archive   = {C_AAAI},
  author    = {Tianyu Huang and Bowen Dong and Jiaying Lin and Xiaohui Liu and Rynson W.H. Lau and Wangmeng Zuo},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25173},
  pages     = {935-943},
  title     = {Symmetry-aware transformer-based mirror detection},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). NLIP: Noise-robust language-image pre-training.
<em>AAAI</em>, 926–934. (<a
href="https://doi.org/10.1609/aaai.v37i1.25172">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Large-scale cross-modal pre-training paradigms have recently shown ubiquitous success on a wide range of downstream tasks, e.g., zero-shot classification, retrieval and image captioning. However, their successes highly rely on the scale and quality of web-crawled data that naturally contain much incomplete and noisy information (e.g., wrong or irrelevant contents). Existing works either design manual rules to clean data or generate pseudo-targets as auxiliary signals for reducing noise impact, which do not explicitly tackle both the incorrect and incomplete challenges at the same time. In this paper, to automatically mitigate the impact of noise by solely mining over existing data, we propose a principled Noise-robust Language-Image Pre-training framework (NLIP) to stabilize pre-training via two schemes: noise-harmonization and noise-completion. First, in noise-harmonization scheme, NLIP estimates the noise probability of each pair according to the memorization effect of cross-modal transformers, then adopts noise-adaptive regularization to harmonize the cross-modal alignments with varying degrees. Second, in noise-completion scheme, to enrich the missing object information of text, NLIP injects a concept-conditioned cross-modal decoder to obtain semantic-consistent synthetic captions to complete noisy ones, which uses the retrieved visual concepts (i.e., objects’ names) for the corresponding image to guide captioning generation. By collaboratively optimizing noise-harmonization and noise-completion schemes, our NLIP can alleviate the common noise effects during image-text pre-training in a more efficient way. Extensive experiments show the significant performance improvements of our NLIP using only 26M data over existing pre-trained models (e.g., CLIP, FILIP and BLIP) on 12 zero-shot classification datasets (e.g., +8.6\% over CLIP on average accuracy), MSCOCO image captioning (e.g., +1.9 over BLIP trained with 129M data on CIDEr) and zero-shot image-text retrieval tasks.},
  archive   = {C_AAAI},
  author    = {Runhui Huang and Yanxin Long and Jianhua Han and Hang Xu and Xiwen Liang and Chunjing Xu and Xiaodan Liang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25172},
  pages     = {926-934},
  title     = {NLIP: Noise-robust language-image pre-training},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ClassFormer: Exploring class-aware dependency with
transformer for medical image segmentation. <em>AAAI</em>, 917–925. (<a
href="https://doi.org/10.1609/aaai.v37i1.25171">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Vision Transformers have recently shown impressive performances on medical image segmentation. Despite their strong capability of modeling long-range dependencies, the current methods still give rise to two main concerns in a class-level perspective: (1) intra-class problem: the existing methods lacked in extracting class-specific correspondences of different pixels, which may lead to poor object coverage and/or boundary prediction; (2) inter-class problem: the existing methods failed to model explicit category-dependencies among various objects, which may result in inaccurate localization. In light of these two issues, we propose a novel transformer, called ClassFormer, powered by two appealing transformers, i.e., intra-class dynamic transformer and inter-class interactive transformer, to address the challenge of fully exploration on compactness and discrepancy. Technically, the intra-class dynamic transformer is first designed to decouple representations of different categories with an adaptive selection mechanism for compact learning, which optimally highlights the informative features to reflect the salient keys/values from multiple scales. We further introduce the inter-class interactive transformer to capture the category dependency among different objects, and model class tokens as the representative class centers to guide a global semantic reasoning. As a consequence, the feature consistency is ensured with the expense of intra-class penalization, while inter-class constraint strengthens the feature discriminability between different categories. Extensive empirical evidence shows that ClassFormer can be easily plugged into any architecture, and yields improvements over the state-of-the-art methods in three public benchmarks.},
  archive   = {C_AAAI},
  author    = {Huimin Huang and Shiao Xie and Lanfen Lin and Ruofeng Tong and Yen-Wei Chen and Hong Wang and Yuexiang Li and Yawen Huang and Yefeng Zheng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25171},
  pages     = {917-925},
  title     = {ClassFormer: Exploring class-aware dependency with transformer for medical image segmentation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Resolving task confusion in dynamic expansion architectures
for class incremental learning. <em>AAAI</em>, 908–916. (<a
href="https://doi.org/10.1609/aaai.v37i1.25170">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The dynamic expansion architecture is becoming popular in class incremental learning, mainly due to its advantages in alleviating catastrophic forgetting. However, task confu- sion is not well assessed within this framework, e.g., the discrepancy between classes of different tasks is not well learned (i.e., inter-task confusion, ITC), and certain prior- ity is still given to the latest class batch (i.e., old-new con- fusion, ONC). We empirically validate the side effects of the two types of confusion. Meanwhile, a novel solution called Task Correlated Incremental Learning (TCIL) is pro- posed to encourage discriminative and fair feature utilization across tasks. TCIL performs a multi-level knowledge distil- lation to propagate knowledge learned from old tasks to the new one. It establishes information flow paths at both fea- ture and logit levels, enabling the learning to be aware of old classes. Besides, attention mechanism and classifier re- scoring are applied to generate more fair classification scores. We conduct extensive experiments on CIFAR100 and Ima- geNet100 datasets. The results demonstrate that TCIL con- sistently achieves state-of-the-art accuracy. It mitigates both ITC and ONC, while showing advantages in battle with catas- trophic forgetting even no rehearsal memory is reserved. Source code: https://github.com/YellowPancake/TCIL.},
  archive   = {C_AAAI},
  author    = {Bingchen Huang and Zhineng Chen and Peng Zhou and Jiayin Chen and Zuxuan Wu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25170},
  pages     = {908-916},
  title     = {Resolving task confusion in dynamic expansion architectures for class incremental learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GPTR: Gestalt-perception transformer for diagram object
detection. <em>AAAI</em>, 899–907. (<a
href="https://doi.org/10.1609/aaai.v37i1.25169">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Diagram object detection is the key basis of practical applications such as textbook question answering. Because the diagram mainly consists of simple lines and color blocks, its visual features are sparser than those of natural images. In addition, diagrams usually express diverse knowledge, in which there are many low-frequency object categories in diagrams. These lead to the fact that traditional data-driven detection model is not suitable for diagrams. In this work, we propose a gestalt-perception transformer model for diagram object detection, which is based on an encoder-decoder architecture. Gestalt perception contains a series of laws to explain human perception, that the human visual system tends to perceive patches in an image that are similar, close or connected without abrupt directional changes as a perceptual whole object. Inspired by these thoughts, we build a gestalt-perception graph in transformer encoder, which is composed of diagram patches as nodes and the relationships between patches as edges. This graph aims to group these patches into objects via laws of similarity, proximity, and smoothness implied in these edges, so that the meaningful objects can be effectively detected. The experimental results demonstrate that the proposed GPTR achieves the best results in the diagram object detection task. Our model also obtains comparable results over the competitors in natural image object detection.},
  archive   = {C_AAAI},
  author    = {Xin Hu and Lingling Zhang and Jun Liu and Jinfu Fan and Yang You and Yaqiang Wu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25169},
  pages     = {899-907},
  title     = {GPTR: Gestalt-perception transformer for diagram object detection},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Leveraging sub-class discimination for compositional
zero-shot learning. <em>AAAI</em>, 890–898. (<a
href="https://doi.org/10.1609/aaai.v37i1.25168">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Compositional Zero-Shot Learning (CZSL) aims at identifying unseen compositions composed of previously seen attributes and objects during the test phase. In real images, the visual appearances of attributes and objects (primitive concepts) generally interact with each other. Namely, the visual appearances of an attribute may change when composed with different objects, and vice versa. But previous works overlook this important property. In this paper, we introduce a simple yet effective approach with leveraging sub-class discrimination. Specifically, we define the primitive concepts in different compositions as sub-classes, and then maintain the sub-class discrimination to address the above challenge. More specifically, inspired by the observation that the composed recognition models could account for the differences across sub-classes, we first propose to impose the embedding alignment between the composed and disentangled recognition to incorporate sub-class discrimination at the feature level. Then we develop the prototype modulator networks to adjust the class prototypes w.r.t. the composition information, which can enhance sub-class discrimination at the classifier level. We conduct extensive experiments on the challenging benchmark datasets, and the considerable performance improvement over state-of-the-art approaches is achieved, which indicates the effectiveness of our method. Our code is available at https://github.com/hxm97/SCD-CZSL.},
  archive   = {C_AAAI},
  author    = {Xiaoming Hu and Zilei Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25168},
  pages     = {890-898},
  title     = {Leveraging sub-class discimination for compositional zero-shot learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). High-resolution iterative feedback network for camouflaged
object detection. <em>AAAI</em>, 881–889. (<a
href="https://doi.org/10.1609/aaai.v37i1.25167">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Spotting camouflaged objects that are visually assimilated into the background is tricky for both object detection algorithms and humans who are usually confused or cheated by the perfectly intrinsic similarities between the foreground objects and the background surroundings. To tackle this challenge, we aim to extract the high-resolution texture details to avoid the detail degradation that causes blurred vision in edges and boundaries. We introduce a novel HitNet to refine the low-resolution representations by high-resolution features in an iterative feedback manner, essentially a global loop-based connection among the multi-scale resolutions. To design better feedback feature ﬂow and avoid the feature corruption caused by recurrent path, an iterative feedback strategy is proposed to impose more constraints on each feedback connection. Extensive experiments on four challenging datasets demonstrate that our HitNet breaks the performance bottleneck and achieves significant improvements compared with 29 state-of-the-art methods. In addition, to address the data scarcity in camouflaged scenarios, we provide an application example to convert the salient objects to camouflaged objects, thereby generating more camouflaged training samples from the diverse salient object datasets. Code will be made publicly available.},
  archive   = {C_AAAI},
  author    = {Xiaobin Hu and Shuo Wang and Xuebin Qin and Hang Dai and Wenqi Ren and Donghao Luo and Ying Tai and Ling Shao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25167},
  pages     = {881-889},
  title     = {High-resolution iterative feedback network for camouflaged object detection},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PointCA: Evaluating the robustness of 3D point cloud
completion models against adversarial examples. <em>AAAI</em>, 872–880.
(<a href="https://doi.org/10.1609/aaai.v37i1.25166">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Point cloud completion, as the upstream procedure of 3D recognition and segmentation, has become an essential part of many tasks such as navigation and scene understanding. While various point cloud completion models have demonstrated their powerful capabilities, their robustness against adversarial attacks, which have been proven to be fatally malicious towards deep neural networks, remains unknown. In addition, existing attack approaches towards point cloud classifiers cannot be applied to the completion models due to different output forms and attack purposes. In order to evaluate the robustness of the completion models, we propose PointCA, the first adversarial attack against 3D point cloud completion models. PointCA can generate adversarial point clouds that maintain high similarity with the original ones, while being completed as another object with totally different semantic information. Specifically, we minimize the representation discrepancy between the adversarial example and the target point set to jointly explore the adversarial point clouds in the geometry space and the feature space. Furthermore, to launch a stealthier attack, we innovatively employ the neighbourhood density information to tailor the perturbation constraint, leading to geometry-aware and distribution-adaptive modifications for each point. Extensive experiments against different premier point cloud completion networks show that PointCA can cause the performance degradation from 77.9\% to 16.7\%, with the structure chamfer distance kept below 0.01. We conclude that existing completion models are severely vulnerable to adversarial examples, and state-of-the-art defenses for point cloud classification will be partially invalid when applied to incomplete and uneven point cloud data.},
  archive   = {C_AAAI},
  author    = {Shengshan Hu and Junwei Zhang and Wei Liu and Junhui Hou and Minghui Li and Leo Yu Zhang and Hai Jin and Lichao Sun},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25166},
  pages     = {872-880},
  title     = {PointCA: Evaluating the robustness of 3D point cloud completion models against adversarial examples},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Store and fetch immediately: Everything is all you need for
space-time video super-resolution. <em>AAAI</em>, 863–871. (<a
href="https://doi.org/10.1609/aaai.v37i1.25165">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Existing space-time video super-resolution (ST-VSR) methods fail to achieve high-quality reconstruction since they fail to fully explore the spatial-temporal correlations, long-range components in particular. Although the recurrent structure for ST-VSR adopts bidirectional propagation to aggregate information from the entire video, collecting the temporal information between the past and future via one-stage representations inevitably loses the long-range relations. To alleviate the limitation, this paper proposes an immediate storeand-fetch network to promote long-range correlation learning, where the stored information from the past and future can be refetched to help the representation of the current frame. Specifically, the proposed network consists of two modules: a backward recurrent module (BRM) and a forward recurrent module (FRM). The former first performs backward inference from future to past, while storing future super-resolution (SR) information for each frame. Following that, the latter performs forward inference from past to future to super-resolve all frames, while storing past SR information for each frame. Since FRM inherits SR information from BRM, therefore, spatial and temporal information from the entire video sequence is immediately stored and fetched, which allows drastic improvement for ST-VSR. Extensive experiments both on ST-VSR and space video super-resolution (S-VSR) as well as time video super-resolution (T-VSR) have demonstrated the effectiveness of our proposed method over other state-of-the-art methods on public datasets. Code is available https://github.com/hhhhhumengshun/SFI-STVR},
  archive   = {C_AAAI},
  author    = {Mengshun Hu and Kui Jiang and Zhixiang Nie and Jiahuan Zhou and Zheng Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25165},
  pages     = {863-871},
  title     = {Store and fetch immediately: Everything is all you need for space-time video super-resolution},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-emphasizing network for continuous sign language
recognition. <em>AAAI</em>, 854–862. (<a
href="https://doi.org/10.1609/aaai.v37i1.25164">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Hand and face play an important role in expressing sign language. Their features are usually especially leveraged to improve system performance. However, to effectively extract visual representations and capture trajectories for hands and face, previous methods always come at high computations with increased training complexity. They usually employ extra heavy pose-estimation networks to locate human body keypoints or rely on additional pre-extracted heatmaps for supervision. To relieve this problem, we propose a self-emphasizing network (SEN) to emphasize informative spatial regions in a self-motivated way, with few extra computations and without additional expensive supervision. Specifically, SEN first employs a lightweight subnetwork to incorporate local spatial-temporal features to identify informative regions, and then dynamically augment original features via attention maps. It&#39;s also observed that not all frames contribute equally to recognition. We present a temporal self-emphasizing module to adaptively emphasize those discriminative frames and suppress redundant ones. A comprehensive comparison with previous methods equipped with hand and face features demonstrates the superiority of our method, even though they always require huge computations and rely on expensive extra supervision. Remarkably, with few extra computations, SEN achieves new state-of-the-art accuracy on four large-scale datasets, PHOENIX14, PHOENIX14-T, CSL-Daily, and CSL. Visualizations verify the effects of SEN on emphasizing informative spatial and temporal features. Code is available at https://github.com/hulianyuyy/SEN_CSLR},
  archive   = {C_AAAI},
  author    = {Lianyu Hu and Liqing Gao and Zekang Liu and Wei Feng},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25164},
  pages     = {854-862},
  title     = {Self-emphasizing network for continuous sign language recognition},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-supervised learning for multilevel skeleton-based
forgery detection via temporal-causal consistency of actions.
<em>AAAI</em>, 844–853. (<a
href="https://doi.org/10.1609/aaai.v37i1.25163">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Skeleton-based human action recognition and analysis have become increasingly attainable in many areas, such as security surveillance and anomaly detection. Given the prevalence of skeleton-based applications, tampering attacks on human skeletal features have emerged very recently. In particular, checking the temporal inconsistency and/or incoherence (TII) in the skeletal sequence of human action is a principle of forgery detection. To this end, we propose an approach to self-supervised learning of the temporal causality behind human action, which can effectively check TII in skeletal sequences. Especially, we design a multilevel skeleton-based forgery detection framework to recognize the forgery on frame level, clip level, and action level in terms of learning the corresponding temporal-causal skeleton representations for each level. Specifically, a hierarchical graph convolution network architecture is designed to learn low-level skeleton representations based on physical skeleton connections and high-level action representations based on temporal-causal dependencies for specific actions. Extensive experiments consistently show state-of-the-art results on multilevel forgery detection tasks and superior performance of our framework compared to current competing methods.},
  archive   = {C_AAAI},
  author    = {Liang Hu and Dora D. Liu and Qi Zhang and Usman Naseem and Zhong Yuan Lai},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25163},
  pages     = {844-853},
  title     = {Self-supervised learning for multilevel skeleton-based forgery detection via temporal-causal consistency of actions},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). GAM: Gradient attention module of optimization for point
clouds analysis. <em>AAAI</em>, 835–843. (<a
href="https://doi.org/10.1609/aaai.v37i1.25162">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the point cloud analysis task, the existing local feature aggregation descriptors (LFAD) do not fully utilize the neighborhood information of center points. Previous methods only use the distance information to constrain the local aggregation process, which is easy to be affected by abnormal points and cannot adequately fit the original geometry of the point cloud. This paper argues that fine-grained geometric information (FGGI) plays an important role in the aggregation of local features. Based on this, we propose a gradient-based local attention module to address the above problem, which is called Gradient Attention Module (GAM). GAM simplifies the process of extracting the gradient information in the neighborhood to explicit representation using the Zenith Angle matrix and Azimuth Angle matrix, which makes the module 35X faster. The comprehensive experiments on the ScanObjectNN dataset, ShapeNet dataset, S3DIS dataset, Modelnet40 dataset, and KITTI dataset demonstrate the effectiveness, efficientness, and generalization of our newly proposed GAM for 3D point cloud analysis. Especially in S3DIS, GAM achieves the highest index in the current point-based model with mIoU/OA/mAcc of 74.4\%/90.6\%/83.2\%.},
  archive   = {C_AAAI},
  author    = {Haotian Hu and Fanyi Wang and Zhiwang Zhang and Yaonong Wang and Laifeng Hu and Yanhao Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25162},
  pages     = {835-843},
  title     = {GAM: Gradient attention module of optimization for point clouds analysis},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DarkFeat: Noise-robust feature detector and descriptor for
extremely low-light RAW images. <em>AAAI</em>, 826–834. (<a
href="https://doi.org/10.1609/aaai.v37i1.25161">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Low-light visual perception, such as SLAM or SfM at night, has received increasing attention, in which keypoint detection and local feature description play an important role. Both handcraft designs and machine learning methods have been widely studied for local feature detection and description, however, the performance of existing methods degrades in the extreme low-light scenarios in a certain degree, due to the low signal-to-noise ratio in images. To address this challenge, images in RAW format that retain more raw sensing information have been considered in recent works with a denoise-then-detect scheme. However, existing denoising methods are still insufficient for RAW images and heavily time-consuming, which limits the practical applications of such scheme. In this paper, we propose DarkFeat, a deep learning model which directly detects and describes local features from extreme low-light RAW images in an end-to-end manner. A novel noise robustness map and selective suppression constraints are proposed to effectively mitigate the influence of noise and extract more reliable keypoints. Furthermore, a customized pipeline of synthesizing dataset containing low-light RAW image matching pairs is proposed to extend end-to-end training. Experimental results show that DarkFeat achieves state-of-the-art performance on both indoor and outdoor parts of the challenging MID benchmark, outperforms the denoise-then-detect methods and significantly reduces computational costs up to 70\%. Code is available at https://github.com/THU-LYJ-Lab/DarkFeat.},
  archive   = {C_AAAI},
  author    = {Yuze He and Yubin Hu and Wang Zhao and Jisheng Li and Yong-Jin Liu and Yuxing Han and Jiangtao Wen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25161},
  pages     = {826-834},
  title     = {DarkFeat: Noise-robust feature detector and descriptor for extremely low-light RAW images},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Parameter-efficient model adaptation for vision
transformers. <em>AAAI</em>, 817–825. (<a
href="https://doi.org/10.1609/aaai.v37i1.25160">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In computer vision, it has achieved great transfer learning performance via adapting large-scale pretrained vision models (e.g., vision transformers) to downstream tasks. Common approaches for model adaptation either update all model parameters or leverage linear probes. In this paper, we aim to study parameter-efficient model adaptation strategies for vision transformers on the image classification task. We formulate efficient model adaptation as a subspace training problem and perform a comprehensive benchmarking over different efficient adaptation methods. We conduct an empirical study on each efficient model adaptation method focusing on its performance alongside parameter cost. Furthermore, we propose a parameter-efficient model adaptation framework, which first selects submodules by measuring local intrinsic dimensions and then projects them into subspace for further decomposition via a novel Kronecker Adaptation method. We analyze and compare our method with a diverse set of baseline model adaptation methods (including state-of-the-art methods for pretrained language models). Our method performs the best in terms of the tradeoff between accuracy and parameter efficiency across 20 datasets under the few-shot setting and 7 image classification datasets under the full-shot setting.},
  archive   = {C_AAAI},
  author    = {Xuehai He and Chunyuan Li and Pengchuan Zhang and Jianwei Yang and Xin Eric Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25160},
  pages     = {817-825},
  title     = {Parameter-efficient model adaptation for vision transformers},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Open-vocabulary multi-label classification via multi-modal
knowledge transfer. <em>AAAI</em>, 808–816. (<a
href="https://doi.org/10.1609/aaai.v37i1.25159">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Real-world recognition system often encounters the challenge of unseen labels. To identify such unseen labels, multi-label zero-shot learning (ML-ZSL) focuses on transferring knowledge by a pre-trained textual label embedding (e.g., GloVe). However, such methods only exploit single-modal knowledge from a language model, while ignoring the rich semantic information inherent in image-text pairs. Instead, recently developed open-vocabulary (OV) based methods succeed in exploiting such information of image-text pairs in object detection, and achieve impressive performance. Inspired by the success of OV-based methods, we propose a novel open-vocabulary framework, named multi-modal knowledge transfer (MKT), for multi-label classification. Specifically, our method exploits multi-modal knowledge of image-text pairs based on a vision and language pre-training (VLP) model. To facilitate transferring the image-text matching ability of VLP model, knowledge distillation is employed to guarantee the consistency of image and label embeddings, along with prompt tuning to further update the label embeddings. To further enable the recognition of multiple objects, a simple but effective two-stream module is developed to capture both local and global features. Extensive experimental results show that our method significantly outperforms state-of-the-art methods on public benchmark datasets.},
  archive   = {C_AAAI},
  author    = {Sunan He and Taian Guo and Tao Dai and Ruizhi Qiao and Xiujun Shu and Bo Ren and Shu-Tao Xia},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25159},
  pages     = {808-816},
  title     = {Open-vocabulary multi-label classification via multi-modal knowledge transfer},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). TransVCL: Attention-enhanced video copy localization network
with flexible supervision. <em>AAAI</em>, 799–807. (<a
href="https://doi.org/10.1609/aaai.v37i1.25158">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Video copy localization aims to precisely localize all the copied segments within a pair of untrimmed videos in video retrieval applications. Previous methods typically start from frame-to-frame similarity matrix generated by cosine similarity between frame-level features of the input video pair, and then detect and refine the boundaries of copied segments on similarity matrix under temporal constraints. In this paper, we propose TransVCL: an attention-enhanced video copy localization network, which is optimized directly from initial frame-level features and trained end-to-end with three main components: a customized Transformer for feature enhancement, a correlation and softmax layer for similarity matrix generation, and a temporal alignment module for copied segments localization. In contrast to previous methods demanding the handcrafted similarity matrix, TransVCL incorporates long-range temporal information between feature sequence pair using self- and cross- attention layers. With the joint design and optimization of three components, the similarity matrix can be learned to present more discriminative copied patterns, leading to significant improvements over previous methods on segment-level labeled datasets (VCSL and VCDB). Besides the state-of-the-art performance in fully supervised setting, the attention architecture facilitates TransVCL to further exploit unlabeled or simply video-level labeled data. Additional experiments of supplementing video-level labeled datasets including SVD and FIVR reveal the high flexibility of TransVCL from full supervision to semi-supervision (with or without video-level annotation). Code is publicly available at https://github.com/transvcl/TransVCL.},
  archive   = {C_AAAI},
  author    = {Sifeng He and Yue He and Minlong Lu and Chen Jiang and Xudong Yang and Feng Qian and Xiaobo Zhang and Lei Yang and Jiandong Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25158},
  pages     = {799-807},
  title     = {TransVCL: Attention-enhanced video copy localization network with flexible supervision},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Efficient mirror detection via multi-level heterogeneous
learning. <em>AAAI</em>, 790–798. (<a
href="https://doi.org/10.1609/aaai.v37i1.25157">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present HetNet (Multi-level Heterogeneous Network), a highly efficient mirror detection network. Current mirror detection methods focus more on performance than efficiency, limiting the real-time applications (such as drones). Their lack of efficiency is aroused by the common design of adopting homogeneous modules at different levels, which ignores the difference between different levels of features. In contrast, HetNet detects potential mirror regions initially through low-level understandings (e.g., intensity contrasts) and then combines with high-level understandings (contextual discontinuity for instance) to finalize the predictions. To perform accurate yet efficient mirror detection, HetNet follows an effective architecture that obtains specific information at different stages to detect mirrors. We further propose a multi-orientation intensity-based contrasted module (MIC) and a reflection semantic logical module (RSL), equipped on HetNet, to predict potential mirror regions by low-level understandings and analyze semantic logic in scenarios by high-level understandings, respectively. Compared to the state-of-the-art method, HetNet runs 664\% faster and draws an average performance gain of 8.9\% on MAE, 3.1\% on IoU, and 2.0\% on F-measure on two mirror detection benchmarks. The code is available at https://github.com/Catherine-R-He/HetNet.},
  archive   = {C_AAAI},
  author    = {Ruozhen He and Jiaying Lin and Rynson W.H. Lau},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25157},
  pages     = {790-798},
  title     = {Efficient mirror detection via multi-level heterogeneous learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Weakly-supervised camouflaged object detection with scribble
annotations. <em>AAAI</em>, 781–789. (<a
href="https://doi.org/10.1609/aaai.v37i1.25156">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Existing camouflaged object detection (COD) methods rely heavily on large-scale datasets with pixel-wise annotations. However, due to the ambiguous boundary, annotating camouflage objects pixel-wisely is very time-consuming and labor-intensive, taking ~60mins to label one image. In this paper, we propose the first weakly-supervised COD method, using scribble annotations as supervision. To achieve this, we first relabel 4,040 images in existing camouflaged object datasets with scribbles, which takes ~10s to label one image. As scribble annotations only describe the primary structure of objects without details, for the network to learn to localize the boundaries of camouflaged objects, we propose a novel consistency loss composed of two parts: a cross-view loss to attain reliable consistency over different images, and an inside-view loss to maintain consistency inside a single prediction map. Besides, we observe that humans use semantic information to segment regions near the boundaries of camouflaged objects. Hence, we further propose a feature-guided loss, which includes visual features directly extracted from images and semantically significant features captured by the model. Finally, we propose a novel network for COD via scribble learning on structural information and semantic relations. Our network has two novel modules: the local-context contrasted (LCC) module, which mimics visual inhibition to enhance image contrast/sharpness and expand the scribbles into potential camouflaged regions, and the logical semantic relation (LSR) module, which analyzes the semantic relation to determine the regions representing the camouflaged object. Experimental results show that our model outperforms relevant SOTA methods on three COD benchmarks with an average improvement of 11.0\% on MAE, 3.2\% on S-measure, 2.5\% on E-measure, and 4.4\% on weighted F-measure.},
  archive   = {C_AAAI},
  author    = {Ruozhen He and Qihua Dong and Jiaying Lin and Rynson W.H. Lau},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25156},
  pages     = {781-789},
  title     = {Weakly-supervised camouflaged object detection with scribble annotations},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Target-aware tracking with long-term context attention.
<em>AAAI</em>, 773–780. (<a
href="https://doi.org/10.1609/aaai.v37i1.25155">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Most deep trackers still follow the guidance of the siamese paradigms and use a template that contains only the target without any contextual information, which makes it difficult for the tracker to cope with large appearance changes, rapid target movement, and attraction from similar objects. To alleviate the above problem, we propose a long-term context attention (LCA) module that can perform extensive information fusion on the target and its context from long-term frames, and calculate the target correlation while enhancing target features. The complete contextual information contains the location of the target as well as the state around the target. LCA uses the target state from the previous frame to exclude the interference of similar objects and complex backgrounds, thus accurately locating the target and enabling the tracker to obtain higher robustness and regression accuracy. By embedding the LCA module in Transformer, we build a powerful online tracker with a target-aware backbone, termed as TATrack. In addition, we propose a dynamic online update algorithm based on the classification confidence of historical information without additional calculation burden. Our tracker achieves state-of-the-art performance on multiple benchmarks, with 71.1\% AUC, 89.3\% NP, and 73.0\% AO on LaSOT, TrackingNet, and GOT-10k. The code and trained models are available on https://github.com/hekaijie123/TATrack.},
  archive   = {C_AAAI},
  author    = {Kaijie He and Canlong Zhang and Sheng Xie and Zhixin Li and Zhiwen Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25155},
  pages     = {773-780},
  title     = {Target-aware tracking with long-term context attention},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Generating transferable 3D adversarial point cloud via
random perturbation factorization. <em>AAAI</em>, 764–772. (<a
href="https://doi.org/10.1609/aaai.v37i1.25154">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent studies have demonstrated that existing deep neural networks (DNNs) on 3D point clouds are vulnerable to adversarial examples, especially under the white-box settings where the adversaries have access to model parameters. However, adversarial 3D point clouds generated by existing white-box methods have limited transferability across different DNN architectures. They have only minor threats in real-world scenarios under the black-box settings where the adversaries can only query the deployed victim model. In this paper, we revisit the transferability of adversarial 3D point clouds. We observe that an adversarial perturbation can be randomly factorized into two sub-perturbations, which are also likely to be adversarial perturbations. It motivates us to consider the effects of the perturbation and its sub-perturbations simultaneously to increase the transferability for sub-perturbations also contain helpful information. In this paper, we propose a simple yet effective attack method to generate more transferable adversarial 3D point clouds. Specifically, rather than simply optimizing the loss of perturbation alone, we combine it with its random factorization. We conduct experiments on benchmark dataset, verifying our method&#39;s effectiveness in increasing transferability while preserving high efficiency.},
  archive   = {C_AAAI},
  author    = {Bangyan He and Jian Liu and Yiming Li and Siyuan Liang and Jingzhi Li and Xiaojun Jia and Xiaochun Cao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25154},
  pages     = {764-772},
  title     = {Generating transferable 3D adversarial point cloud via random perturbation factorization},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Few-shot object detection via variational feature
aggregation. <em>AAAI</em>, 755–763. (<a
href="https://doi.org/10.1609/aaai.v37i1.25153">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As few-shot object detectors are often trained with abundant base samples and fine-tuned on few-shot novel examples, the learned models are usually biased to base classes and sensitive to the variance of novel examples. To address this issue, we propose a meta-learning framework with two novel feature aggregation schemes. More precisely, we first present a Class-Agnostic Aggregation (CAA) method, where the query and support features can be aggregated regardless of their categories. The interactions between different classes encourage class-agnostic representations and reduce confusion between base and novel classes. Based on the CAA, we then propose a Variational Feature Aggregation (VFA) method, which encodes support examples into class-level support features for robust feature aggregation. We use a variational autoencoder to estimate class distributions and sample variational features from distributions that are more robust to the variance of support examples. Besides, we decouple classification and regression tasks so that VFA is performed on the classification branch without affecting object localization. Extensive experiments on PASCAL VOC and COCO demonstrate that our method significantly outperforms a strong baseline (up to 16\%) and previous state-of-the-art methods (4\% in average).},
  archive   = {C_AAAI},
  author    = {Jiaming Han and Yuqiang Ren and Jian Ding and Ke Yan and Gui-Song Xia},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25153},
  pages     = {755-763},
  title     = {Few-shot object detection via variational feature aggregation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CALIP: Zero-shot enhancement of CLIP with parameter-free
attention. <em>AAAI</em>, 746–754. (<a
href="https://doi.org/10.1609/aaai.v37i1.25152">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Contrastive Language-Image Pre-training (CLIP) has been shown to learn visual representations with promising zero-shot performance. To further improve its downstream accuracy, existing works propose additional learnable modules upon CLIP and fine-tune them by few-shot training sets. However, the resulting extra training cost and data requirement severely hinder the efficiency for model deployment and knowledge transfer. In this paper, we introduce a free-lunch enhancement method, CALIP, to boost CLIP&#39;s zero-shot performance via a parameter-free attention module. Specifically, we guide visual and textual representations to interact with each other and explore cross-modal informative features via attention. As the pre-training has largely reduced the embedding distances between two modalities, we discard all learnable parameters in the attention and bidirectionally update the multi-modal features, enabling the whole process to be parameter-free and training-free. In this way, the images are blended with textual-aware signals and the text representations become visual-guided for better adaptive zero-shot alignment. We evaluate CALIP on various benchmarks of 14 datasets for both 2D image and 3D point cloud few-shot classification, showing consistent zero-shot performance improvement over CLIP. Based on that, we further insert a small number of linear layers in CALIP&#39;s attention module and verify our robustness under the few-shot settings, which also achieves leading performance compared to existing methods. Those extensive experiments demonstrate the superiority of our approach for efficient enhancement of CLIP. Code is available at https://github.com/ZiyuGuo99/CALIP.},
  archive   = {C_AAAI},
  author    = {Ziyu Guo and Renrui Zhang and Longtian Qiu and Xianzheng Ma and Xupeng Miao and Xuming He and Bin Cui},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25152},
  pages     = {746-754},
  title     = {CALIP: Zero-shot enhancement of CLIP with parameter-free attention},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Social relation reasoning based on triangular constraints.
<em>AAAI</em>, 737–745. (<a
href="https://doi.org/10.1609/aaai.v37i1.25151">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Social networks are essentially in a graph structure where persons act as nodes and the edges connecting nodes denote social relations. The prediction of social relations, therefore, relies on the context in graphs to model the higher-order constraints among relations, which has not been exploited sufficiently by previous works, however. In this paper, we formulate the paradigm of the higher-order constraints in social relations into triangular relational closed-loop structures, i.e., triangular constraints, and further introduce the triangular reasoning graph attention network (TRGAT). Our TRGAT employs the attention mechanism to aggregate features with triangular constraints in the graph, thereby exploiting the higher-order context to reason social relations iteratively. Besides, to acquire better feature representations of persons, we introduce node contrastive learning into relation reasoning. Experimental results show that our method outperforms existing approaches significantly, with higher accuracy and better consistency in generating social relation graphs.},
  archive   = {C_AAAI},
  author    = {Yunfei Guo and Fei Yin and Wei Feng and Xudong Yan and Tao Xue and Shuqi Mei and Cheng-Lin Liu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25151},
  pages     = {737-745},
  title     = {Social relation reasoning based on triangular constraints},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RankDNN: Learning to rank for few-shot learning.
<em>AAAI</em>, 728–736. (<a
href="https://doi.org/10.1609/aaai.v37i1.25150">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper introduces a new few-shot learning pipeline that casts relevance ranking for image retrieval as binary ranking relation classification. In comparison to image classification, ranking relation classification is sample efficient and domain agnostic. Besides, it provides a new perspective on few-shot learning and is complementary to state-of-the-art methods. The core component of our deep neural network is a simple MLP, which takes as input an image triplet encoded as the difference between two vector-Kronecker products, and outputs a binary relevance ranking order. The proposed RankMLP can be built on top of any state-of-the-art feature extractors, and our entire deep neural network is called the ranking deep neural network, or RankDNN. Meanwhile, RankDNN can be flexibly fused with other post-processing methods. During the meta test, RankDNN ranks support images according to their similarity with the query samples, and each query sample is assigned the class label of its nearest neighbor. Experiments demonstrate that RankDNN can effectively improve the performance of its baselines based on a variety of backbones and it outperforms previous state-of-the-art algorithms on multiple few-shot learning benchmarks, including miniImageNet, tieredImageNet, Caltech-UCSD Birds, and CIFAR-FS. Furthermore, experiments on the cross-domain challenge demonstrate the superior transferability of RankDNN.The code is available at: https://github.com/guoqianyu-alberta/RankDNN.},
  archive   = {C_AAAI},
  author    = {Qianyu Guo and Gong Haotong and Xujun Wei and Yanwei Fu and Yizhou Yu and Wenqiang Zhang and Weifeng Ge},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25150},
  pages     = {728-736},
  title     = {RankDNN: Learning to rank for few-shot learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). RAFaRe: Learning robust and accurate non-parametric 3D face
reconstruction from pseudo 2D&amp;3D pairs. <em>AAAI</em>, 719–727. (<a
href="https://doi.org/10.1609/aaai.v37i1.25149">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose a robust and accurate non-parametric method for single-view 3D face reconstruction (SVFR). While tremendous efforts have been devoted to parametric SVFR, a visible gap still lies between the result 3D shape and the ground truth. We believe there are two major obstacles: 1) the representation of the parametric model is limited to a certain face database; 2) 2D images and 3D shapes in the fitted datasets are distinctly misaligned. To resolve these issues, a large-scale pseudo 2D&amp;3D dataset is created by first rendering the detailed 3D faces, then swapping the face in the wild images with the rendered face. These pseudo 2D&amp;3D pairs are created from publicly available datasets which eliminate the gaps between 2D and 3D data while covering diverse appearances, poses, scenes, and illumination. We further propose a non-parametric scheme to learn a well-generalized SVFR model from the created dataset, and the proposed hierarchical signed distance function turns out to be effective in predicting middle-scale and small-scale 3D facial geometry. Our model outperforms previous methods on FaceScape-wild/lab and MICC benchmarks and is well generalized to various appearances, poses, expressions, and in-the-wild environments. The code is released at https://github.com/zhuhao-nju/rafare.},
  archive   = {C_AAAI},
  author    = {Longwei Guo and Hao Zhu and Yuanxun Lu and Menghua Wu and Xun Cao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25149},
  pages     = {719-727},
  title     = {RAFaRe: Learning robust and accurate non-parametric 3D face reconstruction from pseudo 2D&amp;3D pairs},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ShadowFormer: Global context helps shadow removal.
<em>AAAI</em>, 710–718. (<a
href="https://doi.org/10.1609/aaai.v37i1.25148">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent deep learning methods have achieved promising results in image shadow removal. However, most of the existing approaches focus on working locally within shadow and non-shadow regions, resulting in severe artifacts around the shadow boundaries as well as inconsistent illumination between shadow and non-shadow regions. It is still challenging for the deep shadow removal model to exploit the global contextual correlation between shadow and non-shadow regions. In this work, we first propose a Retinex-based shadow model, from which we derive a novel transformer-based network, dubbed ShandowFormer, to exploit non-shadow regions to help shadow region restoration. A multi-scale channel attention framework is employed to hierarchically capture the global information. Based on that, we propose a Shadow-Interaction Module (SIM) with Shadow-Interaction Attention (SIA) in the bottleneck stage to effectively model the context correlation between shadow and non-shadow regions. We conduct extensive experiments on three popular public datasets, including ISTD, ISTD+, and SRD, to evaluate the proposed method. Our method achieves state-of-the-art performance by using up to 150X fewer model parameters.},
  archive   = {C_AAAI},
  author    = {Lanqing Guo and Siyu Huang and Ding Liu and Hao Cheng and Bihan Wen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25148},
  pages     = {710-718},
  title     = {ShadowFormer: Global context helps shadow removal},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Underwater ranker: Learn which is better and how to be
better. <em>AAAI</em>, 702–709. (<a
href="https://doi.org/10.1609/aaai.v37i1.25147">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we present a ranking-based underwater image quality assessment (UIQA) method, abbreviated as URanker. The URanker is built on the efficient conv-attentional image Transformer. In terms of underwater images, we specially devise (1) the histogram prior that embeds the color distribution of an underwater image as histogram token to attend global degradation and (2) the dynamic cross-scale correspondence to model local degradation. The final prediction depends on the class tokens from different scales, which comprehensively considers multi-scale dependencies. With the margin ranking loss, our URanker can accurately rank the order of underwater images of the same scene enhanced by different underwater image enhancement (UIE) algorithms according to their visual quality. To achieve that, we also contribute a dataset, URankerSet, containing sufficient results enhanced by different UIE algorithms and the corresponding perceptual rankings, to train our URanker. Apart from the good performance of URanker, we found that a simple U-shape UIE network can obtain promising performance when it is coupled with our pre-trained URanker as additional supervision. In addition, we also propose a normalization tail that can significantly improve the performance of UIE networks. Extensive experiments demonstrate the state-of-the-art performance of our method. The key designs of our method are discussed. Our code and dataset are available at https://li-chongyi.github.io/URanker_files/.},
  archive   = {C_AAAI},
  author    = {Chunle Guo and Ruiqi Wu and Xin Jin and Linghao Han and Weidong Zhang and Zhi Chai and Chongyi Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25147},
  pages     = {702-709},
  title     = {Underwater ranker: Learn which is better and how to be better},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Flexible 3D lane detection by hierarchical shape matching.
<em>AAAI</em>, 694–701. (<a
href="https://doi.org/10.1609/aaai.v37i1.25146">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As one of the basic while vital technologies for HD map construction, 3D lane detection is still an open problem due to varying visual conditions, complex typologies, and strict demands for precision. In this paper, an end-to-end flexible and hierarchical lane detector is proposed to precisely predict 3D lane lines from point clouds. Specifically, we design a hierarchical network predicting flexible representations of lane shapes at different levels, simultaneously collecting global instance semantics and avoiding local errors. In the global scope, we propose to regress parametric curves w.r.t adaptive axes that help to make more robust predictions towards complex scenes, while in the local vision the structure of lane segment is detected in each of the dynamic anchor cells sampled along the global predicted curves. Moreover, corresponding global and local shape matching losses and anchor cell generation strategies are designed. Experiments on two datasets show that we overwhelm current top methods under high precision standards, and full ablation studies also verify each part of our method. Our codes will be released at https://github.com/Doo-do/FHLD.},
  archive   = {C_AAAI},
  author    = {Zhihao Guan and Ruixin Liu and Zejian Yuan and Ao Liu and Kun Tang and Tong Zhou and Erlong Li and Chao Zheng and Shuqi Mei},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25146},
  pages     = {694-701},
  title     = {Flexible 3D lane detection by hierarchical shape matching},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Incremental image de-raining via associative memory.
<em>AAAI</em>, 685–693. (<a
href="https://doi.org/10.1609/aaai.v37i1.25145">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {While deep learning models have achieved the state-of-the-art performance on single-image rain removal, most methods only consider learning fixed mapping rules on the single synthetic dataset for lifetime. This limits the real-life application as iterative optimization may change mapping rules and training samples. However, when models learn a sequence of datasets in multiple incremental steps, they are susceptible to catastrophic forgetting that adapts to new incremental episodes while failing to preserve previously acquired mapping rules. In this paper, we argue the importance of sample diversity in the episodes on the iterative optimization, and propose a novel memory management method, Associative Memory, to achieve incremental image de-raining. It bridges connections between current and past episodes for feature reconstruction by sampling domain mappings of past learning steps, and guides the learning to trace the current pathway back to the historical environment without storing extra data. Experiments demonstrate that our method can achieve better performance than existing approaches on both inhomogeneous and incremental datasets within the spectrum of highly compact systems.},
  archive   = {C_AAAI},
  author    = {Yi Gu and Chao Wang and Jie Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25145},
  pages     = {685-693},
  title     = {Incremental image de-raining via associative memory},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Progressive multi-view human mesh recovery with
self-supervision. <em>AAAI</em>, 676–684. (<a
href="https://doi.org/10.1609/aaai.v37i1.25144">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {To date, little attention has been given to multi-view 3D human mesh estimation, despite real-life applicability (e.g., motion capture, sport analysis) and robustness to single-view ambiguities. Existing solutions typically suffer from poor generalization performance to new settings, largely due to the limited diversity of image/3D-mesh pairs in multi-view training data. To address this shortcoming, people have explored the use of synthetic images. But besides the usual impact of visual gap between rendered and target data, synthetic-data-driven multi-view estimators also suffer from overfitting to the camera viewpoint distribution sampled during training which usually differs from real-world distributions. Tackling both challenges, we propose a novel simulation-based training pipeline for multi-view human mesh recovery, which (a) relies on intermediate 2D representations which are more robust to synthetic-to-real domain gap; (b) leverages learnable calibration and triangulation to adapt to more diversified camera setups; and (c) progressively aggregates multi-view information in a canonical 3D space to remove ambiguities in 2D representations. Through extensive benchmarking, we demonstrate the superiority of the proposed solution especially for unseen in-the-wild scenarios.},
  archive   = {C_AAAI},
  author    = {Xuan Gong and Liangchen Song and Meng Zheng and Benjamin Planche and Terrence Chen and Junsong Yuan and David Doermann and Ziyan Wu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25144},
  pages     = {676-684},
  title     = {Progressive multi-view human mesh recovery with self-supervision},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Point-teaching: Weakly semi-supervised object detection with
point annotations. <em>AAAI</em>, 667–675. (<a
href="https://doi.org/10.1609/aaai.v37i1.25143">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Point annotations are considerably more time-efficient than bounding box annotations. However, how to use cheap point annotations to boost the performance of semi-supervised object detection is still an open question. In this work, we present Point-Teaching, a weakly- and semi-supervised object detection framework to fully utilize the point annotations. Specifically, we propose a Hungarian-based point-matching method to generate pseudo labels for point-annotated images. We further propose multiple instance learning (MIL) approaches at the level of images and points to supervise the object detector with point annotations. Finally, we propose a simple data augmentation, named Point-Guided Copy-Paste, to reduce the impact of those unmatched points. Experiments demonstrate the effectiveness of our method on a few datasets and various data regimes. In particular, Point-Teaching outperforms the previous best method Group R-CNN by 3.1 AP with 5\% fully labeled data and 2.3 AP with 30\% fully labeled data on the MS COCO dataset. We believe that our proposed framework can largely lower the bar of learning accurate object detectors and pave the way for its broader applications. The code is available at https://github.com/YongtaoGe/Point-Teaching.},
  archive   = {C_AAAI},
  author    = {Yongtao Ge and Qiang Zhou and Xinlong Wang and Chunhua Shen and Zhibin Wang and Hao Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25143},
  pages     = {667-675},
  title     = {Point-teaching: Weakly semi-supervised object detection with point annotations},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Causal intervention for human trajectory prediction with
cross attention mechanism. <em>AAAI</em>, 658–666. (<a
href="https://doi.org/10.1609/aaai.v37i1.25142">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Human trajectory Prediction (HTP) in complex social environments plays a crucial and fundamental role in artificial intelligence systems. Conventional methods make use of both history behaviors and social interactions to forecast future trajectories. However, we demonstrate that the social environment is a confounder that misleads the model to learn spurious correlations between history and future trajectories. To end this, we first formulate the social environment, history and future trajectory variables into a structural causal model to analyze the causalities among them. Based on causal intervention rather than conventional likelihood, we propose a Social Environment ADjustment (SEAD) method, to remove the confounding effect of the social environment. The core of our method is implemented by a Social Cross Attention (SCA) module, which is universal, simple and effective. Our method has consistent improvements on ETH-UCY datasets with three baseline models and achieves competitive performances with existing methods.},
  archive   = {C_AAAI},
  author    = {Chunjiang Ge and Shiji Song and Gao Huang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25142},
  pages     = {658-666},
  title     = {Causal intervention for human trajectory prediction with cross attention mechanism},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Scene-level sketch-based image retrieval with minimal
pairwise supervision. <em>AAAI</em>, 650–657. (<a
href="https://doi.org/10.1609/aaai.v37i1.25141">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The sketch-based image retrieval (SBIR) task has long been researched at the instance level, where both query sketches and candidate images are assumed to contain only one dominant object. This strong assumption constrains its application, especially with the increasingly popular intelligent terminals and human-computer interaction technology. In this work, a more general scene-level SBIR task is explored, where sketches and images can both contain multiple object instances. The new general task is extremely challenging due to several factors: (i) scene-level SBIR inherently shares sketch-specific difficulties with instance-level SBIR (e.g., sparsity, abstractness, and diversity), (ii) the cross-modal similarity is measured between two partially aligned domains (i.e., not all objects in images are drawn in scene sketches), and (iii) besides instance-level visual similarity, a more complex multi-dimensional scene-level feature matching problem is imposed (including appearance, semantics, layout, etc.). Addressing these challenges, a novel Conditional Graph Autoencoder model is proposed to deal with scene-level sketch-images retrieval. More importantly, the model can be trained with only pairwise supervision, which distinguishes our study from others in that elaborate instance-level annotations (for example, bounding boxes) are no longer required. Extensive experiments confirm the ability of our model to robustly retrieve multiple related objects at the scene level and exhibit superior performance beyond strong competitors.},
  archive   = {C_AAAI},
  author    = {Ce Ge and Jingyu Wang and Qi Qi and Haifeng Sun and Tong Xu and Jianxin Liao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25141},
  pages     = {650-657},
  title     = {Scene-level sketch-based image retrieval with minimal pairwise supervision},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploit domain-robust optical flow in domain adaptive video
semantic segmentation. <em>AAAI</em>, 641–649. (<a
href="https://doi.org/10.1609/aaai.v37i1.25140">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Domain adaptive semantic segmentation aims to exploit the pixel-level annotated samples on source domain to assist the segmentation of unlabeled samples on target domain. For such a task, the key is to construct reliable supervision signals on target domain. However, existing methods can only provide unreliable supervision signals constructed by segmentation model (SegNet) that are generally domain-sensitive. In this work, we try to find a domain-robust clue to construct more reliable supervision signals. Particularly, we experimentally observe the domain-robustness of optical flow in video tasks as it mainly represents the motion characteristics of scenes. However, optical flow cannot be directly used as supervision signals of semantic segmentation since both of them essentially represent different information. To tackle this issue, we first propose a novel Segmentation-to-Flow Module (SFM) that converts semantic segmentation maps to optical flows, named the segmentation-based flow (SF), and then propose a Segmentation-based Flow Consistency (SFC) method to impose consistency between SF and optical flow, which can implicitly supervise the training of segmentation model. The extensive experiments on two challenging benchmarks demonstrate the effectiveness of our method, and it outperforms previous state-of-the-art methods with considerable performance improvement. Our code is available at https://github.com/EdenHazardan/SFC.},
  archive   = {C_AAAI},
  author    = {Yuan Gao and Zilei Wang and Jiafan Zhuang and Yixin Zhang and Junjie Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25140},
  pages     = {641-649},
  title     = {Exploit domain-robust optical flow in domain adaptive video semantic segmentation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SEFormer: Structure embedding transformer for 3D object
detection. <em>AAAI</em>, 632–640. (<a
href="https://doi.org/10.1609/aaai.v37i1.25139">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Effectively preserving and encoding structure features from objects in irregular and sparse LiDAR points is a crucial challenge to 3D object detection on the point cloud. Recently, Transformer has demonstrated promising performance on many 2D and even 3D vision tasks. Compared with the fixed and rigid convolution kernels, the self-attention mechanism in Transformer can adaptively exclude the unrelated or noisy points and is thus suitable for preserving the local spatial structure in the irregular LiDAR point cloud. However, Transformer only performs a simple sum on the point features, based on the self-attention mechanism, and all the points share the same transformation for value. A such isotropic operation cannot capture the direction-distance-oriented local structure, which is essential for 3D object detection. In this work, we propose a Structure-Embedding transFormer (SEFormer), which can not only preserve the local structure as a traditional Transformer but also have the ability to encode the local structure. Compared to the self-attention mechanism in traditional Transformer, SEFormer learns different feature transformations for value points based on the relative directions and distances to the query point. Then we propose a SEFormer-based network for high-performance 3D object detection. Extensive experiments show that the proposed architecture can achieve SOTA results on the Waymo Open Dataset, one of the most significant 3D detection benchmarks for autonomous driving. Specifically, SEFormer achieves 79.02\% mAP, which is 1.2\% higher than existing works. https://github.com/tdzdog/SEFormer.},
  archive   = {C_AAAI},
  author    = {Xiaoyu Feng and Heming Du and Hehe Fan and Yueqi Duan and Yongpan Liu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25139},
  pages     = {632-640},
  title     = {SEFormer: Structure embedding transformer for 3D object detection},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Unsupervised domain adaptation for medical image
segmentation by selective entropy constraints and adaptive semantic
alignment. <em>AAAI</em>, 623–631. (<a
href="https://doi.org/10.1609/aaai.v37i1.25138">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Generalizing a deep learning model to new domains is crucial for computer-aided medical diagnosis systems. Most existing unsupervised domain adaptation methods have made significant progress in reducing the domain distribution gap through adversarial training. However, these methods may still produce overconfident but erroneous results on unseen target images. This paper proposes a new unsupervised domain adaptation framework for cross-modality medical image segmentation. Specifically, We first introduce two data augmentation approaches to generate two sets of semantics-preserving augmented images. Based on the model&#39;s predictive consistency on these two sets of augmented images, we identify reliable and unreliable pixels. We then perform a selective entropy constraint: we minimize the entropy of reliable pixels to increase their confidence while maximizing the entropy of unreliable pixels to reduce their confidence. Based on the identified reliable and unreliable pixels, we further propose an adaptive semantic alignment module which performs class-level distribution adaptation by minimizing the distance between same class prototypes between domains, where unreliable pixels are removed to derive more accurate prototypes. We have conducted extensive experiments on the cross-modality cardiac structure segmentation task. The experimental results show that the proposed method significantly outperforms the state-of-the-art comparison algorithms. Our code and data are available at https://github.com/fengweie/SE_ASA.},
  archive   = {C_AAAI},
  author    = {Wei Feng and Lie Ju and Lin Wang and Kaimin Song and Xin Zhao and Zongyuan Ge},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25138},
  pages     = {623-631},
  title     = {Unsupervised domain adaptation for medical image segmentation by selective entropy constraints and adaptive semantic alignment},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Uncertainty-aware image captioning. <em>AAAI</em>, 614–622.
(<a href="https://doi.org/10.1609/aaai.v37i1.25137">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {It is well believed that the higher uncertainty in a word of the caption, the more inter-correlated context information is required to determine it. However, current image captioning methods usually consider the generation of all words in a sentence sequentially and equally. In this paper, we propose an uncertainty-aware image captioning framework, which parallelly and iteratively operates insertion of discontinuous candidate words between existing words from easy to difficult until converged. We hypothesize that high-uncertainty words in a sentence need more prior information to make a correct decision and should be produced at a later stage. The resulting non-autoregressive hierarchy makes the caption generation explainable and intuitive. Specifically, we utilize an image-conditioned bag-of-word model to measure the word uncertainty and apply a dynamic programming algorithm to construct the training pairs. During inference, we devise an uncertainty-adaptive parallel beam search technique that yields an empirically logarithmic time complexity. Extensive experiments on the MS COCO benchmark reveal that our approach outperforms the strong baseline and related methods on both captioning quality as well as decoding speed.},
  archive   = {C_AAAI},
  author    = {Zhengcong Fei and Mingyuan Fan and Li Zhu and Junshi Huang and Xiaoming Wei and Xiaolin Wei},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25137},
  pages     = {614-622},
  title     = {Uncertainty-aware image captioning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Weakly-supervised semantic segmentation for histopathology
images based on dataset synthesis and feature consistency constraint.
<em>AAAI</em>, 606–613. (<a
href="https://doi.org/10.1609/aaai.v37i1.25136">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Tissue segmentation is a critical task in computational pathology due to its desirable ability to indicate the prognosis of cancer patients. Currently, numerous studies attempt to use image-level labels to achieve pixel-level segmentation to reduce the need for fine annotations. However, most of these methods are based on class activation map, which suffers from inaccurate segmentation boundaries. To address this problem, we propose a novel weakly-supervised tissue segmentation framework named PistoSeg, which is implemented under a fully-supervised manner by transferring tissue category labels to pixel-level masks. Firstly, a dataset synthesis method is proposed based on Mosaic transformation to generate synthesized images with pixel-level masks. Next, considering the difference between synthesized and real images, this paper devises an attention-based feature consistency, which directs the training process of a proposed pseudo-mask refining module. Finally, the refined pseudo-masks are used to train a precise segmentation model for testing. Experiments based on WSSS4LUAD and BCSS-WSSS validate that PistoSeg outperforms the state-of-the-art methods. The code is released at https://github.com/Vison307/PistoSeg.},
  archive   = {C_AAAI},
  author    = {Zijie Fang and Yang Chen and Yifeng Wang and Zhi Wang and Xiangyang Ji and Yongbing Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25136},
  pages     = {606-613},
  title     = {Weakly-supervised semantic segmentation for histopathology images based on dataset synthesis and feature consistency constraint},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). One is all: Bridging the gap between neural radiance fields
architectures with progressive volume distillation. <em>AAAI</em>,
597–605. (<a href="https://doi.org/10.1609/aaai.v37i1.25135">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Neural Radiance Fields (NeRF) methods have proved effective as compact, high-quality and versatile representations for 3D scenes, and enable downstream tasks such as editing, retrieval, navigation, etc. Various neural architectures are vying for the core structure of NeRF, including the plain Multi-Layer Perceptron (MLP), sparse tensors, low-rank tensors, hashtables and their compositions. Each of these representations has its particular set of trade-offs. For example, the hashtable-based representations admit faster training and rendering but their lack of clear geometric meaning hampers downstream tasks like spatial-relation-aware editing. In this paper, we propose Progressive Volume Distillation (PVD), a systematic distillation method that allows any-to-any conversions between different architectures, including MLP, sparse or low-rank tensors, hashtables and their compositions. PVD consequently empowers downstream applications to optimally adapt the neural representations for the task at hand in a post hoc fashion. The conversions are fast, as distillation is progressively performed on different levels of volume representations, from shallower to deeper. We also employ special treatment of density to deal with its specific numerical instability problem. Empirical evidence is presented to validate our method on the NeRF-Synthetic, LLFF and TanksAndTemples datasets. For example, with PVD, an MLP-based NeRF model can be distilled from a hashtable-based Instant-NGP model at a 10~20X faster speed than being trained the original NeRF from scratch, while achieving a superior level of synthesis quality. Code is available at https://github.com/megvii-research/AAAI2023-PVD.},
  archive   = {C_AAAI},
  author    = {Shuangkang Fang and Weixin Xu and Heng Wang and Yi Yang and Yufeng Wang and Shuchang Zhou},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25135},
  pages     = {597-605},
  title     = {One is all: Bridging the gap between neural radiance fields architectures with progressive volume distillation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Target-free text-guided image manipulation. <em>AAAI</em>,
588–596. (<a href="https://doi.org/10.1609/aaai.v37i1.25134">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We tackle the problem of target-free text-guided image manipulation, which requires one to modify the input reference image based on the given text instruction, while no ground truth target image is observed during training. To address this challenging task, we propose a Cyclic-Manipulation GAN (cManiGAN) in this paper, which is able to realize where and how to edit the image regions of interest. Specifically, the image editor in cManiGAN learns to identify and complete the input image, while cross-modal interpreter and reasoner are deployed to verify the semantic correctness of the output image based on the input instruction. While the former utilizes factual/counterfactual description learning for authenticating the image semantics, the latter predicts the &quot;undo&quot; instruction and provides pixel-level supervision for the training of cManiGAN. With the above operational cycle-consistency, our cManiGAN can be trained in the above weakly supervised setting. We conduct extensive experiments on the datasets of CLEVR and COCO datasets, and the effectiveness and generalizability of our proposed method can be successfully verified. Project page: sites.google.com/view/wancyuanfan/projects/cmanigan.},
  archive   = {C_AAAI},
  author    = {Wan-Cyuan Fan and Cheng-Fu Yang and Chiao-An Yang and Yu-Chiang Frank Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25134},
  pages     = {588-596},
  title     = {Target-free text-guided image manipulation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Frido: Feature pyramid diffusion for complex scene image
synthesis. <em>AAAI</em>, 579–587. (<a
href="https://doi.org/10.1609/aaai.v37i1.25133">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Diffusion models (DMs) have shown great potential for high-quality image synthesis. However, when it comes to producing images with complex scenes, how to properly describe both image global structures and object details remains a challenging task. In this paper, we present Frido, a Feature Pyramid Diffusion model performing a multi-scale coarse-to-fine denoising process for image synthesis. Our model decomposes an input image into scale-dependent vector quantized features, followed by a coarse-to-fine gating for producing image output. During the above multi-scale representation learning stage, additional input conditions like text, scene graph, or image layout can be further exploited. Thus, Frido can be also applied for conditional or cross-modality image synthesis. We conduct extensive experiments over various unconditioned and conditional image generation tasks, ranging from text-to-image synthesis, layout-to-image, scene-graph-to-image, to label-to-image. More specifically, we achieved state-of-the-art FID scores on five benchmarks, namely layout-to-image on COCO and OpenImages, scene-graph-to-image on COCO and Visual Genome, and label-to-image on COCO.},
  archive   = {C_AAAI},
  author    = {Wan-Cyuan Fan and Yen-Chun Chen and DongDong Chen and Yu Cheng and Lu Yuan and Yu-Chiang Frank Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25133},
  pages     = {579-587},
  title     = {Frido: Feature pyramid diffusion for complex scene image synthesis},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Few-shot defect image generation via defect-aware feature
manipulation. <em>AAAI</em>, 571–578. (<a
href="https://doi.org/10.1609/aaai.v37i1.25132">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The performances of defect inspection have been severely hindered by insufficient defect images in industries, which can be alleviated by generating more samples as data augmentation. We propose the first defect image generation method in the challenging few-shot cases. Given just a handful of defect images and relatively more defect-free ones, our goal is to augment the dataset with new defect images. Our method consists of two training stages. First, we train a data-efficient StyleGAN2 on defect-free images as the backbone. Second, we attach defect-aware residual blocks to the backbone, which learn to produce reasonable defect masks and accordingly manipulate the features within the masked regions by training the added modules on limited defect images. Extensive experiments on MVTec AD dataset not only validate the effectiveness of our method in generating realistic and diverse defect images, but also manifest the benefits it brings to downstream defect inspection tasks. Codes are available at https://github.com/Ldhlwh/DFMGAN.},
  archive   = {C_AAAI},
  author    = {Yuxuan Duan and Yan Hong and Li Niu and Liqing Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25132},
  pages     = {571-578},
  title     = {Few-shot defect image generation via defect-aware feature manipulation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Domain-general crowd counting in unseen scenarios.
<em>AAAI</em>, 561–570. (<a
href="https://doi.org/10.1609/aaai.v37i1.25131">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Domain shift across crowd data severely hinders crowd counting models to generalize to unseen scenarios. Although domain adaptive crowd counting approaches close this gap to a certain extent, they are still dependent on the target domain data to adapt (e.g. finetune) their models to the specific domain. In this paper, we instead target to train a model based on a single source domain which can generalize well on any unseen domain. This falls into the realm of domain generalization that remains unexplored in crowd counting. We first introduce a dynamic sub-domain division scheme which divides the source domain into multiple sub-domains such that we can initiate a meta-learning framework for domain generalization. The sub-domain division is dynamically refined during the meta-learning. Next, in order to disentangle domain-invariant information from domain-specific information in image features, we design the domain-invariant and -specific crowd memory modules to re-encode image features. Two types of losses, i.e. feature reconstruction and orthogonal losses, are devised to enable this disentanglement. Extensive experiments on several standard crowd counting benchmarks i.e. SHA, SHB, QNRF, and NWPU, show the strong generalizability of our method. Our code is available at: https://github.com/ZPDu/Domain-general-Crowd-Counting-in-Unseen-Scenarios},
  archive   = {C_AAAI},
  author    = {Zhipeng Du and Jiankang Deng and Miaojing Shi},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25131},
  pages     = {561-570},
  title     = {Domain-general crowd counting in unseen scenarios},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). PeCo: Perceptual codebook for BERT pre-training of vision
transformers. <em>AAAI</em>, 552–560. (<a
href="https://doi.org/10.1609/aaai.v37i1.25130">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper explores a better prediction target for BERT pre-training of vision transformers. We observe that current prediction targets disagree with human perception judgment. This contradiction motivates us to learn a perceptual prediction target. We argue that perceptually similar images should stay close to each other in the prediction target space. We surprisingly find one simple yet effective idea: enforcing perceptual similarity during the dVAE training. Moreover, we adopt a self-supervised transformer model for deep feature extraction and show that it works well for calculating perceptual similarity. We demonstrate that such learned visual tokens indeed exhibit better semantic meanings, and help pre-training achieve superior transfer performance in various downstream tasks. For example, we achieve 84.5\% Top-1 accuracy on ImageNet-1K with ViT-B backbone, outperforming the competitive method BEiT by +1.3\% under the same pre-training epochs. Our approach also gets significant improvement on object detection and segmentation on COCO and semantic segmentation on ADE20K. Equipped with a larger backbone ViT-H, we achieve the state-of-the-art ImageNet accuracy (88.3\%) among methods using only ImageNet-1K data.},
  archive   = {C_AAAI},
  author    = {Xiaoyi Dong and Jianmin Bao and Ting Zhang and Dongdong Chen and Weiming Zhang and Lu Yuan and Dong Chen and Fang Wen and Nenghai Yu and Baining Guo},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25130},
  pages     = {552-560},
  title     = {PeCo: Perceptual codebook for BERT pre-training of vision transformers},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Incremental-DETR: Incremental few-shot object detection via
self-supervised learning. <em>AAAI</em>, 543–551. (<a
href="https://doi.org/10.1609/aaai.v37i1.25129">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Incremental few-shot object detection aims at detecting novel classes without forgetting knowledge of the base classes with only a few labeled training data from the novel classes. Most related prior works are on incremental object detection that rely on the availability of abundant training samples per novel class that substantially limits the scalability to real-world setting where novel data can be scarce. In this paper, we propose the Incremental-DETR that does incremental few-shot object detection via fine-tuning and self-supervised learning on the DETR object detector. To alleviate severe over-fitting with few novel class data, we first fine-tune the class-specific components of DETR with self-supervision from additional object proposals generated using Selective Search as pseudo labels. We further introduce an incremental few-shot fine-tuning strategy with knowledge distillation on the class-specific components of DETR to encourage the network in detecting novel classes without forgetting the base classes. Extensive experiments conducted on standard incremental object detection and incremental few-shot object detection settings show that our approach significantly outperforms state-of-the-art methods by a large margin. Our source code is available at https://github.com/dongnana777/Incremental-DETR.},
  archive   = {C_AAAI},
  author    = {Na Dong and Yongqiang Zhang and Mingli Ding and Gim Hee Lee},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25129},
  pages     = {543-551},
  title     = {Incremental-DETR: Incremental few-shot object detection via self-supervised learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Exploring tuning characteristics of ventral stream’s neurons
for few-shot image classification. <em>AAAI</em>, 534–542. (<a
href="https://doi.org/10.1609/aaai.v37i1.25128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Human has the remarkable ability of learning novel objects by browsing extremely few examples, which may be attributed to the generic and robust feature extracted in the ventral stream of our brain for representing visual objects. In this sense, the tuning characteristics of ventral stream&#39;s neurons can be useful prior knowledge to improve few-shot classification. Specifically, we computationally model two groups of neurons found in ventral stream which are respectively sensitive to shape cues and color cues. Then we propose the hierarchical feature regularization method with these neuron models to regularize the backbone of a few-shot model, thus making it produce more generic and robust features for few-shot classification. In addition, to simulate the tuning characteristic that neuron firing at a higher rate in response to foreground stimulus elements compared to background elements, which we call belongingness, we design a foreground segmentation algorithm based on the observation that the foreground object usually does not appear at the edge of the picture, then multiply the foreground mask with the backbone of few-shot model. Our method is model-agnostic and can be applied to few-shot models with different backbones, training paradigms and classifiers.},
  archive   = {C_AAAI},
  author    = {Lintao Dong and Wei Zhai and Zheng-Jun Zha},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25128},
  pages     = {534-542},
  title     = {Exploring tuning characteristics of ventral stream’s neurons for few-shot image classification},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hierarchical contrast for unsupervised skeleton-based action
representation learning. <em>AAAI</em>, 525–533. (<a
href="https://doi.org/10.1609/aaai.v37i1.25127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper targets unsupervised skeleton-based action representation learning and proposes a new Hierarchical Contrast (HiCo) framework. Different from the existing contrastive-based solutions that typically represent an input skeleton sequence into instance-level features and perform contrast holistically, our proposed HiCo represents the input into multiple-level features and performs contrast in a hierarchical manner. Specifically, given a human skeleton sequence, we represent it into multiple feature vectors of different granularities from both temporal and spatial domains via sequence-to-sequence (S2S) encoders and unified downsampling modules. Besides, the hierarchical contrast is conducted in terms of four levels: instance level, domain level, clip level, and part level. Moreover, HiCo is orthogonal to the S2S encoder, which allows us to flexibly embrace state-of-the-art S2S encoders. Extensive experiments on four datasets, i.e., NTU-60, NTU-120, PKU-I and PKU-II, show that HiCo achieves a new state-of-the-art for unsupervised skeleton-based action representation learning in two downstream tasks including action recognition and retrieval, and its learned action representation is of good transferability. Besides, we also show that our framework is effective for semi-supervised skeleton-based action recognition. Our code is available at https://github.com/HuiGuanLab/HiCo.},
  archive   = {C_AAAI},
  author    = {Jianfeng Dong and Shengkai Sun and Zhonglin Liu and Shujie Chen and Baolong Liu and Xun Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25127},
  pages     = {525-533},
  title     = {Hierarchical contrast for unsupervised skeleton-based action representation learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Head-free lightweight semantic segmentation with linear
transformer. <em>AAAI</em>, 516–524. (<a
href="https://doi.org/10.1609/aaai.v37i1.25126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Existing semantic segmentation works have been mainly focused on designing effective decoders; however, the computational load introduced by the overall structure has long been ignored, which hinders their applications on resource-constrained hardwares. In this paper, we propose a head-free lightweight architecture specifically for semantic segmentation, named Adaptive Frequency Transformer (AFFormer). AFFormer adopts a parallel architecture to leverage prototype representations as specific learnable local descriptions which replaces the decoder and preserves the rich image semantics on high-resolution features. Although removing the decoder compresses most of the computation, the accuracy of the parallel structure is still limited by low computational resources. Therefore, we employ heterogeneous operators (CNN and vision Transformer) for pixel embedding and prototype representations to further save computational costs. Moreover, it is very difficult to linearize the complexity of the vision Transformer from the perspective of spatial domain. Due to the fact that semantic segmentation is very sensitive to frequency information, we construct a lightweight prototype learning block with adaptive frequency filter of complexity O(n) to replace standard self attention with O(n^2). Extensive experiments on widely adopted datasets demonstrate that AFFormer achieves superior accuracy while retaining only 3M parameters. On the ADE20K dataset, AFFormer achieves 41.8 mIoU and 4.6 GFLOPs, which is 4.4 mIoU higher than Segformer, with 45\% less GFLOPs. On the Cityscapes dataset, AFFormer achieves 78.7 mIoU and 34.4 GFLOPs, which is 2.5 mIoU higher than Segformer with 72.5\% less GFLOPs. Code is available at https://github.com/dongbo811/AFFormer.},
  archive   = {C_AAAI},
  author    = {Bo Dong and Pichao Wang and Fan Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25126},
  pages     = {516-524},
  title     = {Head-free lightweight semantic segmentation with linear transformer},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Defending backdoor attacks on vision transformer via patch
processing. <em>AAAI</em>, 506–515. (<a
href="https://doi.org/10.1609/aaai.v37i1.25125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Vision Transformers (ViTs) have a radically different architecture with significantly less inductive bias than Convolutional Neural Networks. Along with the improvement in performance, security and robustness of ViTs are also of great importance to study. In contrast to many recent works that exploit the robustness of ViTs against adversarial examples, this paper investigates a representative causative attack, i.e., backdoor. We first examine the vulnerability of ViTs against various backdoor attacks and find that ViTs are also quite vulnerable to existing attacks. However, we observe that the clean-data accuracy and backdoor attack success rate of ViTs respond distinctively to patch transformations before the positional encoding. Then, based on this finding, we propose an effective method for ViTs to defend both patch-based and blending-based trigger backdoor attacks via patch processing. The performances are evaluated on several benchmark datasets, including CIFAR10, GTSRB, and TinyImageNet, which show the proposedds defense is very successful in mitigating backdoor attacks for ViTs. To the best of our knowledge, this paper presents the first defensive strategy that utilizes a unique characteristic of ViTs against backdoor attacks.},
  archive   = {C_AAAI},
  author    = {Khoa D. Doan and Yingjie Lao and Peng Yang and Ping Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25125},
  pages     = {506-515},
  title     = {Defending backdoor attacks on vision transformer via patch processing},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving crowded object detection via copy-paste.
<em>AAAI</em>, 497–505. (<a
href="https://doi.org/10.1609/aaai.v37i1.25124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Crowdedness caused by overlapping among similar objects is a ubiquitous challenge in the field of 2D visual object detection. In this paper, we first underline two main effects of the crowdedness issue: 1) IoU-confidence correlation disturbances (ICD) and 2) confused de-duplication (CDD). Then we explore a pathway of cracking these nuts from the perspective of data augmentation. Primarily, a particular copy- paste scheme is proposed towards making crowded scenes. Based on this operation, we first design a &quot;consensus learning&quot; method to further resist the ICD problem and then find out the pasting process naturally reveals a pseudo &quot;depth&quot; of object in the scene, which can be potentially used for alleviating CDD dilemma. Both methods are derived from magical using of the copy-pasting without extra cost for hand-labeling. Experiments show that our approach can easily improve the state-of-the-art detector in typical crowded detection task by more than 2\% without any bells and whistles. Moreover, this work can outperform existing data augmentation strategies in crowded scenario.},
  archive   = {C_AAAI},
  author    = {Jiangfan Deng and Dewen Fan and Xiaosong Qiu and Feng Zhou},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25124},
  pages     = {497-505},
  title     = {Improving crowded object detection via copy-paste},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-resolution monocular depth map fusion by
self-supervised gradient-based composition. <em>AAAI</em>, 488–496. (<a
href="https://doi.org/10.1609/aaai.v37i1.25123">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Monocular depth estimation is a challenging problem on which deep neural networks have demonstrated great potential. However, depth maps predicted by existing deep models usually lack fine-grained details due to convolution operations and down-samplings in networks. We find that increasing input resolution is helpful to preserve more local details while the estimation at low resolution is more accurate globally. Therefore, we propose a novel depth map fusion module to combine the advantages of estimations with multi-resolution inputs. Instead of merging the low- and high-resolution estimations equally, we adopt the core idea of Poisson fusion, trying to implant the gradient domain of high-resolution depth into the low-resolution depth. While classic Poisson fusion requires a fusion mask as supervision, we propose a self-supervised framework based on guided image filtering. We demonstrate that this gradient-based composition performs much better at noisy immunity, compared with the state-of-the-art depth map fusion method. Our lightweight depth fusion is one-shot and runs in real-time, making it 80X faster than a state-of-the-art depth fusion method. Quantitative evaluations demonstrate that the proposed method can be integrated into many fully convolutional monocular depth estimation backbones with a significant performance boost, leading to state-of-the-art results of detail enhancement on depth maps. Codes are released at https://github.com/yuinsky/gradient-based-depth-map-fusion.},
  archive   = {C_AAAI},
  author    = {Yaqiao Dai and Renjiao Yi and Chenyang Zhu and Hongjun He and Kai Xu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25123},
  pages     = {488-496},
  title     = {Multi-resolution monocular depth map fusion by self-supervised gradient-based composition},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Dual-domain attention for image deblurring. <em>AAAI</em>,
479–487. (<a href="https://doi.org/10.1609/aaai.v37i1.25122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As a long-standing and challenging task, image deblurring aims to reconstruct the latent sharp image from its degraded counterpart. In this study, to bridge the gaps between degraded/sharp image pairs in the spatial and frequency domains simultaneously, we develop the dual-domain attention mechanism for image deblurring. Self-attention is widely used in vision tasks, however, due to the quadratic complexity, it is not applicable to image deblurring with high-resolution images. To alleviate this issue, we propose a novel spatial attention module by implementing self-attention in the style of dynamic group convolution for integrating information from the local region, enhancing the representation learning capability and reducing computational burden. Regarding frequency domain learning, many frequency-based deblurring approaches either treat the spectrum as a whole or decompose frequency components in a complicated manner. In this work, we devise a frequency attention module to compactly decouple the spectrum into distinct frequency parts and accentuate the informative part with extremely lightweight learnable parameters. Finally, we incorporate attention modules into a U-shaped network. Extensive comparisons with prior arts on the common benchmarks show that our model, named Dual-domain Attention Network (DDANet), obtains comparable results with a significantly improved inference speed.},
  archive   = {C_AAAI},
  author    = {Yuning Cui and Yi Tao and Wenqi Ren and Alois Knoll},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25122},
  pages     = {479-487},
  title     = {Dual-domain attention for image deblurring},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). OctFormer: Efficient octree-based transformer for point
cloud compression with local enhancement. <em>AAAI</em>, 470–478. (<a
href="https://doi.org/10.1609/aaai.v37i1.25121">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Point cloud compression with a higher compression ratio and tiny loss is essential for efficient data transportation. However, previous methods that depend on 3D convolution or frequent multi-head self-attention operations bring huge computations. To address this problem, we propose an octree-based Transformer compression method called OctFormer, which does not rely on the occupancy information of sibling nodes. Our method uses non-overlapped context windows to construct octree node sequences and share the result of a multi-head self-attention operation among a sequence of nodes. Besides, we introduce a locally-enhance module for exploiting the sibling features and a positional encoding generator for enhancing the translation invariance of the octree node sequence. Compared to the previous state-of-the-art works, our method obtains up to 17\% Bpp savings compared to the voxel-context-based baseline and saves an overall 99\% coding time compared to the attention-based baseline.},
  archive   = {C_AAAI},
  author    = {Mingyue Cui and Junhua Long and Mingjian Feng and Boyang Li and Huang Kai},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25121},
  pages     = {470-478},
  title     = {OctFormer: Efficient octree-based transformer for point cloud compression with local enhancement},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Weakly supervised 3D multi-person pose estimation for
large-scale scenes based on monocular camera and single LiDAR.
<em>AAAI</em>, 461–469. (<a
href="https://doi.org/10.1609/aaai.v37i1.25120">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Depth estimation is usually ill-posed and ambiguous for monocular camera-based 3D multi-person pose estimation. Since LiDAR can capture accurate depth information in long-range scenes, it can benefit both the global localization of individuals and the 3D pose estimation by providing rich geometry features. Motivated by this, we propose a monocular camera and single LiDAR-based method for 3D multi-person pose estimation in large-scale scenes, which is easy to deploy and insensitive to light. Specifically, we design an effective fusion strategy to take advantage of multi-modal input data, including images and point cloud, and make full use of temporal information to guide the network to learn natural and coherent human motions. Without relying on any 3D pose annotations, our method exploits the inherent geometry constraints of point cloud for self-supervision and utilizes 2D keypoints on images for weak supervision. Extensive experiments on public datasets and our newly collected dataset demonstrate the superiority and generalization capability of our proposed method. Project homepage is at \url{https://github.com/4DVLab/FusionPose.git}.},
  archive   = {C_AAAI},
  author    = {Peishan Cong and Yiteng Xu and Yiming Ren and Juze Zhang and Lan Xu and Jingya Wang and Jingyi Yu and Yuexin Ma},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25120},
  pages     = {461-469},
  title     = {Weakly supervised 3D multi-person pose estimation for large-scale scenes based on monocular camera and single LiDAR},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Adversarial alignment for source free object detection.
<em>AAAI</em>, 452–460. (<a
href="https://doi.org/10.1609/aaai.v37i1.25119">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Source-free object detection (SFOD) aims to transfer a detector pre-trained on a label-rich source domain to an unlabeled target domain without seeing source data. While most existing SFOD methods generate pseudo labels via a source-pretrained model to guide training, these pseudo labels usually contain high noises due to heavy domain discrepancy. In order to obtain better pseudo supervisions, we divide the target domain into source-similar and source-dissimilar parts and align them in the feature space by adversarial learning.Specifically, we design a detection variance-based criterion to divide the target domain. This criterion is motivated by a finding that larger detection variances denote higher recall and larger similarity to the source domain. Then we incorporate an adversarial module into a mean teacher framework to drive the feature spaces of these two subsets indistinguishable. Extensive experiments on multiple cross-domain object detection datasets demonstrate that our proposed method consistently outperforms the compared SFOD methods. Our implementation is available at https://github.com/ChuQiaosong.},
  archive   = {C_AAAI},
  author    = {Qiaosong Chu and Shuyan Li and Guangyi Chen and Kai Li and Xiu Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25119},
  pages     = {452-460},
  title     = {Adversarial alignment for source free object detection},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Neural architecture search for wide spectrum adversarial
robustness. <em>AAAI</em>, 442–451. (<a
href="https://doi.org/10.1609/aaai.v37i1.25118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {One major limitation of CNNs is that they are vulnerable to adversarial attacks. Currently, adversarial robustness in neural networks is commonly optimized with respect to a small pre-selected adversarial noise strength, causing them to have potentially limited performance when under attack by larger adversarial noises in real-world scenarios. In this research, we aim to find Neural Architectures that have improved robustness on a wide range of adversarial noise strengths through Neural Architecture Search. In detail, we propose a lightweight Adversarial Noise Estimator to reduce the high cost of generating adversarial noise with respect to different strengths. Besides, we construct an Efficient Wide Spectrum Searcher to reduce the cost of adjusting network architecture with the large adversarial validation set during the search. With the two components proposed, the number of adversarial noise strengths searched can be increased significantly while having a limited increase in search time. Extensive experiments on benchmark datasets such as CIFAR and ImageNet demonstrate that with a significantly richer search signal in robustness, our method can find architectures with improved overall robustness while having a limited impact on natural accuracy and around 40\% reduction in search time compared with the naive approach of searching. Codes available at: https://github.com/zhicheng2T0/Wsr-NAS.git},
  archive   = {C_AAAI},
  author    = {Zhi Cheng and Yanxi Li and Minjing Dong and Xiu Su and Shan You and Chang Xu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25118},
  pages     = {442-451},
  title     = {Neural architecture search for wide spectrum adversarial robustness},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). User-controllable arbitrary style transfer via entropy
regularization. <em>AAAI</em>, 433–441. (<a
href="https://doi.org/10.1609/aaai.v37i1.25117">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Ensuring the overall end-user experience is a challenging task in arbitrary style transfer (AST) due to the subjective nature of style transfer quality. A good practice is to provide users many instead of one AST result. However, existing approaches require to run multiple AST models or inference a diversified AST (DAST) solution multiple times, and thus they are either slow in speed or limited in diversity. In this paper, we propose a novel solution ensuring both efficiency and diversity for generating multiple user-controllable AST results by systematically modulating AST behavior at run-time. We begin with reformulating three prominent AST methods into a unified assign-and-mix problem and discover that the entropies of their assignment matrices exhibit a large variance. We then solve the unified problem in an optimal transport framework using the Sinkhorn-Knopp algorithm with a user input ε to control the said entropy and thus modulate stylization. Empirical results demonstrate the superiority of the proposed solution, with speed and stylization quality comparable to or better than existing AST and significantly more diverse than previous DAST works. Code is available at https://github.com/cplusx/eps-Assign-and-Mix.},
  archive   = {C_AAAI},
  author    = {Jiaxin Cheng and Yue Wu and Ayush Jaiswal and Xu Zhang and Pradeep Natarajan and Prem Natarajan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25117},
  pages     = {433-441},
  title     = {User-controllable arbitrary style transfer via entropy regularization},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cross-modality person re-identification with memory-based
contrastive embedding. <em>AAAI</em>, 425–432. (<a
href="https://doi.org/10.1609/aaai.v37i1.25116">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Visible-infrared person re-identification (VI-ReID) aims to retrieve the person images of the same identity from the RGB to infrared image space, which is very important for real-world surveillance system. In practice, VI-ReID is more challenging due to the heterogeneous modality discrepancy, which further aggravates the challenges of traditional single-modality person ReID problem, i.e., inter-class confusion and intra-class variations. In this paper, we propose an aggregated memory-based cross-modality deep metric learning framework, which benefits from the increasing number of learned modality-aware and modality-agnostic centroid proxies for cluster contrast and mutual information learning. Furthermore, to suppress the modality discrepancy, the proposed cross-modality alignment objective simultaneously utilizes both historical and up-to-date learned cluster proxies for enhanced cross-modality association. Such training mechanism helps to obtain hard positive references through increased diversity of learned cluster proxies, and finally achieves stronger ``pulling close&#39;&#39; effect between cross-modality image features. Extensive experiment results demonstrate the effectiveness of the proposed method, surpassing state-of-the-art works significantly by a large margin on the commonly used VI-ReID datasets.},
  archive   = {C_AAAI},
  author    = {De Cheng and Xiaolong Wang and Nannan Wang and Zhen Wang and Xiaoyu Wang and Xinbo Gao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25116},
  pages     = {425-432},
  title     = {Cross-modality person re-identification with memory-based contrastive embedding},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023e). Imperceptible adversarial attack via invertible neural
networks. <em>AAAI</em>, 414–424. (<a
href="https://doi.org/10.1609/aaai.v37i1.25115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Adding perturbations via utilizing auxiliary gradient information or discarding existing details of the benign images are two common approaches for generating adversarial examples. Though visual imperceptibility is the desired property of adversarial examples, conventional adversarial attacks still generate traceable adversarial perturbations. In this paper, we introduce a novel Adversarial Attack via Invertible Neural Networks (AdvINN) method to produce robust and imperceptible adversarial examples. Specifically, AdvINN fully takes advantage of the information preservation property of Invertible Neural Networks and thereby generates adversarial examples by simultaneously adding class-specific semantic information of the target class and dropping discriminant information of the original class. Extensive experiments on CIFAR-10, CIFAR-100, and ImageNet-1K demonstrate that the proposed AdvINN method can produce less imperceptible adversarial images than the state-of-the-art methods and AdvINN yields more robust adversarial examples with high confidence compared to other adversarial attacks. Code is available at https://github.com/jjhuangcs/AdvINN.},
  archive   = {C_AAAI},
  author    = {Zihan Chen and Ziyue Wang and Jun-Jie Huang and Wentao Zhao and Xiao Liu and Dejian Guan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25115},
  pages     = {414-424},
  title     = {Imperceptible adversarial attack via invertible neural networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). DUET: Cross-modal semantic grounding for contrastive
zero-shot learning. <em>AAAI</em>, 405–413. (<a
href="https://doi.org/10.1609/aaai.v37i1.25114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Zero-shot learning (ZSL) aims to predict unseen classes whose samples have never appeared during training. One of the most effective and widely used semantic information for zero-shot image classification are attributes which are annotations for class-level visual characteristics. However, the current methods often fail to discriminate those subtle visual distinctions between images due to not only the shortage of fine-grained annotations, but also the attribute imbalance and co-occurrence. In this paper, we present a transformer-based end-to-end ZSL method named DUET, which integrates latent semantic knowledge from the pre-trained language models (PLMs) via a self-supervised multi-modal learning paradigm. Specifically, we (1) developed a cross-modal semantic grounding network to investigate the model&#39;s capability of disentangling semantic attributes from the images; (2) applied an attribute-level contrastive learning strategy to further enhance the model&#39;s discrimination on fine-grained visual characteristics against the attribute co-occurrence and imbalance; (3) proposed a multi-task learning policy for considering multi-model objectives. We find that our DUET can achieve state-of-the-art performance on three standard ZSL benchmarks and a knowledge graph equipped ZSL benchmark. Its components are effective and its predictions are interpretable.},
  archive   = {C_AAAI},
  author    = {Zhuo Chen and Yufeng Huang and Jiaoyan Chen and Yuxia Geng and Wen Zhang and Yin Fang and Jeff Z. Pan and Huajun Chen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25114},
  pages     = {405-413},
  title     = {DUET: Cross-modal semantic grounding for contrastive zero-shot learning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023d). Tagging before alignment: Integrating multi-modal tags for
video-text retrieval. <em>AAAI</em>, 396–404. (<a
href="https://doi.org/10.1609/aaai.v37i1.25113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Vision-language alignment learning for video-text retrieval arouses a lot of attention in recent years. Most of the existing methods either transfer the knowledge of image-text pretraining model to video-text retrieval task without fully exploring the multi-modal information of videos, or simply fuse multi-modal features in a brute force manner without explicit guidance. In this paper, we integrate multi-modal information in an explicit manner by tagging, and use the tags as the anchors for better video-text alignment. Various pretrained experts are utilized for extracting the information of multiple modalities, including object, person, motion, audio, etc. To take full advantage of these information, we propose the TABLE (TAgging Before aLignmEnt) network, which consists of a visual encoder, a tag encoder, a text encoder, and a tag-guiding cross-modal encoder for jointly encoding multi-frame visual features and multi-modal tags information. Furthermore, to strengthen the interaction between video and text, we build a joint cross-modal encoder with the triplet input of [vision, tag, text] and perform two additional supervised tasks, Video Text Matching (VTM) and Masked Language Modeling (MLM). Extensive experimental results demonstrate that the TABLE model is capable of achieving State-Of-The-Art (SOTA) performance on various video-text retrieval benchmarks, including MSR-VTT, MSVD, LSMDC and DiDeMo.},
  archive   = {C_AAAI},
  author    = {Yizhen Chen and Jie Wang and Lijian Lin and Zhongang Qi and Jin Ma and Ying Shan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25113},
  pages     = {396-404},
  title     = {Tagging before alignment: Integrating multi-modal tags for video-text retrieval},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023c). MGFN: Magnitude-contrastive glance-and-focus network for
weakly-supervised video anomaly detection. <em>AAAI</em>, 387–395. (<a
href="https://doi.org/10.1609/aaai.v37i1.25112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Weakly supervised detection of anomalies in surveillance videos is a challenging task. Going beyond existing works that have deficient capabilities to localize anomalies in long videos, we propose a novel glance and focus network to effectively integrate spatial-temporal information for accurate anomaly detection. In addition, we empirically found that existing approaches that use feature magnitudes to represent the degree of anomalies typically ignore the effects of scene variations, and hence result in sub-optimal performance due to the inconsistency of feature magnitudes across scenes. To address this issue, we propose the Feature Amplification Mechanism and a Magnitude Contrastive Loss to enhance the discriminativeness of feature magnitudes for detecting anomalies. Experimental results on two large-scale benchmarks UCF-Crime and XD-Violence manifest that our method outperforms state-of-the-art approaches.},
  archive   = {C_AAAI},
  author    = {Yingxian Chen and Zhengzhe Liu and Baoheng Zhang and Wilton Fok and Xiaojuan Qi and Yik-Chung Wu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25112},
  pages     = {387-395},
  title     = {MGFN: Magnitude-contrastive glance-and-focus network for weakly-supervised video anomaly detection},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hybrid CNN-transformer feature fusion for single image
deraining. <em>AAAI</em>, 378–386. (<a
href="https://doi.org/10.1609/aaai.v37i1.25111">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Since rain streaks exhibit diverse geometric appearances and irregular overlapped phenomena, these complex characteristics challenge the design of an effective single image deraining model. To this end, rich local-global information representations are increasingly indispensable for better satisfying rain removal. In this paper, we propose a lightweight Hybrid CNN-Transformer Feature Fusion Network (dubbed as HCT-FFN) in a stage-by-stage progressive manner, which can harmonize these two architectures to help image restoration by leveraging their individual learning strengths. Specifically, we stack a sequence of the degradation-aware mixture of experts (DaMoE) modules in the CNN-based stage, where appropriate local experts adaptively enable the model to emphasize spatially-varying rain distribution features. As for the Transformer-based stage, a background-aware vision Transformer (BaViT) module is employed to complement spatially-long feature dependencies of images, so as to achieve global texture recovery while preserving the required structure. Considering the indeterminate knowledge discrepancy among CNN features and Transformer features, we introduce an interactive fusion branch at adjacent stages to further facilitate the reconstruction of high-quality deraining results. Extensive evaluations show the effectiveness and extensibility of our developed HCT-FFN. The source code is available at https://github.com/cschenxiang/HCT-FFN.},
  archive   = {C_AAAI},
  author    = {Xiang Chen and Jinshan Pan and Jiyang Lu and Zhentao Fan and Hao Li},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25111},
  pages     = {378-386},
  title     = {Hybrid CNN-transformer feature fusion for single image deraining},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Scalable spatial memory for scene rendering and navigation.
<em>AAAI</em>, 369–377. (<a
href="https://doi.org/10.1609/aaai.v37i1.25110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Neural scene representation and rendering methods have shown promise in learning the implicit form of scene structure without supervision. However, the implicit representation learned in most existing methods is non-expandable and cannot be inferred online for novel scenes, which makes the learned representation difficult to be applied across different reinforcement learning (RL) tasks. In this work, we introduce Scene Memory Network (SMN) to achieve online spatial memory construction and expansion for view rendering in novel scenes. SMN models the camera projection and back-projection as spatially aware memory control processes, where the memory values store the information of the partial 3D area, and the memory keys indicate the position of that area. The memory controller can learn the geometry property from observations without the camera&#39;s intrinsic parameters and depth supervision. We further apply the memory constructed by SMN to exploration and navigation tasks. The experimental results reveal the generalization ability of our proposed SMN in large-scale scene synthesis and its potential to improve the performance of spatial RL tasks.},
  archive   = {C_AAAI},
  author    = {Wen-Cheng Chen and Chu-Song Chen and Wei-Chen Chiu and Min-Chun Hu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25110},
  pages     = {369-377},
  title     = {Scalable spatial memory for scene rendering and navigation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023b). Bidirectional optical flow NeRF: High accuracy and high
quality under fewer views. <em>AAAI</em>, 359–368. (<a
href="https://doi.org/10.1609/aaai.v37i1.25109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Neural Radiance Fields (NeRF) can implicitly represent 3D-consistent RGB images and geometric by optimizing an underlying continuous volumetric scene function using a sparse set of input views, which has greatly benefited view synthesis tasks. However, NeRF fails to estimate correct geometry when given fewer views, resulting in failure to synthesize novel views. Existing works rely on introducing depth images or adding depth estimation networks to resolve the problem of poor synthetic view in NeRF with fewer views. However, due to the lack of spatial consistency of the single-depth image and the poor performance of depth estimation with fewer views, the existing methods still have challenges in addressing this problem. So this paper proposes Bidirectional Optical Flow NeRF(BOF-NeRF), which addresses this problem by mining optical flow information between 2D images. Our key insight is that utilizing 2D optical flow images to design a loss can effectively guide NeRF to learn the correct geometry and synthesize the right novel view. We also propose a view-enhanced fusion method based on geometry and color consistency to solve the problem of novel view details loss in NeRF. We conduct extensive experiments on the NeRF-LLFF and DTU MVS benchmarks for novel view synthesis tasks with fewer images in different complex real scenes. We further demonstrate the robustness of BOF-NeRF under different baseline distances on the Middlebury dataset. In all cases, BOF-NeRF outperforms current state-of-the-art baselines for novel view synthesis and scene geometry estimation.},
  archive   = {C_AAAI},
  author    = {Shuo Chen and Binbin Yan and Xinzhu Sang and Duo Chen and Peng Wang and Xiao Guo and Chongli Zhong and Huaming Wan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25109},
  pages     = {359-368},
  title     = {Bidirectional optical flow NeRF: High accuracy and high quality under fewer views},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-supervised joint dynamic scene reconstruction and
optical flow estimation for spiking camera. <em>AAAI</em>, 350–358. (<a
href="https://doi.org/10.1609/aaai.v37i1.25108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Spiking camera, a novel retina-inspired vision sensor, has shown its great potential for capturing high-speed dynamic scenes with a sampling rate of 40,000 Hz. The spiking camera abandons the concept of exposure window, with each of its photosensitive units continuously capturing photons and firing spikes asynchronously. However, the special sampling mechanism prevents the frame-based algorithm from being used to spiking camera. It remains to be a challenge to reconstruct dynamic scenes and perform common computer vision tasks for spiking camera. In this paper, we propose a self-supervised joint learning framework for optical flow estimation and reconstruction of spiking camera. The framework reconstructs clean frame-based spiking representations in a self-supervised manner, and then uses them to train the optical flow networks. We also propose an optical flow based inverse rendering process to achieve self-supervision by minimizing the difference with respect to the original spiking temporal aggregation image. The experimental results demonstrate that our method bridges the gap between synthetic and real-world scenes and achieves desired results in real-world scenarios. To the best of our knowledge, this is the first attempt to jointly reconstruct dynamic scenes and estimate optical flow for spiking camera from a self-supervised learning perspective.},
  archive   = {C_AAAI},
  author    = {Shiyan Chen and Zhaofei Yu and Tiejun Huang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25108},
  pages     = {350-358},
  title     = {Self-supervised joint dynamic scene reconstruction and optical flow estimation for spiking camera},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Improving dynamic HDR imaging with fusion transformer.
<em>AAAI</em>, 340–349. (<a
href="https://doi.org/10.1609/aaai.v37i1.25107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets.},
  archive   = {C_AAAI},
  author    = {Rufeng Chen and Bolun Zheng and Hua Zhang and Quan Chen and Chenggang Yan and Gregory Slabaugh and Shanxin Yuan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25107},
  pages     = {340-349},
  title     = {Improving dynamic HDR imaging with fusion transformer},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Take your model further: A general post-refinement network
for light field disparity estimation via BadPix correction.
<em>AAAI</em>, 331–339. (<a
href="https://doi.org/10.1609/aaai.v37i1.25106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Most existing light field (LF) disparity estimation algorithms focus on handling occlusion, texture-less or other areas that harm LF structure to improve accuracy, while ignoring other potential modeling ideas. In this paper, we propose a novel idea called Bad Pixel (BadPix) correction for method modeling, then implement a general post-refinement network for LF disparity estimation: Bad-pixel Correction Network (BpCNet). Given an initial disparity map generated by a specific algorithm, we assume that all BadPixs on it are in a small range. Then BpCNet is modeled as a fine-grained search strategy, and a more accurate result can be obtained by evaluating the consistency of LF images in this limited range. Due to the assumption and the consistency between input and output, BpCNet can perform as a general post-refinement network, and can work on almost all existing algorithms iteratively. We demonstrate the feasibility of our theory through extensive experiments, and achieve remarkable performance on the HCI 4D Light Field Benchmark.},
  archive   = {C_AAAI},
  author    = {Rongshan Chen and Hao Sheng and Da Yang and Sizhe Wang and Zhenglong Cui and Ruixuan Cong},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25106},
  pages     = {331-339},
  title     = {Take your model further: A general post-refinement network for light field disparity estimation via BadPix correction},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). SwinRDM: Integrate SwinRNN with diffusion model towards
high-resolution and high-quality weather forecasting. <em>AAAI</em>,
322–330. (<a href="https://doi.org/10.1609/aaai.v37i1.25105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Data-driven medium-range weather forecasting has attracted much attention in recent years. However, the forecasting accuracy at high resolution is unsatisfactory currently. Pursuing high-resolution and high-quality weather forecasting, we develop a data-driven model SwinRDM which integrates an improved version of SwinRNN with a diffusion model. SwinRDM performs predictions at 0.25-degree resolution and achieves superior forecasting accuracy to IFS (Integrated Forecast System), the state-of-the-art operational NWP model, on representative atmospheric variables including 500 hPa geopotential (Z500), 850 hPa temperature (T850), 2-m temperature (T2M), and total precipitation (TP), at lead times of up to 5 days. We propose to leverage a two-step strategy to achieve high-resolution predictions at 0.25-degree considering the trade-off between computation memory and forecasting accuracy. Recurrent predictions for future atmospheric fields are firstly performed at 1.40625-degree resolution, and then a diffusion-based super-resolution model is leveraged to recover the high spatial resolution and finer-scale atmospheric details. SwinRDM pushes forward the performance and potential of data-driven models for a large margin towards operational applications.},
  archive   = {C_AAAI},
  author    = {Lei Chen and Fei Du and Yuan Hu and Zhibin Wang and Fan Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25105},
  pages     = {322-330},
  title     = {SwinRDM: Integrate SwinRNN with diffusion model towards high-resolution and high-quality weather forecasting},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Amodal instance segmentation via prior-guided expansion.
<em>AAAI</em>, 313–321. (<a
href="https://doi.org/10.1609/aaai.v37i1.25104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Amodal instance segmentation aims to infer the amodal mask, including both the visible part and occluded part of each object instance. Predicting the occluded parts is challenging. Existing methods often produce incomplete amodal boxes and amodal masks, probably due to lacking visual evidences to expand the boxes and masks. To this end, we propose a prior-guided expansion framework, which builds on a two-stage segmentation model (i.e., Mask R-CNN) and performs box-level (resp., pixel-level) expansion for amodal box (resp., mask) prediction, by retrieving regression (resp., flow) transformations from a memory bank of expansion prior. We conduct extensive experiments on KINS, D2SA, and COCOA cls datasets, which show the effectiveness of our method.},
  archive   = {C_AAAI},
  author    = {Junjie Chen and Li Niu and Jianfu Zhang and Jianlou Si and Chen Qian and Liqing Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25104},
  pages     = {313-321},
  title     = {Amodal instance segmentation via prior-guided expansion},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Tracking and reconstructing hand object interactions from
point cloud sequences in the wild. <em>AAAI</em>, 304–312. (<a
href="https://doi.org/10.1609/aaai.v37i1.25103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this work, we tackle the challenging task of jointly tracking hand object poses and reconstructing their shapes from depth point cloud sequences in the wild, given the initial poses at frame 0. We for the first time propose a point cloud-based hand joint tracking network, HandTrackNet, to estimate the inter-frame hand joint motion. Our HandTrackNet proposes a novel hand pose canonicalization module to ease the tracking task, yielding accurate and robust hand joint tracking. Our pipeline then reconstructs the full hand via converting the predicted hand joints into a MANO hand. For object tracking, we devise a simple yet effective module that estimates the object SDF from the first frame and performs optimization-based tracking. Finally, a joint optimization step is adopted to perform joint hand and object reasoning, which alleviates the occlusion-induced ambiguity and further refines the hand pose. During training, the whole pipeline only sees purely synthetic data, which are synthesized with sufficient variations and by depth simulation for the ease of generalization. The whole pipeline is pertinent to the generalization gaps and thus directly transferable to real in-the-wild data. We evaluate our method on two real hand object interaction datasets, e.g. HO3D and DexYCB, without any fine-tuning. Our experiments demonstrate that the proposed method significantly outperforms the previous state-of-the-art depth-based hand and object pose estimation and tracking methods, running at a frame rate of 9 FPS. We have released our code on https://github.com/PKU-EPIC/HOTrack.},
  archive   = {C_AAAI},
  author    = {Jiayi Chen and Mi Yan and Jiazhao Zhang and Yinzhen Xu and Xiaolong Li and Yijia Weng and Li Yi and Shuran Song and He Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25103},
  pages     = {304-312},
  title     = {Tracking and reconstructing hand object interactions from point cloud sequences in the wild},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deconstructed generation-based zero-shot model.
<em>AAAI</em>, 295–303. (<a
href="https://doi.org/10.1609/aaai.v37i1.25102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent research on Generalized Zero-Shot Learning (GZSL) has focused primarily on generation-based methods. However, current literature has overlooked the fundamental principles of these methods and has made limited progress in a complex manner. In this paper, we aim to deconstruct the generator-classifier framework and provide guidance for its improvement and extension. We begin by breaking down the generator-learned unseen class distribution into class-level and instance-level distributions. Through our analysis of the role of these two types of distributions in solving the GZSL problem, we generalize the focus of the generation-based approach, emphasizing the importance of (i) attribute generalization in generator learning and (ii) independent classifier learning with partially biased data. We present a simple method based on this analysis that outperforms SotAs on four public GZSL datasets, demonstrating the validity of our deconstruction. Furthermore, our proposed method remains effective even without a generative model, representing a step towards simplifying the generator-classifier structure. Our code is available at https://github.com/cdb342/DGZ.},
  archive   = {C_AAAI},
  author    = {Dubing Chen and Yuming Shen and Haofeng Zhang and Philip H.S. Torr},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25102},
  pages     = {295-303},
  title     = {Deconstructed generation-based zero-shot model},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). KT-net: Knowledge transfer for unpaired 3D shape completion.
<em>AAAI</em>, 286–294. (<a
href="https://doi.org/10.1609/aaai.v37i1.25101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Unpaired 3D object completion aims to predict a complete 3D shape from an incomplete input without knowing the correspondence between the complete and incomplete shapes. In this paper, we propose the novel KTNet to solve this task from the new perspective of knowledge transfer. KTNet elaborates a teacher-assistant-student network to establish multiple knowledge transfer processes. Specifically, the teacher network takes complete shape as input and learns the knowledge of complete shape. The student network takes the incomplete one as input and restores the corresponding complete shape. And the assistant modules not only help to transfer the knowledge of complete shape from the teacher to the student, but also judge the learning effect of the student network. As a result, KTNet makes use of a more comprehensive understanding to establish the geometric correspondence between complete and incomplete shapes in a perspective of knowledge transfer, which enables more detailed geometric inference for generating high-quality complete shapes. We conduct comprehensive experiments on several datasets, and the results show that our method outperforms previous methods of unpaired point cloud completion by a large margin. Code is available at https://github.com/a4152684/KT-Net.},
  archive   = {C_AAAI},
  author    = {Zhen Cao and Wenxiao Zhang and Xin Wen and Zhen Dong and Yu-Shen Liu and Xiongwu Xiao and Bisheng Yang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25101},
  pages     = {286-294},
  title     = {KT-net: Knowledge transfer for unpaired 3D shape completion},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). MMTN: Multi-modal memory transformer network for
image-report consistent medical report generation. <em>AAAI</em>,
277–285. (<a href="https://doi.org/10.1609/aaai.v37i1.25100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Automatic medical report generation is an essential task in applying artificial intelligence to the medical domain, which can lighten the workloads of doctors and promote clinical automation. The state-of-the-art approaches employ Transformer-based encoder-decoder architectures to generate reports for medical images. However, they do not fully explore the relationships between multi-modal medical data, and generate inaccurate and inconsistent reports. To address these issues, this paper proposes a Multi-modal Memory Transformer Network (MMTN) to cope with multi-modal medical data for generating image-report consistent medical reports. On the one hand, MMTN reduces the occurrence of image-report inconsistencies by designing a unique encoder to associate and memorize the relationship between medical images and medical terminologies. On the other hand, MMTN utilizes the cross-modal complementarity of the medical vision and language for the word prediction, which further enhances the accuracy of generating medical reports. Extensive experiments on three real datasets show that MMTN achieves significant effectiveness over state-of-the-art approaches on both automatic metrics and human evaluation.},
  archive   = {C_AAAI},
  author    = {Yiming Cao and Lizhen Cui and Lei Zhang and Fuqiang Yu and Zhen Li and Yonghui Xu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25100},
  pages     = {277-285},
  title     = {MMTN: Multi-modal memory transformer network for image-report consistent medical report generation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Painterly image harmonization in dual domains.
<em>AAAI</em>, 268–276. (<a
href="https://doi.org/10.1609/aaai.v37i1.25099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Image harmonization aims to produce visually harmonious composite images by adjusting the foreground appearance to be compatible with the background. When the composite image has photographic foreground and painterly background, the task is called painterly image harmonization. There are only few works on this task, which are either time-consuming or weak in generating well-harmonized results. In this work, we propose a novel painterly harmonization network consisting of a dual-domain generator and a dual-domain discriminator, which harmonizes the composite image in both spatial domain and frequency domain. The dual-domain generator performs harmonization by using AdaIN modules in the spatial domain and our proposed ResFFT modules in the frequency domain. The dual-domain discriminator attempts to distinguish the inharmonious patches based on the spatial feature and frequency feature of each patch, which can enhance the ability of generator in an adversarial manner. Extensive experiments on the benchmark dataset show the effectiveness of our method. Our code and model are available at https://github.com/bcmi/PHDNet-Painterly-Image-Harmonization.},
  archive   = {C_AAAI},
  author    = {Junyan Cao and Yan Hong and Li Niu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25099},
  pages     = {268-276},
  title     = {Painterly image harmonization in dual domains},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Explicit invariant feature induced cross-domain crowd
counting. <em>AAAI</em>, 259–267. (<a
href="https://doi.org/10.1609/aaai.v37i1.25098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Cross-domain crowd counting has shown progressively improved performance. However, most methods fail to explicitly consider the transferability of different features between source and target domains. In this paper, we propose an innovative explicit Invariant Feature induced Cross-domain Knowledge Transformation framework to address the inconsistent domain-invariant features of different domains. The main idea is to explicitly extract domain-invariant features from both source and target domains, which builds a bridge to transfer more rich knowledge between two domains. The framework consists of three parts, global feature decoupling (GFD), relation exploration and alignment (REA), and graph-guided knowledge enhancement (GKE). In the GFD module, domain-invariant features are efficiently decoupled from domain-specific ones in two domains, which allows the model to distinguish crowds features from backgrounds in the complex scenes. In the REA module both inter-domain relation graph (Inter-RG) and intra-domain relation graph (Intra-RG) are built. Specifically, Inter-RG aggregates multi-scale domain-invariant features between two domains and further aligns local-level invariant features. Intra-RG preserves taskrelated specific information to assist the domain alignment. Furthermore, GKE strategy models the confidence of pseudolabels to further enhance the adaptability of the target domain. Various experiments show our method achieves state-of-theart performance on the standard benchmarks. Code is available at https://github.com/caiyiqing/IF-CKT.},
  archive   = {C_AAAI},
  author    = {Yiqing Cai and Lianggangxu Chen and Haoyue Guan and Shaohui Lin and Changhong Lu and Changbo Wang and Gaoqi He},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25098},
  pages     = {259-267},
  title     = {Explicit invariant feature induced cross-domain crowd counting},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Parametric surface constrained upsampler network for point
cloud. <em>AAAI</em>, 250–258. (<a
href="https://doi.org/10.1609/aaai.v37i1.25097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Designing a point cloud upsampler, which aims to generate a clean and dense point cloud given a sparse point representation, is a fundamental and challenging problem in computer vision. A line of attempts achieves this goal by establishing a point-to-point mapping function via deep neural networks. However, these approaches are prone to produce outlier points due to the lack of explicit surface-level constraints. To solve this problem, we introduce a novel surface regularizer into the upsampler network by forcing the neural network to learn the underlying parametric surface represented by bicubic functions and rotation functions, where the new generated points are then constrained on the underlying surface. These designs are integrated into two different networks for two tasks that take advantages of upsampling layers -- point cloud upsampling and point cloud completion for evaluation. The state-of-the-art experimental results on both tasks demonstrate the effectiveness of the proposed method. The implementation code will be available at https://github.com/corecai163/PSCU.},
  archive   = {C_AAAI},
  author    = {Pingping Cai and Zhenyao Wu and Xinyi Wu and Song Wang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25097},
  pages     = {250-258},
  title     = {Parametric surface constrained upsampler network for point cloud},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). VASR: Visual analogies of situation recognition.
<em>AAAI</em>, 241–249. (<a
href="https://doi.org/10.1609/aaai.v37i1.25096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A core process in human cognition is analogical mapping: the ability to identify a similar relational structure between different situations. We introduce a novel task, Visual Analogies of Situation Recognition, adapting the classical word-analogy task into the visual domain. Given a triplet of images, the task is to select an image candidate B&#39; that completes the analogy (A to A&#39; is like B to what?). Unlike previous work on visual analogy that focused on simple image transformations, we tackle complex analogies requiring understanding of scenes. We leverage situation recognition annotations and the CLIP model to generate a large set of 500k candidate analogies. Crowdsourced annotations for a sample of the data indicate that humans agree with the dataset label ~80\% of the time (chance level 25\%). Furthermore, we use human annotations to create a gold-standard dataset of 3,820 validated analogies. Our experiments demonstrate that state-of-the-art models do well when distractors are chosen randomly (~86\%), but struggle with carefully chosen distractors (~53\%, compared to 90\% human accuracy). We hope our dataset will encourage the development of new analogy-making models. Website: https://vasr-dataset.github.io/},
  archive   = {C_AAAI},
  author    = {Yonatan Bitton and Ron Yosef and Eliyahu Strugo and Dafna Shahaf and Roy Schwartz and Gabriel Stanovsky},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25096},
  pages     = {241-249},
  title     = {VASR: Visual analogies of situation recognition},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-supervised image local forgery detection by JPEG
compression trace. <em>AAAI</em>, 232–240. (<a
href="https://doi.org/10.1609/aaai.v37i1.25095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {For image local forgery detection, the existing methods require a large amount of labeled data for training, and most of them cannot detect multiple types of forgery simultaneously. In this paper, we firstly analyzed the JPEG compression traces which are mainly caused by different JPEG compression chains, and designed a trace extractor to learn such traces. Then, we utilized the trace extractor as the backbone and trained self-supervised to strengthen the discrimination ability of learned traces. With its benefits, regions with different JPEG compression chains can easily be distinguished within a forged image. Furthermore, our method does not rely on a large amount of training data, and even does not require any forged images for training. Experiments show that the proposed method can detect image local forgery on different datasets without re-training, and keep stable performance over various types of image local forgery.},
  archive   = {C_AAAI},
  author    = {Xiuli Bi and Wuqing Yan and Bo Liu and Bin Xiao and Weisheng Li and Xinbo Gao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25095},
  pages     = {232-240},
  title     = {Self-supervised image local forgery detection by JPEG compression trace},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Multi-level compositional reasoning for interactive
instruction following. <em>AAAI</em>, 223–231. (<a
href="https://doi.org/10.1609/aaai.v37i1.25094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Robotic agents performing domestic chores by natural language directives are required to master the complex job of navigating environment and interacting with objects in the environments. The tasks given to the agents are often composite thus are challenging as completing them require to reason about multiple subtasks, e.g., bring a cup of coffee. To address the challenge, we propose to divide and conquer it by breaking the task into multiple subgoals and attend to them individually for better navigation and interaction. We call it Multi-level Compositional Reasoning Agent (MCR-Agent). Specifically, we learn a three-level action policy. At the highest level, we infer a sequence of human-interpretable subgoals to be executed based on language instructions by a high-level policy composition controller. At the middle level, we discriminatively control the agent’s navigation by a master policy by alternating between a navigation policy and various independent interaction policies. Finally, at the lowest level, we infer manipulation actions with the corresponding object masks using the appropriate interaction policy. Our approach not only generates human interpretable subgoals but also achieves 2.03\% absolute gain to comparable state of the arts in the efficiency metric (PLWSR in unseen set) without using rule-based planning or a semantic spatial memory. The code is available at https://github.com/yonseivnl/mcr-agent.},
  archive   = {C_AAAI},
  author    = {Suvaansh Bhambri and Byeonghwi Kim and Jonghyun Choi},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25094},
  pages     = {223-231},
  title     = {Multi-level compositional reasoning for interactive instruction following},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Cross-modal label contrastive learning for unsupervised
audio-visual event localization. <em>AAAI</em>, 215–222. (<a
href="https://doi.org/10.1609/aaai.v37i1.25093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper for the first time explores audio-visual event localization in an unsupervised manner. Previous methods tackle this problem in a supervised setting and require segment-level or video-level event category ground-truth to train the model. However, building large-scale multi-modality datasets with category annotations is human-intensive and thus not scalable to real-world applications. To this end, we propose cross-modal label contrastive learning to exploit multi-modal information among unlabeled audio and visual streams as self-supervision signals. At the feature representation level, multi-modal representations are collaboratively learned from audio and visual components by using self-supervised representation learning. At the label level, we propose a novel self-supervised pretext task i.e. label contrasting to self-annotate videos with pseudo-labels for localization model training. Note that irrelevant background would hinder the acquisition of high-quality pseudo-labels and thus lead to an inferior localization model. To address this issue, we then propose an expectation-maximization algorithm that optimizes the pseudo-label acquisition and localization model in a coarse-to-fine manner. Extensive experiments demonstrate that our unsupervised approach performs reasonably well compared to the state-of-the-art supervised methods.},
  archive   = {C_AAAI},
  author    = {Peijun Bao and Wenhan Yang and Boon Poh Ng and Meng Hwa Er and Alex C. Kot},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25093},
  pages     = {215-222},
  title     = {Cross-modal label contrastive learning for unsupervised audio-visual event localization},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Layout representation learning with spatial and structural
hierarchies. <em>AAAI</em>, 206–214. (<a
href="https://doi.org/10.1609/aaai.v37i1.25092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present a novel hierarchical modeling method for layout representation learning, the core of design documents (e.g., user interface, poster, template). Existing works on layout representation often ignore element hierarchies, which is an important facet of layouts, and mainly rely on the spatial bounding boxes for feature extraction. This paper proposes a Spatial-Structural Hierarchical Auto-Encoder (SSH-AE) that learns hierarchical representation by treating a hierarchically annotated layout as a tree format. On the one side, we model SSH-AE from both spatial (semantic views) and structural (organization and relationships) perspectives, which are two complementary aspects to represent a layout. On the other side, the semantic/geometric properties are associated at multiple resolutions/granularities, naturally handling complex layouts. Our learned representations are used for effective layout search from both spatial and structural similarity perspectives. We also newly involve the tree-edit distance (TED) as an evaluation metric to construct a comprehensive evaluation protocol for layout similarity assessment, which benefits a systematic and customized layout search. We further present a new dataset of POSTER layouts which we believe will be useful for future layout research. We show that our proposed SSH-AE outperforms the existing methods achieving state-of-the-art performance on two benchmark datasets. Code is available at github.com/yueb17/SSH-AE.},
  archive   = {C_AAAI},
  author    = {Yue Bai and Dipu Manandhar and Zhaowen Wang and John Collomosse and Yun Fu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25092},
  pages     = {206-214},
  title     = {Layout representation learning with spatial and structural hierarchies},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-contrastive learning: Single-viewed supervised
contrastive framework using sub-network. <em>AAAI</em>, 197–205. (<a
href="https://doi.org/10.1609/aaai.v37i1.25091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Contrastive loss has significantly improved performance in supervised classification tasks by using a multi-viewed framework that leverages augmentation and label information. The augmentation enables contrast with another view of a single image but enlarges training time and memory usage. To exploit the strength of multi-views while avoiding the high computation cost, we introduce a multi-exit architecture that outputs multiple features of a single image in a single-viewed framework. To this end, we propose Self-Contrastive (SelfCon) learning, which self-contrasts within multiple outputs from the different levels of a single network. The multi-exit architecture efficiently replaces multi-augmented images and leverages various information from different layers of a network. We demonstrate that SelfCon learning improves the classification performance of the encoder network, and empirically analyze its advantages in terms of the single-view and the sub-network. Furthermore, we provide theoretical evidence of the performance increase based on the mutual information bound. For ImageNet classification on ResNet-50, SelfCon improves accuracy by +0.6\% with 59\% memory and 48\% time of Supervised Contrastive learning, and a simple ensemble of multi-exit outputs boosts performance up to +1.5\%. Our code is available at https://github.com/raymin0223/self-contrastive-learning.},
  archive   = {C_AAAI},
  author    = {Sangmin Bae and Sungnyun Kim and Jongwoo Ko and Gihun Lee and Seungjong Noh and Se-Young Yun},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25091},
  pages     = {197-205},
  title     = {Self-contrastive learning: Single-viewed supervised contrastive framework using sub-network},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep digging into the generalization of self-supervised
monocular depth estimation. <em>AAAI</em>, 187–196. (<a
href="https://doi.org/10.1609/aaai.v37i1.25090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Self-supervised monocular depth estimation has been widely studied recently. Most of the work has focused on improving performance on benchmark datasets, such as KITTI, but has offered a few experiments on generalization performance. In this paper, we investigate the backbone networks (e.g., CNNs, Transformers, and CNN-Transformer hybrid models) toward the generalization of monocular depth estimation. We first evaluate state-of-the-art models on diverse public datasets, which have never been seen during the network training. Next, we investigate the effects of texture-biased and shape-biased representations using the various texture-shifted datasets that we generated. We observe that Transformers exhibit a strong shape bias and CNNs do a strong texture-bias. We also find that shape-biased models show better generalization performance for monocular depth estimation compared to texture-biased models. Based on these observations, we newly design a CNN-Transformer hybrid network with a multi-level adaptive feature fusion module, called MonoFormer. The design intuition behind MonoFormer is to increase shape bias by employing Transformers while compensating for the weak locality bias of Transformers by adaptively fusing multi-level representations. Extensive experiments show that the proposed method achieves state-of-the-art performance with various public datasets. Our method also shows the best generalization ability among the competitive methods.},
  archive   = {C_AAAI},
  author    = {Jinwoo Bae and Sungho Moon and Sunghoon Im},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25090},
  pages     = {187-196},
  title     = {Deep digging into the generalization of self-supervised monocular depth estimation},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Rethinking interpretation: Input-agnostic saliency mapping
of deep visual classifiers. <em>AAAI</em>, 178–186. (<a
href="https://doi.org/10.1609/aaai.v37i1.25089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Saliency methods provide post-hoc model interpretation by attributing input features to the model outputs. Current methods mainly achieve this using a single input sample, thereby failing to answer input-independent inquiries about the model. We also show that input-specific saliency mapping is intrinsically susceptible to misleading feature attribution. Current attempts to use `general&#39; input features for model interpretation assume access to a dataset containing those features, which biases the interpretation. Addressing the gap, we introduce a new perspective of input-agnostic saliency mapping that computationally estimates the high-level features attributed by the model to its outputs. These features are geometrically correlated, and are computed by accumulating model&#39;s gradient information with respect to an unrestricted data distribution. To compute these features, we nudge independent data points over the model loss surface towards the local minima associated by a human-understandable concept, e.g., class label for classifiers. With a systematic projection, scaling and refinement process, this information is transformed into an interpretable visualization without compromising its model-fidelity. The visualization serves as a stand-alone qualitative interpretation. With an extensive evaluation, we not only demonstrate successful visualizations for a variety of concepts for large-scale models, but also showcase an interesting utility of this new form of saliency mapping by identifying backdoor signatures in compromised classifiers.},
  archive   = {C_AAAI},
  author    = {Naveed Akhtar and Mohammad Amir Asim Khan Jalwana},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25089},
  pages     = {178-186},
  title     = {Rethinking interpretation: Input-agnostic saliency mapping of deep visual classifiers},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Denoising after entropy-based debiasing a robust training
method for dataset bias with noisy labels. <em>AAAI</em>, 169–177. (<a
href="https://doi.org/10.1609/aaai.v37i1.25088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Improperly constructed datasets can result in inaccurate inferences. For instance, models trained on biased datasets perform poorly in terms of generalization (i.e., dataset bias). Recent debiasing techniques have successfully achieved generalization performance by underestimating easy-to-learn samples (i.e., bias-aligned samples) and highlighting difficult-to-learn samples (i.e., bias-conflicting samples). However, these techniques may fail owing to noisy labels, because the trained model recognizes noisy labels as difficult-to-learn and thus highlights them. In this study, we find that earlier approaches that used the provided labels to quantify difficulty could be affected by the small proportion of noisy labels. Furthermore, we find that running denoising algorithms before debiasing is ineffective because denoising algorithms reduce the impact of difficult-to-learn samples, including valuable bias-conflicting samples. Therefore, we propose an approach called denoising after entropy-based debiasing, i.e., DENEB, which has three main stages. (1) The prejudice model is trained by emphasizing (bias-aligned, clean) samples, which are selected using a Gaussian Mixture Model. (2) Using the per-sample entropy from the output of the prejudice model, the sampling probability of each sample that is proportional to the entropy is computed. (3) The final model is trained using existing denoising algorithms with the mini-batches constructed by following the computed sampling probability. Compared to existing debiasing and denoising algorithms, our method achieves better debiasing performance on multiple benchmarks.},
  archive   = {C_AAAI},
  author    = {Sumyeong Ahn and Se-Young Yun},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25088},
  pages     = {169-177},
  title     = {Denoising after entropy-based debiasing a robust training method for dataset bias with noisy labels},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Progress and limitations of deep networks to recognize
objects in unusual poses. <em>AAAI</em>, 160–168. (<a
href="https://doi.org/10.1609/aaai.v37i1.25087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep networks should be robust to rare events if they are to be successfully deployed in high-stakes real-world applications. Here we study the capability of deep networks to recognize objects in unusual poses. We create a synthetic dataset of images of objects in unusual orientations, and evaluate the robustness of a collection of 38 recent and competitive deep networks for image classification. We show that classifying these images is still a challenge for all networks tested, with an average accuracy drop of 29.5\% compared to when the objects are presented upright. This brittleness is largely unaffected by various design choices, such as training losses, architectures, dataset modalities, and data-augmentation schemes. However, networks trained on very large datasets substantially outperform others, with the best network tested—Noisy Student trained on JFT-300M—showing a relatively small accuracy drop of only 14.5\% on unusual poses. Nevertheless, a visual inspection of the failures of Noisy Student reveals a remaining gap in robustness with humans. Furthermore, combining multiple object transformations—3D-rotations and scaling—further degrades the performance of all networks. Our results provide another measurement of the robustness of deep networks to consider when using them in the real world. Code and datasets are available at https://github.com/amro-kamal/ObjectPose.},
  archive   = {C_AAAI},
  author    = {Amro Abbas and Stéphane Deny},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25087},
  pages     = {160-168},
  title     = {Progress and limitations of deep networks to recognize objects in unusual poses},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ScatterFormer: Locally-invariant scattering transformer for
patient-independent multispectral detection of epileptiform discharges.
<em>AAAI</em>, 148–158. (<a
href="https://doi.org/10.1609/aaai.v37i1.25086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Patient-independent detection of epileptic activities based on visual spectral representation of continuous EEG (cEEG) has been widely used for diagnosing epilepsy. However, precise detection remains a considerable challenge due to subtle variabilities across subjects, channels and time points. Thus, capturing fine-grained, discriminative features of EEG patterns, which is associated with high-frequency textural information, is yet to be resolved. In this work, we propose Scattering Transformer (ScatterFormer), an invariant scattering transform-based hierarchical Transformer that specifically pays attention to subtle features. In particular, the disentangled frequency-aware attention (FAA) enables the Transformer to capture clinically informative high-frequency components, offering a novel clinical explainability based on visual encoding of multichannel EEG signals. Evaluations on two distinct tasks of epileptiform detection demonstrate the effectiveness our method. Our proposed model achieves median AUCROC and accuracy of 98.14\%, 96.39\% in patients with Rolandic epilepsy. On a neonatal seizure detection benchmark, it outperforms the state-of-the-art by 9\% in terms of average AUCROC.},
  archive   = {C_AAAI},
  author    = {Ruizhe Zheng and Jun Li and Yi Wang and Tian Luo and Yuguo Yu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25086},
  pages     = {148-158},
  title     = {ScatterFormer: Locally-invariant scattering transformer for patient-independent multispectral detection of epileptiform discharges},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Learning temporal-ordered representation for spike streams
based on discrete wavelet transforms. <em>AAAI</em>, 137–147. (<a
href="https://doi.org/10.1609/aaai.v37i1.25085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Spike camera, a new type of neuromorphic visual sensor that imitates the sampling mechanism of the primate fovea, can capture photons and output 40000 Hz binary spike streams. Benefiting from the asynchronous sampling mechanism, the spike camera can record fast-moving objects and clear images can be recovered from the spike stream at any specified timestamps without motion blurring. Despite these, due to the dense time sequence information of the discrete spike stream, it is not easy to directly apply the existing algorithms of traditional cameras to the spike camera. Therefore, it is necessary and interesting to explore a universally effective representation of dense spike streams to better fit various network architectures. In this paper, we propose to mine temporal-robust features of spikes in time-frequency space with wavelet transforms. We present a novel Wavelet-Guided Spike Enhancing (WGSE) paradigm consisting of three consecutive steps: multi-level wavelet transform, CNN-based learnable module, and inverse wavelet transform. With the assistance of WGSE, the new streaming representation of spikes can be learned. We demonstrate the effectiveness of WGSE on two downstream tasks, achieving state-of-the-art performance on the image reconstruction task and getting considerable performance on semantic segmentation. Furthermore, We build a new spike-based synthesized dataset for semantic segmentation. Code and Datasets are available at https://github.com/Leozhangjiyuan/WGSE-SpikeCamera.},
  archive   = {C_AAAI},
  author    = {Jiyuan Zhang and Shanshan Jia and Zhaofei Yu and Tiejun Huang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25085},
  pages     = {137-147},
  title     = {Learning temporal-ordered representation for spike streams based on discrete wavelet transforms},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Disentangling reafferent effects by doing nothing.
<em>AAAI</em>, 128–136. (<a
href="https://doi.org/10.1609/aaai.v37i1.25084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {An agent&#39;s ability to distinguish between sensory effects that are self-caused, and those that are not, is instrumental in the achievement of its goals. This ability is thought to be central to a variety of functions in biological organisms, from perceptual stabilisation and accurate motor control, to higher level cognitive functions such as planning, mirroring and the sense of agency. Although many of these functions are well studied in AI, this important distinction is rarely made explicit and the focus tends to be on the associational relationship between action and sensory effect or success. Toward the development of more general agents, we develop a framework that enables agents to disentangle self-caused and externally-caused sensory effects. Informed by relevant models and experiments in robotics, and in the biological and cognitive sciences, we demonstrate the general applicability of this framework through an extensive experimental evaluation over three different environments.},
  archive   = {C_AAAI},
  author    = {Benedict Wilkins and Kostas Stathis},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25084},
  pages     = {128-136},
  title     = {Disentangling reafferent effects by doing nothing},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). CMNet: Contrastive magnification network for
micro-expression recognition. <em>AAAI</em>, 119–127. (<a
href="https://doi.org/10.1609/aaai.v37i1.25083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Micro-Expression Recognition (MER) is challenging because the Micro-Expressions&#39; (ME) motion is too weak to distinguish. This hurdle can be tackled by enhancing intensity for a more accurate acquisition of movements. However, existing magnification strategies tend to use the features of facial images that include not only intensity clues as intensity features, leading to the intensity representation deficient of credibility. In addition, the intensity variation over time, which is crucial for encoding movements, is also neglected. To this end, we provide a reliable scheme to extract intensity clues while considering their variation on the time scale. First, we devise an Intensity Distillation (ID) loss to acquire the intensity clues by contrasting the difference between frames, given that the difference in the same video lies only in the intensity. Then, the intensity clues are calibrated to follow the trend of the original video. Specifically, due to the lack of truth intensity annotation of the original video, we build the intensity tendency by setting each intensity vacancy an uncertain value, which guides the extracted intensity clues to converge towards this trend rather some fixed values. A Wilcoxon rank sum test (Wrst) method is enforced to implement the calibration. Experimental results on three public ME databases i.e. CASME II, SAMM, and SMIC-HS validate the superiority against state-of-the-art methods.},
  archive   = {C_AAAI},
  author    = {Mengting Wei and Xingxun Jiang and Wenming Zheng and Yuan Zong and Cheng Lu and Jiateng Liu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25083},
  pages     = {119-127},
  title     = {CMNet: Contrastive magnification network for micro-expression recognition},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Self-supervised graph learning for long-tailed cognitive
diagnosis. <em>AAAI</em>, 110–118. (<a
href="https://doi.org/10.1609/aaai.v37i1.25082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Cognitive diagnosis is a fundamental yet critical research task in the field of intelligent education, which aims to discover the proficiency level of different students on specific knowledge concepts. Despite the effectiveness of existing efforts, previous methods always considered the mastery level on the whole students, so they still suffer from the Long Tail Effect. A large number of students who have sparse interaction records are usually wrongly diagnosed during inference. To relieve the situation, we proposed a Self-supervised Cognitive Diagnosis (SCD) framework which leverages the self-supervised manner to assist the graph-based cognitive diagnosis, then the performance on those students with sparse data can be improved. Specifically, we came up with a graph confusion method that drops edges under some special rules to generate different sparse views of the graph. By maximizing the cross-view consistency of node representations, our model could pay more attention on long-tailed students. Additionally, we proposed an importance-based view generation rule to improve the influence of long-tailed students. Extensive experiments on real-world datasets show the effectiveness of our approach, especially on the students with much sparser interaction records. Our code is available at https://github.com/zeng-zhen/SCD.},
  archive   = {C_AAAI},
  author    = {Shanshan Wang and Zhen Zeng and Xun Yang and Xingyi Zhang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25082},
  pages     = {110-118},
  title     = {Self-supervised graph learning for long-tailed cognitive diagnosis},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023a). Complex dynamic neurons improved spiking transformer
network for efficient automatic speech recognition. <em>AAAI</em>,
102–109. (<a href="https://doi.org/10.1609/aaai.v37i1.25081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The spiking neural network (SNN) using leaky-integrated-and-fire (LIF) neurons has been commonly used in automatic speech recognition (ASR) tasks. However, the LIF neuron is still relatively simple compared to that in the biological brain. Further research on more types of neurons with different scales of neuronal dynamics is necessary. Here we introduce four types of neuronal dynamics to post-process the sequential patterns generated from the spiking transformer to get the complex dynamic neuron improved spiking transformer neural network (DyTr-SNN). We found that the DyTr-SNN could handle the non-toy automatic speech recognition task well, representing a lower phoneme error rate, lower computational cost, and higher robustness. These results indicate that the further cooperation of SNNs and neural dynamics at the neuron and network scales might have much in store for the future, especially on the ASR tasks.},
  archive   = {C_AAAI},
  author    = {Qingyu Wang and Tielin Zhang and Minglun Han and Yi Wang and Duzhen Zhang and Bo Xu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25081},
  pages     = {102-109},
  title     = {Complex dynamic neurons improved spiking transformer network for efficient automatic speech recognition},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Zero-shot linear combinations of grounded social
interactions with linear social MDPs. <em>AAAI</em>, 94–101. (<a
href="https://doi.org/10.1609/aaai.v37i1.25080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Humans and animals engage in rich social interactions. It is often theorized that a relatively small number of basic social interactions give rise to the full range of behavior observed. But no computational theory explaining how social interactions combine together has been proposed before. We do so here. We take a model, the Social MDP, which is able to express a range of social interactions, and extend it to represent linear combinations of social interactions. Practically for robotics applications, such models are now able to not just express that an agent should help another agent, but to express goal-centric social interactions. Perhaps an agent is helping someone get dressed, but preventing them from falling, and is happy to exchange stories in the meantime. How an agent responds socially, should depend on what it thinks the other agent is doing at that point in time. To encode this notion, we take linear combinations of social interactions as defined in Social MDPs, and compute the weights on those combinations on the fly depending on the estimated goals of other agents. This new model, the Linear Social MDP, enables zero-shot reasoning about complex social interactions, provides a mathematical basis for the long-standing intuition that social interactions should compose, and leads to interesting new behaviors that we validate using human observers. Complex social interactions are part of the future of intelligent agents, and having principled mathematical models built on a foundation like MDPs will make it possible to bring social interactions to every robotic application.},
  archive   = {C_AAAI},
  author    = {Ravi Tejwani and Yen-Ling Kuo and Tianmin Shu and Bennett Stankovits and Dan Gutfreund and Joshua B. Tenenbaum and Boris Katz and Andrei Barbu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25080},
  pages     = {94-101},
  title     = {Zero-shot linear combinations of grounded social interactions with linear social MDPs},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). ESL-SNNs: An evolutionary structure learning strategy for
spiking neural networks. <em>AAAI</em>, 86–93. (<a
href="https://doi.org/10.1609/aaai.v37i1.25079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Spiking neural networks (SNNs) have manifested remarkable advantages in power consumption and event-driven property during the inference process. To take full advantage of low power consumption and improve the efficiency of these models further, the pruning methods have been explored to find sparse SNNs without redundancy connections after training. However, parameter redundancy still hinders the efficiency of SNNs during training. In the human brain, the rewiring process of neural networks is highly dynamic, while synaptic connections maintain relatively sparse during brain development. Inspired by this, here we propose an efficient evolutionary structure learning (ESL) framework for SNNs, named ESL-SNNs, to implement the sparse SNN training from scratch. The pruning and regeneration of synaptic connections in SNNs evolve dynamically during learning, yet keep the structural sparsity at a certain level. As a result, the ESL-SNNs can search for optimal sparse connectivity by exploring all possible parameters across time. Our experiments show that the proposed ESL-SNNs framework is able to learn SNNs with sparse structures effectively while reducing the limited accuracy. The ESL-SNNs achieve merely 0.28\% accuracy loss with 10\% connection density on the DVS-Cifar10 dataset. Our work presents a brand-new approach for sparse training of SNNs from scratch with biologically plausible evolutionary mechanisms, closing the gap in the expressibility between sparse training and dense training. Hence, it has great potential for SNN lightweight training and inference with low power consumption and small memory usage.},
  archive   = {C_AAAI},
  author    = {Jiangrong Shen and Qi Xu and Jian K. Liu and Yueming Wang and Gang Pan and Huajin Tang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25079},
  pages     = {86-93},
  title     = {ESL-SNNs: An evolutionary structure learning strategy for spiking neural networks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). AVCAffe: A large scale audio-visual dataset of cognitive
load and affect for remote work. <em>AAAI</em>, 76–85. (<a
href="https://doi.org/10.1609/aaai.v37i1.25078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We introduce AVCAffe, the first Audio-Visual dataset consisting of Cognitive load and Affect attributes. We record AVCAffe by simulating remote work scenarios over a video-conferencing platform, where subjects collaborate to complete a number of cognitively engaging tasks. AVCAffe is the largest originally collected (not collected from the Internet) affective dataset in English language. We recruit 106 participants from 18 different countries of origin, spanning an age range of 18 to 57 years old, with a balanced male-female ratio. AVCAffe comprises a total of 108 hours of video, equivalent to more than 58,000 clips along with task-based self-reported ground truth labels for arousal, valence, and cognitive load attributes such as mental demand, temporal demand, effort, and a few others. We believe AVCAffe would be a challenging benchmark for the deep learning research community given the inherent difficulty of classifying affect and cognitive load in particular. Moreover, our dataset fills an existing timely gap by facilitating the creation of learning systems for better self-management of remote work meetings, and further study of hypotheses regarding the impact of remote work on cognitive load and affective states.},
  archive   = {C_AAAI},
  author    = {Pritam Sarkar and Aaron Posen and Ali Etemad},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25078},
  pages     = {76-85},
  title     = {AVCAffe: A large scale audio-visual dataset of cognitive load and affect for remote work},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Intensity-aware loss for dynamic facial expression
recognition in the wild. <em>AAAI</em>, 67–75. (<a
href="https://doi.org/10.1609/aaai.v37i1.25077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Compared with the image-based static facial expression recognition (SFER) task, the dynamic facial expression recognition (DFER) task based on video sequences is closer to the natural expression recognition scene. However, DFER is often more challenging. One of the main reasons is that video sequences often contain frames with different expression intensities, especially for the facial expressions in the real-world scenarios, while the images in SFER frequently present uniform and high expression intensities. Nevertheless, if the expressions with different intensities are treated equally, the features learned by the networks will have large intra-class and small inter-class differences, which are harmful to DFER. To tackle this problem, we propose the global convolution-attention block (GCA) to rescale the channels of the feature maps. In addition, we introduce the intensity-aware loss (IAL) in the training process to help the network distinguish the samples with relatively low expression intensities. Experiments on two in-the-wild dynamic facial expression datasets (i.e., DFEW and FERV39k) indicate that our method outperforms the state-of-the-art DFER approaches. The source code will be available at https://github.com/muse1998/IAL-for-Facial-Expression-Recognition.},
  archive   = {C_AAAI},
  author    = {Hanting Li and Hongjing Niu and Zhaoqing Zhu and Feng Zhao},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25077},
  pages     = {67-75},
  title     = {Intensity-aware loss for dynamic facial expression recognition in the wild},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Persuasion strategies in advertisements. <em>AAAI</em>,
57–66. (<a href="https://doi.org/10.1609/aaai.v37i1.25076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Modeling what makes an advertisement persuasive, i.e., eliciting the desired response from consumer, is critical to the study of propaganda, social psychology, and marketing. Despite its importance, computational modeling of persuasion in computer vision is still in its infancy, primarily due to the lack of benchmark datasets that can provide persuasion-strategy labels associated with ads. Motivated by persuasion literature in social psychology and marketing, we introduce an extensive vocabulary of persuasion strategies and build the first ad image corpus annotated with persuasion strategies. We then formulate the task of persuasion strategy prediction with multi-modal learning, where we design a multi-task attention fusion model that can leverage other ad-understanding tasks to predict persuasion strategies. The dataset also provides image segmentation masks, which labels persuasion strategies in the corresponding ad images on the test split. We publicly release our code and dataset at https://midas-research.github.io/persuasion-advertisements/.},
  archive   = {C_AAAI},
  author    = {Yaman Kumar and Rajat Jha and Arunim Gupta and Milan Aggarwal and Aditya Garg and Tushar Malyan and Ayush Bhardwaj and Rajiv Ratn Shah and Balaji Krishnamurthy and Changyou Chen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25076},
  pages     = {57-66},
  title     = {Persuasion strategies in advertisements},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A machine with short-term, episodic, and semantic memory
systems. <em>AAAI</em>, 48–56. (<a
href="https://doi.org/10.1609/aaai.v37i1.25075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Inspired by the cognitive science theory of the explicit human memory systems, we have modeled an agent with short-term, episodic, and semantic memory systems, each of which is modeled with a knowledge graph. To evaluate this system and analyze the behavior of this agent, we designed and released our own reinforcement learning agent environment, “the Room”, where an agent has to learn how to encode, store, and retrieve memories to maximize its return by answering questions. We show that our deep Q-learning based agent successfully learns whether a short-term memory should be forgotten, or rather be stored in the episodic or semantic memory systems. Our experiments indicate that an agent with human-like memory systems can outperform an agent without this memory structure in the environment.},
  archive   = {C_AAAI},
  author    = {Taewoon Kim and Michael Cochez and Vincent Francois-Lavet and Mark Neerincx and Piek Vossen},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25075},
  pages     = {48-56},
  title     = {A machine with short-term, episodic, and semantic memory systems},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). A semi-parametric model for decision making in
high-dimensional sensory discrimination tasks. <em>AAAI</em>, 40–47. (<a
href="https://doi.org/10.1609/aaai.v37i1.25074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Psychometric functions typically characterize binary sensory decisions along a single stimulus dimension. However, real-life sensory tasks vary along a greater variety of dimensions (e.g. color, contrast and luminance for visual stimuli). Approaches to characterizing high-dimensional sensory spaces either require strong parametric assumptions about these additional contextual dimensions, or fail to leverage known properties of classical psychometric curves. We overcome both limitations by introducing a semi-parametric model of sensory discrimination that applies traditional psychophysical models along a stimulus intensity dimension, but puts Gaussian process (GP) priors on the parameters of these models with respect to the remaining dimensions. By combining the flexibility of the GP with the deep literature on parametric psychophysics, our semi-parametric models achieve good performance with much less data than baselines on both synthetic and real-world, high-dimensional psychophysics datasets. We additionally show strong performance in a Bayesian active learning setting, and present a novel active learning paradigm for the semi-parametric model.},
  archive   = {C_AAAI},
  author    = {Stephen Keeley and Benjamin Letham and Craig Sanders and Chase Tymms and Michael Shvartsman},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25074},
  pages     = {40-47},
  title     = {A semi-parametric model for decision making in high-dimensional sensory discrimination tasks},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Deep spiking neural networks with high representation
similarity model visual pathways of macaque and mouse. <em>AAAI</em>,
31–39. (<a href="https://doi.org/10.1609/aaai.v37i1.25073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep artificial neural networks (ANNs) play a major role in modeling the visual pathways of primate and rodent. However, they highly simplify the computational properties of neurons compared to their biological counterparts. Instead, Spiking Neural Networks (SNNs) are more biologically plausible models since spiking neurons encode information with time sequences of spikes, just like biological neurons do. However, there is a lack of studies on visual pathways with deep SNNs models. In this study, we model the visual cortex with deep SNNs for the first time, and also with a wide range of state-of-the-art deep CNNs and ViTs for comparison. Using three similarity metrics, we conduct neural representation similarity experiments on three neural datasets collected from two species under three types of stimuli. Based on extensive similarity analyses, we further investigate the functional hierarchy and mechanisms across species. Almost all similarity scores of SNNs are higher than their counterparts of CNNs with an average of 6.6\%. Depths of the layers with the highest similarity scores exhibit little differences across mouse cortical regions, but vary significantly across macaque regions, suggesting that the visual processing structure of mice is more regionally homogeneous than that of macaques. Besides, the multi-branch structures observed in some top mouse brain-like neural networks provide computational evidence of parallel processing streams in mice, and the different performance in fitting macaque neural representations under different stimuli exhibits the functional specialization of information processing in macaques. Taken together, our study demonstrates that SNNs could serve as promising candidates to better model and explain the functional hierarchy and mechanisms of the visual system.},
  archive   = {C_AAAI},
  author    = {Liwei Huang and Zhengyu Ma and Liutao Yu and Huihui Zhou and Yonghong Tian},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25073},
  pages     = {31-39},
  title     = {Deep spiking neural networks with high representation similarity model visual pathways of macaque and mouse},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Hierarchical ConViT with attention-based relational reasoner
for visual analogical reasoning. <em>AAAI</em>, 22–30. (<a
href="https://doi.org/10.1609/aaai.v37i1.25072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Raven’s Progressive Matrices (RPMs) have been widely used to evaluate the visual reasoning ability of humans. To tackle the challenges of visual perception and logic reasoning on RPMs, we propose a Hierarchical ConViT with Attention-based Relational Reasoner (HCV-ARR). Traditional solution methods often apply relatively shallow convolution networks to visually perceive shape patterns in RPM images, which may not fully model the long-range dependencies of complex pattern combinations in RPMs. The proposed ConViT consists of a convolutional block to capture the low-level attributes of visual patterns, and a transformer block to capture the high-level image semantics such as pattern formations. Furthermore, the proposed hierarchical ConViT captures visual features from multiple receptive fields, where the shallow layers focus on the image fine details while the deeper layers focus on the image semantics. To better model the underlying reasoning rules embedded in RPM images, an Attention-based Relational Reasoner (ARR) is proposed to establish the underlying relations among images. The proposed ARR well exploits the hidden relations among question images through the developed element-wise attentive reasoner. Experimental results on three RPM datasets demonstrate that the proposed HCV-ARR achieves a significant performance gain compared with the state-of-the-art models. The source code is available at: https://github.com/wentaoheunnc/HCV-ARR.},
  archive   = {C_AAAI},
  author    = {Wentao He and Jialu Zhang and Jianfeng Ren and Ruibin Bai and Xudong Jiang},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25072},
  pages     = {22-30},
  title     = {Hierarchical ConViT with attention-based relational reasoner for visual analogical reasoning},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Reducing ANN-SNN conversion error through residual membrane
potential. <em>AAAI</em>, 11–21. (<a
href="https://doi.org/10.1609/aaai.v37i1.25071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Spiking Neural Networks (SNNs) have received extensive academic attention due to the unique properties of low power consumption and high-speed computing on neuromorphic chips. Among various training methods of SNNs, ANN-SNN conversion has shown the equivalent level of performance as ANNs on large-scale datasets. However, unevenness error, which refers to the deviation caused by different temporal sequences of spike arrival on activation layers, has not been effectively resolved and seriously suffers the performance of SNNs under the condition of short time-steps. In this paper, we make a detailed analysis of unevenness error and divide it into four categories. We point out that the case of the ANN output being zero while the SNN output being larger than zero accounts for the largest percentage. Based on this, we theoretically prove the sufficient and necessary conditions of this case and propose an optimization strategy based on residual membrane potential to reduce unevenness error. The experimental results show that the proposed method achieves state-of-the-art performance on CIFAR-10, CIFAR-100, and ImageNet datasets. For example, we reach top-1 accuracy of 64.32\% on ImageNet with 10-steps. To the best of our knowledge, this is the first time ANN-SNN conversion can simultaneously achieve high accuracy and ultra-low-latency on the complex dataset. Code is available at https://github.com/hzc1208/ANN2SNN_SRP.},
  archive   = {C_AAAI},
  author    = {Zecheng Hao and Tong Bu and Jianhao Ding and Tiejun Huang and Zhaofei Yu},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25071},
  pages     = {11-21},
  title     = {Reducing ANN-SNN conversion error through residual membrane potential},
  year      = {2023},
}
</textarea>
</details></li>
<li><details>
<summary>
(2023). Back to the future: Toward a hybrid architecture for ad hoc
teamwork. <em>AAAI</em>, 3–10. (<a
href="https://doi.org/10.1609/aaai.v37i1.25070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {State of the art methods for ad hoc teamwork, i.e., for collaboration without prior coordination, often use a long history of prior observations to model the behavior of other agents (or agent types) and to determine the ad hoc agent&#39;s behavior. In many practical domains, it is difficult to obtain large training datasets, and necessary to quickly revise the existing models to account for changes in team composition or domain attributes. Our architecture builds on the principles of step-wise refinement and ecological rationality to enable an ad hoc agent to perform non-monotonic logical reasoning with prior commonsense domain knowledge and models learned rapidly from limited examples to predict the behavior of other agents. In the simulated multiagent collaboration domain Fort Attack, we experimentally demonstrate that our architecture enables an ad hoc agent to adapt to changes in the behavior of other agents, and provides enhanced transparency and better performance than a state of the art data-driven baseline.},
  archive   = {C_AAAI},
  author    = {Hasra Dodampegama and Mohan Sridharan},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  doi       = {10.1609/aaai.v37i1.25070},
  pages     = {3-10},
  title     = {Back to the future: Toward a hybrid architecture for ad hoc teamwork},
  year      = {2023},
}
</textarea>
</details></li>
</ul>

</body>
</html>
