<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>GECCO_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="gecco---181">GECCO - 181</h2>
<ul>
<li><details>
<summary>
(2024). Guiding quality diversity on monotone submodular functions:
Customising the feature space by adding boolean conjunctions.
<em>GECCO</em>, 1614–1622. (<a
href="https://doi.org/10.1145/3638529.3654160">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Quality Diversity (QD) aims to evolve a population of solutions that are both diverse and of high quality. The Map-Elites QD approach partitions the search space according to a feature space and stores the best solution for each feature. Bossek \&amp;amp; Sudholt (GECCO 2023) showed that a simple QD algorithm on the feature space defined by the number of selected elements efficiently computes (1 - 1/e)-approximations for maximising monotone submodular functions.We extend this approach by adding Boolean conjunctions to the feature space, which allow the user to enforce or to exclude certain elements. This enhanced feature space overlays several customised problems, which are optimised in parallel. We bound the expected time for QD to find (1 - 1/e)-approximations for all problems simultaneously and show that adding sub-problems mechanically via helper formulas guides the search and speeds up optimisation. Finally, we give instances on which the use of crossover yields drastic speedups.Our work contributes to the theoretical understanding of QD algorithms and suggests a way to maximise the potential of QD.},
  archive   = {C_GECCO},
  author    = {Schmidbauer, Marcus and Opris, Andre and Bossek, Jakob and Neumann, Frank and Sudholt, Dirk},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654160},
  pages     = {1614–1622},
  title     = {Guiding quality diversity on monotone submodular functions: Customising the feature space by adding boolean conjunctions},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A tight o(4k/pc) runtime bound for a (μ+1)GA on jumpk for
realistic crossover probabilities. <em>GECCO</em>, 1605–1613. (<a
href="https://doi.org/10.1145/3638529.3654120">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Jumpk benchmark was the first problem for which crossover was proven to give a speedup over mutation-only evolutionary algorithms. Jansen and Wegener (2002) proved an upper bound of O(poly(n) + 4k/pc) for the (μ+1) Genetic Algorithm ((μ+1) GA), but only for unrealistically small crossover probabilities pc. To this date, it remains an open problem to prove similar upper bounds for realistic pc; the best known runtime bound for pc = Ω(1) is O((n/x)k-1), χ a positive constant.Using recently developed techniques, we analyse the evolution of the population diversity, measured as sum of pairwise Hamming distances, for a variant of the (μ+1) GA on Jumpk. We show that population diversity converges to an equilibrium of near-perfect diversity. This yields an improved and tight time bound of O(μn log(k) + 4k/pc) for a range of k under the mild assumptions pc = O(1/k) and μ ϵ Ω(kn). For all constant k the restriction is satisfied for some pc = Ω(1). Our work partially solves a problem that has been open for more than 20 years.},
  archive   = {C_GECCO},
  author    = {Opris, Andre and Lengler, Johannes and Sudholt, Dirk},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654120},
  pages     = {1605–1613},
  title     = {A tight o(4k/pc) runtime bound for a (μ+1)GA on jumpk for realistic crossover probabilities},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Runtime analyses of NSGA-III on many-objective problems.
<em>GECCO</em>, 1596–1604. (<a
href="https://doi.org/10.1145/3638529.3654218">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {NSGA-II and NSGA-III are two of the most popular evolutionary multi-objective algorithms used in practice. While NSGA-II is used for few objectives such as 2 and 3, NSGA-III is designed to deal with a larger number of objectives. In a recent breakthrough, Wietheger and Doerr (IJCAI 2023) gave the first runtime analysis for NSGA-III on the 3-objective OneMinMax problem, showing that this state-of-the-art algorithm can be analyzed rigorously.We advance this new line of research by presenting the first runtime analyses of NSGA-III on the popular many-objective benchmark problems m-LOTZ, m-OMM, and m-COCZ, for an arbitrary constant number m of objectives. Our analysis provides ways to set the important parameters of the algorithm: the number of reference points and the population size, so that a good performance can be guaranteed. We show how these parameters should be scaled with the problem dimension, the number of objectives and the fitness range. To our knowledge, these are the first runtime analyses for NSGA-III for more than 3 objectives.},
  archive   = {C_GECCO},
  author    = {Opris, Andre and Dang, Duc-Cuong and Neumann, Frank and Sudholt, Dirk},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654218},
  pages     = {1596–1604},
  title     = {Runtime analyses of NSGA-III on many-objective problems},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Plus strategies are exponentially slower for planted optima
of random height. <em>GECCO</em>, 1587–1595. (<a
href="https://doi.org/10.1145/3638529.3654088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We compare the (1, λ)-EA and the (1 + λ)-EA on the recently introduced benchmark DisOM, which is the OneMax function with randomly planted local optima. Previous work showed that if all local optima have the same relative height, then the plus strategy never loses more than a factor O(n log n) compared to the comma strategy. Here we show that even small random fluctuations in the heights of the local optima have a devastating effect for the plus strategy and lead to super-polynomial runtimes. On the other hand, due to their ability to escape local optima, comma strategies are unaffected by the height of the local optima and remain efficient. Our results hold for a broad class of possible distortions and show that the plus strategy, but not the comma strategy, is generally deceived by sparse unstructured fluctuations of a smooth landscape. We further develop new techniques for analyzing &quot;frozen noise&quot; which may be of independent interest.},
  archive   = {C_GECCO},
  author    = {Lengler, Johannes and Schiller, Leon and Sieberling, Oliver},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654088},
  pages     = {1587–1595},
  title     = {Plus strategies are exponentially slower for planted optima of random height},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A flexible evolutionary algorithm with dynamic mutation rate
archive. <em>GECCO</em>, 1578–1586. (<a
href="https://doi.org/10.1145/3638529.3654076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose a new, flexible approach for dynamically maintaining successful mutation rates in evolutionary algorithms using k-bit flip mutations. The algorithm adds successful mutation rates to an archive of promising rates that are favored in subsequent steps. Rates expire when their number of unsuccessful trials has exceeded a threshold, while rates currently not present in the archive can enter it in two ways: (i) via user-defined minimum selection probabilities for rates combined with a successful step or (ii) via a stagnation detection mechanism increasing the value for a promising rate after the current bit-flip neighborhood has been explored with high probability. For the minimum selection probabilities, we suggest different options, including heavy-tailed distributions.We conduct rigorous runtime analysis of the flexible evolutionary algorithm on the OneMax and Jump functions, on general unimodal functions, on minimum spanning trees, and on a class of hurdle-like functions with varying hurdle width that benefit particularly from the archive of promising mutation rates. In all cases, the runtime bounds are close to or even outperform the best known results for both stagnation detection and heavy-tailed mutations.},
  archive   = {C_GECCO},
  author    = {Krejca, Martin S. and Witt, Carsten},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654076},
  pages     = {1578–1586},
  title     = {A flexible evolutionary algorithm with dynamic mutation rate archive},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Run time bounds for integer-valued OneMax functions.
<em>GECCO</em>, 1569–1577. (<a
href="https://doi.org/10.1145/3638529.3654091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {While most theoretical run time analyses of discrete randomized search heuristics focus on finite search spaces, we consider the search space Zn. Understanding this search space is especially relevant for developing better algorithms for mixed-integer black box optimization (MI-BBO) problems.We consider as a fitness functions the distance to the (unique) non-zero optimum a (based on the ℓ1-metric) and study the (1+1) EA which mutates by applying a step-operator on each component that is determined to be varied. For changing by ±1, we show that the expected optimization time is Θ(n · (|a|∞ + log(|a|H))). In particular, the time is linear in |a|∞, a measure of distance between starting point and target a. Employing a different step operator which chooses a step size from a distribution so heavy-tailed that the expectation is infinite, we get an optimization time of O(n · log2(|a|1) · (log(log(|a|1)))1+∈).Furthermore, we show that RLS with step size adaptation achieves an optimization time of Θ(n · log(|a|1)) and that ℓ1-symmetric operators (as suggested by Rudolph&#39;94) require a time at least linear in |a|1.We complement our findings with experimental results which show that asymptotically sub-optimal algorithms can be faster for smaller values of |a|∞.},
  archive   = {C_GECCO},
  author    = {Gadea Harder, Jonathan and K\&quot;{o}tzing, Timo and Li, Xiaoyue and Radhakrishnan, Aishwarya and Ruff, Janosch},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654091},
  pages     = {1569–1577},
  title     = {Run time bounds for integer-valued OneMax functions},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A runtime analysis of bias-invariant neuroevolution and
dynamic fitness evaluation. <em>GECCO</em>, 1560–1568. (<a
href="https://doi.org/10.1145/3638529.3654044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the field of neuroevolution (NE), evolutionary algorithms are used to update the weights, biases and topologies of artificial neural networks (ANNs). A recent theoretical work presented the first runtime analysis of NE in a simple setting, considering a single neuron and intuitive benchmark function classes. However, this work was limited by the unrealistic settings with regard to activation functions and fitness measurements.In this paper, we extend upon this first work by overcoming the two shortcomings. Firstly, we consider a more realistic setting in which the NE also evolves a third parameter, termed the bend, allowing the previous benchmark function classes to be solved efficiently even in the fixed bias case. This setting mimics rectified linear unit activation functions, which are common in real-world applications of ANNs. Secondly, we consider a dynamic fitness function evaluation paradigm where the weights and biases are updated after each new sample. Experimental results in both cases support the presented theoretical results.},
  archive   = {C_GECCO},
  author    = {Fischer, Paul and Warwicker, John Alasdair and Witt, Carsten},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654044},
  pages     = {1560–1568},
  title     = {A runtime analysis of bias-invariant neuroevolution and dynamic fitness evaluation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The SLO hierarchy of pseudo-boolean functions and runtime of
evolutionary algorithms. <em>GECCO</em>, 1551–1559. (<a
href="https://doi.org/10.1145/3638529.3654221">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {While some common fitness landscape characteristics are critical when determining the runtime of evolutionary algorithms (EAs), the relationship between fitness landscape structure and the runtime of EAs is poorly understood. Recently, Dang et al. (2021) introduced a classification of pseudo-Boolean problems showing that &quot;sparsity&quot; of local optima and the &quot;density&quot; of fitness valleys can be crucial characteristics when determining the runtime of EAs. However, their approach could only classify some classes of pseudo-Boolean functions and thus defined an incomplete hierarchy.We generalise the previous work to a complete hierarchy for all pseudo-Boolean functions. The hierarchy is consistent with existing results for the runtime of EAs. The hardest part of the hierarchy consists of problems satisfying the No Free Lunch theorem. The easiest part contains well-known theoretical benchmark problems, easy for EAs. The intermediary parts contain instances of NP-hard problems. Problem classes where local optima sparsity exceed fitness valley density are shown to have exponential black-box complexity. We study how random perturbations of a function can change its classification. E.g, randomly perturbing search points in OneMax with constant probability leads to a problem class that can still be optimised efficiently with appropriately tuned non-elitist EAs.},
  archive   = {C_GECCO},
  author    = {Dang, Duc-Cuong and Lehre, Per Kristian},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654221},
  pages     = {1551–1559},
  title     = {The SLO hierarchy of pseudo-boolean functions and runtime of evolutionary algorithms},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Runtime analysis of coevolutionary algorithms on a class of
symmetric zero-sum games. <em>GECCO</em>, 1542–1550. (<a
href="https://doi.org/10.1145/3638529.3654216">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A standard aim in game theory is to find a pure or mixed Nash equilibrium. For strategy spaces too large for a Nash equilibrium to be computed classically, this can instead be approached using a co-evolutionary algorithm. How to design coevolutionary algorithms which avoid pathological behaviours (such as cycling or forgetting) on challenging games is then a crucial open problem.We argue that runtime analysis can provide insight and inform the design of more powerful and reliable algorithms for this purpose. To this end, we consider a class of symmetric zero-sum games for which the role of population diversity is pivotal to an algorithm&#39;s success. We prove that a broad class of algorithms which do not utilise a population have superpolynomial runtime for this class. In the other direction we prove that, with high probability, a coevolutionary instance of the univariate marginal distribution algorithm finds the unique Nash equilibrium in time O(n(log n)2).Together, these results demonstrate the importance of generating diverse search points for evolving better strategies. The corresponding proofs develop several techniques that may benefit future analysis of estimation of distribution and coevolutionary algorithms.},
  archive   = {C_GECCO},
  author    = {Benford, Alistair and Lehre, Per Kristian},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654216},
  pages     = {1542–1550},
  title     = {Runtime analysis of coevolutionary algorithms on a class of symmetric zero-sum games},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evolutionary computation meets graph drawing: Runtime
analysis for crossing minimisation on layered graph drawings.
<em>GECCO</em>, 1533–1541. (<a
href="https://doi.org/10.1145/3638529.3654105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph Drawing aims to make graphs visually comprehensible while faithfully representing their structure. In layered drawings, each vertex is drawn on a horizontal line and edges are drawn as y-monotone curves. A key ingredient for constructing such drawings is the One-Sided Bipartite Crossing Minimisation (OBCM) problem: given two layers of a bipartite graph and a fixed horizontal order of the vertices on the first layer, the task is to order the vertices on the second layer to minimise the number of edge crossings.We analyse the performance of simple evolutionary algorithms for OBCM and compare different operators for permutations: exchanging two elements, swapping adjacent elements and jumping an element to a new position. We show that the simplest and cheapest mutation operator, swap, shows excellent performance on instances that can be drawn crossing-free, which corresponds to a generalised sorting problem. We give a tight runtime bound of Θ(n2) via a parallel BubbleSort algorithm and a delay sequence argument. This gives a positive answer to an open problem from Scharnow, Tinnefeld, and Wegener (2004) on whether the best-known bound of O(n2 log n) for sorting in permutation spaces can be improved to Θ(n2), albeit for an even simpler operator.},
  archive   = {C_GECCO},
  author    = {Baumann, Jakob and Rutter, Ignaz and Sudholt, Dirk},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654105},
  pages     = {1533–1541},
  title     = {Evolutionary computation meets graph drawing: Runtime analysis for crossing minimisation on layered graph drawings},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Already moderate population sizes provably yield strong
robustness to noise. <em>GECCO</em>, 1524–1532. (<a
href="https://doi.org/10.1145/3638529.3654196">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Experience shows that typical evolutionary algorithms can cope well with stochastic disturbances such as noisy function evaluations. In this first mathematical runtime analysis of the (1 + λ) and (1, λ) evolutionary algorithms in the presence of prior bit-wise noise, we show that both algorithms can tolerate constant noise probabilities without increasing the asymptotic runtime on the OneMax benchmark. For this, a population size λ suffices that is at least logarithmic in the problem size n. The only previous result in this direction regarded the less realistic one-bit noise model, required a population size super-linear in the problem size, and proved a runtime guarantee roughly cubic in the noiseless runtime for the OneMax benchmark. Our significantly stronger results are based on the novel proof argument that the noiseless offspring can be seen as a biased uniform crossover between the parent and the noisy offspring. We are optimistic that the technical lemmas resulting from this insight will find applications also in future mathematical runtime analyses of evolutionary algorithms.},
  archive   = {C_GECCO},
  author    = {Antipov, Denis and Doerr, Benjamin and Ivanova, Alexandra},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654196},
  pages     = {1524–1532},
  title     = {Already moderate population sizes provably yield strong robustness to noise},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive aggregative multitask competitive particle swarm
optimization with bi-directional asymmetric flip strategy for
high-dimensional feature selection. <em>GECCO</em>, 1515–1523. (<a
href="https://doi.org/10.1145/3638529.3654021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Evolutionary multitask optimization (EMTO) has been increasingly employed in addressing high-dimensional feature selection challenges, but current EMTO algorithms still have three deficiencies: First, in task generation, they just consider the linear correlation among features but ignore the nonlinear correlation. Second, they commonly encounter negative knowledge transfer. Third, they are hard to strike an optimal balance between global search capability and computational efficiency. This paper proposes an adaptive aggregative multitask competitive swarm optimization (AAMCSO) for high-dimensional feature selection, which contains three novel and effective strategies to address the above deficiencies. Firstly, AAMCSO proposes a linear-and-nonlinear-correlation-based task generation strategy to generate multiple tasks while considering both linear and nonlinear correlation between features and labels. Secondly, AAMCSO proposes an adaptive aggregative knowledge transfer strategy to adaptively transfer positive knowledge among related tasks. Thirdly, AAMCSO proposes a bi-directional asymmetric flip strategy to guide the population to search for a smaller feature subset with better classification performance. We have conducted extensive comparative experiments on AAMCSO and multiple state-of-the-art feature selection algorithms in high-dimensional feature selection problems with up to 10000 dimensions. The results show that AAMCSO achieves significantly superior performance to the state-of-the-art comparison algorithms in terms of both classification accuracy and feature number.},
  archive   = {C_GECCO},
  author    = {Zhang, Yong and Du, Ke-Jing and Jiang, Yi and Wang, Li-Min and Wang, Hua and Zhan, Zhi-Hui},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654021},
  pages     = {1515–1523},
  title     = {Adaptive aggregative multitask competitive particle swarm optimization with bi-directional asymmetric flip strategy for high-dimensional feature selection},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fine-grain knowledge transfer-based multitask particle swarm
optimization with dual clustering-based task generation for
high-dimensional feature selection. <em>GECCO</em>, 1506–1514. (<a
href="https://doi.org/10.1145/3638529.3654023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Evolutionary multitasking (EMT), as a very popular research topic in the evolutionary computation community, has been used to solve high-dimensional FS problems and has shown good performance recently. However, most of the existing EMT-based methods still have two drawbacks. First, they only consider using filter-based task generation strategies to retain highly relevant features for generating the additional tasks, whereas the redundancy between features is ignored. Second, they always consider a complete variable vector (e.g., global optimum or mean positional information of a population at current generation) as positive knowledge and transfer it, which greatly weakens the variety of transferred knowledge and increases the possibility of falling into local optimality. To deal with these two drawbacks, we propose a new EMT-assisted multitask particle swarm optimization (MPSO) algorithm with two innovations for high-dimensional FS. First, we propose a dual clustering-based task generation strategy to generate tasks by considering both feature relevance and redundancy. Second, we propose a fine-grain knowledge transfer strategy to realize explicit transfer of knowledge between different tasks. Experimental results on 15 public datasets show the effectiveness and competitiveness of our proposed MPSO algorithm over other state-of-the-art FS methods in dealing with high-dimensional FS problems.},
  archive   = {C_GECCO},
  author    = {Wang, Xin-Yu and Yang, Qi-Te and Jiang, Yi and Tan, Kay Chen and Zhang, Jun and Zhan, Zhi-Hui},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654023},
  pages     = {1506–1514},
  title     = {Fine-grain knowledge transfer-based multitask particle swarm optimization with dual clustering-based task generation for high-dimensional feature selection},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Auto-configuring exploration-exploitation tradeoff in
evolutionary computation via deep reinforcement learning.
<em>GECCO</em>, 1497–1505. (<a
href="https://doi.org/10.1145/3638529.3653996">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Evolutionary computation (EC) algorithms, renowned as powerful black-box optimizers, leverage a group of individuals to cooperatively search for the optimum. The exploration-exploitation tradeoff (EET) plays a crucial role in EC, which, however, has traditionally been governed by manually designed rules. In this paper, we propose a deep reinforcement learning-based framework that autonomously configures and adapts the EET throughout the EC search process. The framework allows different individuals of the population to selectively attend to the global and local exemplars based on the current search state, maximizing the cooperative search outcome. Our proposed framework is characterized by its simplicity, effectiveness, and generalizability, with the potential to enhance numerous existing EC algorithms. To validate its capabilities, we apply our framework to several representative EC algorithms and conduct extensive experiments on the augmented CEC2021 benchmark. The results demonstrate significant improvements in the performance of the backbone algorithms, as well as favorable generalization across diverse problem classes, dimensions, and population sizes. Additionally, we provide an in-depth analysis of the EET issue by interpreting the learned behaviors of EC.},
  archive   = {C_GECCO},
  author    = {Ma, Zeyuan and Chen, Jiacheng and Guo, Hongshu and Ma, Yining and Gong, Yue-Jiao},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3653996},
  pages     = {1497–1505},
  title     = {Auto-configuring exploration-exploitation tradeoff in evolutionary computation via deep reinforcement learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Markov chain-based optimization time analysis of bivalent
ant colony optimization for sorting and LeadingOnes. <em>GECCO</em>,
1488–1496. (<a href="https://doi.org/10.1145/3638529.3654022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {So far, only few bounds on the runtime behavior of Ant Colony Optimization (ACO) have been reported. To alleviate this situation, we investigate the ACO variant we call Bivalent ACO (BACO) that uses exactly two pheromone values. We provide and successfully apply a new Markov chain-based approach to calculate the expected optimization time, i. e., the expected number of iterations until the algorithm terminates. This approach allows to derive exact formul\ae{} for the expected optimization time for the problems Sorting and LeadingOnes. It turns out that the ratio of the two pheromone values significantly governs the runtime behavior of BACO. To the best of our knowledge, for the first time, we can present tight bounds for Sorting (Θ(n3)) with a specifically chosen objective function and prove the missing lower bound Ω(n2) for LeadingOnes which, thus, is tightly bounded by Θ(n2). We show that despite we have a drastically simplified ant algorithm with respect to the influence of the pheromones on the solving process, known bounds on the expected optimization time for the problems OneMax (O(n log n)) and LeadingOnes (O(n2)) can be re-produced as a by-product of our approach. Experiments validate our theoretical findings.},
  archive   = {C_GECCO},
  author    = {Kerga\ss{}ner, Matthias and Keszocze, Oliver and Wanka, Rolf},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654022},
  pages     = {1488–1496},
  title     = {Markov chain-based optimization time analysis of bivalent ant colony optimization for sorting and LeadingOnes},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Emergent behavior in evolutionary swarms for machine
olfaction. <em>GECCO</em>, 1479–1487. (<a
href="https://doi.org/10.1145/3638529.3653992">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Navigation via olfaction (scent) is one of the most primitive forms of exploration used by organisms. Machine olfaction is a growing field within sensing systems and AI and many of its use cases are motivated by swarm intelligence. With this work, we are specifically interested in demonstrating the collaborative ability that evolutionary optimization can enable in swarm navigation via machine olfaction. We designate each particle of the swarm as a reinforcement learning (RL) agent and show how agent rewards can be directly correlated to maximize the swarm&#39;s reward signal. In doing so, we show how different behaviors emerge within swarms depending on which RL algorithms are used. We are motivated by the application of machine olfaction and evaluate multiple swarm permutations against a suite of scent navigation tasks to demonstrate preferences exhibited by the swarm. Our results indicate that swarms can be designed to achieve desired behaviors as a function of the algorithm each agent demonstrates. This paper contributes to the field of cooperative co-evolutionary algorithms by proposing a method by which evolutionary techniques can significantly improve how swarms of simple agents collaborate to solve complex tasks faster than a single large agent can under identical conditions.},
  archive   = {C_GECCO},
  author    = {France, Kordel and Paul, Anirban and Banga, Ivneet and Prasad, Shalini},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3653992},
  pages     = {1479–1487},
  title     = {Emergent behavior in evolutionary swarms for machine olfaction},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A self-adaptive rotationally invariant particle swarm
optimization for global optimization. <em>GECCO</em>, 1470–1478. (<a
href="https://doi.org/10.1145/3638529.3654008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, the rotational invariance property has been introduced into the field of meta-heuristic algorithms, aiming to ensure consistent algorithm performance across arbitrarily rotated problems, thereby enhancing algorithmic universality. However, designing a practical rotationally invariant Particle Swarm Optimization (PSO) variant with superior performance across various optimization problems still remains a subject of in-depth research. In this paper, we propose a novel rotationally invariant PSO variant termed self-adaptive rotationally invariant PSO (sariPSO). Specifically, sariPSO incorporates a newly developed rotationally invariant solution updating equation, formulated using random vectors uniformly distributed within D-dimensional ellipsoids. Additionally, to further enhance the algorithm performance across various problems, sariPSO employs a self-adaptive approach to determine the axis length parameters of the ellipsoids, based on evaluation of performances of the solution updating equation under different axis length parameters in the last few iterations. Numerical experiments conducted on 10 well-known test problems demonstrate the rotational invariance property and superior performance of sariPSO compared to several existing PSO variants.},
  archive   = {C_GECCO},
  author    = {Dong, Ting and Wang, Haoxin and Ding, Wenbo and Shi, Libao},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654008},
  pages     = {1470–1478},
  title     = {A self-adaptive rotationally invariant particle swarm optimization for global optimization},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A differential pheromone grouping ant colony optimization
algorithm for the 1-d bin packing problem. <em>GECCO</em>, 1463–1469.
(<a href="https://doi.org/10.1145/3638529.3654074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The bin packing problem (BPP) is a well-researched and important NP-hard problem with many contemporary applications (e.g. stock cutting, machine scheduling), which requires a set of items with variable sizes to be packed into a set of fixed-capacity containers. Many metaheuristic approaches have been successfully trialled on this problem, including evolutionary algorithms, ant colony optimization and local search techniques. The most successful variants of these approaches use grouping techniques whereby the algorithm considers sets of items together rather than as separate decision variables. This paper presents an Ant Colony Optimization integrated with a grouping technique and a novel differential pheromone procedure for bin packing. The proposed differential pheromone grouping ACO shows state-of-the-art results for ACO approaches in BPP and approaches the performance of the best evolutionary methods.},
  archive   = {C_GECCO},
  author    = {Ali, Aseel Ismael and Keedwell, Edward and Helal, Ayah},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654074},
  pages     = {1463–1469},
  title     = {A differential pheromone grouping ant colony optimization algorithm for the 1-D bin packing problem},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The electric vehicle problem with road junctions and road
types: An ant colony optimization approach. <em>GECCO</em>, 1454–1462.
(<a href="https://doi.org/10.1145/3638529.3653997">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper presents a novel extension of the Electric Vehicle Routing Problem (EVRP) to better align with real-world logistics operations and urban environments. We incorporate additional nodes into the road network, representing road junctions. This is in contrast to traditionally considered road networks consisting merely of depots, charging stations, and customers. In addition, each edge of the road network has a specific road type, including highways, urban roads, and city streets. Each road type is characterized by a distinct speed limit. The objective function is designed around the energy consumption of vehicles, which varies based on load, speed, and distance traveled. This results in a more detailed and accurate modeling of the EVRP, making it more suitable for practical implementations. To solve the problem, we provide a construction heuristic based on the Clark and Wright Savings algorithm and an Ant Colony Optimization algorithm based on the MAX-MIN Ant System.},
  archive   = {C_GECCO},
  author    = {Akbay, Mehmet Anil and Blum, Christian and Saliba, Michella},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3653997},
  pages     = {1454–1462},
  title     = {The electric vehicle problem with road junctions and road types: An ant colony optimization approach},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Socialz: Multi-feature social fuzz testing. <em>GECCO</em>,
1445–1453. (<a href="https://doi.org/10.1145/3638529.3654033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Online social networks have become an integral aspect of our daily lives and play a crucial role in shaping our relationships with others. However, bugs and glitches, even minor ones, can cause anything from frustrating problems to serious data leaks that can have far-reaching impacts on millions of users.To mitigate these risks, fuzz testing, a method of testing with randomised inputs, can provide increased confidence in the correct functioning of a social network. However, implementing traditional fuzz testing methods can be prohibitively difficult or impractical for programmers outside of the social network&#39;s development team.To tackle this challenge, we present Socialz, a novel approach to social fuzz testing that (1) characterises real users of a social network, (2) diversifies their interaction using evolutionary computation across multiple, non-trivial features, and (3) collects performance data as these interactions are executed. With Socialz, we aim to put social testing tools in everybody&#39;s hands, thereby improving the reliability and security of social networks used worldwide.In our study, we came across (1) one known limitation of the current GitLab CE and (2) 6,907 errors, of which 40.16\% are beyond our debugging skills.},
  archive   = {C_GECCO},
  author    = {Zanartu, Francisco and Treude, Christoph and Wagner, Markus},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654033},
  pages     = {1445–1453},
  title     = {Socialz: Multi-feature social fuzz testing},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Search-based repair of DNN controllers of AI-enabled
cyber-physical systems guided by system-level specifications.
<em>GECCO</em>, 1435–1444. (<a
href="https://doi.org/10.1145/3638529.3654078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In AI-enabled CPSs, DNNs are used as controllers for the physical system. Despite their advantages, DNN controllers can produce wrong control decisions, which can lead to safety risks for the system. Once wrong behaviors are detected, the DNN controller should be fixed. DNN repair is a technique that allows to perform this fine-grained improvement. However, state-of-the-art DNN repair techniques require ground-truth labels to guide the repair. For AI-enabled CPSs, these are not available, as it is not possible to assess whether a specific control decision is correct. Nevertheless, it is possible to assess whether the DNN controller leads to wrong behaviors of the controlled system by considering system-level requirements. In this paper, following this observation, we propose a novel DNN repair approach that is guided by system-level specifications. The approach takes in input a system-level specification, some tests violating the specification, and some faulty DNN weights. The approach searches for alternative weight values with the goal of fixing the behavior on the failing tests without breaking the passing tests. We also propose a heuristic that allows us to accelerate the search by avoiding the execution of some tests. Experiments on real-world AI-enabled CPSs show that the approach effectively repairs their controllers.},
  archive   = {C_GECCO},
  author    = {Lyu, Deyun and Zhang, Zhenya and Arcaini, Paolo and Ishikawa, Fuyuki and Laurent, Thomas and Zhao, Jianjun},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654078},
  pages     = {1435–1444},
  title     = {Search-based repair of DNN controllers of AI-enabled cyber-physical systems guided by system-level specifications},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Search-based crash reproduction for android apps.
<em>GECCO</em>, 1426–1434. (<a
href="https://doi.org/10.1145/3638529.3654034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Android apps are known to be fragile: Users as well as automated test generators frequently encounter app crashes. An important prerequisite for fixing the underlying faults is to provide developers with automated tests to reliably reproduce such crashes. Unfortunately, often the only information available is the stack trace of the crash. While search-based test generation has been successfully used for finding tests that reproduce crashes from stack traces in other domains, such approaches are fundamentally limited in their applicability on Android apps. For example, even the basic search operator of crossover used in evolutionary algorithms is challenged since applicable inputs depend on the state of the app, such that sequences of inputs cannot be arbitrarily concatenated. To overcome this problem we use an estimation of distribution search algorithm, which guides the reproduction using a probabilistic model of relevant actions, requiring no complicated search operators. The probabilistic model is bootstrapped using established Android testing heuristics and crash-related information extracted from the stack trace and byte code, and is updated throughout the search using a fitness function based on stack traces. Evaluation on 30 real-world app crashes, of which 24 are successfully reproduced, demonstrates that the approach is effective, reliable and fast.},
  archive   = {C_GECCO},
  author    = {Auer, Michael and Diner, Dominik and Fraser, Gordon},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654034},
  pages     = {1426–1434},
  title     = {Search-based crash reproduction for android apps},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evolving molecular graph neural networks with hierarchical
evaluation strategy. <em>GECCO</em>, 1417–1425. (<a
href="https://doi.org/10.1145/3638529.3654055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph representation of molecular data enables extracting stereoscopic features, with graph neural networks (GNNs) excelling in molecular property prediction. However, selecting optimal hyper-parameters for GNN construction is challenging due to the vast search space and high computational costs. To tackle this, we introduce a hierarchical evaluation strategy integrated with a genetic algorithm (HESGA). HESGA combines full and fast evaluations of GNNs. Full evaluation involves training a GNN with preset epochs, using root mean square error (RMSE) to measure hyperparameter quality. Fast evaluation interrupts training early, using the difference in RMSE values as a score for GNN potential. HESGA integrates these evaluations, with fast evaluation guiding candidate selection for full evaluation, maintaining elite individuals. Applying HESGA to optimise deep GNNs for molecular property prediction, experimental results on three datasets demonstrate its superiority over traditional Bayesian optimisation, Tree-structured Parzen Estimator, and CMA-ES. HESGA efficiently navigates the complex GNN hyperparameter space, offering a promising approach for molecular property prediction.},
  archive   = {C_GECCO},
  author    = {Yuan, Yingfang and Wang, Wenjun and Li, Xin and Chen, Kefan and Zhang, Yonghan and Pang, Wei},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654055},
  pages     = {1417–1425},
  title     = {Evolving molecular graph neural networks with hierarchical evaluation strategy},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Genetic programming empowered feature construction towards
energy efficient BVI wearables. <em>GECCO</em>, 1408–1416. (<a
href="https://doi.org/10.1145/3638529.3654002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Blind and visually impaired (BVI) individuals face serious mobility-related risks daily due to the lack of progression in hazard detection and assistive technologies. Most existing techniques are demanding in computational resources and energy consumption, yet still struggle in real-time performance. The challenge is particularly evident when deploying these techniques on portable devices, on which lightweight coupled with sustainable low battery usage is a must. Hence in this study, we aim to leverage Genetic Programming (GP), which is well known for its feature construction capability, to develop more energy-efficient models with better features. The objective is to find more condensed features by GP, to reduce energy consumed and inference time, but without significant accuracy loss in obstacle detection from a head-mount wearable device for BVIs. Features have been trained on a series of in-door settings that represent a BVI person navigating through corridors and furniture. Models with these constructed features then are validated on actual portable board deployment, as well as on Field Programmable Gate Array simulation (FPGA). Comparative analyses are conducted using a range of performance metrics across models training by different learning methods. The metrics include accuracy, model execution time, prediction time, energy consumption, and hardware resource utilization. Our study demonstrates that GP-constructed models can generally reduce energy consumption and inference time with negligible accuracy loss. Furthermore, it can build models with higher accuracy than the benchmark, allowing users to adjust between energy usage and accuracy according to their needs.},
  archive   = {C_GECCO},
  author    = {Xu, Peijie and Song, Andy and Wang, Ke},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654002},
  pages     = {1408–1416},
  title     = {Genetic programming empowered feature construction towards energy efficient BVI wearables},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Differential evolution based on light-weight-surrogate for
solving high-dimensional energy management problem. <em>GECCO</em>,
1399–1407. (<a href="https://doi.org/10.1145/3638529.3654130">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In modern power engineering, given the high penetration of distributed energy resources, a risk-based and day-ahead management problem can often be formulated as a high-dimensional problem. In addition, the mathematical mapping from the input control vector to the quantiles of the system output becomes too complex due to the nested relationship between the different systems. Hence, this type of problem is often approached as a black box model, i.e., the decision maker can only observe the input and output ends. However, as a practical engineering problem, it often requires the corresponding optimization in limited time or evaluations, which poses a challenge to conventional differential evolution algorithms. This paper proposes a novel differential evolution algorithm with a compatible surrogate operator that provides dynamic rational exploration during the iterations to achieve reliable performance in limited time and space complexity. The surrogate also facilitates faster exploration of the optimal solution region compared with the state-of-the-art under the same configurations and conditions. A GECCO competition testbed is utilized to evaluate the performance, where the simulation results demonstrate that the proposed algorithm is more effective than most DE, PSO (and their typical variants).},
  archive   = {C_GECCO},
  author    = {Xiao, Chixin and He, Maoxin and Jiang, Dechen and Zhang, Yiwei and Tang, Yuxin and Ling, Zhenyu},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654130},
  pages     = {1399–1407},
  title     = {Differential evolution based on light-weight-surrogate for solving high-dimensional energy management problem},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mixed-variable correlation-aware metaheuristic for
deployment optimization of 3-d sensor networks. <em>GECCO</em>,
1390–1398. (<a href="https://doi.org/10.1145/3638529.3654040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deployment optimization of 3-D sensor networks is essential for the overall cost of the system and the downstream tasks performance. The key of establishing realistic deployment is twofold: a high-fidelity mathematical programming model and an efficient algorithm for solving it. In this paper, we revisit the 3-D sensor networks deployment and present a mixed-variable optimization problem (MVOP) which jointly considers the discrete subset selection decision, continuous orientation decision, and decisionmaking under uncertainty. Based on the proposed real-world application, we innovatively design a mixed-variable correlation-aware genetic algorithm as the solver. Different from mainstream two-partition methods in MVOP, our algorithm captures the problem-specific features of deployment optimization and introduces a correlation-aware search paradigm which interactively updates the discrete and continuous decision variables. On the one hand, we update the discrete part (i.e., subset selection of candidate locations) first and then optimize the continuous part (i.e., sensor orientation parameters). On the other hand, we customize a heuristic mechanism to start with continuous part to identify the suitable discrete part. Experiments demonstrate that our approach can improve the performance of small-scale and large-scale scenarios of deployment by up to 55.7\% and 56.4\%, respectively, compared to state-of-the-art MVOP algorithms.},
  archive   = {C_GECCO},
  author    = {Wu, Tongyu and Zhang, Yuntian and Miao, Changhao and Chen, Chen and Ding, Shuxin},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654040},
  pages     = {1390–1398},
  title     = {Mixed-variable correlation-aware metaheuristic for deployment optimization of 3-D sensor networks},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The lunar lander landing site selection benchmark
reexamined: Problem characterization and algorithm performance.
<em>GECCO</em>, 1381–1389. (<a
href="https://doi.org/10.1145/3638529.3654229">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The benchmark problem of lunar lander landing site selection is a nonlinear constrained optimization problem introduced as a challenge for the 2018 Evolutionary Computation Symposium competition. In the single-objective variant, the task is to find the latitude and the longitude of the landing site maximizing the total communication time with Earth, and satisfying constraints for consecutive shade days and the landing site inclination angle. The requirements of the multiobjective variant are to maximize the total communication time, and minimize the consecutive shade days and the landing site inclination angle, while satisfying the constraints for the latter two objectives. We reexamine the problem by first characterizing it by means of problem landscape analysis, then performing a comparative study of algorithm performance, and finally relating the results of the two phases. The characterization relies on both the features known from the literature and the recently constructed ones for analyzing constrained and multiobjective problem landscapes, while the algorithmic study includes several single- and multiobjective evolutionary algorithms. The findings are insightful and allow for a better understanding of both the problem and the optimization algorithm behavior. They help identify appropriate algorithms for landing site selection and are advantageous for solving comparable problem instances.},
  archive   = {C_GECCO},
  author    = {Vodopija, Aljo\v{s}a and Cork, Jordan N. and Filipi\v{c}, Bogdan},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654229},
  pages     = {1381–1389},
  title     = {The lunar lander landing site selection benchmark reexamined: Problem characterization and algorithm performance},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the performance of user association in space-ground
communications with integer-coded genetic algorithms. <em>GECCO</em>,
1373–1380. (<a href="https://doi.org/10.1145/3638529.3654083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper considers fairness designs under the user-centric framework with heterogeneous receivers comprising access points (APs) and a satellite. We exploit the closed-form ergodic throughput per user to formulate a generic optimization class that addresses the network fairness subject to the association patterns of all the users. Exhibiting the combinatorial structure, the global optimal solution to the association patterns can be obtained by an exhaustive search for small-scale networks with a small number of APs and users. For large-scale networks, we design two low computational complexity algorithms based on evolutionary computation to obtain a good solution in polynomial time. Specifically, we adapt the genetic algorithm (GA) to handle the discrete feasible region and the fairness metrics. Numerical results demonstrate that the optimized association patterns significantly improve the per-user throughput. The proposed GA-based algorithms yield the global optimum for small-scale networks coincided with an exhaustive search. Besides, the GA-based algorithms unveil practical association patterns for large-scale networks.},
  archive   = {C_GECCO},
  author    = {Van Chien, Trinh and Thu, Ngo Tran Anh and Nguyen, Lam and Binh, Nguyen and Binh, Huynh},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654083},
  pages     = {1373–1380},
  title     = {On the performance of user association in space-ground communications with integer-coded genetic algorithms},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Feature extraction with automated scale selection in skin
cancer image classification: A genetic programming approach.
<em>GECCO</em>, 1363–1372. (<a
href="https://doi.org/10.1145/3638529.3654071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Early detection of cancer is vital for reducing mortality rates, but medical images come in various resolutions, often captured from diverse devices, and pose challenges due to high inter-class and intra-class variability. Integrating various feature descriptors enhances high-level feature extraction for improved classification. Having varied structure sizes of tumor characteristics in these medical images, extracting features from a single scale might not provide meaningful or discriminative features. Genetic Programming (GP) proves effective in this context due to its flexible representation and global search capabilities. Unlike existing GP methods relying on extracting features from a single scale of the input image, this paper introduces a novel GP-based feature learning approach that automatically selects scales and combines image descriptors for skin cancer detection. The method learns global features from diverse scales, leading to improved classification performance on dermoscopic and standard camera image datasets. The evolved solutions not only enhance classification but also pinpoint the most effective scales and feature descriptors for different skin cancer image datasets. The proposed method generates interpretable models, aiding medical practitioners in diagnoses by identifying cancer characteristics captured through automatically selected feature descriptors in the evolutionary process.},
  archive   = {C_GECCO},
  author    = {Ul Ain, Qurrat and Al-Sahaf, Harith and Xue, Bing and Zhang, Mengjie},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654071},
  pages     = {1363–1372},
  title     = {Feature extraction with automated scale selection in skin cancer image classification: A genetic programming approach},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Function class learning with genetic programming: Towards
explainable meta learning for tumor growth functionals. <em>GECCO</em>,
1354–1362. (<a href="https://doi.org/10.1145/3638529.3654145">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Paragangliomas are rare, primarily slow-growing tumors for which the underlying growth pattern is unknown. Therefore, determining the best care for a patient is hard. Currently, if no significant tumor growth is observed, treatment is often delayed, as treatment itself is not without risk. However, by doing so, the risk of (irreversible) adverse effects due to tumor growth may increase. Being able to predict the growth accurately could assist in determining whether a patient will need treatment during their lifetime and, if so, the timing of this treatment. The aim of this work is to learn the general underlying growth pattern of paragangliomas from multiple tumor growth data sets, in which each data set contains a tumor&#39;s volume over time. To do so, we propose a novel approach based on genetic programming to learn a function class, i.e., a parameterized function that can be fit anew for each tumor. We do so in a unique, multi-modal, multi-objective fashion to find multiple potentially interesting function classes in a single run. We evaluate our approach on a synthetic and a real-world data set. By analyzing the resulting function classes, we can effectively explain the general patterns in the data.},
  archive   = {C_GECCO},
  author    = {Sijben, Evi and Jansen, Jeroen and Bosman, Peter and Alderliesten, Tanja},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654145},
  pages     = {1354–1362},
  title     = {Function class learning with genetic programming: Towards explainable meta learning for tumor growth functionals},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploring the prompt space of large language models through
evolutionary sampling. <em>GECCO</em>, 1345–1353. (<a
href="https://doi.org/10.1145/3638529.3654049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Large language models (LLMs) are increasingly gaining relevance in every-day life, due to their apparent ability in solving tasks that demand intricate linguistic comprehension. Recent studies state that one of the key points that impact their outcome is the quality of the prompt used to interact with them. This work proposes a grammar-based evolutionary approach for exploring the prompt space of LLMs, driven by a fitness function that aims at optimizing the performance on a given task. We tested our technique by steering two state-of-the-art models through evolved prompts, and by comparing the performance they obtain on 8 benchmark tasks with that obtained when using other baseline prompts on the same tasks, showing that in most cases our prompts yield better results. Further, we defined a constrained mutation operator that limits the changes to specific grammar non-terminals, allowing to study and highlight the elements in the prompt that mostly affect the output of the LLM. Finally, a thorough discussion points out some issues that limit the relevance of the emerging prompt engineering discipline, given the existence of many effective prompt structures and the possible diversity that can be observed in the LLM output given the same input to the model.},
  archive   = {C_GECCO},
  author    = {Saletta, Martina and Ferretti, Claudio},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654049},
  pages     = {1345–1353},
  title     = {Exploring the prompt space of large language models through evolutionary sampling},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Redesigning road infrastructure to integrate e-scooter
micromobility as part of multimodal transportation. <em>GECCO</em>,
1336–1344. (<a href="https://doi.org/10.1145/3638529.3654142">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper proposes a multi-criteria approach to optimize urban infrastructure for e-scooters mobility. The problem considers redesigning road infrastructure to integrate e-scooters into a city&#39;s multimodal transportation system. This research aims to improve cycle lane coverage and connectivity for e-scooters while minimizing installation costs. Two parallel multi-objective evolutionary algorithms are devised to solve this problem in a real-world instance based on M\&#39;{a}laga. The results showed that the algorithms effectively explored the Pareto front, offering diverse trade-off solutions. Key solutions are analyzed to evaluate the trade-offs between travel time improvement, cycle lane connectivity, multimodality, and installation costs. Visualization of proposed infrastructure changes illustrates significant reductions in travel time.},
  archive   = {C_GECCO},
  author    = {Pedroza-Perez, Diego and Toutouh, Jamal and Luque, Gabriel},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654142},
  pages     = {1336–1344},
  title     = {Redesigning road infrastructure to integrate e-scooter micromobility as part of multimodal transportation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cost and performance comparison of holistic solution
approaches for complex supply chains on a novel linked problem
benchmark. <em>GECCO</em>, 1327–1335. (<a
href="https://doi.org/10.1145/3638529.3654163">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Modern supply chains are complex structures of interacting units exchanging goods and services. Business decisions made by individual units in the supply chain have knock-on effects on decisions made by successor units in the chain. Linked Optimisation Problems are an abstraction of real-world supply chains and are defined as a directed network where each node is a formally defined optimisation problem, and each link indicates dependencies. The development of approaches to holistically solve linked optimisation problems is of high significance to decarbonisation as well as building robust industrial supply chains resilient to economic shock and climate change. This paper develops a novel linked problem benchmark (IWSP-VAP-MTSP) integrating Inventory Warehouse Selection Problem, Vehicle Assignment Problem and Multiple Traveling Salesmen Problem. The linked problem represents tactical and operational supply chain decision problems that arise in inventory location and routing. We consider three algorithmic approaches, Sequential, Nondominated Sorting Genetic Algorithm for Linked Problem (NSGALP) and Multi-Criteria Ranking Genetic Algorithm for Linked Problem (MCRGALP). We generated 960 randomised instances of IWSP-VAP-MTSP and statistically compared the performance of the proposed holistic approaches. Results show that MCRGALP outperforms the other two approaches based on the performance metrics used, however, at the expense of greater computational time.},
  archive   = {C_GECCO},
  author    = {Ogunsemi, Akinola and McCall, John and Zavoianu, Ciprian and Christie, Lee A.},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654163},
  pages     = {1327–1335},
  title     = {Cost and performance comparison of holistic solution approaches for complex supply chains on a novel linked problem benchmark},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Quality diversity approaches for time-use optimisation to
improve health outcomes. <em>GECCO</em>, 1318–1326. (<a
href="https://doi.org/10.1145/3638529.3654085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {How people spend their finite time budget of 24 hours on daily activities is linked to their wellbeing. Yet, how to best allocate time to optimise multi-dimensional wellbeing (physical, mental and cognitive) remains unknown. Here, we utilise a number of (objective) functions derived using compositional data analysis and a large child cohort (n &amp;gt; 1000), to predict how time allocation is associated with wellbeing outcomes such as body mass index, life satisfaction, and cognition. We develop and advocate joint cumulative distribution function constraints to ensure the feasible solutions do not extrapolate the sampled data for which the objective function is derived from. Moreover, we incorporate quality diversity (QD) approaches to study these objective functions. We define two types of behavioural spaces (BSs), one based on the activities, called the variable-based BS, and the other based on objectives. The variable-based BS aids in studying solution space and generating a set of high-quality solutions with different variable values, while the objective-based BS is beneficial in diversifying the objective values for a number of objective functions while optimising another. We also demonstrate a web application, Time allocation optimiser, providing personalised, optimised time-use plans.},
  archive   = {C_GECCO},
  author    = {Nikfarjam, Adel and Stanford, Ty and Neumann, Aneta and Dumuid, Dorothea and Neumann, Frank},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654085},
  pages     = {1318–1326},
  title     = {Quality diversity approaches for time-use optimisation to improve health outcomes},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimizing cyber response time on temporal active directory
networks using decoys. <em>GECCO</em>, 1309–1317. (<a
href="https://doi.org/10.1145/3638529.3654035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Microsoft Active Directory (AD) is the default security management system for Window domain network. We study the problem of placing decoys in AD network to detect potential attacks. We model the problem as a Stackelberg game between an attacker and a defender on AD attack graphs where the defender employs a set of decoys to detect the attacker on their way to Domain Admin (DA). Contrary to previous works, we consider time-varying (temporal) attack graphs. We proposed a novel metric called response time, to measure the effectiveness of our decoy placement in temporal attack graphs. Response time is defined as the duration from the moment attackers trigger the first decoy to when they compromise the DA. Our goal is to maximize the defender&#39;s response time to the worst-case attack paths. We establish the NP-hard nature of the defender&#39;s optimization problem, leading us to develop Evolutionary Diversity Optimization (EDO) algorithms. EDO algorithms identify diverse sets of high-quality solutions for the optimization problem. Despite the polynomial nature of the fitness function, it proves experimentally slow for larger graphs. To enhance scalability, we proposed an algorithm that exploits the static nature of AD infrastructure in the temporal setting. Then, we introduce problem-tailored repair operations, ensuring the convergence to better results while maintaining scalability for larger graphs.},
  archive   = {C_GECCO},
  author    = {Ngo, Huy and Guo, Mingyu and Nguyen, Hung},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654035},
  pages     = {1309–1317},
  title     = {Optimizing cyber response time on temporal active directory networks using decoys},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A satellite band selection framework for amazon forest
deforestation detection task. <em>GECCO</em>, 1300–1308. (<a
href="https://doi.org/10.1145/3638529.3654000">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The conservation of tropical forests is a topic of significant social and ecological relevance due to their crucial role in the global ecosystem. Unfortunately, deforestation and degradation impact millions of hectares annually, necessitating government or private initiatives for effective forest monitoring. This study introduces a novel framework that employs the Univariate Marginal Distribution Algorithm (UMDA) to select spectral bands from Landsat-8 satellite optical sensor, optimizing the representation of deforested areas. This selection guides a semantic segmentation architecture, DeepLabv3+, enhancing its performance. Experimental results revealed several band compositions that achieved superior balanced accuracy compared to commonly adopted combinations for deforestation detection, utilizing segment classification via a Support Vector Machine (SVM). Moreover, the optimal band compositions identified by the UMDA-based approach improved the performance of the DeepLabv3+ architecture, surpassing state-of-the-art approaches compared in this study. The observation that a few selected bands outperform the total contradicts the data-driven paradigm prevalent in the deep learning field. Therefore, this suggests an exception to the conventional wisdom that &#39;more is always better&#39;.},
  archive   = {C_GECCO},
  author    = {Neto, Eduardo Bouhid and Faria, Fabio Augusto and De Oliveira, Amanda de Almeida Sales and Fazenda, Alvaro Luiz},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654000},
  pages     = {1300–1308},
  title     = {A satellite band selection framework for amazon forest deforestation detection task},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Interactive evolutionary multiobjective optimization of
primer design with uncertain objectives. <em>GECCO</em>, 1291–1299. (<a
href="https://doi.org/10.1145/3638529.3654167">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The choice of primer designs for polymerase chain reaction experiments affects the results. Designing optimal combinations of forward and reverse primers requires solving multiple conflicting objectives simultaneously. Most of the tools for primer design optimize the problem by a priori scalarization or by setting constraints with preset preferences. Therefore, the decision-maker (DM) or domain expert has to re-execute the optimizer with new preferences to find satisfactory solutions. An a priori method is detrimental to decision-making since the DM cannot learn about the problem characteristics, and re-executing the optimizer with new preferences increases the number of function evaluations. In addition, the existing methods rely on a single mathematical model to estimate the melting temperature of primers. In this paper, we formulate a multiobjective optimization problem consisting of three uncertain objectives that use six different models to estimate the melting temperatures of primers. The formulated problem was solved using an interactive multiobjective evolutionary algorithm that enabled the DM to guide the solution process. We also proposed a selection criterion tailored to our problem that could find optimal primer designs according to the DM&#39;s preferences. Finally, we demonstrate the proposed interactive approach to find optimal primers for a bacterial 16S DNA sequence.},
  archive   = {C_GECCO},
  author    = {Mazumdar, Atanu and Jain, Bhavya and Mitra, Monisha and Dhar, Prodyut},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654167},
  pages     = {1291–1299},
  title     = {Interactive evolutionary multiobjective optimization of primer design with uncertain objectives},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Genetic algorithm selection of interacting features (GASIF)
for selecting biological gene-gene interactions. <em>GECCO</em>,
1282–1290. (<a href="https://doi.org/10.1145/3638529.3654159">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Feature interactions are particularly useful in modeling biological effects, such as gene-gene interactions, but are difficult to model due to the exponential increase in the feature space. We present GASIF, a Genetic Algorithm that selects features and their interactions for the purposes of solving a supervised classification problem, designed for the identification of gene-gene interactions. GASIF works by constructing individuals with a collection of chromosomes that represent a subset of features and their interactions. It then determines individual fitness as a combination of the number of unique features used and the cross-validation performance of a logistic regression classifier trained on that feature subset with an ElasticNet penalty. A variety of intuitive operations are used to select, mate, and mutate individuals from generation to generation to limit the search space of features and interactions. We evaluate this Genetic Algorithm on a real-world dataset of human brain transcriptomic data from neuropathologically normal postmortem samples and pathologically confirmed late-onset Alzheimer&#39;s disease individuals and determine the face validity of the gene-gene interactions that it identifies. Across multiple iterations of GASIF, we consistently identified the same features and interactions as most informative, all of which relate to genes known to be implicated in Alzheimer&#39;s disease.},
  archive   = {C_GECCO},
  author    = {Kumar, Rachit and Zhang, David and Ritchie, Marylyn DeRiggi},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654159},
  pages     = {1282–1290},
  title     = {Genetic algorithm selection of interacting features (GASIF) for selecting biological gene-gene interactions},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-objective quality-diversity for crystal structure
prediction. <em>GECCO</em>, 1273–1281. (<a
href="https://doi.org/10.1145/3638529.3654048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Crystal structures are indispensable across various domains, from batteries to solar cells, and extensive research has been dedicated to predicting their properties based on their atomic configurations. However, prevailing Crystal Structure Prediction methods focus on identifying the most stable solutions that lie at the global minimum of the energy function. This approach overlooks other potentially interesting materials that lie in neighbouring local minima and have different material properties such as conductivity or resistance to deformation. By contrast, Quality-Diversity algorithms provide a promising avenue for Crystal Structure Prediction as they aim to find a collection of high-performing solutions that have diverse characteristics. However, it may also be valuable to optimise for the stability of crystal structures alongside other objectives such as magnetism or thermoelectric efficiency. Therefore, in this work, we harness the power of Multi-Objective Quality-Diversity algorithms in order to find crystal structures which have diverse features and achieve different trade-offs of objectives. We analyse our approach on 5 crystal systems and demonstrate that it is not only able to re-discover known real-life structures, but also find promising new ones. Moreover, we propose a method for illuminating the objective space to gain an understanding of what trade-offs can be achieved.},
  archive   = {C_GECCO},
  author    = {Janmohamed, Hannah and Wolinska, Marta and Surana, Shikha and Pierrot, Thomas and Walsh, Aron and Cully, Antoine},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654048},
  pages     = {1273–1281},
  title     = {Multi-objective quality-diversity for crystal structure prediction},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Genetic meta cipher. <em>GECCO</em>, 1264–1272. (<a
href="https://doi.org/10.1145/3638529.3654018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present a concrete application of genetic algorithm in the field of cryptography. More precisely, we provide a new and original cryptographic symmetric encryption scheme called Genetic Meta Cipher (GMC) using the non-dominated sorting-based multiobjective genetic algorithm, NSGA-II. The originality of GMC is that it is a keyless encryption meta-program i.e. a program capable of producing encryption algorithms from modular operations (bitwise primitives) with configurable options. Compared with the randomness test methods for binary sequence of the Standardization Administration of China (SAC), the ciphering result obtained with the encryption algorithms generated by GMC is equivalent in terms of randomness to that obtained with AES protocol (using a random set of keys). Another feature of GMC is that, instead of renewing a single encryption key as with known symmetric algorithms, an entire encryption algorithm is renewed, making its cryptanalysis more complex. GMC therefore appears to be an effective and promising cryptographic response to privacy and security issues, with a new way of thinking about encryption and a wider use of genetic algorithms in cryptography.},
  archive   = {C_GECCO},
  author    = {Hufschmitt, Aline and Parraud, Patrice},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654018},
  pages     = {1264–1272},
  title     = {Genetic meta cipher},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A systematic exploration of evolutionary computation for the
design of hardware-oriented non-cryptographic hash functions.
<em>GECCO</em>, 1255–1263. (<a
href="https://doi.org/10.1145/3638529.3654009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Non-cryptographic (NC) hash functions are crucial in high-speed search applications and probabilistic data structures (PDS) such as Bloom filters and Count-Min sketches for efficient lookups and counting. These operations necessitate execution at line rates to accommodate the high-speed demands of Terabit Ethernet networks, characterized by bandwidths exceeding 100 Gbps. Consequently, a growing inclination towards hardware platforms, particularly Field Programmable Gate Arrays (FPGAs), is evident in network security applications. Given the centrality of hash functions in these structures, any enhancements to their design carry substantial implications for overall system performance. However, hash functions must exhibit independence, uniform distribution, and hardware-friendly characteristics. In this work, we employ Genetic Programming (GP) with avalanche metrics as a fitness function to devise a hardware-friendly family of NC hash functions called the Evolutionary hash (E-hash). We provide a detailed experimental analysis to offer insights on primitive set combinations involving logical operations and diverse hyperparameter settings, encompassing variables such as the number of nodes, tree height, population size, crossover and mutation rate, tournament size, number of constants, and generations. Compared to existing state-of-the-art hardware-friendly hash functions, the proposed E-hash family exhibits an 8.4\% improvement in terms of operating frequency and throughput and 7.74\% in latency on FPGA.},
  archive   = {C_GECCO},
  author    = {Hassan, Mujtaba and Vliegen, Jo and Picek, Stjepan and Mentens, Nele},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654009},
  pages     = {1255–1263},
  title     = {A systematic exploration of evolutionary computation for the design of hardware-oriented non-cryptographic hash functions},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Using genetic algorithms for privacy-preserving optimization
of multi-objective assignment problems in time-critical settings: An
application in air traffic flow management. <em>GECCO</em>, 1246–1254.
(<a href="https://doi.org/10.1145/3638529.3654128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In air traffic flow management (ATFM), temporarily reduced capacity in the European air traffic network leads to the Network Manager imposing a regulation, meaning that flights are assigned new arrival times on a first-planned, first-served basis. Some flights, however, are more important for airlines and the airport than others due to various reasons, e.g., different numbers of affected passengers across flights. Therefore, optimization of the assignment of flights to available arrival times based on airline and airport preferences has the potential to considerably improve overall efficiency. In the ATFM setting, with its multiple, often competing stakeholders, the inputs for the optimization, e.g., costs of delay, are sensitive information, which must be protected. Furthermore, solutions must be found within the available time frame, which for the flight prioritization problem in ATFM is only in the order of minutes. The privacy-preserving implementation of multi-objective optimization algorithms has considerable computational overhead, which may lead to the optimization not finishing within the deadline. To alleviate this problem, we propose the separation of the search for solutions and the evaluation of the solutions, with only the evaluation requiring a privacy-preserving implementation. Our experimental results suggest good convergence under limited time while protecting sensitive inputs.},
  archive   = {C_GECCO},
  author    = {Gruber, Sebastian and Feichtenschlager, Paul and Schuetz, Christoph G.},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654128},
  pages     = {1246–1254},
  title     = {Using genetic algorithms for privacy-preserving optimization of multi-objective assignment problems in time-critical settings: An application in air traffic flow management},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evolutionary diversity optimisation for sparse directed
communication networks. <em>GECCO</em>, 1237–1245. (<a
href="https://doi.org/10.1145/3638529.3654184">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This study proposes Evolutionary Diversity Optimisation (EDO) to Lower the Probability of Detection (LPD) in directed wireless networks. LPD communication aims to communicate between authorised parties, however minimises the probability that an intruder can detect the communication. We represent the problem as a directed graph and our objective is to minimise the area of detectability in a network whilst avoiding adversary nodes to be in the area. We utilise EDO to produce a population of solutions that are of quality i.e., that minimise the area of detectability whilst providing solutions that are diverse. To produce a solution, we find the strongly connected components by running depth-first-search (DFS) twice and extracting the edges traversed from the DFS runs. We use 3 permutation operators (insert, swap, random) to produce different solutions. We propose 2 methods for survival selection - one based on the diversity value and the other on the edge population count. We control the sparsity of the directed graphs by implementing a maximal communication range. Our results show that sparser graphs had smaller areas of detectability, however the final population was less diverse. We also found controlling the maximal communication range an effective strategy to reduce the area of detectability.},
  archive   = {C_GECCO},
  author    = {Gounder, Sharlotte and Neumann, Frank and Neumann, Aneta},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654184},
  pages     = {1237–1245},
  title     = {Evolutionary diversity optimisation for sparse directed communication networks},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Creating ensembles of classifiers through UMDA for aerial
scene classification. <em>GECCO</em>, 1228–1236. (<a
href="https://doi.org/10.1145/3638529.3653998">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Aerial scene classification in remote sensing presents a significant challenge due to high intra-class variability and the different scales and orientations of the objects within dataset images. While deep learning architectures are commonly used for scene classification tasks and in the remote sensing area, Deep metric learning (DML) offers a more adaptable solution for more challenging classification scenarios by learning the characteristics of each class. This study exploits the usage of DML approaches for aerial scene classification tasks, analyzing their behavior with different pre-trained Convolutional Neural Networks (CNNs), and their combination through evolutionary computation algorithms. Our experiments show that DML approaches can achieve better classification results as compared to traditional pre-trained CNNs for three well-known remote sensing aerial scene datasets. Furthermore, we found that using the Univariate Marginal Distribution Algorithm (UMDA) to construct the final ensemble of varied DML-based classifiers is essential for achieving consistency and high-accuracy results across all datasets, improving the state-of-the-art by over 5.6\%.},
  archive   = {C_GECCO},
  author    = {Faria, Fabio Augusto and Buris, Luiz Henrique and Pereira, Luis Augusto Martins and Cappabianco, Fabio Augusto Menocci},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3653998},
  pages     = {1228–1236},
  title     = {Creating ensembles of classifiers through UMDA for aerial scene classification},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Energy-aware dynamic resource allocation and container
migration in cloud servers: A co-evolution GPHH approach.
<em>GECCO</em>, 1219–1227. (<a
href="https://doi.org/10.1145/3638529.3654070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Containers are a popular way of deploying software in cloud data centers. Containers are allocated to Virtual machines (VMs) which are allocated to Physical machines (PMs) within the data center. Since the resources required by containers often do not match those of VMs, where to allocate them must be decided. A poor solution can result in high energy costs. Many existing methods to solve this problem use heuristics which do not consider containers leaving the data center after being allocated. Some do consider migrating containers between VMs but few do for energy efficiency reasons. These overlooked aspects may lead to increased energy usage, particularly since studies have demonstrated that many containers run for only a brief duration. In this paper, we develop a model of the container-based cloud resource allocation problem that considers the energy impact of leaving and migrating containers. We then design a new Genetic Programming Hyper-Heuristic (GPHH) algorithm to jointly evolve three heuristics for container placement, VM placement and container migration control. We utilize newly designed terminals to ensure the effectiveness of our GPHH algorithm. Experiments have been conducted with results indicating that the heuristics evolved by our GPHH algorithm can achieve better performance compared to several state-of-the-art techniques.},
  archive   = {C_GECCO},
  author    = {Falloon, Mathew and Ma, Hui and Chen, Aaron},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654070},
  pages     = {1219–1227},
  title     = {Energy-aware dynamic resource allocation and container migration in cloud servers: A co-evolution GPHH approach},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). 2-step evolutionary algorithm for the generation of dungeons
with lock door missions using horizontal symmetry. <em>GECCO</em>,
1210–1218. (<a href="https://doi.org/10.1145/3638529.3654153">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper introduces a novel two-step evolutionary algorithm (2-Step EA) for the procedural generation of dungeons in video games. Our approach is designed to address the complex challenge of generating dungeons that are not only structurally coherent and navigable with strategically placed keys and barriers. The algorithm divides the dungeon generation process in two phases: the initial phase focuses on the formation of dungeon layout considering room quantity and linear coefficient and the second phase deals with the allocation of keys and barriers within this structure.We compare our algorithm with existing methods, emphasizing efficiency and adherence to specified dungeon parameters. Our results show the effectiveness of the 2-Step EA in generating diverse and engaging dungeons. This research contributes to the field of procedural content generation in games, offering insights into the optimization of dungeon generation algorithms.},
  archive   = {C_GECCO},
  author    = {Dumont, Felipe and Riff, Mar\&#39;{\i}a-Cristina},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654153},
  pages     = {1210–1218},
  title     = {2-step evolutionary algorithm for the generation of dungeons with lock door missions using horizontal symmetry},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimizing a car patrolling application by iterated local
search. <em>GECCO</em>, 1201–1209. (<a
href="https://doi.org/10.1145/3638529.3654080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We address a car patrolling application arising in a service company that needs to visit customers in a large area periodically. Customers are divided into clusters, each of which is assigned to a single patrol and requires different services, either mandatory or optional, on a weekly basis. The services have to be performed by satisfying several operational constraints, including interdependent time windows and maximum route duration. The aim is to maximize a weighted function that combines the profit collected from the optional services and the total working time required to perform all routes. The resulting optimization problem can be represented as a territory design and multi-period team orienteering problem. We solve the problem using an Iterated Local Search that invokes several inner procedures, including dedicated heuristics for creating the initial clusters, perturbation operators to diversify the search, and a variable neighborhood descent to search for good-quality routes. Extensive computational tests on a set of real-world instances involving up to a few hundred customers and a few thousand services prove the algorithm efficiency.},
  archive   = {C_GECCO},
  author    = {Corr\^{e}a, Victor Hugo Vidigal and Alves de Queiroz, Thiago and Iori, Manuel and Dos Santos, Andr\&#39;{e} Gustavo and Yagiura, Mutsunory and Zucchi, Giorgio},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654080},
  pages     = {1201–1209},
  title     = {Optimizing a car patrolling application by iterated local search},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimizing electric vehicle charging station placement
integrating daily mobility patterns and residential locations.
<em>GECCO</em>, 1192–1200. (<a
href="https://doi.org/10.1145/3638529.3654141">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Electric vehicles (EVs) are establishing themselves as the mobility of the future. However, it requires an infrastructure, i.e., charging stations, still needs to adapt to the growing demand. This article presents a multi-objective approach to placing EV charging stations (EVCS) in urban areas. Our study takes into account both the quality of service to the citizens and the cost associated with the installation of charging stations. We have considered multiple types of EVCS, which will have different uses depending on the types of drivers. Also, our study integrates citizens&#39; daily mobility patterns and residential locations. We used three multi-objective metaheuristics, NSGA-II, SPEA2, and MOEA/D, and evaluated them in a real-world case study in Malaga, Spain. Results indicated that NSGA-II and SPEA2 provide both competitive solutions, highlighting their effectiveness in balancing service quality and installation costs. This enhanced approach captures the dynamic aspects of citizens&#39; daily and residential locations, offering nuanced insights into the electric vehicle charging station location problem.},
  archive   = {C_GECCO},
  author    = {Cintrano, Christian and Toutouh, Jamal and Nesmachnow, Sergio},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654141},
  pages     = {1192–1200},
  title     = {Optimizing electric vehicle charging station placement integrating daily mobility patterns and residential locations},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An order-aware adaptive iterative local search metaheuristic
for multi-depot UAV pickup and delivery problem. <em>GECCO</em>,
1183–1191. (<a href="https://doi.org/10.1145/3638529.3654106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The emergence of the last-mile delivery by unmanned aerial vehicles (UAVs) has gained widespread attention in both scientific and industrial communities in recent years. The problem can be modeled as a mixed linear integer programming problem to minimize the routing cost to serve all customers and the number of UAV launches. Considering the complexity of the multi-depot, multi-UAV, and multi-customer pickup and delivery integrated scheduling problem, this paper proposes a novel two-stage order-aware adaptive iterative local search metaheuristic algorithm to solve this problem. In the first stage, tasks are assigned to different depots, transforming the complex original problem into multiple single depot scheduling problem. In the second stage, an order-aware adaptive iterative local search (OAILS) metaheuristic is designed to optimize the route planning for each depot&#39;s UAVs. In AILS, we propose a novel order-based adaptive operator selection named (OAOS) to select the appropriate operator based on the recent performance of operator and the order relationships of operators. Finally, a series of experiments were conducted to verify the effectiveness of the proposed OAOS and OAILS methods.},
  archive   = {C_GECCO},
  author    = {Chen, Xiang-Ling and Liao, Xiao-Cheng and Wei, Feng-Feng and Chen, Wei-Neng},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654106},
  pages     = {1183–1191},
  title     = {An order-aware adaptive iterative local search metaheuristic for multi-depot UAV pickup and delivery problem},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-objective optimization for large-scale allocation of
soybean crops. <em>GECCO</em>, 1174–1182. (<a
href="https://doi.org/10.1145/3638529.3654026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The optimal allocation of crops to different parcels of land is a problem of paramount practical importance, not only to improve production, but also to address the challenges posed by climate change. However, this optimization problem is inherently complex, characterized by a vast search space that renders traditional optimization techniques impractical without oversimplified assumptions. Compounding this challenge, climate change introduces conflicting objectives, as solutions aiming to just maximize total yield may be more susceptible to extreme weather events, and thus obtain more unpredictable year-by-year outcomes. In order to tackle this complex optimization problem, we propose a multi-objective approach, simultaneously maximizing the overall yield, minimizing the year-on-year yield variance, and minimizing the total cultivated surface. The approach exploits an established multi-objective evolutionary algorithm, and employs a machine learning model able to predict yield from weather and soil conditions, trained on historical data, making it possible to tackle allocation problems of large size. An experimental evaluation focusing on the allocation of soybean crops in the European continent for the years 2000-2023 shows that the proposed methodology is able to identify different trade-offs between the conflicting objectives, that an expert analysis later reveals to be realistic and meaningful for driving stakeholder decisions.},
  archive   = {C_GECCO},
  author    = {Chen, Mathilde and Makowski, David and Tonda, Alberto},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654026},
  pages     = {1174–1182},
  title     = {Multi-objective optimization for large-scale allocation of soybean crops},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evolutionary exploration of triply periodic minimal surfaces
via quality diversity. <em>GECCO</em>, 1165–1173. (<a
href="https://doi.org/10.1145/3638529.3654039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Triply Periodic Minimal Surfaces (TPMSs) are a family of mathematical structures that exhibit constant zero mean curvature and 3-dimensional periodicity. They are often used to produce cellular solids with advantageous structural, thermal, and optical properties. Existing applications represent TPMSs as trigonometric approximations of a Fourier series. Due to the mathematical difficulty of determining new exact forms and their approximations, previous work has mostly evaluated metrics based on geometry, manufacturability, and mechanical performance across parameterisations of a small set of known TPMS equations. In this work, we define TPMS-like structures as having low estimated mean curvature, and apply a coupling of Grammatical Evolution and Quality Diversity to generate a diverse set of novel structures of this kind. We additionally explore the effect of being TPMS-like on the manufacturability of evolved structures. Results show that many TPMS-like designs can be found for different combinations of total surface area and Gaussian curvature, and that there is not a strong relationship between how TPMS-like a design is and its manufacturability. Our method serves as a basis for future application of novel TPMS-like structures and exploration of the pairing of evolutionary design with generative approaches from broader machine learning.},
  archive   = {C_GECCO},
  author    = {Bishop, Jordan T and Jooste, Jason and Howard, David},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654039},
  pages     = {1165–1173},
  title     = {Evolutionary exploration of triply periodic minimal surfaces via quality diversity},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tensorized NeuroEvolution of augmenting topologies for GPU
acceleration. <em>GECCO</em>, 1156–1164. (<a
href="https://doi.org/10.1145/3638529.3654210">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The NeuroEvolution of Augmenting Topologies (NEAT) algorithm has received considerable recognition in the field of neuroevolution. Its effectiveness is derived from initiating with simple networks and incrementally evolving both their topologies and weights. Although its capability across various challenges is evident, the algorithm&#39;s computational efficiency remains an impediment, limiting its scalability potential. In response, this paper introduces a tensorization method for the NEAT algorithm, enabling the transformation of its diverse network topologies and associated operations into uniformly shaped tensors for computation. This advancement facilitates the execution of the NEAT algorithm in a parallelized manner across the entire population. Furthermore, we develop TensorNEAT, a library that implements the tensorized NEAT algorithm and its variants, such as CPPN and HyperNEAT. Building upon JAX, TensorNEAT promotes efficient parallel computations via automated function vectorization and hardware acceleration. Moreover, the TensorNEAT library supports various benchmark environments including Gym, Brax, and gymnax. Through evaluations across a spectrum of robotics control environments in Brax, TensorNEAT achieves up to 500x speedups compared to the existing implementations such as NEAT-Python. Source codes are available at: https://github.com/EMI-Group/tensorneat.},
  archive   = {C_GECCO},
  author    = {Wang, Lishuang and Zhao, Mengfei and Liu, Enyu and Sun, Kebin and Cheng, Ran},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654210},
  pages     = {1156–1164},
  title     = {Tensorized NeuroEvolution of augmenting topologies for GPU acceleration},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient multi-objective neural architecture search via
pareto dominance-based novelty search. <em>GECCO</em>, 1146–1155. (<a
href="https://doi.org/10.1145/3638529.3654064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Neural Architecture Search (NAS) aims to automate the discovery of high-performing deep neural network architectures. Traditional objective-based NAS approaches typically optimize a certain performance metric (e.g., prediction accuracy), overlooking large parts of the architecture search space that potentially contain interesting network configurations. Furthermore, objective-driven population-based metaheuristics in complex search spaces often quickly exhaust population diversity and succumb to premature convergence to local optima. This issue becomes more complicated in NAS when performance objectives do not fully align with the actual performance of the candidate architectures, as is often the case with training-free metrics. While training-free metrics have gained popularity for their rapid performance estimation of candidate architectures without incurring computation-heavy network training, their effective incorporation into NAS remains a challenge. This paper presents the Pareto Dominance-based Novelty Search for multi-objective NAS with Multiple Training-Free metrics (MTF-PDNS). Unlike conventional NAS methods that optimize explicit objectives, MTF-PDNS promotes population diversity by utilizing a novelty score calculated based on multiple training-free performance and complexity metrics, thereby yielding a broader exploration of the search space. Experimental results on standard NAS benchmark suites demonstrate that MTF-PDNS outperforms conventional methods driven by explicit objectives in terms of convergence speed, diversity maintenance, architecture transferability, and computational costs.},
  archive   = {C_GECCO},
  author    = {Vo, An and Luong, Ngoc Hoang},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654064},
  pages     = {1146–1155},
  title     = {Efficient multi-objective neural architecture search via pareto dominance-based novelty search},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evolving generalist controllers to handle a wide range of
morphological variations. <em>GECCO</em>, 1137–1145. (<a
href="https://doi.org/10.1145/3638529.3654116">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Neuro-evolutionary methods have proven effective in addressing a wide range of tasks. However, the study of the robustness and generalizability of evolved artificial neural networks (ANNs) has remained limited. This has immense implications in the fields like robotics where such controllers are used in control tasks. Unexpected morphological or environmental changes during operation can risk failure if the ANN controllers are unable to handle these changes. This paper proposes an algorithm that aims to enhance the robustness and generalizability of the controllers. This is achieved by introducing morphological variations during the evolutionary training process. As a results, it is possible to discover generalist controllers that can handle a wide range of morphological variations sufficiently without the need of the information regarding their morphologies or adaptation of their parameters. We perform an extensive experimental analysis on simulation that demonstrates the trade-off between specialist and generalist controllers. The results show that generalists are able to control a range of morphological variations with a cost of underperforming on a specific morphology relative to a specialist. This research contributes to the field by addressing the limited understanding of robustness and generalizability and proposes a method by which to improve these properties.},
  archive   = {C_GECCO},
  author    = {Triebold, Corinna and Yaman, Anil},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654116},
  pages     = {1137–1145},
  title     = {Evolving generalist controllers to handle a wide range of morphological variations},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). THNAS-GA: A genetic algorithm for training-free
hardware-aware neural architecture search. <em>GECCO</em>, 1128–1136.
(<a href="https://doi.org/10.1145/3638529.3654226">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Neural Architecture Search (NAS) is a promising approach to automate the design of neural network architectures, which can find architectures that perform better than manually designed ones. Hardware-aware NAS is a real-world application of NAS where the architectures found also need to satisfy certain requirements for the deployment of specific devices. Despite the practical importance, hardware-aware NAS still receives a lack of attention from the community. Existing research mostly focuses on the search space with a limited number of architectures, reducing the search process to finding the optimal hyperparameters. In addition, the performance evaluation of found networks is resources-intensive, which can severely hinder reproducibility. In this work, we propose a genetic algorithm approach to the hardware-aware NAS problem, incorporating a latency filtering selection to guarantee the latency validity of candidate solutions. We also introduce an extended search space that can cover various existing architectures from previous research. To speed up the search process, we also present a method to estimate the latency of candidate networks and a training-free performance estimation method to quickly evaluate candidate networks. Our experiments demonstrate that our method achieves competitive performance with state-of-the-art networks while maintaining lower latency with less computation requirements for searching.},
  archive   = {C_GECCO},
  author    = {Thanh, Tran Hai and Doan, Long and Luong, Ngoc Hoang and Huynh Thi Thanh, Binh},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654226},
  pages     = {1128–1136},
  title     = {THNAS-GA: A genetic algorithm for training-free hardware-aware neural architecture search},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Structurally flexible neural networks: Evolving the building
blocks for general agents. <em>GECCO</em>, 1119–1127. (<a
href="https://doi.org/10.1145/3638529.3654113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Artificial neural networks used for reinforcement learning are structurally rigid, meaning that each optimized parameter of the network is tied to its specific placement in the network structure. Structural rigidity limits the ability to optimize parameters of policies across multiple environments that do not share input and output spaces. This is a consequence of the number of optimized parameters being directly dependent on the structure of the network. In this paper, we present Structurally Flexible Neural Networks (SFNNs), which consist of connected gated recurrent units (GRUs) as synaptic plasticity rules and linear layers as neurons. In contrast to earlier work, SFNNs contain several different sets of parameterized building blocks. Here we show that SFNNs can overcome the challenging symmetry dilemma, which refers to the problem of optimizing units with shared parameters to each express different representations during deployment. In this paper, the same SFNN can learn to solve three classic control environments that have different input/output spaces. SFFNs thus represent a step toward a more general model capable of solving several environments at once.},
  archive   = {C_GECCO},
  author    = {Pedersen, Joachim and Plantec, Erwan and Nisioti, Eleni and Montero, Milton and Risi, Sebastian},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654113},
  pages     = {1119–1127},
  title     = {Structurally flexible neural networks: Evolving the building blocks for general agents},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LLMatic: Neural architecture search via large language
models and quality diversity optimization. <em>GECCO</em>, 1110–1118.
(<a href="https://doi.org/10.1145/3638529.3654017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Large language models (LLMs) have emerged as powerful tools capable of accomplishing a broad spectrum of tasks. Their abilities span numerous areas, and one area where they have made a significant impact is in the domain of code generation. Here, we propose using the coding abilities of LLMs to introduce meaningful variations to code defining neural networks. Meanwhile, Quality-Diversity (QD) algorithms are known to discover diverse and robust solutions. By merging the code-generating abilities of LLMs with the diversity and robustness of QD solutions, we introduce LLMatic, a Neural Architecture Search (NAS) algorithm. While LLMs struggle to conduct NAS directly through prompts, LLMatic uses a procedural approach, leveraging QD for prompts and network architecture to create diverse and high-performing networks. We test LLMatic on the CIFAR-10 and NAS-bench-201 benchmarks, demonstrating that it can produce competitive networks while evaluating just 2, 000 candidates, even without prior knowledge of the benchmark domain or exposure to any previous top-performing models for the benchmark. The open-sourced code is available at https://github.com/umair-nasir14/LLMatic.},
  archive   = {C_GECCO},
  author    = {Nasir, Muhammad Umair and Earle, Sam and Togelius, Julian and James, Steven and Cleghorn, Christopher},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654017},
  pages     = {1110–1118},
  title     = {LLMatic: Neural architecture search via large language models and quality diversity optimization},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Neural optimizer equation, decay function, and learning
rate schedule joint evolution. <em>GECCO</em>, 1100–1109. (<a
href="https://doi.org/10.1145/3638529.3654187">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A major contributor to the quality of a deep learning model is the selection of the optimizer. We propose a new dual-joint search space in the realm of neural optimizer search (NOS), along with an integrity check, to automate the process of finding deep learning optimizers. Our dual-joint search space simultaneously allows for the optimization of not only the update equation, but also internal decay functions and learning rate schedules for optimizers. We search the space using our proposed mutation-only, particle-based genetic algorithm able to be massively parallelized for our domain-specific problem. We evaluate our candidate optimizers on the CIFAR-10 dataset using a small ConvNet. To assess generalization, the final optimizers were then transferred to large-scale image classification on CIFAR-100 and TinyImageNet, while also being fine-tuned on Flowers102, Cars196, and Caltech101 using EfficientNetV2Small. We found multiple optimizers, learning rate schedules, and Adam variants that outperformed Adam, as well as other standard deep learning optimizers, across the image classification tasks.},
  archive   = {C_GECCO},
  author    = {Morgan, Brandon and Hougen, Dean},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654187},
  pages     = {1100–1109},
  title     = {Neural optimizer equation, decay function, and learning rate schedule joint evolution},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Evolving loss functions for specific image augmentation
techniques. <em>GECCO</em>, 1091–1099. (<a
href="https://doi.org/10.1145/3638529.3654186">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Previous work in Neural Loss Function Search (NLFS) has shown a lack of correlation between smaller surrogate functions and large convolutional neural networks with massive regularization. We expand upon this research by revealing another disparity that exists, correlation between different types of image augmentation techniques. We show that different loss functions can perform well on certain image augmentation techniques, while performing poorly on others. We exploit this disparity by performing an evolutionary search on five types of image augmentation techniques in the hopes of finding image augmentation specific loss functions. The best loss functions from each evolution were then taken and transferred to WideResNet-28-10 on CIFAR-10 and CIFAR-100 across each of the five image augmentation techniques. The best from that were then taken and evaluated by fine-tuning EfficientNetV2Small on the CARS, Oxford-Flowers, and Caltech datasets across each of the five image augmentation techniques. Multiple loss functions were found that outperformed cross-entropy across multiple experiments. In the end, we found a single loss function, which we called the inverse bessel logarithm loss, that was able to outperform cross-entropy across the majority of experiments.},
  archive   = {C_GECCO},
  author    = {Morgan, Brandon and Hougen, Dean},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654186},
  pages     = {1091–1099},
  title     = {Evolving loss functions for specific image augmentation techniques},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing MAP-elites with multiple parallel evolution
strategies. <em>GECCO</em>, 1082–1090. (<a
href="https://doi.org/10.1145/3638529.3654089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With the development of fast and massively parallel evaluations in many domains, Quality-Diversity (QD) algorithms, that already proved promising in a large range of applications, have seen their potential multiplied. However, we have yet to understand how to best use a large number of evaluations as using them for random variations alone is not always effective. High-dimensional search spaces are a typical situation where random variations struggle to effectively search. Another situation is uncertain settings where solutions can appear better than they truly are and naively evaluating more solutions might mislead QD algorithms. In this work, we propose MAP-Elites-Multi-ES (MEMES), a novel QD algorithm based on Evolution Strategies (ES) designed to exploit fast parallel evaluations more effectively. MEMES maintains multiple (up to ~ 100) simultaneous ES processes, each with its own independent objective and reset mechanism designed for QD optimisation, all on just a single GPU. We show that MEMES outperforms both gradient-based and mutation-based QD algorithms on black-box optimisation and QD-Reinforcement-Learning tasks, demonstrating its benefit across domains. Additionally, our approach outperforms sampling-based QD methods in uncertain domains when given the same evaluation budget. Overall, MEMES generates reproducible solutions that are high-performing and diverse through large-scale ES optimisation on easily accessible hardware.},
  archive   = {C_GECCO},
  author    = {Flageat, Manon and Lim, Bryan and Cully, Antoine},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654089},
  pages     = {1082–1090},
  title     = {Enhancing MAP-elites with multiple parallel evolution strategies},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Machine learning-enhanced ant colony optimization for column
generation. <em>GECCO</em>, 1073–1081. (<a
href="https://doi.org/10.1145/3638529.3654043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Column generation (CG) is a powerful technique for solving optimization problems that involve a large number of variables or columns. This technique begins by solving a smaller problem with a subset of columns and gradually generates additional columns as needed. However, the generation of columns often requires solving difficult subproblems repeatedly, which can be a bottleneck for CG. To address this challenge, we propose a novel method called machine learning enhanced ant colony optimization (MLACO), to efficiently generate multiple high-quality columns from a sub-problem. Specifically, we train a ML model to predict the optimal solution of a subproblem, and then integrate this ML prediction into the probabilistic model of ACO to sample multiple high-quality columns. Our experimental results on the bin packing problem with conflicts show that the MLACO method significantly improves the performance of CG compared to several state-of-the-art methods. Furthermore, when our method is incorporated into a Branch-and-Price method, it leads to a significant reduction in solution time.},
  archive   = {C_GECCO},
  author    = {Xu, Hongjie and Shen, Yunzhuang and Sun, Yuan and Li, Xiaodong},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654043},
  pages     = {1073–1081},
  title     = {Machine learning-enhanced ant colony optimization for column generation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Accelerate evolution strategy by proximal policy
optimization. <em>GECCO</em>, 1064–1072. (<a
href="https://doi.org/10.1145/3638529.3654090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A pivotal challenge in meta-heuristic optimization is the lack of knowledge inheritance in heuristic rules. For example, the Covariance Matrix Adaptation Evolution Strategy (CMA-ES) requires generating historical data from scratch for its adaptation mechanisms for each new instance, demanding an extensive number of fitness evaluations. This severely limits the practicality of meta-heuristics, especially under restricted evaluation budgets, hindering efficient navigation in high-dimensional spaces. To overcome this, we integrate Proximal Policy Optimization (PPO) with a vanilla Evolution Strategy (ES), forming the novel PPO-ES approach. Distinct from other adaptive ES variants like CMA-ES with cumulative path calculation and covariance matrix adaptation, it leverages PPO&#39;s capability for dynamic step-size adjustment. Our method streamlines the optimization process and incorporates a meticulously designed reward system to adeptly navigate the scalability challenge, significantly enhancing adaptability and efficiency of ES. PPO-ES, trained on part of the bbob benchmarks, was tested on these and the rest unseen problems, and further validated on bbob-largescale benchmarks with much higher dimensions. Results show that PPO-ES achieves faster or comparable convergence to CMA-ES. Our code can be found online: https://github.com/burningxt/PPO-ES_GECCO24.},
  archive   = {C_GECCO},
  author    = {Xu, Tao and Chen, Hongyang Chen and He, Jun},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654090},
  pages     = {1064–1072},
  title     = {Accelerate evolution strategy by proximal policy optimization},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GRAHF: A hyper-heuristic framework for evolving
heterogeneous island model topologies. <em>GECCO</em>, 1054–1063. (<a
href="https://doi.org/10.1145/3638529.3654136">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Practitioners frequently encounter the challenge of selecting the best optimization algorithm from a pool of options. However, why not, rather than selecting a single algorithm, let evolution determine the optimal combination of all algorithms? In this paper, we present an approach to algorithm design inspired by a well-known traditional method for coarse-grained hybridization: the heterogeneous island model. Our hyper-heuristic framework represents island models as graphs and identifies optimal island topologies and parameters for specific sets of problem instances. Since the framework operates at the level of metaheuristic algorithms rather than components and incorporates a configuration mechanism directly into the search, it combines concepts from algorithm design, selection, and configuration. The proposed framework is investigated on 24 training sets of varying difficulty and demonstrates its ability to discover complex hybrids. A post-evaluation on real-world constrained optimization problems shows a significant improvement over the algorithms on their own. These results suggest that it is a promising way to design hybrid metaheuristics with minimal manual intervention, given representative training instances, a set of optimization algorithms, and sufficient computational resources.},
  archive   = {C_GECCO},
  author    = {Wurth, Jonathan and Stegherr, Helena and Heider, Michael and H\&quot;{a}hner, J\&quot;{o}rg},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654136},
  pages     = {1054–1063},
  title     = {GRAHF: A hyper-heuristic framework for evolving heterogeneous island model topologies},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep neural crossover: A multi-parent operator that
leverages gene correlations. <em>GECCO</em>, 1045–1053. (<a
href="https://doi.org/10.1145/3638529.3654020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present a novel multi-parent crossover operator in genetic algorithms (GAs) called &quot;Deep Neural Crossover&quot; (DNC). Unlike conventional GA crossover operators that rely on a random selection of parental genes, DNC leverages the capabilities of deep reinforcement learning (DRL) and an encoder-decoder architecture to select the genes. Specifically, we use DRL to learn a policy for selecting promising genes. The policy is stochastic, to maintain the stochastic nature of GAs, representing a distribution for selecting genes with a higher probability of improving fitness. Our architecture features a recurrent neural network (RNN) to encode the parental genomes into latent memory states, and a decoder RNN that utilizes an attention-based pointing mechanism to generate a distribution over the next selected gene in the offspring. The operator&#39;s architecture is designed to find linear and nonlinear correlations between genes and translate them to gene selection. To reduce computational cost, we present a transfer-learning approach, wherein the architecture is initially trained on a single problem within a specific domain and then applied to solving other problems of the same domain. We compare DNC to known operators from the literature over two benchmark domains, outperforming all baselines.},
  archive   = {C_GECCO},
  author    = {Shem-Tov, Eliad and Elyasaf, Achiya},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654020},
  pages     = {1045–1053},
  title     = {Deep neural crossover: A multi-parent operator that leverages gene correlations},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evolving reliable differentiating constraints for the
chance-constrained maximum coverage problem. <em>GECCO</em>, 1036–1044.
(<a href="https://doi.org/10.1145/3638529.3654181">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Chance-constrained problems involve stochastic components in the constraints which can be violated with a small probability. We investigate the impact of different types of chance constraints on the performance of iterative search algorithms and study the classical maximum coverage problem in graphs with chance constraints. Our goal is to evolve reliable chance constraint settings for a given graph where the performance of algorithms differs significantly not just in expectation but with high confidence. This allows to better learn and understand how different types of algorithms can deal with different types of constraint settings and supports automatic algorithm selection. We develop an evolutionary algorithm that provides sets of chance constraints that differentiate the performance of two stochastic search algorithms with high confidence. We initially use traditional approximation ratio as the fitness function of (1+1) EA to evolve instances, which shows inadequacy to generate reliable instances. To address this issue, we introduce a new measure to calculate the performance difference for two algorithms, which considers variances of performance ratios. Our experiments show that our approach is highly successful in solving the instability issue of the performance ratios and leads to evolving reliable sets of chance constraints with significantly different performance for various types of algorithms.},
  archive   = {C_GECCO},
  author    = {Sadeghi Ahouei, Saba and De Nobel, Jacob and Neumann, Aneta and B\&quot;{a}ck, Thomas and Neumann, Frank},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654181},
  pages     = {1036–1044},
  title     = {Evolving reliable differentiating constraints for the chance-constrained maximum coverage problem},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving algorithm-selectors and performance-predictors via
learning discriminating training samples. <em>GECCO</em>, 1026–1035. (<a
href="https://doi.org/10.1145/3638529.3654025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The choice of input-data used to train algorithm-selection models is recognised as being a critical part of the model success. Recently, feature-free methods for algorithm-selection that use short trajectories obtained from running a solver as input have shown promise. However, it is unclear to what extent these trajectories reliably discriminate between solvers. We propose a meta approach to generating discriminatory trajectories with respect to a portfolio of solvers. The algorithm-configuration tool irace is used to tune the parameters of a simple Simulated Annealing algorithm (SA) to produce trajectories that maximise the performance metrics of ML models trained on this data. We show that when the trajectories obtained from the tuned SA algorithm are used in ML models for algorithm-selection and performance prediction, we obtain significantly improved performance metrics compared to models trained both on raw trajectory data and on exploratory landscape features.},
  archive   = {C_GECCO},
  author    = {Renau, Quentin and Hart, Emma},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654025},
  pages     = {1026–1035},
  title     = {Improving algorithm-selectors and performance-predictors via learning discriminating training samples},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning from offline and online experiences: A hybrid
adaptive operator selection framework. <em>GECCO</em>, 1017–1025. (<a
href="https://doi.org/10.1145/3638529.3654062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In many practical applications, usually, similar optimisation problems or scenarios repeatedly appear. Learning from previous problem-solving experiences can help adjust algorithm components of meta-heuristics, e.g., adaptively selecting promising search operators, to achieve better optimisation performance. However, those experiences obtained from previously solved problems, namely offline experiences, may sometimes provide misleading perceptions when solving a new problem, if the characteristics of previous problems and the new one are relatively different. Learning from online experiences obtained during the ongoing problem-solving process is more instructive but highly restricted by limited computational resources. This paper focuses on the effective combination of offline and online experiences. A novel hybrid framework that learns to dynamically and adaptively select promising search operators is proposed. Two adaptive operator selection modules with complementary paradigms cooperate in the framework to learn from offline and online experiences and make decisions. An adaptive decision policy is maintained to balance the use of those two modules in an online manner. Extensive experiments on 170 widely studied real-value benchmark optimisation problems and a benchmark set with 34 instances for combinatorial optimisation show that the proposed hybrid framework outperforms the state-of-the-art methods. Ablation study verifies the effectiveness of each component of the framework.},
  archive   = {C_GECCO},
  author    = {Pei, Jiyuan and Liu, Jialin and Mei, Yi},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654062},
  pages     = {1017–1025},
  title     = {Learning from offline and online experiences: A hybrid adaptive operator selection framework},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Impact of training instance selection on automated algorithm
selection models for numerical black-box optimization. <em>GECCO</em>,
1007–1016. (<a href="https://doi.org/10.1145/3638529.3654100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The recently proposed MA-BBOB function generator provides a way to create numerical black-box benchmark problems based on the well-established BBOB suite. Initial studies on this generator highlighted its ability to smoothly transition between the component functions, both from a low-level landscape feature perspective, as well as with regard to algorithm performance. This suggests that MA-BBOB-generated functions can be an ideal testbed for automated machine learning methods, such as automated algorithm selection (AAS).In this paper, we generate 11 800 functions in dimensions d = 2 and d = 5, respectively, and analyze the potential gains from AAS by studying performance complementarity within a set of eight algorithms. We combine this performance data with exploratory landscape features to create an AAS pipeline that we use to investigate how to efficiently select training sets within this space. We show that simply using the BBOB component functions for training yields poor test performance, while the ranking between uniformly chosen and diversity-based training sets strongly depends on the distribution of the test set.},
  archive   = {C_GECCO},
  author    = {Dietrich, Konstantin and Vermetten, Diederick and Doerr, Carola and Kerschke, Pascal},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654100},
  pages     = {1007–1016},
  title     = {Impact of training instance selection on automated algorithm selection models for numerical black-box optimization},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bias-variance decomposition: An effective tool to improve
generalization of genetic programming-based evolutionary feature
construction for regression. <em>GECCO</em>, 998–1006. (<a
href="https://doi.org/10.1145/3638529.3654075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Evolutionary feature construction is a technique that has been widely studied in the domain of automated machine learning. A key challenge that needs to be addressed in feature construction is its tendency to overfit the training data. Instead of the traditional approach to control overfitting by reducing model complexity, this paper proposes to control overfitting based on bias-variance decomposition. Specifically, this paper proposes reducing the variance of a model, i.e., reducing the variance of predictions when exposed to data with injected noise, to improve its generalization performance within a multi-objective optimization framework. Experiments conducted on 42 datasets demonstrate that the proposed method effectively controls overfitting and outperforms six model complexity measures for overfitting control. Moreover, further analysis reveals that controlling overfitting adhering to bias-variance decomposition outperforms several plausible variants, highlighting the importance of controlling overfitting based on solid machine learning theory.},
  archive   = {C_GECCO},
  author    = {Zhang, Hengzhe and Chen, Qi and Xue, Bing and Banzhaf, Wolfgang and Zhang, Mengjie},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654075},
  pages     = {998–1006},
  title     = {Bias-variance decomposition: An effective tool to improve generalization of genetic programming-based evolutionary feature construction for regression},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reinforcement learning-assisted genetic programming hyper
heuristic approach to location-aware dynamic online application
deployment in clouds. <em>GECCO</em>, 988–997. (<a
href="https://doi.org/10.1145/3638529.3654058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Location-Aware Dynamic Online Application dePloyment (LADOAP) in clouds is an NP-hard combinatorial optimisation problem. Genetic Programming Hyper-Heuristic (GPHH) has emerged as a promising approach for addressing LADOAP demands by dynamically generating Virtual Machine (VM) selection heuristics online. However, the performance of GPHH is impeded by long simulation times and low sampling efficiency. In this paper, we propose a novel hyper-heuristic framework that integrates Genetic Programming Hyper-Heuristic (GPHH) and Reinforcement Learning (RL) approaches to evolve rules for efficiently selecting location-aware Virtual Machines (VMs) capable of hosting multiple containers. The RL policy&#39;s value function acts as a surrogate model, significantly expediting the evaluation of generated VM selection rules. By applying this hybrid framework to LADOAP problems, we achieve competitive performance with a notable reduction in the number of required simulations. This innovative approach not only enhances the efficiency of VM selection but also contributes to advancing the state-of-the-art in addressing complex LADOAP challenges.},
  archive   = {C_GECCO},
  author    = {Yan, Longfei Felix and Ma, Hui and Chen, Gang},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654058},
  pages     = {988–997},
  title     = {Reinforcement learning-assisted genetic programming hyper heuristic approach to location-aware dynamic online application deployment in clouds},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sign change detection based fitness evaluation for automatic
implicit equation discovery. <em>GECCO</em>, 980–987. (<a
href="https://doi.org/10.1145/3638529.3654015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Automatic implicit equation discovery is a meaningful and challenging problem in symbolic regression. The current common methods for the automatic discovery of implicit equations include derivative calculations and comprehensive learning. However, both methods come with their own set of challenges. Derivative calculations pose difficulties in handling sparse data. The comprehensive learning method may encounter problems associated with multiple multiplications, making it difficult to find the optimal equation. Inspired by Bolzano&#39;s theorem,we propose a new evaluation mechanism known as the &quot;Sign Change Detection (SCD) based Fitness Evaluation&quot;. The main idea of our proposed mechanism is to approximate the solution of an equation using Bolzano&#39;s theorem. This mechanism can overcome the limitations associated with derivative calculations and comprehensive learning methods. Furthermore, we integrate this mechanism with self-learning gene expression programming (SL-GEP) to develop a new SCD-GEP method. Experimental results have shown that the proposed method surpasses the compared approaches in discovering implicit equations, achieving a higher success rate in finding optimal solutions.},
  archive   = {C_GECCO},
  author    = {Wen, Jiahao and Dong, Junlan and Zhong, Jinghui},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654015},
  pages     = {980–987},
  title     = {Sign change detection based fitness evaluation for automatic implicit equation discovery},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving the efficiency of GP-GOMEA for higher-arity
operators. <em>GECCO</em>, 971–979. (<a
href="https://doi.org/10.1145/3638529.3654118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deploying machine learning models into sensitive domains in our society requires these models to be explainable. Genetic Programming (GP) can offer a way to evolve inherently interpretable expressions. GP-GOMEA is a form of GP that has been found particularly effective at evolving expressions that are accurate yet of limited size and, thus, promote interpretability. Despite this strength, a limitation of GP-GOMEA is template-based. This negatively affects its scalability regarding the arity of operators that can be used, since with increasing operator arity, an increasingly large part of the template tends to go unused. In this paper, we therefore propose two enhancements to GP-GOMEA: (i) semantic subtree inheritance, which performs additional variation steps that consider the semantic context of a subtree, and (ii) greedy child selection, which explicitly considers parts of the template that in standard GP-GOMEA remain unused. We compare different versions of GP-GOMEA regarding search enhancements on a set of continuous and discontinuous regression problems, with varying tree depths and operator sets. Experimental results show that both proposed search enhancements have a generally positive impact on the performance of GP-GOMEA, especially when the set of operators to choose from is large and contains higher-arity operators.},
  archive   = {C_GECCO},
  author    = {Schlender, Thalea and Malafaia, Mafalda and Alderliesten, Tanja and Bosman, Peter},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654118},
  pages     = {971–979},
  title     = {Improving the efficiency of GP-GOMEA for higher-arity operators},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multiview symbolic regression. <em>GECCO</em>, 961–970. (<a
href="https://doi.org/10.1145/3638529.3654087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Symbolic regression (SR) searches for analytical expressions representing the relationship between explanatory and response variables. Current SR methods assume a single dataset extracted from a single experiment. Nevertheless, frequently, the researcher is confronted with multiple sets of results obtained from experiments conducted with different set-ups. Traditional SR methods may fail to find the underlying expression since the parameters of each experiment can be different. In this work we present Multiview Symbolic Regression (MvSR), which takes into account multiple datasets simultaneously, mimicking experimental environments, and outputs a general parametric solution. This approach fits the evaluated expression to each independent dataset and returns a parametric family of functions f(x; θ) simultaneously capable of accurately fitting all datasets. We demonstrate the effectiveness of MvSR using data generated from known expressions, as well as real-world data from astronomy, chemistry and economy, for which an a priori analytical expression is not available. Results show that MvSR obtains the correct expression more frequently and is robust to hyperparameters change. In real-world data, it is able to grasp the group behaviour, recovering known expressions from the literature as well as promising alternatives, thus enabling the use MvSR to a large range of experimental scenarios.},
  archive   = {C_GECCO},
  author    = {Russeil, Etienne and de Franca, Fabricio Olivetti and Malanchev, Konstantin and Burlacu, Bogdan and Ishida, Emille and Leroux, Marion and Michelin, Cl\&#39;{e}ment and Moinard, Guillaume and Gangler, Emmanuel},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654087},
  pages     = {961–970},
  title     = {Multiview symbolic regression},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Effective adaptive mutation rates for program synthesis.
<em>GECCO</em>, 952–960. (<a
href="https://doi.org/10.1145/3638529.3654135">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The problem-solving performance of many evolutionary algorithms, including genetic programming systems used for program synthesis, depends on the values of hyperparameters including mutation rates. The mutation method used to produce some of the best results to date on software synthesis benchmark problems, Uniform Mutation by Addition and Deletion (UMAD), adds new genes into a genome at a predetermined rate and then deletes genes at a rate that balances the addition rate, producing no size change on average. While UMAD with a predetermined addition rate outperforms many other mutation and crossover schemes, we do not expect a single rate to be optimal across all problems or all generations within one run of an evolutionary system. However, many current adaptive mutation schemes such as self-adaptive mutation rates suffer from pathologies like the vanishing mutation rate problem, in which the mutation rate quickly decays to zero. We propose an adaptive bandit-based scheme that addresses this problem and essentially removes the need to specify a mutation rate. Although the proposed scheme itself introduces hyperparameters, we either set these to good values or ensemble them in a reasonable range. Results on software synthesis and symbolic regression problems validate the effectiveness of our approach.},
  archive   = {C_GECCO},
  author    = {Ni, Andrew and Spector, Lee},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654135},
  pages     = {952–960},
  title     = {Effective adaptive mutation rates for program synthesis},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Genetic-based constraint programming for resource
constrained job scheduling. <em>GECCO</em>, 942–951. (<a
href="https://doi.org/10.1145/3638529.3654046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Resource constrained job scheduling is a hard combinatorial optimisation problem that originates in the mining industry. Off-the-shelf solvers cannot solve this problem satisfactorily in reasonable time-frames, while other solution methods such as evolutionary computation methods and matheuristics cannot guarantee optimality and require low-level customisation and specialised heuristics to be effective. This paper addresses this gap by proposing a genetic programming algorithm to discover efficient search strategies of constraint programming for resource-constrained job scheduling. In the proposed algorithm, evolved programs represent variable selectors to be used in the search process of constraint programming, and their fitness is determined by the quality of solutions obtained by constraint programming for training instances. The novelties of this algorithm are (1) a new representation of variable selectors, (2) a new fitness evaluation scheme, and (3) a pre-selection mechanism. Tests with a large set of random and benchmark instances show that the evolved variable selectors can significantly improve the efficiency of constraining programming. Compared to highly customised metaheuristics and hybrid algorithms, evolved variable selectors can help constraint programming identify quality solutions faster and proving optimality is possible if sufficiently large run-times are allowed. The evolved variable selectors are especially helpful when solving instances with large numbers of machines.},
  archive   = {C_GECCO},
  author    = {Nguyen, Su and Thiruvady, Dhananjay and Sun, Yuan and Zhang, Mengjie},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654046},
  pages     = {942–951},
  title     = {Genetic-based constraint programming for resource constrained job scheduling},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Searching for a diversity of interpretable graph control
policies. <em>GECCO</em>, 933–941. (<a
href="https://doi.org/10.1145/3638529.3653987">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph-based Genetic Programming (GGP) can create interpretable control policies in graph form, but faces challenges such as local optima and solution fragility, which undermine its efficacy. Quality-Diversity (QD) has been effective in addressing similar issues, traditionally in Artificial Neural Network (ANN) optimization. In this paper, we introduce a general Graph Quality-Diversity (G-QD) framework to enhance the performance of GGP with QD optimization, obtaining a variety of interpretable, effective, and resilient policies. Using Cartesian Genetic Programming (CGP) as the GGP technique and MAP-Elites (ME) as the QD algorithm, we leverage a combination of behavior and graph structural descriptors. Experimenting on two navigation and two locomotion continuous control tasks, our framework yields an array of effective yet behaviorally and structurally diverse policies, surpassing the performance of a standard Genetic Algorithm (GA). The resulting solution set also increases interpretability, allowing for insight into the control tasks. Additionally, our experiments demonstrate the robustness of the solutions to faults such as sensor damage.},
  archive   = {C_GECCO},
  author    = {Nadizar, Giorgia and Medvet, Eric and Wilson, Dennis},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3653987},
  pages     = {933–941},
  title     = {Searching for a diversity of interpretable graph control policies},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning traffic signal control via genetic programming.
<em>GECCO</em>, 924–932. (<a
href="https://doi.org/10.1145/3638529.3654037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The control of traffic signals is crucial for improving transportation efficiency. Recently, learning-based methods, especially Deep Reinforcement Learning (DRL), garnered substantial success in the quest for more efficient traffic signal control strategies. However, the design of rewards in DRL highly demands domain knowledge to converge to an effective policy, and the final policy also presents difficulties in terms of explainability. In this work, a new learning-based method for signal control in complex intersections is proposed. In our approach, we design a concept of phase urgency for each signal phase. During signal transitions, the traffic light control strategy selects the next phase to be activated based on the phase urgency. We then proposed to represent the urgency function as an explainable tree structure. The urgency function can calculate the phase urgency for a specific phase based on the current road conditions. Genetic programming is adopted to perform gradient-free optimization of the urgency function. We test our algorithm on multiple public traffic signal control datasets. The experimental results indicate that the tree-shaped urgency function evolved by genetic programming outperforms the baselines, including a state-of-the-art method in the transportation field and a well-known DRL-based method.},
  archive   = {C_GECCO},
  author    = {Liao, Xiao-Cheng and Mei, Yi and Zhang, Mengjie},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654037},
  pages     = {924–932},
  title     = {Learning traffic signal control via genetic programming},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Large language model-based test case generation for GP
agents. <em>GECCO</em>, 914–923. (<a
href="https://doi.org/10.1145/3638529.3654056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Genetic programming (GP) is a popular problem-solving and optimization technique. However, generating effective test cases for training and evaluating GP programs requires strong domain knowledge. Furthermore, GP programs often prematurely converge on local optima when given excessively difficult problems early in their training. Curriculum learning (CL) has been effective in addressing similar issues across different reinforcement learning (RL) domains, but it requires the manual generation of progressively difficult test cases as well as their careful scheduling. In this work, we leverage the domain knowledge and the strong generative abilities of large language models (LLMs) to generate effective test cases of increasing difficulties and schedule them according to various curricula. We show that by integrating a curriculum scheduler with LLM-generated test cases we can effectively train a GP agent player with environments-based curricula for a single-player game and opponent-based curricula for a multi-player game. Finally, we discuss the benefits and challenges of implementing this method for other problem domains.},
  archive   = {C_GECCO},
  author    = {Jorgensen, Steven and Nadizar, Giorgia and Pietropolli, Gloria and Manzoni, Luca and Medvet, Eric and O&#39;Reilly, Una-May and Hemberg, Erik},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654056},
  pages     = {914–923},
  title     = {Large language model-based test case generation for GP agents},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Minimum variance threshold for epsilon-lexicase selection.
<em>GECCO</em>, 905–913. (<a
href="https://doi.org/10.1145/3638529.3654149">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Parent selection plays an important role in evolutionary algorithms, and many strategies exist to select the parent pool before breeding the next generation. Methods often rely on average error over the entire dataset as a criterion to select the parents, which can lead to an information loss due to aggregation of all test cases. Under ϵ-lexicase selection, the population goes to a selection pool that is iteratively reduced by using each test individually, discarding individuals with an error higher than the elite error plus the median absolute deviation (MAD) of errors for that particular test case. In an attempt to better capture differences in performance of individuals on cases, we propose a new criteria that splits errors into two partitions that minimize the total variance within partitions. Our method was embedded into the FEAT symbolic regression algorithm, and evaluated with the SRBench framework, containing 122 black-box synthetic and real-world regression problems. The empirical results show a better performance of our approach compared to traditional ϵ-lexicase selection in the real-world datasets while showing equivalent performance on the synthetic dataset.},
  archive   = {C_GECCO},
  author    = {Imai Aldeia, Guilherme Seidyo and De Fran\c{c}a, Fabr\&#39;{\i}cio Olivetti and La Cava, William G.},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654149},
  pages     = {905–913},
  title     = {Minimum variance threshold for epsilon-lexicase selection},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Inexact simplification of symbolic regression expressions
with locality-sensitive hashing. <em>GECCO</em>, 896–904. (<a
href="https://doi.org/10.1145/3638529.3654147">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Symbolic regression (SR) searches for parametric models that accurately fit a dataset, prioritizing simplicity and interpretability. Despite this secondary objective, studies point out that the models are often overly complex due to redundant operations, introns, and bloat that arise during the iterative process, and can hinder the search with repeated exploration of bloated segments. Applying a fast heuristic algebraic simplification may not fully simplify the expression and exact methods can be infeasible depending on size or complexity of the expressions. We propose a novel agnostic simplification and bloat control for SR employing an efficient memoization with locality-sensitive hashing (LHS). The idea is that expressions and their sub-expressions traversed during the iterative simplification process are stored in a dictionary using LHS, enabling efficient retrieval of similar structures. We iterate through the expression, replacing subtrees with others of same hash if they result in a smaller expression. Empirical results shows that applying this simplification during evolution performs equal or better than without simplification in minimization of error, significantly reducing the number of nonlinear functions. This technique can learn simplification rules that work in general or for a specific problem, and improves convergence while reducing model complexity.},
  archive   = {C_GECCO},
  author    = {Imai Aldeia, Guilherme Seidyo and De Fran\c{c}a, Fabr\&#39;{\i}cio Olivetti and La Cava, William G.},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654147},
  pages     = {896–904},
  title     = {Inexact simplification of symbolic regression expressions with locality-sensitive hashing},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Facilitating function application in code building genetic
programming. <em>GECCO</em>, 887–895. (<a
href="https://doi.org/10.1145/3638529.3654068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Code Building Genetic Programming (CBGP) is a method for general inductive program synthesis that uses a genetic algorithm and a formal type system to evolve linear genomes that are compiled into type-safe programs in a host language. Prior work showed that CBGP can evolve programs that use arbitrary abstractions from existing codebases along with higher-order functions and polymorphism. In tests on benchmark problems, however, the problem solving capabilities of CBGP have been mixed. One hypothesized explanation for weak performance on some problems is that many functions encountered during the compilation process are typically not applied. Here we propose two modifications to the compilation algorithm, both of which make it more likely that functions will be applied when composing programs. The first modification changes how frequently CBGP attempts to perform function application, while the second allows the construction of function applications to backtrack. While both modifications increase solution rates on benchmark problems, the backtracking modification shows more promise with a modest increase in computational cost and no additional configuration requirements. We argue that this modification should be considered the new standard compilation algorithm for CBGP systems.},
  archive   = {C_GECCO},
  author    = {Helmuth, Thomas and Fedoroff, Jayden and Pantridge, Edward and Spector, Lee},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654068},
  pages     = {887–895},
  title     = {Facilitating function application in code building genetic programming},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MetaSR: A meta-learning approach to fitness formulation for
frequency-aware symbolic regression. <em>GECCO</em>, 878–886. (<a
href="https://doi.org/10.1145/3638529.3654096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {State-of-the-art Symbolic Regression (SR) algorithms employ evolutionary techniques to fulfill the task of generating a concise mathematical expression that fulfills an objective. A common objective is to fit to a dataset of input-output pairs, in which the faithfulness of a predicted output to the actual output is used as the fitness measure (e.g., R-squared). In many datasets, among the candidate expressions evaluated, there tends to be a large number of pseudo-expressions, referring to expressions that achieve high fitness but do not resemble the ground-truth equation. These pseudo-expressions decrease the equation recovery rate of SR algorithms. To formulate novel fitness measures that function as better discriminators of the ground-truth equation, we introduce a novel meta-learning approach to SR, MetaSR, in which we utilize SR itself to discover new fitness measures that can be complex combinations of existing base measures. In this paper, we focus on frequency-aware symbolic regression, where the fitness can depend on the frequency domain. We show that our new fitness measures better discriminate the ground-truth equation from other equations and demonstrate the improved performance of our method against existing algorithms.},
  archive   = {C_GECCO},
  author    = {Fong, Kei Sen and Motani, Mehul},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654096},
  pages     = {878–886},
  title     = {MetaSR: A meta-learning approach to fitness formulation for frequency-aware symbolic regression},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the nature of the phenotype in tree genetic programming.
<em>GECCO</em>, 868–877. (<a
href="https://doi.org/10.1145/3638529.3654129">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this contribution, we discuss the basic concepts of genotypes and phenotypes in tree-based GP (TGP), and then analyze their behavior using five real-world datasets. We show that TGP exhibits the same behavior that we can observe in other GP representations: At the genotypic level trees show frequently unchecked growth with seemingly ineffective code, but on the phenotypic level, much smaller trees can be observed. To generate phenotypes, we provide a unique technique for removing semantically ineffective code from GP trees. The approach extracts considerably simpler phenotypes while not being limited to local operations in the genotype. We generalize this transformation based on a problem-independent parameter that enables a further simplification of the exact phenotype by coarse-graining to produce approximate phenotypes. The concept of these phenotypes (exact and approximate) allows us to clarify what evolved solutions truly predict, making GP models considered at the phenotypic level much better interpretable.},
  archive   = {C_GECCO},
  author    = {Banzhaf, Wolfgang and Bakurov, Illya},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654129},
  pages     = {868–877},
  title     = {On the nature of the phenotype in tree genetic programming},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A functional analysis approach to symbolic regression.
<em>GECCO</em>, 859–867. (<a
href="https://doi.org/10.1145/3638529.3654079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Symbolic regression (SR) poses a significant challenge for randomized search heuristics due to its reliance on the synthesis of expressions for input-output mappings. Although traditional genetic programming (GP) algorithms have achieved success in various domains, they exhibit limited performance when tree-based representations are used for SR. To address these limitations, we introduce a novel SR approach called Fourier Tree Growing (FTG) that draws insights from functional analysis. This new perspective enables us to perform optimization directly in a different space, thus avoiding intricate symbolic expressions. Our proposed algorithm exhibits significant performance improvements over traditional GP methods on a range of classical one-dimensional benchmarking problems. To identify and explain the limiting factors of GP and FTG, we perform experiments on a large-scale polynomials benchmark with high-order polynomials up to degree 100. To the best of the authors&#39; knowledge, this work represents the pioneering application of functional analysis in addressing SR problems. The superior performance of the proposed algorithm and insights into the limitations of GP open the way for further advancing GP for SR and related areas of explainable machine learning.},
  archive   = {C_GECCO},
  author    = {Antonov, Kirill and Kalkreuth, Roman and Yang, Kaifeng and B\&quot;{a}ck, Thomas and Stein, Niki and Kononova, Anna},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654079},
  pages     = {859–867},
  title     = {A functional analysis approach to symbolic regression},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distance-targeting mutation operator for evolutionary design
of 3D structures. <em>GECCO</em>, 850–858. (<a
href="https://doi.org/10.1145/3638529.3654060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Evolutionary design of 3D structures - an automated design by the methods of evolutionary algorithms - is a hard optimization problem. One of the contributing factors is a complex genotype-to-phenotype mapping often associated with the genetic representations of the designs. In such case, the genetic operators may exhibit low locality, i.e., a small change introduced in a genotype may result in a significant change in the phenotype and its fitness, hampering the search process. To overcome this challenge in evolutionary design, we introduce the Distance-Targeting Mutation Operator (DTM). The aim of this operator is to create offspring whose distance to the parent solution, according to a selected dissimilarity measure, approximates a predefined value. We compare the performance of the DTM operator to the performance of the mutation operator without parent-offspring distance control in a series of evolutionary experiments. We use different genetic representations, dissimilarity measures, and optimization goals, including velocity and height of active and passive 3D structures. The introduced DTM operator outperforms the standard one in terms of best fitness in most of the considered cases.},
  archive   = {C_GECCO},
  author    = {Komosinski, Maciej and Mensfelt, Agnieszka},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654060},
  pages     = {850–858},
  title     = {Distance-targeting mutation operator for evolutionary design of 3D structures},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A self-adaptive coevolutionary algorithm. <em>GECCO</em>,
841–849. (<a href="https://doi.org/10.1145/3638529.3654132">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Coevolutionary algorithms are helpful computational abstractions of adversarial behavior and they demonstrate multiple ways that populations of competing adversaries influence one another. We introduce the ability for each competitor&#39;s mutation rate to evolve through self-adaptation. Because dynamic environments are frequently addressed with self-adaptation, we set up dynamic problem environments to investigate the impact of this ability. For a simple bilinear problem, a sensitivity analysis of the adaptive method&#39;s parameters reveals that it is robust over a range of multiplicative rate factors, when the rate is changed up or down with equal probability. An empirical study determines that each population&#39;s mutation rates converge to values close to the error threshold. Mutation rate dynamics are complex when both populations adapt their rates. Large scale empirical self-adaptation results reveal that both reasonable solutions and rates can be found. This addresses the challenge of selecting ideal static mutation rates in coevolutionary algorithms. The algorithm&#39;s payoffs are also robust. They are rarely poor and frequently they are as high as the payoff of the static rate to which they converge. On rare runs, they are higher.},
  archive   = {C_GECCO},
  author    = {Hevia Fajardo, Mario Alejandro and Hemberg, Erik and Toutouh, Jamal and O&#39;Reilly, Una-May and Lehre, Per Kristian},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654132},
  pages     = {841–849},
  title     = {A self-adaptive coevolutionary algorithm},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Lamarckian co-design of soft robots via transfer learning.
<em>GECCO</em>, 832–840. (<a
href="https://doi.org/10.1145/3638529.3654180">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the realm of robot design, co-design aims to optimize both the structure and the controller of a robot concurrently. One approach integrates genetic algorithms to optimize the soft robot&#39;s structure with deep reinforcement learning for the controller. A significant challenge in this approach is the inheritance of the controller due to the mismatch of the sensors and actuators of the robots across generations. In this study, we propose a Lamarckian co-design method to inherit the controller optimized by deep reinforcement learning through transfer learning. In experimental evaluations through the Evogym benchmark, we demonstrate that our proposed method achieves an average reduction of 41.7\% in the optimization time for robots compared to existing methods and concurrently leads to an average performance improvement of 118.5\%. Furthermore, we show that combining the inheritance of controllers with the crossover of structure genomes from two robots allows for additional reductions in optimization time and improvements in performance in several tasks.},
  archive   = {C_GECCO},
  author    = {Harada, Kazuaki and Iba, Hitoshi},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654180},
  pages     = {832–840},
  title     = {Lamarckian co-design of soft robots via transfer learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generative design through quality-diversity data synthesis
and language models. <em>GECCO</em>, 823–831. (<a
href="https://doi.org/10.1145/3638529.3654138">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Two fundamental challenges face generative models in engineering applications: the acquisition of high-performing, diverse datasets, and the adherence to precise constraints in generated designs. We propose a novel approach combining optimization, constraint satisfaction, and language models to tackle these challenges in architectural design. Our method uses Quality-Diversity (QD) to generate a diverse, high-performing dataset. We then fine-tune a language model with this dataset to generate high-level designs. These designs are then refined into detailed, constraint-compliant layouts using the Wave Function Collapse algorithm. Our system demonstrates reliable adherence to textual guidance, enabling the generation of layouts with targeted architectural and performance features. Crucially, our results indicate that data synthesized through the evolutionary search of QD not only improves overall model performance but is essential for the model&#39;s ability to closely adhere to textual guidance. This improvement underscores the pivotal role evolutionary computation can play in creating the datasets key to training generative models for design. Web article at https://tilegpt.github.io},
  archive   = {C_GECCO},
  author    = {Gaier, Adam and Stoddart, James and Villaggi, Lorenzo and Sudhakaran, Shyam},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654138},
  pages     = {823–831},
  title     = {Generative design through quality-diversity data synthesis and language models},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Applying a quantum annealer to the traffic assignment
problem. <em>GECCO</em>, 814–822. (<a
href="https://doi.org/10.1145/3638529.3654131">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Traffic Assignment Problem (TAP) is a complex transportation optimisation problem typically solved using meta-heuristics on classical computers. Quantum computers, despite being a nascent technology, have the potential to significantly speed up computation by exploiting quantum parallelism. A quantum annealer (QA) is a quantum computer tailored to solve combinatorial optimisation problems formulated as a Quadratic Unconstrained Binary Optimisation (QUBO). Formulating complex optimisation problems as QUBO is an open challenge. This paper derives a new QUBO formulation for TAP by employing a streamlined methodology of general applicability. It also attempts a direct comparison at solving TAP encompassing a QA (D-WAVE), a hybrid quantum-classical algorithm, and classical methods including Simulated Annealing and Genetic Algorithms. This comparison is difficult and seldom done due to the inherent differences between quantum and classic hardware. As expected from the current quantum technology, our results show that a pure QA suffers from significant noise in qubits and requires significant additional computational time, although we show that the time required solely by the QPU does not increase with problem size. We also show that the hybrid QA mitigates these noise issues and is on a par with traditional methods.},
  archive   = {C_GECCO},
  author    = {Chitty, Darren M. and Charles, James and Moraglio, Alberto and Keedwell, Ed},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654131},
  pages     = {814–822},
  title     = {Applying a quantum annealer to the traffic assignment problem},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Late bloomers, first glances, second chances: Exploration of
the mechanisms behind fitness diversity. <em>GECCO</em>, 805–813. (<a
href="https://doi.org/10.1145/3638529.3654168">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Fitness diversity is an idea in the field of evolutionary algorithms, which calls for supporting the evolution of solutions at all fitness levels simultaneously. In some cases, this idea may even extend to cultivating the worst solutions. While this may seem counterintuitive, fitness diversity has shown its promise in algorithms such as Hierarchical Fair Competition and Convection Selection. Although these algorithms share many similarities, the role fitness diversity serves in each of them is different. In Hierarchical Fair Competition, fitness diversity facilitates a constant incorporation of novel genotypes into the solutions that are already good - a mechanism we dub First Glances - and discovery of solutions through the exploration of neutral networks of different fitness levels - which we name Late Bloomers. On the other hand, Convection Selection uses fitness diversity techniques to give broken solutions time and shelter necessary to cross larger valleys in the fitness landscape - a mechanism we call Second Chances. In this work, we compare these two algorithms and their respective mechanisms over a range of numerical and 3D structure design optimization problems. We analyze the extent to which their mechanisms are utilized, and measure the impact of these mechanisms on finding good solutions.},
  archive   = {C_GECCO},
  author    = {Aksenyuk, Sofya and Bujowski, Szymon and Komosinski, Maciej and Miazga, Konrad},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654168},
  pages     = {805–813},
  title     = {Late bloomers, first glances, second chances: Exploration of the mechanisms behind fitness diversity},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mixed binomial distributions for binary mutation operators.
<em>GECCO</em>, 796–804. (<a
href="https://doi.org/10.1145/3638529.3654010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Mutation operators are crucial for evolutionary algorithms to make progress through a search landscape. Sometimes a mutation strategy that works in one part of the landscape is less effective in other regions of the landscape. If nothing is known about the best mutation operator, many strategies (such as self-adaptation, heavy-tailed mutation, variable neighborhood search) exist to overcome this. However, in some cases, some limited information may be available, either a priori or after probing. In this paper, we study the setting of a mixture of binomial distributions for pseudo-Boolean optimization. We show that, when a limited amount of information is available, evolutionary algorithms using mutation based on a mixture of binomial distributions can hill-climb and escape local optima efficiently.},
  archive   = {C_GECCO},
  author    = {Aboutaib, Brahim and Sutton, Andrew M.},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654010},
  pages     = {796–804},
  title     = {Mixed binomial distributions for binary mutation operators},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). What performance indicators to use for self-adaptation in
multi-objective evolutionary algorithms. <em>GECCO</em>, 787–795. (<a
href="https://doi.org/10.1145/3638529.3654073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Parameter control has succeeded in accelerating the convergence process of evolutionary algorithms. While empirical and theoretical studies have shed light on the behavior of algorithms for single-objective optimization, little is known about how self-adaptation influences multi-objective evolutionary algorithms. In this work, we contribute (1) extensive experimental analysis of the Global Simple Evolutionary Multi-objective Algorithm (GSEMO) variants on classic problems, such as OneMinMax, LOTZ, COCZ, and (2) a novel version of GSEMO with self-adjusting mutation rates.To enable self-adaptation in GSEMO, we explore three techniques from single-objective optimization for self-adjusting mutation rates and use various performance metrics, such as hypervolume and inverted generational distance, to guide the adaptation. Our experiments show that adapting the mutation rate based on single-objective optimization and hypervolume can speed up the convergence of GSEMO. Moreover, we demonstrate that a GSEMO with self-adjusting mutation rates, which focuses on optimizing one of the objectives alternatively and adjusts the mutation rate for each solution individually, can outperform the GSEMO with static mutation rates across the tested problem.This work provides a comprehensive benchmarking study for MOEAs and complements existing theoretical runtime analysis. Our proposed algorithm addresses interesting issues for designing MOEAs for future practical applications.},
  archive   = {C_GECCO},
  author    = {Ye, Furong and Neumann, Frank and de Nobel, Jacob and Neumann, Aneta and B\&quot;{a}ck, Thomas},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654073},
  pages     = {787–795},
  title     = {What performance indicators to use for self-adaptation in multi-objective evolutionary algorithms},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Understanding search trajectories in parameter tuning.
<em>GECCO</em>, 778–786. (<a
href="https://doi.org/10.1145/3638529.3654146">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The search for proper parameter values is a key process for applying metaheuristic algorithms to solving complex optimization problems. Several specialized tuning methods have been proposed in the literature. One of the main difficulties when tuning parameters is the stochastic nature of metaheuristic algorithms and their requirement to solve problem instances with different features. In this work, we are interested in understanding different tuning process features using the Search Trajectory Networks approach. Here, a network of search processes can be constructed based on the solutions visited and the sequences of visits performed. Here, we extend the definitions of Search Trajectory Networks to tuning processes using two tuning methods from the literature: ParamILS and Evoca. We analyze the differences between the parameter tuning processes they perform and the incidence of their main hyper-parameters in these processes. From our results, we conclude the relevance of the number of pairs seed/instance for the search performed by ParamILS but not for Evoca regarding the number of visited configurations and the network&#39;s connectivity. Moreover, the evolutionary nature of Evoca promotes an exploratory behavior, traversing trajectories with fewer nodes in common compared to ParamILS.},
  archive   = {C_GECCO},
  author    = {Riveros, Mar\&#39;{\i}a and Rojas-Morales, Nicolas and Montero, Elizabeth and Ochoa, Gabriela},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654146},
  pages     = {778–786},
  title     = {Understanding search trajectories in parameter tuning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The role of the substrate in CA-based evolutionary
algorithms. <em>GECCO</em>, 768–777. (<a
href="https://doi.org/10.1145/3638529.3654112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Cellular automata (CA) are a convenient way to describe the distributed evolution of a dynamical system over discrete time and space. They can be used to express evolutionary algorithms (EAs), where the time is the flow of iterations and the space is where the population is hosted. When the CA evolves over a finite grid of cells, the substrate, each cell hosts an individual and the CA rule applies variation operators using the local and neighbor individuals. In this paper, we explore the possibility of enforcing a structure on the substrate. Instead of a flat toroidal grid, we use substrates where some empty cells never host individuals. These cells may act as barriers, slowing down the propagation of genetic traits and hence potentially improving the population diversity, eventually mitigating the risk of premature convergence. We experimentally evaluate the impact of these substrates using a simple CA-based EA on multi-modal and multi-objective problems. We find evidence of a positive impact in some circumstances; on multi-modal problems, convergence is slightly faster and the EA more often reaches all the targets.},
  archive   = {C_GECCO},
  author    = {Pietropolli, Gloria and Nichele, Stefano and Medvet, Eric},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654112},
  pages     = {768–777},
  title     = {The role of the substrate in CA-based evolutionary algorithms},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Promoting two-sided fairness in dynamic vehicle routing
problems. <em>GECCO</em>, 759–767. (<a
href="https://doi.org/10.1145/3638529.3654207">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Dynamic Vehicle Routing Problem (DVRP), is an extension of the classic Vehicle Routing Problem (VRP), which is a fundamental problem in logistics and transportation. Typically, DVRPs involve two stakeholders: service providers that deliver services to customers and customers who raise requests from different locations. Many real-world applications can be formulated as DVRP such as ridesharing and non-compliance capture. Apart from original objectives like optimising total utility or efficiency, DVRP should also consider fairness for all parties. Unfairness can induce service providers and customers to give up on the systems, leading to negative financial and social impacts. However, most existing DVRP-related applications focus on improving fairness from a single side, and there have been few works considering two-sided fairness and utility optimisation concurrently. To this end, we propose a novel framework, a Two-sided Fairness-aware Genetic Algorithm (named 2FairGA), which expands the genetic algorithm from the original objective solely focusing on utility to multi-objectives that incorporate two-sided fairness. Subsequently, the impact of injecting two fairness definitions into the utility-focused model and the correlation between any pair of the three objectives are explored. Extensive experiments demonstrate the superiority of our proposed framework compared to the state-of-the-art.},
  archive   = {C_GECCO},
  author    = {Kang, Yufan and Zhang, Rongsheng and Shao, Wei and Salim, Flora and Chan, Jeffrey},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654207},
  pages     = {759–767},
  title     = {Promoting two-sided fairness in dynamic vehicle routing problems},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Federated genetic algorithm: Two-layer privacy-preserving
trajectory data publishing. <em>GECCO</em>, 749–758. (<a
href="https://doi.org/10.1145/3638529.3654200">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Nowadays, trajectory data is widely available and used in various real-world applications such as urban planning, navigation services, and location-based services. However, publishing trajectory data can potentially leak sensitive information about identity, personal profiles, and social relationships, and requires privacy protection. This paper focuses on optimizing Privacy-Preserving Trajectory Data Publishing (PP-TDP) problems, addressing the limitations of existing techniques in the trade-off between privacy protection and information preservation. We propose the Federated Genetic Algorithm (FGA) in this paper, aiming to achieve better local privacy protection and global information preservation. FGA consists of multiple local optimizers and a single global optimizer. The parallel local optimizer enables the local data center to retain the original trajectory data and share only the locally anonymized outcomes. The global optimizer collects the local anonymized outcomes and further optimizes the preservation of information while achieving comprehensive privacy protection. To optimize the discrete-domain PP-TDP problems more efficiently, this paper proposes a grouping-based strategy, an intersection-based crossover operation, and a complement-based mutation operation. Experimental results demonstrate that FGA outperforms its competitors in terms of solution accuracy and search efficiency.},
  archive   = {C_GECCO},
  author    = {Ge, Yong-Feng and Wang, Hua and Cao, Jinli and Zhang, Yanchun and Kambourakis, Georgios},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654200},
  pages     = {749–758},
  title     = {Federated genetic algorithm: Two-layer privacy-preserving trajectory data publishing},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reinforcing inter-class dependencies in the asymmetric
island model. <em>GECCO</em>, 740–748. (<a
href="https://doi.org/10.1145/3638529.3654213">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multiagent learning allows agents to learn cooperative behaviors necessary to accomplish team objectives. However, coordination requires agents to learn diverse behaviors that work well as part of a team, a task made more difficult by all agents simultaneously learning their own individual behaviors. This is made more challenging when there are multiple classes of asymmetric agents in the system with differing capabilities that work together as a team. The Asymmetric Island Model alleviates these difficulties by simultaneously optimizing for class-specific and team-wide behaviors as independent processes that enable agents to discover and refine optimal joint-behaviors. However, agents learn to optimize agent-specific behaviors in isolation from other agent classes, leading them to learn egocentric behaviors that are potentially sub-optimal when paired with other agent classes. This work introduces Reinforced Asymmetric Island Model (RAIM), a framework for explicitly reinforcing closely dependent inter-class agent behaviors. When optimizing the class-specific behaviors, agents learn alongside stationary representations of other classes, allowing them to efficiently optimize class-specific behaviors that are conditioned on the expectation of the behaviors of the complementary agent classes. Experiments in an asymmetric harvest environment highlight the effectiveness of our method in learning robust inter-agent behaviors that can adapt to diverse environment dynamics.},
  archive   = {C_GECCO},
  author    = {Festa, Andrew and Dixit, Gaurav and Tumer, Kagan},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654213},
  pages     = {740–748},
  title     = {Reinforcing inter-class dependencies in the asymmetric island model},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CMA-ES with adaptive reevaluation for multiplicative noise.
<em>GECCO</em>, 731–739. (<a
href="https://doi.org/10.1145/3638529.3654182">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The covariance matrix adaptation evolution strategy (CMA-ES) is a powerful optimization method for continuous black-box optimization problems. Several noise-handling methods have been proposed to bring out the optimization performance of the CMA-ES on noisy objective functions. The adaptations of the population size and the learning rate are two major approaches that perform well under additive Gaussian noise. The reevaluation technique is another technique that evaluates each solution multiple times. In this paper, we discuss the difference between those methods from the perspective of stochastic relaxation that considers the maximization of the expected utility function. We derive that the set of maximizers of the noise-independent utility, which is used in the reevaluation technique, certainly contains the optimal solution, while the noise-dependent utility, which is used in the population size and leaning rate adaptations, does not satisfy it under multiplicative noise. Based on the discussion, we develop the reevaluation adaptation CMA-ES (RA-CMA-ES), which computes two update directions using half of the evaluations and adapts the number of reevaluations based on the estimated correlation of those two update directions. The numerical simulation shows that the RA-CMA-ES outperforms the comparative method under multiplicative noise, maintaining competitive performance under additive noise.},
  archive   = {C_GECCO},
  author    = {Uchida, Kento and Nishihara, Kenta and Shirakawa, Shinichi},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654182},
  pages     = {731–739},
  title     = {CMA-ES with adaptive reevaluation for multiplicative noise},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CMA-ES for safe optimization. <em>GECCO</em>, 722–730. (<a
href="https://doi.org/10.1145/3638529.3654193">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In several real-world applications in medical and control engineering, there are unsafe solutions whose evaluations involve inherent risk. This optimization setting is known as safe optimization and formulated as a specialized type of constrained optimization problem with constraints for safety functions. Safe optimization requires performing efficient optimization without evaluating unsafe solutions. A few studies have proposed the optimization methods for safe optimization based on Bayesian optimization and the evolutionary algorithm. However, Bayesian optimization-based methods often struggle to achieve superior solutions, and the evolutionary algorithm-based method fails to effectively reduce unsafe evaluations. This study focuses on CMA-ES as an efficient evolutionary algorithm and proposes an optimization method termed safe CMA-ES. The safe CMA-ES is designed to achieve both safety and efficiency in safe optimization. The safe CMA-ES estimates the Lipschitz constants of safety functions transformed with the distribution parameters using the maximum norm of the gradient in Gaussian process regression. Subsequently, the safe CMA-ES projects the samples to the nearest point in the safe region constructed with the estimated Lipschitz constants. The numerical simulation using the benchmark functions shows that the safe CMA-ES successfully performs optimization, suppressing the unsafe evaluations, while the existing methods struggle to significantly reduce the unsafe evaluations.},
  archive   = {C_GECCO},
  author    = {Uchida, Kento and Hamano, Ryoki and Nomura, Masahiro and Saito, Shota and Shirakawa, Shinichi},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654193},
  pages     = {722–730},
  title     = {CMA-ES for safe optimization},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Benchmarking parameter control methods in differential
evolution for mixed-integer black-box optimization. <em>GECCO</em>,
712–721. (<a href="https://doi.org/10.1145/3638529.3654019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Differential evolution (DE) generally requires parameter control methods (PCMs) for the scale factor and crossover rate. Although a better understanding of PCMs provides a useful clue to designing an efficient DE, their effectiveness is poorly understood in mixed-integer black-box optimization. In this context, this paper benchmarks PCMs in DE on the mixed-integer black-box optimization benchmarking function (bbob-mixint) suite in a componentwise manner. First, we demonstrate that the best PCM significantly depends on the combination of the mutation strategy and repair method. Although the PCM of SHADE is state-of-the-art for numerical black-box optimization, our results show its poor performance for mixed-integer black-box optimization. In contrast, our results show that some simple PCMs (e.g., the PCM of CoDE) perform the best in most cases. Then, we demonstrate that a DE with a suitable PCM performs significantly better than CMA-ES with integer handling for larger budgets of function evaluations. Finally, we show how the adaptation in the PCM of SHADE fails.},
  archive   = {C_GECCO},
  author    = {Tanabe, Ryoji},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654019},
  pages     = {712–721},
  title     = {Benchmarking parameter control methods in differential evolution for mixed-integer black-box optimization},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Direct augmented lagrangian evolution strategies.
<em>GECCO</em>, 703–711. (<a
href="https://doi.org/10.1145/3638529.3654012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Existing evolutionary and swarm based algorithms that employ augmented Lagrangian techniques to solve constrained black-box optimization problems update the Lagrange multipliers using either tailored heuristics or variations of the prescription underlying the method of multipliers. We introduce an evolution strategy relying on an exact Lagrangian update instead, determining multiplier values and penalties from population based estimates of derivative related values. Numerical experiments on multiple test problems illustrate the potential of the approach.},
  archive   = {C_GECCO},
  author    = {Porter, Jeremy and Arnold, Dirk V.},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654012},
  pages     = {703–711},
  title     = {Direct augmented lagrangian evolution strategies},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sign-averaging covariance matrix adaptation evolution
strategy. <em>GECCO</em>, 694–702. (<a
href="https://doi.org/10.1145/3638529.3654065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In black-box optimization, the user inevitably encounters noise in an objective function. Many noise treatment techniques have been developed to properly evaluate the effectiveness of solutions in the optimization process. A noise treatment called sign averaging was proposed recently, and it is proved that the adverse effects of noise can be reduced and the ranking of the candidate solutions on the median of the objective function can be estimated, even when the mean of the objective function is not well-defined. Although a theoretical guarantee exists, empirical studies on sign averaging are yet to be conducted. In this study, we implemented sign averaging in a covariance matrix adaptation evolution strategy, named the SA-CMA-ES, with an adaptive mechanism controlling the strength of the noise treatment. We experimentally demonstrated that 1) the SA-CMA-ES successfully continues to lower the median of the objective function given more budgets and is more sample efficient than the SA-CMA-ES without the adaptive mechanism for sign averaging; 2) the SA-CMA-ES is competitive with the UH-CMA-ES with Monte-Carlo median estimation and that with conventional averaging for optimizing the mean and median, and it is better than that with conventional averaging when the variance of the objective function is not well-defined.},
  archive   = {C_GECCO},
  author    = {Morinaga, Daiki and Akimoto, Youhei},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654065},
  pages     = {694–702},
  title     = {Sign-averaging covariance matrix adaptation evolution strategy},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RLEMMO: Evolutionary multimodal optimization assisted by
deep reinforcement learning. <em>GECCO</em>, 683–693. (<a
href="https://doi.org/10.1145/3638529.3653995">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Solving multimodal optimization problems (MMOP) requires finding all optimal solutions, which is challenging in limited function evaluations. Although existing works strike the balance of exploration and exploitation through hand-crafted adaptive strategies, they require certain expert knowledge, hence inflexible to deal with MMOP with different properties. In this paper, we propose RLEMMO, a Meta-Black-Box Optimization framework, which maintains a population of solutions and incorporates a reinforcement learning agent for flexibly adjusting individual-level searching strategies to match the up-to-date optimization status, hence boosting the search performance on MMOP. Concretely, we encode landscape properties and evolution path information into each individual and then leverage attention networks to advance population information sharing. With a novel reward mechanism that encourages both quality and diversity, RLEMMO can be effectively trained using a policy gradient algorithm. The experimental results on the CEC2013 MMOP benchmark underscore the competitive optimization performance of RLEMMO against several strong baselines.},
  archive   = {C_GECCO},
  author    = {Lian, Hongqiao and Ma, Zeyuan and Guo, Hongshu and Huang, Ting and Gong, Yue-Jiao},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3653995},
  pages     = {683–693},
  title     = {RLEMMO: Evolutionary multimodal optimization assisted by deep reinforcement learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Density descent for diversity optimization. <em>GECCO</em>,
674–682. (<a href="https://doi.org/10.1145/3638529.3654001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Diversity optimization seeks to discover a set of solutions that elicit diverse features. Prior work has proposed Novelty Search (NS), which, given a current set of solutions, seeks to expand the set by finding points in areas of low density in the feature space. However, to estimate density, NS relies on a heuristic that considers the k-nearest neighbors of the search point in the feature space, which yields a weaker stability guarantee. We propose Density Descent Search (DDS), an algorithm that explores the feature space via CMA-ES on a continuous density estimate of the feature space that also provides a stronger stability guarantee. We experiment with DDS and two density estimation methods: kernel density estimation (KDE) and continuous normalizing flow (CNF). On several standard diversity optimization benchmarks, DDS outperforms NS, the recently proposed MAP-Annealing algorithm, and other state-of-the-art baselines. Additionally, we prove that DDS with KDE provides stronger stability guarantees than NS, making it more suitable for adaptive optimizers. Furthermore, we prove that NS is a special case of DDS that descends a KDE of the feature space.},
  archive   = {C_GECCO},
  author    = {Lee, David H. and Palaparthi, Anishalakshmi and Fontaine, Matthew C. and Tjanaka, Bryon and Nikolaidis, Stefanos},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654001},
  pages     = {674–682},
  title     = {Density descent for diversity optimization},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Overlapping cooperative co-evolution for overlapping
large-scale global optimization problems. <em>GECCO</em>, 665–673. (<a
href="https://doi.org/10.1145/3638529.3654171">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {One of the main approaches for solving Large-Scale Global Optimization (LSGO) problems is embedding a decomposition strategy into a Cooperative Co-Evolution (CC) framework. Decomposing an LSGO problem into smaller subproblems and optimizing them separately using a CC framework was shown to be effective when a considered problem is partially separable. Components in CC frameworks are usually disjoint. Thus, the existence of the perfect decomposition of such problems allows of the optimization of independent components. However, for overlapping problems, the perfect, unique decomposition does not exist due to the existence of shared variables. Despite this, each variable is usually assigned to a single component, and the assignment does not change during a whole framework run. In this paper, we propose a new CC framework that allows multiple assignments of shared variables. Allocating computational resources to each of its components is influenced by other components that share variables with it. According to experimental results, our proposed method outperforms the state-of-the-art LSGO-dedicated optimization methods, including other CC frameworks, when overlapping LSGO problems are considered.},
  archive   = {C_GECCO},
  author    = {Komarnicki, Marcin Michal and Przewozniczek, Michal Witold and Tin\&#39;{o}s, Renato and Li, Xiaodong},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654171},
  pages     = {665–673},
  title     = {Overlapping cooperative co-evolution for overlapping large-scale global optimization problems},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CatCMA: Stochastic optimization for mixed-category problems.
<em>GECCO</em>, 656–664. (<a
href="https://doi.org/10.1145/3638529.3654198">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Black-box optimization problems often require simultaneously optimizing different types of variables, such as continuous, integer, and categorical variables. Unlike integer variables, categorical variables do not necessarily have a meaningful order, and the discretization approach of continuous variables does not work well. Although several Bayesian optimization methods can deal with mixed-category black-box optimization (MC-BBO), they suffer from a lack of scalability to high-dimensional problems and internal computational cost. This paper proposes CatCMA, a stochastic optimization method for MC-BBO problems, which employs the joint probability distribution of multivariate Gaussian and categorical distributions as the search distribution. CatCMA updates the parameters of the joint probability distribution in the natural gradient direction. CatCMA also incorporates the acceleration techniques used in the covariance matrix adaptation evolution strategy (CMA-ES) and the stochastic natural gradient method, such as step-size adaptation and learning rate adaptation. In addition, we restrict the ranges of the categorical distribution parameters by margin to prevent premature convergence and analytically derive a promising margin setting. Numerical experiments show that the performance of CatCMA is superior and more robust to problem dimensions compared to state-of-the-art Bayesian optimization algorithms.},
  archive   = {C_GECCO},
  author    = {Hamano, Ryoki and Saito, Shota and Nomura, Masahiro and Uchida, Kento and Shirakawa, Shinichi},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654198},
  pages     = {656–664},
  title     = {CatCMA: Stochastic optimization for mixed-category problems},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fitness-based linkage learning and maximum-clique
conditional linkage modelling for gray-box optimization with RV-GOMEA.
<em>GECCO</em>, 647–655. (<a
href="https://doi.org/10.1145/3638529.3654103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {For many real-world optimization problems it is possible to perform partial evaluations, meaning that the impact of changing a few variables on a solution&#39;s fitness can be computed very efficiently. It has been shown that such partial evaluations can be excellently leveraged by the Real-Valued Gene-pool Optimal Mixing Evolutionary Algorithm (RV-GOMEA) that uses a linkage model to capture dependencies between problem variables. Recently, conditional linkage models were introduced for RV-GOMEA, expanding its state-of-the-art performance even to problems with overlapping dependencies. However, that work assumed that the dependency structure is known a priori. Fitness-based linkage learning techniques have previously been used to detect dependencies during optimization, but only for non-conditional linkage models. In this work, we combine fitness-based linkage learning and conditional linkage modelling in RV-GOMEA. In addition, we propose a new way to model overlapping dependencies in conditional linkage models to maximize the joint sampling of fully interdependent groups of variables. We compare the resulting novel variant of RV-GOMEA to other variants of RV-GOMEA and VkD-CMA on 12 problems with varying degree of overlapping dependencies. We find that the new RV-GOMEA not only performs best on most problems, also the overhead of learning the conditional linkage models during optimization is often negligible.},
  archive   = {C_GECCO},
  author    = {Andreadis, Georgios and Alderliesten, Tanja and Bosman, Peter A. N.},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654103},
  pages     = {647–655},
  title     = {Fitness-based linkage learning and maximum-clique conditional linkage modelling for gray-box optimization with RV-GOMEA},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Extending pareto dominance for multi-constraints
satisfaction and multi-performance enhancement in constrained
multi-objective optimization. <em>GECCO</em>, 639–646. (<a
href="https://doi.org/10.1145/3638529.3654005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-objective optimization problems (MOPs) in science and engineering frequently involve intricate multi-constraints. This paper extends the application of the Pareto dominance in MOPs on addressing complex multi-constraints and enhancing algorithmic conflicting multi-performance, such as convergence, diversity, and feasibility. The approach begins by identifying non-dominated constraints that closest approximate the actual constrained Pareto Front (CPF) through Pareto non-dominated sorting of every single constrained Pareto Front (SCPF). Subsequently, a Pareto non-dominated sorting multi-performance methodology is employed under the determined non-dominated constraints, considering convergence, diversity, and feasibility as competing objectives. Building upon extending the Pareto dominance approach for constrained multi-objective optimization (EPDCMO), this paper introduces a dual-population multi-archive optimization mechanism to optimize multiple constraints and performance simultaneously. The effectiveness of the proposed approach is validated through the evaluation of 23 constrained multi-objective problems (CMOPs) and practical applications in the domain of CMOPs. The results demonstrate the algorithm&#39;s capability to generate competitive solutions for MOPs characterized by multi-constraints.},
  archive   = {C_GECCO},
  author    = {Yu, Fan and Chen, Qun and Zhou, Jinlong},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654005},
  pages     = {639–646},
  title     = {Extending pareto dominance for multi-constraints satisfaction and multi-performance enhancement in constrained multi-objective optimization},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evolutionary preference sampling for pareto set learning.
<em>GECCO</em>, 630–638. (<a
href="https://doi.org/10.1145/3638529.3654024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, Pareto Set Learning (PSL) has been proposed for learning the entire Pareto set using a neural network. PSL employs preference vectors to scalarize multiple objectives, facilitating the learning of mappings from preference vectors to specific Pareto optimal solutions. Previous PSL methods have shown their effectiveness in solving artificial multi-objective optimization problems (MOPs) with uniform preference vector sampling. The quality of the learned Pareto set is influenced by the sampling strategy of the preference vector, and the sampling of the preference vector needs to be decided based on the Pareto front shape. However, a fixed preference sampling strategy cannot simultaneously adapt the Pareto front of multiple MOPs. To address this limitation, this paper proposes an Evolutionary Preference Sampling (EPS) strategy to efficiently sample preference vectors. Inspired by evolutionary algorithms, we consider preference sampling as an evolutionary process to generate preference vectors for neural network training. We integrate the EPS strategy into five advanced PSL methods. Extensive experiments demonstrate that our proposed method has a faster convergence speed than baseline algorithms on 7 testing problems. Our implementation is available at https://github.com/rG223/EPS.},
  archive   = {C_GECCO},
  author    = {Ye, Rongguang and Chen, Longcan and Zhang, Jinyuan and Ishibuchi, Hisao},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654024},
  pages     = {630–638},
  title     = {Evolutionary preference sampling for pareto set learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sampling-based pareto optimization for chance-constrained
monotone submodular problems. <em>GECCO</em>, 621–629. (<a
href="https://doi.org/10.1145/3638529.3654176">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently surrogate functions based on the tail inequalities were developed to evaluate the chance constraints in the context of evolutionary computation and several Pareto optimization algorithms using these surrogates were successfully applied in optimizing chance-constrained monotone submodular problems. However, the difference in performance between algorithms using the surrogates and those employing the direct sampling-based evaluation remains unclear. Within the paper, a sampling-based method is proposed to directly evaluate the chance constraint. Furthermore, to address the problems with more challenging settings, an enhanced GSEMO algorithm integrated with an adaptive sliding window, called ASW-GSEMO, is introduced. In the experiments, the ASW-GSEMO employing the sampling-based approach is tested on the chance-constrained version of the maximum coverage problem with different settings. Its results are compared with those from other algorithms using different surrogate functions. The experimental findings indicate that the ASW-GSEMO with the sampling-based evaluation approach outperforms other algorithms, highlighting that the performances of algorithms using different evaluation methods are comparable. Additionally, the behaviors of ASW-GSEMO are visualized to explain the distinctions between it and the algorithms utilizing the surrogate functions.},
  archive   = {C_GECCO},
  author    = {Yan, Xiankun and Neumann, Aneta and Neumann, Frank},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654176},
  pages     = {621–629},
  title     = {Sampling-based pareto optimization for chance-constrained monotone submodular problems},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An updated performance metric for preference-based
evolutionary multi-objective optimization algorithms. <em>GECCO</em>,
612–620. (<a href="https://doi.org/10.1145/3638529.3654031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Evolutionary multi-objective optimization (EMO) algorithms are widely used to solve problems involving multiple conflicting objectives. In general, these problems result in a well-distributed and diverse set of Pareto-optimal solutions, consisting of individual objective-optimal solutions at their extreme and various compromise objective solutions at their core. However, in practice, decision-makers (DMs) usually have certain pre-conceived preference information which may make a majority of the Pareto solution set uninteresting to the DMs. In such cases, DM&#39;s preference information can be utilized to update EMO algorithms to focus on the preferred part of the Pareto set, rather than the entire Pareto set. While EMO researchers have proposed preference-based EMO algorithms for this purpose, appropriate metrics to evaluate their performance have received lukewarm attention. In this paper, we critically analyze a recently proposed preference-based hypervolume (R-HV) metric for its sensitivity to handle various scenarios and propose an updated version to remedy the difficulties associated with it. The updated R-HV metric is then compared with the original R-HV metric on solutions obtained from a number of preference-based EMO algorithms. The suggestion of a more appropriate R-HV metric presented in this paper should encourage further research in preference-based multi-objective optimization.},
  archive   = {C_GECCO},
  author    = {Yadav, Deepanshu and Ramu, Palaniappan and Deb, Kalyanmoy},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654031},
  pages     = {612–620},
  title     = {An updated performance metric for preference-based evolutionary multi-objective optimization algorithms},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Approximating pareto local optimal solution networks.
<em>GECCO</em>, 603–611. (<a
href="https://doi.org/10.1145/3638529.3653999">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The design of automated landscape-aware techniques requires low-cost features that characterize the structure of the target optimization problem. This paper approximates network-based landscape models of multi-objective optimization problems, which were constructed by full search space enumeration in previous studies. Specifically, we propose a sampling method using dominance-based local search for constructing an approximation of the Pareto local optimal solution network (PLOS-net) and its variant, the compressed PLOS-net. Both models are valuable to visualize and compute features on the distribution of Pareto local optima. We conduct experiments with multi-objective nk-landscapes and compare the features of full-enumerated PLOS-nets with that of approximate PLOS-nets. We analyze the correlation between landscape features and the performance of well-established multi-objective evolutionary and local search algorithms. Our results show that approximated networks can predict algorithm performance and provide recommendation for algorithm selection with the same level of accuracy, even though they are much more computationally affordable compared to full-enumerated networks. We finally illustrate how the approximate PLOS-net scale to large-size instances.},
  archive   = {C_GECCO},
  author    = {Tanaka, Shoichiro and Ochoa, Gabriela and Liefooghe, Arnaud and Takadama, Keiki and Sato, Hiroyuki},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3653999},
  pages     = {603–611},
  title     = {Approximating pareto local optimal solution networks},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the robustness of lexicase selection to contradictory
objectives. <em>GECCO</em>, 594–602. (<a
href="https://doi.org/10.1145/3638529.3654215">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Lexicase and ϵ-lexicase selection are state of the art parent selection techniques for problems featuring multiple selection criteria. Originally, lexicase selection was developed for cases where these selection criteria are unlikely to be in conflict with each other, but preliminary work suggests it is also a highly effective many-objective optimization algorithm. However, to predict whether these results generalize, we must understand lexicase selection&#39;s performance on contradictory objectives. Prior work has shown mixed results on this question. Here, we develop theory identifying circumstances under which lexicase selection will succeed or fail to find a Pareto-optimal solution. To make this analysis tractable, we restrict our investigation to a theoretical problem with maximally contradictory objectives. Ultimately, we find that lexicase and ϵ-lexicase selection each have a region of parameter space where they are incapable of optimizing contradictory objectives. Outside of this region, however, they perform well despite the presence of contradictory objectives. Based on these findings, we propose theoretically-backed guidelines for parameter choice. Additionally, we identify other properties that may affect whether a many-objective optimization problem is a good fit for lexicase or ϵ-lexicase selection.},
  archive   = {C_GECCO},
  author    = {Shahbandegan, Shakiba and Dolson, Emily},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654215},
  pages     = {594–602},
  title     = {On the robustness of lexicase selection to contradictory objectives},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Gradient-guided local search for IGD/IGDPlus subset
selection. <em>GECCO</em>, 585–593. (<a
href="https://doi.org/10.1145/3638529.3654053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Subset selection is always a hot topic in the community of evolutionary multi-objective optimization (EMO) since it is used in mating selection, environmental selection, and final selection. In the first two scenarios, the task of subset selection algorithms is to select a subset from a small candidate set (e.g., population). However, in the last scenario, it is to select a subset from an unbounded archive with all non-dominated solutions examined during the evolutionary process. Most existing subset selection algorithms aim to improve the hypervolume of subsets (i.e., hypervolume subset selection) selected from the archive. However, only a few researchers work on the IGD and IGD+ (two well-known indicators) subset selection in the last scenario. In this paper, we propose a gradient-guided local search algorithm for IGD/IGD+ subset selection problems. The experimental results show that the proposed algorithm is much faster than the existing lazy greedy inclusion IGD/IGD+ subset selection algorithm, and the quality of the selected subsets is competitive with that selected by the existing greedy algorithms.},
  archive   = {C_GECCO},
  author    = {Nan, Yang and Ishibuchi, Hisao and Shu, Tianye and Shang, Ke},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654053},
  pages     = {585–593},
  title     = {Gradient-guided local search for IGD/IGDPlus subset selection},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Analysis of real-world constrained multi-objective problems
and performance comparison of multi-objective algorithms.
<em>GECCO</em>, 576–584. (<a
href="https://doi.org/10.1145/3638529.3653994">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Real-world multi-objective optimization problems usually have multiple constraints. To solve constrained multi-objective optimization problems (CMOPs), researchers have proposed various evolutionary multi-objective optimization (EMO) algorithms with constraint handling techniques. Those EMO algorithms explicitly or implicitly assume the existence of a large infeasible region in the objective space between initial solutions and the Pareto front. As a result, they use some special mechanisms to traverse such an infeasible region (e.g., push-and-pull search). However, it is not clear whether real-world CMOPs have similar characteristics. It is also unclear whether state-of-the-art EMO algorithms that proposed for artificial CMOPs work well on real-world CMOPs. In this paper, we examine the characteristics of some real-world CMOPs. We find that the examined real-world CMOPs have no large infeasible region near the Pareto front. We also compare the performance of some constrained EMO algorithms on artificial CMOPs and real-world CMOPs. Our experimental results show that performance comparison results on real-world CMOPs are clearly different from those on artificial CMOPs. It is also shown that some recently-proposed constrained EMO algorithms are outperformed by NSGA-II with the basic constraint domination principle when they are compared on real-world CMOPs.},
  archive   = {C_GECCO},
  author    = {Nan, Yang and Ishibuchi, Hisao and Shu, Tianye and Shang, Ke},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3653994},
  pages     = {576–584},
  title     = {Analysis of real-world constrained multi-objective problems and performance comparison of multi-objective algorithms},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GPU-accelerated evolutionary multiobjective optimization
using tensorized RVEA. <em>GECCO</em>, 566–575. (<a
href="https://doi.org/10.1145/3638529.3654223">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Evolutionary multiobjective optimization has witnessed remarkable progress during the past decades. However, existing algorithms often encounter computational challenges in large-scale scenarios, primarily attributed to the absence of hardware acceleration. In response, we introduce a Tensorized Reference Vector Guided Evolutionary Algorithm (TensorRVEA) for harnessing the advancements of GPU acceleration. In TensorRVEA, the key data structures and operators are fully transformed into tensor forms for leveraging GPU-based parallel computing. In numerical benchmark tests involving large-scale populations and problem dimensions, TensorRVEA consistently demonstrates high computational performance, achieving up to over 1000\texttimes{} speedups. Then, we applied TensorRVEA to the domain of multiobjective neuroevolution for addressing complex challenges in robotic control tasks. Furthermore, we assessed TensorRVEA&#39;s extensibility by altering several tensorized reproduction operators. Experimental results demonstrate promising scalability and robustness of TensorRVEA. Source codes are available at https://github.com/EMI-Group/tensorrvea.},
  archive   = {C_GECCO},
  author    = {Liang, Zhenyu and Jiang, Tao and Sun, Kebin and Cheng, Ran},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654223},
  pages     = {566–575},
  title     = {GPU-accelerated evolutionary multiobjective optimization using tensorized RVEA},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Transfer search directions among decomposed subtasks for
evolutionary multitasking in multiobjective optimization.
<em>GECCO</em>, 557–565. (<a
href="https://doi.org/10.1145/3638529.3653989">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Evolutionary multitasking has attracted much attention over the past years due to its inter-task knowledge transfer capability. In this area, multiobjective multitask optimization (MO-MTO), aims to handle multiple multiobjective optimization tasks faster and better simultaneously via population synergies among tasks. Existing multiobjective multitask evolutionary algorithms (MO-MTEAs) for MO-MTO mostly transfer positions, i.e., decision variables, which may invoke negative knowledge transfer on tasks with low optimal domain similarities. However, such low similarities are common in practice. To address this issue, this paper proposes a new MO-MTEA, named MTEA/D-TSD, which transfers search directions, rather than positions, among decomposed subtasks for MO-MTO. In addition to position-neighborhood in the decomposition method, MTEA/D-TSD constructs and adaptively updates the search-direction-neighborhood for each subtask. It transfers successful search directions among neighbor subtasks to accelerate population evolution. Moreover, to further improve the efficiency of knowledge transfer, a transfer rate self-adaptation strategy is designed for MTEA/D-TSD. Experimental results on MO-MTO benchmark problems and a real-world application of sensor coverage problems demonstrated the superior performance of MTEA/D-TSD against state-of-the-art MO-MTEAs.},
  archive   = {C_GECCO},
  author    = {Li, Yanchi and Gong, Wenyin and Gu, Qiong},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3653989},
  pages     = {557–565},
  title     = {Transfer search directions among decomposed subtasks for evolutionary multitasking in multiobjective optimization},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Empirical comparison between MOEAs and local search on
multi-objective combinatorial optimisation problems. <em>GECCO</em>,
547–556. (<a href="https://doi.org/10.1145/3638529.3654077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Local search has gained its popularity in addressing multi-objective combinatorial optimisation problems (MOCOPs) within the communities of evolutionary computation and operational research. The ease of defining the neighbourhood in discrete spaces of MOCOPs makes local search well-suited to conducting step-wise moves. On the other side, evolutionary algorithms are amongst very first choices in solving various multi-objective optimisation problems. Although most multi-objective evolutionary algorithms (MOEAs) are developed, tested and studied on the basis of continuous problems, when encountering a practical MOCOP, practitioners tend to resort to popular MOEAs. Therefore, a relevant question is that between MOEAs and local search heuristics, which one may be more suitable for MOCOPs. In this paper, we attempt to answer this question. We choose seven well-known &quot;baseline&quot; MOEAs and local search heuristics in the area and systematically study their behaviours on four MOCOPs. We find that, unsurprisingly, different search paradigms have their own sweet spots; it depends on problem types, problem settings and search budgets. However, surprisingly, there exists one search heuristic, SEMO, which can be seen as a &quot;transition&quot; between the two search paradigms (i.e., a simple MOEA or randomised local search), that performs consistently better than the other heuristics across all the settings.},
  archive   = {C_GECCO},
  author    = {Li, Miqing and Han, Xiaofeng and Chu, Xiaochen and Liang, Zimin},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654077},
  pages     = {547–556},
  title     = {Empirical comparison between MOEAs and local search on multi-objective combinatorial optimisation problems},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tasks scheduling with load balancing in fog computing: A
bi-level multi-objective optimization approach. <em>GECCO</em>, 538–546.
(<a href="https://doi.org/10.1145/3638529.3654069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Fog computing is characterized by its proximity to edge devices, allowing it to handle data near the source. This capability alleviates the computational burden on data centers and minimizes latency. Ensuring high throughput and reliability of services in Fog environments depends on the critical roles of load balancing of resources and task scheduling. A significant challenge in task scheduling is allocating tasks to optimal nodes. In this paper, we tackle the challenge posed by the dependency between optimally scheduled tasks and the optimal nodes for task scheduling and propose a novel bi-level multi-objective task scheduling approach. At the upper level, which pertains to task scheduling optimization, the objective functions include the minimization of makespan, cost, and energy. At the lower level, corresponding to load balancing optimization, the objective functions include the minimization of response time and maximization of resource utilization. Our approach is based on an Improved Multi-Objective Ant Colony algorithm (IMOACO). Simulation experiments using iFogSim confirm the performance of our approach and its advantage over existing algorithms, including heuristic and meta-heuristic approaches.},
  archive   = {C_GECCO},
  author    = {Kouka, Najwa and Piuri, Vincenzo and Samarati, Pierangela},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654069},
  pages     = {538–546},
  title     = {Tasks scheduling with load balancing in fog computing: A bi-level multi-objective optimization approach},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Innovation path: Discovering an ordered set of optimized
intermediate solutions from an existing to a desired solution.
<em>GECCO</em>, 529–537. (<a
href="https://doi.org/10.1145/3638529.3654051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In practice, there is often a need to modify an existing implemented solution in order to achieve a better performance or accommodate new demands or technologies. However, a new optimal solution for the updated problem may be quite different from the existing solution, thereby causing an apathy for its implementation involving large cost, changes, and efforts. For such scenarios, we propose a concept of an &quot;innovation path&quot; (IP) containing a sequence of intermediate solutions from the existing to the new target solution with gradual and controlled change from one to the next. To discover intermediate solutions of the IP simultaneously, we propose a bi-objective formulation of the original problem, so that Pareto-optimal solutions of the resulting bi-objective problem become the IP solutions. We demonstrate the working of the proposed approach on a number of single and two-objective test and engineering problems. Results are encouraging and suggest further research and application to make the proposed innovation path approach more efficient and practical.},
  archive   = {C_GECCO},
  author    = {Khan, Ahmer and Deb, Kalyanmoy},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654051},
  pages     = {529–537},
  title     = {Innovation path: Discovering an ordered set of optimized intermediate solutions from an existing to a desired solution},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Using 3-objective evolutionary algorithms for the dynamic
chance constrained knapsack problem. <em>GECCO</em>, 520–528. (<a
href="https://doi.org/10.1145/3638529.3654067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Real-world optimization problems often involve stochastic and dynamic components. Evolutionary algorithms are particularly effective in these scenarios, as they can easily adapt to uncertain and changing environments but often uncertainty and dynamic changes are studied in isolation. In this paper, we explore the use of 3-objective evolutionary algorithms for the chance constrained knapsack problem with dynamic constraints. In our setting, the weights of the items are stochastic and the knapsack&#39;s capacity changes over time. We introduce a 3-objective formulation that is able to deal with the stochastic and dynamic components at the same time and is independent of the confidence level required for the constraint. This new approach is then compared to the 2-objective formulation which is limited to a single confidence level. We evaluate the approach using two different multi-objective evolutionary algorithms (MOEAs), namely the global simple evolutionary multi-objective optimizer (GSEMO) and the multi-objective evolutionary algorithm based on decomposition (MOEA/D), across various benchmark scenarios. Our analysis highlights the advantages of the 3-objective formulation over the 2-objective formulation in addressing the dynamic chance constrained knapsack problem.},
  archive   = {C_GECCO},
  author    = {Hewa Pathiranage, Ishara and Neumann, Frank and Antipov, Denis and Neumann, Aneta},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654067},
  pages     = {520–528},
  title     = {Using 3-objective evolutionary algorithms for the dynamic chance constrained knapsack problem},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Performance of NSGA-III on multi-objective combinatorial
optimization problems heavily depends on its implementations.
<em>GECCO</em>, 511–519. (<a
href="https://doi.org/10.1145/3638529.3654004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Newly proposed many-objective algorithms have been almost always compared with NSGA-III for performance evaluation. Since the authors of the NSGA-III paper have not provided any source code, researchers usually use an available implementation in popular optimization platforms. This can lead to unreliable comparison results if different performance of NSGA-III is obtained depending on the choice of a platform. In this paper, we show that the implementations of NSGA-III are slightly different between the two most frequently used EMO optimization platforms: PlatEMO and pymoo. Then, we examine the effect of the implementation difference on the performance of NSGA-III in each platform. Our experimental results show that almost the same results are obtained from the two implementations on the frequently-used DTLZ test problems. However, our experimental results also show that clearly different results are obtained from the two implementations on multi-objective combinatorial optimization problems. Finally, we demonstrate that the weaker performance of the PlatEMO implementation of NSGA-III can be improved by replacing its normalization mechanism with the corresponding mechanism in Pymoo. That is, our experimental results show that small differences in the normalization mechanisms of the two implementations lead to large differences in their performance on multi-objective combinatorial optimization problems.},
  archive   = {C_GECCO},
  author    = {Gong, Cheng and Nan, Yang and Pang, Meng and Ishibuchi, Hisao and Zhang, Qingfu},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654004},
  pages     = {511–519},
  title     = {Performance of NSGA-III on multi-objective combinatorial optimization problems heavily depends on its implementations},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). User-preference based evolutionary algorithms for solving
multi-objective nonlinear minimum cost flow problems. <em>GECCO</em>,
502–510. (<a href="https://doi.org/10.1145/3638529.3654036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Network flow optimisation has various applications such as communication, transportation, computer networks and logistics. The minimum cost flow problem (MCFP) is the most common network flow problem, which can be formulated as a multi-objective optimisation, with multiple criteria such as time, cost, distance and risk. In many real-world scenarios, decision-makers (DMs) aim for solutions in a preferred region(s). Using a reference point(s) allows the algorithm to efficiently search in the vicinity of the preferred regions instead of the entire search space. This paper introduces evolutionary multi-objective algorithms (EMOs) by employing a novel probability tree-based representation scheme (denoted as PTbNSGA-II and PTbMOEA/D) to address multi-objective integer minimum cost flow problems (MOIMCFPs) incorporating nonlinear cost functions. We also propose user-preference based EMO algorithms to solve MOIMCFPs using preference information (denoted as r-PTbNSGA-II and R-PTbMOEA/D). Since the algorithms utilise preference-based information, they have significantly lower computational costs compared to those of conventional EMOs. The performance of the proposed methods is evaluated on a set of 30 MOIMCFP instances. The experimental results demonstrate the superiority of PTbNSGA-II over PTbMOEA/D in finding high-quality solutions as well as the superiority of r-PTbNSGA-II over R-PTbMOEA/D in efficiently finding the high-quality solutions close to the preferred region.},
  archive   = {C_GECCO},
  author    = {Ghasemishabankareh, Behrooz and Li, Xiaodong and Ozlen, Melih},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654036},
  pages     = {502–510},
  title     = {User-preference based evolutionary algorithms for solving multi-objective nonlinear minimum cost flow problems},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A block-coordinate descent EMO algorithm: Theoretical and
empirical analysis. <em>GECCO</em>, 493–501. (<a
href="https://doi.org/10.1145/3638529.3654169">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider whether conditions exist under which block-coordinate descent is asymptotically efficient in evolutionary multi-objective optimization, addressing an open problem. Block-coordinate descent, where an optimization problem is decomposed into k blocks of decision variables and each of the blocks is optimized (with the others fixed) in a sequence, is a technique used in some large-scale optimization problems such as airline scheduling, however its use in multi-objective optimization is less studied. We propose a block-coordinate version of GSEMO and compare its running time to the standard GSEMO algorithm. Theoretical and empirical results on a bi-objective test function, a variant of LOTZ, serve to demonstrate the existence of cases where block-coordinate descent is faster. The result may yield wider insights into this class of algorithms.},
  archive   = {C_GECCO},
  author    = {Doerr, Benjamin and Knowles, Joshua and Neumann, Aneta and Neumann, Frank},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654169},
  pages     = {493–501},
  title     = {A block-coordinate descent EMO algorithm: Theoretical and empirical analysis},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Illustrating the efficiency of popular evolutionary
multi-objective algorithms using runtime analysis. <em>GECCO</em>,
484–492. (<a href="https://doi.org/10.1145/3638529.3654177">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Runtime analysis has recently been applied to popular evolutionary multi-objective (EMO) algorithms like NSGA-II in order to establish a rigorous theoretical foundation. However, most analyses showed that these algorithms have the same performance guarantee as the simple (G)SEMO algorithm. To our knowledge, there are no runtime analyses showing an advantage of a popular EMO algorithm over the simple algorithm for deterministic problems.We propose such a problem and use it to showcase the superiority of popular EMO algorithms over (G)SEMO: OneTrapZeroTrap is a straightforward generalization of the well-known Trap function to two objectives. We prove that, while GSEMO requires at least nn expected fitness evaluations to optimise OneTrapZeroTrap, popular EMO algorithms NSGA-II, NSGA-III and SMS-EMOA, all enhanced with a mild diversity mechanism of avoiding genotype duplication, only require O(n log n) expected fitness evaluations. Our analysis reveals the importance of the key components in each of these sophisticated algorithms and contributes to a better understanding of their capabilities.},
  archive   = {C_GECCO},
  author    = {Dang, Duc-Cuong and Opris, Andre and Sudholt, Dirk},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654177},
  pages     = {484–492},
  title     = {Illustrating the efficiency of popular evolutionary multi-objective algorithms using runtime analysis},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing the convergence ability of evolutionary
multi-objective optimization algorithms with momentum. <em>GECCO</em>,
476–483. (<a href="https://doi.org/10.1145/3638529.3654072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {To improve the convergence ability of evolutionary multi-objective optimization algorithms (EMOAs), various strategies have been proposed. One effective strategy is to use good momentum from the previous generations to create new solutions. However, the definition of good momentum has not been carefully studied. In this paper, we propose five different definitions of good momentum for EMOAs. Then, we explain their integration into popular EMOAs such as NSGA-II, MOEA/D, and SMS-EMOA. Through computational experiments, we demonstrate that the use of an appropriate definition of good momentum greatly accelerates the convergence of EMOAs on both artificial test problems and real-world problems, particularly on large-scale problems.},
  archive   = {C_GECCO},
  author    = {Chen, Longcan and Pang, Lie Meng and Zhang, Qingfu and Ishibuchi, Hisao},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654072},
  pages     = {476–483},
  title     = {Enhancing the convergence ability of evolutionary multi-objective optimization algorithms with momentum},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A detailed experimental analysis of evolutionary diversity
optimization for OneMinMax. <em>GECCO</em>, 467–475. (<a
href="https://doi.org/10.1145/3638529.3654082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Real-world optimization problems often require finding not only one good solution, but a diverse set of good solutions. Evolutionary algorithms (EAs) have been shown to suit well for such a task. However our theoretical understanding of their behavior remains unsatisfying, especially in the multi-objective domain.In this paper, we study how one of such EAs, the GSEMOD, finds a diverse population when optimizing the bi-objective benchmark problem OneMinMax. We show empirically that the expected runtime of this algorithm grows with problem size n approximately as fast as n2 ln(n). We prove that there exists a sub-optimal population from which the algorithm cannot reach the optimal diversity using only one-bit flips, which suggests that we need to use a mutation operator which can make two-bits flips (e.g., the standard bit mutation) to have a finite expected runtime. We complement these results with an empirical study of the population dynamics by observing how the Hamming distances between the individuals which are neighbors on the Pareto front change during the optimization.},
  archive   = {C_GECCO},
  author    = {Antipov, Denis and Neumann, Aneta and Neumann, Frank},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654082},
  pages     = {467–475},
  title     = {A detailed experimental analysis of evolutionary diversity optimization for OneMinMax},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing algorithm performance prediction in constrained
multiobjective optimization using additional training problems.
<em>GECCO</em>, 458–466. (<a
href="https://doi.org/10.1145/3638529.3654098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A research problem studied extensively in recent years is the prediction of optimization algorithm performance. A common approach is using the landscape features of optimization problems to train machine learning models. These models are then used to predict algorithm performance. Due to the small number of constrained multiobjective optimization problems (CMOPs) available for benchmarking, training a machine learning model to predict algorithm performance is a hard task. To address this issue, this study uses the functions from the bbob and bbob-constrained benchmark problems to generate new CMOPs. These are then used as additional training examples for the machine learning models. Given the large number of generated CMOPs, the experiments in this study are limited to those with two objectives and two variables. The obtained results are promising. Using additional problems in the training phase improves the predictions in half of the defined classification tasks.},
  archive   = {C_GECCO},
  author    = {Andova, Andrejaana and Cork, Jordan N. and Tu\v{s}ar, Tea and Filipi\v{c}, Bogdan},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654098},
  pages     = {458–466},
  title     = {Enhancing algorithm performance prediction in constrained multiobjective optimization using additional training problems},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pixel logo attack: Embedding attacks as logo-like pixels.
<em>GECCO</em>, 449–457. (<a
href="https://doi.org/10.1145/3638529.3654231">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent research shows that deep neural networks make wrong predictions when faced with adversarial examples with small perturbations added. In the setting of white-box attack, it is easy to generate adversarial samples with high attack success rate through gradients. But in reality, gradients are usually unavailable. At present, most black-box attack achieves the purpose of the attack by adding small perturbations, the intensity of the perturbation and the attack success rate are a kind of trade off. However, the noise added by most methods is meaningless. This paper introduces a novel adversarial attack algorithm called Pixel Logo Attack (PLA), which rationalizes noise by arranging pixel patterns into a logo-style, thereby presenting itself as an identity for protecting copyright information. Unlike most existing methods, this method can completely expose the added noise to the user without arousing user suspicion, and does not affect the usage of image. We use the differential evolution(DE) to search for suitable pixel positions and RGB values, and compare the performance of PLA with the state-of-the-art adversarial attack algorithms on the CIFAR-10 and ImageNet datasets. Experimental results show that PLA has good performance in solving black-box adversarial attack problems, especially non-targeted attack.},
  archive   = {C_GECCO},
  author    = {Zhu, Jiang and Zhao, Hong and Yu, He and Liu, Jing},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654231},
  pages     = {449–457},
  title     = {Pixel logo attack: Embedding attacks as logo-like pixels},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Nature-inspired preference learning algorithms using the
choquet integral. <em>GECCO</em>, 440–448. (<a
href="https://doi.org/10.1145/3638529.3654054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We introduce various algorithms for learning the parameters of a threshold-based sorting procedure powered by the Choquet integral. This model accounts for interactions between monotonic criteria and facilitates categorizing decision alternatives into predefined, preferentially ordered classes. We focus on developing heuristic preference learning methods capable of efficiently processing large datasets of classification examples. Specifically, we utilize Local Search, Simulated Annealing, and nature-inspired approaches such as Genetic Algorithm, Fish School Search, and Particle Swarm Optimization. We demonstrate the effectiveness of the proposed model through a case study. Additionally, we present an experimental comparison of the recommendation accuracy achieved by these algorithms on a suite of benchmark sorting problems.},
  archive   = {C_GECCO},
  author    = {W\&#39;{o}jcik, Micha\l{} and Kadzi\&#39;{n}ski, Mi\l{}osz},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654054},
  pages     = {440–448},
  title     = {Nature-inspired preference learning algorithms using the choquet integral},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Survival-LCS: A rule-based machine learning approach to
survival analysis. <em>GECCO</em>, 431–439. (<a
href="https://doi.org/10.1145/3638529.3654154">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Survival analysis is a critical aspect of modeling time-to-event data in fields such as epidemiology, engineering, and econometrics. Traditional survival methods rely heavily on assumptions and are limited in their application to real-world datasets. To overcome these challenges, we introduce the survival learning classifier system (Survival-LCS) as a more flexible approach. Survival-LCS extends the capabilities of ExSTraCS, a rule-based machine learning algorithm optimized for biomedical applications, to handle survival (time-to-event) data. In addition to accounting for right-censored observations, Survival-LCS handles multiple feature types and missing data, and makes no assumptions about baseline hazard or survival distributions.As proof of concept, we evaluated the Survival-LCS on simulated genetic survival datasets of increasing complexity derived from the GAMETES software. The four genetic models included univariate, epistatic, additive, and heterogeneous models, simulated across a range of censoring proportions, minor allele frequencies, and number of features. The results of this sensitivity analysis demonstrated the ability of Survival-LCS to identify complex patterns of association in survival data. Using the integrated Brier score as the key performance metric, Survival-LCS demonstrated reliable survival time and distribution predictions, potentially useful for clinical applications such as informing self-controls in clinical trials.},
  archive   = {C_GECCO},
  author    = {Woodward, Alexa and Bandhey, Harsh and Moore, Jason H. and Urbanowicz, Ryan J.},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654154},
  pages     = {431–439},
  title     = {Survival-LCS: A rule-based machine learning approach to survival analysis},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). EZUAS: Evolutionary zero-shot u-shape architecture search
for medical image segmentation. <em>GECCO</em>, 422–430. (<a
href="https://doi.org/10.1145/3638529.3654041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, deep learning-based methods have become the mainstream for medical image segmentation. Since manually designing deep neural networks (DNNs) is laborious and time-consuming, neural architecture search (NAS) becomes a popular stream for automatically designing DNNs for medical image segmentation. However, existing NAS work for medical image segmentation is still computationally expensive. Given the limited computation power, it is not always applicable to search for a well-performing model from an enlarged search space. In this paper, we propose EZUAS, a novel method of evolutionary zero-shot NAS for medical image segmentation, to address these issues. First, a new search space is designed for the automated design of DNNs. A genetic algorithm (GA) with an aligned crossover operation is then leveraged to search the network architectures under the model complexity constraints to get performant and lightweight models. In addition, a variable-length integer encoding scheme is devised to encode the candidate U-shaped DNNs with different stages. We conduct experiments on two commonly used medical image segmentation datasets to verify the effectiveness of the proposed EZUAS. Compared with the state-of-the-art methods, the proposed method can find a model much faster (about 0.04 GPU day) and achieve the best performance with lower computational complexity.},
  archive   = {C_GECCO},
  author    = {Wei, Jiahong and Xue, Bing and Zhang, Mengjie},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654041},
  pages     = {422–430},
  title     = {EZUAS: Evolutionary zero-shot U-shape architecture search for medical image segmentation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CANNIBAL unveils the hidden gems: Hyperspectral band
selection via clustering of weighted variable interaction graphs.
<em>GECCO</em>, 412–421. (<a
href="https://doi.org/10.1145/3638529.3654203">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Hyperspectral imaging brings important opportunities in a variety of fields due to the unprecedented amount of information it captures in numerous narrow and contiguous spectral bands. However, the high spectral and spatial dimensionality of hyperspectral images makes them challenging to transfer, store, and ultimately analyze, while only a subset of bands may be significant in specific downstream applications in Earth observation. In this article, we tackle this issue and introduce CANNIBAL---a band selection algorithm based on unsupervised clustering of inter-band dependencies captured in weighted Variable Interaction Graphs, which are a side-effect of the optimization performed by the Genetic Algorithm with Linkage Learning. We apply CANNIBAL to two downstream tasks of hyperspectral unmixing and segmentation. Our experimental study revealed that it outperforms other band selection algorithms and allows us to dramatically reduce the number of bands without negatively affecting the quality of downstream models. Finally, CANNIBAL offers a high level of flexibility, as it can be both parametric and non-parametric, depending on a use case.},
  archive   = {C_GECCO},
  author    = {Tulczyjew, Lukasz and Przewozniczek, Michal and Tin\&#39;{o}s, Renato and Wijata, Agata M. and Nalepa, Jakub},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654203},
  pages     = {412–421},
  title     = {CANNIBAL unveils the hidden gems: Hyperspectral band selection via clustering of weighted variable interaction graphs},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-objective evolutionary hindsight experience replay for
robot manipulation tasks. <em>GECCO</em>, 403–411. (<a
href="https://doi.org/10.1145/3638529.3654045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Reinforcement learning (RL) algorithms often face challenges in efficiently learning effective policies for sparse-reward multi-goal robot manipulation tasks, thus requiring a vast amount of experiences. The state-of-the-art algorithm in the field, Hindsight Experience Replay (HER), addresses this issue by using failed trajectories and replacing the desired goal with hindsight goals. However, HER performs poorly when the desired goal is distant from the initial state. To address this limitation, Hindsight Goal Generation (HGG) has been proposed, which generates a curriculum of goals from already visited states. This curriculum generation is based on a single objective, and does not take obstacles into account. Here, we make a step forward by proposing Multi-Objective Evolutionary Hindsight Experience Replay (MOEHER), a novel curriculum RL algorithm that reformulates curriculum generation considering multiple objectives and obstacles. MOEHER utilizes NSGA-II to generate a curriculum that is optimized w.r.t. four objectives, namely the Q-function, the goal-proximity function, and two distance metrics, while simultaneously satisfying constraints on the obstacles. We evaluate MOEHER on four different sparse-reward robot manipulation tasks, with and without obstacles, and compare it with HER and HGG. The results demonstrate that MOEHER surpasses or performs on par with these methods on the tested tasks.},
  archive   = {C_GECCO},
  author    = {Sayar, Erdi and Iacca, Giovanni and Knoll, Alois},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654045},
  pages     = {403–411},
  title     = {Multi-objective evolutionary hindsight experience replay for robot manipulation tasks},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-objective evolutionary GAN for tabular data synthesis.
<em>GECCO</em>, 394–402. (<a
href="https://doi.org/10.1145/3638529.3654052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Synthetic data has a key role to play in data sharing by statistical agencies and other generators of statistical data products. Generative Adversarial Networks (GANs), typically applied to image synthesis, are also a promising method for tabular data synthesis. However, there are unique challenges in tabular data compared to images, eg tabular data may contain both continuous and discrete variables and conditional sampling, and, critically, the data should possess high utility and low disclosure risk (the risk of re-identifying a population unit or learning something new about them), providing an opportunity for multi-objective (MO) optimization. Inspired by MO GANs for images, this paper proposes a smart MO evolutionary conditional tabular GAN (SMOE-CTGAN). This approach models conditional synthetic data by applying conditional vectors in training, and uses concepts from MO optimisation to balance disclosure risk against utility. Our results indicate that SMOE-CTGAN is able to discover synthetic datasets with different risk and utility levels for multiple national census datasets. We also find a sweet spot in the early stage of training where a competitive utility and extremely low risk are achieved, by using an Improvement Score. The full code can be downloaded from github1.},
  archive   = {C_GECCO},
  author    = {Ran, Nian and Nasution, Bahrul and Little, Claire and Allmendinger, Richard and Elliot, Mark},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654052},
  pages     = {394–402},
  title     = {Multi-objective evolutionary GAN for tabular data synthesis},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Transfer learning of surrogate models via domain affine
transformation. <em>GECCO</em>, 385–393. (<a
href="https://doi.org/10.1145/3638529.3654032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Surrogate models are widely applied in many scenarios to replace expensive executions of real-world procedures. Training a high-quality surrogate model often requires many sample points, which can be costly to obtain. We would amortize this cost if we could reuse already-trained surrogates in future tasks, provided certain invariances are retained across tasks. This paper studies transferring a surrogate model trained on a source function to a target function using a small data set. As a first step, we consider the following invariance: the domains of the source and target functions are related by an unknown affine transformation. We propose to parameterize the surrogate of the source with an affine transformation and optimize it w.r.t. an empirical loss measured with a small transfer data set sampled on the target. We select all functions from the well-known black-box optimization benchmark (BBOB) as the source and artificially generate the target with affine transformation sampled u.a.r. We experiment with a commonly used surrogate model, Gaussian process regression, where results show that the transferred surrogate significantly outperforms both the original surrogate and the one built from scratch with the transfer data set.},
  archive   = {C_GECCO},
  author    = {Pan, Shuaiqun and Vermetten, Diederick and L\&#39;{o}pez-Ib\&#39;{a}\~{n}ez, Manuel and B\&quot;{a}ck, Thomas and Wang, Hao},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654032},
  pages     = {385–393},
  title     = {Transfer learning of surrogate models via domain affine transformation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LLM guided evolution - the automation of models advancing
models. <em>GECCO</em>, 377–384. (<a
href="https://doi.org/10.1145/3638529.3654178">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the realm of machine learning, traditional model development and automated approaches like AutoML typically rely on layers of abstraction, such as tree-based or Cartesian genetic programming. Our study introduces &quot;Guided Evolution&quot; (GE), a novel framework that diverges from these methods by utilizing Large Language Models (LLMs) to directly modify code. GE leverages LLMs for a more intelligent, supervised evolutionary process, guiding mutations and crossovers. Our unique &quot;Evolution of Thought&quot; (EoT) technique further enhances GE by enabling LLMs to reflect on and learn from the outcomes of previous mutations. This results in a self-sustaining feedback loop that augments decision-making in model evolution. GE maintains genetic diversity, crucial for evolutionary algorithms, by leveraging LLMs&#39; capability to generate diverse responses from expertly crafted prompts and modulate model temperature. This not only accelerates the evolution process but also injects expert like creativity and insight into the process. Our application of GE in evolving the ExquisiteNetV2 model demonstrates its efficacy: the LLM-driven GE autonomously produced variants with improved accuracy, increasing from 92.52\% to 93.34\%, without compromising model compactness. This underscores the potential of LLMs to accelerate the traditional model design pipeline, enabling models to autonomously evolve and enhance their own designs.},
  archive   = {C_GECCO},
  author    = {Morris, Clint and Jurado, Michael and Zutty, Jason},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654178},
  pages     = {377–384},
  title     = {LLM guided evolution - the automation of models advancing models},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards multi-morphology controllers with diversity and
knowledge distillation. <em>GECCO</em>, 367–376. (<a
href="https://doi.org/10.1145/3638529.3654013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Finding controllers that perform well across multiple morphologies is an important milestone for large-scale robotics, in line with recent advances via foundation models in other areas of machine learning. However, the challenges of learning a single controller to control multiple morphologies make the &#39;one robot one task&#39; paradigm dominant in the field. To alleviate these challenges, we present a pipeline that: (1) leverages Quality Diversity algorithms like MAP-Elites to create a dataset of many single-task/single-morphology teacher controllers, then (2) distills those diverse controllers into a single multi-morphology controller that performs well across many different body plans by mimicking the sensory-action patterns of the teacher controllers via supervised learning. The distilled controller scales well with the number of teachers/morphologies and shows emergent properties. It generalizes to unseen morphologies in a zero-shot manner, providing robustness to morphological perturbations and instant damage recovery. Lastly, the distilled controller is also independent of the teacher controllers - we can distill the teacher&#39;s knowledge into any controller model, making our approach synergistic with architectural improvements and existing training algorithms for teacher controllers.},
  archive   = {C_GECCO},
  author    = {Mertan, Alican and Cheney, Nick},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654013},
  pages     = {367–376},
  title     = {Towards multi-morphology controllers with diversity and knowledge distillation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Runtime analysis of population-based evolutionary neural
architecture search for a binary classification problem. <em>GECCO</em>,
358–366. (<a href="https://doi.org/10.1145/3638529.3654003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Evolutionary neural architecture search (ENAS) employs evolutionary techniques, e.g., evolutionary algorithm (EA), to design high-performing neural network architectures, and has achieved great success. However, compared to the application, its theoretical analysis is still in its infancy and only touches the ENAS without populations. In this work, we consider the (μ+λ)-ENAS algorithm (based on a general population-based EA with mutation only, i.e., (μ+λ)-EA) to find an optimal neural network architecture capable of solving a binary classification problem Uniform (with problem size n), and obtain the following mathematical runtime results: 1) by applying a local mutation, it can find the optimum in an expected runtime of O(μ + nλ/(1 - e-λ/μ)) and Ω(μ + nλ/(1 - e−-λ)); 2) by applying a global mutation, it can find the optimum in an expected runtime of O(μ + λcλn/(1 - e−-λ/μ)), and Ω(μ + λn ln ln re/ln n) for some constant c &amp;gt; 1. The derived results reveal that the (μ+λ)-ENAS algorithm is always not asymptotically faster than (1+1)-ENAS on the Uniform problem when λ ϵ ω(ln n/(ln ln n)). The concrete theoretical analysis and proof show that increasing the population size has the potential to increase the runtime and thus should be carefully considered in the ENAS algorithm setup.},
  archive   = {C_GECCO},
  author    = {Lv, Zeqiong and Bian, Chao and Qian, Chao and Sun, Yanan},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654003},
  pages     = {358–366},
  title     = {Runtime analysis of population-based evolutionary neural architecture search for a binary classification problem},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A phenotypic learning classifier system for problems with
continuous features. <em>GECCO</em>, 349–357. (<a
href="https://doi.org/10.1145/3638529.3654007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Over the past four decades, Learning Classifier Systems (LCSs) have faced challenges in producing accurate and interpretable models for domains with continuous features, mainly due to the irrelevance issue caused by genotypic methods. These methods directly modify genotypes (conditions), leading to the creation of irrelevant rules. Phenotypic LCSs, which first modify a rule&#39;s phenotype (covered instance set) before altering its genotype, can avoid this issue. However, previous phenotypic LCSs struggle with overfitting, resulting in lower testing performance. In response, we propose a novel phenotypic LCS featuring innovations: 1) a heterogeneous phenotype approach in the rule discovery mechanism to alleviate overfitting, and 2) Informed Mutation leverages the inherent neighbouring of similar instances to enhance rule generalization, thereby improving model interpretability. The proposed LCS demonstrates its success with superior testing performance and more interpretable models in all experiments compared to other LCSs. Notably, in a problem with 2048 features, the proposed LCS model outperformed the genotypic UCS by achieving a 97.4\% testing accuracy with just 13 rules, compared to the UCS&#39;s 9961 rules but only 49.9\% accuracy.},
  archive   = {C_GECCO},
  author    = {Liu, Yi and Cui, Yu and Cheng, Wen and Browne, Will Neil and Xue, Bing and Zhu, Chengyuan and Zhang, Yiding and Sheng, Mingkai and Zeng, Lingfang},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654007},
  pages     = {349–357},
  title     = {A phenotypic learning classifier system for problems with continuous features},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Using bayesian optimization to improve hyperparameter search
in TPOT. <em>GECCO</em>, 340–348. (<a
href="https://doi.org/10.1145/3638529.3654061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Automated machine learning (AutoML) has emerged as a pivotal tool for applying machine learning (ML) models to real-world problems. Tree-based pipeline optimization tool (TPOT) is an AutoML framework known for effectively solving complex tasks. TPOT&#39;s search involves two fundamental objectives: finding optimal pipeline structures (i.e., combinations of ML operators) and identifying suitable hyperparameters for these structures. While its use of genetic programming enables TPOT to excel in structural search, its hyperparameter search, involving discretization and random selection from extensive potential value ranges, can be computationally inefficient. This paper presents a novel methodology that heavily restricts the initial hyperparameter search space, directing TPOT&#39;s focus towards structural exploration. As the search evolves, Bayesian optimization (BO) is used to refine the hyperparameter space based on data from previous pipeline evaluations. This method leads to a more targeted search, crucial in situations with limited computational resources. Two variants of this approach are proposed and compared with standard TPOT across six datasets, with up to 20 features and 20,000 samples. The results show the proposed method is competitive with canonical TPOT, and outperforms it in some cases. The study also provides new insights into the dynamics of pipeline structure and hyperparameter search within TPOT.},
  archive   = {C_GECCO},
  author    = {Kenny, Angus and Ray, Tapabrata and Limmer, Steffen and Singh, Hemant Kumar and Rodemann, Tobias and Olhofer, Markus},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654061},
  pages     = {340–348},
  title     = {Using bayesian optimization to improve hyperparameter search in TPOT},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cooperative coevolutionary spatial topologies for
autoencoder training. <em>GECCO</em>, 331–339. (<a
href="https://doi.org/10.1145/3638529.3654127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Training autoencoders is non-trivial. Convergence to the identity function or overfitting are common pitfalls. Population based algorithms like coevolutionary algorithms can provide diversity. To more robustly train autoencoders, we introduce a novel cooperative coevolutionary algorithm that exploits a spatial topology. We investigate the impact of algorithm parameters and design choices on the performance. On a simple tunable benchmark problem we observe that the performance can be improved over that of an conventionally trained autoencoder. However, the training convergence can be slow, despite the final model performance being competitive with a conventional autoencoder.},
  archive   = {C_GECCO},
  author    = {Hemberg, Erik and O&#39;Reilly, Una-May and Toutouh, Jamal},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654127},
  pages     = {331–339},
  title     = {Cooperative coevolutionary spatial topologies for autoencoder training},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Influence based fitness shaping for coevolutionary agents.
<em>GECCO</em>, 322–330. (<a
href="https://doi.org/10.1145/3638529.3654175">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Coevolving cooperative teams creates a challenging joint-action discovery problem because fitness functions generally evaluate team performance rather than individual agent performance. Feedback &quot;sparsity&quot; where agents only receive feedback when they jointly stumble upon a valuable action compounds this problem. Fitness shaping techniques alleviate this problem by extracting agent contributions and providing stepping stone incentives in sparse feedback settings. However, such techniques require agents to make direct and measurable impacts to system performance. If agents have indirect impacts, such as influencing other agents to accomplish tasks, existing shaping methods fail to provide adequate feedback. In this work, we introduce Influence Based Fitness Shaping (IBFS) to capture and incentivize indirect impacts. IBFS extracts an agent&#39;s impact based on how it influences other agents and guides exploration towards influencing actions in sparse feedback settings. Our results in a multiagent shepherding problem show that IBFS outperforms standard fitness shaping, and the gains increase when feedback becomes sparser.},
  archive   = {C_GECCO},
  author    = {Gonzalez, Everardo and Viswanathan, Siddarth and Tumer, Kagan},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654175},
  pages     = {322–330},
  title     = {Influence based fitness shaping for coevolutionary agents},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Informed diversity search for learning in asymmetric
multiagent systems. <em>GECCO</em>, 313–321. (<a
href="https://doi.org/10.1145/3638529.3654206">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {To coordinate in multiagent settings, asymmetric agents (agents with distinct objectives and capabilities) must learn diverse behaviors that allow them to maximize their individual and team objectives. Hierarchical learning techniques partially address this by leveraging a combination of Quality-Diversity to learn diverse agent-specific behaviors and evolutionary optimization to maximize team objectives. However, isolating diversity search from team optimization is prone to producing egocentric behaviors that have misaligned objectives. This work introduces Diversity Aligned Island Model (DA-IM), a coevolutionary framework that fluidly adapts diversity search to focus on behaviors that yield high fitness teams. An evolutionary algorithm evolves a population of teams to optimize the team objective. Concurrently, a combination of gradient-based optimizers utilize experiences collected by the teams to reinforce agent-specific behaviors and selectively mutate them based on their fitness on the team objective. Periodically, the mutated policies are added to the evolutionary population to inject diversity and to ensure alignment between the two processes. Empirical evaluations on two asymmetric coordination problems with varying degrees of alignment highlight DA-IM&#39;s ability to produce diverse behaviors that outperform existing population-based diversity search methods.},
  archive   = {C_GECCO},
  author    = {Dixit, Gaurav and Tumer, Kagan},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654206},
  pages     = {313–321},
  title     = {Informed diversity search for learning in asymmetric multiagent systems},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evolutionary multitasking with two-level knowledge transfer
for multi-view point cloud registration. <em>GECCO</em>, 304–312. (<a
href="https://doi.org/10.1145/3638529.3654108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Point cloud registration is a hot research topic in the field of computer vision. In recent years, the registration method based on evolutionary computation has attracted more and more attention because of its robustness to initial pose and flexibility of objective function design. However, most of the current evolutionary computation-based point cloud registration methods do not take into account the multi-view problem, that is, to capture the close relationship between point clouds from different perspectives. We fully realize that if these relations are used correctly, the registration performance can be improved. Therefore, this paper proposes an evolutionary multitasking multi-view point cloud registration method, which solves the problem of multi-view error accumulation. To ensure the unity of global and local, a two-level knowledge transfer strategy is proposed, which divides the multi-view cloud registration task into two levels. This strategy unifies the search space of two registration tasks, solves the negative transfer phenomenon, and avoids the problem of falling into the local optimum. Finally, the effectiveness of the method is verified by sufficient experiments. This method has strong robustness to noise and outliers, and can be effectively implemented in various registration scenarios.},
  archive   = {C_GECCO},
  author    = {Ding, Hangqi and Xu, Haoran and Wu, Yue and Li, Hao and Gong, Maoguo and Ma, Wenping and Miao, Qiguang and Shi, Jiao and Lei, Yu},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654108},
  pages     = {304–312},
  title     = {Evolutionary multitasking with two-level knowledge transfer for multi-view point cloud registration},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). NEvoFed: A decentralized approach to federated
NeuroEvolution of heterogeneous neural networks. <em>GECCO</em>,
295–303. (<a href="https://doi.org/10.1145/3638529.3654029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the past few years, Federated Learning (FL) has emerged as an effective approach for training neural networks (NNs) over a computing network while preserving data privacy. Most of the existing FL approaches require the user to define a priori the same structure for all the NNs running on the clients, along with an explicit aggregation procedure. This can be a limiting factor in cases where pre-defining such algorithmic details is difficult. To overcome these issues, we propose a novel approach to FL, which leverages Neuroevolution running on the clients. This implies that the NN structures may be different across clients, hence providing better adaptation to the local data. Furthermore, in our approach, the aggregation is implicitly accomplished on the client side by exploiting the information about the models used on the other clients, thus allowing the emergence of optimal NN architectures without needing an explicit aggregation. We test our approach on three datasets, showing that very compact NNs can be obtained without significant drops in performance compared to canonical FL. Moreover, we show that such compact structures allow for a step towards explainability, which is highly desirable in domains such as digital health, from which the tested datasets come.},
  archive   = {C_GECCO},
  author    = {Custode, Leonardo Lucio and De Falco, Ivanoe and Della Cioppa, Antonio and Iacca, Giovanni and Scafuri, Umberto},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654029},
  pages     = {295–303},
  title     = {NEvoFed: A decentralized approach to federated NeuroEvolution of heterogeneous neural networks},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning aligned local evaluations for better credit
assignment in cooperative coevolution. <em>GECCO</em>, 286–294. (<a
href="https://doi.org/10.1145/3638529.3654157">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Cooperative coevolutionary algorithms prove effective in solving tasks that can be easily decoupled into subproblems. When applied to problems with high coupling (where the fitness depends heavily on specific joint actions), evolution is often stifled by the credit assignment problem. This is due to each agent evolving their policy using a shared evaluation function that is sensitive to the &quot;noise&quot; of all other agents&#39; actions. Using fitness critics alleviates this problem by approximating a local model of an agent&#39;s contribution and using that signal as a fitness function. However, fitness critics suffer when the quality of the local approximation degrades. In this work, we present Global Aligned Local Error (GALE), a loss function that generates better credit-assigning local evaluations that aim to maximize the alignment of the local and global evaluations. In a multiagent exploration domain, we show GALE&#39;s ability to learn better credit assignment, which leads to improved teaming behavior.},
  archive   = {C_GECCO},
  author    = {Cook, Joshua and Tumer, Kagan},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654157},
  pages     = {286–294},
  title     = {Learning aligned local evaluations for better credit assignment in cooperative coevolution},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evolving form and function: Dual-objective optimization in
neural symbolic regression networks. <em>GECCO</em>, 277–285. (<a
href="https://doi.org/10.1145/3638529.3654030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Data increasingly abounds, but distilling their underlying relationships down to something interpretable remains challenging. One approach is genetic programming, which &#39;symbolically regresses&#39; a data set down into an equation. However, symbolic regression (SR) faces the issue of requiring training from scratch for each new dataset. To generalize across all datasets, deep learning techniques have been applied to SR. These networks, however, are only able to be trained using a symbolic objective: NN-generated and target equations are symbolically compared. But this does not consider the predictive power of these equations, which could be measured by a behavioral objective that compares the generated equation&#39;s predictions to actual data. Here we introduce a method that combines gradient descent and evolutionary computation to yield neural networks that minimize the symbolic and behavioral errors of the equations they generate from data. As a result, these evolved networks are shown to generate more symbolically and behaviorally accurate equations than those generated by networks trained by state-of-the-art gradient based neural symbolic regression methods. We hope this method suggests that evolutionary algorithms, combined with gradient descent, can improve SR results by yielding equations with more accurate form and function.},
  archive   = {C_GECCO},
  author    = {Bertschinger, Amanda and Bagrow, James and Bongard, Joshua},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654030},
  pages     = {277–285},
  title     = {Evolving form and function: Dual-objective optimization in neural symbolic regression networks},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Semantically rich local dataset generation for explainable
AI in genomics. <em>GECCO</em>, 267–276. (<a
href="https://doi.org/10.1145/3638529.3653990">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Black box deep learning models trained on genomic sequences excel at predicting the outcomes of different gene regulatory mechanisms. Therefore, interpreting these models may provide novel insights into the underlying biology, supporting downstream biomedical applications. Due to their complexity, interpretable surrogate models can only be built for local explanations (e.g., a single instance). However, accomplishing this requires generating a dataset in the neighborhood of the input, which must maintain syntactic similarity to the original data while introducing semantic variability in the model&#39;s predictions. This task is challenging due to the complex sequence-to-function relationship of DNA.We propose using Genetic Programming to generate datasets by evolving perturbations in sequences that contribute to their semantic diversity. Our custom, domain-guided individual representation effectively constrains syntactic similarity, and we provide two alternative fitness functions that promote diversity with no computational effort. Applied to the RNA splicing domain, our approach quickly achieves good diversity and significantly outperforms a random baseline in exploring the search space, as shown by our proof-of-concept, short RNA sequence. Furthermore, we assess its generalizability and demonstrate scalability to larger sequences, resulting in a ≈30\% improvement over the baseline.},
  archive   = {C_GECCO},
  author    = {Barbosa, Pedro and Savisaar, Rosina and Fonseca, Alcides},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3653990},
  pages     = {267–276},
  title     = {Semantically rich local dataset generation for explainable AI in genomics},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evolutionary multi-objective optimisation for fairness-aware
self adjusting memory classifiers in data streams. <em>GECCO</em>,
258–266. (<a href="https://doi.org/10.1145/3638529.3654038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper introduces a novel approach, evolutionary multi-objective optimisation for fairness-aware self-adjusting memory classifiers, designed to enhance fairness in machine learning algorithms applied to data stream classification. With the growing concern over discrimination in algorithmic decision-making, particularly in dynamic data stream environments, there is a need for methods that ensure fair treatment of individuals across sensitive attributes like race or gender. The proposed approach addresses this challenge by integrating the strengths of the self-adjusting memory K-Nearest-Neighbour algorithm with evolutionary multi-objective optimisation. This combination allows the new approach to efficiently manage concept drift in streaming data and leverage the flexibility of evolutionary multi-objective optimisation to maximise accuracy and minimise discrimination simultaneously. We demonstrate the effectiveness of the proposed approach through extensive experiments on various datasets, comparing its performance against several baseline methods in terms of accuracy and fairness metrics. Our results show that the proposed approach maintains competitive accuracy and significantly reduces discrimination, highlighting its potential as a robust solution for fairness-aware data stream classification. Further analyses also confirm the effectiveness of the strategies to trigger evolutionary multi-objective optimisation and adapt classifiers in the proposed approach.},
  archive   = {C_GECCO},
  author    = {Amarasinghe, Pivithuru and Pham, Diem and Tran, Binh and Nguyen, Su and Sun, Yuan and Alahakoon, Damminda},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654038},
  pages     = {258–266},
  title     = {Evolutionary multi-objective optimisation for fairness-aware self adjusting memory classifiers in data streams},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An adaptive interactive routing-packing strategy for split
delivery vehicle routing problem with 3D loading constraints.
<em>GECCO</em>, 249–257. (<a
href="https://doi.org/10.1145/3638529.3653991">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The split delivery vehicle routing problem with three-dimensional loading constraints (3L-SDVRP) extends the traditional capacitated vehicle routing problem by integrating vehicle routing and three-dimensional packing, thus increasing the overall complexity of the problem. The interaction between routing and packing is crucial to the efficacy of any solution method for 3L-SDVRP. However, conventional approaches such as packing first routing second (P1R2) and routing first packing second (R1P2) exhibit limitations in computational efficiency and adaptability. Based on current strategies, we propose a interactive routing-packing strategy that adaptively decides between loading a single node or two nodes together during the routing. By allowing independent node loading, our method enables the generation of a loading plan prior to routing, thereby eliminating the need for repetitive solving packing sub-problem---an advantage similar to the P1R2 paradigm. Conversely, loading two nodes together requires immediate packing adjustments and helps to reduce the number of vehicles needed---a benefit akin to the R1P2. Our strategy integrates the strengths of both P1R2 and R1P2, thereby achieving enhanced loading flexibility and computational efficiency. Experimental results demonstrate that our methodology outperforms existing strategies regarding vehicle count.},
  archive   = {C_GECCO},
  author    = {Zhang, Han and Li, Qing and Yao, Xin},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3653991},
  pages     = {249–257},
  title     = {An adaptive interactive routing-packing strategy for split delivery vehicle routing problem with 3D loading constraints},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimization through iterative smooth morphological
transformations. <em>GECCO</em>, 241–248. (<a
href="https://doi.org/10.1145/3638529.3654093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we introduce SMorph, a new methodology for combinatorial optimization that works in the instance space of the problem at hand. Indeed, given the problem instance to solve, SMorph builds a simplified instance whose optimum is easy to locate, then it iteratively evolves this instance towards the target one by alternating two steps: optimization and smooth transformation of the current instance. The knowledge acquired in each iteration is transferred to next one, while the entire process is designed with the aim of improving the last optimization step. Although the abstract search scheme of SMorph is general enough to be instantiated for a variety of combinatorial optimization problems, here we present an implementation for the well-known Linear Optimization Problem (LOP). Experiments have been conducted on a set of commonly adopted benchmark instances of the LOP, and the results validate the proposed approach.},
  archive   = {C_GECCO},
  author    = {Santucci, Valentino and Baioletti, Marco and Tomassini, Marco},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654093},
  pages     = {241–248},
  title     = {Optimization through iterative smooth morphological transformations},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient multi-fidelity neural architecture search with
zero-cost proxy-guided local search. <em>GECCO</em>, 232–240. (<a
href="https://doi.org/10.1145/3638529.3654027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Using zero-cost (ZC) metrics as proxies for network performance in Neural Architecture Search (NAS) allows search algorithms to thoroughly explore the architecture space due to their low computing costs. Nevertheless, recent studies indicate that relying exclusively on ZC proxies appears to be less effective than using traditional training-based metrics, such as validation accuracy, in seeking high-performance networks. In this study, we investigate the effectiveness of ZC proxies by taking a deeper look into fitness landscapes of ZC proxy-based local searches by utilizing Local Optima Networks (LONs). Our findings exhibit that ZC proxies having high correlation with network performance do not guarantee finding top-performing architectures, and ZC proxies with low correlations could still be better in certain situations. Our results further consolidate the suggestion of favoring training-based metrics over ZC proxies as the search objective. Although we could figure out architectures having the optimal ZC proxy scores, their true performance is often poor. We then propose the Multi-Fidelity Neural Architecture Search (MF-NAS) framework that makes use of the efficiency of ZC proxies and the efficacy of training-based metrics. Experimental results on a wide range of NAS benchmarks demonstrate the superiority of our MF-NAS to state-of-the-art methods under a strict budget.},
  archive   = {C_GECCO},
  author    = {Phan, Quan Minh and Luong, Ngoc Hoang},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654027},
  pages     = {232–240},
  title     = {Efficient multi-fidelity neural architecture search with zero-cost proxy-guided local search},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-objective evolutionary algorithms with sliding window
selection for the dynamic chance-constrained knapsack problem.
<em>GECCO</em>, 223–231. (<a
href="https://doi.org/10.1145/3638529.3654081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Evolutionary algorithms are particularly effective for optimisation problems with dynamic and stochastic components. We propose multi-objective evolutionary approaches for the knapsack problem with stochastic profits under static and dynamic weight constraints. The chance-constrained problem model allows us to effectively capture the stochastic profits and associate a confidence level to the solutions&#39; profits. We consider a bi-objective formulation that maximises expected profit and minimises variance, which allows optimising the problem independent of a specific confidence level on the profit. We derive a three-objective formulation by relaxing the weight constraint into an additional objective. We consider the GSEMO algorithm with standard and a sliding window-based parent selection to evaluate the objective formulations. Moreover, we modify fitness formulations and algorithms for the dynamic problem variant to store some infeasible solutions to cater to future changes. We conduct experimental investigations on both problems using the proposed problem formulations and algorithms. Our results show that three-objective approaches outperform approaches that use bi-objective formulations, and they further improve when GSEMO uses sliding window selection.},
  archive   = {C_GECCO},
  author    = {Perera, Kokila Kasuni and Neumann, Aneta},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654081},
  pages     = {223–231},
  title     = {Multi-objective evolutionary algorithms with sliding window selection for the dynamic chance-constrained knapsack problem},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The chance constrained travelling thief problem: Problem
formulations and algorithms. <em>GECCO</em>, 214–222. (<a
href="https://doi.org/10.1145/3638529.3654014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The travelling thief problem (TTP) is a multi-component combinatorial optimization problem that has gained significant attention in the evolutionary computation and heuristic search literature. In this paper, we introduce the chance constrained TTP which involves stochastic weights. Our problem formulation captures the stochastic aspect of the knapsack in the form of a chance constraint. Such a constraint can only be violated with a small probability. We introduce surrogate and sampling-based approaches for the chance constrained TTP to optimize the expected objective score under the condition that the solution is feasible with a high probability. We use these approaches to evaluate the feasibility of solutions and incorporate our approaches into high-performing algorithms for deterministic TTP. In our experimental investigations, we compare the performance of these algorithms and show the impact of uncertainty in connection with the underlying stochastic model.},
  archive   = {C_GECCO},
  author    = {Pathirage Don, Thilina and Neumann, Aneta and Neumann, Frank},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654014},
  pages     = {214–222},
  title     = {The chance constrained travelling thief problem: Problem formulations and algorithms},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning descriptors for novelty-search based instance
generation via meta-evolution. <em>GECCO</em>, 206–213. (<a
href="https://doi.org/10.1145/3638529.3654028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The ability to generate example instances from a domain is important in order to benchmark algorithms and to generate data that covers an instance-space in order to train machine-learning models for algorithm selection. Quality-Diversity (QD) algorithms have recently been shown to be effective in generating diverse and discriminatory instances with respect to a portfolio of solvers in various combinatorial optimisation domains. However these methods all rely on defining a descriptor which defines the space in which the algorithm searches for diversity: this is usually done manually defining a vector of features relevant to the domain. As this is a limiting factor in the use of QD methods, we propose a meta-QD algorithm which uses an evolutionary algorithm to search for a nonlinear 2D projection of an original feature-space such that applying novelty-search method in this space to generate instances improves the coverage of the instance-space. We demonstrate the effectiveness of the approach by generating instances from the Knapsack domain, showing the meta-QD approach both generates instances in regions of an instance-space not covered by other methods, and also produces significantly more instances.},
  archive   = {C_GECCO},
  author    = {Marrero, Alejandro and Segredo, Eduardo and Le\&#39;{o}n, Coromoto and Hart, Emma},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654028},
  pages     = {206–213},
  title     = {Learning descriptors for novelty-search based instance generation via meta-evolution},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Classical thermodynamics-based parallel annealing algorithm
for high-speed and robust combinatorial optimization. <em>GECCO</em>,
196–205. (<a href="https://doi.org/10.1145/3638529.3654042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In recent years, quantum annealing has triggered active research on annealing methods for solving various combinatorial optimization problems (COPs) by mapping them to the Ising model based on spin glass theory. In particular, parallel annealing algorithms (PAAs) that can update all variables simultaneously attract attention due to fast optimization using parallel computers, either as an extension of Simulated Annealing rooted in classical thermodynamics or as a quantum-inspired algorithm. However, both types of PAAs face their own challenges. The classical thermodynamics-based PAAs (c-PAAs) perform inferior to the quantum-inspired PAAs (q-PAAs), whereas the q-PAAs require more parameters to be tuned than the c-PAAs. This paper proposes a new c-PAA based on Mean Field Annealing, which has the unique feature of updating analog variables deterministically. The proposed PAA achieves high speed and robustness despite fewer parameters than the q-PAAs, which means the proposed PAA breaks through the challenges of conventional PAAs. We demonstrate its performance through experiments on four types of COPs: Maximum Cut Problem, Graph Coloring Problem, Maximum Independent Set Problem, and Traveling Salesman Problem. These results imply that unless a real physical phenomenon is used, quantum-inspired algorithms cannot be considered superior to classical thermodynamics-based algorithms.},
  archive   = {C_GECCO},
  author    = {Kuroki, Kyo and Jimbo, Satoru and Chu, Thiem Van and Motomura, Masato and Kawamura, Kazushi},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654042},
  pages     = {196–205},
  title     = {Classical thermodynamics-based parallel annealing algorithm for high-speed and robust combinatorial optimization},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Effective 2- and 3-objective MOEA/d approaches for the
chance constrained knapsack problem. <em>GECCO</em>, 187–195. (<a
href="https://doi.org/10.1145/3638529.3654066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Optimizing real-world problems often involves decision-making under uncertainty due to the presence of unknown or uncontrollable variables. Chance-constraints allow to model the optimization problem with stochastic components by ensuring the probabilistic constraint is satisfied with high probability. Multi-objective evolutionary algorithms (MOEAs) are successfully applied to chance constrained optimization problems to achieve high-quality results. Most of these algorithms are based on Pareto dominance for measuring the quality of solutions during their search. A very few algorithms are based on the decomposition approach which tries to optimize the aggregations of the objectives. Among them, multi-objective evolutionary algorithm based on decomposition (MOEA/D) is one of the efficient MOEAs which decomposes the multi-objective optimization problems (MOPs) into a number of scalar optimization problems and then optimizes these sub-problems simultaneously. In this paper, we investigate the effectiveness of the MOEA/D algorithm when solving 2- and 3-objective formulations of the chance constrained knapsack problem, where the weights of each item are stochastic. We compare its performance with global simple evolutionary multi-objective optimizer (GSEMO) across various benchmark scenarios. Overall, we demonstrate that the MOEA/D achieved high-quality solutions with lower computational complexity.},
  archive   = {C_GECCO},
  author    = {Hewa Pathiranage, Ishara and Neumann, Frank and Antipov, Denis and Neumann, Aneta},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654066},
  pages     = {187–195},
  title     = {Effective 2- and 3-objective MOEA/D approaches for the chance constrained knapsack problem},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Heuristic initialization and knowledge-based mutation for
large-scale multi-objective 0-1 knapsack problems. <em>GECCO</em>,
178–186. (<a href="https://doi.org/10.1145/3638529.3654006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, there has been a growing interest in large-scale multiobjective optimization problems within the evolutionary multiobjective optimization (EMO) community. These problems involve hundreds or thousands of decision variables and multiple conflicting objectives, which pose significant challenges for conventional EMO algorithms (EMOAs). It is generally believed that EMOAs have difficulty in efficiently finding good non-dominated solutions as the number of decision variables increases. To address this issue, in this paper, we propose a novel method that incorporates heuristic initialization and knowledge-based mutation into EMOAs for solving large-scale multi-objective 0-1 knapsack problems. Various large-scale multi-objective 0-1 knapsack problems with an arbitrary number of constraints are generated as test problems to evaluate the effectiveness of the proposed method. Experimental results show that the proposed novel initialization and mutation method significantly improves the performance of the original EMOAs in terms of both the convergence speed in early generations and the quality of the final population.},
  archive   = {C_GECCO},
  author    = {Gong, Cheng and Nan, Yang and Pang, Lie Meng and Ishibuchi, Hisao and Zhang, Qingfu},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654006},
  pages     = {178–186},
  title     = {Heuristic initialization and knowledge-based mutation for large-scale multi-objective 0-1 knapsack problems},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Superior genetic algorithms for the target set selection
problem based on power-law parameter choices and simple greedy
heuristics. <em>GECCO</em>, 169–177. (<a
href="https://doi.org/10.1145/3638529.3654140">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The target set selection problem (TSS) asks for a set of vertices such that an influence spreading process started in these vertices reaches the whole graph. The current state of the art for this NP-hard problem are three recently proposed randomized search heuristics, namely a biased random-key genetic algorithm (BRKGA) obtained from extensive parameter tuning, a max-min ant system (MMAS), and a MMAS using Q-learning with a graph convolutional network.We show that the BRKGA with two simple modifications and without the costly parameter tuning obtains significantly better results. Our first modification is to simply choose all parameters of the BRKGA in each iteration randomly from a power-law distribution. The resulting parameterless BRKGA is already competitive with the tuned BRKGA, as our experiments on the previously used benchmarks show.We then add a natural greedy heuristic, namely to repeatedly discard small-degree vertices that are not necessary for reaching the whole graph. The resulting algorithm consistently outperforms all of the state-of-the-art algorithms.Besides providing a superior algorithm for the TSS problem, this work shows that randomized parameter choices and elementary greedy heuristics can give better results than complex algorithms and costly parameter tuning.},
  archive   = {C_GECCO},
  author    = {Doerr, Benjamin and Krejca, Martin S. and Vu, Nguyen},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654140},
  pages     = {169–177},
  title     = {Superior genetic algorithms for the target set selection problem based on power-law parameter choices and simple greedy heuristics},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Large language models for the automated analysis of
optimization algorithms. <em>GECCO</em>, 160–168. (<a
href="https://doi.org/10.1145/3638529.3654086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The ability of Large Language Models (LLMs) to generate high-quality text and code has fuelled their rise in popularity. In this paper, we aim to demonstrate the potential of LLMs within the realm of optimization algorithms by integrating them into STNWeb. This is a web-based tool for the generation of Search Trajectory Networks (STNs), which are visualizations of optimization algorithm behavior. Although visualizations produced by STNWeb can be very informative for algorithm designers, they often require a certain level of prior knowledge to be interpreted. In an attempt to bridge this knowledge gap, we have incorporated LLMs, specifically GPT-4, into STNWeb to produce extensive written reports, complemented by automatically generated plots, thereby enhancing the user experience and reducing the barriers to the adoption of this tool by the research community. Moreover, our approach can be expanded to other tools from the optimization community, showcasing the versatility and potential of LLMs in this field.},
  archive   = {C_GECCO},
  author    = {Chac\&#39;{o}n Sartori, Camilo and Blum, Christian and Ochoa, Gabriela},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654086},
  pages     = {160–168},
  title     = {Large language models for the automated analysis of optimization algorithms},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). An extension of STNWeb functionality: On the use of
hierarchical agglomerative clustering as an advanced search space
partitioning strategy. <em>GECCO</em>, 151–159. (<a
href="https://doi.org/10.1145/3638529.3654084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Search Trajectory Networks (STNs) serve as a tool for visualizing algorithm behavior within the realm of optimization problems. Despite their user-friendly nature, challenges arise in obtaining interpretable plots, for example, in the case of optimization problems with large solutions or many dimensions. To address this, we have introduced a new search space partitioning strategy utilizing hierarchical agglomerative clustering. This enhanced strategy, now available in STNWeb, the web version of STNs, produces plots that are easier to interpret than those produced by existing search space partitioning strategies. This facilitates an improved understanding of algorithm performance in complex scenarios.},
  archive   = {C_GECCO},
  author    = {Chac\&#39;{o}n Sartori, Camilo and Blum, Christian and Ochoa, Gabriela},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654084},
  pages     = {151–159},
  title     = {An extension of STNWeb functionality: On the use of hierarchical agglomerative clustering as an advanced search space partitioning strategy},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Letting a large neighborhood search for an electric
dial-a-ride problem fly: On-the-fly charging station insertion.
<em>GECCO</em>, 142–150. (<a
href="https://doi.org/10.1145/3638529.3654057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider the electric autonomous dial-a-ride problem (E-ADARP), a challenging extension of the dial-a-ride problem with the goal of finding minimum cost routes serving given transportation requests with a fleet of electric and autonomous vehicles (EAVs). Special emphasis lies on the minimization of user excess ride time under consideration of the charging requirements of the EAVs while constraints regarding, for example, user ride times and time windows have to be satisfied. We propose a novel large neighborhood search (LNS) approach for the E-ADARP employing the concept of battery-restricted fragments for route representation and efficient cost computations. For the charging of the EAVs, the scheduling, and route evaluation, we introduce two approaches where one deals with these challenges separately and one provides a combined approach. The first approach uses dedicated LNS operators and a forward labeling algorithm whereas the latter employs a novel route evaluation procedure for inserting charging stops on-the-fly as needed. The performance of our LNS-based algorithms is evaluated on common benchmark instances and results show that especially the approach with the on-the-fly insertion almost consistently outperforms former state-of-the-art techniques, finding new best-known solutions for many instances.},
  archive   = {C_GECCO},
  author    = {Bresich, Maria and Raidl, G\&quot;{u}nther R. and Limmer, Steffen},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654057},
  pages     = {142–150},
  title     = {Letting a large neighborhood search for an electric dial-A-ride problem fly: On-the-fly charging station insertion},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generalised kruskal mutation for the multi-objective minimum
spanning tree problem. <em>GECCO</em>, 133–141. (<a
href="https://doi.org/10.1145/3638529.3654165">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Approximating the Pareto-set of the multi-objective minimum spanning tree problem (moMST) is a challenging task, which was tackled multiple times over the last decades, also by applying evolutionary approaches. A very recent work introduced two novel and strongly problem-tailored sub-graph based mutation operators embedded in NSGA-II. The authors show that these operators excel on a large set of problem instances in terms of convergence speed and approximation quality. Essentially, these operators replace sub-trees of solution candidates by applying Kruskal&#39;s well-known MST algorithm to a sub-graph of the input graph reduced to scalar edge weights via weighted-sum scalarisation. This work changes the perspective on the working principle of these operators and proposes a more general construction framework. We show that the before mentioned operators can be embedded into this framework, which &#39;rewires&#39; sub-trees using a generalisation of Kruskal&#39;s algorithm. Additionally, we introduce several improvements to the operators reducing their running time significantly without deteriorating their effectiveness, introduce a novel mutation operator, which utilises the framework in an insertion-first approach (contrary to the other operators), and derive theoretical runtime bounds for all considered operators. A short benchmark study demonstrates the effectiveness of the introduced approach.},
  archive   = {C_GECCO},
  author    = {Bossek, Jakob and Grimme, Christian},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654165},
  pages     = {133–141},
  title     = {Generalised kruskal mutation for the multi-objective minimum spanning tree problem},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Integrating diverse evolutionary patterns of collective
animal behaviours into a unified selfish herd model. <em>GECCO</em>,
124–132. (<a href="https://doi.org/10.1145/3638529.3654095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The behavioural adaptation of group-living animals in predation has been commonly illustrated as a united resistance against predators. However, fewer investigations have focused on whether individual fitness always conforms to group benefit in evolution. This study highlights the impact of individual selection towards the evolution of collective patterns, treating prey as purely egoistic agents unconcerned with predator fitness. Utilising the game-theoretic framework and computational approaches, we identify evolutionarily stable strategies and collective patterns under a complete range of environmental risk distributions. Our findings reveal that collective motion in groups is stable only when leaders face greater danger than followers. Additionally, we observe that the selfish herd scenario, both with and without crowding effects, is consistent with our results. Surprisingly, collective motion can also be stable in less commonly mentioned scenarios, like when the group centre is at more risk than the border. These findings imply that certain natural animal behaviours may be driven solely by individual selection, with minimal influence from higher-level mechanisms, redefining our understanding of group dynamics in predation.},
  archive   = {C_GECCO},
  author    = {Yang, Wen-Chi},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654095},
  pages     = {124–132},
  title     = {Integrating diverse evolutionary patterns of collective animal behaviours into a unified selfish herd model},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Understanding fitness landscapes in morpho-evolution via
local optima networks. <em>GECCO</em>, 114–123. (<a
href="https://doi.org/10.1145/3638529.3654059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Morpho-Evolution (ME) refers to the simultaneous optimisation of a robot&#39;s design and controller to maximise performance given a task and environment. Many genetic encodings have been proposed which are capable of representing design and control. Previous research has provided empirical comparisons between encodings in terms of their performance with respect to an objective function and the diversity of designs that are evaluated, however there has been no attempt to explain the observed findings. We address this by applying Local Optima Network (LON) analysis to investigate the structure of the fitness landscapes induced by three different encodings when evolving a robot for a locomotion task, shedding new light on the ease by which different fitness landscapes can be traversed by a search process. This is the first time LON analysis has been applied in the field of ME despite its popularity in combinatorial optimisation domains; the findings will facilitate design of new algorithms or operators that are customised to ME landscapes in the future.},
  archive   = {C_GECCO},
  author    = {Thomson, Sarah L. and Le Goff, L\&#39;{e}ni and Hart, Emma and Buchanan, Edgar},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654059},
  pages     = {114–123},
  title     = {Understanding fitness landscapes in morpho-evolution via local optima networks},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Quality with just enough diversity in evolutionary policy
search. <em>GECCO</em>, 105–113. (<a
href="https://doi.org/10.1145/3638529.3654047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Evolution Strategies (ES) are effective gradient-free optimization methods that can be competitive with gradient-based approaches for policy search. ES only rely on the total episodic scores of solutions in their population, from which they estimate fitness gradients for their update with no access to true gradient information. However this makes them sensitive to deceptive fitness landscapes, and they tend to only explore one way to solve a problem. Quality-Diversity methods such as MAP-Elites introduced additional information with behavior descriptors (BD) to return a population of diverse solutions, which helps exploration but leads to a large part of the evaluation budget not being focused on finding the best performing solution. Here we show that behavior information can also be leveraged to find the best policy by identifying promising search areas which can then be efficiently explored with ES. We introduce the framework of Quality with Just Enough Diversity (JEDi) which learns the relationship between behavior and fitness to focus evaluations on solutions that matter. When trying to reach higher fitness values, JEDi outperforms both QD and ES methods on hard exploration tasks like mazes and on complex control problems with large policies.},
  archive   = {C_GECCO},
  author    = {Templier, Paul and Grillotti, Luca and Rachelson, Emmanuel and Wilson, Dennis and Cully, Antoine},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654047},
  pages     = {105–113},
  title     = {Quality with just enough diversity in evolutionary policy search},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning from evolution: Improving collective
decision-making mechanisms using insights from evolutionary robotics.
<em>GECCO</em>, 96–104. (<a
href="https://doi.org/10.1145/3638529.3653988">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Collective decision-making enables multi-robot systems to act autonomously in real-world environments. Existing collective decision-making mechanisms suffer from the so-called speed versus accuracy trade-off or rely on high complexity, e.g., by including global communication. Recent work has shown that more efficient collective decision-making mechanisms based on artificial neural networks can be generated using methods from evolutionary computation. A major drawback of these decision-making neural networks is their limited interpretability. Analyzing evolved decision-making mechanisms can help us improve the efficiency of hand-coded decision-making mechanisms while maintaining a higher interpretability. In this paper, we analyze evolved collective decision-making mechanisms in detail and hand-code two new decision-making mechanisms based on the insights gained. In benchmark experiments, we show that the newly implemented collective decision-making mechanisms are more efficient than the state-of-the-art collective decision-making mechanisms voter model and majority rule.},
  archive   = {C_GECCO},
  author    = {Kaiser, Tanja Katharina},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3653988},
  pages     = {96–104},
  title     = {Learning from evolution: Improving collective decision-making mechanisms using insights from evolutionary robotics},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neuron-centric hebbian learning. <em>GECCO</em>, 87–95. (<a
href="https://doi.org/10.1145/3638529.3654011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {One of the most striking capabilities behind the learning mechanisms of the brain is the adaptation, through structural and functional plasticity, of its synapses. While synapses have the fundamental role of transmitting information across the brain, several studies show that it is the neuron activations that produce changes on synapses. Yet, most plasticity models devised for artificial Neural Networks (NNs), e.g., the ABCD rule, focus on synapses, rather than neurons, therefore optimizing synaptic-specific Hebbian parameters. This approach, however, increases the complexity of the optimization process since each synapse is associated to multiple Hebbian parameters. To overcome this limitation, we propose a novel plasticity model, called Neuron-centric Hebbian Learning (NcHL), where optimization focuses on neuron- rather than synaptic-specific Hebbian parameters. Compared to the ABCD rule, NcHL reduces the parameters from 5W to 5N, being W and N the number of weights and neurons, and usually N « W. We also devise a &quot;weightless&quot; NcHL model, which requires less memory by approximating the weights based on a record of neuron activations. Our experiments on two robotic locomotion tasks reveal that NcHL performs comparably to the ABCD rule, despite using up to ~ 97 times less parameters, thus allowing for scalable plasticity.},
  archive   = {C_GECCO},
  author    = {Ferigo, Andrea and Cunegatti, Elia and Iacca, Giovanni},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654011},
  pages     = {87–95},
  title     = {Neuron-centric hebbian learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evolving hierarchical neural cellular automata.
<em>GECCO</em>, 78–86. (<a
href="https://doi.org/10.1145/3638529.3654150">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Much is unknown about how living systems grow into, coordinate communication across, and maintain themselves as hierarchical arrangements of semi-independent cells, tissues, organs, and entire bodies, where each component at each level has its own goals and sensor, motor, and communication capabilities. Similar uncertainty surrounds exactly how selection acts on the components across these levels. Finally, growing interest in viewing intelligence not as something localized to the brain but rather distributed across biological hierarchies has renewed investigation into the nature of such hierarchies. Here we show that organizing neural cellular automata (NCAs) into a hierarchical structure can improve the ability to evolve them to perform morphogenesis and homeostasis, compared to non-hierarchical NCAs. The increased evolvability of hierarchical NCAs (HNCAs) compared to non-hierarchical NCAs suggests an evolutionary advantage to the formation and utilization of higher-order structures, across larger spatial scales, for some tasks, and suggests new ways to design and optimize NCA models and hierarchical arrangements of robots. The results presented here demonstrate the value of explicitly incorporating hierarchical structure into systems that must grow and maintain complex patterns. The introduced method may also serve as a platform to further investigate the evolutionary dynamics of multiscale systems.},
  archive   = {C_GECCO},
  author    = {Bielawski, Kameron and Gaylinn, Nate and Lunn, Cameron and Motia, Kevin and Bongard, Joshua},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654150},
  pages     = {78–86},
  title     = {Evolving hierarchical neural cellular automata},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Parametric-task MAP-elites. <em>GECCO</em>, 68–77. (<a
href="https://doi.org/10.1145/3638529.3653993">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Optimizing a set of functions simultaneously by leveraging their similarity is called multi-task optimization. Current black-box multi-task algorithms only solve a finite set of tasks, even when the tasks originate from a continuous space. In this paper, we introduce Parametric-Task MAP-Elites (PT-ME), a new black-box algorithm for continuous multi-task optimization problems. This algorithm (1) solves a new task at each iteration, effectively covering the continuous space, and (2) exploits a new variation operator based on local linear regression. The resulting dataset of solutions makes it possible to create a function that maps any task parameter to its optimal solution. We show that PT-ME outperforms all baselines, including the deep reinforcement learning algorithm PPO on two parametric-task toy problems and a robotic problem in simulation.},
  archive   = {C_GECCO},
  author    = {Anne, Timoth\&#39;{e}e and Mouret, Jean-Baptiste},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3653993},
  pages     = {68–77},
  title     = {Parametric-task MAP-elites},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SDDObench: A benchmark for streaming data-driven
optimization with concept drift. <em>GECCO</em>, 59–67. (<a
href="https://doi.org/10.1145/3638529.3654063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In recent years, the data-driven optimization area has seen a shift in the research focus from static batched data environment to dynamic streaming data environment. However, this field is hindered by the lack of a comprehensive and standardized test suite. To fill this gap, we introduce SDDObench, the first benchmark tailored for evaluating and comparing the streaming data-driven evolutionary algorithms (SDDEAs). SDDObench comprises two sets of objective functions combined with five different types of concept drifts, which offer the benefit of being inclusive in generating data streams that mimic various real-world situations, while also facilitating straight-forward description and analysis. As a proof-of-concept study, four well-known algorithms are selected to tackle the problems generated by SDDObench. The experiment results and analysis reveal ongoing challenges in attaining good performance for streaming data-driven optimization. Our SDDObench is open-source and accessible at: https://github.com/LabGong/SDDObench.},
  archive   = {C_GECCO},
  author    = {Zhong, Yuanting and Wang, Xincan and Sun, Yuhong and Gong, Yue-Jiao},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654063},
  pages     = {59–67},
  title     = {SDDObench: A benchmark for streaming data-driven optimization with concept drift},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Clustering in dynamic environments: A framework for
benchmark dataset generation with heterogeneous changes. <em>GECCO</em>,
50–58. (<a href="https://doi.org/10.1145/3638529.3654188">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Clustering in dynamic environments is of increasing importance, with broad applications ranging from real-time data analysis and online unsupervised learning to dynamic facility location problems. While meta-heuristics have shown promising effectiveness in static clustering tasks, their application for tracking optimal clustering solutions or robust clustering over time in dynamic environments remains largely underexplored. This is partly due to a lack of dynamic datasets with diverse, controllable, and realistic dynamic characteristics, hindering systematic performance evaluations of clustering algorithms in various dynamic scenarios. This deficiency leads to a gap in our understanding and capability to effectively design algorithms for clustering in dynamic environments. To bridge this gap, this paper introduces the Dynamic Dataset Generator (DDG). DDG features multiple dynamic Gaussian components integrated with a range of heterogeneous, local, and global changes. These changes vary in spatial and temporal severity, patterns, and domain of influence, providing a comprehensive tool for simulating a wide range of dynamic scenarios.},
  archive   = {C_GECCO},
  author    = {Yazdani, Danial and Branke, Juergen and Khorshidi, Mohammad Sadegh and Omidvar, Mohammad Nabi and Li, Xiaodong and Gandomi, Amir H. and Yao, Xin},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654188},
  pages     = {50–58},
  title     = {Clustering in dynamic environments: A framework for benchmark dataset generation with heterogeneous changes},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Large-scale benchmarking of metaphor-based optimization
heuristics. <em>GECCO</em>, 41–49. (<a
href="https://doi.org/10.1145/3638529.3654122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The number of proposed iterative optimization heuristics is growing steadily, and with this growth, there have been many points of discussion within the wider community. One particular criticism that is raised towards many new algorithms is their focus on metaphors used to present the method, rather than emphasizing their potential algorithmic contributions. Several studies into popular metaphor-based algorithms have highlighted these problems, even showcasing algorithms that are functionally equivalent to older existing methods. Unfortunately, this detailed approach is not scalable to the whole set of metaphor-based algorithms. Because of this, we investigate ways in which benchmarking can shed light on these algorithms. To this end, we run a set of 294 algorithm implementations on the BBOB function suite. We investigate how the choice of the budget, the performance measure, or other aspects of experimental design impact the comparison of these algorithms. Our results emphasize why benchmarking is a key step in expanding our understanding of the algorithm space, and what challenges still need to be overcome to fully gauge the potential improvements to the state-of-the-art hiding behind the metaphors.},
  archive   = {C_GECCO},
  author    = {Vermetten, Diederick and Doerr, Carola and Wang, Hao and Kononova, Anna V. and B\&quot;{a}ck, Thomas},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654122},
  pages     = {41–49},
  title     = {Large-scale benchmarking of metaphor-based optimization heuristics},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the investigation of multimodal evolutionary algorithms
using search trajectory networks. <em>GECCO</em>, 32–40. (<a
href="https://doi.org/10.1145/3638529.3654050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Evolutionary algorithms (EAs) are often employed to tackle multimodal optimization (MMO), offering the possibility to obtain multiple distinct optimal solutions in one run of the algorithm. Nevertheless, it is challenging to analyze the behaviors of multimodal EAs (MEAs) due to the synergies between the global stage (typically a niching method) and the local stage (typically a core search algorithm) that exist in most MEAs. While Search Trajectory Networks (STNs) are a helpful visualization tool to characterize the behaviors of EAs in approaching a single global optimum, naively applying STNs in MMO yields unintelligible resulting graphs. We here propose an STN variant adapted specifically for depicting the progress of MEAs when locating the set of all global optima. Using this multimodal STN, we carry out investigations for four MEAs created from the combinations of two global-stage mechanisms (i.e., uniform random restart and hill-valley clustering) and two local-stage algorithms (i.e., an evolution strategy and a Gaussian estimation-of-distribution algorithm). Visualization results on 20 functions of the CEC 2013 niching benchmark suite exhibit intrinsic capabilities of these MEAs, yielding interesting explanations for their performance. Source code is available at: https://github.com/ELO-Lab/MDSTN.},
  archive   = {C_GECCO},
  author    = {Tran, Bao Thai and Luong, Ngoc Hoang},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654050},
  pages     = {32–40},
  title     = {On the investigation of multimodal evolutionary algorithms using search trajectory networks},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Temporal true and surrogate fitness landscape analysis for
expensive bi-objective optimisation. <em>GECCO</em>, 23–31. (<a
href="https://doi.org/10.1145/3638529.3654125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Many real-world problems have expensive-to-compute fitness functions and are multi-objective in nature. Surrogate-assisted evolutionary algorithms are often used to tackle such problems. Despite this, literature about analysing the fitness landscapes induced by surrogate models is limited, and even non-existent for multi-objective problems. This study addresses this critical gap by comparing landscapes of the true fitness function with those of surrogate models for multi-objective functions. Moreover, it does so temporally by examining landscape features at different points in time during optimisation, in the vicinity of the population at that point in time. We consider the BBOB bi-objective benchmark functions in our experiments. The results of the fitness landscape analysis reveals significant differences between true and surrogate features at different time points during optimisation. Despite these differences, the true and surrogate landscape features still show high correlations between each other. Furthermore, this study identifies which landscape features are related to search and demonstrates that both surrogate and true landscape features are capable of predicting algorithm performance. These findings indicate that temporal analysis of the landscape features may help to facilitate the design of surrogate switching approaches to improve performance in multi-objective optimisation.},
  archive   = {C_GECCO},
  author    = {Rodriguez, Cedric and Thomson, Sarah and Alderliesten, Tanja and Bosman, Peter},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654125},
  pages     = {23–31},
  title     = {Temporal true and surrogate fitness landscape analysis for expensive bi-objective optimisation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CGP++: A modern c++ implementation of cartesian genetic
programming. <em>GECCO</em>, 13–22. (<a
href="https://doi.org/10.1145/3638529.3654092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The reference implementation of Cartesian Genetic Programming (CGP) was written in the C programming language. C inherently follows a procedural programming paradigm, which entails challenges in providing a reusable and scalable implementation model for complex structures and methods. Moreover, due to the limiting factors of C, the reference implementation of CGP does not provide a generic framework and is therefore restricted to a set of predefined evaluation types. Besides the reference implementation, we also observe that other existing implementations are limited with respect to the features provided. In this work, we therefore propose the first version of a modern C++ implementation of CGP that pursues object-oriented design and generic programming paradigm to provide an efficient implementation model that can facilitate the discovery of new problem domains and the implementation of complex advanced methods that have been proposed for CGP over time. With the proposal of our new implementation, we aim to generally promote interpretability, accessibility and reproducibility in the field of CGP.},
  archive   = {C_GECCO},
  author    = {Kalkreuth, Roman and Baeck, Thomas},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654092},
  pages     = {13–22},
  title     = {CGP++: A modern c++ implementation of cartesian genetic programming},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). New tunable test problems for benchmarking niching methods
for multimodal optimization. <em>GECCO</em>, 4–12. (<a
href="https://doi.org/10.1145/3638529.3654016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This study introduces novel tunable benchmark test problems for continuous box-constrained multimodal optimization (MMO). It first introduces a new approach to control the non-uniformity of distribution of global minima, a notable challenge in MMO. Then, it builds upon an existing procedure to create composite functions in which the severity of two distinguishable groups of MMO challenges can be controlled: i) challenges shared with global optimization (GO), such as ill-conditioning, and ii) challenges specific to MMO, such as non-uniform distribution of global minima. Eight new scalable and tunable MMO functions are then proposed, based on which a test suite of 16 continuous MMO test problems is suggested. This test suite is designed to be i) comprehensive, which means they simulate most, if not all, prominent challenges associated with MMO, ii) discriminating, which means test problems can disclose the gap between the performance of diverse MMO methods, and iii) illuminating, which means test problems can reveal and compare strengths and weaknesses of MMO methods. The code of these problems is made available in two different programming languages to encourage its adoption by the research community.},
  archive   = {C_GECCO},
  author    = {Ahrari, Ali and Fieldsend, Jonathan and Preuss, Mike and Li, Xiaodong and Epitropakis, Michael},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3654016},
  pages     = {4–12},
  title     = {New tunable test problems for benchmarking niching methods for multimodal optimization},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generative AI: Why all the fuss? <em>GECCO</em>, 3. (<a
href="https://doi.org/10.1145/3638529.3663650">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {ChatGPT burst into people&#39;s lives at the end of 2022, heralding the arrival of large language models in particular, and generative AI in general. How best to see this moment in the development of AI. What is generative AI actually good for? And what are its limitations? And how might we tackle them? In this talk, I&#39;ll explore how to understand recent breakthroughs in AI, and discuss what might come next.},
  archive   = {C_GECCO},
  author    = {Walsh, Toby},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3663650},
  pages     = {3},
  title     = {Generative AI: Why all the fuss?},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Lessons from curiosity-driven physics research.
<em>GECCO</em>, 2. (<a
href="https://doi.org/10.1145/3638529.3665089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {From the serendipitous discovery of X-rays in a German laboratory, to the scientists trying to prove Einstein wrong about quantum mechanics (and inadvertently proving him right), to the race to split the atom: physicists have shaped innumerable aspects of how we live today. In this talk, accelerator physicist and author Suzie Sheehy will share her key lessons from over 100 years of curiosity-driven experiments to understand the microscopic. Far from just talking about revolutions in understanding the cosmos, Sheehy will share lessons learned by bringing physics down to Earth and putting it firmly back where it belongs, in the hands of the people.},
  archive   = {C_GECCO},
  author    = {Sheehy, Suzie},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3665089},
  pages     = {2},
  title     = {Lessons from curiosity-driven physics research},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Coevolution in natural and artificial systems.
<em>GECCO</em>, 1. (<a
href="https://doi.org/10.1145/3638529.3663651">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In its most recognizable form, coevolution is a natural process. It is ubiquitous in natural systems whether they are biological or social. But, a community of Evolutionary Computation researchers have also used computation and algorithms to artificially replicate coevolution. They do so for a rich variety of purposes. I will talk about the remarkable correspondences and contrasts between coevolution in nature and computation, and I will outline open challenges and opportunities in this fascinating, complex research area.},
  archive   = {C_GECCO},
  author    = {O’Reilly, Una-May},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  doi       = {10.1145/3638529.3663651},
  pages     = {1},
  title     = {Coevolution in natural and artificial systems},
  year      = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
