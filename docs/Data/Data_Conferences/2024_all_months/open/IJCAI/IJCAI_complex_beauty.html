<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>IJCAI_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ijcai---1048">IJCAI - 1048</h2>
<ul>
<li><details>
<summary>
(2024). Oasis: Data curation and assessment system for pretraining
of large language models. <em>IJCAI</em>, 8855–8859. (<a
href="https://doi.org/10.24963/ijcai.2024/1048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Data is one of the most critical elements in building a large language model. However, existing systems either fail to customize a corpus curation pipeline or neglect to leverage comprehensive corpus assessment for iterative optimization of the curation. To this end, we present a pretraining corpus curation and assessment platform called Oasis — a one-stop system for data quality improvement and quantification with user-friendly interactive interfaces. Specifically, the interactive modular rule filter module can devise customized rules according to explicit feedback. The debiased neural filter module builds the quality classification dataset in a negative-centric manner to remove the undesired bias. The adaptive document deduplication module could execute large-scale deduplication with limited memory resources. These three parts constitute the customized data curation module. And in the holistic data assessment module, a corpus can be assessed in local and global views, with three evaluation means including human, GPT-4, and heuristic metrics. We exhibit a complete process to use Oasis for the curation and assessment of pretraining data. In addition, an 800GB bilingual corpus curated by Oasis is publicly released. Keywords: Natural Language Processing: NLP: Tools Natural Language Processing: NLP: Applications Natural Language Processing: NLP: Language models},
  archive   = {C_IJCAI},
  author    = {Tong Zhou and Yubo Chen and Pengfei Cao and Kang Liu and Shengping Liu and Jun Zhao},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/1048},
  month     = {8},
  pages     = {8855-8859},
  title     = {Oasis: Data curation and assessment system for pretraining of large language models},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RLOP: A framework for reinforcement learning, optimization
and planning algorithms. <em>IJCAI</em>, 8851–8854. (<a
href="https://doi.org/10.24963/ijcai.2024/1047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Reinforcement learning, optimization, and planning/search are interconnected domains in artificial intelligence. Algorithms within these domains share many similarities. They complement each other in solving complex decision-making problems, and also offer opportunities for cross-disciplinary integration. However, conducting research on algorithms across these domains typically requires learning the specialized libraries. These libraries often couple algorithms with domain-specific problem classes, making it difficult to conduct cross-disciplinary researches. In order to solve this problem, we developed a generic and lightweight framework for reinforcement learning, optimization, and planning/search algorithms (RLOP). It implements only the core logic of algorithms, abstracting away domain-specific details by defining interface functions, which enables flexible customization and efficient integration across different domains. The framework has been open-sourced at https://github.com/songzhg/RLOP. Keywords: Machine Learning: ML: Reinforcement learning Search: S: Search and machine learning Planning and Scheduling: PS: Search in planning and scheduling Search: S: Combinatorial search and optimisation Planning and Scheduling: PS: Planning algorithms Search: S: Heuristic search Search: S: Local search Multidisciplinary Topics and Applications: MDA: Computer games Planning and Scheduling: PS: Routing Search: S: Game playing Constraint Satisfaction and Optimization: CSO: Solvers and tools Planning and Scheduling: PS: Markov decisions processes},
  archive   = {C_IJCAI},
  author    = {Song Zhang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/1047},
  month     = {8},
  pages     = {8851-8854},
  title     = {RLOP: A framework for reinforcement learning, optimization and planning algorithms},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). M2RL: A multi-player multi-agent reinforcement learning
framework for complex games. <em>IJCAI</em>, 8847–8850. (<a
href="https://doi.org/10.24963/ijcai.2024/1046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Distributed deep reinforcement learning (DDRL) has gained increasing attention due to the emerging requirements for addressing complex games like Go and StarCraft. However, how to effectively and stably train bots with asynchronous and heterogeneous agents cooperation and competition for multiple players under multiple machines (with multiple CPUs and GPUs) using DDRL is still an open problem. We propose and open M2RL, a Multi-player and Multi-agent Reinforcement Learning framework, to make training bots for complex games an easy-to-use warehouse. Experiments involving training a two-player multi-agent Wargame AI, and a sixteen-player multi-agent community game Neural MMO AI, demonstrate the effectiveness of the proposed framework by winning a silver award and beating high-level AI bots designed by professional players. Keywords: Agent-based and Multi-agent Systems: MAS: Engineering methods, platforms, languages and tools Agent-based and Multi-agent Systems: MAS: Applications Agent-based and Multi-agent Systems: MAS: Multi-agent learning Uncertainty in AI: UAI: Sequential decision making},
  archive   = {C_IJCAI},
  author    = {Tongtong Yu and Chenghua He and Qiyue Yin},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/1046},
  month     = {8},
  pages     = {8847-8850},
  title     = {M2RL: A multi-player multi-agent reinforcement learning framework for complex games},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Upgrading search applications in the era of LLMs: A
demonstration with practical lessons. <em>IJCAI</em>, 8843–8846. (<a
href="https://doi.org/10.24963/ijcai.2024/1045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {While traditional search systems have mostly been satisfactorily relying on lexical based sparse retrievers such as BM25, recent research advances in neural models, the current day large language models (LLMs) hold good promise for practical search applications as well. In this work, we discuss a collaboration between IBM and National Library of Australia to upgrade an existing search application (referred to as NLA) over terabytes of Australian Web Archive data and serving thousands of daily users. We posit and demonstrate both empirically and through qualitative user studies that LLMs and neural models can indeed provide good gains, when combined effectively with traditional search. We believe this demonstration will show the unique challenges associated with real world practical deployments and also offer valuable insights into how to effectively upgrade legacy search applications in the era of LLMs. Keywords: Natural Language Processing: NLP: Information retrieval and text mining Natural Language Processing: NLP: Applications Natural Language Processing: NLP: Natural language semantics Natural Language Processing: NLP: Question answering},
  archive   = {C_IJCAI},
  author    = {Shuang Yu and Nirandika Wanigasekara and Jeff Tan and Kent Fitch and Jaydeep Sen},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/1045},
  month     = {8},
  pages     = {8843-8846},
  title     = {Upgrading search applications in the era of LLMs: A demonstration with practical lessons},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FasterVD: On acceleration of video diffusion models.
<em>IJCAI</em>, 8838–8842. (<a
href="https://doi.org/10.24963/ijcai.2024/1044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Equipped with Denoising Diffusion Probabilistic Models, video content generation has gained significant research interest recently. However, diffusion pipelines call for intensive computation and model storage, which poses challenges for their wide and efficient deployment. In this work, we address this issue by integrating LCM-LoRA to reduce the denoising steps and escalating the video generation process by frame skipping and interpolation. Our framework achieves an approximately 10× inference acceleration for high-quality realistic video generation on commonly available GPUs. Keywords: Machine Learning: ML: Optimization Machine Learning: ML: Applications},
  archive   = {C_IJCAI},
  author    = {Pinrui Yu and Dan Luo and Timothy Rupprecht and Lei Lu and Zhenglun Kong and Pu Zhao and Yanyu Li and Octavia Camps and Xue Lin and Yanzhi Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/1044},
  month     = {8},
  pages     = {8838-8842},
  title     = {FasterVD: On acceleration of video diffusion models},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reinforcement learning for athletic intelligence: Lessons
from the 1st “AI olympics with RealAIGym” competition. <em>IJCAI</em>,
8833–8837. (<a href="https://doi.org/10.24963/ijcai.2024/1043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As artificial intelligence gains new capabilities, it becomes important to evaluate it on real-world tasks. In particular, the fields of robotics and reinforcement learning (RL) are lacking in standardized benchmarking tasks on real hardware. To facilitate reproducibility and stimulate algorithmic advancements, we held an AI Olympics competition at IJCAI 2023 conference based on the double pendulum system in the RealAIGym project where the participants were asked to develop a controller for the swing up and stabilization task. This paper presents the methods and results from the top participating teams and provides insights into the real-world performance of RL algorithms with respect to a baseline time-varying LQR controller. Keywords: Robotics: ROB: Learning in robotics Robotics: ROB: Motion and path planning Machine Learning: ML: Deep reinforcement learning Robotics: ROB: Behavior and control},
  archive   = {C_IJCAI},
  author    = {Felix Wiebe and Niccolò Turcato and Alberto Dalla Libera and Chi Zhang and Theo Vincent and Shubham Vyas and Giulio Giacomuzzo and Ruggero Carli and Diego Romeres and Akhil Sathuluri and Markus Zimmermann and Boris Belousov and Jan Peters and Frank Kirchner and Shivesh Kumar},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/1043},
  month     = {8},
  pages     = {8833-8837},
  title     = {Reinforcement learning for athletic intelligence: Lessons from the 1st “AI olympics with RealAIGym” competition},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Benchmarking stroke forecasting with stroke-level badminton
dataset. <em>IJCAI</em>, 8829–8832. (<a
href="https://doi.org/10.24963/ijcai.2024/1042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In recent years, badminton analytics has drawn attention due to the advancement of artificial intelligence and the efficiency of data collection. While there is a line of effective applications to improve and investigate player performance, there are only a few public badminton datasets that can be used by researchers outside the badminton domain. Existing badminton singles datasets focus on specific matchups; however, they cannot provide comprehensive studies on different players and various matchups. In this paper, we provide a badminton singles dataset, ShuttleSet22, which is collected from high-ranking matches in 2022. ShuttleSet22 consists of 30,172 strokes in 2,888 rallies in the training set, 1,400 strokes in 450 rallies in the validation set, and 2,040 strokes in 654 rallies in the testing set, with detailed stroke-level metadata within a rally. To benchmark existing work with ShuttleSet22, we hold a challenge, Track 2: Forecasting Future Turn-Based Strokes in Badminton Rallies, at CoachAI Badminton Challenge @ IJCAI 2023, to encourage researchers to tackle this real-world problem through innovative approaches and to summarize insights between the state-of-the-art baseline and improved techniques, exchanging inspiring ideas. The baseline codes and the dataset are made available at https://github.com/wywyWang/CoachAI-Projects/tree/main/CoachAI-Challenge-IJCAI2023. Keywords: Multidisciplinary Topics and Applications: MDA: Sports Multidisciplinary Topics and Applications: MDA: Other},
  archive   = {C_IJCAI},
  author    = {Wei-Yao Wang and Wei-Wei Du and Wen-Chih Peng and Tsi-Ui Ik},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/1042},
  month     = {8},
  pages     = {8829-8832},
  title     = {Benchmarking stroke forecasting with stroke-level badminton dataset},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Carbon market simulation with adaptive mechanism design.
<em>IJCAI</em>, 8824–8828. (<a
href="https://doi.org/10.24963/ijcai.2024/1041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A carbon market is a market-based tool that incentivizes economic agents to align individual profits with the global utility, i.e., reducing carbon emissions to tackle climate change. Cap and trade stands as a critical principle based on allocating and trading carbon allowances (carbon emission credit), enabling economic agents to follow planned emissions and penalizing excess emissions. A central authority is responsible for introducing and allocating those allowances in cap and trade. However, the complexity of carbon market dynamics makes accurate simulation intractable, which in turn hinders the design of effective allocation strategies. To address this, we propose an adaptive mechanism design framework, simulating the market using hierarchical, model-free multi-agent reinforcement learning (MARL). Government agents allocate carbon credits, while enterprises engage in economic activities and carbon trading. This framework illustrates agents’ behavior comprehensively. Numerical results show MARL enables government agents to balance productivity, equality, and carbon emissions. Our project is available at https: //anonymous.4open.science/r/Carbon-Simulator. Keywords: Agent-based and Multi-agent Systems: MAS: Agent-based simulation and emergence Agent-based and Multi-agent Systems: MAS: Applications Agent-based and Multi-agent Systems: MAS: Engineering methods, platforms, languages and tools Agent-based and Multi-agent Systems: MAS: Multi-agent learning Game Theory and Economic Paradigms: GTEP: Mechanism design Machine Learning: ML: Reinforcement learning Multidisciplinary Topics and Applications: MDA: Economics},
  archive   = {C_IJCAI},
  author    = {Han Wang and Wenhao Li and Hongyuan Zha and Baoxiang Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/1041},
  month     = {8},
  pages     = {8824-8828},
  title     = {Carbon market simulation with adaptive mechanism design},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AI-olympics: Exploring the generalization of agents through
open competitions. <em>IJCAI</em>, 8820–8823. (<a
href="https://doi.org/10.24963/ijcai.2024/1040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Between 2021 and 2023, AI-Olympics---a series of online AI competitions, was hosted by the online evaluation platform Jidi in collaboration with the IJCAI committee. In these competitions, an agent is required to accomplish diverse sports tasks in a two-dimensional continuous world, while competing against an opponent. This paper provides a brief overview of the competition series and highlights notable findings. We aim to contribute insights to the field of multi-agent decision-making and explore the generalization of agents through engineering efforts. Keywords: Agent-based and Multi-agent Systems: MAS: Engineering methods, platforms, languages and tools Agent-based and Multi-agent Systems: MAS: Multi-agent planning Agent-based and Multi-agent Systems: MAS: Agent-based simulation and emergence},
  archive   = {C_IJCAI},
  author    = {Chen Wang and Yan Song and Shuai Wu and Sa Wu and Ruizhi Zhang and Shu Lin and Haifeng Zhang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/1040},
  month     = {8},
  pages     = {8820-8823},
  title     = {AI-olympics: Exploring the generalization of agents through open competitions},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). KnowledgeHub: An end-to-end tool for assisted scientific
discovery. <em>IJCAI</em>, 8815–8819. (<a
href="https://doi.org/10.24963/ijcai.2024/1039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper describes the KnowledgeHub tool, a scientific literature Information Extraction (IE) and Question Answering (QA) pipeline. This is achieved by supporting the ingestion of PDF documents that are converted to text and structured representations. An ontology can then be constructed where a user defines the types of entities and relationships they want to capture. A browser-based annotation tool enables annotating the contents of the PDF documents according to the ontology. Named Entity Recognition (NER) and Relation Classification (RC) models can be trained on the resulting annotations and can be used to annotate the unannotated portion of the documents. A knowledge graph is constructed from these entity and relation triples which can be queried to obtain insights from the data. Furthermore, we integrate a suite of Large Language Models (LLMs) that can be used for QA and summarisation that is grounded in the included documents. KnowledgeHub is a unique tool that supports annotation, IE and QA, which gives the user full insight into the knowledge discovery pipeline. Keywords: Natural Language Processing: NLP: Information extraction Data Mining: DM: Information retrieval Humans and AI: HAI: Human-AI collaboration Machine Learning: ML: Relational learning Natural Language Processing: NLP: Applications Natural Language Processing: NLP: Information retrieval and text mining Natural Language Processing: NLP: Language generation Natural Language Processing: NLP: Language models Natural Language Processing: NLP: Named entities Natural Language Processing: NLP: Question answering Natural Language Processing: NLP: Summarization Natural Language Processing: NLP: Tagging, chunking, and parsing Natural Language Processing: NLP: Tools},
  archive   = {C_IJCAI},
  author    = {Shinnosuke Tanaka and James Barry and Vishnudev Kuruvanthodi and Movina Moses and Maxwell J. Giammona and Nathan Herr and Mohab Elkaref and Geeth de Mel},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/1039},
  month     = {8},
  pages     = {8815-8819},
  title     = {KnowledgeHub: An end-to-end tool for assisted scientific discovery},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A framework for centralized traffic routing in urban areas.
<em>IJCAI</em>, 8810–8814. (<a
href="https://doi.org/10.24963/ijcai.2024/1038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Dealing with the ever-increasing demand for traffic management is one of the main challenges of the 21st century. The issue is much more apparent in urban areas during rush hours. Traffic congestion causes economic losses due to delays and increased fuel consumption and, on top of that, is a major health risk. Intelligent centralized traffic routing is an important concept aiming at reducing traffic congestion in urban areas by more effectively utilizing road networks. In this demo, we present a framework that, in a nutshell, integrates techniques for intelligent centralized traffic routing into the well-known SUMO simulator, so these techniques can be evaluated in realistic settings on real/realistic datasets. In particular, the framework automatically identifies ``problematic&#39;&#39; urban regions by analyzing historical traffic data, then simplifies the road networks by precomputing promising routes (for each considered traffic flow), and finally, leverages a planning-based approach to generate routes. Our framework is evaluated on a real dataset from Dublin&#39;s metropolitan area. Keywords: Multidisciplinary Topics and Applications: MDA: Transportation Planning and Scheduling: PS: Applications Planning and Scheduling: PS: Routing},
  archive   = {C_IJCAI},
  author    = {Matyáš Švadlenka and Lukas Chrpa},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/1038},
  month     = {8},
  pages     = {8810-8814},
  title     = {A framework for centralized traffic routing in urban areas},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PiShield: A PyTorch package for learning with requirements.
<em>IJCAI</em>, 8805–8809. (<a
href="https://doi.org/10.24963/ijcai.2024/1037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep learning models have shown their strengths in various application domains, however, they often struggle to meet safety requirements for their outputs. In this paper, we introduce PiShield, the first package ever allowing for the integration of the requirements into the neural networks&#39; topology. PiShield guarantees compliance with these requirements, regardless of input. Additionally, it allows for integrating requirements both at inference and/or training time, depending on the practitioners&#39; needs. Given the widespread application of deep learning, there is a growing need for frameworks allowing for the integration of the requirements across various domains. Here, we explore three application scenarios: functional genomics, autonomous driving, and tabular data generation. Keywords: Machine Learning: ML: Neuro-symbolic methods Machine Learning: ML: Knowledge-aided learning Machine Learning: ML: Structured prediction AI Ethics, Trust, Fairness: ETF: Safety and robustness},
  archive   = {C_IJCAI},
  author    = {Mihaela C. Stoian and Alex Tatomir and Thomas Lukasiewicz and Eleonora Giunchiglia},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/1037},
  month     = {8},
  pages     = {8805-8809},
  title     = {PiShield: A PyTorch package for learning with requirements},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ToDo: Token downsampling for efficient generation of
high-resolution images. <em>IJCAI</em>, 8801–8804. (<a
href="https://doi.org/10.24963/ijcai.2024/1036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Attention has been a crucial component in the success of image diffusion models, however, their quadratic computational complexity limits the sizes of images we can process within reasonable time and memory constraints. This paper investigates the importance of dense attention in generative image models, which often contain redundant features, making them suitable for sparser attention mechanisms. We propose a novel training-free method ToDo that relies on token downsampling of key and value tokens to accelerate Stable Diffusion inference by up to 2x for common sizes and up to 4.5x or more for high resolutions like 2048 × 2048. We demonstrate that our approach outperforms previous methods in balancing efficient throughput and fidelity. Keywords: Computer Vision: CV: Neural generative models, auto encoders, GANs Machine Learning: ML: Attention models},
  archive   = {C_IJCAI},
  author    = {Ethan Smith and Nayan Saxena and Aninda Saha},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/1036},
  month     = {8},
  pages     = {8801-8804},
  title     = {ToDo: Token downsampling for efficient generation of high-resolution images},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards a resilient intelligent automation system.
<em>IJCAI</em>, 8797–8800. (<a
href="https://doi.org/10.24963/ijcai.2024/1035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Intelligent Process Automation (IPA) solutions must adapt to changes in user interfaces autonomously, without manual intervention. Addressing this critical challenge and aiming to advance the state-of-the-art, last year we introduced the IPA Challenge competition at IJCAI 2023. This demo paper presents IDA - our novel UI automation solution, developed to tackle complex resiliency issues. Leveraging the capabilities of large language models and employing grounded instructions, our system demonstrates a significant advancement towards resilient IPA. We provide an overview of the IPA Challenge, detail the architecture of our system, and illustrate its effectiveness in overcoming the resiliency challenges. A link to the demo video can be found at: https://youtu.be/G5nI3V9Umjc Keywords: Humans and AI: HAI: Intelligent user interfaces Agent-based and Multi-agent Systems: MAS: Trust and reputation AI Ethics, Trust, Fairness: ETF: Safety and robustness Humans and AI: HAI: Applications Humans and AI: HAI: Other Natural Language Processing: NLP: Language grounding},
  archive   = {C_IJCAI},
  author    = {Segev Shlomov and Sami Marreed and Avi Yaeli},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/1035},
  month     = {8},
  pages     = {8797-8800},
  title     = {Towards a resilient intelligent automation system},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). O2ARC 3.0: A platform for solving and creating ARC tasks.
<em>IJCAI</em>, 8793–8796. (<a
href="https://doi.org/10.24963/ijcai.2024/1034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We introduce O2ARC 3.0 interface for the Abstraction and Reasoning Corpus (ARC). O2ARC 3.0 gamifies the experience, fostering user engagement through competitive features and community-driven problem creation and evaluation. Built with a React frontend and NestJS backend, the platform provides a responsive and intuitive interface for efficient rule inference. This approach not only improves data collection for AI training but also enhances the problem-solving process, offering a scalable solution for advancing cognitive AI research. O2ARC is available at https://o2arc.com. Keywords: Humans and AI: HAI: Intelligent user interfaces Data Mining: DM: Applications Humans and AI: HAI: Applications Humans and AI: HAI: Human-computer interaction Knowledge Representation and Reasoning: KRR: Reasoning about knowledge and belief Machine Learning: ML: Applications Machine Learning: ML: Few-shot learning Multidisciplinary Topics and Applications: MDA: Interactive entertainment Multidisciplinary Topics and Applications: MDA: Software engineering},
  archive   = {C_IJCAI},
  author    = {Suyeon Shim and Dohyun Ko and Hosung Lee and Seokki Lee and Doyoon Song and Sanha Hwang and Sejin Kim and Sundong Kim},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/1034},
  month     = {8},
  pages     = {8793-8796},
  title     = {O2ARC 3.0: A platform for solving and creating ARC tasks},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Rhythm inference helping writing music scores.
<em>IJCAI</em>, 8789–8792. (<a
href="https://doi.org/10.24963/ijcai.2024/1033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present a new problem called rhythm inference. It consists in inferring the duration of each note and each rest from a partial specification. We then formulate rhythm inference as a constraint satisfaction problem and we use mixed linear programming to solve it. The solution is implemented for a language representing music scores, called abcd. Interestingly, the rhythm is inferred in real-time from partial musical indications. Keywords: Constraint Satisfaction and Optimization: CSO: Applications Constraint Satisfaction and Optimization: CSO: Constraint satisfaction Constraint Satisfaction and Optimization: CSO: Modeling Multidisciplinary Topics and Applications: MDA: Arts and creativity},
  archive   = {C_IJCAI},
  author    = {François Schwarzentruber},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/1033},
  month     = {8},
  pages     = {8789-8792},
  title     = {Rhythm inference helping writing music scores},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Inside out: Emotional multiagent multimodal dialogue
systems. <em>IJCAI</em>, 8784–8788. (<a
href="https://doi.org/10.24963/ijcai.2024/1032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we introduce the novel technological framework for the development of emotional dialogue systems. Inspired by the &quot;Inside Out&quot; film, we propose to use multiple emotional agents based on Large Language Models (LLMs) to prepare answers to a user query. Their answers are aggregated into a single response, taking into account the current emotional state of a user. The latter is estimated by video-based facial expression recognition (FER). We introduce several publicly available lightweight neural networks that show near state-of-the-art results on the AffectNet dataset. Qualitative examples using either GPT-3.5 or LLama2 and Mistral demonstrate that the proposed approach leads to more emotional responses in LLMs. Keywords: Natural Language Processing: NLP: Language generation Computer Vision: CV: Biometrics, face, gesture and pose recognition Agent-based and Multi-agent Systems: MAS: Applications Humans and AI: HAI: Human-computer interaction},
  archive   = {C_IJCAI},
  author    = {Andrey V. Savchenko and Lyudmila V. Savchenko},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/1032},
  month     = {8},
  pages     = {8784-8788},
  title     = {Inside out: Emotional multiagent multimodal dialogue systems},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Digital avatars: Framework development and their evaluation.
<em>IJCAI</em>, 8780–8783. (<a
href="https://doi.org/10.24963/ijcai.2024/1031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present a novel prompting strategy for artificial intelligence driven digital avatars. To better quantify how our prompting strategy affects anthropomorphic features like humor, authenticity, and favorability we present Crowd Vote - an adaptation of Crowd Score that allows for judges to elect a large language model (LLM) candidate over competitors answering the same or similar prompts. To visualize the responses of our LLM, and the effectiveness of our prompting strategy we propose an end-to-end framework for creating high-fidelity artificial intelligence (AI) driven digital avatars. This pipeline effectively captures an individual&#39;s essence for interaction and our streaming algorithm delivers a high-quality digital avatar with real-time audio-video streaming from server to mobile device. Both our visualization tool, and our Crowd Vote metrics demonstrate our AI driven digital avatars have state-of-the-art humor, authenticity, and favorability outperforming all competitors and baselines. In the case of our Donald Trump and Joe Biden avatars, their authenticity and favorability are rated higher than even their real-world equivalents. Keywords: Humans and AI: HAI: Applications Humans and AI: HAI: Human-AI collaboration Humans and AI: HAI: Human-computer interaction},
  archive   = {C_IJCAI},
  author    = {Timothy Rupprecht and Sung-En Chang and Yushu Wu and Lei Lu and Enfu Nan and Chih-hsiang Li and Caiyue Lai and Zhimin Li and Zhijun Hu and Yumei He and David Kaeli and Yanzhi Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/1031},
  month     = {8},
  pages     = {8780-8783},
  title     = {Digital avatars: Framework development and their evaluation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AADMIP: Adversarial attacks and defenses modeling in
industrial processes. <em>IJCAI</em>, 8776–8779. (<a
href="https://doi.org/10.24963/ijcai.2024/1030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The development of the smart manufacturing trend includes the integration of Artificial Intelligence technologies into industrial processes. One example of such implementation is deep learning models that diagnose the current state of a technological process. Recent studies have demonstrated that small data perturbations, named adversarial attacks, can significantly affect the correct predictions of such models. This fact is critical in industrial systems, where AI-based decisions can be made to manage physical equipment. In this work, we present a system which can help to evaluate the robustness of technological process diagnosis models to adversarial attacks, as well as consider protection options. We briefly review the system&#39;s modules and also consider some useful applications. Our demo video is available at: http://tinyurl.com/3by9zcj5 Keywords: Machine Learning: ML: Adversarial machine learning Machine Learning: ML: Evaluation Multidisciplinary Topics and Applications: MDA: Real-time systems Multidisciplinary Topics and Applications: MDA: Security and privacy},
  archive   = {C_IJCAI},
  author    = {Vitaliy Pozdnyakov and Aleksandr Kovalenko and Ilya Makarov and Mikhail Drobyshevskiy and Kirill Lukyanov},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/1030},
  month     = {8},
  pages     = {8776-8779},
  title     = {AADMIP: Adversarial attacks and defenses modeling in industrial processes},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). XGA-osteo: Towards XAI-enabled knee osteoarthritis diagnosis
with adversarial learning. <em>IJCAI</em>, 8771–8775. (<a
href="https://doi.org/10.24963/ijcai.2024/1029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This research introduces XGA-Osteo, an innovative approach that leverages Explainable Artificial Intelligence (XAI) to enhance the accuracy and interpretability of knee osteoarthritis diagnosis. Recent studies have utilized AI approaches to automate the diagnosis using knee joint X-ray images. However, these studies have primarily focused on predicting the severity of osteoarthritis without providing additional information to assist doctors in their diagnoses. In addition to accurately diagnosing the severity of the condition, XGA-Osteo generates an anomaly map, produced from a reconstructed image of a healthy knee using adversarial learning. Thus, the abnormal regions in X-ray images can be highlighted, offering valuable supplementary information to medical experts during the diagnosis process. Keywords: Multidisciplinary Topics and Applications: MDA: Health and medicine Machine Learning: ML: Autoencoders Machine Learning: ML: Generative adverserial networks Machine Learning: ML: Unsupervised learning},
  archive   = {C_IJCAI},
  author    = {Hieu Phan and Loc Le and Mao Nguyen and Phat Nguyen and Sang Nguyen and Minh-Triet Tran and Tho Quan},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/1029},
  month     = {8},
  pages     = {8771-8775},
  title     = {XGA-osteo: Towards XAI-enabled knee osteoarthritis diagnosis with adversarial learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SmartTransit.AI: A dynamic paratransit and microtransit
application. <em>IJCAI</em>, 8767–8770. (<a
href="https://doi.org/10.24963/ijcai.2024/1028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {New rideshare and shared mobility services have transformed urban mobility in recent years. Such services have the potential to improve efficiency and reduce costs by allowing users to share rides in high-capacity vehicles and vans. Most transit agencies already operate various ridepooling services, including microtransit and paratransit. However, the objectives and constraints for implementing these services vary greatly between agencies and can be challenging. First, off-the-shelf ridepooling formulations must be adapted for real-world conditions and constraints. Second, the lack of modular and reusable software makes it hard to implement and evaluate new ridepooling algorithms and approaches in real-world settings. We demonstrate a modular on-demand public transportation scheduling software for microtransit and paratransit services. The software is aimed at transit agencies looking to incorporate state-of-the-art rideshare and ridepooling algorithms in their everyday operations. We provide management software for dispatchers and mobile applications for drivers and users and conclude with results from the demonstration in Chattanooga, TN. Keywords: Multidisciplinary Topics and Applications: MDA: Transportation Planning and Scheduling: PS: Applications Planning and Scheduling: PS: Planning algorithms Planning and Scheduling: PS: Scheduling},
  archive   = {C_IJCAI},
  author    = {Sophie Pavia and David Rogers and Amutheezan Sivagnanam and Michael Wilbur and Danushka Edirimanna and Youngseo Kim and Ayan Mukhopadhyay and Philip Pugliese and Samitha Samaranayake and Aron Laszka and Abhishek Dubey},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/1028},
  month     = {8},
  pages     = {8767-8770},
  title     = {SmartTransit.AI: A dynamic paratransit and microtransit application},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AVIN-chat: An audio-visual interactive chatbot system with
emotional state tuning. <em>IJCAI</em>, 8763–8766. (<a
href="https://doi.org/10.24963/ijcai.2024/1027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This work presents an audio-visual interactive chatbot (AVIN-Chat) system that allows users to have face-to-face conversations with 3D avatars in real-time. Compared to the previous chatbot services, which provide text-only or speech-only communications, the proposed AVIN-Chat can offer audio-visual communications providing users with a superior experience quality. In addition, the proposed AVIN-Chat emotionally speaks and expresses according to the user&#39;s emotional state. Thus, it enables users to establish a strong bond with the chatbot system, increasing the user&#39;s immersion. Through user subjective tests, it is demonstrated that the proposed system provides users with a higher sense of immersion than previous chatbot systems. The demonstration video is available at https://www.youtube.com/watch?v=Z74uIV9k7_k. Keywords: Computer Vision: CV: Applications Natural Language Processing: NLP: Applications},
  archive   = {C_IJCAI},
  author    = {Chanhyuk Park and Jungbin Cho and Junwan Kim and Seongmin Lee and Jungsu Kim and Sanghoon Lee},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/1027},
  month     = {8},
  pages     = {8763-8766},
  title     = {AVIN-chat: An audio-visual interactive chatbot system with emotional state tuning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ComVas: Contextual moral values alignment system.
<em>IJCAI</em>, 8759–8762. (<a
href="https://doi.org/10.24963/ijcai.2024/1026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In contemporary society, the integration of artificial intelligence (AI) systems into various aspects of daily life raises significant ethical concerns. One critical aspect is to ensure that AI systems align with the moral values of the endusers. To that end, we introduce the Contextual Moral Value Alignment System, ComVas. Unlike traditional AI systems which have moral values predefined, ComVas empowers users to dynamically select and customize the desired moral values thereby guiding the system’s decision-making process. Through a user-friendly interface, individuals can specify their preferred morals, allowing the system to steer the model’s responses and actions accordingly. ComVas utilizes advanced natural language processing techniques to engage with the users in a meaningful dialogue, understanding their preferences, and reasoning about moral dilemmas in diverse contexts. This demo article showcases the functionality of ComVas, illustrating its potential to foster ethical decision-making in AI systems while respecting individual autonomy and promoting user-centric design principles. Keywords: Natural Language Processing: NLP: Language models AI Ethics, Trust, Fairness: ETF: Moral decision making},
  archive   = {C_IJCAI},
  author    = {Inkit Padhi and Pierre Dognin and Jesus Rios and Ronny Luss and Swapnaja Achintalwar and Matthew Riemer and Miao Liu and Prasanna Sattigeri and Manish Nagireddy and Kush R. Varshney and Djallel Bouneffouf},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/1026},
  month     = {8},
  pages     = {8759-8762},
  title     = {ComVas: Contextual moral values alignment system},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LangXAI: Integrating large vision models for generating
textual explanations to enhance explainability in visual perception
tasks. <em>IJCAI</em>, 8754–8758. (<a
href="https://doi.org/10.24963/ijcai.2024/1025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {LangXAI is a framework that integrates Explainable Artificial Intelligence (XAI) with advanced vision models to generate textual explanations for visual recognition tasks. Despite XAI advancements, an understanding gap persists for end-users with limited domain knowledge in artificial intelligence and computer vision. LangXAI addresses this by furnishing text-based explanations for classification, object detection, and semantic segmentation model outputs to end-users. Preliminary results demonstrate LangXAI&#39;s enhanced plausibility, with high BERTScore across tasks, fostering a more transparent and reliable AI framework on vision tasks for end-users. The code and demo of this work can be found at https://analytics-everywhere-lab.github.io/langxai.io/. Keywords: AI Ethics, Trust, Fairness: ETF: Explainability and interpretability Computer Vision: CV: Applications},
  archive   = {C_IJCAI},
  author    = {Hung Nguyen and Tobias Clement and Loc Nguyen and Nils Kemmerzell and Binh Truong and Khang Nguyen and Mohamed Abdelaal and Hung Cao},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/1025},
  month     = {8},
  pages     = {8754-8758},
  title     = {LangXAI: Integrating large vision models for generating textual explanations to enhance explainability in visual perception tasks},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ReportParse: A unified NLP tool for extracting document
structure and semantics of corporate sustainability reporting.
<em>IJCAI</em>, 8749–8753. (<a
href="https://doi.org/10.24963/ijcai.2024/1024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We introduce ReportParse, a Python-based tool designed to parse corporate sustainability reports. It combines document structure analysis with natural language processing (NLP) models to extract sustainability-related information from the reports. We also provide easy-to-use web and command interfaces. The tool is expected to aid researchers and analysts in evaluating corporate commitment to and management of sustainability efforts. Keywords: Natural Language Processing: NLP: Tools Multidisciplinary Topics and Applications: MDA: Finance Multidisciplinary Topics and Applications: MDA: Social sciences Natural Language Processing: NLP: Applications},
  archive   = {C_IJCAI},
  author    = {Gaku Morio and Soh Young In and Jungah Yoon and Harri Rowlands and Christopher Manning},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/1024},
  month     = {8},
  pages     = {8749-8753},
  title     = {ReportParse: A unified NLP tool for extracting document structure and semantics of corporate sustainability reporting},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SaGol: Using MiniGPT-4 to generate alt text for improving
image accessibility. <em>IJCAI</em>, 8745–8748. (<a
href="https://doi.org/10.24963/ijcai.2024/1023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {SaGol is an AI-powered application to improve image accessibility for people with visual impairments (PVI) users. Alternative (alt) text, a general method of web accessibility for PVI users, is text or phrases that describe images on a website in an understandable way. SaGol generates alt text with the images on the user&#39;s smartphone using a vision large language model called MiniGPT-4. SaGol searches for similar images based on the generated alt text. We evaluated the length of alt text and the search accuracy. This paper shows a potential opportunity to improve image accessibility for PVI users. Keywords: Humans and AI: HAI: Human-computer interaction Humans and AI: HAI: Applications Humans and AI: HAI: Intelligent user interfaces},
  archive   = {C_IJCAI},
  author    = {Yunseo Moon and Hyunmin Lee and SeungYoung Oh and Hyunggu Jung},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/1023},
  month     = {8},
  pages     = {8745-8748},
  title     = {SaGol: Using MiniGPT-4 to generate alt text for improving image accessibility},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DFRP: A dual-track feedback recommendation system for
educational resources. <em>IJCAI</em>, 8741–8744. (<a
href="https://doi.org/10.24963/ijcai.2024/1022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The educational disparities among different regions are remarkably significant. The educational resource platform can effectively bridge the educational capability gap between regions. Most of the existing recommendation algorithms only consider interaction history, while we argue that the dependencies between knowledge points and education-related features are crucial for education resource recommendations. To address this, we propose DFRP, an educational resource recommendation platform based on knowledge graphs(KGs) and educational scale feedback. DFRP employs a recommendation algorithm based on teaching pathways and educational dimensions to achieve accurate recommendations and active feedback on educational resources. We also provide a detailed description of the system framework and present a demonstration scenario that uses educational scales for active feedback and KGs to show knowledge point dependencies. Keywords: Data Mining: DM: Recommender systems Humans and AI: HAI: Computer-aided education Multidisciplinary Topics and Applications: MDA: Education Search: S: Applications},
  archive   = {C_IJCAI},
  author    = {ChaoJun Meng and Changfan Pan and Zilong Li and Cong Zhou and Xinran Cao and Jia Zhu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/1022},
  month     = {8},
  pages     = {8741-8744},
  title     = {DFRP: A dual-track feedback recommendation system for educational resources},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AESim: A data-driven aircraft engine simulator.
<em>IJCAI</em>, 8737–8740. (<a
href="https://doi.org/10.24963/ijcai.2024/1021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present AESim, a data-driven Aircraft Engine Simulator developed using transformer-based conditional generative adversarial networks. AESim generates samples of aircraft engine sensor measurements over full flights, conditioned on a given flight mission profile representing the flight conditions. It constitutes an essential tool in aircraft engine digital twins, capable of simulating their performance for different flight missions. It allows for comparison of the behavior of different engines under the same operational conditions, simulation of various scenarios for a given engine, facilitating applications like engine behavior analysis, performance limit identification, and optimization of maintenance schedules within a global Prognostics and Health Management (PHM) strategy. It also allows the imputation of missing flight data and addresses confidentiality concerns by generating synthetic flight datasets that can be shared for public research purposes or data challenges. Keywords: Machine Learning: ML: Applications Machine Learning: ML: Attention models Machine Learning: ML: Generative adverserial networks Machine Learning: ML: Time series and data streams},
  archive   = {C_IJCAI},
  author    = {Abdellah Madane and Florent Forest and Hanane Azzag and Mustapha Lebbah and Jérôme Lacaille},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/1021},
  month     = {8},
  pages     = {8737-8740},
  title     = {AESim: A data-driven aircraft engine simulator},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mahjong AI competition: Exploring AI application in complex
real-world games. <em>IJCAI</em>, 8733–8736. (<a
href="https://doi.org/10.24963/ijcai.2024/1020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper presents three Mahjong AI competitions we held at IJCAI. We briefly introduce the rule of Mahjong and its challenges to AI algorithms. By showing the results and the application of various algorithms in the competitions, we claim that existing algorithms show promising results in Mahjong, while open problems remain and more efforts are needed towards solving this complex game. Keywords: Multidisciplinary Topics and Applications: MDA: Game playing Machine Learning: ML: Applications Machine Learning: ML: Deep reinforcement learning Search: S: Game playing Search: S: Heuristic search Multidisciplinary Topics and Applications: MDA: Computer games Agent-based and Multi-agent Systems: MAS: Applications Agent-based and Multi-agent Systems: MAS: Multi-agent learning},
  archive   = {C_IJCAI},
  author    = {Yunlong Lu and Wenxin Li},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/1020},
  month     = {8},
  pages     = {8733-8736},
  title     = {Mahjong AI competition: Exploring AI application in complex real-world games},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Place anything into any video. <em>IJCAI</em>, 8729–8732.
(<a href="https://doi.org/10.24963/ijcai.2024/1019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Controllable video editing has demonstrated remarkable potential across diverse applications, particularly in scenarios where capturing or re-capturing real-world videos is either impractical or costly. This paper introduces a novel and efficient system named Place-Anything, which facilitates the insertion of any object into any video solely based on a picture or text description of the target object or element. The system comprises three modules: 3D generation, video reconstruction, and 3D target insertion. This integrated approach offers an efficient and effective solution for producing and editing high-quality videos by naturally inserting realistic objects. Through experiment, we demonstrate that our system can effortlessly place any object into any video using just a photograph of the object. Our demo video can be found at https://youtu.be/afXqgLLRnTE. Please also visit our project page https://place-anything.github.io to get more information. Keywords: Computer Vision: CV: Applications Computer Vision: CV: Scene analysis and understanding Computer Vision: CV: Video analysis and understanding},
  archive   = {C_IJCAI},
  author    = {Ziling Liu and Jinyu Yang and Mingqi Gao and Feng Zheng},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/1019},
  month     = {8},
  pages     = {8729-8732},
  title     = {Place anything into any video},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Real-time multi-modal object detection and tracking on edge
for regulatory compliance monitoring. <em>IJCAI</em>, 8725–8728. (<a
href="https://doi.org/10.24963/ijcai.2024/1018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Regulatory compliance auditing in agrifood processing facilities is crucial for upholding the highest standards of quality assurance and traceability. However, the current manual and intermittent approaches to auditing present significant challenges and risks, potentially leading to gaps or loopholes in the system. To address these shortcomings, we introduce a real-time, multi-modal sensing system that utilizes 3D time-of-flight and RGB cameras and leverages unsupervised learning techniques on edge AI devices. The proposed system enables continuous object tracking, leading to improved efficiency in record-keeping and reduced manual labor. We demonstrate the effectiveness of the system in a knife sanitization monitoring scenario, showcasing its capability to overcome occlusion and low-light performance limitations commonly encountered with conventional RGB cameras. Keywords: Computer Vision: CV: Action and behavior recognition Computer Vision: CV: 3D computer vision Computer Vision: CV: Applications Computer Vision: CV: Recognition (object detection, categorization) Computer Vision: CV: Video analysis and understanding Machine Learning: ML: Applications},
  archive   = {C_IJCAI},
  author    = {Jia Syuen Lim and Ziwei Wang and Jiajun Liu and Abdelwahed Khamis and Reza Arablouei and Robert Barlow and Ryan McAllister},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/1018},
  month     = {8},
  pages     = {8725-8728},
  title     = {Real-time multi-modal object detection and tracking on edge for regulatory compliance monitoring},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Interactive visual learning for stable diffusion.
<em>IJCAI</em>, 8721–8724. (<a
href="https://doi.org/10.24963/ijcai.2024/1017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Diffusion-based generative models’ impressive ability to create convincing images has garnered global attention. However, their complex internal structures and operations often pose challenges for non-experts to grasp. We introduce Diffusion Explainer, the first interactive visualization tool designed to elucidate how Stable Diffusion transforms text prompts into images. It tightly integrates a visual overview of Stable Diffusion’s complex components with detailed explanations of their underlying operations. This integration enables users to fluidly transition between multiple levels of abstraction through animations and interactive elements. Offering real-time hands-on experience, Diffusion Explainer allows users to adjust Stable Diffusion’s hyperparameters and prompts without the need for installation or specialized hardware. Accessible via users’ web browsers, Diffusion Explainer is making significant strides in democratizing AI education, fostering broader public access. More than 7,200 users spanning 113 countries have used our open-sourced tool at https://poloclub.github.io/diffusion-explainer/. A video demo is available at https://youtu.be/MbkIADZjPnA. Keywords: Humans and AI: HAI: Human-computer interaction Computer Vision: CV: Neural generative models, auto encoders, GANs Humans and AI: HAI: Intelligent user interfaces},
  archive   = {C_IJCAI},
  author    = {Seongmin Lee and Benjamin Hoover and Hendrik Strobelt and Zijie J. Wang and ShengYun Peng and Austin Wright and Kevin Li and Haekyu Park and Haoyang Yang and Duen Horng Chau},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/1017},
  month     = {8},
  pages     = {8721-8724},
  title     = {Interactive visual learning for stable diffusion},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). IFakeDetector: Real time integrated web-based deepfake
detection system. <em>IJCAI</em>, 8717–8720. (<a
href="https://doi.org/10.24963/ijcai.2024/1016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, deepfake detection research has been actively conducted. While many deepfake detectors have been proposed, validating the practicality of such systems against real world settings has not been explored much. Indeed, there are some gaps and disparities when they are applied in the real world. In this work, we developed a real time integrated web-based deepfake detection system, iFakeDetector, which incorporates the recent high performing deepfake detectors, and enables easy access for non-expert users to evaluate deepfake videos. Our system takes a deepfake video as input, allowing users to upload videos and select different detectors, and provides detection results on whether the uploaded video is a deepfake or not. Also, we provide an analysis tool that enables the video to be analyzed on a frame-by-frame basis with the probability of each frame being manipulated. Finally, we tested and deployed iFakeDetector in a real world scenario to verify its practicality and feasibility. Keywords: AI Ethics, Trust, Fairness: ETF: Ethical, legal and societal issues AI Ethics, Trust, Fairness: ETF: Societal impact of AI Computer Vision: CV: Applications Computer Vision: CV: Machine learning for vision Humans and AI: HAI: Applications Humans and AI: HAI: Human-computer interaction},
  archive   = {C_IJCAI},
  author    = {Kangjun Lee and Inho Jung and Simon S. Woo},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/1016},
  month     = {8},
  pages     = {8717-8720},
  title     = {IFakeDetector: Real time integrated web-based deepfake detection system},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SPARK: Harnessing human-centered workflows with biomedical
foundation models for drug discovery. <em>IJCAI</em>, 8713–8716. (<a
href="https://doi.org/10.24963/ijcai.2024/1015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Biomedical foundation models, trained on diverse sources of small molecule data, hold great potential for accelerating drug discovery. However, their complex nature often presents a barrier for researchers seeking scientific insights and drug candidate generation. SPARK addresses this challenge by providing a user-friendly, web-based interface that empowers researchers to leverage these powerful models in their scientific workflows. Through SPARK, users can specify target proteins and desired molecule properties, adjust pre-trained models for tailored inferences, generate lists of potential drug candidates, analyze and compare molecules through interactive visualizations, and filter candidates based on key metrics (e.g., toxicity). By seamlessly integrating human knowledge and biomedical AI models&#39; capabilities through an interactive web-based system, SPARK can improve the efficiency of collaboration between human experts and AI, thereby accelerating drug candidate discovery and ultimately leading to breakthroughs in finding cures for various diseases. Keywords: Humans and AI: HAI: Human-AI collaboration Data Mining: DM: Data visualization Multidisciplinary Topics and Applications: MDA: Bioinformatics Multidisciplinary Topics and Applications: MDA: Health and medicine},
  archive   = {C_IJCAI},
  author    = {Bum Chul Kwon and Simona Rabinovici-Cohen and Beldine Moturi and Ruth Mwaura and Kezia Wahome and Oliver Njeru and Miguel Shinyenyi and Catherine Wanjiru and Sekou Remy and William Ogallo and Itai Guez and Partha Suryanarayanan and Joseph Morrone and Shreyans Sethi and Seung-Gu Kang and Tien Huynh and Kenney Ng and Diwakar Mahajan and Hongyang Li and Matan Ninio and Shervin Ayati and Efrat Hexter and Wendy Cornell},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/1015},
  month     = {8},
  pages     = {8713-8716},
  title     = {SPARK: Harnessing human-centered workflows with biomedical foundation models for drug discovery},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ProMoAI: Process modeling with generative AI.
<em>IJCAI</em>, 8708–8712. (<a
href="https://doi.org/10.24963/ijcai.2024/1014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {ProMoAI is a novel tool that leverages Large Language Models (LLMs) to automatically generate process models from textual descriptions, incorporating advanced prompt engineering, error handling, and code generation techniques. Beyond automating the generation of complex process models, ProMoAI also supports process model optimization. Users can interact with the tool by providing feedback on the generated model, which is then used for refining the process model. ProMoAI utilizes the capabilities LLMs to offer a novel, AI-driven approach to process modeling, significantly reducing the barrier to entry for users without deep technical knowledge in process modeling. Keywords: Natural Language Processing: NLP: Language models Natural Language Processing: NLP: Applications Natural Language Processing: NLP: Dialogue and interactive systems Humans and AI: General},
  archive   = {C_IJCAI},
  author    = {Humam Kourani and Alessandro Berti and Daniel Schuster and Wil M.P. van der Aalst},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/1014},
  month     = {8},
  pages     = {8708-8712},
  title     = {ProMoAI: Process modeling with generative AI},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AUTODRAITEC: An infrastructure-based AUTOnomous DRiving
system using artificial intelligence and TEleCommunication technologies.
<em>IJCAI</em>, 8704–8707. (<a
href="https://doi.org/10.24963/ijcai.2024/1013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper introduces AUTODRAITEC, a novel AI-based system that is deployed on the road infrastructure to control the driving of Connected and Autonomous Vehicles (CAVs). For this purpose, we present a convincing proof of concept that demonstrates the effectiveness of our solution. The system deploys a hybrid machine learning approach comprised of a supervised learning classifier to characterize the behaviors of human drivers, with a deep reinforcement learning policy to provide speed recommendations for CAVs. This system is implemented using perception sensors and an industrial computer (IPC), which are intended to be deployed on the road infrastructure. Using a 1:18 scale testbed that faithfully replicates real-world driving scenarios, we demonstrate that AUTODRAITEC improves driving safety and efficiency while preserving the traffic flow rate. Keywords: Machine Learning: ML: Deep reinforcement learning Machine Learning: ML: Explainable/Interpretable machine learning Multidisciplinary Topics and Applications: MDA: Transportation Robotics: ROB: Motion and path planning},
  archive   = {C_IJCAI},
  author    = {Zine el abidine Kherroubi and Fouzi Boukhalfa and Thierry Lestable and Carlos-Faouzi Bader},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/1013},
  month     = {8},
  pages     = {8704-8707},
  title     = {AUTODRAITEC: An infrastructure-based AUTOnomous DRiving system using artificial intelligence and TEleCommunication technologies},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). NEGOTIATOR: A comprehensive framework for human-agent
negotiation integrating preferences, interaction, and emotion.
<em>IJCAI</em>, 8700–8703. (<a
href="https://doi.org/10.24963/ijcai.2024/1012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The paper introduces a comprehensive human-agent negotiation framework designed to facilitate the development and evaluation of research studies on human-agent negotiation without building each component from scratch. Leveraging the interoperability and reusability of its components, this framework offers various functionalities, including speech-to-text conversion, emotion recognition, a repository of negotiation strategies, and an interaction manager capable of managing gestures designed for Nao, Pepper, and QT, and coordinating message exchanges in a turn-taking fashion. This framework aims to lower the entry barrier for researchers in human-agent negotiation by providing a versatile platform that supports a wide range of research directions, including affective computing, natural language processing, decision-making, and non-verbal communication. Keywords: Agent-based and Multi-agent Systems: MAS: Agreement technologies: Negotiation and contract-based systems Agent-based and Multi-agent Systems: MAS: Human-agent interaction},
  archive   = {C_IJCAI},
  author    = {Mehmet Onur Keskin and Berk Buzcu and Berkecan Koçyiğit and Umut Çakan and Anıl Doğru and Reyhan Aydoğan},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/1012},
  month     = {8},
  pages     = {8700-8703},
  title     = {NEGOTIATOR: A comprehensive framework for human-agent negotiation integrating preferences, interaction, and emotion},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Using large language models and recruiter expertise for
optimized multilingual job offer – applicant CV matching.
<em>IJCAI</em>, 8696–8699. (<a
href="https://doi.org/10.24963/ijcai.2024/1011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the context of the increasingly globalised economy and labour market, recruitment agencies face the challenge to deal with a magnitude of job offers and job applications written in a variety of languages, formats, and styles. Quite often, this leads to a suboptimal evaluation of the CVs of job seekers with respect to their relevance to a job offer. To address this challenge, we propose an interactive system that follows the ``human-in-the-loop&#39;&#39; approach, actively involving recruiters in the job offer -- applicant CV matching. The system uses a fine-tuned state-of-the-art classification model that aligns job seeker CVs with labels of the {\it European Skills, Competences, Qualifications and Occupations} taxonomy to propose an initial match between job offers with the CVs of job candidates. This match is refined in sequential LLM driven-interaction with the recruiter, which culminates in CV relevance scores and reports that justify them. Keywords: Natural Language Processing: NLP: Applications Humans and AI: HAI: Human-AI collaboration Machine Learning: ML: Applications Natural Language Processing: NLP: Language models Natural Language Processing: NLP: Text classification},
  archive   = {C_IJCAI},
  author    = {Hamit Kavas and Marc Serra-Vidal and Leo Wanner},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/1011},
  month     = {8},
  pages     = {8696-8699},
  title     = {Using large language models and recruiter expertise for optimized multilingual job offer – applicant CV matching},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Demo: Enhancing wildlife acoustic data annotation efficiency
through transfer and active learning. <em>IJCAI</em>, 8691–8695. (<a
href="https://doi.org/10.24963/ijcai.2024/1010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Passive Acoustic Monitoring (PAM) has become a key technology in wildlife monitoring, generating large amounts of acoustic data. However, the effective application of machine learning methods for sound event detection in PAM datasets is highly dependent on the accessibility of annotated data, a process that can be labour intensive. As a team of domain experts and machine learning researchers, in this paper we present a no-code annotation tool designed for PAM datasets that incorporates transfer learning and active learning strategies to address the data annotation challenge inherent in PAM. Transfer learning is applied to use pre-trained models to compute meaningful embeddings from the PAM audio files. Active learning iteratively identifies the most informative samples and then presents them to the user for annotation. This iterative approach improves the performance of the model compared to random sample selection. In a preliminary evaluation of the tool, a domain expert annotated part of a real PAM data set. Compared to conventional tools, the workflow of the proposed tool showed a speed improvement of 2-4 times. Further enhancements, such as the incorporation of sound examples, have the potential to further improve efficiency. Keywords: Multidisciplinary Topics and Applications: MDA: Computational sustainability Machine Learning: ML: Active learning Machine Learning: ML: Applications Machine Learning: ML: Classification Machine Learning: ML: Few-shot learning},
  archive   = {C_IJCAI},
  author    = {Hannes Kath and Patricia P. Serafini and Ivan B. Campos and Thiago S. Gouvêa and Daniel Sonntag},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/1010},
  month     = {8},
  pages     = {8691-8695},
  title     = {Demo: Enhancing wildlife acoustic data annotation efficiency through transfer and active learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Artificial intelligence-driven video indexing for rapid
surveillance footage summarization and review. <em>IJCAI</em>,
8687–8690. (<a href="https://doi.org/10.24963/ijcai.2024/1009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper introduces VIDEX, an advanced tool designed to streamline the analysis of surveillance video through a user-friendly interface. VIDEX achieves high development efficiency and maintainability utilizing the Model-View-ViewModel (MVVM) design pattern. The core feature of VIDEX is a footage summary using object detection and anomaly detection. Its architecture ensures efficient data management by organizing detected objects and anomalies within an indexed database, thus facilitating a more rapid review process. Additionally, multi-threading was used to shorten the processing time. VIDEX provides a video summarization that can be used primarily in the criminal investigation stage using the information stored in a database. Discover more about VIDEX and access its resources at https://github.com/nth221/videx. Keywords: Machine Learning: ML: Applications Computer Vision: CV: Recognition (object detection, categorization) Data Mining: DM: Anomaly/outlier detection},
  archive   = {C_IJCAI},
  author    = {Jaemin Jung and Soonyong Park and Harim Kim and Changha Lee and Charmgil Hong},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/1009},
  month     = {8},
  pages     = {8687-8690},
  title     = {Artificial intelligence-driven video indexing for rapid surveillance footage summarization and review},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). InViTe: Individual virtual transfer for personalized 3D face
generation system. <em>IJCAI</em>, 8683–8686. (<a
href="https://doi.org/10.24963/ijcai.2024/1008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With the expansion of the virtual communication industry using VR/AR, it has attracted increasing attention to enable users to represent their personalities in a 3D avatar. As the face of 3D avatars plays a crucial role in conveying human personality, a system that generates and manipulates 3D faces is desired. However, establishing the system is challenging due to the need for human effort and specialized knowledge. To fill this void, we present the Individual Virtual Transfer (InViTe), which enables the creation and customization of a 3D face according to the user&#39;s preference. Our proposed system is featured for 1) 3D face reconstruction with high fidelity texture map, 2) 3D face personalization, 3) realistic rendering results, and 4) real-time mobile virtual applications. We conduct an experiment to demonstrate that the proposed system can achieve sufficient individual personalization of 3D faces. Furthermore, we evaluate the system&#39;s data transmission protocol and demonstrate its efficiency. The demonstration video is available at https://www.youtube.com/watch?v=D 4pXZvGUWU. Keywords: Computer Vision: CV: 3D computer vision Computer Vision: CV: Applications},
  archive   = {C_IJCAI},
  author    = {Mingyu Jang and Kyungjune Lee and Seongmin Lee and Hoseok Tong and Juwan Chung and Yusung Ro and Sanghoon Lee},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/1008},
  month     = {8},
  pages     = {8683-8686},
  title     = {InViTe: Individual virtual transfer for personalized 3D face generation system},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An LLM-enhanced agent-based simulation tool for information
propagation. <em>IJCAI</em>, 8679–8682. (<a
href="https://doi.org/10.24963/ijcai.2024/1007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Influence diffusion models are used for simulating information propagation in social networks. While most existing influence diffusion models are probabilistic, the emergence of Large Language Model (LLM) sheds light on the language-level inferences and interactions of user agents. This paper presents an LLM-enhanced Agent-based Influence Diffusion model (LAID), and a web-based visualization tool, LAIDSim, for simulating the information propagation in social networks. Keywords: Agent-based and Multi-agent Systems: MAS: Agent-based simulation and emergence Agent-based and Multi-agent Systems: MAS: Agent communication Agent-based and Multi-agent Systems: MAS: Agent societies Agent-based and Multi-agent Systems: MAS: Agent theories and models},
  archive   = {C_IJCAI},
  author    = {Yuxuan Hu and Gemju Sherpa and Lan Zhang and Weihua Li and Quan Bai and Yijun Wang and Xiaodan Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/1007},
  month     = {8},
  pages     = {8679-8682},
  title     = {An LLM-enhanced agent-based simulation tool for information propagation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CVAT-BWV: A web-based video annotation platform for police
body-worn video. <em>IJCAI</em>, 8674–8678. (<a
href="https://doi.org/10.24963/ijcai.2024/1006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We introduce an open-source platform for annotating body-worn video (BWV) footage aimed at enhancing transparency and accountability in policing. Despite the widespread adoption of BWVs in police departments, analyzing the vast amount of footage generated has presented significant challenges. This is primarily due to resource constraints, the sensitive nature of the data, which limits widespread access, and consequently, lack of annotations for training machine learning models. Our platform, called CVAT-BWV, offers a secure, locally hosted annotation environment that integrates several AI tools to assist in annotating multimodal data. With features such as automatic speech recognition, speaker diarization, object detection, and face recognition, CVAT-BWV aims to reduce the manual annotation workload, improve annotation quality, and allow for capturing perspectives from a diverse population of annotators. This tool aims to streamline the collection of annotations and the building of models, enhancing the use of BWV data for oversight and learning purposes to uncover insights into police-civilian interactions. Keywords: AI Ethics, Trust, Fairness: ETF: Societal impact of AI Humans and AI: HAI: Human-AI collaboration Machine Learning: ML: Applications Computer Vision: CV: Applications},
  archive   = {C_IJCAI},
  author    = {Parsa Hejabi and Akshay Kiran Padte and Preni Golazizian and Rajat Hebbar and Jackson Trager and Georgios Chochlakis and Aditya Kommineni and Ellie Graeden and Shrikanth Narayanan and Benjamin A.T. Graham and Morteza Dehghani},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/1006},
  month     = {8},
  pages     = {8674-8678},
  title     = {CVAT-BWV: A web-based video annotation platform for police body-worn video},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Plug-and-play unsupervised fault detection and diagnosis for
complex industrial monitoring. <em>IJCAI</em>, 8669–8673. (<a
href="https://doi.org/10.24963/ijcai.2024/1005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Today industrial facilities are equipped with lots of sensors throughout all the production line for monitoring means. Gathered data can be used to detect and predict failures; however, manual labeling of large amounts of data for supervised learning is complicated. This paper introduces an innovative approach to unsupervised fault detection and diagnosis tailored for monitoring industrial chemical processes. We showcase the efficacy of our model using two publicly accessible datasets from the Tennessee Eastman Process, each containing various faults. Furthermore, we illustrate that by fine-tuning the model on a limited amount of labeled data, it achieves performance close to that of a state-of-the-art model trained on the entire dataset. Keywords: Data Mining: DM: Anomaly/outlier detection Machine Learning: ML: Clustering Machine Learning: ML: Self-supervised Learning Machine Learning: ML: Time series and data streams Machine Learning: ML: Unsupervised learning},
  archive   = {C_IJCAI},
  author    = {Maksim Golyadkin and Maria Shtark and Petr Ivanov and Alexander Kozhevnikov and Leonid Zhukov and Ilya Makarov},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/1005},
  month     = {8},
  pages     = {8669-8673},
  title     = {Plug-and-play unsupervised fault detection and diagnosis for complex industrial monitoring},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing manufacturing with AI-powered process design.
<em>IJCAI</em>, 8665–8668. (<a
href="https://doi.org/10.24963/ijcai.2024/1004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Manufacturing companies are experiencing a transformative journey, moving from labor-intensive processes to integrating cutting-edge technologies such as digitalization and AI. In this demo paper, we present a novel AI tool to enhance manufacturing processes. Remarkably, our work has been developed in collaboration with Agrati S.p.A., a worldwide leading company in the bolts manufacturing sector. In particular, we propose an AI-powered tool to address the problem of automatically generating the production cycle of a bolt. Currently, this decision-making task is performed by process engineers who spend several days to study, draw, and test multiple alternatives before finding the desired production cycle. We cast this task as a model-based planning problem, mapping bolt technical drawings and metal deformations to, potentially continuous, states and actions, respectively. Furthermore, we resort to computer vision tools and visual transformers to design efficient heuristics that make the search affordable in concrete applications. Agrati S.p.A.&#39;s process engineers extensively validated our tool, and they are currently using it to support their work. To the best of our knowledge, ours is the first AI tool dealing with production cycle design in bolt manufacturing. Keywords: Planning and Scheduling: PS: Applications Search: S: Heuristic search},
  archive   = {C_IJCAI},
  author    = {Gianmarco Genalti and Gabriele Corbo and Tommaso Bianchi and Marco Missaglia and Luca Negri and Andrea Sala and Luca Magri and Giacomo Boracchi and Giovanni Miragliotta and Nicola Gatti},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/1004},
  month     = {8},
  pages     = {8665-8668},
  title     = {Enhancing manufacturing with AI-powered process design},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). From 2D to 3D: AISG-SLA visual localization challenge.
<em>IJCAI</em>, 8661–8664. (<a
href="https://doi.org/10.24963/ijcai.2024/1003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Research in 3D mapping is crucial for smart city applications, yet the cost of acquiring 3D data often hinders progress. Visual localization, particularly monocular camera position estimation, offers a solution by determining the camera&#39;s pose solely through visual cues. However, this task is challenging due to limited data from a single camera. To tackle these challenges, we organized the AISG–SLA Visual Localization Challenge (VLC) at IJCAI 2023 to explore how AI can accurately extract camera pose data from 2D images in 3D space. The challenge attracted over 300 participants worldwide, forming 50+ teams. Winning teams achieved high accuracy in pose estimation using images from a car-mounted camera with low frame rates. The VLC dataset is available for research purposes upon request via vlc-dataset@aisingapore.org. Keywords: Computer Vision: CV: 3D computer vision Computer Vision: CV: Applications Computer Vision: CV: Machine learning for vision Computer Vision: CV: Motion and tracking Computer Vision: CV: Recognition (object detection, categorization) Computer Vision: CV: Scene analysis and understanding Computer Vision: CV: Segmentation},
  archive   = {C_IJCAI},
  author    = {Jialin Gao and Bill Ong and Darld Lwi and Zhen Hao Ng and Xun Wei Yee and Mun-Thye Mak and Wee Siong Ng and See-Kiong Ng and Hui Ying Teo and Victor Khoo and Georg Bökman and Johan Edstedt and Kirill Brodt and Clémentin Boittiaux and Maxime Ferrera and Stepan Konev},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/1003},
  month     = {8},
  pages     = {8661-8664},
  title     = {From 2D to 3D: AISG-SLA visual localization challenge},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LLM-powered GraphQL generator for data retrieval.
<em>IJCAI</em>, 8657–8660. (<a
href="https://doi.org/10.24963/ijcai.2024/1002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {GraphQL offers an efficient, powerful, and flexible alternative to REST APIs. However, application developers writing GraphQL clients need both technical and domain-specific expertise to reap its benefits, and avoid over-fetching or under-fetching data. Automated GraphQL generation has so far proven to be a hard problem because of complex GraphQL schema and lack of benchmark datasets. To address these issues, our work focuses on building an LLM-powered pipeline that can accept user requirements in natural language along with the complex GraphQL schema and automatically produce the GraphQL query needed to retrieve the necessary data. Automated GraphQL generation helps reduce entry barriers to application developers, broadening GraphQL adoption. Keywords: Natural Language Processing: NLP: Applications Data Mining: DM: Applications},
  archive   = {C_IJCAI},
  author    = {Balaji Ganesan and Sambit Ghosh and Nitin Gupta and Manish Kesarwani and Sameep Mehta and Renuka Sindhgatta},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/1002},
  month     = {8},
  pages     = {8657-8660},
  title     = {LLM-powered GraphQL generator for data retrieval},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Do you remember the future? Weak-to-strong generalization in
3D object detection. <em>IJCAI</em>, 8653–8656. (<a
href="https://doi.org/10.24963/ijcai.2024/1001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper demonstrates a novel method for LiDAR-based 3D object detection, addressing major field challenges: sparsity and occlusion. Our approach leverages temporal point cloud sequences to generate frames that provide comprehensive views of objects from multiple angles. To address the challenge of generating these frames in real-time, we employ Knowledge Distillation within a Teacher-Student framework, allowing the Student model to emulate the Teacher’s advanced perception. We pioneered the application of weak-to-strong generalization in computer vision by training our Teacher model on enriched, object-complete data. In this demo, we showcase the exceptional quality of labels produced by the X-Ray Teacher on object-complete frames, showing our method distilling its knowledge to enhance object 3D detection models. Keywords: Computer Vision: CV: 3D computer vision Computer Vision: CV: Recognition (object detection, categorization)},
  archive   = {C_IJCAI},
  author    = {Alexander Gambashidze and Aleksandr Dadukin and Maxim Golyadkin and Maria Razzhivina and Ilya Makarov},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/1001},
  month     = {8},
  pages     = {8653-8656},
  title     = {Do you remember the future? weak-to-strong generalization in 3D object detection},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Probabilistic feature matching for fast scalable visual
prompting. <em>IJCAI</em>, 8648–8652. (<a
href="https://doi.org/10.24963/ijcai.2024/1000">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this work, we propose a novel framework for image segmentation guided by visual prompting which leverages the power of vision foundation models. Inspired by recent advancements in computer vision, our approach integrates multiple large-scale pretrained models to address the challenges of segmentation tasks with limited and sparsely annotated data interactively provided by a user. Our method combines a frozen feature extraction backbone with a scalable and efficient probabilistic feature correspondence (soft matching) procedure derived from Optimal Transport to couple pixels between reference and target images. Moreover, a pretrained segmentation model is harnessed to translate user scribbles into reference masks and matched target pixels into output target segmentation masks. This results in a framework that we name Softmatcher, a versatile and fast training-free architecture for image segmentation by visual prompting. We demonstrate the efficiency and scalability of Softmatcher for real-time interactive image segmentation by visual prompting and showcase it in diverse visual domains including technical visual inspection use cases. Keywords: Computer Vision: CV: Segmentation Computer Vision: CV: Applications Computer Vision: CV: Machine learning for vision Humans and AI: HAI: Human-computer interaction},
  archive   = {C_IJCAI},
  author    = {Thomas Frick and Cezary Skura and Filip M. Janicki and Roy Assaf and Niccolo Avogaro and Daniel Caraballo and Yagmur G. Cinar and Brown Ebouky and Ioana Giurgiu and Takayuki Katsuki and Piotr Kluska and Cristiano Malossi and Haoxiang Qiu and Tomoya Sakai and Florian Scheidegger and Andrej Simeski and Daniel Yang and Andrea Bartezzaghi and Mattia Rigotti},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/1000},
  month     = {8},
  pages     = {8648-8652},
  title     = {Probabilistic feature matching for fast scalable visual prompting},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An interactive human-machine learning interface for
collecting and learning from complex annotations. <em>IJCAI</em>,
8644–8647. (<a href="https://doi.org/10.24963/ijcai.2024/999">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Human-Computer Interaction has been shown to lead to improvements in machine learning systems by boosting model performance, accelerating learning and building user confidence. In this work, we aim to alleviate the expectation that human annotators adapt to the constraints imposed by traditional labels by allowing for extra flexibility in the form that supervision information is collected. For this, we propose a human-machine learning interface for binary classification tasks which enables human annotators to utilise counterfactual examples to complement standard binary labels as annotations for a dataset. Finally we discuss the challenges in future extensions of this work. Keywords: Humans and AI: HAI: Human-AI collaboration Humans and AI: HAI: Human-computer interaction Humans and AI: HAI: Intelligent user interfaces},
  archive   = {C_IJCAI},
  author    = {Jonathan Erskine and Matt Clifford and Alexander Hepburn and Raul Santos Rodriguez},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/999},
  month     = {8},
  pages     = {8644-8647},
  title     = {An interactive human-machine learning interface for collecting and learning from complex annotations},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). NegoLog: An integrated python-based automated negotiation
framework with enhanced assessment components. <em>IJCAI</em>,
8640–8643. (<a href="https://doi.org/10.24963/ijcai.2024/998">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The complexity of automated negotiation research calls for dedicated, user-friendly research frameworks that facilitate advanced analytics, comprehensive loggers, visualization tools, and auto-generated domains and preference profiles. This paper introduces NegoLog, a platform that provides advanced and customizable analysis modules to agent developers for exhaustive performance evaluation. NegoLog introduces an automated scenario and tournament generation tool in its Web-based user interface so that the agent developers can adjust the competitiveness and complexity of the negotiations. One of the key novelties of the NegoLog is an individual assessment of preference estimation models independent of the strategies. Keywords: Agent-based and Multi-agent Systems: MAS: Agreement technologies: Negotiation and contract-based systems Agent-based and Multi-agent Systems: MAS: Agent-based simulation and emergence},
  archive   = {C_IJCAI},
  author    = {Anıl Doğru and Mehmet Onur Keskin and Catholijn M. Jonker and Tim Baarslag and Reyhan Aydoğan},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/998},
  month     = {8},
  pages     = {8640-8643},
  title     = {NegoLog: An integrated python-based automated negotiation framework with enhanced assessment components},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). 3D-FuM: Benchmarking 3D molecule learning with functional
groups. <em>IJCAI</em>, 8635–8639. (<a
href="https://doi.org/10.24963/ijcai.2024/997">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Molecular graph representation learning plays a crucial role in various domains, such as drug discovery and chemical reaction prediction, where molecular graphs are typically depicted as 2D topological structures. However, recent insights highlight the critical role of 3D geometric information and functional groups in accurately predicting molecular properties, aspects often neglected in existing molecular graph benchmark datasets. To bridge the research gap, we introduce a comprehensive molecular learning benchmark named 3D-FUM, which incorporates both 3D geometric information and functional groups of a large number of molecules. 3D-FUM integrates 18 state-of-the-art algorithms and 19 evaluation metrics on three molecular learning tasks, including general molecule generation, conditional molecule generation, and property predictions. 3D-FUM, for the first time, take into consideration both 3D geometric information and molecular functional groups, which enables researchers and practitioners to effectively and impartially evaluate newly proposed methods in comparison to existing baselines across diverse datasets. Furthermore, we design a user interface for user-friendly interaction and development with the benchmark for evaluation metrics selection, parameter adjustment, and leaderboard comparison. To ensure accessibility and reproducibility, we opensource our benchmark 3D-FUM and experimental results at https://3dfunctiongroupmoleculedataset.github.io/3D-FuM/#/Home. Keywords: Multidisciplinary Topics and Applications: MDA: Physical sciences Multidisciplinary Topics and Applications: MDA: Bioinformatics},
  archive   = {C_IJCAI},
  author    = {Tingwei Chen and Jianpeng Chen and Dawei Zhou},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/997},
  month     = {8},
  pages     = {8635-8639},
  title     = {3D-FuM: Benchmarking 3D molecule learning with functional groups},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). E-QGen: Educational lecture abstract-based question
generation system. <em>IJCAI</em>, 8631–8634. (<a
href="https://doi.org/10.24963/ijcai.2024/996">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {To optimize the preparation process for educators in academic lectures and associated question-and-answer sessions, this paper presents E-QGen, a lecture abstract-based question generation system. Given a lecture abstract, E-QGen generates potential student inquiries. The questions suggested by our system are expected to not only facilitate teachers in preparing answers in advance but also enable them to supply additional resources when necessary. Keywords: Natural Language Processing: NLP: Applications Natural Language Processing: NLP: Language generation},
  archive   = {C_IJCAI},
  author    = {Mao-Siang Chen and An-Zi Yen},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/996},
  month     = {8},
  pages     = {8631-8634},
  title     = {E-QGen: Educational lecture abstract-based question generation system},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Integrating LLM, VLM, and text-to-image models for enhanced
information graphics: A methodology for accurate and visually engaging
visualizations. <em>IJCAI</em>, 8627–8630. (<a
href="https://doi.org/10.24963/ijcai.2024/995">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This study presents an innovative approach to the creation of information graphics, where the accuracy of content and aesthetic appeal are of paramount importance. Traditional methods often struggle to balance these two aspects, particularly in complex visualizations like phylogenetic trees. Our methodology integrates the strengths of Large Language Models (LLMs), Vision Language Models (VLMs), and advanced text-to-image models to address this challenge. Initially, an LLM plans the layout and structure, employing Mermaid—a JavaScript-based tool that uses Markdown-like scripts for diagramming—to establish a precise and structured foundation. This structured script is crucial for ensuring data accuracy in the graphical representation. Following this, text-to-image models are employed to enhance the vector graphic generated by Mermaid, adding rich visual elements and enhancing overall aesthetic appeal. The integration of text-to-image models is a key innovation, enabling the creation of graphics that are not only informative but also visually captivating. Finally, a VLM performs quality control, ensuring that the visual enhancements align with the informational accuracy. This comprehensive approach effectively combines the accuracy of structured data representation, the creative potential of text-to-image models, and the validation capabilities of VLMs. The result is a new standard in information graphic creation, suitable for diverse applications ranging from education to scientific communication, where both information integrity and visual engagement are essential. Keywords: Multidisciplinary Topics and Applications: MDA: Arts and creativity Computer Vision: CV: Vision and language Humans and AI: HAI: Intelligent user interfaces},
  archive   = {C_IJCAI},
  author    = {Chao-Ting Chen and Hen-Hsen Huang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/995},
  month     = {8},
  pages     = {8627-8630},
  title     = {Integrating LLM, VLM, and text-to-image models for enhanced information graphics: A methodology for accurate and visually engaging visualizations},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). IntEr-HRI competition: Intrinsic error evaluation during
human - robot interaction. <em>IJCAI</em>, 8623–8626. (<a
href="https://doi.org/10.24963/ijcai.2024/994">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Reliable detection of human intentions from electroencephalogram (EEG) to improve human-robot interaction (HRI) has recently gained significant importance. To ensure safe and satisfactory interactions, implicit detection of erroneous behavior of robotic systems, particularly assistive devices, is essential. This can be achieved by detecting error-related potentials (ErrPs) in EEG, evoked by visual, tactile, or visuo-tactile stimuli. Of these, the ErrPs evoked tactilely with the help of a robot remains unexplored and has been the main focus of this competition. The task for participating teams was to develop robust AI models for continuous real-time classification of erroneous behavior of assistive robotic devices from the human EEG. Even though the competition results prove its feasibility, a performance gap (balanced accuracy and computation time) of more than 10% was observed between the offline and online classification of errors in real-world scenarios. In addition to the competitive AI models developed by the participating teams, this competition also contributed towards a one-of-its-kind open-access EEG and EMG dataset, a lossless live streaming solution for EEG data, and a novel quantitative metric for benchmarking online asynchronous EEG detection solutions. Keywords: Robotics: ROB: Human robot interaction Humans and AI: HAI: Brain sciences},
  archive   = {C_IJCAI},
  author    = {Kartik Chari and Niklas Kueper and Su Kyoung Kim and Frank Kirchner and Elsa Andrea Kirchner},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/994},
  month     = {8},
  pages     = {8623-8626},
  title     = {IntEr-HRI competition: Intrinsic error evaluation during human - robot interaction},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FD-UAD: Unsupervised anomaly detection platform based on
defect autonomous imaging and enhancement. <em>IJCAI</em>, 8619–8622.
(<a href="https://doi.org/10.24963/ijcai.2024/993">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In industrial quality control, detecting defects is essential. However, manual checks and machine vision encounter challenges in complex conditions, as defects vary among products made of different materials and shapes. We create FD-UAD, Unsupervised Anomaly Detection Platform Based on Defect Autonomous Imaging and Enhancement. It uses multi-sensor technology, combining RGB and infrared imaging, liquid lenses for adjustable focal lengths, and uses image fusion to capture multidimensional features. The system incorporates image restoration techniques such as enhancement, deblurring, denoising, and super-resolution, alongside unsupervised anomaly detection model for enhanced accuracy. FD-UAD is successfully used in a top diesel engine manufacturer, demonstrating its value in AI-enhanced industrial applications. Keywords: Computer Vision: CV: Recognition (object detection, categorization) Computer Vision: CV: Applications},
  archive   = {C_IJCAI},
  author    = {Yang Chang and Yuxuan Lin and Boyang Wang and Qing Zhao and Yan Wang and Wenqiang Zhang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/993},
  month     = {8},
  pages     = {8619-8622},
  title     = {FD-UAD: Unsupervised anomaly detection platform based on defect autonomous imaging and enhancement},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GigaPevt: Multimodal medical assistant. <em>IJCAI</em>,
8614–8618. (<a href="https://doi.org/10.24963/ijcai.2024/992">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Building an intelligent and efficient medical assistant is still a challenging AI problem. The major limitation comes from the data modality scarceness, which reduces comprehensive patient perception. This demo paper presents GigaPevt, the first multimodal medical assistant that combines the dialog capabilities of large language models with specialized medical models. Such an approach shows immediate advantages in dialog quality and metric performance, with a 1.18% accuracy improvement in the question-answering task. Keywords: Multidisciplinary Topics and Applications: MDA: Health and medicine Natural Language Processing: NLP: Dialogue and interactive systems Computer Vision: CV: Vision and language Computer Vision: CV: Applications},
  archive   = {C_IJCAI},
  author    = {Pavel Blinov and Konstantin Egorov and Ivan Sviridov and Nikolay Ivanov and Stepan Botman and Evgeniy Tagin and Stepan Kudin and Galina Zubkova and Andrey V. Savchenko},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/992},
  month     = {8},
  pages     = {8614-8618},
  title     = {GigaPevt: Multimodal medical assistant},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PyClause - simple and efficient rule handling for knowledge
graphs. <em>IJCAI</em>, 8610–8613. (<a
href="https://doi.org/10.24963/ijcai.2024/991">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Rule mining finds patterns in structured data such as knowledge graphs. Rules can predict facts, help correct errors, and yield explainable insights about the data. However, existing rule mining implementations focus exclusively on mining rules -- and not on their application. The PyClause library offers a rich toolkit for the application of the mined rules: from explaining facts to predicting links, scoring rules, and deducing query results. The library is easy to use and can handle substantial data loads. Keywords: Data Mining: DM: Knowledge graphs and knowledge base completion Knowledge Representation and Reasoning: KRR: Learning and reasoning Knowledge Representation and Reasoning: KRR: Semantic Web},
  archive   = {C_IJCAI},
  author    = {Patrick Betz and Luis Galárraga and Simon Ott and Christian Meilicke and Fabian Suchanek and Heiner Stuckenschmidt},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/991},
  month     = {8},
  pages     = {8610-8613},
  title     = {PyClause - simple and efficient rule handling for knowledge graphs},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Design of a data-driven intervention dashboard for SDG
localization. <em>IJCAI</em>, 8606–8609. (<a
href="https://doi.org/10.24963/ijcai.2024/990">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The localization problem of the United Nations Sustainable Development Goals (SDGs) involves adopting strategies that are in tune with local conditions, to achieve a given SDG target. However, even within a given region, localized conditions may vary drastically. With increasing amounts of Open Government Data (OGD) being available, there is an opportunity to systematically address the localization problem by using predictive and prescriptive modeling techniques. This work presents a predictive and prescriptive modeling dashboard for the SDG indicator maternal deaths (MD) for the Indian state of Karnataka. The dashboard was created by examining a vast set of data points to focus on four factors that showed high correlations with that of MD. We then construct a multivariate linear regression model to showcase the differential impact that a given factor has on the indicator and identify prescribed values for different factors to achieve a given target value of the indicator. Finally, a budget allocation dashboard is also provided that helps policymakers allocate budgets to specific schemes to help operationalize these changes. This dashboard was built by combining data coming from five different OGD sources. Keywords: Multidisciplinary Topics and Applications: MDA: Energy, environment and sustainability Data Mining: DM: Data visualization Machine Learning: ML: Applications Machine Learning: ML: Regression Multidisciplinary Topics and Applications: MDA: Social sciences},
  archive   = {C_IJCAI},
  author    = {Pooja Bassin and Abraham G K and Srinath Srinivasa},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/990},
  month     = {8},
  pages     = {8606-8609},
  title     = {Design of a data-driven intervention dashboard for SDG localization},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). PyXAI: An XAI library for tree-based models.
<em>IJCAI</em>, 8601–8605. (<a
href="https://doi.org/10.24963/ijcai.2024/989">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {PyXAI (Python eXplainable AI) is a Python library designed for providing explanations and cor- recting tree-based Machine Learning (ML) models. It is suited to decision trees, random forests, and boosted trees, when used for regression or classification tasks. In contrast to many model-agnostic approaches to XAI, PyXAI exploits the model it- self to generate explanations, ensuring them to be faithful. PyXAI includes several algorithms for the generation of explanations, which can be abductive or contrastive. PyXAI also includes algorithms for correcting tree-based models when their predictions conflict with pieces of user knowledge. Keywords: Machine Learning: ML: Explainable/Interpretable machine learning AI Ethics, Trust, Fairness: ETF: Explainability and interpretability},
  archive   = {C_IJCAI},
  author    = {Gilles Audemard and Jean-Marie Lagniez and Pierre Marquis and Nicolas Szczepanski},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/989},
  month     = {8},
  pages     = {8601-8605},
  title     = {PyXAI: An XAI library for tree-based models},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). REAVER: Real-time earthquake prediction with attention-based
sliding-window spectrograms. <em>IJCAI</em>, 8596–8600. (<a
href="https://doi.org/10.24963/ijcai.2024/988">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Predicting earthquakes with precision remains an ongoing challenge in earthquake early warning systems (EEWS), that struggle with accuracy and fail to provide timely warnings for impending earthquakes. Recent efforts employing deep learning techniques have shown promise in overcoming these limitations. However, current methods lack the ability to capture subtle frequency changes indicative of seismic activity in real-time, limiting their effectiveness in EEWS. To address this gap, we propose REAVER, a novel approach for real-time prediction of P- and S-waves of earthquakes using attention-based sliding-window spectrograms. REAVER leverages Mel-Spectrogram signal representations to capture temporal frequency changes in seismic signals effectively. By employing an encoder-decoder architecture with attention mechanisms, REAVER accurately predicts the onset of P- and S-waves moments when an earthquake occurs. We benchmark the effectiveness of REAVER, showing its performance in terms of both accuracy and real-time prediction capabilities compared to existing methods. Additionally, we provide a web-based implementation of REAVER, allowing users to monitor seismic activity in real-time and analyze historical earthquake waveforms. Keywords: Machine Learning: ML: Applications Multidisciplinary Topics and Applications: MDA: Real-time systems},
  archive   = {C_IJCAI},
  author    = {Lotfy Abdel Khaliq and Sabine Janzen and Wolfgang Maass},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/988},
  month     = {8},
  pages     = {8596-8600},
  title     = {REAVER: Real-time earthquake prediction with attention-based sliding-window spectrograms},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Machine unlearning: Challenges in data quality and access.
<em>IJCAI</em>, 8589–8594. (<a
href="https://doi.org/10.24963/ijcai.2024/987">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Machine unlearning aims to remove specific knowledge from a well-trained machine learning model. This topic has gained significant attention recently due to the widespread adoption of machine learning models across various applications and the accompanying privacy, legal, and ethical considerations. During the unlearning process, models are typically presented with data that specifies which information should be erased and which should be retained. Nonetheless, practical challenges arise due to prevalent issues of data quality issues and access restrictions. This paper explores these challenges and introduces strategies to address problems related to unsupervised data, weakly supervised data, and scenarios characterized by zero-shot and federated data availability. Finally, we discuss related open questions, particularly concerning evaluation metrics, how the forgetting information is represented and delivered, and the unique challenges posed by large generative models. Keywords: Machine Learning: ML: Trustworthy machine learning Machine Learning: ML: Weakly supervised learning},
  archive   = {C_IJCAI},
  author    = {Miao Xu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/987},
  month     = {8},
  pages     = {8589-8594},
  title     = {Machine unlearning: Challenges in data quality and access},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Computational argumentation: Reasoning, dynamics, and
supporting explainability. <em>IJCAI</em>, 8583–8588. (<a
href="https://doi.org/10.24963/ijcai.2024/986">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This overview accompanies the author&#39;s Early Career Track presentation. We survey recent research and research agenda of the author, focusing on contributions in the area of computational argumentation. Contributions span from foundations of static and dynamic forms of argumentative reasoning and approaches to support explainability, e.g., analysis of the computational complexity of argumentative reasoning and algorithmic approaches. Keywords: Knowledge Representation and Reasoning: KRR: Argumentation Knowledge Representation and Reasoning: KRR: Computational complexity of reasoning},
  archive   = {C_IJCAI},
  author    = {Johannes P. Wallner},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/986},
  month     = {8},
  pages     = {8583-8588},
  title     = {Computational argumentation: Reasoning, dynamics, and supporting explainability},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Formal argumentation in symbolic AI. <em>IJCAI</em>,
8577–8582. (<a href="https://doi.org/10.24963/ijcai.2024/985">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the area of symbolic AI, researchers strive to develop techniques to teach machines (commonsense) reasoning. Human reasoning is often argumentative in its nature, and consequently, computational models of argumentation constitute a vibrant research area in symbolic AI. In this paper I describe my most significant contributions to the field spanning from general non-monotonic logics to formal argumentation. Keywords: Knowledge Representation and Reasoning: KRR: Argumentation Knowledge Representation and Reasoning: KRR: Knowledge representation languages Knowledge Representation and Reasoning: KRR: Computational complexity of reasoning},
  archive   = {C_IJCAI},
  author    = {Markus Ulbricht},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/985},
  month     = {8},
  pages     = {8577-8582},
  title     = {Formal argumentation in symbolic AI},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Expanding the reach of social choice theory. <em>IJCAI</em>,
8571–8576. (<a href="https://doi.org/10.24963/ijcai.2024/984">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The field of social choice theory investigates how individual preferences are aggregated to reach collective decisions. While traditional social choice addresses problems such as choosing a winning candidate based on voter rankings or fairly allocating resources among individuals with the same entitlement, the wide range of decision-making scenarios in real-world applications calls for an extension beyond these basic frameworks. In this paper, I present an overview of my efforts to expand the reach of social choice theory in the domains of fair division, voting, and tournaments. Furthermore, I discuss avenues and challenges of bringing the developed theory closer to practice. Keywords: Game Theory and Economic Paradigms: GTEP: Computational social choice Game Theory and Economic Paradigms: GTEP: Fair division Agent-based and Multi-agent Systems: MAS: Resource allocation AI Ethics, Trust, Fairness: ETF: Fairness and diversity},
  archive   = {C_IJCAI},
  author    = {Warut Suksompong},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/984},
  month     = {8},
  pages     = {8571-8576},
  title     = {Expanding the reach of social choice theory},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A little of that human touch: Achieving human-centric
explainable AI via argumentation. <em>IJCAI</em>, 8565–8570. (<a
href="https://doi.org/10.24963/ijcai.2024/983">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As data-driven AI models achieve unprecedented feats across previously unthinkable tasks, the diminishing levels of interpretability of their increasingly complex architectures can often be sidelined in place of performance. If we are to comprehend and trust these AI models as they advance, it is clear that symbolic methods, given their unparalleled strengths in knowledge representation and reasoning, can play an important role in explaining AI models. In this paper, I discuss some of the ways in which one branch of such methods, computational argumentation, given its human-like nature, can be used to tackle this problem. I first outline a general paradigm for this area of explainable AI, before detailing a prominent methodology therein which we have pioneered. I then illustrate how this approach has been put into practice with diverse AI models and types of explanations, before looking ahead to challenges, future work and the outlook in this field. Keywords: Knowledge Representation and Reasoning: KRR: Argumentation AI Ethics, Trust, Fairness: ETF: Explainability and interpretability AI Ethics, Trust, Fairness: ETF: Trustworthy AI Agent-based and Multi-agent Systems: MAS: Human-agent interaction},
  archive   = {C_IJCAI},
  author    = {Antonio Rago},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/983},
  month     = {8},
  pages     = {8565-8570},
  title     = {A little of that human touch: Achieving human-centric explainable AI via argumentation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Transforming recommender systems: Balancing personalization,
fairness, and human values. <em>IJCAI</em>, 8559–8564. (<a
href="https://doi.org/10.24963/ijcai.2024/982">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent advancements in recommender systems highlight the importance of metrics beyond accuracy, including diversity, serendipity, and fairness. This paper discusses various aspects of modern recommender systems, focusing on challenges such as preference elicitation, the complexity of human decision-making, and multi-domain applicability. The integration of Generative AI and Large Language Models offers enhanced personalization capabilities but also raises concerns regarding transparency and fairness. This work examines ongoing research efforts aimed at developing transparent, fair, and contextually aware systems. Our approach seeks to prioritize user wellbeing and responsibility, contributing to a more equitable and functional digital environment through advanced technologies and interdisciplinary insights. Keywords: Data Mining: DM: Recommender systems Humans and AI: HAI: Personalization and user modeling AI Ethics, Trust, Fairness: ETF: Fairness and diversity AI Ethics, Trust, Fairness: ETF: Societal impact of AI},
  archive   = {C_IJCAI},
  author    = {Julia Neidhardt},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/982},
  month     = {8},
  pages     = {8559-8564},
  title     = {Transforming recommender systems: Balancing personalization, fairness, and human values},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards a theory of machine learning on graphs and its
applications in combinatorial optimization. <em>IJCAI</em>, 8553–8558.
(<a href="https://doi.org/10.24963/ijcai.2024/981">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Machine learning on graphs, especially using graph neural networks (GNNs), has seen a surge in interest due to the wide availability of graph data across many disciplines, from life and physical to social and engineering sciences. Despite their practical success, our theoretical understanding of the properties of GNNs remains incomplete. Here, we survey the author&#39;s and his collaborators&#39; progress in developing a deeper theoretical understanding of GNNs&#39; expressive power and generalization abilities. In addition, we overview recent progress in using GNNs to speed up solvers for hard combinatorial optimization tasks. Keywords: Machine Learning: ML: Representation learning Machine Learning: ML: Learning theory Machine Learning: ML: Theory of deep learning Constraint Satisfaction and Optimization: CSO: Constraint optimization problems},
  archive   = {C_IJCAI},
  author    = {Christopher Morris},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/981},
  month     = {8},
  pages     = {8553-8558},
  title     = {Towards a theory of machine learning on graphs and its applications in combinatorial optimization},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The rise of federated intelligence: From federated
foundation models toward collective intelligence. <em>IJCAI</em>,
8547–8552. (<a href="https://doi.org/10.24963/ijcai.2024/980">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The success of foundation models advances the development of various intelligent and personalized agents to handle intricate tasks in their daily lives, however finite resources and privacy concerns from end users limit the potential of customizing the large intelligent agents for personal use. This paper explores the preliminary design of federated intelligence that paves the way toward personalized intelligent agents in large-scale collaboration scenarios. In Federated Intelligence, agents can collaboratively augment their intelligence quotient (IQ) by learning complementary knowledge and fine-grained adaptations. These personalized intelligent agents can also co-work together to jointly address complex tasks in the form of collective intelligence. The paper will highlight federated intelligence as a new pathway for tackling complex intelligent tasks by refining and extending centralized foundation models to an open and collaborative paradigm. Keywords: Machine Learning: ML: Federated learning Agent-based and Multi-agent Systems: MAS: Coordination and cooperation},
  archive   = {C_IJCAI},
  author    = {Guodong Long},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/980},
  month     = {8},
  pages     = {8547-8552},
  title     = {The rise of federated intelligence: From federated foundation models toward collective intelligence},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Algorithmic fairness in distribution of resources and tasks.
<em>IJCAI</em>, 8541–8546. (<a
href="https://doi.org/10.24963/ijcai.2024/979">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The widespread adoption of Artificial Intelligence (AI) systems has profoundly reshaped decision-making in social, political, and commercial contexts. This paper explores the critical issue of fairness in AI-driven decision-making, particularly in allocating resources and tasks. By examining recent advancements and key questions in computational social choice, I highlight challenges and prospects in designing fair systems in collective decision-making that are scalable, adaptable to intricate environments, and are aligned with complex and diverse human preferences. Keywords: Game Theory and Economic Paradigms: GTEP: Fair division Game Theory and Economic Paradigms: GTEP: Mechanism design Agent-based and Multi-agent Systems: MAS: Resource allocation},
  archive   = {C_IJCAI},
  author    = {Hadi Hosseini},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/979},
  month     = {8},
  pages     = {8541-8546},
  title     = {Algorithmic fairness in distribution of resources and tasks},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Trustworthy machine learning under imperfect data.
<em>IJCAI</em>, 8535–8540. (<a
href="https://doi.org/10.24963/ijcai.2024/978">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Trustworthy machine learning (TML) under imperfect data has recently brought much attention in the data-centric fields of machine learning (ML) and artificial intelligence (AI). Specifically, there are mainly three types of imperfect data along with their challenges for ML, including i) label-level imperfection: noisy labels; ii) feature-level imperfection: adversarial examples; iii) distribution-level imperfection: out-of-distribution data. Therefore, in this paper, we systematically share our insights and solutions of TML to handle three types of imperfect data. More importantly, we discuss some new challenges in TML, which also open more opportunities for future studies, such as trustworthy foundation models, trustworthy federated learning, and trustworthy causal learning. Keywords: Machine Learning: ML: Trustworthy machine learning Machine Learning: ML: Weakly supervised learning Machine Learning: ML: Adversarial machine learning Machine Learning: ML: Robustness},
  archive   = {C_IJCAI},
  author    = {Bo Han},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/978},
  month     = {8},
  pages     = {8535-8540},
  title     = {Trustworthy machine learning under imperfect data},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Human-AI interaction generation: A connective lens for
generative AI and procedural content generation. <em>IJCAI</em>,
8529–8534. (<a href="https://doi.org/10.24963/ijcai.2024/977">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Generative AI has recently gained popularity as a paradigm for content generation. In this paper, we link this paradigm to an older one: Procedural Content Generation (PCG). We propose a lens to identify the commonalities between both paradigms that we call human-AI interactive generation. Using this lens, we identify three beneficial attributes then survey recent related work and summarize relevant findings. Keywords: Humans and AI: HAI: Human-computer interaction Machine Learning: ML: Generative models Multidisciplinary Topics and Applications: MTA: Computer games Humans and AI: HAI: Intelligent user interfaces},
  archive   = {C_IJCAI},
  author    = {Matthew Guzdial},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/977},
  month     = {8},
  pages     = {8529-8534},
  title     = {Human-AI interaction generation: A connective lens for generative AI and procedural content generation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Human-robot alignment through interactivity and
interpretability: Don’t assume a “spherical human.” <em>IJCAI</em>,
8523–8528. (<a href="https://doi.org/10.24963/ijcai.2024/976">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Interactive and interpretable robot learning can help to democratize robots, placing the power of assistive robotic systems in the hands of end-users. While machine learning-based approaches to robotics have achieved impressive results, robot learning is still a feat of costly engineering performed in controlled settings and relying upon impractical assumptions about humans. To achieve a vision in which robots can be integrated sustainably into our daily lives for robotic assistance, researchers must take a human-centered approach and develop novel approaches for human-robot alignment of robot values and behaviors. This paper amalgamates recent human factors insights and computational techniques that can support human-robot alignment through interactive and interpretable robot learning and teaming. Keywords: Robotics: ROB: Human robot interaction Machine Learning: ML: Explainable/Interpretable machine learning Robotics: ROB: Learning in robotics},
  archive   = {C_IJCAI},
  author    = {Matthew Gombolay},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/976},
  month     = {8},
  pages     = {8523-8528},
  title     = {Human-robot alignment through interactivity and interpretability: Don&#39;t assume a ``Spherical human&#39;&#39;},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Culturally-aware image captioning. <em>IJCAI</em>,
8520–8521. (<a href="https://doi.org/10.24963/ijcai.2024/975">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The primary research challenge lies in mitigating and measuring geographical and demographic biases in generative models, which is crucial for ensuring fairness in AI applications. Existing models trained on web-crawled datasets like LAION-400M often perpetuate harmful stereotypes and biases, especially concerning minority groups or less-represented regions. To address this, I proposed a framework called CIC (Culturally-aware Image Caption) to generate culturally-aware image captions. This framework leverages visual question answering (VQA) to extract cultural visual elements from images. It prompts both caption prompts and cultural visual elements to generate culturally-aware captions using large language models (LLMs). Human evaluations confirm the effectiveness of our approach in depicting cultural information accurately. Two key future directions are outlined. First, current image caption evaluation methods are inadequate for assessing culturally-aware captions, necessitating the development of new evaluation metrics leveraging cultural datasets and representations. Second, ethical considerations, particularly concerning stereotypes embedded in existing models, demand consensus and standards development through diverse cultural perspectives. Addressing these challenges is vital for the responsible deployment of AI technologies in diverse real-world contexts. Keywords: DC: AI Ethics, Trust, Fairness DC: Natural Language Processing DC: Computer Vision},
  archive   = {C_IJCAI},
  author    = {Youngsik Yun},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/975},
  month     = {8},
  pages     = {8520-8521},
  title     = {Culturally-aware image captioning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). N-agent ad hoc teamwork. <em>IJCAI</em>, 8518–8519. (<a
href="https://doi.org/10.24963/ijcai.2024/974">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Current approaches to learning cooperative multi-agent behaviors assume relatively restrictive settings. In fully cooperative multi-agent reinforcement learning, the learning algorithm controls all agents in the scenario, while in ad hoc teamwork, the learning algorithm usually assumes control over only a single agent in the scenario. However, many cooperative settings in the real world are much less restrictive. For example, in an autonomous driving scenario, a company might train its cars to cooperate with each other, yet once on the road, these cars must additionally cooperate with cars from other companies. Towards expanding the class of scenarios that cooperative learning methods may optimally address, this research agenda introduces and proposes to study N-agent ad hoc teamwork (NAHT), where a set of autonomous agents must interact and cooperate with dynamically varying numbers and types of teammates. Keywords: DC: Agent-based and Multi-agent Systems DC: Machine Learning},
  archive   = {C_IJCAI},
  author    = {Caroline Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/974},
  month     = {8},
  pages     = {8518-8519},
  title     = {N-agent ad hoc teamwork},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fairness and optimization in dynamic multiagent allocation
problems. <em>IJCAI</em>, 8516–8517. (<a
href="https://doi.org/10.24963/ijcai.2024/973">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In many allocation problems, understanding individual agents&#39; needs, wants, and tradeoffs is crucial for providing fair and efficient solutions. This paper begins with motivating applications and critical definitions. We review existing results, such as advising agents on relaxing restrictions for improved resource allocation, optimizing task allocation in online settings without rejection of a task, and more. We conclude by outlining three potential directions for future research. Keywords: DC: Agent-based and Multi-agent Systems},
  archive   = {C_IJCAI},
  author    = {Yohai Trabelsi},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/973},
  month     = {8},
  pages     = {8516-8517},
  title     = {Fairness and optimization in dynamic multiagent allocation problems},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stakeholder-oriented decision support for auction-based
federated learning. <em>IJCAI</em>, 8514–8515. (<a
href="https://doi.org/10.24963/ijcai.2024/972">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Auction-based federated learning (AFL) is an important area of FL incentive mechanism design. It effectively incentivizes high-quality data owners (DOs) to participate in data consumers&#39; (DCs, i.e., servers&#39;) FL training tasks. However, AFL is still evolving, with existing methods primarily addressing optimal DC-DO matching or DC selection problems in monopoly markets. To enhance the practicality of AFL, we introduce stakeholder-oriented decision support in AFL. This facilitates optimal and strategic decision-making for all stakeholders, improving the efficiency and sustainability of the AFL ecosystem. Keywords: DC: Machine Learning},
  archive   = {C_IJCAI},
  author    = {Xiaoli Tang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/972},
  month     = {8},
  pages     = {8514-8515},
  title     = {Stakeholder-oriented decision support for auction-based federated learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bio-inspired dynamic and decentralized online learning in
uninformed heterogeneous multi-agent environments. <em>IJCAI</em>,
8512–8513. (<a href="https://doi.org/10.24963/ijcai.2024/971">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Dynamic adaptation and learning, akin to natural organisms, is crucial for robots operating in real-world scenarios like search and rescue missions. We propose a solution combining intuition from embodied evolution and Bayes theory to promote flexible exploration in foraging tasks. Our investigation focuses on three main areas: 1) leveraging communication and prior knowledge to develop adaptable strategies in agent groups, 2) addressing challenges from sparse rewards or limited data availability, and 3) developing methods for concurrent evaluation and training in a single iteration, filling a current gap in learning-based solutions. Future directions include exploring decentralized coordination among agents and incorporating assistance based on prospective memory and altruism in multi-agent reinforcement learning. Keywords: DC: Agent-based and Multi-agent Systems DC: Robotics DC: Multidisciplinary Topics and Applications DC: Search},
  archive   = {C_IJCAI},
  author    = {Angel Sylvester},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/971},
  month     = {8},
  pages     = {8512-8513},
  title     = {Bio-inspired dynamic and decentralized online learning in uninformed heterogeneous multi-agent environments},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Implicit anomaly subgraph detection (IASD) in multi-domain
attribute networks. <em>IJCAI</em>, 8510–8511. (<a
href="https://doi.org/10.24963/ijcai.2024/970">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Anomaly subgraph detection is a vital task in various real applications. However, with the advancement of AI technology, it faces new challenges: 1) Anomaly features are often deeply hidden within large datasets, and 2) Anomaly detection approaches are required to unveil the mechanisms behind anomaly generation. Our study focuses on detecting hidden anomaly subgraphs within big data and offering improved explanations for the root cause of anomalies by integrating multi-domain datasets. Keywords: DC: Data Mining DC: Knowledge Representation and Reasoning DC: Machine Learning DC: Search},
  archive   = {C_IJCAI},
  author    = {Ying Sun},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/970},
  month     = {8},
  pages     = {8510-8511},
  title     = {Implicit anomaly subgraph detection (IASD) in multi-domain attribute networks},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning with requirements in the real world.
<em>IJCAI</em>, 8508–8509. (<a
href="https://doi.org/10.24963/ijcai.2024/969">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep learning models have repeatedly shown their strengths in various application domains. However, their predictions often struggle to meet background knowledge requirements, which is a crucial condition for safety-critical systems. My research focuses on integrating requirements into neural networks to guide the learning process and ultimately produce outputs that ensure the requirements&#39; satisfaction. Here, I will discuss my proposed methods in the context of two real-world applications: tabular data generation and autonomous driving. Keywords: DC: Machine Learning DC: Multidisciplinary Topics and Applications},
  archive   = {C_IJCAI},
  author    = {Mihaela C. Stoian},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/969},
  month     = {8},
  pages     = {8508-8509},
  title     = {Deep learning with requirements in the real world},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cooperation and fairness in systems of indirect reciprocity.
<em>IJCAI</em>, 8506–8507. (<a
href="https://doi.org/10.24963/ijcai.2024/968">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Across disciplines, cooperation is a fundamental research topic. While socially desirable to a population, it often bears a cost to the individual who, in their own self-interest, rationally chooses not to engage in costly cooperation. As such, much work has been done in understanding the biological mechanisms behind cooperation in human and animal populations. In my PhD project, I develop and apply these mechanisms both to artificial multi-agent systems and real social systems. I examine how factors such as agent heterogeneity and different learning algorithms affect not only the level of cooperation within a system, but also the level of fairness in the distribution of payoffs. In previous work, I showed how the effectiveness of the social norm-based mechanism of indirect reciprocity is affected when in-group biased cooperation is present. Beyond my future work on online platforms, I also plan to explore the effects of space, gossip, and partial and subjective observations to widen the potential scope of applications. Keywords: DC: Agent-based and Multi-agent Systems DC: AI Ethics, Trust, Fairness},
  archive   = {C_IJCAI},
  author    = {Martin Smit},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/968},
  month     = {8},
  pages     = {8506-8507},
  title     = {Cooperation and fairness in systems of indirect reciprocity},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimization under epistemic uncertainty using prediction.
<em>IJCAI</em>, 8504–8505. (<a
href="https://doi.org/10.24963/ijcai.2024/967">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Due to the complexity of randomness, optimization problems are often modeled to be deterministic to be solvable. Specifically epistemic uncertainty, i.e., uncertainty that is caused due to a lack of knowledge, is not easy to model, let alone easy to subsequently solve. Despite this, taking uncertainty into account is often required for optimization models to produce robust decisions that perform well in practice. We analyze effective existing frameworks, aiming to improve robustness without increasing complexity. Specifically we focus on robustness in decision-focused learning, which is a framework aimed at making context-based predictions for an optimization problem&#39;s uncertain parameters that minimize decision error. Keywords: DC: Constraint Satisfaction and Optimization DC: Uncertainty in AI DC: Machine Learning},
  archive   = {C_IJCAI},
  author    = {Noah Schutte},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/967},
  month     = {8},
  pages     = {8504-8505},
  title     = {Optimization under epistemic uncertainty using prediction},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multivariate analysis and structural restrictions in
computational social choice. <em>IJCAI</em>, 8502–8503. (<a
href="https://doi.org/10.24963/ijcai.2024/966">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In my research, I focus on computationally hard problems in the area of computational social choice. I am interested in the study of input restrictions that guarantee the existence of efficient and scalable algorithms that can be of practical interest. Keywords: DC: Game Theory and Economic Paradigms},
  archive   = {C_IJCAI},
  author    = {Šimon Schierreich},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/966},
  month     = {8},
  pages     = {8502-8503},
  title     = {Multivariate analysis and structural restrictions in computational social choice},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fair and efficient chore allocation: Existence and
computation. <em>IJCAI</em>, 8500–8501. (<a
href="https://doi.org/10.24963/ijcai.2024/965">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We investigate the existence and computation of fair and efficient allocations of indivisible chores to agents with additive preferences. We consider the popular envy-based fairness notions of envy-freeness up to one chore (EF1) and the efficiency notion of Pareto-optimality (PO). The existence of an allocation of chores that is simultaneously EF1 and PO is regarded a major open problem in discrete fair division. We show that an EF1 and PO allocation can be computed in polynomial time for certain structured instances. These results comprise the first non-trivial positive results for the problem and reveal insights towards settling the problem in its full generality. Keywords: DC: Game Theory and Economic Paradigms},
  archive   = {C_IJCAI},
  author    = {Aniket Murhekar},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/965},
  month     = {8},
  pages     = {8500-8501},
  title     = {Fair and efficient chore allocation: Existence and computation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing policy gradient algorithms with search in
imperfect information games. <em>IJCAI</em>, 8498–8499. (<a
href="https://doi.org/10.24963/ijcai.2024/964">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Sequential decision-making under uncertainty in multi-agent environments is a fundamental problem in artificial intelligence. Games serve as a base model for these problems. Finding optimal plans in games that model real-world scenarios necessitates scalable algorithms. In games with perfect information, algorithms that use a combination of search and deep reinforcement learning can scale to arbitrary-sized games and achieve superhuman performance. In games with imperfect information, the situation is more challenging due to the nature of the search. This work aims to develop algorithms that use search but can scale into larger games than currently possible. Keywords: DC: Agent-based and Multi-agent Systems DC: Game Theory and Economic Paradigms DC: Search DC: Machine Learning},
  archive   = {C_IJCAI},
  author    = {Ondřej Kubíček},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/964},
  month     = {8},
  pages     = {8498-8499},
  title     = {Enhancing policy gradient algorithms with search in imperfect information games},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Two-sided facility location games. <em>IJCAI</em>,
8496–8497. (<a href="https://doi.org/10.24963/ijcai.2024/963">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Facility location problems have been studied in settings like hospital placement or the competition between stores. In some cases, a central authority coordinates facility placements to optimize metrics like the coverage of an area or emergency response time. In many cases, however, facilities are placed by multiple rational agents to maximize their utility, e.g., the number of clients they attract. In previous research, these games feature simplistic client behavior independent of other clients&#39; strategic choices, e.g., visiting the closest facility. Our goal is to understand what happens if clients also act selfishly, resulting in a two-stage game consisting of strategic facility and client agents. In three recent publications, we investigated such two-stage models for clients that optimize their waiting times. We showed the existence and gave algorithms for (approximate) subgame perfect equilibria, a common extension of Nash equilibria for sequential games. To learn more about this domain, we intend to investigate further natural client behaviors and eventually create a more general model or hierarchy of two-sided facility location games. With this, we aim to make predictions in real-world settings, e.g., the placement of renewable energy infrastructure. Keywords: DC: Game Theory and Economic Paradigms},
  archive   = {C_IJCAI},
  author    = {Simon Krogmann},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/963},
  month     = {8},
  pages     = {8496-8497},
  title     = {Two-sided facility location games},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Parameter efficient instruction tuning of LLMs for financial
applications. <em>IJCAI</em>, 8494–8495. (<a
href="https://doi.org/10.24963/ijcai.2024/962">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {XBRL tagging in financial texts involves categorizing entities into numerous labels, presenting challenges for state-of-the-art models. Financial reports like 10-Q and 10-K, which must be tagged with XBRL according to a taxonomy with thousands of labels. The FNXL dataset exemplifies this with 2,794 labels. Manual tagging is neither scalable nor cost-effective, necessitating automatic annotation methods. Additionally, summarizing long Earnings Call Transcripts (ECTs) is crucial for financial decision-making. The ECTSum dataset highlights challenges in automatic summarization, including a high compression ratio and documents exceeding typical LLM token limits. This study proposes novel methods for both XBRL tagging and ECT summarization. Keywords: DC: Natural Language Processing DC: Machine Learning DC: Data Mining DC: Multidisciplinary Topics and Applications},
  archive   = {C_IJCAI},
  author    = {Subhendu Khatuya},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/962},
  month     = {8},
  pages     = {8494-8495},
  title     = {Parameter efficient instruction tuning of LLMs for financial applications},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). NeuroSymbolic LLM for mathematical reasoning and software
engineering. <em>IJCAI</em>, 8492–8493. (<a
href="https://doi.org/10.24963/ijcai.2024/961">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In recent years, there has been a significant interest in Large Language Models (LLMs) owing to their notable performance in natural language processing (NLP) tasks. However, while their results show promise in mathematical reasoning and software engineering tasks, LLMs have not yet achieved a satisfactory performance level in these domains. In response, current approaches have prioritized scaling up the size of LLMs, necessitating substantial computational resources and data. Our objective, however, is to pursue a different path by developing neurosymbolic language models. We propose to integrate logical and symbolic feedback during the training process, enabling significantly smaller language models to achieve far better reasoning capabilities than the LLMs currently in use. Keywords: DC: Natural Language Processing DC: Knowledge Representation and Reasoning DC: Machine Learning},
  archive   = {C_IJCAI},
  author    = {Prithwish Jana},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/961},
  month     = {8},
  pages     = {8492-8493},
  title     = {NeuroSymbolic LLM for mathematical reasoning and software engineering},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Causal graph modeling with deep neural engines for strong
abstract reasoning in language and vision. <em>IJCAI</em>, 8490–8491.
(<a href="https://doi.org/10.24963/ijcai.2024/960">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep learning (DL) relies on discovering correlation patterns in low-level data and aggregating the information to solve a task. Despite success in a wide variety of applications, ranging from natural language to vision tasks, the learned patterns are often brittle and do not transfer out of the training data distribution (i.e. to different domains). Causality theory proposes methods to discover and estimate cause-effect relationships beyond correlations. Its powerful inference frameworks have been recently highlighted as a potential way to improve the lack of out-of-distribution generalisation in deep neural networks. However, their applications to deep learning problems remain largely under-explored. Our work attempts to bridge this gap and apply causal graphical models to abstract and causal reasoning problems in natural language and vision, requiring strong generalisation abilities beyond correlations. We integrate causal graph modelling methods into deep vision networks and Large Language Models to improve their capacity to perform strong and out-of-distribution reasoning on complex abstract problems. Keywords: DC: Machine Learning DC: Knowledge Representation and Reasoning DC: Natural Language Processing DC: Computer Vision},
  archive   = {C_IJCAI},
  author    = {Gaël Gendron},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/960},
  month     = {8},
  pages     = {8490-8491},
  title     = {Causal graph modeling with deep neural engines for strong abstract reasoning in language and vision},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards revolutionized smart grids: An AI-driven broker for
improved operational efficiency. <em>IJCAI</em>, 8488–8489. (<a
href="https://doi.org/10.24963/ijcai.2024/959">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Smart grid system encompasses large power plants in the wholesale market and retail customers in the tariff market. An electricity broker liaises between the wholesale and tariff markets by procuring electricity from the power plants and selling it to subscribed customers. In our work, we address the prominent challenges in the smart grid system to achieve better efficiency. We discuss the wholesale market, for which we design efficient bidding strategies in periodic double auctions (PDAs), and the tariff market, which includes tariff contract generation strategies and peak demand mitigation strategies. We use the PowerTAC simulator as a test-bed; also utilise these strategies for our autonomous broker, VidyutVanika, which has been proven efficient in the PowerTAC tournaments. Keywords: DC: Agent-based and Multi-agent Systems DC: Game Theory and Economic Paradigms DC: Planning and Scheduling DC: Machine Learning},
  archive   = {C_IJCAI},
  author    = {Sanjay Chandlekar},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/959},
  month     = {8},
  pages     = {8488-8489},
  title     = {Towards revolutionized smart grids: An AI-driven broker for improved operational efficiency},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploiting cultural biases via homoglyphs inText-to-image
synthesis (abstract reprint). <em>IJCAI</em>, 8486. (<a
href="https://doi.org/10.24963/ijcai.2024/958">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Models for text-to-image synthesis, such as DALL-E 2 and Stable Diffusion, have recently drawn a lot of interest from academia and the general public. These models are capable of producing high-quality images that depict a variety of concepts and styles when conditioned on textual descriptions. However, these models adopt cultural characteristics associated with specific Unicode scripts from their vast amount of training data, which may not be immediately apparent. We show that by simply inserting single non-Latin characters in the textual description, common models reflect cultural biases in their generated images. We analyze this behavior both qualitatively and quantitatively and identify a model’s text encoder as the root cause of the phenomenon. Such behavior can be interpreted as a model feature, offering users a simple way to customize the image generation and reflect their own cultural background. Yet, malicious users or service providers may also try to intentionally bias the image generation. One goal might be to create racist stereotypes by replacing Latin characters with similarly-looking characters from non-Latin scripts, so-called homoglyphs. To mitigate such unnoticed script attacks, we propose a novel homoglyph unlearning method to fine-tune a text encoder, making it robust against homoglyph manipulations. Keywords: Journal Track: Journal Track},
  archive   = {C_IJCAI},
  author    = {Lukas Struppek and Dominik Hintersdorf and Felix Friedrich and Manuel Brack and Patrick Schramowski and Kristian Kersting},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/958},
  month     = {8},
  pages     = {8486},
  title     = {Exploiting cultural biases via homoglyphs inText-to-image synthesis (Abstract reprint)},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hierarchical decompositions and termination analysis for
generalized planning (abstract reprint). <em>IJCAI</em>, 8485. (<a
href="https://doi.org/10.24963/ijcai.2024/957">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper presents new methods for analyzing and evaluating generalized plans that can solve broad classes of related planning problems. Although synthesis and learning of generalized plans has been a longstanding goal in AI, it remains challenging due to fun- damental gaps in methods for analyzing the scope and utility of a given generalized plan. This paper addresses these gaps by developing a new conceptual framework along with proof techniques and algorithmic processes for assessing termination and goal-reachability related properties of generalized plans. We build upon classic results from graph theory to decompose generalized plans into smaller components that are then used to derive hi- erarchical termination arguments. These methods can be used to determine the utility of a given generalized plan, as well as to guide the synthesis and learning processes for generalized plans. We present theoretical as well as empirical results illustrating the scope of this new approach. Our analysis shows that this approach significantly extends the class of generalized plans that can be assessed automatically, thereby reducing barriers in the synthesis and learning of reliable generalized plans. Keywords: Journal Track: Journal Track},
  archive   = {C_IJCAI},
  author    = {Siddharth Srivastava},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/957},
  month     = {8},
  pages     = {8485},
  title     = {Hierarchical decompositions and termination analysis for generalized planning (Abstract reprint)},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Methods for recovering conditional independence graphs
(abstract reprint). <em>IJCAI</em>, 8484. (<a
href="https://doi.org/10.24963/ijcai.2024/956">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Conditional Independence (CI) graphs are a type of probabilistic graphical models that are primarily used to gain insights about feature relationships. Each edge represents the partial correlation between the connected features which gives information about their direct dependence. In this survey, we list out different methods and study the advances in techniques developed to recover CI graphs. We cover traditional optimization methods as well as recently developed deep learning architectures along with their recommended implementations . To facilitate wider adoption, we include preliminaries that consolidate associated operations, for example techniques to obtain covariance matrix for mixed datatypes. Keywords: Conditional Independence Graphs, Probabilistic Graphical Models, Graphical Lasso, Deep Learning, Optimization Keywords: Journal Track: Journal Track},
  archive   = {C_IJCAI},
  author    = {Harsh Shrivastava and Urszula Chajewska},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/956},
  month     = {8},
  pages     = {8484},
  title     = {Methods for recovering conditional independence graphs (Abstract reprint)},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Performative ethics from within the ivory tower: How
CSPractitioners uphold systems of oppression (abstract reprint).
<em>IJCAI</em>, 8483. (<a
href="https://doi.org/10.24963/ijcai.2024/955">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper analyzes where Artificial Intelligence (AI) Ethics research fails and breaks down the dangers of well-intentioned, but ultimately performative ethics research. A large majority of AI ethics research is critiqued for lacking a comprehensive analysis of how AI is interconnected with sociological systems of oppression and power. Our work contributes to the handful of research that presents intersectional, Western systems of oppression and power as a framework for examining AI ethics work and the complexities of building less harmful technology; directly connecting technology to named systems such as capitalism and classism, colonialism, racism and white supremacy, patriarchy, and ableism. We then explore current AI ethics rhetoric&#39;s effect on the AI ethics domain and AI regulation. In conclusion, we provide an applied example to contextualize intersectional systems of oppression and AI interventions in the U.S. justice system and present actionable steps for AI practitioners to participate in a less performative, critical analysis of AI. Keywords: Journal Track: Journal Track},
  archive   = {C_IJCAI},
  author    = {Zari McFadden and Lauren Alvarez},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/955},
  month     = {8},
  pages     = {8483},
  title     = {Performative ethics from within the ivory tower: How CSPractitioners uphold systems of oppression (Abstract reprint)},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mitigating robust overfitting via self-residual-calibration
regularization (abstract reprint). <em>IJCAI</em>, 8482. (<a
href="https://doi.org/10.24963/ijcai.2024/954">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Overfitting in adversarial training has attracted the interest of researchers in the community of artificial intelligence and machine learning in recent years. To address this issue, in this paper we begin by evaluating the defense performances of several calibration methods on various robust models. Our analysis and experiments reveal two intriguing properties: 1) a well-calibrated robust model is decreasing the confidence of robust model; 2) there is a trade-off between the confidences of natural and adversarial images. These new properties offer a straightforward insight into designing a simple but effective regularization, called Self-Residual-Calibration (SRC). The proposed SRC calculates the absolute residual between adversarial and natural logit features corresponding to the ground-truth labels. Furthermore, we utilize the pinball loss to minimize the quantile residual between them, resulting in more robust regularization. Extensive experiments indicate that our SRC can effectively mitigate the overfitting problem while improving the robustness of state-of-the-art models. Importantly, SRC is complementary to various regularization methods. When combined with them, we are capable of achieving the top-rank performance on the AutoAttack benchmark leaderboard. Keywords: Journal Track: Journal Track},
  archive   = {C_IJCAI},
  author    = {Hong Liu and Zhun Zhong and Nicu Sebe and Shin&#39;ichi Satoh},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/954},
  month     = {8},
  pages     = {8482},
  title     = {Mitigating robust overfitting via self-residual-calibration regularization (Abstract reprint)},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimality guarantees for particle belief approximation of
POMDPs (abstract reprint). <em>IJCAI</em>, 8481. (<a
href="https://doi.org/10.24963/ijcai.2024/953">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Partially observable Markov decision processes (POMDPs) provide a flexible representation for real-world decision and control problems. However, POMDPs are notoriously difficult to solve, especially when the state and observation spaces are continuous or hybrid, which is often the case for physical systems. While recent online sampling-based POMDP algorithms that plan with observation likelihood weighting have shown practical effectiveness, a general theory characterizing the approximation error of the particle filtering techniques that these algorithms use has not previously been proposed. Our main contribution is bounding the error between any POMDP and its corresponding finite sample particle belief MDP (PB-MDP) approximation. This fundamental bridge between PB-MDPs and POMDPs allows us to adapt any sampling-based MDP algorithm to a POMDP by solving the corresponding particle belief MDP, thereby extending the convergence guarantees of the MDP algorithm to the POMDP. Practically, this is implemented by using the particle filter belief transition model as the generative model for the MDP solver. While this requires access to the observation density model from the POMDP, it only increases the transition sampling complexity of the MDP solver by a factor of O(C), where C is the number of particles. Thus, when combined with sparse sampling MDP algorithms, this approach can yield algorithms for POMDPs that have no direct theoretical dependence on the size of the state and observation spaces. In addition to our theoretical contribution, we perform five numerical experiments on benchmark POMDPs to demonstrate that a simple MDP algorithm adapted using PB-MDP approximation, Sparse-PFT, achieves performance competitive with other leading continuous observation POMDP solvers. Keywords: Journal Track: Journal Track},
  archive   = {C_IJCAI},
  author    = {Michael Lim and Tyler Becker and Mykel Kochenderfer and Claire Tomlin and Zachary Sunberg},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/953},
  month     = {8},
  pages     = {8481},
  title     = {Optimality guarantees for particle belief approximation of POMDPs (Abstract reprint)},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On mitigating the utility-loss in differentially private
learning: A new perspective by a geometrically inspired kernel approach
(abstract reprint). <em>IJCAI</em>, 8480. (<a
href="https://doi.org/10.24963/ijcai.2024/952">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Privacy-utility tradeoff remains as one of the fundamental issues of differentially private machine learning. This paper introduces a geometrically inspired kernel-based approach to mitigate the accuracy-loss issue in classification. In this approach, a representation of the affine hull of given data points is learned in Reproducing Kernel Hilbert Spaces (RKHS). This leads to a novel distance measure that hides privacy-sensitive information about individual data points and improves the privacy-utility tradeoff via significantly reducing the risk of membership inference attacks. The effectiveness of the approach is demonstrated through experiments on MNIST dataset, Freiburg groceries dataset, and a real biomedical dataset. It is verified that the approach remains computationally practical. The application of the approach to federated learning is considered and it is observed that the accuracy-loss due to data being distributed is either marginal or not significantly high. Keywords: Journal Track: Journal Track},
  archive   = {C_IJCAI},
  author    = {Mohit Kumar and Bernhard A. Moser and Lukas Fischer},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/952},
  month     = {8},
  pages     = {8480},
  title     = {On mitigating the utility-loss in differentially private learning: A new perspective by a geometrically inspired kernel approach (Abstract reprint)},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SensorSCAN: Self-supervised learning and deep clustering for
fault diagnosis in chemical processes (abstract reprint).
<em>IJCAI</em>, 8479. (<a
href="https://doi.org/10.24963/ijcai.2024/951">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Modern industrial facilities generate large volumes of raw sensor data during the production process. This data is used to monitor and control the processes and can be analyzed to detect and predict process abnormalities. Typically, the data has to be annotated by experts in order to be used in predictive modeling. However, manual annotation of large amounts of data can be difficult in industrial settings. In this paper, we propose SensorSCAN, a novel method for unsupervised fault detection and diagnosis, designed for industrial chemical process monitoring. We demonstrate our model&#39;s performance on two publicly available datasets of the Tennessee Eastman Process with various faults. The results show that our method significantly outperforms existing approaches (+0.2-0.3 TPR for a fixed FPR) and effectively detects most of the process faults without expert annotation. Moreover, we show that the model fine-tuned on a small fraction of labeled data nearly reaches the performance of a SOTA model trained on the full dataset. We also demonstrate that our method is suitable for real-world applications where the number of faults is not known in advance. The code is available at https://github.com/AIRI-Institute/sensorscan Keywords: Journal Track: Journal Track},
  archive   = {C_IJCAI},
  author    = {Maksim Golyadkin and Vitaliy Pozdnyakov and Leonid Zhukov and Ilya Makarov},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/951},
  month     = {8},
  pages     = {8479},
  title     = {SensorSCAN: Self-supervised learning and deep clustering for fault diagnosis in chemical processes (Abstract reprint)},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A differentiable first-order rule learner for inductive
logic programming (abstract reprint). <em>IJCAI</em>, 8478. (<a
href="https://doi.org/10.24963/ijcai.2024/950">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Learning first-order logic programs from relational facts yields intuitive insights into the data. Inductive logic programming (ILP) models are effective in learning first-order logic programs from observed relational data. Symbolic ILP models support rule learning in a data-ecient manner. However, symbolic ILP models are not robust to learn from noisy data. Neuro-symbolic ILP models utilize neural networks to learn logic programs in a differentiable manner which improves the robustness of ILP models. However, most neuro-symbolic methods need a strong language bias to learn logic programs, which reduces the usability and flexibility of ILP models and limits the logic program formats. In addition, most neuro-symbolic ILP methods cannot learn logic programs effectively from both small-size datasets and large-size datasets such as knowledge graphs. In the paper, we introduce a novel differentiable ILP model called differentiable first-order rule learner (DFORL), which is scalable to learn rules from both smaller and larger datasets. Besides, DFORL only needs the number of variables in the learned logic programs as input. Hence, DFORL is easy to use and does not need a strong language bias. We demonstrate that DFORL can perform well on several standard ILP datasets, knowledge graphs, and probabilistic relation facts and outperform several well-known differentiable ILP models. Experimental results indicate that DFORL is a precise, robust, scalable, and computationally cheap differentiable ILP model. Keywords: Journal Track: Journal Track},
  archive   = {C_IJCAI},
  author    = {Kun Gao and Katsumi Inoue and Yongzhi Cao and Hanpin Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/950},
  month     = {8},
  pages     = {8478},
  title     = {A differentiable first-order rule learner for inductive logic programming (Abstract reprint)},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning to resolve social dilemmas: A survey (abstract
reprint). <em>IJCAI</em>, 8477. (<a
href="https://doi.org/10.24963/ijcai.2024/949">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Social dilemmasare situations of inter-dependent decision making in which individualrationality can lead to outcomes with poor social qualities. The ubiquity of social dilem-mas in social, biological, and computational systems has generated substantial researchacross these diverse disciplines into the study of mechanisms for avoiding deficient outcomes by promoting and maintaining mutual cooperation. Much of this research is focused on studying how individuals faced with a dilemma can learn to cooperate by adapting their behaviours according to their past experience. In particular, three types of learning approaches have been studied: evolutionary game-theoretic learning, reinforcement learning, and best-response learning. This article is a comprehensive integrated survey of these learning approaches in the context of dilemma games. We formally introduce dilemma games and their inherent challenges. We then outline the three learning approaches and, for eachapproach, provide a survey of the solutions proposed for dilemma resolution. Finally, we provide a comparative summary and discuss directions in which further research is needed. Keywords: Journal Track: Journal Track},
  archive   = {C_IJCAI},
  author    = {Shaheen Fatima and Nicholas Jennings and Michael Wooldridge},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/949},
  month     = {8},
  pages     = {8477},
  title     = {Learning to resolve social dilemmas: A survey (Abstract reprint)},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Detecting change intervalswith isolation distributional
kernel (abstract reprint). <em>IJCAI</em>, 8476. (<a
href="https://doi.org/10.24963/ijcai.2024/948">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Detecting abrupt changes in data distribution is one of the most significant tasks in streaming data analysis. Although many unsupervised Change-Point Detection (CPD) methods have been proposed recently to identify those changes, they still suffer from missing subtle changes, poor scalability, or/and sensitivity to outliers. To meet these challenges, we are the first to generalise the CPD problem as a special case of the Change-Interval Detection (CID) problem. Then we propose a CID method, named iCID, based on a recent Isolation Distributional Kernel (IDK). iCID identifies the change interval if there is a high dissimilarity score between two non-homogeneous temporal adjacent intervals. The data-dependent property and finite feature map of IDK enabled iCID to efficiently identify various types of change-points in data streams with the tolerance of outliers. Moreover, the proposed online and offline versions of iCID have the ability to optimise key parameter settings. The effectiveness and efficiency of iCID have been systematically verified on both synthetic and real-world datasets. Keywords: Journal Track: Journal Track},
  archive   = {C_IJCAI},
  author    = {Yang Cao and Ye Zhu and Kai Ming Ting and Flora D. Salim and Hong Xian Li and Luxing Yang and Gang Li},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/948},
  month     = {8},
  pages     = {8476},
  title     = {Detecting change intervalswith isolation distributional kernel (Abstract reprint)},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Weighted, circular and semi-algebraic proofs (abstract
reprint). <em>IJCAI</em>, 8475. (<a
href="https://doi.org/10.24963/ijcai.2024/947">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In recent years there has been an increasing interest in studying proof systems stronger than Resolution, with the aim of building more efficient SAT solvers based on them. In defining these proof systems, we try to find a balance between the power of the proof system (the size of the proofs required to refute a formula) and the difficulty of finding the proofs. In this paper we consider the proof systems circular Resolution, Sherali-Adams, Nullstellensatz and Weighted Resolution and we study their relative power from a theoretical perspective. We prove that circular Resolution, Sherali-Adams and Weighted Resolution are polynomially equivalent proof systems. We also prove that Nullstellensatz is polynomially equivalent to a restricted version of Weighted Resolution. The equivalences carry on also for versions of the systems where the coefficients/weights are expressed in unary. The practical interest in these systems comes from the fact that they admit efficient algorithms to find proofs in case these have small width/degree. Keywords: Journal Track: Journal Track},
  archive   = {C_IJCAI},
  author    = {Ilario Bonacina and Maria Luisa Bonet and Jordi Levy},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/947},
  month     = {8},
  pages     = {8475},
  title     = {Weighted, circular and semi-algebraic proofs (Abstract reprint)},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Negative human rights as a basis for long-term AI safety and
regulation (abstract reprint). <em>IJCAI</em>, 8474. (<a
href="https://doi.org/10.24963/ijcai.2024/946">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {If autonomous AI systems are to be reliably safe in novel situations, they will need to incorporate general principles guiding them to recognize and avoid harmful behaviours. Such principles may need to be supported by a binding system of regulation, which would need the underlying principles to be widely accepted. They should also be specific enough for technical implementation. Drawing inspiration from law, this article explains how negative human rights could fulfil the role of such principles and serve as a foundation both for an international regulatory system and for building technical safety constraints for future AI systems. Keywords: Journal Track: Journal Track},
  archive   = {C_IJCAI},
  author    = {Ondrej Bajgar and Jan Horenovsky},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/946},
  month     = {8},
  pages     = {8474},
  title     = {Negative human rights as a basis for long-term AI safety and regulation (Abstract reprint)},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hybrid planning for challenging construction problems: An
answer set programming approach (abstract reprint). <em>IJCAI</em>,
8473. (<a href="https://doi.org/10.24963/ijcai.2024/945">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study construction problems where multiple robots rearrange stacks of prefabricated blocks to build stable structures. These problems are challenging due to ramifications of actions, true concurrency, and requirements of supportedness of blocks by a surface or a robot and stability of the overall structure at all times. We propose a general elaboration tolerant method to solve a wide range of construction problems, based on the knowledge representation and reasoning paradigm of Answer Set Programming. This method not only (i) determines a stable final configuration of the structure, but also (ii) computes the order of manipulation tasks for multiple autonomous robots to build the structure from an initial configuration, (iii) while simultaneously ensuring the requirements of supportedness and stability at all times. We prove the soundness and completeness of our method with respect to these properties. We introduce a set of challenging construction benchmark instances, including construction of (uneven) bridges and overhangs, and discuss the usefulness of our framework over these instances. Furthermore, we perform experiments to investigate the computational performance of our hybrid method, and demonstrate the applicability of our method using a bimanual Baxter robot. Keywords: Journal Track: Journal Track},
  archive   = {C_IJCAI},
  author    = {Faseeh Ahmad and Volkan Patoglu and Esra Erdem},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/945},
  month     = {8},
  pages     = {8473},
  title     = {Hybrid planning for challenging construction problems: An answer set programming approach (Abstract reprint)},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the complexity of finding set repairs for data-graphs
(abstract reprint). <em>IJCAI</em>, 8472. (<a
href="https://doi.org/10.24963/ijcai.2024/944">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the deeply interconnected world we live in, pieces of information link domains all around us. As graph databases embrace effectively relationships among data and allow processing and querying these connections efficiently, they are rapidly becoming a popular platform for storage that supports a wide range of domains and applications. As in the relational case, it is expected that data preserves a set of integrity constraints that define the semantic structure of the world it represents. When a database does not satisfy its integrity constraints, a possible approach is to search for a ‘similar’ database that does satisfy the constraints, also known as a repair. In this work, we study the problem of computing subset and superset repairs for graph databases with data values using a notion of consistency based on having a set of Reg-GXPath expressions as integrity constraints. We show that for positive fragments of Reg-GXPath these problems admit a polynomialtime algorithm, while the full expressive power of the language renders them intractable. Keywords: Journal Track: Journal Track},
  archive   = {C_IJCAI},
  author    = {Sergio Abriola and Maria Vanina Martinez and Nina Pardal and Santiago Cifuentes and Edwin Pin Baque},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/944},
  month     = {8},
  pages     = {8472},
  title     = {On the complexity of finding set repairs for data-graphs (Abstract reprint)},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards efficient MCMC sampling in bayesian neural networks
by exploiting symmetry (extended abstract). <em>IJCAI</em>, 8466–8470.
(<a href="https://doi.org/10.24963/ijcai.2024/943">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Bayesian inference in deep neural networks is challenging due to the high-dimensional, strongly multi-modal parameter posterior density landscape. Markov chain Monte Carlo approaches asymptotically recover the true posterior but are considered prohibitively expensive for large modern architectures. We argue that the dilemma between exact-but-unaffordable and cheap-but-inexact approaches can be mitigated by exploiting symmetries in the posterior landscape. We show theoretically that the posterior predictive density in Bayesian neural networks can be restricted to a symmetry-free parameter reference set. By further deriving an upper bound on the number of Monte Carlo chains required to capture the functional diversity, we propose a straightforward approach for feasible Bayesian inference. Keywords: Machine Learning: ML: Bayesian learning Machine Learning: ML: Probabilistic machine learning Uncertainty in AI: UAI: Inference Uncertainty in AI: UAI: Tractable probabilistic models},
  archive   = {C_IJCAI},
  author    = {Jonas Gregor Wiese and Lisa Wimmer and Theodore Papamarkou and Bernd Bischl and Stephan Guennemann and David Ruegamer},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/943},
  month     = {8},
  pages     = {8466-8470},
  title     = {Towards efficient MCMC sampling in bayesian neural networks by exploiting symmetry (Extended abstract)},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). All in one: Multi-task prompting for graph neural networks
(extended abstract). <em>IJCAI</em>, 8460–8465. (<a
href="https://doi.org/10.24963/ijcai.2024/942">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper is an extended abstract of our original work published in KDD23, where we won the best research paper award. The paper introduces a novel approach to bridging the gap between pre-trained graph models and the diverse tasks they’re applied to, inspired by the success of prompt learning in NLP. Recognizing the challenge of aligning pre-trained models with varied graph tasks (node level, edge level, and graph level), which can lead to negative transfer and poor performance, we propose a multi-task prompting method for graphs. This method involves unifying graph and language prompt formats, enabling NLP’s prompting strategies to be adapted for graph tasks. By analyzing the task space of graph applications, we reformulate problems to fit graph-level tasks and apply meta-learning to improve prompt initialization for multiple tasks. Experiments show our method’s effectiveness in enhancing model performance across different graph tasks. Beyond the original work, in this extended abstract, we further discuss the graph prompt from a bigger picture and provide some of the latest work toward this area. Keywords: Data Mining: DM: Mining graphs Data Mining: DM: Networks Machine Learning: ML: Representation learning Multidisciplinary Topics and Applications: MTA: Web and social networks},
  archive   = {C_IJCAI},
  author    = {Xiangguo Sun and Hong Cheng and Jia Li and Bo Liu and Jihong Guan},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/942},
  month     = {8},
  pages     = {8460-8465},
  title     = {All in one: Multi-task prompting for graph neural networks (Extended abstract)},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Voting by axioms (extended abstract). <em>IJCAI</em>,
8455–8459. (<a href="https://doi.org/10.24963/ijcai.2024/941">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We develop an approach for collective decision making from first principles. In this approach, rather than using a---necessarily imperfect---voting rule to map any given scenario where individual agents report their preferences into a collective decision, we identify for every concrete such scenario the most appealing set of normative principles (known as axioms in social choice theory) that would entail a unique decision and then implement that decision. We analyse some of the fundamental properties of this new approach, from both an algorithmic and a normative point of view. Keywords: Game Theory and Economic Paradigms: GTEP: Computational social choice},
  archive   = {C_IJCAI},
  author    = {Marie Christin Schmidtlein and Ulle Endriss},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/941},
  month     = {8},
  pages     = {8455-8459},
  title     = {Voting by axioms (Extended abstract)},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Content matters: A computational investigation into the
effectiveness of retrieval practice and worked examples (extended
abstract). <em>IJCAI</em>, 8450–8454. (<a
href="https://doi.org/10.24963/ijcai.2024/940">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we argue that computational models of learning can contribute precise theory to explain surprising student learning phenomena. In some past studies, practice produces better learning than studying examples, whereas other studies show the opposite result. We explain this contradiction by suggesting that retrieval practice and example study involve different learning cognitive processes, memorization and induction, and each process is optimal for different types of knowledge. We implement and test this theoretical explanation by extending an AI model of human cognition to include both memory and induction processes and comparing the behavior of the simulated learners to those of human participants. We show that the behavior of simulated learners with forgetting matches that of human participants better than simulated learners without forgetting. Simulated learners with forgetting learn best using retrieval practice in situations that emphasize memorization (such as learning facts), whereas studying examples improves learning when multiple pieces of information are available, so induction and generalization are necessary (such as learning skills). Keywords: Multidisciplinary Topics and Applications: MTA: Education Humans and AI: HAI: Cognitive modeling},
  archive   = {C_IJCAI},
  author    = {Napol Rachatasumrit and Paulo F. Carvalho and Sophie Li and Kenneth R. Koedinger},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/940},
  month     = {8},
  pages     = {8450-8454},
  title     = {Content matters: A computational investigation into the effectiveness of retrieval practice and worked examples (Extended abstract)},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GSASRec: Reducing overconfidence in sequential
recommendation trained with negative sampling (extended abstract).
<em>IJCAI</em>, 8447–8449. (<a
href="https://doi.org/10.24963/ijcai.2024/939">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Sequential recommendation models predict the next item in a sequence of user-item interactions, akin to how language models predict the next tokens. These models often adapt language model architectures, treating item IDs as if they were token IDs. However, the number of potential items in recommender systems makes calculating the interaction probability for all items impractical during training; therefore, recommender systems frequently employ negative sampling, where the model learns to differentiate between actual user interactions (positives) and randomly chosen non-interactions (negatives), often using Binary Cross-Entropy (BCE) the loss, framing the problem as a binary classification task. We demonstrate that using negative sampling with BCE can lead to overconfidence, where the model&#39;s predicted probabilities for user interactions are higher than the actual probabilities. Although the actual score magnitude is not important for ranking items (only the order of scores matters), overconfidence leads to training instability when using Binary Cross-Entropy (BCE) loss. We show that overconfidence explains the performance gap between two leading sequential recommendation models, SASRec and BERT4Rec -- the former uses negative sampling, while the latter does not. To counter overconfidence, we introduce Generalised Binary Cross-Entropy (gBCE) loss and the gSASRec model that utilises gBCE. We mathematically prove and empirically validate that gSASRec effectively addresses the issue of overconfidence. Consequently, gSASRec&#39;s effectiveness is better than that of SASRec and matches the state of the BERT4Rec while retaining negative sampling. On the Gowalla dataset with more than 1MM items, where training BERT4Rec is infeasible, gSASRec outperforms the original SASRec model by 41% in terms of NDCG@10. Keywords: Data Mining: DM: Recommender systems Machine Learning: ML: Probabilistic machine learning Data Mining: DM: Information retrieval Machine Learning: ML: Sequence and graph learning},
  archive   = {C_IJCAI},
  author    = {Aleksandr V. Petrov and Craig Macdonald},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/939},
  month     = {8},
  pages     = {8447-8449},
  title     = {GSASRec: Reducing overconfidence in sequential recommendation trained with negative sampling (Extended abstract)},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Proof logging for smart extensional constraints (extended
abstract). <em>IJCAI</em>, 8444–8446. (<a
href="https://doi.org/10.24963/ijcai.2024/938">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Proof logging provides an auditable way of guaranteeing that a solver has produced a correct answer using sound reasoning. This is standard practice for Boolean satisfiability solving, but for constraint programming, a challenge is that every propagator must be able to justify all inferences it performs. Here we demonstrate how to support proof logging for a wide range of previously uncertified global constraints. We do this by showing how to justify every inference that could be performed by the propagation algorithms for two families of generalised extensional constraint: &quot;Smart Table&quot; and &quot;Regular Language Membership&quot;. Keywords: Constraint Satisfaction and Optimization: CSO: Constraint programming},
  archive   = {C_IJCAI},
  author    = {Matthew J. McIlree and Ciaran McCreesh},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/938},
  month     = {8},
  pages     = {8444-8446},
  title     = {Proof logging for smart extensional constraints (Extended abstract)},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MPGraf: A modular and pre-trained graphformer for learning
to rank at web-scale (extended abstract). <em>IJCAI</em>, 8439–8443. (<a
href="https://doi.org/10.24963/ijcai.2024/937">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Both Transformer and Graph Neural Networks (GNNs) have been used in learning to rank (LTR), however, they adhere to two distinct yet complementary problem formulations, i.e., ranking score regression based on query-webpage pairs and link prediction within query-webpage bipartite graphs, respectively. Though it is possible to pre-train GNNs or Transformers on source datasets and fine-tune them subject to sparsely annotated LTR datasets separately, the source-target distribution shifts across the pairs and bipartite graphs domains make it extremely difficult to integrate these diverse models into a single LTR framework at a web-scale. We introduce the novel MPGraf model, which utilizes a modular and capsule-based pre-training approach, aiming to incorporate regression capacities from Transformers and link prediction capabilities of GNNs cohesively. We conduct extensive experiments to evaluate the performance of MPGraf using real-world datasets collected from large-scale search engines. The results show that MPGraf can outperform baseline algorithms on several major metrics. Further, we deploy and evaluate MPGraf atop a large-scale search engine with realistic web traffic via A/B tests, where we can still observe significant improvement. MPGraf performs consistently in both offline and online evaluations. Keywords: Data Mining: DM: Mining text, web, social media},
  archive   = {C_IJCAI},
  author    = {Yuchen Li and Haoyi Xiong and Linghe Kong and Zeyi Sun and Hongyang Chen and Shuaiqiang Wang and Dawei Yin},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/937},
  month     = {8},
  pages     = {8439-8443},
  title     = {MPGraf: A modular and pre-trained graphformer for learning to rank at web-scale (Extended abstract)},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GS2P: A generative pre-trained learning to rank model with
over-parameterization for web-scale search (extended abstract).
<em>IJCAI</em>, 8433–8438. (<a
href="https://doi.org/10.24963/ijcai.2024/936">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {While Learning to Rank (LTR) is widely employed in web searches to prioritize pertinent webpages from the retrieved contents based on input queries, traditional LTR models stumble over two principal stumbling blocks leading to subpar performance: 1) the lack of well-annotated query-webpage pairs with ranking scores to cover search queries of various popularity, debilitating their coverage of search queries across the popularity spectrum, and 2) ill-trained models that are incapable of inducing generalized representations for LTR, culminating in overfitting. To tackle above challenges, we proposed a Generative Semi-supervised Pre-trained (GS2P) LTR model. Specifically, GS2P first generates pseudo-labels for the unlabeled samples using tree-based LTR models after a series of co-training procedures, then learns the representations of query-webpage pairs with self-attentive transformers via both discriminative and generative losses. Finally, GS2P boosts the performance of LTR through incorporating Random Fourier Features to over-parameterize the models into &quot;interpolating regime&quot;, so as to enjoy the further descent of generalization errors with learned representations. We conduct extensive offline experiments on a publicly available dataset and a real-world dataset collected from a large-scale search engine. The results show that GS2P can achieve the best performance on both datasets, compared to baselines. We also deploy GS2P at a large-scale web search engine with realistic traffic, where we can still observe significant improvement in real-world applications. Keywords: Data Mining: DM: Mining text, web, social media},
  archive   = {C_IJCAI},
  author    = {Yuchen Li and Haoyi Xiong and Linghe Kong and Jiang Bian and Shuaiqiang Wang and Guihai Chen and Dawei Yin},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/936},
  month     = {8},
  pages     = {8433-8438},
  title     = {GS2P: A generative pre-trained learning to rank model with over-parameterization for web-scale search (Extended abstract)},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). POWL: Partially ordered workflow language (extended
abstract). <em>IJCAI</em>, 8427–8432. (<a
href="https://doi.org/10.24963/ijcai.2024/935">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Processes in real-life scenarios tend to inherently establish partial orders over their constituent activities. This makes partially ordered graphs viable for process modeling. While partial orders capture both concurrent and sequential interactions among activities in a compact way, they fall short in modeling choice and cyclic behavior. To address this gap, we introduce the Partially Ordered Workflow Language (POWL), a novel language for process modeling that combines traditional hierarchical modeling languages with partial orders. In a POWL model, sub-models are combined into larger ones either as partial orders or using control-flow operators that enable the representation of choice and loop structures. This integration of hierarchical structure and partial orders not only offers an effective solution for process modeling but also provides quality guarantees that make POWL particularly suitable for the automated discovery of process models. Keywords: Data Mining: General Multidisciplinary Topics and Applications: General},
  archive   = {C_IJCAI},
  author    = {Humam Kourani and Sebastiaan van Zelst},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/935},
  month     = {8},
  pages     = {8427-8432},
  title     = {POWL: Partially ordered workflow language (Extended abstract)},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A single vector is not enough: Taxonomy expansion via box
embeddings (extended abstract). <em>IJCAI</em>, 8421–8426. (<a
href="https://doi.org/10.24963/ijcai.2024/934">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Taxonomies support various practical web applications such as product navigation in online shopping and user profile tagging on social platforms. Most existing methods for expanding taxonomies encode entities into vector embeddings (i.e., single points). However, we argue that vectors are insufficient to model the ``is-a&#39;&#39; hierarchy in taxonomy (asymmetrical relation), because two points can only represent pairwise similarity (symmetrical relation). To this end, we propose to project taxonomy entities into boxes (i.e., hyperrectangles). Two boxes can be &quot;contained&quot;, &quot;disjoint&quot; and &quot;intersecting&quot;, thus naturally representing an asymmetrical taxonomic hierarchy. Upon box embeddings, we propose a novel model BoxTaxo for taxonomy expansion. The core of BoxTaxo is to learn boxes for entities to capture their child-parent hierarchies. Extensive experiments on two benchmarks demonstrate the effectiveness of BoxTaxo compared to vector based models. Keywords: Knowledge Representation and Reasoning: KRR: Semantic Web},
  archive   = {C_IJCAI},
  author    = {Song Jiang and Qiyue Yao and Qifan Wang and Yizhou Sun},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/934},
  month     = {8},
  pages     = {8421-8426},
  title     = {A single vector is not enough: Taxonomy expansion via box embeddings (Extended abstract)},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Defending against backdoor attacks by layer-wise feature
analysis (extended abstract). <em>IJCAI</em>, 8416–8420. (<a
href="https://doi.org/10.24963/ijcai.2024/933">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Training deep neural networks (DNNs) usually requires massive training data and computational resources. Users who cannot afford this may prefer to outsource training to a third party or resort to publicly available pre-trained models. Unfortunately, doing so facilitates a new training-time attack (i.e., backdoor attack) against DNNs. This attack aims to induce misclassification of input samples containing adversary-specified trigger patterns. In this paper, we first conduct a layer-wise feature analysis of poisoned and benign samples from the target class. We find out that the feature difference between benign and poisoned samples tends to be maximum at a critical layer, which is not always the one typically used in existing defenses, namely the layer before fully-connected layers. We also demonstrate how to locate this critical layer based on the behaviors of benign samples. We then propose a simple yet effective method to filter poisoned samples by analyzing the feature differences between suspicious and benign samples at the critical layer. Extensive experiments on two benchmark datasets are reported which confirm the effectiveness of our defense. Keywords: AI Ethics, Trust, Fairness: ETF: Trustworthy AI Machine Learning: ML: Trustworthy machine learning Machine Learning: ML: Robustness},
  archive   = {C_IJCAI},
  author    = {Najeeb Moharram Jebreel and Josep Domingo-Ferrer and Yiming Li},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/933},
  month     = {8},
  pages     = {8416-8420},
  title     = {Defending against backdoor attacks by layer-wise feature analysis (Extended abstract)},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bagging is an optimal PAC learner (extended abstract).
<em>IJCAI</em>, 8411–8415. (<a
href="https://doi.org/10.24963/ijcai.2024/932">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Determining the optimal sample complexity of PAC learning in the realizable setting was a central open problem in learning theory for decades. Finally, seminal work by Hanneke gave an algorithm with a provably optimal sample complexity. His algorithm is based on a careful and structured sub-sampling of the training data and then returning a majority vote among hypotheses trained on each of the sub-samples. While being a very exciting theoretical result, it has not had much impact in practice, in part due to inefficiency, since it constructs a polynomial number of sub-samples of the training data, each of linear size. In this work, we prove the surprising result that the practical and classic heuristic bagging (a.k.a. bootstrap aggregation), due to Breiman, is in fact also an optimal PAC learner. Bagging pre-dates Hanneke&#39;s algorithm by twenty years and is taught in most undergraduate machine learning courses. Moreover, we show that it only requires a logarithmic number of sub-samples to reach optimality. Keywords: Machine Learning: ML: Learning theory Machine Learning: ML: Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Kasper Green Larsen},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/932},
  month     = {8},
  pages     = {8411-8415},
  title     = {Bagging is an optimal PAC learner (Extended abstract)},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The information retrieval experiment platform (extended
abstract). <em>IJCAI</em>, 8405–8410. (<a
href="https://doi.org/10.24963/ijcai.2024/931">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We have built TIREx, the information retrieval experiment platform, to promote standardized, reproducible, scalable, and blinded retrieval experiments. Standardization is achieved through integration with PyTerrier&#39;s interfaces and compatibility with ir_datasets and ir_measures. Reproducibility and scalability are based on the underlying TIRA framework, which runs dockerized software in a cloud-native execution environment. Using Docker images of 50 standard retrieval approaches, we evaluated all of them on 32 tasks (i.e., 1,600 runs) in less than a week on a midsize cluster (1,620 CPU cores and 24 GPUs), demonstrating multi-task scalability. Importantly, TIRA also enables blind evaluation of AI experiments, as the test data can be hidden from public access and the tested approaches run in a sandbox that prevents data leaks. Keeping the test data hidden from public access ensures that it cannot be used by third parties for LLM training, preventing future training-test leaks. Keywords: Natural Language Processing: NLP: Information retrieval and text mining Natural Language Processing: NLP: Resources and evaluation Natural Language Processing: NLP: Tools},
  archive   = {C_IJCAI},
  author    = {Maik Fröbe and Jan Heinrich Reimer and Sean MacAvaney and Niklas Deckers and Simon Reich and Janek Bevendorff and Benno Stein and Matthias Hagen and Martin Potthast},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/931},
  month     = {8},
  pages     = {8405-8410},
  title     = {The information retrieval experiment platform (Extended abstract)},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Capturing (optimal) relaxed plans with stable and supported
models of logic programs (extended abstract). <em>IJCAI</em>, 8399–8404.
(<a href="https://doi.org/10.24963/ijcai.2024/930">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We establish a novel relation between delete-free planning, an important task for the AI Planning community also known as relaxed planning, and logic programming. We show that given a planning problem, all subsets of actions that could be ordered to produce relaxed plans for the problem can be bijectively captured with stable models of a logic program describing the corresponding relaxed planning problem. We also consider the supported model semantics of logic programs, and introduce one causal and one diagnostic encoding of the relaxed planning problem as logic programs, both capturing relaxed plans with their supported models. Our experimental results show that these new encodings can provide major performance gain when computing optimal relaxed plans. Keywords: Knowledge Representation and Reasoning: KRR: Logic programming Planning and Scheduling: General Knowledge Representation and Reasoning: KRR: Causality Knowledge Representation and Reasoning: KRR: Reasoning about actions},
  archive   = {C_IJCAI},
  author    = {Masood Feyzbakhsh Rankooh and Tomi Janhunen},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/930},
  month     = {8},
  pages     = {8399-8404},
  title     = {Capturing (Optimal) relaxed plans with stable and supported models of logic programs (Extended abstract)},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Self-repellent random walks on general graphs - achieving
minimal sampling variance via nonlinear markov chains (extended
abstract). <em>IJCAI</em>, 8394–8398. (<a
href="https://doi.org/10.24963/ijcai.2024/929">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider random walks on discrete state spaces, such as general undirected graphs, where the random walkers are designed to approximate a target quantity over the network topology via sampling and neighborhood exploration in the form of Markov chain Monte Carlo (MCMC) procedures. Given any Markov chain corresponding to a target probability distribution, we design a self-repellent random walk (SRRW) which is less likely to transition to nodes that were highly visited in the past, and more likely to transition to seldom visited nodes. For a class of SRRWs parameterized by a positive real α, we prove that the empirical distribution of the process converges almost surely to the target (stationary) distribution of the underlying Markov chain kernel. We then provide a central limit theorem and derive the exact form of the arising asymptotic co-variance matrix, which allows us to show that the SRRW with stronger repellence (larger α) always achieves a smaller asymptotic covariance, in the sense of Loewner ordering of co-variance matrices. Especially for SRRW-driven MCMC algorithms, we show that the decrease in the asymptotic sampling variance is of the order O(1/α), eventually going down to zero. After generalizing these results for a class of weighted empirical measures, we use them as a stepping stone to show that a similar performance ordering can also be obtained for distributed stochastic optimization tasks using token algorithms. More explicitly, by replacing a Markovian token by a SRRW version with the same target distribution, we show that the asymptotic co-variance of the optimization iterates decreases at rate O(1/α^2) - the performance benefit of using SRRW thereby amplified in the stochastic optimization context. Empirical results support our theoretical findings. Keywords: Data Mining: DM: Mining graphs Machine Learning: ML: Learning theory Machine Learning: ML: Optimization},
  archive   = {C_IJCAI},
  author    = {Vishwaraj Doshi and Jie Hu and Do Young Eun},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/929},
  month     = {8},
  pages     = {8394-8398},
  title     = {Self-repellent random walks on general graphs - achieving minimal sampling variance via nonlinear markov chains (Extended abstract)},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Streamlining input/output logics with sequent calculi
(extended abstract). <em>IJCAI</em>, 8389–8393. (<a
href="https://doi.org/10.24963/ijcai.2024/928">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Input/Output (I/O) logic is a general framework for reasoning about conditional norms and/or causal relations. We streamline Bochman’s causal I/O logics and their original version via proof-search-oriented sequent calculi. As a byproduct, we obtain new, simple semantics for all these logics, complexity bounds, embeddings into normal modal logics, and efficient deduction methods. Our work encompasses many scattered results and provides uniform solutions to various unresolved problems. Keywords: Knowledge Representation and Reasoning: KRR: Causality Knowledge Representation and Reasoning: KRR: Computational complexity of reasoning},
  archive   = {C_IJCAI},
  author    = {Agata Ciabattoni and Dmitry Rozplokhas},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/928},
  month     = {8},
  pages     = {8389-8393},
  title     = {Streamlining Input/Output logics with sequent calculi (Extended abstract)},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Selective learning for sample-efficient training in
multi-agent sparse reward tasks (extended abstract). <em>IJCAI</em>,
8384–8388. (<a href="https://doi.org/10.24963/ijcai.2024/927">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Learning effective strategies in sparse reward tasks is one of the fundamental challenges in reinforcement learning. This becomes extremely difficult in multi-agent environments, as the concurrent learning of multiple agents induces the non-stationarity problem and a sharply increased joint state space. Existing works have attempted to promote multi-agent cooperation through experience sharing. However, learning from a large collection of shared experiences is inefficient as there are only a few high-value states in sparse reward tasks, which may instead lead to the curse of dimensionality in large-scale multi-agent systems. This paper focuses on sparse-reward multi-agent cooperative tasks and proposes an effective experience-sharing method, Multi-Agent Selective Learning (MASL), to boost sample-efficient training by reusing valuable experiences from other agents. MASL adopts a retrogression-based selection method to identify high-value traces of agents from the team rewards, based on which some recall traces are generated and shared among agents to motivate effective exploration. Moreover, MASL selectively considers information from other agents to cope with the non-stationarity issue while enabling efficient training for large-scale agents. Experimental results show that MASL significantly improves sample efficiency compared with state-of-the-art MARL algorithms in cooperative tasks with sparse rewards. Keywords: Machine Learning: ML: Multiagent Reinforcement Learning Agent-based and Multi-agent Systems: MAS: Coordination and cooperation},
  archive   = {C_IJCAI},
  author    = {Xinning Chen and Xuan Liu and Yanwen Ba and Shigeng Zhang and Bo Ding and Kenli Li},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/927},
  month     = {8},
  pages     = {8384-8388},
  title     = {Selective learning for sample-efficient training in multi-agent sparse reward tasks (Extended abstract)},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Planning for temporally extended goals in pure-past linear
temporal logic (extended abstract). <em>IJCAI</em>, 8378–8383. (<a
href="https://doi.org/10.24963/ijcai.2024/926">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study classical planning for temporally extended goals expressed in Pure-Past Linear Temporal Logic (PPLTL). PPLTL is as expressive as Linear-time Temporal Logic on finite traces (LTLf), but as shown in this paper, it is computationally much better behaved for planning. Specifically, we show that planning for PPLTL goals can be encoded into classical planning with minimal overhead, introducing only a number of new fluents that is at most linear in the PPLTL goal and no spurious additional actions. Based on these results, we implemented a system called Plan4Past, which can be used along with state-of-the-art classical planners, such as LAMA. An empirical analysis demonstrates the practical effectiveness of Plan4Past, showing that a classical planner generally performs better with our compilation than with other existing compilations for LTLf goals over the considered benchmarks. Keywords: Planning and Scheduling: General Knowledge Representation and Reasoning: KRR: Knowledge representation languages Knowledge Representation and Reasoning: KRR: Qualitative, geometric, spatial, and temporal reasoning},
  archive   = {C_IJCAI},
  author    = {Luigi Bonassi and Giuseppe De Giacomo and Marco Favorito and Francesco Fuggitti and Alfonso Emilio Gerevini and Enrico Scala},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/926},
  month     = {8},
  pages     = {8378-8383},
  title     = {Planning for temporally extended goals in pure-past linear temporal logic (Extended abstract)},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Inferring ontological categories of OWL classes using
foundational rules (extended abstract). <em>IJCAI</em>, 8373–8377. (<a
href="https://doi.org/10.24963/ijcai.2024/925">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Several efforts that leverage the tools of formal ontology have demonstrated the fruitfulness of considering key metaproperties of classes in ontology engineering. Despite that, it is still a common practice to apply representation schemes and approaches--such as OWL--that do not benefit from identifying ontological categories, and simply treat all classes in the same manner. In the original study, we proposed an approach to support the automated classification of classes into the ontological categories underlying the (g)UFO foundational ontology. We proposed a set of inference rules derived from (g)UFO&#39;s axiomatization that, given an initial classification of the classes in an OWL ontology, supports the inference of the classification for the remaining classes in the ontology. We formalized these rules, implemented them in a tool, and assessed them against a catalog of ontologies. Keywords: Knowledge Representation and Reasoning: KRR: Semantic Web Knowledge Representation and Reasoning: KRR: Applications},
  archive   = {C_IJCAI},
  author    = {Pedro Paulo F. Barcelos and Tiago Prince Sales and Elena Romanenko and João Paulo A. Almeida and Gal Engelberg and Dan Klein and Giancarlo Guizzardi},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/925},
  month     = {8},
  pages     = {8373-8377},
  title     = {Inferring ontological categories of OWL classes using foundational rules (Extended abstract)},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Continual learning with pre-trained models: A survey.
<em>IJCAI</em>, 8363–8371. (<a
href="https://doi.org/10.24963/ijcai.2024/924">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Nowadays, real-world applications often face streaming data, which requires the learning system to absorb new knowledge as data evolves. Continual Learning (CL) aims to achieve this goal and meanwhile overcome the catastrophic forgetting of former knowledge when learning new ones. Typical CL methods build the model from scratch to grow with incoming data. However, the advent of the pre-trained model (PTM) era has sparked immense research interest, particularly in leveraging PTMs&#39; robust representational capabilities. This paper presents a comprehensive survey of the latest advancements in PTM-based CL. We categorize existing methodologies into three distinct groups, providing a comparative analysis of their similarities, differences, and respective advantages and disadvantages. Additionally, we offer an empirical study contrasting various state-of-the-art methods to highlight concerns regarding fairness in comparisons. The source code to reproduce these evaluations is available at: https://github.com/sun-hailong/LAMDA-PILOT Keywords: Machine Learning: ML: Incremental learning Machine Learning: ML: Classification Machine Learning: ML: Multi-task and transfer learning},
  archive   = {C_IJCAI},
  author    = {Da-Wei Zhou and Hai-Long Sun and Jingyi Ning and Han-Jia Ye and De-Chuan Zhan},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/924},
  month     = {8},
  pages     = {8363-8371},
  title     = {Continual learning with pre-trained models: A survey},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). More is better: Deep domain adaptation with multiple
sources. <em>IJCAI</em>, 8354–8362. (<a
href="https://doi.org/10.24963/ijcai.2024/923">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In many practical applications, it is often difficult and expensive to obtain large-scale labeled data to train state-of-the-art deep neural networks. Therefore, transferring the learned knowledge from a separate, labeled source domain to an unlabeled or sparsely labeled target domain becomes an appealing alternative. However, direct transfer often results in significant performance decay due to domain shift. Domain adaptation (DA) aims to address this problem by aligning the distributions between the source and target domains. Multi-source domain adaptation (MDA) is a powerful and practical extension in which the labeled data may be collected from multiple sources with different distributions. In this survey, we first define various MDA strategies. Then we systematically summarize and compare modern MDA methods in the deep learning era from different perspectives, followed by commonly used datasets and a brief benchmark. Finally, we discuss future research directions for MDA that are worth investigating. Keywords: Machine Learning: ML: Multi-task and transfer learning Computer Vision: CV: Transfer, low-shot, semi- and un- supervised learning},
  archive   = {C_IJCAI},
  author    = {Sicheng Zhao and Hui Chen and Hu Huang and Pengfei Xu and Guiguang Ding},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/923},
  month     = {8},
  pages     = {8354-8362},
  title     = {More is better: Deep domain adaptation with multiple sources},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A comprehensive survey and taxonomy on point cloud
registration based on deep learning. <em>IJCAI</em>, 8344–8353. (<a
href="https://doi.org/10.24963/ijcai.2024/922">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Point cloud registration (PCR) involves determining a rigid transformation that aligns one point cloud to another. Despite the plethora of outstanding deep learning (DL)-based registration methods proposed, comprehensive and systematic studies on DL-based PCR techniques are still lacking. In this paper, we present a comprehensive survey and taxonomy of recently proposed PCR methods. Firstly, we conduct a taxonomy of commonly utilized datasets and evaluation metrics. Secondly, we classify the existing research into two main categories: supervised and unsupervised registration, providing insights into the core concepts of various influential PCR models. Finally, we highlight open challenges and potential directions for future research. A curated collection of valuable resources is made available at https://github.com/yxzhang15/PCR. Keywords: Computer Vision: General Computer Vision: CV: 3D computer vision},
  archive   = {C_IJCAI},
  author    = {Yu-Xin Zhang and Jie Gui and Xiaofeng Cong and Xin Gong and Wenbing Tao},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/922},
  month     = {8},
  pages     = {8344-8353},
  title     = {A comprehensive survey and taxonomy on point cloud registration based on deep learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Large language models for time series: A survey.
<em>IJCAI</em>, 8335–8343. (<a
href="https://doi.org/10.24963/ijcai.2024/921">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Large Language Models (LLMs) have seen significant use in domains such as natural language processing and computer vision. Going beyond text, image and graphics, LLMs present a significant potential for analysis of time series data, benefiting domains such as climate, IoT, healthcare, traffic, audio and finance. This survey paper provides an in-depth exploration and a detailed taxonomy of the various methodologies employed to harness the power of LLMs for time series analysis. We address the inherent challenge of bridging the gap between LLMs&#39; original text data training and the numerical nature of time series data, and explore strategies for transferring and distilling knowledge from LLMs to numerical time series analysis. We detail various methodologies, including (1) direct prompting of LLMs, (2) time series quantization, (3) aligning techniques, (4) utilization of the vision modality as a bridging mechanism, and (5) the combination of LLMs with tools. Additionally, this survey offers a comprehensive overview of the existing multimodal time series and text datasets in diverse domains, and discusses the challenges and future opportunities of this emerging field. Keywords: Machine Learning: ML: Time series and data streams Data Mining: DM: Mining spatial and/or temporal data Natural Language Processing: NLP: Language models},
  archive   = {C_IJCAI},
  author    = {Xiyuan Zhang and Ranak Roy Chowdhury and Rajesh K. Gupta and Jingbo Shang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/921},
  month     = {8},
  pages     = {8335-8343},
  title     = {Large language models for time series: A survey},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). AI-enhanced virtual reality in medicine: A comprehensive
survey. <em>IJCAI</em>, 8326–8334. (<a
href="https://doi.org/10.24963/ijcai.2024/920">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With the rapid advance of computer graphics and artificial intelligence technologies, the ways we interact with the world have undergone a transformative shift. Virtual Reality (VR) technology, aided by artificial intelligence (AI), has emerged as a dominant interaction media in multiple application areas, thanks to its advantage of providing users with immersive experiences. Among those applications, medicine is considered one of the most promising areas. In this paper, we present a comprehensive examination of the burgeoning field of AI-enhanced VR applications in medical care and services. By introducing a systematic taxonomy, we meticulously classify the pertinent techniques and applications into three well-defined categories based on different phases of medical diagnosis and treatment: Visualization Enhancement, VR-related Medical Data Processing, and VR-assisted Intervention. This categorization enables a structured exploration of the diverse roles that AI-powered VR plays in the medical domain, providing a framework for a more comprehensive understanding and evaluation of these technologies.nTo our best knowledge, this work is the first systematic survey of AI-powered VR systems in medical settings, laying a foundation for future research in this interdisciplinary domain. Keywords: Multidisciplinary Topics and Applications: MTA: Health and medicine Computer Vision: CV: 3D computer vision Computer Vision: CV: Action and behavior recognition Computer Vision: CV: Applications Computer Vision: CV: Biomedical image analysis Computer Vision: CV: Motion and tracking Computer Vision: CV: Recognition (object detection, categorization) Computer Vision: CV: Scene analysis and understanding Computer Vision: CV: Segmentation Multidisciplinary Topics and Applications: MTA: Real-time systems},
  archive   = {C_IJCAI},
  author    = {Yixuan Wu and Kaiyuan Hu and Danny Z. Chen and Jian Wu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/920},
  month     = {8},
  pages     = {8326-8334},
  title     = {AI-enhanced virtual reality in medicine: A comprehensive survey},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on efficient federated learning methods for
foundation model training. <em>IJCAI</em>, 8317–8325. (<a
href="https://doi.org/10.24963/ijcai.2024/919">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Federated Learning (FL) has become an established technique to facilitate privacy-preserving collaborative training across a multitude of clients. However, new approaches to FL often discuss their contributions involving small deep-learning models only and focus on training full models on clients. In the wake of Foundation Models (FM), the reality is different for many deep learning applications. Typically, FMs have already been pre-trained across a wide variety of tasks and can be fine-tuned to specific downstream tasks over significantly smaller datasets than required for full model training. However, access to such datasets is often challenging. By its design, FL can help to open data silos. With this survey, we introduce a novel taxonomy focused on computational and communication efficiency, the vital elements to make use of FMs in FL systems. We discuss the benefits and drawbacks of parameter-efficient fine-tuning (PEFT) for FL applications, elaborate on the readiness of FL frameworks to work with FMs and provide future research opportunities on how to evaluate generative models in FL as well as the interplay of privacy and PEFT. Keywords: Machine Learning: ML: Federated learning Data Mining: DM: Big data and scalability},
  archive   = {C_IJCAI},
  author    = {Herbert Woisetschläger and Alexander Erben and Shiqiang Wang and Ruben Mayer and Hans-Arno Jacobsen},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/919},
  month     = {8},
  pages     = {8317-8325},
  title     = {A survey on efficient federated learning methods for foundation model training},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the essence and prospect: An investigation of alignment
approaches for big models. <em>IJCAI</em>, 8308–8316. (<a
href="https://doi.org/10.24963/ijcai.2024/918">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Big models have achieved revolutionary breakthroughs in the field of AI, but they also pose potential ethical and societal risks to humans. Addressing such problems, alignment technologies were introduced to make these models conform to human preferences and values. Despite the considerable advancements in the past year, various challenges lie in establishing the optimal alignment strategy, such as data cost and scalable oversight, and how to align remains an open question. In this survey paper, we comprehensively investigate value alignment approaches. We first unpack the historical context of alignment tracing back to the 1920s (where it comes from), then delve into the mathematical essence of alignment (what it is), shedding light on the inherent challenges. Following this foundation, we provide a detailed examination of existing alignment methods, which fall into three categories: RL-based Alignment, SFT-based Alignment, and Inference-Time Alignment, and demonstrate their intrinsic connections, strengths, and limitations, helping readers better understand this research area. In addition, two emerging topics, alignment goal and multimodal alignment, are also discussed as novel frontiers in the field. Looking forward, we discuss potential alignment paradigms and how they could handle remaining challenges, prospecting where future alignment will go. Keywords: AI Ethics, Trust, Fairness: ETF: Values Natural Language Processing: NLP: Language generation Natural Language Processing: NLP: Language models},
  archive   = {C_IJCAI},
  author    = {Xinpeng Wang and Shitong Duan and Xiaoyuan Yi and Jing Yao and Shanlin Zhou and Zhihua Wei and Peng Zhang and Dongkuan Xu and Maosong Sun and Xing Xie},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/918},
  month     = {8},
  pages     = {8308-8316},
  title     = {On the essence and prospect: An investigation of alignment approaches for big models},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Beyond the limits: A survey of techniques to extend the
context length in large language models. <em>IJCAI</em>, 8299–8307. (<a
href="https://doi.org/10.24963/ijcai.2024/917">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, large language models (LLMs) have shown remarkable capabilities including understanding context, engaging in logical reasoning, and generating responses. However, this is achieved at the expense of stringent computational and memory requirements, hindering their ability to effectively support long input sequences. This survey provides an inclusive review of the recent techniques and methods devised to extend the sequence length in LLMs, thereby enhancing their capacity for long-context understanding. In particular, we review and categorize a wide range of techniques including architectural modifications, such as modified positional encoding and altered attention mechanisms, which are designed to enhance the processing of longer sequences while avoiding a proportional increase in computational cost. The diverse methodologies investigated in this study can be leveraged across different phases of LLMs, i.e., training, fine-tuning and inference. This enables LLMs to efficiently process extended sequences. The limitations of the current methodologies is discussed in the last section along with the suggestions for future research directions, underscoring the importance of sequence length in the continued advancement of LLMs. Keywords: Natural Language Processing: NLP: Language models Natural Language Processing: General},
  archive   = {C_IJCAI},
  author    = {Xindi Wang and Mahsa Salmani and Parsa Omidi and Xiangyu Ren and Mehdi Rezagholizadeh and Armaghan Eshaghi},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/917},
  month     = {8},
  pages     = {8299-8307},
  title     = {Beyond the limits: A survey of techniques to extend the context length in large language models},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on extractive knowledge graph summarization:
Applications, approaches, evaluation, and future directions.
<em>IJCAI</em>, 8290–8298. (<a
href="https://doi.org/10.24963/ijcai.2024/916">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With the continuous growth of large Knowledge Graphs (KGs), extractive KG summarization becomes a trending task. Aiming at distilling a compact subgraph with condensed information, it facilitates various downstream KG-based tasks. In this survey paper, we are among the first to provide a systematic overview of its applications and define a taxonomy for existing methods from its interdisciplinary studies. Future directions are also laid out based on our extensive and comparative review. Keywords: Data Mining: DM: Knowledge graphs and knowledge base completion Data Mining: DM: Mining graphs Knowledge Representation and Reasoning: KRR: Semantic Web},
  archive   = {C_IJCAI},
  author    = {Xiaxia Wang and Gong Cheng},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/916},
  month     = {8},
  pages     = {8290-8298},
  title     = {A survey on extractive knowledge graph summarization: Applications, approaches, evaluation, and future directions},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on rank aggregation. <em>IJCAI</em>, 8281–8289. (<a
href="https://doi.org/10.24963/ijcai.2024/915">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Rank aggregation (RA), the technique of combining multiple basic rankings into a consensus one, plays an important role in social choices, bioinformatics, information retrieval, metasearch, and recommendation systems. Although recent years have witnessed remarkable progress in RA, the absence of a systematic overview motivates us to conduct a comprehensive survey including both classic algorithms and the latest advances in RA study. Specifically, we first discuss the challenges of RA research, then present a systematic review with a fine-grained taxonomy to introduce representative algorithms in unsupervised RA, supervised RA, as well as the previously overlooked semi-supervised RA. Within each category, we not only summarize the common ideas of similar methods, but also discuss their strengths and weaknesses. Particularly, to investigate the performance difference of different types of RA methods, we conduct the largest scale of comparative evaluation to date of 27 RA methods on 7 public datasets from person re-identification, recommendation systems, bioinformatics and social choices. Finally, we raise two open questions in the current RA research and make our comments about future trends in the context of the latest research progress. Keywords: Data Mining: DM: Information retrieval Search: S: Search and machine learning},
  archive   = {C_IJCAI},
  author    = {Siyi Wang and Qi Deng and Shiwei Feng and Hong Zhang and Chao Liang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/915},
  month     = {8},
  pages     = {8281-8289},
  title     = {A survey on rank aggregation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Recent advances in predictive modeling with electronic
health records. <em>IJCAI</em>, 8272–8280. (<a
href="https://doi.org/10.24963/ijcai.2024/914">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The development of electronic health records (EHR) systems has enabled the collection of a vast amount of digitized patient data. However, utilizing EHR data for predictive modeling presents several challenges due to its unique characteristics. With the advancements in machine learning techniques, deep learning has demonstrated its superiority in various applications, including healthcare. This survey systematically reviews recent advances in deep learning-based predictive models using EHR data. Specifically, we introduce the background of EHR data and provide a mathematical definition of the predictive modeling task. We then categorize and summarize predictive deep models from multiple perspectives. Furthermore, we present benchmarks and toolkits relevant to predictive modeling in healthcare. Finally, we conclude this survey by discussing open challenges and suggesting promising directions for future research. Keywords: Multidisciplinary Topics and Applications: MTA: Health and medicine Data Mining: DM: Applications},
  archive   = {C_IJCAI},
  author    = {Jiaqi Wang and Junyu Luo and Muchao Ye and Xiaochen Wang and Yuan Zhong and Aofei Chang and Guanjie Huang and Ziyi Yin and Cao Xiao and Jimeng Sun and Fenglong Ma},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/914},
  month     = {8},
  pages     = {8272-8280},
  title     = {Recent advances in predictive modeling with electronic health records},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey of constraint formulations in safe reinforcement
learning. <em>IJCAI</em>, 8262–8271. (<a
href="https://doi.org/10.24963/ijcai.2024/913">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Safety is critical when applying reinforcement learning (RL) to real-world problems. As a result, safe RL has emerged as a fundamental and powerful paradigm for optimizing an agent’s policy while incorporating notions of safety. A prevalent safe RL approach is based on a constrained criterion, which seeks to maximize the expected cumulative reward subject to specific safety constraints. Despite recent effort to enhance safety in RL, a systematic understanding of the field remains difficult. This challenge stems from the diversity of constraint representations and little exploration of their interrelations. To bridge this knowledge gap, we present a comprehensive review of representative constraint formulations, along with a curated selection of algorithms designed specifically for each formulation. In addition, we elucidate the theoretical underpinnings that reveal the mathematical mutual relations among common problem formulations. We conclude with a discussion of the current state and future directions of safe reinforcement learning research Keywords: Machine Learning: ML: Reinforcement learning AI Ethics, Trust, Fairness: ETF: Safety and robustness Planning and Scheduling: PS: Markov decisions processes},
  archive   = {C_IJCAI},
  author    = {Akifumi Wachi and Xun Shen and Yanan Sui},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/913},
  month     = {8},
  pages     = {8262-8271},
  title     = {A survey of constraint formulations in safe reinforcement learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Intelligent agents for auction-based federated learning: A
survey. <em>IJCAI</em>, 8253–8261. (<a
href="https://doi.org/10.24963/ijcai.2024/912">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Auction-based federated learning (AFL) is an important emerging category of FL incentive mechanism design, due to its ability to fairly and efficiently motivate high-quality data owners to join data consumers&#39; (i.e., servers&#39;) FL training tasks. To enhance the efficiency in AFL decision support for stakeholders (i.e., data consumers, data owners, and the auctioneer), intelligent agent-based techniques have emerged. However, due to the highly interdisciplinary nature of this field and the lack of a comprehensive survey providing an accessible perspective, it is a challenge for researchers to enter and contribute to this field. This paper bridges this important gap by providing a first-of-its-kind survey on the Intelligent Agents for AFL (IA-AFL) literature. We propose a unique multi-tiered taxonomy that organises existing IA-AFL works according to 1) the stakeholders served, 2) the auction mechanism adopted, and 3) the goals of the agents, to provide readers with a multi-perspective view into this field. In addition, we analyse the limitations of existing approaches, summarise the commonly adopted performance evaluation metrics, and discuss promising future directions leading towards effective and efficient stakeholder-oriented decision support in IA-AFL ecosystems. Keywords: Machine Learning: ML: Federated learning},
  archive   = {C_IJCAI},
  author    = {Xiaoli Tang and Han Yu and Xiaoxiao Li and Sarit Kraus},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/912},
  month     = {8},
  pages     = {8253-8261},
  title     = {Intelligent agents for auction-based federated learning: A survey},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A systematic survey on federated semi-supervised learning.
<em>IJCAI</em>, 8244–8252. (<a
href="https://doi.org/10.24963/ijcai.2024/911">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Federated learning (FL) revolutionizes distributed machine learning by enabling devices to collaboratively learn a model while maintaining data privacy. However, FL usually faces a critical challenge with limited labeled data, making semi-supervised learning (SSL) crucial for utilizing abundant unlabeled data. The integration of SSL within the federated framework gives rise to federated semi-supervised learning (FSSL), a novel approach that exploits unlabeled data across devices without compromising privacy. This paper systematically explores FSSL, shedding light on its four basic problem settings that commonly appear in real-world scenarios. By examining the unique challenges, generic solutions, and representative methods tailored for each setting of FSSL, we aim to provide a cohesive overview of the current state of the art and pave the way for future research directions in this promising field. Keywords: Machine Learning: General Machine Learning: ML: Federated learning Machine Learning: ML: Semi-supervised learning},
  archive   = {C_IJCAI},
  author    = {Zixing Song and Xiangli Yang and Yifei Zhang and Xinyu Fu and Zenglin Xu and Irwin King},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/911},
  month     = {8},
  pages     = {8244-8252},
  title     = {A systematic survey on federated semi-supervised learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Building expressive and tractable probabilistic generative
models: A review. <em>IJCAI</em>, 8234–8243. (<a
href="https://doi.org/10.24963/ijcai.2024/910">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present a comprehensive survey of the advancements and techniques in the field of tractable probabilistic generative modeling, primarily focusing on Probabilistic Circuits (PCs). We provide a unified perspective on the inherent trade-offs between expressivity and tractability, highlighting the design principles and algorithmic extensions that have enabled building expressive and efficient PCs, and provide a taxonomy of the field. We also discuss recent efforts to build deep and hybrid PCs by fusing notions from deep neural models, and outline the challenges and open questions that can guide future research in this evolving field. Keywords: Uncertainty in AI: UAI: Tractable probabilistic models Machine Learning: ML: Generative models},
  archive   = {C_IJCAI},
  author    = {Sahil Sidheekh and Sriraam Natarajan},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/910},
  month     = {8},
  pages     = {8234-8243},
  title     = {Building expressive and tractable probabilistic generative models: A review},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Supervised algorithmic fairness in distribution shifts: A
survey. <em>IJCAI</em>, 8225–8233. (<a
href="https://doi.org/10.24963/ijcai.2024/909">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Supervised fairness-aware machine learning under distribution shifts is an emerging field that addresses the challenge of maintaining equitable and unbiased predictions when faced with changes in data distributions from source to target domains. In real-world applications, machine learning models are often trained on a specific dataset but deployed in environments where the data distribution may shift over time due to various factors. This shift can lead to unfair predictions, disproportionately affecting certain groups characterized by sensitive attributes, such as race and gender. In this survey, we provide a summary of various types of distribution shifts and comprehensively investigate existing methods based on these shifts, highlighting six commonly used approaches in the literature. Additionally, this survey lists publicly available datasets and evaluation metrics for empirical studies. We further explore the interconnection with related research fields, discuss the significant challenges, and identify potential directions for future studies. Keywords: AI Ethics, Trust, Fairness: ETF: Fairness and diversity AI Ethics, Trust, Fairness: ETF: Bias},
  archive   = {C_IJCAI},
  author    = {Minglai Shao and Dong Li and Chen Zhao and Xintao Wu and Yujie Lin and Qin Tian},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/909},
  month     = {8},
  pages     = {8225-8233},
  title     = {Supervised algorithmic fairness in distribution shifts: A survey},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on network alignment: Approaches, applications and
future directions. <em>IJCAI</em>, 8216–8224. (<a
href="https://doi.org/10.24963/ijcai.2024/908">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Network alignment, the task of mapping corresponding nodes across networks, is attracting more attention for cross-network analysis in diverse domains, including social, biological, and co-authorship networks. Although a variety of methods have been proposed, we lack a holistic understanding of the approaches and applications. Our survey aims to bridge this gap by first proposing a taxonomy of network alignment, characterizing existing approaches, and then systematically summarizing and reviewing their performance and highlighting their scopes for future development. Finally, we discuss some important applications and give directions for future research within this domain. Keywords: Data Mining: DM: Applications Data Mining: DM: Mining graphs Data Mining: DM: Networks Knowledge Representation and Reasoning: KRR: Applications Machine Learning: ML: Active learning Machine Learning: ML: Adversarial machine learning Machine Learning: ML: Applications Machine Learning: ML: Representation learning Machine Learning: ML: Sequence and graph learning},
  archive   = {C_IJCAI},
  author    = {Shruti Saxena and Joydeep Chandra},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/908},
  month     = {8},
  pages     = {8216-8224},
  title     = {A survey on network alignment: Approaches, applications and future directions},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning structural causal models through deep generative
models: Methods, guarantees, and challenges. <em>IJCAI</em>, 8207–8215.
(<a href="https://doi.org/10.24963/ijcai.2024/907">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper provides a comprehensive review of deep structural causal models (DSCMs), particularly focusing on their ability to answer counterfactual queries using observational data within known causal structures. It delves into the characteristics of DSCMs by analyzing the hypotheses, guarantees, and applications inherent to the underlying deep learning components and structural causal models, fostering a finer understanding of their capabilities and limitations in addressing different counterfactual queries. Furthermore, it highlights the challenges and open questions in the field of deep structural causal modeling. It sets the stages for researchers to identify future work directions and for practitioners to get an overview in order to find out the most appropriate methods for their needs. Keywords: Machine Learning: ML: Causality Machine Learning: ML: Generative models},
  archive   = {C_IJCAI},
  author    = {Audrey Poinsot and Alessandro Leite and Nicolas Chesneau and Michele Sebag and Marc Schoenauer},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/907},
  month     = {8},
  pages     = {8207-8215},
  title     = {Learning structural causal models through deep generative models: Methods, guarantees, and challenges},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A comprehensive survey of cross-domain policy transfer for
embodied agents. <em>IJCAI</em>, 8197–8206. (<a
href="https://doi.org/10.24963/ijcai.2024/906">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The burgeoning fields of robot learning and embodied AI have triggered an increasing demand for large quantities of data. However, collecting sufficient unbiased data from the target domain remains a challenge due to costly data collection processes and stringent safety requirements. Consequently, researchers often resort to data from easily accessible source domains, such as simulation and laboratory environments, for cost-effective data acquisition and rapid model iteration. Nevertheless, the environments and embodiments of these source domains can be quite different from their target domain counterparts, underscoring the need for effective cross-domain policy transfer approaches. In this paper, we conduct a systematic review of existing cross-domain policy transfer methods. Through a nuanced categorization of domain gaps, we encapsulate the overarching insights and design considerations of each problem setting. We also provide a high-level discussion about the key methodologies used in cross-domain policy transfer problems. Lastly, we summarize the open challenges that lie beyond the capabilities of current paradigms and discuss potential future directions in this field. Keywords: Robotics: General Machine Learning: ML: Multi-task and transfer learning Robotics: ROB: Learning in robotics},
  archive   = {C_IJCAI},
  author    = {Haoyi Niu and Jianming Hu and Guyue Zhou and Xianyuan Zhan},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/906},
  month     = {8},
  pages     = {8197-8206},
  title     = {A comprehensive survey of cross-domain policy transfer for embodied agents},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Knowledge distillation in federated learning: A practical
guide. <em>IJCAI</em>, 8188–8196. (<a
href="https://doi.org/10.24963/ijcai.2024/905">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Federated Learning (FL) enables the training of Deep Learning models without centrally collecting possibly sensitive raw data. The most used algorithms for FL are parameter-averaging based schemes (e.g., Federated Averaging) that, however, have well known limits, i.e., model homogeneity, high communication cost, poor performance in presence of heterogeneous data distributions. Federated adaptations of regular Knowledge Distillation (KD) can solve or mitigate the weaknesses of parameter-averaging FL algorithms while possibly introducing other trade-offs. In this article, we originally present a focused review of the state-of-the-art KD-based algorithms specifically tailored for FL, by providing both a novel classification of the existing approaches and a detailed technical description of their pros, cons, and tradeoffs. Keywords: Machine Learning: ML: Federated learning Machine Learning: ML: Ensemble methods},
  archive   = {C_IJCAI},
  author    = {Alessio Mora and Irene Tenison and Paolo Bellavista and Irina Rish},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/905},
  month     = {8},
  pages     = {8188-8196},
  title     = {Knowledge distillation in federated learning: A practical guide},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). X-former elucidator: Reviving efficient attention for long
context language modeling. <em>IJCAI</em>, 8179–8187. (<a
href="https://doi.org/10.24963/ijcai.2024/904">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Transformer-based LLMs are becoming increasingly important in various AI applications. However, apart from the success of LLMs, the explosive demand of long context handling capabilities is a key and in-time problem for both academia and industry. Due to the limitations from the quadratic complexity of the attention mechanism, long context scenarios require much more resources for LLM development and deployment, bringing huge challenges to the underlying AI infrastructure. Meanwhile, we observe that there is a trend of reviving previous efficient attention mechanisms to latest LLMs. However, it still remains an open question about how to select from these diverse approaches in practice. In this paper, we answer this question from several aspects. First, we revisit these latest long-context LLM innovations and discuss their relationship with prior approaches with a novel and comprehensive taxonomy. Next, we conduct a thorough evaluation over various types of workloads considering both efficiency and effectiveness. Finally, we provide an in-depth analysis, summarize our key findings, and offer insightful suggestions on the trade-offs of designing and deploying efficient attention mechanisms for Transformer-based LLMs. Keywords: Natural Language Processing: General Machine Learning: ML: Attention models Multidisciplinary Topics and Applications: MTA: Computational sustainability Natural Language Processing: NLP: Language models},
  archive   = {C_IJCAI},
  author    = {Xupeng Miao and Shenhan Zhu and Fangcheng Fu and Ziyu Guo and Zhi Yang and Yaofeng Tu and Zhihao Jia and Bin Cui},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/904},
  month     = {8},
  pages     = {8179-8187},
  title     = {X-former elucidator: Reviving efficient attention for long context language modeling},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Graph neural networks for brain graph learning: A survey.
<em>IJCAI</em>, 8170–8178. (<a
href="https://doi.org/10.24963/ijcai.2024/903">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Exploring the complex structure of the human brain is crucial for understanding its functionality and diagnosing brain disorders. Thanks to advancements in neuroimaging technology, a novel approach has emerged that involves modeling the human brain as a graph-structured pattern, with different brain regions represented as nodes and the functional relationships among these regions as edges. Moreover, graph neural networks (GNNs) have demonstrated a significant advantage in mining graph-structured data. Developing GNNs to learn brain graph representations for brain disorder analysis has recently gained increasing attention. However, there is a lack of systematic survey work summarizing current research methods in this domain. In this paper, we aim to bridge this gap by reviewing brain graph learning works that utilize GNNs. We first introduce the process of brain graph modeling based on common neuroimaging data. Subsequently, we systematically categorize current works based on the type of brain graph generated and the targeted research problems. To make this research accessible to a broader range of interested researchers, we provide an overview of representative methods and commonly used datasets, along with their implementation sources. Finally, we present our insights on future research directions. The repository of this survey is available at https://github.com/XuexiongLuoMQ/Awesome-Brain-Graph-Learning-with-GNNs. Keywords: Data Mining: DM: Mining graphs Humans and AI: HAI: Brain sciences},
  archive   = {C_IJCAI},
  author    = {Xuexiong Luo and Jia Wu and Jian Yang and Shan Xue and Amin Beheshti and Quan Z. Sheng and David McAlpine and Paul Sowman and Alexis Giral and Philip S. Yu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/903},
  month     = {8},
  pages     = {8170-8178},
  title     = {Graph neural networks for brain graph learning: A survey},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Label leakage in vertical federated learning: A survey.
<em>IJCAI</em>, 8160–8169. (<a
href="https://doi.org/10.24963/ijcai.2024/902">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Vertical federated learning (VFL) is a distributed machine learning paradigm that collaboratively trains models using passive parties with features and an active party with additional labels. While VFL offers privacy preservation through data localization, the threat of label leakage remains a significant challenge. Label leakage occurs due to label inference attacks, where passive parties attempt to infer labels for their privacy and commercial value. Extensive research has been conducted on this specific VFL attack, but a comprehensive summary is still lacking. To bridge this gap, our paper aims to survey the existing label inference attacks and defenses. We propose two new taxonomies for both label inference attacks and defenses, respectively. Beyond summarizing the current state of research, we highlight techniques that we believe hold potential and could significantly influence future studies. Moreover, experimental benchmark datasets and evaluation metrics are summarized to provide a guideline for subsequent work. Keywords: Machine Learning: ML: Federated learning Multidisciplinary Topics and Applications: MTA: Security and privacy},
  archive   = {C_IJCAI},
  author    = {Yige Liu and Yiwei Lou and Yang Liu and Yongzhi Cao and Hanpin Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/902},
  month     = {8},
  pages     = {8160-8169},
  title     = {Label leakage in vertical federated learning: A survey},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Safety of multimodal large language models on images and
text. <em>IJCAI</em>, 8151–8159. (<a
href="https://doi.org/10.24963/ijcai.2024/901">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Attracted by the impressive power of Multimodal Large Language Models (MLLMs), the public is increasingly utilizing them to improve the efficiency of daily work. Nonetheless, the vulnerabilities of MLLMs to unsafe instructions bring huge safety risks when these models are deployed in real-world scenarios. In this paper, we systematically survey current efforts on the evaluation, attack, and defense of MLLMs&#39; safety on images and text. We begin with introducing the overview of MLLMs on images and text and understanding of safety, which helps researchers know the detailed scope of our survey. Then, we review the evaluation datasets and metrics for measuring the safety of MLLMs. Next, we comprehensively present attack and defense techniques related to MLLMs&#39; safety. Finally, we analyze several unsolved issues and discuss promising research directions. The relevant papers are collected at &quot;https://github.com/isXinLiu/Awesome-MLLM-Safety&quot;. Keywords: AI Ethics, Trust, Fairness: General AI Ethics, Trust, Fairness: ETF: Safety and robustness},
  archive   = {C_IJCAI},
  author    = {Xin Liu and Yichen Zhu and Yunshi Lan and Chao Yang and Yu Qiao},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/901},
  month     = {8},
  pages     = {8151-8159},
  title     = {Safety of multimodal large language models on images and text},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Recent advances in end-to-end simultaneous speech
translation. <em>IJCAI</em>, 8142–8150. (<a
href="https://doi.org/10.24963/ijcai.2024/900">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Simultaneous speech translation (SimulST) is a demanding task that involves generating translations in real-time while continuously processing speech input. This paper offers a comprehensive overview of the recent developments in SimulST research, focusing on four major challenges. Firstly, the complexities associated with processing lengthy and continuous speech streams pose significant hurdles. Secondly, satisfying real-time requirements presents inherent difficulties due to the need for immediate translation output. Thirdly, striking a balance between translation quality and latency constraints remains a critical challenge. Finally, the scarcity of annotated data adds another layer of complexity to the task. Through our exploration of these challenges and the proposed solutions, we aim to provide valuable insights into the current landscape of SimulST research and suggest promising directions for future exploration. Keywords: Natural Language Processing: General Natural Language Processing: NLP: Speech},
  archive   = {C_IJCAI},
  author    = {Xiaoqian Liu and Guoqiang Hu and Yangfan Du and Erfeng He and YingFeng Luo and Chen Xu and Tong Xiao and Jingbo Zhu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/900},
  month     = {8},
  pages     = {8142-8150},
  title     = {Recent advances in end-to-end simultaneous speech translation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Budget feasible mechanisms: A survey. <em>IJCAI</em>,
8132–8141. (<a href="https://doi.org/10.24963/ijcai.2024/899">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In recent decades, the design of budget feasible mechanisms for a wide range of procurement auction settings has received significant attention in the Artificial Intelligence (AI) community. These procurement auction settings have practical applications in various domains such as federated learning, crowdsensing, edge computing, and resource allocation. In a basic procurement auction setting of these domains, a buyer with a limited budget is tasked with procuring items (\eg, goods or services) from strategic sellers, who have private information on the true costs of their items and incentives to misrepresent their items&#39; true costs. The primary goal of budget feasible mechanisms is to elicit the true costs from sellers and determine items to procure from sellers to maximize the buyer valuation function for the items and ensure that the total payment to the sellers is no more than the budget. In this survey, we provide a comprehensive overview of key procurement auction settings and results of budget feasible mechanisms. We provide several promising future research directions. Keywords: Game Theory and Economic Paradigms: GTEP: Auctions and market-based systems Game Theory and Economic Paradigms: GTEP: Mechanism design},
  archive   = {C_IJCAI},
  author    = {Xiang Liu and Hau Chan and Minming Li and Weiwei Wu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/899},
  month     = {8},
  pages     = {8132-8141},
  title     = {Budget feasible mechanisms: A survey},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). A survey of graph meets large language model: Progress and
future directions. <em>IJCAI</em>, 8123–8131. (<a
href="https://doi.org/10.24963/ijcai.2024/898">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph plays a significant role in representing and analyzing complex relationships in real-world applications such as citation networks, social networks, and biological data. Recently, Large Language Models (LLMs), which have achieved tremendous success in various domains, have also been leveraged in graph-related tasks to surpass traditional Graph Neural Networks (GNNs) based methods and yield state-of-the-art performance. In this survey, we first present a comprehensive review and analysis of existing methods that integrate LLMs with graphs. First of all, we propose a new taxonomy, which organizes existing methods into three categories based on the role (i.e., enhancer, predictor, and alignment component) played by LLMs in graph-related tasks. Then we systematically survey the representative methods along the three categories of the taxonomy. Finally, we discuss the remaining limitations of existing studies and highlight promising avenues for future research. The relevant papers are summarized and will be consistently updated at: https://github.com/yhLeeee/Awesome-LLMs-in-Graph-tasks. Keywords: Data Mining: DM: Mining graphs Natural Language Processing: NLP: Applications},
  archive   = {C_IJCAI},
  author    = {Yuhan Li and Zhixun Li and Peisong Wang and Jia Li and Xiangguo Sun and Hong Cheng and Jeffrey Xu Yu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/898},
  month     = {8},
  pages     = {8123-8131},
  title     = {A survey of graph meets large language model: Progress and future directions},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Automated essay scoring: Recent successes and future
directions. <em>IJCAI</em>, 8114–8122. (<a
href="https://doi.org/10.24963/ijcai.2024/897">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Automated essay scoring (AES), the task of automatically assigning a score to an essay that summarizes its quality, is a challenging task that remains largely unsolved despite more than 50 years of research. This survey paper discusses the milestones in AES research and reflects on future directions. Keywords: Natural Language Processing: NLP: Applications},
  archive   = {C_IJCAI},
  author    = {Shengjie Li and Vincent Ng},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/897},
  month     = {8},
  pages     = {8114-8122},
  title     = {Automated essay scoring: Recent successes and future directions},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey of data-efficient graph learning. <em>IJCAI</em>,
8104–8113. (<a href="https://doi.org/10.24963/ijcai.2024/896">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph-structured data, prevalent in domains ranging from social networks to biochemical analysis, serve as the foundation for diverse real-world systems. While graph neural networks demonstrate proficiency in modeling this type of data, their success is often reliant on significant amounts of labeled data, posing a challenge in practical scenarios with limited annotation resources. To tackle this problem, tremendous efforts have been devoted to enhancing graph machine learning performance under low-resource settings by exploring various approaches to minimal supervision. In this paper, we introduce a novel concept of Data-Efficient Graph Learning (DEGL) as a research frontier, and present the first survey that summarizes the current progress of DEGL. We initiate by highlighting the challenges inherent in training models with large labeled data, paving the way for our exploration into DEGL. Next, we systematically review recent advances on this topic from several key aspects, including self-supervised graph learning, semi-supervised graph learning, and few-shot graph learning. Also, we state promising directions for future research, contributing to the evolution of graph machine learning. Keywords: Data Mining: DM: Mining graphs Machine Learning: ML: Few-shot learning Machine Learning: ML: Self-supervised Learning Machine Learning: ML: Semi-supervised learning Machine Learning: ML: Weakly supervised learning},
  archive   = {C_IJCAI},
  author    = {Wei Ju and Siyu Yi and Yifan Wang and Qingqing Long and Junyu Luo and Zhiping Xiao and Ming Zhang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/896},
  month     = {8},
  pages     = {8104-8113},
  title     = {A survey of data-efficient graph learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Empowering time series analysis with large language models:
A survey. <em>IJCAI</em>, 8095–8103. (<a
href="https://doi.org/10.24963/ijcai.2024/895">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, remarkable progress has been made over large language models (LLMs), demonstrating their unprecedented capability in varieties of natural language tasks. However, completely training a large general-purpose model from the scratch is challenging for time series analysis, due to the large volumes and varieties of time series data, as well as the non-stationarity that leads to concept drift impeding continuous model adaptation and re-training. Recent advances have shown that pre-trained LLMs can be exploited to capture complex dependencies in time series data and facilitate various applications. In this survey, we provide a systematic overview of existing methods that leverage LLMs for time series analysis. Specifically, we first state the challenges and motivations of applying language models in the context of time series as well as brief preliminaries of LLMs. Next, we summarize the general pipeline for LLM-based time series analysis, categorize existing methods into different groups (\textit{i.e.}, direct query, tokenization, prompt design, fine-tune, and model integration), and highlight the key ideas within each group. We also discuss the applications of LLMs for both general and spatial-temporal time series data, tailored to specific domains. Finally, we thoroughly discuss future research opportunities to empower time series analysis with LLMs. Keywords: Machine Learning: ML: Time series and data streams Data Mining: DM: Mining spatial and/or temporal data},
  archive   = {C_IJCAI},
  author    = {Yushan Jiang and Zijie Pan and Xikun Zhang and Sahil Garg and Anderson Schneider and Yuriy Nevmyvaka and Dongjin Song},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/895},
  month     = {8},
  pages     = {8095-8103},
  title     = {Empowering time series analysis with large language models: A survey},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust counterfactual explanations in machine learning: A
survey. <em>IJCAI</em>, 8086–8094. (<a
href="https://doi.org/10.24963/ijcai.2024/894">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Counterfactual explanations (CEs) are advocated as being ideally suited to providing algorithmic recourse for subjects affected by the predictions of machine learning models. While CEs can be beneficial to affected individuals, recent work has exposed severe issues related to the robustness of state-of-the-art methods for obtaining CEs. Since a lack of robustness may compromise the validity of CEs, techniques to mitigate this risk are in order. In this survey, we review works in the rapidly growing area of robust CEs and perform an in-depth analysis of the forms of robustness they consider. We also discuss existing solutions and their limitations, providing a solid foundation for future developments. Keywords: AI Ethics, Trust, Fairness: ETF: Explainability and interpretability AI Ethics, Trust, Fairness: ETF: Safety and robustness AI Ethics, Trust, Fairness: ETF: Trustworthy AI Machine Learning: ML: Explainable/Interpretable machine learning Machine Learning: ML: Robustness Machine Learning: ML: Trustworthy machine learning},
  archive   = {C_IJCAI},
  author    = {Junqi Jiang and Francesco Leofante and Antonio Rago and Francesca Toni},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/894},
  month     = {8},
  pages     = {8086-8094},
  title     = {Robust counterfactual explanations in machine learning: A survey},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Strategic aspects of stable matching markets: A survey.
<em>IJCAI</em>, 8077–8085. (<a
href="https://doi.org/10.24963/ijcai.2024/893">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Matching markets consist of two disjoint sets of agents, where each agent has a preference list over agents on the other side. The primary objective is to find a stable matching between the agents such that no unmatched pair of agents prefer each other to their matched partners. The incompatibility between stability and strategy-proofness in this domain gives rise to a variety of strategic behavior of agents, which in turn may influence the resulting matching. In this paper, we discuss fundamental properties of stable matchings, review essential structural observations, survey key results in manipulation algorithms and their game-theoretical aspects, and more importantly, highlight a series of open research questions. Keywords: Game Theory and Economic Paradigms: GTEP: Computational social choice Agent-based and Multi-agent Systems: MAS: Resource allocation Game Theory and Economic Paradigms: GTEP: Auctions and market-based systems Game Theory and Economic Paradigms: GTEP: Other},
  archive   = {C_IJCAI},
  author    = {Hadi Hosseini and Shraddha Pathak},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/893},
  month     = {8},
  pages     = {8077-8085},
  title     = {Strategic aspects of stable matching markets: A survey},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Social learning through interactions with other agents: A
survey. <em>IJCAI</em>, 8067–8076. (<a
href="https://doi.org/10.24963/ijcai.2024/892">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Social learning plays an important role in the development of human intelligence. As children, we imitate our parent&#39;s speech patterns until we are able to produce sounds; we learn from them praising us and scolding us, and as adults, we learn by working with others. In this work, we survey the degree to which this developmental paradigm -- social learning -- has been mirrored in machine learning. In particular, since learning socially requires interacting with others, we are interested in how embodied agents can and have utilised these techniques. This is especially in light of the degree to which recent advances in natural language processing (NLP) enable us to perform new forms of social learning. We look at how behaviour cloning and next-token prediction mirror human imitation, how learning from human feedback mirrors human education, and how we can go further to enable fully communicative agents that learn from each other. We find that while individual social learning techniques have been used successfully, there has been little unifying work showing how to bring them together into socially embodied agents. Keywords: Machine Learning: ML: Other Agent-based and Multi-agent Systems: MAS: Agent theories and models Agent-based and Multi-agent Systems: MAS: Multi-agent learning Humans and AI: HAI: Human-AI collaboration Natural Language Processing: NLP: Dialogue and interactive systems},
  archive   = {C_IJCAI},
  author    = {Dylan Hillier and Cheston Tan and Jing Jiang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/892},
  month     = {8},
  pages     = {8067-8076},
  title     = {Social learning through interactions with other agents: A survey},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A comprehensive survey on graph reduction: Sparsification,
coarsening, and condensation. <em>IJCAI</em>, 8058–8066. (<a
href="https://doi.org/10.24963/ijcai.2024/891">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Many real-world datasets can be naturally represented as graphs, spanning a wide range of domains. However, the increasing complexity and size of graph datasets present significant challenges for analysis and computation. In response, graph reduction techniques have gained prominence for simplifying large graphs while preserving essential properties. In this survey, we aim to provide a comprehensive understanding of graph reduction methods, including graph sparsification, graph coarsening, and graph condensation. Specifically, we establish a unified definition for these methods and introduce a hierarchical taxonomy to categorize the challenges they address. Our survey then systematically reviews the technical details of these methods and emphasizes their practical applications across diverse scenarios. Furthermore, we outline critical research directions to ensure the continued effectiveness of graph reduction techniques. Keywords: Data Mining: DM: Mining graphs Machine Learning: ML: Sequence and graph learning Machine Learning: General},
  archive   = {C_IJCAI},
  author    = {Mohammad Hashemi and Shengbo Gong and Juntong Ni and Wenqi Fan and B. Aditya Prakash and Wei Jin},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/891},
  month     = {8},
  pages     = {8058-8066},
  title     = {A comprehensive survey on graph reduction: Sparsification, coarsening, and condensation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Large language model based multi-agents: A survey of
progress and challenges. <em>IJCAI</em>, 8048–8057. (<a
href="https://doi.org/10.24963/ijcai.2024/890">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Large Language Models (LLMs) have achieved remarkable success across a wide array of tasks. Due to their notable capabilities in planning and reasoning, LLMs have been utilized as autonomous agents for the automatic execution of various tasks. Recently, LLM-based agent systems have rapidly evolved from single-agent planning or decision-making to operating as multi-agent systems, enhancing their ability in complex problem-solving and world simulation. To offer an overview of this dynamic field, we present this survey to offer an in-depth discussion on the essential aspects and challenges of LLM-based multi-agent (LLM-MA) systems. Our objective is to provide readers with an in-depth understanding of these key points: the domains and settings where LLM-MA systems operate or simulate; the profiling and communication methods of these agents; and the means by which these agents develop their skills. For those interested in delving into this field, we also summarize the commonly used datasets or benchmarks. To keep researchers updated on the latest studies, we maintain an open-source GitHub repository (github.com/taichengguo/LLM_MultiAgents_Survey_Papers), dedicated to outlining the research of LLM-MA research. Keywords: Natural Language Processing: NLP: Language models Agent-based and Multi-agent Systems: MAS: Other},
  archive   = {C_IJCAI},
  author    = {Taicheng Guo and Xiuying Chen and Yaqi Wang and Ruidi Chang and Shichao Pei and Nitesh V. Chawla and Olaf Wiest and Xiangliang Zhang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/890},
  month     = {8},
  pages     = {8048-8057},
  title     = {Large language model based multi-agents: A survey of progress and challenges},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on neural question generation: Methods,
applications, and prospects. <em>IJCAI</em>, 8038–8047. (<a
href="https://doi.org/10.24963/ijcai.2024/889">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this survey, we present a detailed examination of the advancements in Neural Question Generation (NQG), a field leveraging neural network techniques to generate relevant questions from diverse inputs like knowledge bases, texts, and images. The survey begins with an overview of NQG&#39;s background, encompassing the task&#39;s problem formulation, prevalent benchmark datasets, established evaluation metrics, and notable applications. It then methodically classifies NQG approaches into three predominant categories: structured NQG, which utilizes organized data sources, unstructured NQG, focusing on more loosely structured inputs like texts or visual content, and hybrid NQG, drawing on diverse input modalities. This classification is followed by an in-depth analysis of the distinct neural network models tailored for each category, discussing their inherent strengths and potential limitations. The survey culminates with a forward-looking perspective on the trajectory of NQG, identifying emergent research trends and prospective developmental paths. Accompanying this survey is a curated collection of related research papers, datasets, and codes, all of which are available on GitHub. This provides an extensive reference for those delving into NQG. Keywords: Natural Language Processing: NLP: Question answering Natural Language Processing: NLP: Language generation},
  archive   = {C_IJCAI},
  author    = {Shasha Guo and Lizi Liao and Cuiping Li and Tat-Seng Chua},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/889},
  month     = {8},
  pages     = {8038-8047},
  title     = {A survey on neural question generation: Methods, applications, and prospects},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Recurrent concept drifts on data streams. <em>IJCAI</em>,
8029–8037. (<a href="https://doi.org/10.24963/ijcai.2024/888">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In an era where machine learning permeates every facet of human existence, and data evolves incessantly, the application of machine learning models transcends mere data processing. It involves navigating constant changes exemplified by the phenomenon of concept drift, which often affects model performance. These drifts can be recurrent due to the cyclic nature of the underlying data generation processes, which could be influenced by recurrent phenomena such as weather and time of the day. Stream Learning on data streams with recurrent concept drifts attempts to learn from such streams of data. The survey underscores the significance of the field and its practical applications, delving into nuanced definitions of machine learning for data streams afflicted by recurrent concept drifts. It explores diverse methodological approaches, elucidating their key design components. Additionally, it examines various evaluation techniques, benchmark datasets, and available software tailored for simulating and analysing data streams with recurrent concept drifts. Concluding, the survey offers insights into potential avenues for future research in the field. Keywords: Machine Learning: ML: Time series and data streams Data Mining: DM: Mining data streams},
  archive   = {C_IJCAI},
  author    = {Nuwan Gunasekara and Bernhard Pfahringer and Heitor Murilo Gomes and Albert Bifet and Yun Sing Koh},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/888},
  month     = {8},
  pages     = {8029-8037},
  title     = {Recurrent concept drifts on data streams},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey of multimodal sarcasm detection. <em>IJCAI</em>,
8020–8028. (<a href="https://doi.org/10.24963/ijcai.2024/887">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Sarcasm is a rhetorical device that is used to convey the opposite of the literal meaning of an utterance. Sarcasm is widely used on social media and other forms of computer-mediated communication motivating the use of computational models to identify it automatically. While the clear majority of approaches to sarcasm detection have been carried out on text only, sarcasm detection often requires additional information present in tonality, facial expression, and contextual images. This has led to the introduction of multimodal models, opening the possibility to detect sarcasm in multiple modalities such as audio, images, text, and video. In this paper, we present the first comprehensive survey on multimodal sarcasm detection - henceforth MSD - to date. We survey papers published between 2018 and 2023 on the topic, and discuss the models and datasets used for this task. We also present future research directions in MSD. Keywords: Machine Learning: ML: Multi-modal learning Machine Learning: General Natural Language Processing: General Natural Language Processing: NLP: Applications Natural Language Processing: NLP: Sentiment analysis, stylistic analysis, and argument mining Natural Language Processing: NLP: Speech Natural Language Processing: NLP: Text classification},
  archive   = {C_IJCAI},
  author    = {Shafkat Farabi and Tharindu Ranasinghe and Diptesh Kanojia and Yu Kong and Marcos Zampieri},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/887},
  month     = {8},
  pages     = {8020-8028},
  title     = {A survey of multimodal sarcasm detection},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Lifted planning: Recent advances in planning using
first-order representations. <em>IJCAI</em>, 8010–8019. (<a
href="https://doi.org/10.24963/ijcai.2024/886">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Lifted planning is usually defined as planning directly over a first-order representation. From the mid-1990s until the late 2010s, lifted planning was sidelined, as most of the state-of-the-art planners first ground the task and then solve it using a propositional representation. Moreover, it was unclear whether lifted planners could scale. But as planning problems become harder, they also become infeasible to ground. Recently, lifted planners came back into play, aiming at problems where grounding is a bottleneck. In this work, we survey recent advances in lifted planning. The main techniques rely either on state-space search or logic satisfiability. For lifted search-based planners, we show the direct connections to other areas of computer science, such as constraint satisfaction problems and databases. For lifted planners based on satisfiability, the advances in modeling are crucial to their scalability. We briefly describe the main planners available in the literature and their techniques. Keywords: Planning and Scheduling: General Knowledge Representation and Reasoning: KRR: Reasoning about actions},
  archive   = {C_IJCAI},
  author    = {Augusto B. Corrêa and Giuseppe De Giacomo},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/886},
  month     = {8},
  pages     = {8010-8019},
  title     = {Lifted planning: Recent advances in planning using first-order representations},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey of robotic language grounding: Tradeoffs between
symbols and embeddings. <em>IJCAI</em>, 7999–8009. (<a
href="https://doi.org/10.24963/ijcai.2024/885">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With large language models, robots can understand language more flexibly and more capable than ever before. This survey reviews and situates recent literature into a spectrum with two poles: 1) mapping between language and some manually defined formal representation of meaning, and 2) mapping between language and high-dimensional vector spaces that translate directly to low-level robot policy. Using a formal representation allows the meaning of the language to be precisely represented, limits the size of the learning problem, and leads to a framework for interpretability and formal safety guarantees. Methods that embed language and perceptual data into high-dimensional spaces avoid this manually specified symbolic structure and thus have the potential to be more general when fed enough data but require more data and computing to train. We discuss the benefits and tradeoffs of each approach and finish by providing directions for future work that achieves the best of both worlds. Keywords: Robotics: ROB: Learning in robotics Natural Language Processing: NLP: Language grounding Machine Learning: ML: Neuro-symbolic methods Machine Learning: ML: Symbolic methods},
  archive   = {C_IJCAI},
  author    = {Vanya Cohen and Jason Xinyu Liu and Raymond Mooney and Stefanie Tellex and David Watkins},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/885},
  month     = {8},
  pages     = {7999-8009},
  title     = {A survey of robotic language grounding: Tradeoffs between symbols and embeddings},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on cross-domain sequential recommendation.
<em>IJCAI</em>, 7989–7998. (<a
href="https://doi.org/10.24963/ijcai.2024/884">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Cross-domain sequential recommendation (CDSR) shifts the modeling of user preferences from flat to stereoscopic by integrating and learning interaction information from multiple domains at different granularities (ranging from inter-sequence to intra-sequence and from single-domain to cross-domain). In this survey, we initially define the CDSR problem using a four-dimensional tensor and then analyze its multi-type input representations under multidirectional dimensionality reductions. Following that, we provide a systematic overview from both macro and micro views. From a macro view, we abstract the multi-level fusion structures of various models across domains and discuss their bridges for fusion. From a micro view, focusing on the existing models, we specifically discuss the basic technologies and then explain the auxiliary learning technologies. Finally, we exhibit the available public datasets and the representative experimental results as well as provide some insights into future directions for research in CDSR. Keywords: Data Mining: DM: Recommender systems},
  archive   = {C_IJCAI},
  author    = {Shu Chen and Zitao Xu and Weike Pan and Qiang Yang and Zhong Ming},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/884},
  month     = {8},
  pages     = {7989-7998},
  title     = {A survey on cross-domain sequential recommendation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Faster and lighter LLMs: A survey on current challenges and
way forward. <em>IJCAI</em>, 7980–7988. (<a
href="https://doi.org/10.24963/ijcai.2024/883">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Despite the impressive performance of LLMs, their widespread adoption faces challenges due to substantial computational and memory requirements during inference. Recent advancements in model compression and system-level optimization methods aim to enhance LLM inference. This survey offers an overview of these methods, emphasizing recent developments. Through experiments on LLaMA(/2)-7B, we evaluate various compression techniques, providing practical insights for efficient LLM deployment in a unified setting. The empirical analysis on LLaMA(/2)-7B highlights the effectiveness of these methods. Drawing from survey insights, we identify current limitations and discuss potential future directions to improve LLM inference efficiency. We release the codebase to reproduce the results presented in this paper at https://github.com/nyunAI/Faster-LLM-Survey Keywords: Natural Language Processing: NLP: Language models Natural Language Processing: NLP: Resources and evaluation},
  archive   = {C_IJCAI},
  author    = {Arnav Chavan and Raghav Magazine and Shubham Kushwaha and Merouane Debbah and Deepak Gupta},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/883},
  month     = {8},
  pages     = {7980-7988},
  title     = {Faster and lighter LLMs: A survey on current challenges and way forward},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Trends, applications, and challenges in human attention
modelling. <em>IJCAI</em>, 7971–7979. (<a
href="https://doi.org/10.24963/ijcai.2024/882">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Human attention modelling has proven, in recent years, to be particularly useful not only for understanding the cognitive processes underlying visual exploration, but also for providing support to artificial intelligence models that aim to solve problems in various domains, including image and video processing, vision-and-language applications, and language modelling. This survey offers a reasoned overview of recent efforts to integrate human attention mechanisms into contemporary deep learning models and discusses future research directions and challenges. For a comprehensive overview of the ongoing research, refer to our dedicated repository available at https://github.com/aimagelab/awesome-human-visual-attention. Keywords: Humans and AI: General Humans and AI: HAI: Applications},
  archive   = {C_IJCAI},
  author    = {Giuseppe Cartella and Marcella Cornia and Vittorio Cuculo and Alessandro D&#39;Amelio and Dario Zanca and Giuseppe Boccignone and Rita Cucchiara},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/882},
  month     = {8},
  pages     = {7971-7979},
  title     = {Trends, applications, and challenges in human attention modelling},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Guide to numerical experiments on elections in computational
social choice. <em>IJCAI</em>, 7962–7970. (<a
href="https://doi.org/10.24963/ijcai.2024/881">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We analyze how numerical experiments regarding elections were conducted within computational social choice literature (focusing on papers published in the IJCAI, AAAI, and AAMAS conferences). We analyze the sizes of the studied elections and the methods of generating preference data, thereby making previously hidden standards and practices explicit. In particular, we survey a number of statistical cultures for generating elections and their commonly used parameters. Keywords: Game Theory and Economic Paradigms: GTEP: Computational social choice},
  archive   = {C_IJCAI},
  author    = {Niclas Boehmer and Piotr Faliszewski and Łukasz Janeczko and Andrzej Kaczmarczyk and Grzegorz Lisowski and Grzegorz Pierczyński and Simon Rey and Dariusz Stolicki and Stanisław Szufa and Tomasz Wąs},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/881},
  month     = {8},
  pages     = {7962-7970},
  title     = {Guide to numerical experiments on elections in computational social choice},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Policy space response oracles: A survey. <em>IJCAI</em>,
7951–7961. (<a href="https://doi.org/10.24963/ijcai.2024/880">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Game theory provides a mathematical way to study the interaction between multiple decision makers. However, classical game-theoretic analysis is limited in scalability due to the large number of strategies, precluding direct application to more complex scenarios. This survey provides a comprehensive overview of a framework for large games, known as Policy Space Response Oracles (PSRO), which holds promise to improve scalability by focusing attention on sufficient subsets of strategies. We first motivate PSRO and provide historical context. We then focus on the strategy exploration problem for PSRO: the challenge of assembling effective subsets of strategies that still represent the original game well with minimum computational cost. We survey current research directions for enhancing the efficiency of PSRO, and explore the applications of PSRO across various domains. We conclude by discussing open questions and future research. Keywords: Agent-based and Multi-agent Systems: General Game Theory and Economic Paradigms: General Game Theory and Economic Paradigms: GTEP: Noncooperative games},
  archive   = {C_IJCAI},
  author    = {Ariyan Bighashdel and Yongzhao Wang and Stephen McAleer and Rahul Savani and Frans A. Oliehoek},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/880},
  month     = {8},
  pages     = {7951-7961},
  title     = {Policy space response oracles: A survey},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on plan optimization. <em>IJCAI</em>, 7941–7950.
(<a href="https://doi.org/10.24963/ijcai.2024/879">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Automated Planning deals with finding a sequence of actions that solves a given (planning) problem. The cost of the solution is a direct consequence of these actions, for example its number or their accumulated costs. Thus, in most applications, cheaper plans are preferred. Yet, finding an optimal solution is more challenging than finding some solution. So, many planning algorithms find some solution and then post-process, i.e., optimize it -- a technique called plan optimization. Over the years many different approaches were developed, not all for the same kind of plans, and not all optimize the same metric. In this comprehensive survey, we give an overview of the existing plan optimization goals, their computational complexity (if known), and existing techniques for such optimizations. Keywords: Planning and Scheduling: General Planning and Scheduling: PS: Hierarchical planning Planning and Scheduling: PS: Other Planning and Scheduling: PS: Theoretical foundations of planning},
  archive   = {C_IJCAI},
  author    = {Pascal Bercher and Patrik Haslum and Christian Muise},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/879},
  month     = {8},
  pages     = {7941-7950},
  title     = {A survey on plan optimization},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Medical neural architecture search: Survey and taxonomy.
<em>IJCAI</em>, 7932–7940. (<a
href="https://doi.org/10.24963/ijcai.2024/878">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper presents a comprehensive survey of Medical Neural Architecture Search (MedNAS), a burgeoning field at the confluence of deep learning and medical imaging. With the increasing prevalence of FDA-approved medical deep learning models, MedNAS emerges as a key area in leveraging computational innovations for healthcare advancements. Our survey examines the paradigm shift introduced by Neural Architecture Search (NAS), which automates neural network design, replacing traditional, manual designs. We explore the unique search spaces tailored for medical tasks on different types of data from images to EEG, the methodologies of MedNAS, and their impact on medical applications. Keywords: Machine Learning: ML: Automated machine learning Multidisciplinary Topics and Applications: MTA: Health and medicine},
  archive   = {C_IJCAI},
  author    = {Hadjer Benmeziane and Imane Hamzaoui and Zayneb Cherif and Kaoutar El Maghraoui},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/878},
  month     = {8},
  pages     = {7932-7940},
  title     = {Medical neural architecture search: Survey and taxonomy},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on model-free goal recognition. <em>IJCAI</em>,
7923–7931. (<a href="https://doi.org/10.24963/ijcai.2024/877">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Goal Recognition is the task of inferring an agent&#39;s intentions from a set of observations. Existing recognition approaches have made considerable advances in domains such as human-robot interaction, intelligent tutoring systems, and surveillance. However, most approaches rely on explicit domain knowledge, often defined by a domain expert. Much recent research focus on mitigating the need for a domain expert while maintaining the ability to perform quality recognition, leading researchers to explore Model-Free Goal Recognition approaches. We comprehensively survey Model-Free Goal Recognition, and provide a perspective on the state-of-the-art approaches and their applications, showing recent advances. We categorize different approaches, introducing a taxonomy with a focus on their characteristics, strengths, weaknesses, and suitability for different scenarios. We compare the advances each approach made to the state-of-the-art and provide a direction for future research in Model-Free Goal Recognition. Keywords: Planning and Scheduling: PS: Activity and plan recognition},
  archive   = {C_IJCAI},
  author    = {Leonardo Amado and Sveta Paster Shainkopf and Ramon Fraga Pereira and Reuth Mirsky and Felipe Meneguzzi},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/877},
  month     = {8},
  pages     = {7923-7931},
  title     = {A survey on model-free goal recognition},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reassessing evaluation functions in algorithmic recourse: An
empirical study from a human-centered perspective. <em>IJCAI</em>,
7913–7921. (<a href="https://doi.org/10.24963/ijcai.2024/876">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this study, we critically examine the foundational premise of algorithmic recourse - a process of generating counterfactual action plans (i.e., recourses) assisting individuals to reverse adverse decisions made by AI systems. The assumption underlying algorithmic recourse is that individuals accept and act on recourses that minimize the gap between their current and desired states. This assumption, however, remains empirically unverified. To address this issue, we conducted a user study with 362 participants and assessed whether minimizing the distance function, a metric of the gap between the current and desired states, indeed prompts them to accept and act upon suggested recourses. Our findings reveal a nuanced landscape: participants&#39; acceptance of recourses did not correlate with the recourse distance. Moreover, participants&#39; willingness to act upon recourses peaked at the minimal recourse distance but was otherwise constant. These findings cast doubt on the prevailing assumption of algorithmic recourse research and signal the need to rethink the evaluation functions to pave the way for human-centered recourse generation. Keywords: Humans and AI: HAI: Intelligent user interfaces Humans and AI: HAI: Human-computer interaction Humans and AI: HAI: Applications AI Ethics, Trust, Fairness: ETF: Explainability and interpretability},
  archive   = {C_IJCAI},
  author    = {Tomu Tominaga and Naomi Yamashita and Takeshi Kurashima},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/876},
  month     = {8},
  pages     = {7913-7921},
  title     = {Reassessing evaluation functions in algorithmic recourse: An empirical study from a human-centered perspective},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ADESSE: Advice explanations in complex repeated
decision-making environments. <em>IJCAI</em>, 7904–7912. (<a
href="https://doi.org/10.24963/ijcai.2024/875">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the evolving landscape of human-centered AI, fostering a synergistic relationship between humans and AI agents in decision-making processes stands as a paramount challenge. This work considers a problem setup where an intelligent agent comprising a neural network-based prediction component and a deep reinforcement learning component provides advice to a human decision-maker in complex repeated decision-making environments. Whether the human decision-maker would follow the agent&#39;s advice depends on their beliefs and trust in the agent and on their understanding of the advice itself. To this end, we developed an approach named ADESSE to generate explanations about the adviser agent to improve human trust and decision-making. Computational experiments on a range of environments with varying model sizes demonstrate the applicability and scalability of ADESSE. Furthermore, an interactive game-based user study shows that participants were significantly more satisfied, achieved a higher reward in the game, and took less time to select an action when presented with explanations generated by ADESSE. These findings illuminate the critical role of tailored, human-centered explanations in AI-assisted decision-making. Keywords: Machine Learning: ML: Explainable/Interpretable machine learning Humans and AI: HAI: Human-AI collaboration AI Ethics, Trust, Fairness: ETF: Explainability and interpretability Machine Learning: ML: Reinforcement learning},
  archive   = {C_IJCAI},
  author    = {Sören Schleibaum and Lu Feng and Sarit Kraus and Jörg P. Müller},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/875},
  month     = {8},
  pages     = {7904-7912},
  title     = {ADESSE: Advice explanations in complex repeated decision-making environments},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Emergence of social norms in generative agent societies:
Principles and architecture. <em>IJCAI</em>, 7895–7903. (<a
href="https://doi.org/10.24963/ijcai.2024/874">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Social norms play a crucial role in guiding agents towards understanding and adhering to standards of behavior, thus reducing social conflicts within multi-agent systems (MASs). However, current LLM-based (or generative) MASs lack the capability to be normative. In this paper, we propose a novel architecture, named CRSEC, to empower the emergence of social norms within generative MASs. Our architecture consists of four modules: Creation &amp; Representation, Spreading, Evaluation, and Compliance. This addresses several important aspects of the emergent processes all in one: (i) where social norms come from, (ii) how they are formally represented, (iii) how they spread through agents&#39; communications and observations, (iv) how they are examined with a sanity check and synthesized in the long term, and (v) how they are incorporated into agents&#39; planning and actions. Our experiments deployed in the Smallville sandbox game environment demonstrate the capability of our architecture to establish social norms and reduce social conflicts within generative MASs. The positive outcomes of our human evaluation, conducted with 30 evaluators, further affirm the effectiveness of our approach. Our project can be accessed via the following link: https://github.com/sxswz213/CRSEC. Keywords: Agent-based and Multi-agent Systems: MAS: Normative systems Agent-based and Multi-agent Systems: MAS: Agent-based simulation and emergence Agent-based and Multi-agent Systems: MAS: Agent societies Machine Learning: ML: Applications},
  archive   = {C_IJCAI},
  author    = {Siyue Ren and Zhiyao Cui and Ruiqi Song and Zhen Wang and Shuyue Hu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/874},
  month     = {8},
  pages     = {7895-7903},
  title     = {Emergence of social norms in generative agent societies: Principles and architecture},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). From skepticism to acceptance: Simulating the attitude
dynamics toward fake news. <em>IJCAI</em>, 7886–7894. (<a
href="https://doi.org/10.24963/ijcai.2024/873">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the digital era, the rapid propagation of fake news and rumors via social networks brings notable societal challenges and impacts public opinion regulation. Traditional fake news modeling typically forecasts the general popularity trends of different groups or numerically represents opinions shift. However, these methods often oversimplify real-world complexities and overlook the rich semantic information of news text. The advent of large language models (LLMs) provides the possibility of modeling subtle dynamics of opinion. Consequently, in this work, we introduce a Fake news Propagation Simulation framework (FPS) based on LLM, which studies the trends and control of fake news propagation in detail. Specifically, each agent in the simulation represents an individual with a distinct personality. They are equipped with both short-term and long-term memory, as well as a reflective mechanism to mimic human-like thinking. Every day, they engage in random opinion exchanges, reflect on their thinking, and update their opinions. Our simulation results uncover patterns in fake news propagation related to topic relevance, and individual traits, aligning with real-world observations. Additionally, we evaluate various intervention strategies and demonstrate that early and appropriately frequent interventions strike a balance between governance cost and effectiveness, offering valuable insights for practical applications. Our study underscores the significant utility and potential of LLMs in combating fake news. Keywords: Multidisciplinary Topics and Applications: MTA: News and media Natural Language Processing: NLP: Applications Humans and AI: HAI: Applications Multidisciplinary Topics and Applications: MTA: Social sciences},
  archive   = {C_IJCAI},
  author    = {Yuhan Liu and Xiuying Chen and Xiaoqing Zhang and Xing Gao and Ji Zhang and Rui Yan},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/873},
  month     = {8},
  pages     = {7886-7894},
  title     = {From skepticism to acceptance: Simulating the attitude dynamics toward fake news},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). XAI-lyricist: Improving the singability of AI-generated
lyrics with prosody explanations. <em>IJCAI</em>, 7877–7885. (<a
href="https://doi.org/10.24963/ijcai.2024/872">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Explaining the singability of lyrics is an important but missing ability of language models (LMs) in song lyrics generation. This ability allows songwriters to quickly assess if LM-generated lyrics can be sung harmoniously with melodies and helps singers align lyrics with melodies during practice. This paper presents XAI-Lyricist, leveraging musical prosody to guide LMs in generating singable lyrics and providing human-understandable singability explanations. We employ a Transformer model to generate lyrics under musical prosody constraints and provide demonstrations of the lyrics&#39; prosody patterns as singability explanations. XAI-Lyricist is evaluated by computational metrics (perplexity, prosody-BLEU) and a human-grounded study (human ratings, average time and number of attempts for singing). Experimental results show that musical prosody can significantly improve the singability of LM-generated lyrics. A controlled study with 14 singers also confirms the usefulness of the provided explanations in helping them to interpret lyrical singability faster than reading plain text lyrics. Keywords: Multidisciplinary Topics and Applications: MTA: Arts and creativity Humans and AI: HAI: Human-AI collaboration AI Ethics, Trust, Fairness: ETF: Explainability and interpretability},
  archive   = {C_IJCAI},
  author    = {Qihao Liang and Xichu Ma and Finale Doshi-Velez and Brian Lim and Ye Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/872},
  month     = {8},
  pages     = {7877-7885},
  title     = {XAI-lyricist: Improving the singability of AI-generated lyrics with prosody explanations},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The role of perception, acceptance, and cognition in the
usefulness of robot explanations. <em>IJCAI</em>, 7868–7876. (<a
href="https://doi.org/10.24963/ijcai.2024/871">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {It is known that when interacting with explainable autonomous systems, user characteristics are important in determining the most appropriate explanation, but understanding which user characteristics are most relevant to consider is not simple. This paper explores such characteristics and analyses how they affect the perceived usefulness of four types of explanations based on the robot&#39;s mental states. These types are belief, goal, hybrid (goal and belief) and baseline explanations. In this study, the explanations were evaluated in the context of a domestic service robot. The user characteristics considered are the perception of the robot&#39;s rationality and autonomy, the acceptance of the robot and the user&#39;s cognitive tendencies. We found differences in perceived usefulness between explanation types based on user characteristics, with hybrid explanations being the most useful. Keywords: Humans and AI: HAI: Human-AI collaboration Robotics: ROB: Human robot interaction Humans and AI: General AI Ethics, Trust, Fairness: ETF: Explainability and interpretability},
  archive   = {C_IJCAI},
  author    = {Hana Kopecka and Jose Such and Michael Luck},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/871},
  month     = {8},
  pages     = {7868-7876},
  title     = {The role of perception, acceptance, and cognition in the usefulness of robot explanations},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A goal-directed dialogue system for assistance in
safety-critical application. <em>IJCAI</em>, 7859–7867. (<a
href="https://doi.org/10.24963/ijcai.2024/870">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In safety-critical applications where a human is in the loop, providing timely contextual assistance can reduce the severity of emergencies. While the context can typically be inferred passively, engaging the human in an active conversation with the assistance system makes this context richer and more sound. For this, we explore a FOND-planning-powered goal-directed dialogue system with Natural Language Understanding (NLU) capabilities. We use an Ultralight (UL) aviation domain as an example application for test and validation by inferring the current context in situations requiring emergency landings using the goal-directed dialogue system. The inferred context is then used for real-time modelling of the problem instance, necessary for generating strategic plans to guide the human out of the emergency situations. To overcome data scarcity, we augment the data collected from human pilots using generative text models to train the NLU capabilities of the dialogue agent. We benchmark against generative chatbots and demonstrate that our goal-directed dialogue system significantly outperforms them in context inference. Keywords: Humans and AI: HAI: Human-AI collaboration Planning and Scheduling: PS: Applications Natural Language Processing: NLP: Applications Multidisciplinary Topics and Applications: MTA: Other},
  archive   = {C_IJCAI},
  author    = {Prakash Jamakatel and Rebecca De Venezia and Christian Muise and Jane Jean Kiam},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/870},
  month     = {8},
  pages     = {7859-7867},
  title     = {A goal-directed dialogue system for assistance in safety-critical application},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards proactive interactions for in-vehicle conversational
assistants utilizing large language models. <em>IJCAI</em>, 7850–7858.
(<a href="https://doi.org/10.24963/ijcai.2024/869">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Research demonstrates that the proactivity of in-vehicle conversational assistants (IVCAs) can help to reduce distractions and enhance driving safety, better meeting users&#39; cognitive needs. However, existing IVCAs struggle with user intent recognition and context awareness, which leads to suboptimal proactive interactions. Large language models (LLMs) have shown potential for generalizing to various tasks with prompts, but their application in IVCAs and exploration of proactive interaction remain under-explored. These raise questions about how LLMs improve proactive interactions for IVCAs and influence user perception. To investigate these questions systematically, we establish a framework with five proactivity levels across two dimensions—assumption and autonomy—for IVCAs. According to the framework, we propose a ``Rewrite + ReAct + Reflect&#39;&#39; strategy, aiming to empower LLMs to fulfill the specific demands of each proactivity level when interacting with users. Both feasibility and subjective experiments are conducted. The LLM outperforms the state-of-the-art model in success rate and achieves satisfactory results for each proactivity level. Subjective experiments with 40 participants validate the effectiveness of our framework and show the proactive level with strong assumptions and user confirmation is most appropriate. Keywords: Humans and AI: HAI: Human-computer interaction Humans and AI: HAI: Applications Humans and AI: General},
  archive   = {C_IJCAI},
  author    = {Huifang Du and Xuejing Feng and Jun Ma and Meng Wang and Shiyu Tao and Yijie Zhong and Yuan-Fang Li and Haofen Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/869},
  month     = {8},
  pages     = {7850-7858},
  title     = {Towards proactive interactions for in-vehicle conversational assistants utilizing large language models},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Data ownership and privacy in personalized AI models in
assistive healthcare. <em>IJCAI</em>, 7842–7849. (<a
href="https://doi.org/10.24963/ijcai.2024/868">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The use of personalized artificial intelligence (AI) models in assistive healthcare presents a number of ethical and legal challenges, they are examined in this paper. We look at a number of situations in which AI models have close interactions with persons under care. In particular we are interested in the question of model and data ownership, privacy, and ethical implications. The paper also surveys the existing regulatory environment, including the US Congress&#39;s legislative initiatives and the US Federal Trade Commission&#39;s examination of AI. Additionally, it covers AI strategies such as modular AI and discusses possible solutions to the issues described. We present an overview of the current outstanding problems and with this work offer a researched and organized contribution for a public discussion of responsible application of AI in this field of healthcare. Our selection of topics is guided by keeping in mind the key stakeholders: technology providers, healthcare or care providers, care beneficiaries and their families. Keywords: Humans and AI: General AI Ethics, Trust, Fairness: ETF: AI and law, governance, regulation Multidisciplinary Topics and Applications: MTA: Health and medicine Machine Learning: General},
  archive   = {C_IJCAI},
  author    = {Boris Debic and Luka Medvidovic},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/868},
  month     = {8},
  pages     = {7842-7849},
  title     = {Data ownership and privacy in personalized AI models in assistive healthcare},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Human-agent cooperation in games under incomplete
information through natural language communication. <em>IJCAI</em>,
7833–7841. (<a href="https://doi.org/10.24963/ijcai.2024/867">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Developing autonomous agents that can strategize and cooperate with humans under information asymmetry is challenging without effective communication in natural language. We introduce a shared-control game, where two players collectively control a token in alternating turns to achieve a common objective under incomplete information. We formulate a policy synthesis problem for an autonomous agent in this game with a human as the other player. To solve this problem, we propose a communication-based approach comprising a language module and a planning module. The language module translates natural language messages into and from a finite set of flags, a compact representation defined to capture player intents. The planning module leverages these flags to compute a policy using an asymmetric information-set Monte Carlo tree search with flag exchange algorithm we present. We evaluate the effectiveness of this approach in a testbed based on Gnomes at Night, a search-and-find maze board game. Results of human subject experiments show that communication narrows the information gap between players and enhances human-agent cooperation efficiency with fewer turns. Keywords: Humans and AI: HAI: Human-AI collaboration Planning and Scheduling: PS: Planning with Incomplete Information Uncertainty in AI: UAI: Sequential decision making Natural Language Processing: NLP: Dialogue and interactive systems},
  archive   = {C_IJCAI},
  author    = {Shenghui Chen and Daniel Fried and Ufuk Topcu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/867},
  month     = {8},
  pages     = {7833-7841},
  title     = {Human-agent cooperation in games under incomplete information through natural language communication},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Are they the same picture? Adapting concept bottleneck
models for human-AI collaboration in image retrieval. <em>IJCAI</em>,
7824–7832. (<a href="https://doi.org/10.24963/ijcai.2024/866">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Image retrieval plays a pivotal role in applications from wildlife conservation to healthcare, for finding individual animals or relevant images to aid diagnosis. Although deep learning techniques for image retrieval have advanced significantly, their imperfect real-world performance often necessitates including human expertise. Human-in-the-loop approaches typically rely on humans completing the task independently and then combining their opinions with an AI model in various ways, as these models offer very little interpretability or correctability. To allow humans to intervene in the AI model instead, thereby saving human time and effort, we adapt the Concept Bottleneck Model (CBM) and propose CHAIR. CHAIR (a) enables humans to correct intermediate concepts, which helps \textit{improve} embeddings generated, and (b) allows for flexible levels of intervention that accommodate varying levels of human expertise for better retrieval. To show the efficacy of \methodname, we demonstrate that our method performs better than similar models on image retrieval metrics without any external intervention. Furthermore, we also showcase how human intervention helps further improve retrieval performance, thereby achieving human-AI complementarity. Keywords: Humans and AI: HAI: Human-AI collaboration Computer Vision: CV: Image and video retrieval},
  archive   = {C_IJCAI},
  author    = {Vaibhav Balloli and Sara Beery and Elizabeth Bondi-Kelly},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/866},
  month     = {8},
  pages     = {7824-7832},
  title     = {Are they the same picture? adapting concept bottleneck models for human-AI collaboration in image retrieval},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Towards highly realistic artistic style transfer via stable
diffusion with step-aware and layer-aware prompt. <em>IJCAI</em>,
7814–7822. (<a href="https://doi.org/10.24963/ijcai.2024/865">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Artistic style transfer aims to transfer the learned artistic style onto an arbitrary content image, generating artistic stylized images. Existing generative adversarial network-based methods fail to generate highly realistic stylized images and always introduce obvious artifacts and disharmonious patterns. Recently, large-scale pre-trained diffusion models opened up a new way for generating highly realistic artistic stylized images. However, diffusion model-based methods generally fail to preserve the content structure of input content images well, introducing some undesired content structure and style patterns. To address the above problems, we propose a novel pre-trained diffusion-based artistic style transfer method, called LSAST, which can generate highly realistic artistic stylized images while preserving the content structure of input content images well, without bringing obvious artifacts and disharmonious style patterns. Specifically, we introduce a Step-aware and Layer-aware Prompt Space, a set of learnable prompts, which can learn the style information from the collection of artworks and dynamically adjusts the input images&#39; content structure and style pattern. To train our prompt space, we propose a novel inversion method, called Step-ware and Layer-aware Prompt Inversion, which allows the prompt space to learn the style information of the artworks collection. In addition, we inject a pre-trained conditional branch of ControlNet into our LSAST, which further improved our framework&#39;s ability to maintain content structure. Extensive experiments demonstrate that our proposed method can generate more highly realistic artistic stylized images than the state-of-the-art artistic style transfer methods. Code is available at https://github.com/Jamie-Cheung/LSAST. Keywords: Theory and philosophy of arts and creativity in AI systems: Autonomous creative or artistic AI Application domains: Images, movies and visual arts Methods and resources: AI methods for better understanding human creative processes Methods and resources: Machine learning, deep learning, neural models, reinforcement learning},
  archive   = {C_IJCAI},
  author    = {Zhanjie Zhang and Quanwei Zhang and Huaizhong Lin and Wei Xing and Juncheng Mo and Shuaicheng Huang and Jinheng Xie and Guangyuan Li and Junsheng Luan and Lei Zhao and Dalong Zhang and Lixia Chen},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/865},
  month     = {8},
  pages     = {7814-7822},
  title     = {Towards highly realistic artistic style transfer via stable diffusion with step-aware and layer-aware prompt},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MusicMagus: Zero-shot text-to-music editing via diffusion
models. <em>IJCAI</em>, 7805–7813. (<a
href="https://doi.org/10.24963/ijcai.2024/864">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent advances in text-to-music generation models have opened new avenues in musical creativity. However, the task of editing these generated music remains a significant challenge. This paper introduces a novel approach to edit music generated by such models, enabling the modification of specific attributes, such as genre, mood, and instrument, while maintaining other aspects unchanged. Our method transforms text editing to the latent space manipulation, and adds an additional constraint to enforce consistency. It seamlessly integrates with existing pretrained text-to-music diffusion models without requiring additional training. Experimental results demonstrate superior performance over both zero-shot and certain supervised baselines in style and timbre transfer evaluations. We also show the practical applicability of our approach in real-world music editing scenarios. Keywords: Application domains: Music and sound Methods and resources: Machine learning, deep learning, neural models, reinforcement learning},
  archive   = {C_IJCAI},
  author    = {Yixiao Zhang and Yukara Ikemiya and Gus Xia and Naoki Murata and Marco A. Martínez-Ramírez and Wei-Hsiang Liao and Yuki Mitsufuji and Simon Dixon},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/864},
  month     = {8},
  pages     = {7805-7813},
  title     = {MusicMagus: Zero-shot text-to-music editing via diffusion models},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). DP-font: Chinese calligraphy font generation using
diffusion model and physical information neural network. <em>IJCAI</em>,
7796–7804. (<a href="https://doi.org/10.24963/ijcai.2024/863">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As a typical visual art form, Chinese calligraphy has a long history and aesthetic value. However, current methods for generating Chinese fonts still struggle with complex character shapes and lack personalized writing styles. To address these issues, we propose a font generation method for Chinese Calligraphy based on diffusion model incorporating physical information neural network (PINN), which is named DP-Font. Firstly, the multi-attribute guidance is combined to guide the generation process of the diffusion model and introduce the critical constraint of stroke order in Chinese characters, aiming to significantly improve the quality of the generated results. We then incorporate physical constraints into the neural network loss function, utilizing physical equations to provide in-depth guidance and constraints on the learning process. By learning the movement rule of the nib and the diffusion pattern of the ink, DP-Font can generate personalized calligraphy styles. The generated fonts are very close to the calligraphers&#39; works. Compared with existing deep learning-based techniques, DP-Font has made significant progress in enhancing the physical plausibility of the model, generating more realistic and high-quality results. Keywords: Application domains: Images, movies and visual arts Application domains: Text, literature and creative language},
  archive   = {C_IJCAI},
  author    = {Liguo Zhang and Yalong Zhu and Achref Benarab and Yusen Ma and Yuxin Dong and Jianguo Sun},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/863},
  month     = {8},
  pages     = {7796-7804},
  title     = {DP-font: Chinese calligraphy font generation using diffusion model and physical information neural network},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). End-to-end real-world polyphonic piano audio-to-score
transcription with hierarchical decoding. <em>IJCAI</em>, 7788–7795. (<a
href="https://doi.org/10.24963/ijcai.2024/862">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Piano audio-to-score transcription (A2S) is an important yet underexplored task with extensive applications for music composition, practice, and analysis. However, existing end-to-end piano A2S systems faced difficulties in retrieving bar-level information such as key and time signatures, and have been trained and evaluated with only synthetic data. To address these limitations, we propose a sequence-to-sequence (Seq2Seq) model with a hierarchical decoder that aligns with the hierarchical structure of musical scores, enabling the transcription of score information at both the bar and note levels by multi-task learning. To bridge the gap between synthetic data and recordings of human performance, we propose a two-stage training scheme, which involves pre-training the model using an expressive performance rendering (EPR) system on synthetic audio, followed by fine-tuning the model using recordings of human performance. To preserve the voicing structure for score reconstruction, we propose a pre-processing method for **Kern scores in scenarios with an unconstrained number of voices. Experimental results support the effectiveness of our proposed approaches, in terms of both transcription performance on synthetic audio data in comparison to the current state-of-the-art, and the first experiment on human recordings. Keywords: Application domains: Music and sound Methods and resources: Machine learning, deep learning, neural models, reinforcement learning},
  archive   = {C_IJCAI},
  author    = {Wei Zeng and Xian He and Ye Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/862},
  month     = {8},
  pages     = {7788-7795},
  title     = {End-to-end real-world polyphonic piano audio-to-score transcription with hierarchical decoding},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GladCoder: Stylized QR code generation with grayscale-aware
denoising process. <em>IJCAI</em>, 7780–7787. (<a
href="https://doi.org/10.24963/ijcai.2024/861">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Traditional QR codes consist of a grid of black-and-white square modules, which lack aesthetic appeal and meaning for human perception. This has motivated recent research to beautify the visual appearance of QR codes. However, there exists a trade-off between the visual quality and scanning-robustness of the image, causing outputs of previous works are simple and of low quality to ensure scanning-robustness. In this paper, we introduce a novel approach GladCoder to generate stylized QR codes that are personalized, natural, and text-driven. Its pipeline includes a Depth-guided Aesthetic QR code Generator (DAG) to improve quality of image foreground, and a GrayscaLe-Aware Denoising (GLAD) process to enhance scanning-robustness. The overall pipeline is based on diffusion models, which allow users to create stylized QR images from a textual prompt to describe the image and a textual input to be encoded. Experiments demonstrate that our method can generate stylized QR code with appealing perception details, while maintaining robust scanning reliability under real world applications. Keywords: Application domains: Images, movies and visual arts},
  archive   = {C_IJCAI},
  author    = {Yuqiu Xie and Bolin Jiang and Jiawei Li and Naiqi Li and Bin Chen and Tao Dai and Yuang Peng and Shu-Tao Xia},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/861},
  month     = {8},
  pages     = {7780-7787},
  title     = {GladCoder: Stylized QR code generation with grayscale-aware denoising process},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). MuChin: A chinese colloquial description benchmark for
evaluating language models in the field of music. <em>IJCAI</em>,
7771–7779. (<a href="https://doi.org/10.24963/ijcai.2024/860">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The rapidly evolving multimodal Large Language Models (LLMs) urgently require new benchmarks to uniformly evaluate their performance on understanding and textually describing music. However, due to semantic gaps between Music Information Retrieval (MIR) algorithms and human understanding, discrepancies between professionals and the public, and low precision of annotations, existing music description datasets cannot serve as benchmarks. To this end, we present MuChin, the first open-source music description benchmark in Chinese colloquial language, designed to evaluate the performance of multimodal LLMs in understanding and describing music. We established the Caichong Music Annotation Platform (CaiMAP) that employs an innovative multi-person, multi-stage assurance method, and recruited both amateurs and professionals to ensure the precision of annotations and alignment with popular semantics. Utilizing this method, we built a large-scale, private dataset with multi-dimensional, high-precision music annotations, the Caichong Music Dataset (CaiMD), and carefully selected 1,000 high-quality entries to serve as the test set for MuChin. Based on MuChin, we analyzed the discrepancies between professionals and amateurs in terms of music description, and empirically demonstrated the effectiveness of CaiMD for fine-tuning LLMs. Ultimately, we employed MuChin to evaluate existing music understanding models on their ability to provide colloquial descriptions of music. Keywords: Application domains: Music and sound Methods and resources: AI methods for better understanding human creative processes Methods and resources: AI systems for collaboration and co-creation Methods and resources: Computational implementations inspired by fields such as psychology or cognitive science Methods and resources: Datasets, knowledge bases and ontologies Theory and philosophy of arts and creativity in AI systems: Autonomous creative or artistic AI Theory and philosophy of arts and creativity in AI systems: Cultural and social impacts of AI on creativity, creative practice, education and society Theory and philosophy of arts and creativity in AI systems: Ethical issues raised by creative AI systems Theory and philosophy of arts and creativity in AI systems: Evaluation and curation of artistic or creative artefacts Theory and philosophy of arts and creativity in AI systems: Other theory or philosophy of arts and creativity in AI Theory and philosophy of arts and creativity in AI systems: Social (multi-agent) creativity and human-computer co-creation},
  archive   = {C_IJCAI},
  author    = {Zihao Wang and Shuyu Li and Tao Zhang and Qi Wang and Pengfei Yu and Jinyang Luo and Yan Liu and Ming Xi and Kejun Zhang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/860},
  month     = {8},
  pages     = {7771-7779},
  title     = {MuChin: A chinese colloquial description benchmark for evaluating language models in the field of music},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retrieval guided music captioning via multimodal prefixes.
<em>IJCAI</em>, 7762–7770. (<a
href="https://doi.org/10.24963/ijcai.2024/859">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper we put forward a new approach to music captioning, the task of automatically generating natural language descriptions for songs. These descriptions are useful both for categorization and analysis, and also from an accessibility standpoint as they form an important component of closed captions for video content. Our method supplements an audio encoding with a retriever, allowing the decoder to condition on multimodal signal both from the audio of the song itself as well as a candidate caption identified by a nearest neighbor system. This lets us retain the advantages of a retrieval based approach while also allowing for the flexibility of a generative one. We evaluate this system on a dataset of 200k music-caption pairs scraped from Audiostock, a royalty-free music platform, and on MusicCaps, a dataset of 5.5k pairs. We demonstrate significant improvements over prior systems across both automatic metrics and human evaluation. Keywords: Application domains: Music and sound Methods and resources: Machine learning, deep learning, neural models, reinforcement learning},
  archive   = {C_IJCAI},
  author    = {Nikita Srivatsan and Ke Chen and Shlomo Dubnov and Taylor Berg-Kirkpatrick},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/859},
  month     = {8},
  pages     = {7762-7770},
  title     = {Retrieval guided music captioning via multimodal prefixes},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Expressing musical ideas with constraint programming using a
model of tonal harmony. <em>IJCAI</em>, 7753–7761. (<a
href="https://doi.org/10.24963/ijcai.2024/858">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The realm of music composition with artificial intelligence stands as a pertinent and evolving field, attracting increasing interest and exploration in contemporary research and practice. This paper presents a constraint-programming based approach to generating four-voice diatonic chord progressions according to established rules of tonal harmony. It uses the strength of constraint programming as a formal logic to rigorously model musical rules and to offer complete control over the set of rules that are enforced. This allows composers to iteratively interact with the model, adding and removing constraints, allowing them to shape the solutions according to their preferences. We define a constraint model of basic tonal harmony, called Diatony. We show that our implementation using the Gecode solver finds optimal solutions in reasonable time and we show how it can be used by a composer to aid in their composition process. Keywords: Theory and philosophy of arts and creativity in AI systems: Computational paradigms, architectures and models for creativity Application domains: Problem Solving Methods and resources: Techniques for modeling and simulation of creativity Application domains: Science, math and programming},
  archive   = {C_IJCAI},
  author    = {Damien Sprockeels and Peter Van Roy},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/858},
  month     = {8},
  pages     = {7753-7761},
  title     = {Expressing musical ideas with constraint programming using a model of tonal harmony},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A conflict-embedded narrative generation using commonsense
reasoning. <em>IJCAI</em>, 7744–7752. (<a
href="https://doi.org/10.24963/ijcai.2024/857">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Conflict is a critical element in the narrative, inciting dramatic tension. This paper introduces CNGCI (Conflict-driven Narrative Generation through Commonsense Inference), a neuro-symbolic framework designed to generate coherent stories embedded with conflict using commonsense inference. Our framework defines narrative conflict by leveraging the concept of a soft causal threat, where conflict serves as an obstacle that reduces the likelihood of achieving the protagonist&#39;s goal by weakening the causal link between context and goal through defeasible inference. Comparative studies against multiple story generation baselines utilizing commonsense reasoning show that our framework outperforms the baselines in creating narratives that distinctly embody conflict while maintaining coherency. Keywords: Application domains: Text, literature and creative language Theory and philosophy of arts and creativity in AI systems: Autonomous creative or artistic AI Theory and philosophy of arts and creativity in AI systems: Computational paradigms, architectures and models for creativity},
  archive   = {C_IJCAI},
  author    = {Youngrok Song and Gunhee Cho and HyunJu Kim and Youngjune Kim and Byung-Chull Bae and Yun-Gyung Cheong},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/857},
  month     = {8},
  pages     = {7744-7752},
  title     = {A conflict-embedded narrative generation using commonsense reasoning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Disrupting diffusion-based inpainters with semantic
digression. <em>IJCAI</em>, 7735–7743. (<a
href="https://doi.org/10.24963/ijcai.2024/856">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The fabrication of visual misinformation on the web and social media has increased exponentially with the advent of foundational text-to-image diffusion models. Namely, Stable Diffusion inpainters allow the synthesis of maliciously inpainted images of personal and private figures, and copyrighted contents, also known as deepfakes. To combat such generations, a disruption framework, namely Photoguard, has been proposed, where it adds adversarial noise to the context image to disrupt their inpainting synthesis. While their framework suggested a diffusion-friendly approach, the disruption is not sufficiently strong and it requires a significant amount of GPU and time to immunize the context image. In our work, we re-examine both the minimal and favorable conditions for a successful inpainting disruption, proposing DDD, a “Digression guided Diffusion Disruption” framework. First, we identify the most adversarially vulnerable diffusion timestep range with respect to the hidden space. Within this scope of noised manifold, we pose the problem as a semantic digression optimization. We maximize the distance between the inpainting instance&#39;s hidden states and a semantic-aware hidden state centroid, calibrated both by Monte Carlo sampling of hidden states and a discretely projected optimization in the token space. Effectively, our approach achieves stronger disruption and a higher success rate than Photoguard while lowering the GPU memory requirement, and speeding the optimization up to three times faster. Keywords: Theory and philosophy of arts and creativity in AI systems: Ethical issues raised by creative AI systems Application domains: Other domains of art or creativity Methods and resources: Machine learning, deep learning, neural models, reinforcement learning Theory and philosophy of arts and creativity in AI systems: Cultural and social impacts of AI on creativity, creative practice, education and society},
  archive   = {C_IJCAI},
  author    = {Geonho Son and Juhun Lee and Simon S. Woo},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/856},
  month     = {8},
  pages     = {7735-7743},
  title     = {Disrupting diffusion-based inpainters with semantic digression},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Musical phrase segmentation via grammatical induction.
<em>IJCAI</em>, 7726–7734. (<a
href="https://doi.org/10.24963/ijcai.2024/855">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We outline a solution to the challenge of musical phrase segmentation that uses grammatical induction algorithms, a class of algorithms which infer a context-free grammar from an input sequence. We analyze the performance of five grammatical induction algorithms on three datasets using various musical viewpoint combinations. Our experiments show that the LONGESTFIRST algorithm achieves the best F1 scores across all three datasets and that input encodings that include the duration viewpoint result in the best performance. Keywords: Application domains: Music and sound Methods and resources: AI systems for ideation Methods and resources: Datasets, knowledge bases and ontologies Methods and resources: Other methods or resources Theory and philosophy of arts and creativity in AI systems: Autonomous creative or artistic AI},
  archive   = {C_IJCAI},
  author    = {Reed Perkins and Dan Ventura},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/855},
  month     = {8},
  pages     = {7726-7734},
  title     = {Musical phrase segmentation via grammatical induction},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). From pixels to metal: AI-empowered numismatic art.
<em>IJCAI</em>, 7717–7725. (<a
href="https://doi.org/10.24963/ijcai.2024/854">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper describes our response to a unique challenge presented by the Portuguese National Press-Mint: to use Artificial Intelligence to design a commemorative coin that celebrates the &quot;digital world&quot;. We explain the process of this coin&#39;s co-creation, from conceptualisation to production, highlighting the design process, the underlying rationale, key obstacles encountered, and the technical innovations and developments made to meet the challenge. These include the development of an evolutionary art system guided by Contrastive Language–Image Pre-training (CLIP) and Machine Learning-based aesthetic models, a system for prompt evolution, and a representation for encoding genotypes in mintable format. This collaboration produced a limited edition 10 euro silver proof coin, with a total of 4000 units minted by the National Press-Mint. The coin was met with enthusiasm, selling out within two months. This work contributes to Computational Creativity, particularly co-creativity, co-design, and digital art, and represents a significant step in using Artificial Intelligence for Numismatics. Keywords: Application domains: Images, movies and visual arts Theory and philosophy of arts and creativity in AI systems: Autonomous creative or artistic AI Methods and resources: Evolutionary algorithms},
  archive   = {C_IJCAI},
  author    = {Penousal Machado and Tiago Martins and João Correia and Luís Espírito Santo and Nuno Lourenço and João Cunha and Sérgio Rebelo and Pedro Martins and João Bicker},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/854},
  month     = {8},
  pages     = {7717-7725},
  title     = {From pixels to metal: AI-empowered numismatic art},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Re-creation of creations: A new paradigm for lyric-to-melody
generation. <em>IJCAI</em>, 7708–7716. (<a
href="https://doi.org/10.24963/ijcai.2024/853">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Current lyric-to-melody generation methods struggle with the lack of paired lyric-melody data to train, and the lack of adherence to composition guidelines, resulting in melodies that do not sound human-composed. To address these issues, we propose a novel paradigm called Re-creation of Creations (ROC) that combines the strengths of both rule-based and neural-based methods. ROC consists of a two-stage generation-retrieval pipeline: the creation and re-creation stages. In the creation stage, we train a melody language model using melody data to generate high-quality music fragments, which are stored in a database indexed by key features. In the re-creation stage, users provide lyrics and a preferred chord progression, and ROC infers melody features for each lyric sentence. By querying the database, we obtain relevant melody fragments that satisfy composition guidelines, and these candidates are filtered, re-ranked, and concatenated based on the guidelines and the melody language model scores. ROC offers two main advantages: it does not require paired lyric-melody data, and it incorporates commonly used composition guidelines, resulting in music that sounds more human-composed with better controllability. Both objective and subjective evaluation results on English and Chinese lyrics show the effectiveness of ROC. Keywords: Application domains: Music and sound Theory and philosophy of arts and creativity in AI systems: Autonomous creative or artistic AI},
  archive   = {C_IJCAI},
  author    = {Ang Lv and Xu Tan and Tao Qin and Tie-Yan Liu and Rui Yan},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/853},
  month     = {8},
  pages     = {7708-7716},
  title     = {Re-creation of creations: A new paradigm for lyric-to-melody generation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Inferring iterated function systems approximately from
fractal images. <em>IJCAI</em>, 7699–7707. (<a
href="https://doi.org/10.24963/ijcai.2024/852">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As an important mathematical concept, fractals commonly appear in nature and inspire the design of many artistic works. Although we can generate various fractal images easily based on different iterated function systems (IFSs), inferring an IFS from a given fractal image is still a challenging inverse problem for both scientific research and artistic design. In this study, we explore the potential of deep learning techniques for this problem, learning a multi-head auto-encoding model to infer typical IFSs (including Julia set and L-system) from fractal images. In principle, the proposed model encodes fractal images in a latent space and decodes their corresponding IFSs based on the latent representations. For the fractal images generated by heterogeneous IFSs, we let them share the same encoder and apply two decoders to infer the sequential and non-sequential parameters of their IFSs, respectively. By introducing one more decoder to reconstruct fractal images, we can leverage large-scale unlabeled fractal images to learn the model in a semi-supervised way, which suppresses the risk of over-fitting. Comprehensive experiments demonstrate that our method provides a promising solution to infer IFSs approximately from fractal images. Code and supplementary file are available at \url{https://github.com/HaotianLiu123/Inferring-IFSs-From-Fractal-Images}. Keywords: Methods and resources: Techniques for modeling and simulation of creativity Application domains: Images, movies and visual arts Application domains: Problem Solving Application domains: Science, math and programming},
  archive   = {C_IJCAI},
  author    = {Haotian Liu and Dixin Luo and Hongteng Xu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/852},
  month     = {8},
  pages     = {7699-7707},
  title     = {Inferring iterated function systems approximately from fractal images},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Arrange, inpaint, and refine: Steerable long-term music
audio generation and editing via content-based controls. <em>IJCAI</em>,
7690–7698. (<a href="https://doi.org/10.24963/ijcai.2024/851">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Controllable music generation plays a vital role in human-AI music co-creation. While Large Language Models (LLMs) have shown promise in generating high-quality music, their focus on autoregressive generation limits their utility in music editing tasks. To bridge this gap, To address this gap, we propose a novel approach leveraging a parameter-efficient heterogeneous adapter combined with a masking training scheme. This approach enables autoregressive language models to seamlessly address music inpainting tasks. Additionally, our method integrates frame-level content-based controls, facilitating track-conditioned music refinement and score-conditioned music arrangement. We apply this method to fine-tune MusicGen, a leading autoregressive music generation model. Our experiments demonstrate promising results across multiple music editing tasks, offering more flexible controls for future AI-driven music editing tools. The source codes and a demo page showcasing our work are available at https://kikyo-16.github.io/AIR. Keywords: Application domains: Music and sound Methods and resources: Machine learning, deep learning, neural models, reinforcement learning},
  archive   = {C_IJCAI},
  author    = {Liwei Lin and Gus Xia and Yixiao Zhang and Junyan Jiang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/851},
  month     = {8},
  pages     = {7690-7698},
  title     = {Arrange, inpaint, and refine: Steerable long-term music audio generation and editing via content-based controls},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Perception-inspired graph convolution for music
understanding tasks. <em>IJCAI</em>, 7681–7689. (<a
href="https://doi.org/10.24963/ijcai.2024/850">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose a new graph convolutional block, called MusGConv, specifically designed for the efficient processing of musical score data and motivated by general perceptual principles. It focuses on two fundamental dimensions of music, pitch and rhythm, and considers both relative and absolute representations of these components. We evaluate our approach on four different musical understanding problems: monophonic voice separation, harmonic analysis, cadence detection, and composer identification which, in abstract terms, translate to different graph learning problems, namely, node classification, link prediction, and graph classification. Our experiments demonstrate that MusGConv improves the performance on three of the aforementioned tasks while being conceptually very simple and efficient. We interpret this as evidence that it is beneficial to include perception-informed processing of fundamental musical concepts when developing graph network applications on musical score data. All code and models are released on https://github.com/manoskary/musgconv. Keywords: Application domains: Music and sound Methods and resources: Computational implementations inspired by fields such as psychology or cognitive science Methods and resources: Machine learning, deep learning, neural models, reinforcement learning},
  archive   = {C_IJCAI},
  author    = {Emmanouil Karystinaios and Francesco Foscarin and Gerhard Widmer},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/850},
  month     = {8},
  pages     = {7681-7689},
  title     = {Perception-inspired graph convolution for music understanding tasks},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Paintings and drawings aesthetics assessment with rich
attributes for various artistic categories. <em>IJCAI</em>, 7672–7680.
(<a href="https://doi.org/10.24963/ijcai.2024/849">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Image aesthetic evaluation is a highly prominent research domain in the field of computer vision. In recent years, there has been a proliferation of datasets and corresponding evaluation methodologies for assessing the aesthetic quality of photographic works, leading to the establishment of a relatively mature research environment. However, in contrast to the extensive research in photographic aesthetics, the field of aesthetic evaluation for paintings and drawings has seen limited attention until the introduction of the BAID dataset in March 2023. This dataset solely comprises overall scores for high-quality artistic images. Our research marks the pioneering introduction of a multi-attribute, multi-category dataset specifically tailored to the field of painting: Aesthetics of Paintings and Drawings Dataset (APDD). The construction of APDD received active participation from 28 professional artists worldwide, along with dozens of students specializing in the field of art. This dataset encompasses 24 distinct artistic categories and 10 different aesthetic attributes. Each image in APDD has been evaluated by six professionally trained experts in the field of art, including assessments for both total aesthetic scores and aesthetic attribute scores. The final APDD dataset comprises a total of 4985 images, with an annotation count exceeding 31100 entries. Concurrently, we propose an innovative approach: Art Assessment Network for Specific Painting Styles (AANSPS), designed for the assessment of aesthetic attributes in mixed-attribute art datasets. Through this research, our goal is to catalyze advancements in the field of aesthetic evaluation for paintings and drawings, while enriching the available resources and methodologies for its further development and application. Dataset is available at https://github.com/BestiVictory/APDD.git Keywords: Methods and resources: Datasets, knowledge bases and ontologies Application domains: Images, movies and visual arts Methods and resources: Machine learning, deep learning, neural models, reinforcement learning Theory and philosophy of arts and creativity in AI systems: Evaluation and curation of artistic or creative artefacts},
  archive   = {C_IJCAI},
  author    = {Xin Jin and Qianqian Qiao and Yi Lu and Huaye Wang and Shan Gao and Heng Huang and Guangdong Li},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/849},
  month     = {8},
  pages     = {7672-7680},
  title     = {Paintings and drawings aesthetics assessment with rich attributes for various artistic categories},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). KALE: An artwork image captioning system augmented with
heterogeneous graph. <em>IJCAI</em>, 7663–7671. (<a
href="https://doi.org/10.24963/ijcai.2024/848">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Exploring the narratives conveyed by fine-art paintings is a challenge in image captioning, where the goal is to generate descriptions that not only precisely represent the visual content but also offer a in-depth interpretation of the artwork&#39;s meaning. The task is particularly complex for artwork images due to their diverse interpretations and varied aesthetic principles across different artistic schools and styles. In response to this, we present KALE (Knowledge-Augmented vision-Language model for artwork Elaborations), a novel approach that enhances existing vision-language models by integrating artwork metadata as additional knowledge. KALE incorporates the metadata in two ways: firstly as direct textual input, and secondly through a multimodal heterogeneous knowledge graph. To optimize the learning of graph representations, we introduce a new cross-modal alignment loss that maximizes the similarity between the image and its corresponding metadata. Experimental results demonstrate that KALE achieves strong performance (when evaluated with CIDEr, in particular) over existing state-of-the-art work across several artwork datasets. Source code of the project is available at https://github.com/Yanbei-Jiang/Artwork-Interpretation. Keywords: Application domains: Images, movies and visual arts Theory and philosophy of arts and creativity in AI systems: Autonomous creative or artistic AI Application domains: Text, literature and creative language Methods and resources: Machine learning, deep learning, neural models, reinforcement learning},
  archive   = {C_IJCAI},
  author    = {Yanbei Jiang and Krista A. Ehinger and Jey Han Lau},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/848},
  month     = {8},
  pages     = {7663-7671},
  title     = {KALE: An artwork image captioning system augmented with heterogeneous graph},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GEM: Generating engaging multimodal content. <em>IJCAI</em>,
7654–7662. (<a href="https://doi.org/10.24963/ijcai.2024/847">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Generating engaging multimodal content is a key objective in numerous applications, such as the creation of online advertisements that captivate user attention through a synergy of images and text. In this paper, we introduce GEM, a novel framework engineered for the generation of engaging multimodal image-text posts. The GEM framework operates in two primary phases. Initially, GEM integrates a pre-trained engagement discriminator with a technique for deriving an effective continuous prompt tailored for the stable diffusion model. Subsequently, GEM unveils an iterative algorithm dedicated to producing coherent and compelling image-sentence pairs centered around a specified topic of interest. Through a combination of experimental analysis and human evaluations, we establish that the image-sentence pairs generated by GEM not only surpass several established baselines in terms of engagement but also in achieving superior alignment. Keywords: Application domains: Images, movies and visual arts Application domains: Text, literature and creative language Methods and resources: Machine learning, deep learning, neural models, reinforcement learning Theory and philosophy of arts and creativity in AI systems: Autonomous creative or artistic AI},
  archive   = {C_IJCAI},
  author    = {Chongyang Gao and Yiren Jian and Natalia Denisenko and Soroush Vosoughi and V. S. Subrahmanian},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/847},
  month     = {8},
  pages     = {7654-7662},
  title     = {GEM: Generating engaging multimodal content},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Diffutoon: High-resolution editable toon shading via
diffusion models. <em>IJCAI</em>, 7645–7653. (<a
href="https://doi.org/10.24963/ijcai.2024/846">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Toon shading is a type of non-photorealistic rendering task in animation. Its primary purpose is to render objects with a flat and stylized appearance. As diffusion models have ascended to the forefront of image synthesis, this paper delves into an innovative form of toon shading based on diffusion models, aiming to directly render photorealistic videos into anime styles. In video stylization, existing methods encounter persistent challenges, notably in maintaining consistency and achieving high visual quality. In this paper, we model the toon shading problem as four subproblems, i.e., stylization, consistency enhancement, structure guidance, and colorization. To address the challenges in video stylization, we propose an effective toon shading approach called Diffutoon. Diffutoon is capable of rendering remarkably detailed, high-resolution, and extended-duration videos in anime style. It can also edit the video content according to input prompts via an additional branch. The efficacy of Diffutoon is evaluated through quantitive metrics and human evaluation. Notably, Diffutoon surpasses both open-source and closed-source baseline approaches in our experiments. Our work is accompanied by the release of both the source code and example videos on Github. Keywords: Application domains: Computer Graphics and Animation Theory and philosophy of arts and creativity in AI systems: Autonomous creative or artistic AI},
  archive   = {C_IJCAI},
  author    = {Zhongjie Duan and Chengyu Wang and Cen Chen and Weining Qian and Jun Huang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/846},
  month     = {8},
  pages     = {7645-7653},
  title     = {Diffutoon: High-resolution editable toon shading via diffusion models},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Manipulating embeddings of stable diffusion prompts.
<em>IJCAI</em>, 7636–7644. (<a
href="https://doi.org/10.24963/ijcai.2024/845">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Prompt engineering is still the primary way for users of generative text-to-image models to manipulate generated images in a targeted way. Based on treating the model as a continuous function and by passing gradients between the image space and the prompt embedding space, we propose and analyze a new method to directly manipulate the embedding of a prompt instead of the prompt text. We then derive three practical interaction tools to support users with image generation: (1) Optimization of a metric defined in the image space that measures, for example, the image style. (2) Supporting a user in creative tasks by allowing them to navigate in the image space along a selection of directions of &quot;near&quot; prompt embeddings. (3) Changing the embedding of the prompt to include information that a user has seen in a particular seed but has difficulty describing in the prompt. Compared to prompt engineering, user-driven prompt embedding manipulation enables a more fine-grained, targeted control that integrates a user&#39;s intentions. Our user study shows that our methods are considered less tedious and that the resulting images are often preferred. Keywords: Methods and resources: Machine learning, deep learning, neural models, reinforcement learning Application domains: Images, movies and visual arts},
  archive   = {C_IJCAI},
  author    = {Niklas Deckers and Julia Peters and Martin Potthast},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/845},
  month     = {8},
  pages     = {7636-7644},
  title     = {Manipulating embeddings of stable diffusion prompts},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Large language models for human-AI co-creation of robotic
dance performances. <em>IJCAI</em>, 7627–7635. (<a
href="https://doi.org/10.24963/ijcai.2024/844">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper focuses on the potential of Generative Artificial Intelligence (AI), particularly Large Language Models (LLMs), in the still unexplored domain of robotic dance creation. In particular, we assess whether a LLM (GPT-3.5 turbo) can create robotic dance choreographies, and we investigate if the feedback provided by human creators can improve the quality of the output. To this end, we design three prompt engineering techniques for robotic dance creation. In the prompts, we gradually introduce human knowledge through examples and feedback in natural language in order to explore the dynamics of human-AI co-creation. The experimental analysis shows that the capabilities of the LLM can be improved through human collaboration, by producing choreographies with a major artistic impact on the evaluation audience. The findings offer valuable insights into the interplay between human creativity and AI generative models, paving the way for enhanced collaborative frameworks in creative domains. Keywords: Application domains: Performances, dance Methods and resources: AI systems for collaboration and co-creation},
  archive   = {C_IJCAI},
  author    = {Allegra De Filippo and Michela Milano},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/844},
  month     = {8},
  pages     = {7627-7635},
  title     = {Large language models for human-AI co-creation of robotic dance performances},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FastSAG: Towards fast non-autoregressive singing
accompaniment generation. <em>IJCAI</em>, 7618–7626. (<a
href="https://doi.org/10.24963/ijcai.2024/843">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Singing Accompaniment Generation (SAG), which generates instrumental music to accompany input vocals, is crucial to developing human-AI symbiotic art creation systems. The state-of-the-art method, SingSong, utilizes a multi-stage autoregressive (AR) model for SAG, however, this method is extremely slow as it generates semantic and acoustic tokens recursively, and this makes it impossible for real-time applications. In this paper, we aim to develop a Fast SAG method that can create high-quality and coherent accompaniments. A non-AR diffusion-based framework is developed, which by carefully designing the conditions inferred from the vocal signals, generates the Mel spectrogram of the target accompaniment directly. With diffusion and Mel spectrogram modeling, the proposed method significantly simplifies the AR token-based SingSong framework, and largely accelerates the generation. We also design semantic projection, prior projection blocks as well as a set of loss functions, to ensure the generated accompaniment has semantic and rhythm coherence with the vocal signal. By intensive experimental studies, we demonstrate that the proposed method can generate better samples than SingSong, and accelerate the generation by at least 30 times. Audio samples and code are available at this link. Keywords: Application domains: Music and sound Methods and resources: AI systems for collaboration and co-creation},
  archive   = {C_IJCAI},
  author    = {Jianyi Chen and Wei Xue and Xu Tan and Zhen Ye and Qifeng Liu and Yike Guo},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/843},
  month     = {8},
  pages     = {7618-7626},
  title     = {FastSAG: Towards fast non-autoregressive singing accompaniment generation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Re: Draw - context aware translation as a controllable
method for artistic production. <em>IJCAI</em>, 7609–7617. (<a
href="https://doi.org/10.24963/ijcai.2024/842">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We introduce context-aware translation, a novel method that combines the benefits of inpainting and image-to-image translation, respecting simultaneously the original input and contextual relevance -- where existing methods fall short. By doing so, our method opens new avenues for the controllable use of AI within artistic creation, from animation to digital art. As an use case, we apply our method to redraw any hand-drawn animated character eyes based on any design specifications -- eyes serve as a focal point that captures viewer attention and conveys a range of emotions; however, the labor-intensive nature of traditional animation often leads to compromises in the complexity and consistency of eye design. Furthermore, we remove the need for production data for training and introduce a new character recognition method that surpasses existing work by not requiring fine-tuning to specific productions. This proposed use case could help maintain consistency throughout production and unlock bolder and more detailed design choices without the production cost drawbacks. A user study shows context-aware translation is preferred over existing work 95.16% of the time. Keywords: Application domains: Images, movies and visual arts Application domains: Computer Graphics and Animation Methods and resources: AI systems for collaboration and co-creation Methods and resources: Machine learning, deep learning, neural models, reinforcement learning Theory and philosophy of arts and creativity in AI systems: Social (multi-agent) creativity and human-computer co-creation},
  archive   = {C_IJCAI},
  author    = {João Libório Cardoso and Francesco Banterle and Paolo Cignoni and Michael Wimmer},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/842},
  month     = {8},
  pages     = {7609-7617},
  title     = {Re: Draw - context aware translation as a controllable method for artistic production},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Intertwining CP and NLP: The generation of unreasonably
constrained sentences. <em>IJCAI</em>, 7600–7608. (<a
href="https://doi.org/10.24963/ijcai.2024/841">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Constrained text generation remains a challenging task, particularly when dealing with hard constraints. Traditional Natural Language Processing (NLP) approaches prioritize generating meaningful and coherent output. Also, the current state-of-the-art methods often lack the expressiveness and constraint satisfaction capabilities to handle such tasks effectively. This paper presents the Constraints First Framework to remedy this issue. This framework considers a constrained text generation problem as a discrete combinatorial optimization problem. It is solved by a constraint programming method that combines linguistic properties (e.g., n-grams or language level) with other more classical constraints (e.g., the number of characters, syllables, or words). Eventually, a curation phase allows for selecting the best-generated sentences according to perplexity using a large language model. The effectiveness of this approach is demonstrated by tackling a new more tediously constrained text generation problem: the iconic RADNER sentences problem. This problem aims to generate sentences respecting a set of quite strict rules defined by their use in vision and clinical research. Thanks to our CP-based approach, many new strongly constrained sentences have been successfully generated in an automatic manner. This highlights the potential of our approach to handle unreasonably constrained text generation scenarios. Keywords: Application domains: Problem Solving Application domains: Text, literature and creative language Methods and resources: Techniques for combining fast inference and problem solving},
  archive   = {C_IJCAI},
  author    = {Alexandre Bonlarron and Jean-Charles Régin},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/841},
  month     = {8},
  pages     = {7600-7608},
  title     = {Intertwining CP and NLP: The generation of unreasonably constrained sentences},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Integrating view conditions for image synthesis.
<em>IJCAI</em>, 7591–7599. (<a
href="https://doi.org/10.24963/ijcai.2024/840">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the field of image processing, applying intricate semantic modifications within existing images remains an enduring challenge. This paper introduces a pioneering framework that integrates viewpoint information to enhance the control of image editing tasks, especially for interior design scenes. By surveying existing object editing methodologies, we distill three essential criteria --- consistency, controllability, and harmony --- that should be met for an image editing method. In contrast to previous approaches, our framework takes the lead in satisfying all three requirements for addressing the challenge of image synthesis. Through comprehensive experiments, encompassing both quantitative assessments and qualitative comparisons with contemporary state-of-the-art methods, we present compelling evidence of our framework&#39;s superior performance across multiple dimensions. This work establishes a promising avenue for advancing image synthesis techniques and empowering precise object modifications while preserving the visual coherence of the entire composition. Keywords: Application domains: Images, movies and visual arts},
  archive   = {C_IJCAI},
  author    = {Jinbin Bai and Zhen Dong and Aosong Feng and Xiao Zhang and Tian Ye and Kaicheng Zhou},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/840},
  month     = {8},
  pages     = {7591-7599},
  title     = {Integrating view conditions for image synthesis},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Effective high-order graph representation learning for
credit card fraud detection. <em>IJCAI</em>, 7581–7589. (<a
href="https://doi.org/10.24963/ijcai.2024/839">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Credit card fraud imposes significant costs on both cardholders and issuing banks. Fraudsters often disguise their crimes, such as using legitimate transactions through several benign users to bypass anti-fraud detection. Existing graph neural network (GNN) models struggle with learning features of camouflaged, indirect multi-hop transactions due to their inherent over-smoothing issues in deep multi-layer aggregation, presenting a major challenge in detecting disguised relationships. Therefore, in this paper, we propose a novel High-order Graph Representation Learning model (HOGRL) to avoid incorporating excessive noise during the multi-layer aggregation process. In particular, HOGRL learns different orders of \emph{pure} representations directly from high-order transaction graphs. We realize this goal by effectively constructing high-order transaction graphs first and then learning the \emph{pure} representations of each order so that the model could identify fraudsters&#39; multi-hop indirect transactions via multi-layer \emph{pure} feature learning. In addition, we introduce a mixture-of-expert attention mechanism to automatically determine the importance of different orders for jointly optimizing fraud detection performance. We conduct extensive experiments in both the open source and real-world datasets, the result demonstrates the significant improvements of our proposed HOGRL compared with state-of-the-art fraud detection baselines. HOGRL&#39;s superior performance also proves its effectiveness in addressing high-order fraud camouflage criminals. Keywords: Multidisciplinary Topics and Applications: General Data Mining: General},
  archive   = {C_IJCAI},
  author    = {Yao Zou and Dawei Cheng},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/839},
  month     = {8},
  pages     = {7581-7589},
  title     = {Effective high-order graph representation learning for credit card fraud detection},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Safeguarding sustainable cities: Unsupervised video anomaly
detection through diffusion-based latent pattern learning.
<em>IJCAI</em>, 7572–7580. (<a
href="https://doi.org/10.24963/ijcai.2024/838">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Sustainable cities requires high-quality community management and surveillance analytics, which are supported by video anomaly detection techniques. However, mainstream video anomaly detection techniques still require manually labeled data and do not apply to real-world massive videos. Without labeling, unsupervised video anomaly detection (UVAD) is challenged by the problem of pseudo-labeled noise and the openness of anomaly detection. In response, a diffusion-based latent pattern learning UVAD framework is proposed, called DiffVAD. The method learns potential patterns by generating different patterns of the same event through diffusion models. The detection of anomalies is realized by evaluating the pattern distribution. The different patterns of normal events are diverse but correlated, while the different patterns of abnormal events are more diffuse. This manner of detection is equally effective for unseen normal events in the training set. In addition, we design a refinement strategy for pseudo-labels to mitigate the effects of the noise problem. Extensive experiments on six benchmark datasets demonstrate the design’s promising generalization ability and high efficiency. Specifically, DiffVAD obtains an AUC score of 81.9% on the ShanghaiTech dataset. Keywords: Computer Vision: General Data Mining: General Humans and AI: General Search: General},
  archive   = {C_IJCAI},
  author    = {Menghao Zhang and Jingyu Wang and Qi Qi and Pengfei Ren and Haifeng Sun and Zirui Zhuang and Lei Zhang and Jianxin Liao},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/838},
  month     = {8},
  pages     = {7572-7580},
  title     = {Safeguarding sustainable cities: Unsupervised video anomaly detection through diffusion-based latent pattern learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DeepLight: Reconstructing high-resolution observations of
nighttime light with multi-modal remote sensing data. <em>IJCAI</em>,
7563–7571. (<a href="https://doi.org/10.24963/ijcai.2024/837">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Nighttime light (NTL) remote sensing observation serves as a unique proxy for quantitatively assessing progress toward meeting a series of Sustainable Development Goals (SDGs), such as poverty estimation, urban sustainable development, and carbon emission. However, existing NTL observations often suffer from pervasive degradation and inconsistency, limiting their utility for computing the indicators defined by the SDGs. In this study, we propose a novel approach to reconstruct high-resolution NTL images using multimodal remote sensing data. To support this research endeavor, we introduce DeepLightMD, a comprehensive dataset comprising data from five heterogeneous sensors, offering fine spatial resolution and rich spectral information at a national scale. Additionally, we present DeepLightSR, a calibration-aware method for multi-modality super-resolution. DeepLightSR integrates calibration-aware alignment, an auxiliary-to-main multi-modality fusion, and an auxiliary-embedded refinement to effectively address spatial heterogeneity, fuse diversely representative features, and enhance performance in ×8 super-resolution tasks. Extensive experiments demonstrate the superiority of DeepLightSR over 8 competing methods, as evidenced by improvements in PSNR (2.01 dB ~ 13.25 dB) and PIQE (0.49 ~ 9.32). Our findings underscore the practical significance of our proposed dataset and model in reconstructing high-resolution NTL data, supporting efficiently and quantitatively assessing the SDG progress. The code and data will be available at https://github.com/xian1234/DeepLight. Keywords: Computer Vision: General Humans and AI: General},
  archive   = {C_IJCAI},
  author    = {Lixian Zhang and Runmin Dong and Shuai Yuan and Jinxiao Zhang and Mengxuan Chen and Juepeng Zheng and Haohuan Fu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/837},
  month     = {8},
  pages     = {7563-7571},
  title     = {DeepLight: Reconstructing high-resolution observations of nighttime light with multi-modal remote sensing data},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Predicting carpark availability in singapore with
cross-domain data: A new dataset and a data-driven approach.
<em>IJCAI</em>, 7554–7562. (<a
href="https://doi.org/10.24963/ijcai.2024/836">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The increasing number of vehicles highlights the need for efficient parking space management. Predicting real-time Parking Availability (PA) can help mitigate traffic congestion and the corresponding social problems, which is a pressing issue in densely populated cities like Singapore. In this study, we aim to collectively predict future PA across Singapore with complex factors from various domains. The contributions in this paper are listed as follows: (1) A New Dataset: We introduce the SINPA dataset, containing a year&#39;s worth of PA data from 1,687 parking lots in Singapore, enriched with various spatial and temporal factors. (2) A Data-Driven Approach: We present DeepPA, a novel deep-learning framework, to collectively and efficiently predict future PA across thousands of parking lots. (3) Extensive Experiments and Deployment: DeepPA demonstrates a 9.2% reduction in prediction error for up to 3-hour forecasts compared to existing advanced models. Furthermore, we implement DeepPA in a practical web-based platform to provide real-time PA predictions to aid drivers and inform urban planning for the governors in Singapore. We release the dataset and source code at https://github.com/yoshall/SINPA. Keywords: Data Mining: General Machine Learning: General},
  archive   = {C_IJCAI},
  author    = {Huaiwu Zhang and Yutong Xia and Siru Zhong and Kun Wang and Zekun Tong and Qingsong Wen and Roger Zimmermann and Yuxuan Liang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/836},
  month     = {8},
  pages     = {7554-7562},
  title     = {Predicting carpark availability in singapore with cross-domain data: A new dataset and a data-driven approach},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Detecting AI-generated sentences in human-AI collaborative
hybrid texts: Challenges, strategies, and insights. <em>IJCAI</em>,
7545–7553. (<a href="https://doi.org/10.24963/ijcai.2024/835">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This study explores the challenge of sentence-level AI-generated text detection within human-AI collaborative hybrid texts (abbreviated as hybrid texts). Existing studies of AI-generated text detection for hybrid texts often rely on synthetic datasets. These typically involve hybrid texts with a limited number of boundaries, e.g., single-boundary hybrid texts that begin with human-written content and end with machine-generated continuations. We contend that studies of detecting AI-generated content within hybrid texts should cover different types of hybrid texts generated in realistic settings to better inform real-world applications. Therefore, our study utilizes the CoAuthor dataset, which includes diverse, realistic hybrid texts generated through the collaboration between human writers and an intelligent writing system in multi-turn interactions. We adopt a two-step, segmentation-based pipeline: (i) detect segments within a given hybrid text where each segment contains sentences of consistent authorship, and (ii) classify the authorship of each identified segment. Our empirical findings highlight (1) detecting AI-generated sentences in hybrid texts is overall a challenging task because (1.1) human writers&#39; selecting and even editing AI-generated sentences based on personal preferences adds difficulty in identifying the authorship of segments; (1.2) the frequent change of authorship between neighboring sentences within the hybrid text creates difficulties for segment detectors in identifying authorship-consistent segments; (1.3) the short length of text segments within hybrid texts provides limited stylistic cues for reliable authorship determination; (2) before embarking on the detection process, it is beneficial to assess the average length of segments within the hybrid text. This assessment aids in deciding whether (2.1) to employ a text segmentation-based strategy for hybrid texts with longer segments, or (2.2) to adopt a direct sentence-by-sentence classification strategy for those with shorter segments. Keywords: Natural Language Processing: General Humans and AI: General},
  archive   = {C_IJCAI},
  author    = {Zijie Zeng and Shiqi Liu and Lele Sha and Zhuang Li and Kaixun Yang and Sannyuya Liu and Dragan Gasevic and Guangliang Chen},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/835},
  month     = {8},
  pages     = {7545-7553},
  title     = {Detecting AI-generated sentences in human-AI collaborative hybrid texts: Challenges, strategies, and insights},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MuseCL: Predicting urban socioeconomic indicators via
multi-semantic contrastive learning. <em>IJCAI</em>, 7536–7544. (<a
href="https://doi.org/10.24963/ijcai.2024/834">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Predicting socioeconomic indicators within urban regions is crucial for fostering inclusivity, resilience, and sustainability in cities and human settlements. While pioneering studies have attempted to leverage multi-modal data for socioeconomic prediction, jointly exploring their underlying semantics remains a significant challenge. To address the gap, this paper introduces a Multi-Semantic Contrastive Learning (MuseCL) framework for fine-grained urban region profiling and socioeconomic prediction. Within this framework, we initiate the process by constructing contrastive sample pairs for street view and remote sensing images, capitalizing on the similarities in human mobility and Point of Interest (POI) distribution to derive semantic features from the visual modality. Additionally, we extract semantic insights from POI texts embedded within these regions, employing a pre-trained text encoder. To merge the acquired visual and textual features, we devise an innovative cross-modality-based attentional fusion module, which leverages a contrastive mechanism for integration. Experimental results across multiple cities and indicators consistently highlight the superiority of MuseCL, demonstrating an average improvement of 10% in R2 compared to various competitive baseline models. The code of this work is publicly available at https://github.com/XixianYong/MuseCL. Keywords: Knowledge Representation and Reasoning: General Data Mining: General Humans and AI: General},
  archive   = {C_IJCAI},
  author    = {Xixian Yong and Xiao Zhou},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/834},
  month     = {8},
  pages     = {7536-7544},
  title     = {MuseCL: Predicting urban socioeconomic indicators via multi-semantic contrastive learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LEEC for judicial fairness: A legal element extraction
dataset with extensive extra-legal labels. <em>IJCAI</em>, 7527–7535.
(<a href="https://doi.org/10.24963/ijcai.2024/833">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {An extensive label system is pivotal to facilitate judicial fairness and social justice. Prior empirical research and our interview with legal professionals underscore the importance of extra-legal factors in criminal trials. To help identify sentencing biases and facilitate downstream applications, we introduce the Legal Element ExtraCtion (LEEC) dataset comprising 15,919 judicial documents and 155 labels. This dataset was constructed through two main steps: First, designing the label system by legal experts based on prior empirical research which identified critical factors driving and processes generating sentencing outcomes in criminal cases; Second, employing legal knowledge to annotate judicial documents according to the label system and annotation guideline. LEEC represents the most extensive and domain-specific legal element extraction dataset for the Chinese legal system. Our experiments reveal that despite certain capabilities, both Document Event Extraction (DEE) models and Large Language Models(LLMs) face significant restrictions in legal element extraction tasks. Finally, our empirical analysis based on LEEC provides evidence for judicial unfairness in Chinese criminal sentencing and confirms the applicability of LEEC for future empirical research and other downstream applications. LEEC and related resources are available on https://github.com/THUlawtech/LEEC. Keywords: Multidisciplinary Topics and Applications: General Natural Language Processing: General},
  archive   = {C_IJCAI},
  author    = {Zongyue Xue and Huanghai Liu and Yiran Hu and Yuliang Qian and Yajing Wang and Kangle Kong and Chenlu Wang and Yun Liu and Weixing Shen},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/833},
  month     = {8},
  pages     = {7527-7535},
  title     = {LEEC for judicial fairness: A legal element extraction dataset with extensive extra-legal labels},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CGAP: Urban region representation learning with coarsened
graph attention pooling. <em>IJCAI</em>, 7518–7526. (<a
href="https://doi.org/10.24963/ijcai.2024/832">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The explosion of massive urban data recently has provided us with a valuable opportunity to gain deeper insights into urban regions and the daily lives of residents. Urban region representation learning emerges as a crucial realm for fulfilling this task. Among deep learning approaches, graph neural networks (GNNs) have shown promise, given that city elements can be naturally represented as nodes with various connections between them as edges. However, many existing GNN approaches encounter challenges such as over-smoothing and limitations in capturing information from nodes in other regions, resulting in the loss of crucial urban information and a decline in region representation performance. To address these challenges, we leverage urban graph structure information and introduce a hierarchical graph pooling process called Coarsened Graph Attention Pooling (CGAP). CGAP features local attention units to create coarsened intermediate graphs and global features. Additionally, by incorporating urban region graphs and global features into a global attention layer, we harness relational information to enhance representation effectiveness. Furthermore, CGAP integrates region attributes such as Points of Interest (POIs) and inter-regional contexts like human mobility, enabling the exploitation of multi-modal urban data for more comprehensive representation learning. Experiments on three downstream tasks related to the UN Sustainable Development Goals validate the effectiveness of region representations learned by our approach. Experimental results and analyses demonstrate that CGAP excels in various socioeconomic prediction tasks compared to competitive baselines. Keywords: Data Mining: General Machine Learning: General Multidisciplinary Topics and Applications: General},
  archive   = {C_IJCAI},
  author    = {Zhuo Xu and Xiao Zhou},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/832},
  month     = {8},
  pages     = {7518-7526},
  title     = {CGAP: Urban region representation learning with coarsened graph attention pooling},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). From pixels to progress: Generating road network from
satellite imagery for socioeconomic insights in impoverished areas.
<em>IJCAI</em>, 7509–7517. (<a
href="https://doi.org/10.24963/ijcai.2024/831">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Sustainable Development Goals (SDGs) aim to resolve societal challenges, such as eradicating poverty and improving the lives of vulnerable populations in impoverished areas. Those areas rely on road infrastructure construction to promote accessibility and economic development. Although publicly available data like OpenStreetMap is available to monitor road status, data completeness in impoverished areas is limited. Meanwhile, the development of deep learning techniques and satellite imagery shows excellent potential for earth monitoring. To tackle the challenge of road network assessment in impoverished areas, we develop a systematic road extraction framework combining an encoder-decoder architecture and morphological operations on satellite imagery, offering an integrated workflow for interdisciplinary researchers. Extensive experiments of road network extraction on real-world data in impoverished regions achieve a 42.7% enhancement in the F1-score over the baseline methods and reconstruct about 80% of the actual roads. We also propose a comprehensive road network dataset covering approximately 794,178 km2 area and 17.048 million people in 382 impoverished counties in China. The generated dataset is further utilized to conduct socioeconomic analysis in impoverished counties, showing that road network construction positively impacts regional economic development. The technical appendix, code, and generated dataset can be found at https://github.com/tsinghua-fib-lab/Road_network_extraction_impoverished_counties. Keywords: Data Mining: General Computer Vision: General Humans and AI: General Multidisciplinary Topics and Applications: General Machine Learning: General},
  archive   = {C_IJCAI},
  author    = {Yanxin Xi and Yu Liu and Zhicheng Liu and Sasu Tarkoma and Pan Hui and Yong Li},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/831},
  month     = {8},
  pages     = {7509-7517},
  title     = {From pixels to progress: Generating road network from satellite imagery for socioeconomic insights in impoverished areas},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Safeguarding fraud detection from attacks: A robust graph
learning approach. <em>IJCAI</em>, 7500–7508. (<a
href="https://doi.org/10.24963/ijcai.2024/830">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Financial fraud is one of the most significant social issues and has caused tremendous property losses. Graph neural networks (GNNs) have been applied to anti-fraud practices and achieved decent results. However, recent researches have discovered flaws in the robustness of fraud-detection models based on GNNs, enabling fraudsters to mislead them through attacks like data poisoning. In addition, most existing attack-defense models tend to study on ideal settings and lose information during truncation or filtering, which lowers their performances in complicated financial fraud cases. Therefore, in this paper, we propose a novel robust anti-fraud GNN model. In particular, we first design an attack algorithm tampering with both features and structures of graph data to simulate fraudsters&#39; attacking behaviors in real-life complex fraud scenarios. Then we apply singular value decomposition to the graph and learn the decomposed matrices in a GNN model with specifically designed joint losses. This enables our model to learn the graph patterns in low-rank subspaces without losing too much detailed information and fit the graph structure to characteristics including class-homophily and sparsity to guarantee robustness. The proposed approach is experimented on real-world fraud datasets, which demonstrates its advantages in fraud detection and robustness compared with the state-of-the-art baselines. Keywords: Multidisciplinary Topics and Applications: General Data Mining: General},
  archive   = {C_IJCAI},
  author    = {Jiasheng Wu and Xin Liu and Dawei Cheng and Yi Ouyang and Xian Wu and Yefeng Zheng},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/830},
  month     = {8},
  pages     = {7500-7508},
  title     = {Safeguarding fraud detection from attacks: A robust graph learning approach},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Guiding clinical reasoning with large language models via
knowledge seeds. <em>IJCAI</em>, 7491–7499. (<a
href="https://doi.org/10.24963/ijcai.2024/829">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Clinical reasoning refers to the cognitive process that physicians employ in evaluating and managing patients. This process typically involves suggesting necessary examinations, diagnosing patients’ diseases, and selecting appropriate therapies, etc. Accurate clinical reasoning requires extensive medical knowledge and rich clinical experience, setting a high bar for physicians. This is particularly challenging in developing countries due to the overwhelming number of patients and limited physician resources, contributing significantly to global health inequity and necessitating automated clinical reasoning approaches. Recently, the emergence of large language models (LLMs) such as ChatGPT and GPT-4 have demonstrated their potential in clinical reasoning. However, these LLMs are prone to hallucination problems, and the reasoning process of LLMs may not align with the clinical decision pathways of physicians. In this study, we introduce a novel framework, In-Context Padding (ICP), to enhance LLMs reasoning with medical knowledge. Specifically, we infer critical clinical reasoning elements (referred to as knowledge seeds) and use these as anchors to guide the generation process of LLMs. Experiments on two clinical question datasets validate that ICP significantly improves the clinical reasoning ability of LLMs. Keywords: Humans and AI: General Natural Language Processing: General Multidisciplinary Topics and Applications: General Knowledge Representation and Reasoning: General},
  archive   = {C_IJCAI},
  author    = {Jiageng Wu and Xian Wu and Jie Yang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/829},
  month     = {8},
  pages     = {7491-7499},
  title     = {Guiding clinical reasoning with large language models via knowledge seeds},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Fuel-saving route planning with data-driven and
learning-based approaches – a systematic solution for harbor tugs.
<em>IJCAI</em>, 7483–7490. (<a
href="https://doi.org/10.24963/ijcai.2024/828">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In recent years, there are trends toward cleaner port environments through enforcement by imposed legislation. Transit optimisation of fuel-based port service boats like harbour tugs has emerged as a critical task to reduce fuel consumption and carbon emission. In this paper, an innovative learning-based method, comprising a Reinforcement Learning (RL) model together with a fuel consumption prediction model, was proposed to formulate fuel-saving transit routes. Firstly, an ensemble model is established by combining a Long Short-Term Memory (LSTM) model with a Multilayer Perceptron (MLP) model, predicting fuel use based on tugboat movement and environment factors. Subsequently, an innovative RL based on Deep Deterministic Policy Gradient (DDPG) framework is developed considering the characteristics and obstructions of waterway in Singapore as well as the environmental factors to learn the optimal transit strategy that minimizes fuel consumption. We also demonstrate the efficacy of the solution to generate routes from origin to destination terminals, exhibiting significantly reduced fuel consumption in comparison to real-world transit scenarios. Keywords: Planning and Scheduling: General Agent-based and Multi-agent Systems: General Multidisciplinary Topics and Applications: General Data Mining: General},
  archive   = {C_IJCAI},
  author    = {Shengming Wang and Xiaocai Zhang and Jing Li and Xiaoyang Wei and Hoong Chuin Lau and Bing Tian Dai and Binbin Huang and Zhe Xiao and Xiuju Fu and Zheng Qin},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/828},
  month     = {8},
  pages     = {7483-7490},
  title     = {Fuel-saving route planning with data-driven and learning-based approaches – a systematic solution for harbor tugs},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel GAN approach to augment limited tabular data for
short-term substance use prediction. <em>IJCAI</em>, 7474–7482. (<a
href="https://doi.org/10.24963/ijcai.2024/827">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Substance use is a global issue that negatively impacts millions of persons who use drugs (PWUDs). In practice, identifying vulnerable PWUDs for efficient allocation of appropriate resources is challenging due to their complex use patterns (e.g., their tendency to change usage within months) and the high acquisition costs for collecting PWUD-focused substance use data. Thus, there has been a paucity of machine learning models for accurately predicting short-term substance use behaviors of PWUDs. In this paper, using longitudinal survey data of 258 PWUDs in the U.S. Great Plains collected by our team, we design a novel GAN that deals with high-dimensional low-sample-size tabular data and survey skip logic to augment existing data to improve classification models&#39; prediction on (A) whether the PWUDs would increase usage and (B) at which ordinal frequency they would use a particular drug within the next 12 months. Our evaluation results show that, when trained on augmented data from our proposed GAN, the classification models improve their predictive performance (AUROC) by up to 13.4% in Problem (A) and 15.8% in Problem (B) for usage of marijuana, meth, amphetamines, and cocaine, which outperform state-of-the-art generative models. Keywords: Multidisciplinary Topics and Applications: General Machine Learning: General},
  archive   = {C_IJCAI},
  author    = {Nguyen Thach and Patrick Habecker and Bergen Johnston and Lillianna Cervantes and Anika Eisenbraun and Alex Mason and Kimberly Tyler and Bilal Khan and Hau Chan},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/827},
  month     = {8},
  pages     = {7474-7482},
  title     = {A novel GAN approach to augment limited tabular data for short-term substance use prediction},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SUKHSANDESH: An avatar therapeutic question answering
platform for sexual education in rural india. <em>IJCAI</em>, 7465–7473.
(<a href="https://doi.org/10.24963/ijcai.2024/826">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Sexual education aims to foster a healthy lifestyle in terms of emotional, mental and social well-being. In countries like India, where adolescents form the largest demographic group, they face significant vulnerabilities concerning sexual health. Unfortunately, sexual education is often stigmatized, creating barriers to providing essential counseling and information to this at-risk population. Consequently, issues such as early pregnancy, unsafe abortions, sexually transmitted infections, and sexual violence become prevalent. Our current proposal aims to provide a safe and trustworthy platform for sexual education to the vulnerable rural Indian population, thereby fostering the healthy and overall growth of the nation. In this regard, we strive towards designing SUKHSANDESH, a multi-staged AI-based Question Answering platform for sexual education tailored to rural India, adhering to safety guardrails and regional language support. By utilizing information retrieval techniques and large language models, SUKHSANDESH will deliver effective responses to user queries. We also propose to anonymise the dataset to mitigate safety measures and set AI guardrails against any harmful or unwanted response generation. Moreover, an innovative feature of our proposal involves integrating &quot;avatar therapy&quot; with SUKHSANDESH. This feature will convert AI-generated responses into real-time audio delivered by an animated avatar speaking regional Indian languages. This approach aims to foster empathy and connection, which is particularly beneficial for individuals with limited literacy skills. Partnering with Gram Vanni, an industry leader, we will deploy SUKHSANDESH to address sexual education needs in rural India. Keywords: Multidisciplinary Topics and Applications: General Natural Language Processing: General},
  archive   = {C_IJCAI},
  author    = {Salam Michael Singh and Shubhmoy Kumar Garg and Amitesh Misra and Aaditeshwar Seth and Tanmoy Chakraborty},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/826},
  month     = {8},
  pages     = {7465-7473},
  title     = {SUKHSANDESH: An avatar therapeutic question answering platform for sexual education in rural india},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Self-supervised vision for climate downscaling.
<em>IJCAI</em>, 7456–7464. (<a
href="https://doi.org/10.24963/ijcai.2024/825">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Climate change is one of the most critical challenges that our planet is facing today. Rising global temperatures are already affecting Earth&#39;s weather and climate patterns with an increased frequency of unpredictable and extreme events. Future projections for climate change research are based on computer models like Earth System Models (ESMs). Climate simulations typically run on a coarser grid due to the high computational resources required, and then undergo a lighter downscaling process to obtain data on a finer grid. This work presents a self-supervised deep learning model that does not require high resolution ground truth data for downscaling. This is realized by leveraging salient distribution patterns and the hidden dependencies between weather variables for an individual data point at runtime. We propose three climate-specific components that well represent the patterns of underlying weather variables and learn intricate inter-variable dependencies. Extensive evaluation with 2x, 3x, and 4x scaling factors demonstrates that our model obtains 8% to 47% performance gain over existing baselines while greatly reducing the overall runtime. The improved performance and no dependence on high resolution ground truth data make our method a valuable tool for future climate research. Keywords: Computer Vision: General Multidisciplinary Topics and Applications: General Machine Learning: General},
  archive   = {C_IJCAI},
  author    = {Karandeep Singh and Chaeyoon Jeong and Naufal Shidqi and Sungwon Park and Arjun Nellikkattil and Elke Zeller and Meeyoung Cha},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/825},
  month     = {8},
  pages     = {7456-7464},
  title     = {Self-supervised vision for climate downscaling},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). From pink and blue to a rainbow hue! Defying gender bias
through gender neutralizing text transformations. <em>IJCAI</em>,
7447–7455. (<a href="https://doi.org/10.24963/ijcai.2024/824">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In an era where language biases contribute to societal inequalities, this research focuses on gender bias in textual data, with profound implications for promoting inclusivity and equity, aligning with United Nations Sustainable Development Goals (SDGs) and upholding the principle of Leave No One Behind (LNOB). Leveraging advances in artificial intelligence, the study introduces the GEnder-NEutralizing Text Transformation (GENETT) framework, addressing gender bias in text through auto-encoders, vector quantization, and Neutrality-Infused Stylization. Furthermore, we present the first-of-its-kind corpus of GEnder Neutralized REvisions (GENRE) crafted from gender-stereotyped versions. This corpus serves a multifaceted utility, offering a resource for diverse downstream tasks in gender-bias analysis. Extensive experimentation on GENRE highlights the superiority of the proposed model over established baselines and state-of-the-art methods. Access the code and dataset at 1. https://www.iitp.ac.in/~ai-nlp-ml/resources.html#GNR, 2. https://github.com/Soumitra816/GNR. Note: Our research focuses on understanding cyber harassment conversations, especially in under-researched areas, with the exclusion of non-binary cases due to existing dataset limitations, not lack of sensitivity. We strive for inclusivity and plan to address this in future research with suitable datasets. Keywords: Multidisciplinary Topics and Applications: General AI Ethics, Trust, Fairness: General},
  archive   = {C_IJCAI},
  author    = {Gopendra Vikram Singh and Soumitra Ghosh and Neil Dcruze and Asif Ekbal},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/824},
  month     = {8},
  pages     = {7447-7455},
  title     = {From pink and blue to a rainbow hue! defying gender bias through gender neutralizing text transformations},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Wearable sensor-based few-shot continual learning on hand
gestures for motor-impaired individuals via latent embedding
exploitation. <em>IJCAI</em>, 7438–7446. (<a
href="https://doi.org/10.24963/ijcai.2024/823">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Hand gestures can provide a natural means of human-computer interaction and enable people who cannot speak to communicate efficiently. Existing hand gesture recognition methods heavily depend on pre-defined gestures, however, motor-impaired individuals require new gestures tailored to each individual&#39;s gesture motion and style. Gesture samples collected from different persons have distribution shifts due to their health conditions, the severity of the disability, motion patterns of the arms, etc. In this paper, we introduce the Latent Embedding Exploitation (LEE) mechanism in our replay-based Few-Shot Continual Learning (FSCL) framework that significantly improves the performance of fine-tuning a model for out-of-distribution data. Our method produces a diversified latent feature space by leveraging a preserved latent embedding known as gesture prior knowledge, along with intra-gesture divergence derived from two additional embeddings. Thus, the model can capture latent statistical structure in highly variable gestures with limited samples. We conduct an experimental evaluation using the SmartWatch Gesture and the Motion Gesture datasets. The proposed method results in an average test accuracy of 57.0%, 64.6%, and 69.3% by using one, three, and five samples for six different gestures. Our method helps motor-impaired persons leverage wearable devices, and their unique styles of movement can be learned and applied in human-computer interaction and social communication. Code is available at: https://github.com/riyadRafiq/wearable-latent-embedding-exploitation. Keywords: Multidisciplinary Topics and Applications: General Machine Learning: General},
  archive   = {C_IJCAI},
  author    = {Riyad Bin Rafiq and Weishi Shi and Mark V. Albert},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/823},
  month     = {8},
  pages     = {7438-7446},
  title     = {Wearable sensor-based few-shot continual learning on hand gestures for motor-impaired individuals via latent embedding exploitation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deploying mobility-on-demand for all by optimizing
paratransit services. <em>IJCAI</em>, 7430–7437. (<a
href="https://doi.org/10.24963/ijcai.2024/822">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {While on-demand ride-sharing services have become popular in recent years, traditional on-demand transit services cannot be used by everyone, e.g., people who use wheelchairs. Paratransit services, operated by public transit agencies, are a critical infrastructure that offers door-to-door transportation assistance for individuals who face challenges in using standard transit routes. However, with declining ridership and mounting financial pressure, public transit agencies in the USA struggle to operate existing services. We collaborate with a public transit agency from the southern USA, highlight the specific nuances of paratransit optimization, and present a vehicle routing problem formulation for optimizing paratransit. We validate our approach using real-world data from the transit agency, present results from an actual pilot deployment of the proposed approach in the city, and show how the proposed approach comprehensively outperforms existing approaches used by the transit agency. To the best of our knowledge, this work presents one of the first examples of using open-source algorithmic approaches for paratransit optimization. Keywords: Multidisciplinary Topics and Applications: General Planning and Scheduling: General},
  archive   = {C_IJCAI},
  author    = {Sophie Pavia and David Rogers and Amutheezan Sivagnanam and Michael Wilbur and Danushka Edirimanna and Youngseo Kim and Philip Pugliese and Samitha Samaranayake and Aron Laszka and Ayan Mukhopadhyay and Abhishek Dubey},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/822},
  month     = {8},
  pages     = {7430-7437},
  title     = {Deploying mobility-on-demand for all by optimizing paratransit services},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unmasking societal biases in respiratory support for ICU
patients through social determinants of health. <em>IJCAI</em>,
7421–7429. (<a href="https://doi.org/10.24963/ijcai.2024/821">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In critical care settings, where precise and timely interventions are crucial for health outcomes, evaluating disparities in patient outcomes is important. Current approaches often fall short in comprehensively understanding and evaluating the impact of respiratory support interventions on individuals affected by social determinants of health. Attributes such as gender, race, and age are commonly assessed and essential, but provide only a partial view of the complexities faced by diverse populations. In this study, we focus on two clinically motivated tasks: prolonged mechanical ventilation and successful weaning. We also perform fairness audits on the models&#39; predictions across demographic groups and social determinants of health to better understand the health inequities in respiratory interventions in the intensive care unit. We also release a temporal benchmark dataset, verified by clinical experts, to enable benchmarking of clinical respiratory intervention tasks. Keywords: AI Ethics, Trust, Fairness: General Data Mining: General Machine Learning: General},
  archive   = {C_IJCAI},
  author    = {Mira Moukheiber and Lama Moukheiber and Dana Moukheiber and Hyung-Chul Lee},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/821},
  month     = {8},
  pages     = {7421-7429},
  title     = {Unmasking societal biases in respiratory support for ICU patients through social determinants of health},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Ensuring fairness stability for disentangling social
inequality in access to education: The FAiRDAS general method.
<em>IJCAI</em>, 7412–7420. (<a
href="https://doi.org/10.24963/ijcai.2024/820">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent advancements in Artificial Intelligence in Education (AIEd) have revolutionized educational practices using machine learning to extract insights from students&#39; activities and behaviours. Performance prediction, a key domain within AIEd, aims to enhance student achievement levels and address sustainable development goals related to education, health, gender equality, and economic growth. However, the potential of AIEd to contribute to these goals is hindered by the lack of attention to fairness in prediction algorithms, leading to educational inequality. To address this gap, we introduce FAiRDAS a general framework that models long-term fairness as an abstract dynamic system. Our approach, illustrated through a case study in AIEd with real data, offers a customizable solution to promote long-term fairness while promoting the stability of mitigation actions over time. Keywords: AI Ethics, Trust, Fairness: General Multidisciplinary Topics and Applications: General},
  archive   = {C_IJCAI},
  author    = {Eleonora Misino and Roberta Calegari and Michele Lombardi and Michela Milano},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/820},
  month     = {8},
  pages     = {7412-7420},
  title     = {Ensuring fairness stability for disentangling social inequality in access to education: The FAiRDAS general method},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Domain adaptation with joint loss for consistent regression
and ordinal classification in the proxy means test for poverty
targeting. <em>IJCAI</em>, 7403–7411. (<a
href="https://doi.org/10.24963/ijcai.2024/819">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Previous domain adaptation methods are designed to work for a single task, either classification or regression. In this paper, the task of the learner is to produce both an estimation and an ordinal classification of instances that are consistent in that the classification of instances into quantiles is derived from the estimated values. We propose an extension of the boosting for transfer method (TrAdaBoost), Joint Quantile Loss Boosting Domain Adaptation (TrAdaBoost.JQL) for regression transfer learning, that aims to jointly minimize regression and ordinal classification errors. Motivated by the real-world problem of poverty targeting using the Proxy Means Test, we empirically show that TrAdaBoost.JQL can consistently reduce RMSE and inclusion and exclusion errors for estimating per capita household expenditure, across a wide variety of districts in Indonesia, compared to other reweighting-based and invariant feature representation-based domain adaptation methods. We design TrAdaBoost.JQL to be flexible as to the chosen eligibility (poor) threshold used in poverty targeting practice and as to whether estimation or ordinal classification accuracy is prioritized. Keywords: Machine Learning: General Data Mining: General Multidisciplinary Topics and Applications: General},
  archive   = {C_IJCAI},
  author    = {Siti Mariyah and Wayne Wobcke},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/819},
  month     = {8},
  pages     = {7403-7411},
  title     = {Domain adaptation with joint loss for consistent regression and ordinal classification in the proxy means test for poverty targeting},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Understanding public perception towards weather disasters
through the lens of metaphor. <em>IJCAI</em>, 7394–7402. (<a
href="https://doi.org/10.24963/ijcai.2024/818">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Extreme weather can lead to weather-induced disasters. These have a profound impact on communities worldwide, causing loss of life, damage to properties and infrastructure, and disruption of daily activities. In alignment with the United Nations Sustainable Development Goals, addressing the increasing frequency and severity of these events, exacerbated by climate change, is imperative. Exploring public perception and responses to weather disasters becomes crucial for policymakers to formulate effective strategies that not only mitigate the impacts but also contribute to the goal of ensuring sustainable and resilient communities. Social media, as a pervasive and real-time communication platform, has gathered a large amount of public opinion. In this work, we analyze public perception towards weather disasters based on tweets and metaphors. Metaphor, as a linguistic device, plays a pivotal role in unraveling cognitive processes and understanding how individuals perceive and make sense of concepts. We focus on tweets related to four distinct types of weather disasters i.e., floods, hurricanes, tornadoes, and wildfires, aiming to extract nuanced insights regarding public perceptions, concerns, and attitudes towards these specific events. We also deliver constructive recommendations, based on the insights. Keywords: Multidisciplinary Topics and Applications: General Data Mining: General},
  archive   = {C_IJCAI},
  author    = {Rui Mao and Qika Lin and Qiawen Liu and Gianmarco Mengaldo and Erik Cambria},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/818},
  month     = {8},
  pages     = {7394-7402},
  title     = {Understanding public perception towards weather disasters through the lens of metaphor},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RisQNet: Rescuing SMEs from financial shocks with a novel
networked-loan risk assessment. <em>IJCAI</em>, 7385–7393. (<a
href="https://doi.org/10.24963/ijcai.2024/817">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the face of economic downturns, Small and Medium-sized Enterprises (SMEs) within interconnected networked-loans are vulnerable to cascading debt crises, exacerbated by factors like social media-induced financial shocks. Traditional risk assessment models, which mainly rely on financial data, inadequately predict such crises, as evidenced by the collapse of Silicon Valley Bank in 2023. To address this issue, we developed RisQNet, a model that uses temporal graph networks to incorporate diverse risks, including real-time media influences. This approach not only advances risk prediction through news feature extraction and large language models but also enhances risk management strategies with intuitive visualization tools. Validated on a dataset with a total loan volume of USD 3 trillion, RisQNet outperforms the state-of-the-art baseline and achieves 87.1% of AUC. Our collaborative effort with financial regulators and the SME community underpins the model&#39;s development, aligning with the UN SDG 8. RisQNet represents a significant step forward in leveraging AI for financial stability, offering a promising approach to combat the propagation of debt crises in financial networks. Keywords: Data Mining: General Multidisciplinary Topics and Applications: General},
  archive   = {C_IJCAI},
  author    = {Zhaoyuan Lu and Taijun Li and Jingzhen Zhang and Moyang Liu and Xiang Li and Linyi Cui and Junqi Chen and Zhibin Niu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/817},
  month     = {8},
  pages     = {7385-7393},
  title     = {RisQNet: Rescuing SMEs from financial shocks with a novel networked-loan risk assessment},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Benchmarking fish dataset and evaluation metric in keypoint
detection - towards precise fish morphological assessment in aquaculture
breeding. <em>IJCAI</em>, 7376–7384. (<a
href="https://doi.org/10.24963/ijcai.2024/816">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Accurate phenotypic analysis in aquaculture breeding necessitates the quantification of subtle morphological phenotypes. Existing datasets suffer from limitations such as small scale, limited species coverage, and inadequate annotation of keypoints for measuring refined and complex morphological phenotypes of fish body parts. To address this gap, we introduce FishPhenoKey, a comprehensive dataset comprising 23,331 high-resolution images spanning six fish species. Notably, FishPhenoKey includes 22 phenotype-oriented annotations, enabling the capture of intricate morphological phenotypes. Motivated by the nuanced evaluation of these subtle morphologies, we also propose a new evaluation metric, Percentage of Measured Phenotypes (PMP). It is designed to assess the accuracy of individual keypoint positions and is highly sensitive to the phenotype measured using the corresponding keypoints. To enhance keypoint detection accuracy, we further propose a novel loss, Anatomically-Calibrated Regularization (ACR), that can be integrated into keypoint detection models, leveraging biological insights to refine keypoint localization. Our contributions set a new benchmark in fish phenotype analysis, addressing the challenges of precise morphological quantification and opening new avenues for research in sustainable aquaculture and genetic studies. Our dataset and code are available at https://github.com/WeizhenLiuBioinform/FishPhenotype-Detect. Keywords: Multidisciplinary Topics and Applications: General Computer Vision: General Machine Learning: General},
  archive   = {C_IJCAI},
  author    = {Weizhen Liu and Jiayu Tan and Guangyu Lan and Ao Li and Dongye Li and Le Zhao and Xiaohui Yuan and Nanqing Dong},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/816},
  month     = {8},
  pages     = {7376-7384},
  title     = {Benchmarking fish dataset and evaluation metric in keypoint detection - towards precise fish morphological assessment in aquaculture breeding},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Revealing hierarchical structure of leaf venations in plant
science via label-efficient segmentation: Dataset and method.
<em>IJCAI</em>, 7367–7375. (<a
href="https://doi.org/10.24963/ijcai.2024/815">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Hierarchical leaf vein segmentation is a crucial but under-explored task in agricultural sciences, where analysis of the hierarchical structure of plant leaf venation can contribute to plant breeding. While current segmentation techniques rely on data-driven models, there is no publicly available dataset specifically designed for hierarchical leaf vein segmentation. To address this gap, we introduce the HierArchical Leaf Vein Segmentation (HALVS) dataset, the first public hierarchical leaf vein segmentation dataset. HALVS comprises 5,057 real-scanned high-resolution leaf images collected from three plant species: soybean, sweet cherry, and London planetree. It also includes human-annotated ground truth for three orders of leaf veins, with a total labeling effort of 83.8 person-days. Based on HALVS, we further develop a label-efficient learning paradigm that leverages partial label information, i.e. missing annotations for tertiary veins. Empirical studies are performed on HALVS, revealing new observations, challenges, and research directions on leaf vein segmentation. Our dataset and code are available at https://github.com/WeizhenLiuBioinform/ HALVS-Hierarchical-Vein-Segment. Keywords: Multidisciplinary Topics and Applications: General Computer Vision: General Machine Learning: General},
  archive   = {C_IJCAI},
  author    = {Weizhen Liu and Ao Li and Ze Wu and Yue Li and Baobin Ge and Guangyu Lan and Shilin Chen and Minghe Li and Yunfei Liu and Xiaohui Yuan and Nanqing Dong},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/815},
  month     = {8},
  pages     = {7367-7375},
  title     = {Revealing hierarchical structure of leaf venations in plant science via label-efficient segmentation: Dataset and method},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Drug overdose vital-signs evaluator using machine learning.
<em>IJCAI</em>, 7358–7366. (<a
href="https://doi.org/10.24963/ijcai.2024/814">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Opioid overdose is an escalating global epidemic, affecting 16 million individuals. Lack of overdose detection and slower response times are the leading causes of overdose deaths. During a fatal opioid overdose, the user exhibits motionlessness, lack of breathing, and hypoxemia (oxygen saturation drops). In this paper, we discuss the development of a shoulder-based wearable overdose detection device that monitors hypoxemia, motion, and respiration. The device&#39;s design considers the underserved socio-economic population and their psychological contexts. However, conventional approaches to detecting an overdose typically focus on a single biomarker. To address this, we have developed a robust capsule networks based machine learning (ML) model, OxyCaps that integrates oxygen saturation, respiration rate, and motion to classify different levels of hypoxemia. This also helps improve patient adherence by decreasing the chances of false positive alerts. To determine a hypoxemic state, the model considers various features like skin tone, body physiology, motion, and photoplethysmography (PPG) signals. In the absence of real-world opioid overdose data, our research leverages data collected by our device from 19 patients experiencing sleep apnea, exploiting the parallels between overdose and apnea biomarkers. Our dataset provides a novel compilation of raw PPG and motion signals detected from the shoulder. Our model classifies 3 stages of hypoxemia with an average accuracy of 92%, specifically achieving a high recall of 0.98 for the critical hypoxemic state that is crucial in determining an overdose. Keywords: Humans and AI: General Multidisciplinary Topics and Applications: General},
  archive   = {C_IJCAI},
  author    = {Anush Niranjan Lingamoorthy and Abhishek Kumar Mishra and Suman Kumar and David Gordon and Jacob Brenner and Nagarajan Kandasamy and Amanda Watson},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/814},
  month     = {8},
  pages     = {7358-7366},
  title     = {Drug overdose vital-signs evaluator using machine learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Long-term detection and monitory of chinese urban village
using satellite imagery. <em>IJCAI</em>, 7349–7357. (<a
href="https://doi.org/10.24963/ijcai.2024/813">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Urban villages are areas filled with rural-like improvised structures in Chinese cities, usually housing the most vulnerable groups. Under the guidance of the Sustainable Development Goals (SDGs), the Chinese government initiated renewal and redevelopment projects, underscoring the meticulous mapping and segmentation of urban villages. Satellite imagery is advanced and efficient in identifying urban villages and monitoring changes, but traditional methods neglect the morphological diversity in season, shape, size, spacing, and layout of urban villages, which is not satisfying for long-term wide-range data. Here, we design a targeted approach based on Tobler’s First Law of Geography, using curriculum labeling to solve morphological diversity and semi-automatically generate segmentation for urban village boundaries. Specifically, we use manually labeled data as seeds for pre-trained SegFormer models and incrementally fine-tune the model based on geographical proximity. The rigorous experimentation across five diverse cities substantiates the commendable efficacy of our methodology. IoU metric demonstrates a noteworthy improvement of over 119% to baseline. Our final results cover 265,050 urban villages across 433 cities in China over the past 10 years, and the analysis reveals the uneven redevelopment by geography and city scale. We further examine the within-city distribution and verify the urban scaling law associated with several socio-economic factors. Our method can be used nationwide to decide redevelopment priority and resource tilt, contributing to SDG 11.1 on affordable housing and upgrading slums. The code and dataset are available at https://github.com/tsinghua-fib-lab/LtCUV. Keywords: Multidisciplinary Topics and Applications: General Computer Vision: General Data Mining: General Machine Learning: General},
  archive   = {C_IJCAI},
  author    = {Yuming Lin and Xin Zhang and Yu Liu and Zhenyu Han and Qingmin Liao and Yong Li},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/813},
  month     = {8},
  pages     = {7349-7357},
  title     = {Long-term detection and monitory of chinese urban village using satellite imagery},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing sustainable urban mobility prediction with telecom
data: A spatio-temporal framework approach. <em>IJCAI</em>, 7340–7348.
(<a href="https://doi.org/10.24963/ijcai.2024/812">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Traditional traffic prediction, limited by the scope of sensor data, falls short in comprehensive traffic management. Mobile networks offer a promising alternative using network activity counts, but these lack crucial directionality. Thus, we present the TeltoMob dataset, featuring undirected telecom counts and corresponding directional flows, to predict directional mobility flows on roadways. To address this, we propose a two-stage spatio-temporal graph neural network (STGNN) framework. The first stage uses a pre-trained STGNN to process telecom data, while the second stage integrates directional and geographic insights for accurate prediction. Our experiments demonstrate the framework&#39;s compatibility with various STGNN models and confirm its effectiveness. We also show how to incorporate the framework into real-world transportation systems, enhancing sustainable urban mobility. Keywords: Data Mining: General Knowledge Representation and Reasoning: General},
  archive   = {C_IJCAI},
  author    = {ChungYi Lin and Shen-Lung Tung and Hung-Ting Su and Winston H. Hsu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/812},
  month     = {8},
  pages     = {7340-7348},
  title     = {Enhancing sustainable urban mobility prediction with telecom data: A spatio-temporal framework approach},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CDSTraj: Characterized diffusion and spatial-temporal
interaction network for trajectory prediction in autonomous driving.
<em>IJCAI</em>, 7331–7339. (<a
href="https://doi.org/10.24963/ijcai.2024/811">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Trajectory prediction is a cornerstone in autonomous driving (AD), playing a critical role in enabling vehicles to navigate safely and efficiently in dynamic environments. To address this task, this paper presents a novel trajectory prediction model tailored for accuracy in the face of heterogeneous and uncertain traffic scenarios. At the heart of this model lies the Characterized Diffusion Module, an innovative module designed to simulate traffic scenarios with inherent uncertainty. This module enriches the predictive process by infusing it with detailed semantic information, thereby enhancing trajectory prediction accuracy. Complementing this, our Spatio-Temporal (ST) Interaction Module captures the nuanced effects of traffic scenarios on vehicle dynamics across both spatial and temporal dimensions with remarkable effectiveness. Demonstrated through exhaustive evaluations, our model sets a new standard in trajectory prediction, achieving state-of-the-art (SOTA) results on the Next Generation Simulation (NGSIM), Highway Drone (HighD), and Macao Connected Autonomous Driving (MoCAD) datasets across both short and extended temporal spans. This performance underscores the model&#39;s unparalleled adaptability and efficacy in navigating complex traffic scenarios, including highways, urban streets, and intersections. Keywords: Robotics: General Planning and Scheduling: General},
  archive   = {C_IJCAI},
  author    = {Haicheng Liao and Xuelin Li and Yongkang Li and Hanlin Kong and Chengyue Wang and Bonan Wang and Yanchen Guan and KaHou Tam and Zhenning Li},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/811},
  month     = {8},
  pages     = {7331-7339},
  title     = {CDSTraj: Characterized diffusion and spatial-temporal interaction network for trajectory prediction in autonomous driving},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Predicting housing transaction with common covariance GNNs.
<em>IJCAI</em>, 7323–7330. (<a
href="https://doi.org/10.24963/ijcai.2024/810">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Urban migration is a significant aspect of a city&#39;s economy. The exploration of the underlying determinants of housing purchases among current residents contributes to the study of future trends in urban migration, enabling governments to formulate appropriate policies to guide future economic growth. This article employs a factor model to analyze data on residents&#39; rentals, first-time home purchases, and subsequent housing upgrades. We decompose the factors influencing housing purchases into common drivers and specific drivers. Our hypothesis is that common drivers reflect universal social patterns, while personalized drivers represent stochastic elements. We construct a correlation matrix capturing the inter-resident relationships based on the common drivers of housing purchases. We then propose a graph neural network based on the correlation matrix to model housing predictions as a node classification problem. Our model addresses two critical questions. Firstly, we aim to identify which part of rental residents will engage in first-time home purchases in the future. Secondly, we seek to determine which group of residents, having completed rental and first-time home purchases, will opt for a second home purchase. The results of our testing on real-world datasets demonstrate that based solely on rental and home purchase records, we can achieve a sensitivity for housing predictions exceeding 80%. Keywords: Multidisciplinary Topics and Applications: General Machine Learning: General},
  archive   = {C_IJCAI},
  author    = {Jinjin Li and Bin Liu and Chengyan Liu and Hongli Zhang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/810},
  month     = {8},
  pages     = {7323-7330},
  title     = {Predicting housing transaction with common covariance GNNs},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Time-evolving data science and artificial intelligence for
advanced open environmental science (TAIAO) programme. <em>IJCAI</em>,
7314–7322. (<a href="https://doi.org/10.24963/ijcai.2024/809">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {New Zealand&#39;s unique ecosystems face increasing threats from climate change, impacting biodiversity and posing challenges to safety, livelihoods, and well-being. To tackle these complex issues, advanced data science and artificial intelligence techniques can provide unique solutions. Currently, in its fourth year of a seven-year program, TAIAO focuses on methods for analyzing environmental datasets. Recognizing this urgency, the open-source TAIAO platform was developed. This platform enables new artificial intelligence research for environmental data and offers an open-access repository to enhance reproducibility in the field. This paper will showcase four environmental case studies, artificial intelligence research, platform implementation details, and future development plans. Keywords: Machine Learning: General Multidisciplinary Topics and Applications: General},
  archive   = {C_IJCAI},
  author    = {Yun Sing Koh and Albert Bifet and Karin Bryan and Guilherme Cassales and Olivier Graffeuille and Nick Lim and Phil Mourot and Ding Ning and Bernhard Pfahringer and Varvara Vetrova and Heitor Murilo Gomes},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/809},
  month     = {8},
  pages     = {7314-7322},
  title     = {Time-evolving data science and artificial intelligence for advanced open environmental science (TAIAO) programme},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survival guide for iranian women prescribed by iranian
women: Participatory AI to investigate intimate partner physical
violence in iran. <em>IJCAI</em>, 7305–7313. (<a
href="https://doi.org/10.24963/ijcai.2024/808">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Intimate Partner Violence (IPV) is a global problem affecting more than 2 billion women worldwide. Our paper makes two key contributions. First, via a substantial corpus of 53,220 comments to 1,563 Intimate Partner Physical Violence (IPPV) posts gleaned from more than 10 million comments posted on 523,232 posts on a popular parental health website in Iran, we present the first-ever computational analysis of user comments on accounts of IPPV in Iran. We harness large language models and participatory AI and tackle extreme class imbalance and other linguistic challenges that arise from tackling low-resource languages to shed light on the gender struggles of a country with documented stark gender inequality. With active input from a woman with a history of advocacy for social rights and grounded in Iranian culture, we characterize comments on IPPV into three broad categories: empathy, confront, and conform, and analyze their distribution. Second, we release an important dataset of 3,400 comments on IPPV posts. Keywords: Natural Language Processing: General Humans and AI: General AI Ethics, Trust, Fairness: General},
  archive   = {C_IJCAI},
  author    = {Adel Khorramrouz and Mahbeigom Fayyazi and Ashiqur R. KhudaBukhsh},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/808},
  month     = {8},
  pages     = {7305-7313},
  title     = {A survival guide for iranian women prescribed by iranian women: Participatory AI to investigate intimate partner physical violence in iran},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Energy-efficient missing data imputation in wearable health
applications: A classifier-aware statistical approach. <em>IJCAI</em>,
7296–7304. (<a href="https://doi.org/10.24963/ijcai.2024/807">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Wearable devices are being increasingly used in high-impact health applications including vital sign monitoring, rehabilitation, and movement disorders. Wearable health monitoring can aid in the United Nations social development goal of healthy lives by enabling early warning, risk reduction, and management of health risks. Health tasks on wearable devices employ multiple sensors to collect relevant parameters of user’s health and make decisions using machine learning (ML) algorithms. The ML algorithms assume that data from all sensors are available for the health monitoring tasks. However, the applications may encounter missing or incomplete data due to user error, energy limitations, or sensor malfunction. Missing data results in significant loss of accuracy and quality of service. This paper presents a novel Classifier-Aware iMputation (CAM) approach to impute missing data such that classifier accuracy for health tasks is not affected. Specifically, CAM employs unsupervised clustering followed by a principled search algorithm to uncover imputation patterns that maintain high accuracy. Evaluations on seven diverse health tasks show that CAM achieves accuracy within 5% of the baseline with no missing data when one sensor is missing. CAM also achieves significantly higher accuracy compared to generative approaches with negligible energy overhead, making it suitable for wide range of wearable applications. Keywords: Multidisciplinary Topics and Applications: General Machine Learning: General Humans and AI: General Search: General},
  archive   = {C_IJCAI},
  author    = {Dina Hussein and Taha Belkhouja and Ganapati Bhat and Janardhan Rao Doppa},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/807},
  month     = {8},
  pages     = {7296-7304},
  title     = {Energy-efficient missing data imputation in wearable health applications: A classifier-aware statistical approach},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Remote sensing for water quality: A multi-task,
metadata-driven hypernetwork approach. <em>IJCAI</em>, 7287–7295. (<a
href="https://doi.org/10.24963/ijcai.2024/806">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Inland water quality monitoring is vital for clean water access and aquatic ecosystem management. Remote sensing machine learning models enable large-scale observations, but are difficult to train due to data scarcity and variability across many lakes. Multi-task learning approaches enable learning of lake differences by learning multiple lake functions simultaneously. However, they suffer from a trade-off between parameter efficiency and the ability to model task differences flexibly, and struggle to model many diverse lakes with few samples per task. We propose Multi-Task Hypernetworks, a novel multi-task learning architecture which circumvents this trade-off using a shared hypernetwork to generate different network weights for each task from small task-specific embeddings. Our approach stands out from existing works by providing the added capacity to leverage task-level metadata, such as lake depth and temperature, explicitly. We show empirically that Multi-Task Hypernetworks outperform existing multi-task learning architectures for water quality remote sensing and other tabular data problems, and leverages metadata more effectively than existing methods. Keywords: Machine Learning: General Multidisciplinary Topics and Applications: General},
  archive   = {C_IJCAI},
  author    = {Olivier Graffeuille and Yun Sing Koh and Jörg Wicker and Moritz Lehmann},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/806},
  month     = {8},
  pages     = {7287-7295},
  title     = {Remote sensing for water quality: A multi-task, metadata-driven hypernetwork approach},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ReBandit: Random effects based online RL algorithm for
reducing cannabis use. <em>IJCAI</em>, 7278–7286. (<a
href="https://doi.org/10.24963/ijcai.2024/805">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The escalating prevalence of cannabis use, and associated cannabis-use disorder (CUD), poses a significant public health challenge globally. With a notably wide treatment gap, especially among emerging adults (EAs; ages 18-25), addressing cannabis use and CUD remains a pivotal objective within the 2030 United Nations Agenda for Sustainable Development Goals (SDG). In this work, we develop an online reinforcement learning (RL) algorithm called reBandit which will be utilized in a mobile health study to deliver personalized mobile health interventions aimed at reducing cannabis use among EAs. reBandit utilizes random effects and informative Bayesian priors to learn quickly and efficiently in noisy mobile health environments. Moreover, reBandit employs Empirical Bayes and optimization techniques to autonomously update its hyper-parameters online. To evaluate the performance of our algorithm, we construct a simulation testbed using data from a prior study, and compare against commonly used algorithms in mobile health studies. We show that reBandit performs equally well or better than all the baseline algorithms, and the performance gap widens as population heterogeneity increases in the simulation environment, proving its adeptness to adapt to diverse population of study participants. Keywords: Multidisciplinary Topics and Applications: General Machine Learning: General Uncertainty in AI: General},
  archive   = {C_IJCAI},
  author    = {Susobhan Ghosh and Yongyi Guo and Pei-Yao Hung and Lara Coughlin and Erin Bonar and Inbal Nahum-Shani and Maureen Walton and Susan Murphy},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/805},
  month     = {8},
  pages     = {7278-7286},
  title     = {ReBandit: Random effects based online RL algorithm for reducing cannabis use},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Streamflow prediction with uncertainty quantification for
water management: A constrained reasoning and learning approach.
<em>IJCAI</em>, 7269–7277. (<a
href="https://doi.org/10.24963/ijcai.2024/804">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Predicting the spatiotemporal variation in streamflow along with uncertainty quantification enables decision-making for sustainable management of scarce water resources. Process-based hydrological models (aka physics-based models) are based on physical laws, but use simplifying assumptions which can lead to poor accuracy. Data-driven approaches offer a powerful alternative, but they require large amount of training data and tend to produce predictions that are inconsistent with physical laws. This paper studies a constrained reasoning and learning (CRL) approach where physical laws represented as logical constraints are integrated as a layer in the deep neural network. To address small data setting, we develop a theoretically-grounded training approach to improve the generalization accuracy of deep models. For uncertainty quantification, we combine the synergistic strengths of Gaussian processes (GPs) and deep temporal models by passing the learned latent representation as input to a standard distance-based kernel. Experiments on multiple real-world datasets demonstrate the effectiveness of both CRL and GP with deep kernel approaches over strong baseline methods. Keywords: Multidisciplinary Topics and Applications: General Machine Learning: General},
  archive   = {C_IJCAI},
  author    = {Mohammed Amine Gharsallaoui and Bhupinderjeet Singh and Supriya Savalkar and Aryan Deshwal and Ananth Kalyanaraman and Kirti Rajagopalan and Janardhan Rao Doppa},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/804},
  month     = {8},
  pages     = {7269-7277},
  title     = {Streamflow prediction with uncertainty quantification for water management: A constrained reasoning and learning approach},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Spatio-temporal field neural networks for air quality
inference. <em>IJCAI</em>, 7260–7268. (<a
href="https://doi.org/10.24963/ijcai.2024/803">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The air quality inference problem aims to utilize historical data from a limited number of observation sites to infer the air quality index at an unknown location. Considering the sparsity of data due to the high maintenance cost of the stations, good inference algorithms can effectively save the cost and refine the data granularity. While spatio-temporal graph neural networks have made excellent progress on this problem, their non-Euclidean and discrete data structure modeling of reality limits its potential. In this work, we make the first attempt to combine two different spatio-temporal perspectives, fields and graphs, by proposing a new model, Spatio-Temporal Field Neural Network, and its corresponding new framework, Pyramidal Inference. Extensive experiments validate that our model achieves state-of-the-art performance in nationwide air quality inference in the Chinese Mainland, demonstrating the superiority of our proposed model and framework. Keywords: Data Mining: General Humans and AI: General Multidisciplinary Topics and Applications: General},
  archive   = {C_IJCAI},
  author    = {Yutong Feng and Qiongyan Wang and Yutong Xia and Junlin Huang and Siru Zhong and Yuxuan Liang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/803},
  month     = {8},
  pages     = {7260-7268},
  title     = {Spatio-temporal field neural networks for air quality inference},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A teacher classroom dress assessment method based on a new
assessment dataset. <em>IJCAI</em>, 7251–7259. (<a
href="https://doi.org/10.24963/ijcai.2024/802">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Proper attire is a professional requirement for teachers and teachers&#39; dress influence students&#39; perceptions of teacher quality. Therefore, evaluating teacher attire can better regulate and improve the teacher’s dress. However, the lack of a dataset on teacher attire hinders the development of this field. For this purpose, this paper constructs a Teachers&#39; Classroom Dress Assessment (TCDA) dataset. To our knowledge, it is the first dataset focused on teacher attire. This dataset is entirely from the classroom environment, covering 25 teacher attributes, with a total of 11879 teacher dress samples and sufficient positive and negative examples. Therefore, the TCDA dataset is a challenging evaluation dataset with characteristics such as data diversity. In order to verify the effectiveness of the dataset, this paper systematically explores a new perspective on human attribute information and proposes for the first time a Teachers&#39; Dress Assessment Method (TDAM), aiming to use predicted teacher attributes to scoring the overall attire of each teacher, thereby promoting the development of the teacher&#39;s classroom teaching field. The experimental results demonstrate the rationality of the TCDA dataset and the effectiveness of the TDAM method. The dataset and code can be openly obtained at https://github.com/MingZier/TCDA-dataset. Keywords: Computer Vision: General Humans and AI: General Machine Learning: General},
  archive   = {C_IJCAI},
  author    = {Ming Fang and Qi Liu and Yunpeng Zhou and Xinning Du and Qiwen Liang and Shuhua Liu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/802},
  month     = {8},
  pages     = {7251-7259},
  title     = {A teacher classroom dress assessment method based on a new assessment dataset},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Down the toxicity rabbit hole: A framework to bias audit
large language models with key emphasis on racism, antisemitism, and
misogyny. <em>IJCAI</em>, 7242–7250. (<a
href="https://doi.org/10.24963/ijcai.2024/801">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper makes three contributions. First, it presents a generalizable, novel framework dubbed toxicity rabbit hole that iteratively elicits toxic content from a wide suite of large language models. Spanning a set of 1,266 identity groups, we first conduct a bias audit of PaLM 2 guardrails presenting key insights. Next, we report generalizability across several other models. Through the elicited toxic content, we present a broad analysis with a key emphasis on racism, antisemitism, misogyny, Islamophobia, homophobia, and transphobia. We release a massive dataset of machine-generated toxic content with a view toward safety for all. Finally, driven by concrete examples, we discuss potential ramifications. Keywords: AI Ethics, Trust, Fairness: General Natural Language Processing: General},
  archive   = {C_IJCAI},
  author    = {Arka Dutta and Adel Khorramrouz and Sujan Dutta and Ashiqur R. KhudaBukhsh},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/801},
  month     = {8},
  pages     = {7242-7250},
  title     = {Down the toxicity rabbit hole: A framework to bias audit large language models with key emphasis on racism, antisemitism, and misogyny},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). For the misgendered chinese in gender bias research:
Multi-task learning with knowledge distillation for pinyin name gender
prediction. <em>IJCAI</em>, 7233–7241. (<a
href="https://doi.org/10.24963/ijcai.2024/800">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Achieving gender equality is a pivotal factor in realizing the UN&#39;s Global Goals for Sustainable Development. Gender bias studies work towards this and rely on name-based gender inference tools to assign individual gender labels when gender information is unavailable. However, these tools often inaccurately predict gender for Chinese Pinyin names, leading to potential bias in such studies. With the growing participation of Chinese in international activities, this situation is becoming more severe. Specifically, current tools focus on pronunciation (Pinyin) information, neglecting the fact that the latent connections between Pinyin and Chinese characters (Hanzi) behind convey critical information. As a first effort, we formulate the Pinyin name-gender guessing problem and design a Multi-Task Learning Network assisted by Knowledge Distillation that enables the Pinyin representations in the model to possess semantic features of Chinese characters and to learn gender information from Chinese character names. Our open-sourced method surpasses commercial name-gender guessing tools by 9.70% to 20.08% relatively, and also outperforms the state-of-the-art algorithms. Keywords: Data Mining: General Humans and AI: General Multidisciplinary Topics and Applications: General},
  archive   = {C_IJCAI},
  author    = {Xiaocong Du and Haipeng Zhang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/800},
  month     = {8},
  pages     = {7233-7241},
  title     = {For the misgendered chinese in gender bias research: Multi-task learning with knowledge distillation for pinyin name gender prediction},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FairReFuse: Referee-guided fusion for multi-modal causal
fairness in depression detection. <em>IJCAI</em>, 7224–7232. (<a
href="https://doi.org/10.24963/ijcai.2024/799">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Machine learning (ML) bias in mental health detection and analysis is becoming an increasingly pertinent challenge. Despite promising efforts indicating that multimodal methods work better than unimodal methods, there is minimal work on multimodal fairness for depression detection. We propose a causal multimodal framework which consists of two modules. Module 1 performs causal interventional debiasing via backdoor adjustment for each modality to achieve group fairness. Module 2 adaptively fuses the different modalities using a referee-based individual fairness guided fusion mechanism to address individual fairness. We conduct experiments and ablation studies on three depression datasets, D-Vlog, DAIC-WOZ and E-DAIC, and show that our framework improves classification performance as well as group and individual fairness compared to existing approaches. Keywords: AI Ethics, Trust, Fairness: General Machine Learning: General Multidisciplinary Topics and Applications: General},
  archive   = {C_IJCAI},
  author    = {Jiaee Cheong and Sinan Kalkan and Hatice Gunes},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/799},
  month     = {8},
  pages     = {7224-7232},
  title     = {FairReFuse: Referee-guided fusion for multi-modal causal fairness in depression detection},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An embarrassingly simple approach to enhance transformer
performance in genomic selection for crop breeding. <em>IJCAI</em>,
7215–7223. (<a href="https://doi.org/10.24963/ijcai.2024/798">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Genomic selection (GS), as a critical crop breeding strategy, plays a key role in enhancing food production and addressing the global hunger crisis. The predominant approaches in GS currently revolve around employing statistical methods for prediction. However, statistical methods often come with two main limitations: strong statistical priors and linear assumptions. A recent trend is to capture the non-linear relationships between markers by deep learning. However, as crop datasets are commonly long sequences with limited samples, the robustness of deep learning models, especially Transformers, remains a challenge. In this work, to unleash the unexplored potential of attention mechanism for the task of interest, we propose a simple yet effective Transformer-based framework that enables end-to-end training of the whole sequence. Via experiments on rice3k and wheat3k datasets, we show that, with simple tricks such as k-mer tokenization and random masking, Transformer can achieve overall superior performance against seminal methods on GS tasks of interest. Keywords: Multidisciplinary Topics and Applications: General Machine Learning: General},
  archive   = {C_IJCAI},
  author    = {Renqi Chen and Wenwei Han and Haohao Zhang and Haoyang Su and Zhefan Wang and Xiaolei Liu and Hao Jiang and Wanli Ouyang and Nanqing Dong},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/798},
  month     = {8},
  pages     = {7215-7223},
  title     = {An embarrassingly simple approach to enhance transformer performance in genomic selection for crop breeding},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). VulnerabilityMap: An open framework for mapping
vulnerability among urban disadvantaged populations in the united
states. <em>IJCAI</em>, 7206–7214. (<a
href="https://doi.org/10.24963/ijcai.2024/797">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Cities are crucibles of numerous opportunities, but also hotbeds of inequality. The plight of disadvantaged populations who are ``left behind&#39;&#39; within urban environments has been an increasingly pressing concern, which poses substantial threats to the realization of the UN SDG agenda. However, a comprehensive framework for studying this urban dilemma is currently absent, preventing researchers from developing AI models for social good prediction and intervention. To fill this gap, we construct VulnerabilityMap, a framework to meticulously dissect the challenges faced by urban disadvantaged populations, unraveling their vulnerability to a spectrum of shocks and stresses that are categorized through the prism of Maslow&#39;s hierarchy of needs. Specifically, we systematically collect large-scale multi-sourced census and web-based data covering more than 328 million people in the United States regarding demographic features, neighborhood environments, offline mobility behaviors, and online social connections. These features are further related to vulnerability outcomes from short-term shocks such as COVID-19 and long-term physiological, social, and self-actualization stresses. Leveraging our framework, we construct machine learning models that exhibit strong performance in predicting vulnerability outcomes from various disadvantage features, which shows the promising utility of our framework to support targeted AI models. Moreover, we provide model-based explainability analysis to interpret the reasons underlying model predictions, shedding light on intricate social factors that trap certain populations inside vulnerable situations. Our constructed dataset is publicly available at https://github.com/LinChen-65/VulnerabilityMap/. Keywords: Multidisciplinary Topics and Applications: General Data Mining: General Humans and AI: General Machine Learning: General},
  archive   = {C_IJCAI},
  author    = {Lin Chen and Yong Li and Pan Hui},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/797},
  month     = {8},
  pages     = {7206-7214},
  title     = {VulnerabilityMap: An open framework for mapping vulnerability among urban disadvantaged populations in the united states},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fitness activity recognition using a novel pressure sensing
mat and machine learning for the future of accessible training.
<em>IJCAI</em>, 7197–7205. (<a
href="https://doi.org/10.24963/ijcai.2024/796">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Physical inactivity is still a major problem contributing to a growing public health crisis despite a fast-expanding body of technological solutions and wellness research around fitness training. The inaccessibility of professional fitness training remains a leading cause of this gap for reasons encompassing socioeconomic factors, cultural and demographic barriers, and more recently the threat of global pandemics that disrupt traditional modes of staying physically active. Previous lines of work have explored using AI for fitness activity recognition from various sensing modalities such as computer vision, wearable sensors, and force and pressure sensors. However, these works are limited by their feasibility, deployability, and accessibility in real-world scenarios, in addition to the technical challenges faced by each modality for accurate and reliable activity recognition. In this paper, we propose an accessible system for gym activity recognition and correction focusing on foundational fitness activities using ML and a novel pressure sensing mat, and validate its deployability in a real-world use case in a natural gym setting. We present the detailed and previously under-investigated Centre of Pressure (COP) profile of four main gym activities in terms of several COP-related metrics specifically as targets for ML-based recognition tasks. Based on this, we identify COP displacement and COP balance measures as important features for ML-based recognition of these fitness activities for future research in this area. Furthermore, we compare the performance of several ML models in the activity recognition task, achieving 98.5% recognition accuracy using ML models suitable for real-time deployment. Finally, we demonstrate the feasibility of our system in a live real-world with use case in a natural gym environment. Keywords: Multidisciplinary Topics and Applications: General Machine Learning: General},
  archive   = {C_IJCAI},
  author    = {Katia Bourahmoune and Karlos Ishac and Marc Carmichael},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/796},
  month     = {8},
  pages     = {7197-7205},
  title     = {Fitness activity recognition using a novel pressure sensing mat and machine learning for the future of accessible training},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Functional graph convolutional networks: A unified
multi-task and multi-modal learning framework to facilitate health and
social-care insights. <em>IJCAI</em>, 7188–7196. (<a
href="https://doi.org/10.24963/ijcai.2024/795">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper introduces a novel Functional Graph Convolutional Network (funGCN) framework that combines Functional Data Analysis and Graph Convolutional Networks to address the complexities of multi-task and multi-modal learning in digital health and longitudinal studies. With the growing importance of health solutions to improve health care and social support, ensure healthy lives, and promote well-being at all ages, funGCN offers a unified approach to handle multivariate longitudinal data for multiple entities and ensures interpretability even with small sample sizes. Key innovations include task-specific embedding components that manage different data types, the ability to perform classification, regression, and forecasting, and the creation of a knowledge graph for insightful data interpretation. The efficacy of funGCN is validated through simulation experiments and a real-data application. funGCN source code is publicly available at https://github.com/IBM/funGCN. Keywords: Machine Learning: General Multidisciplinary Topics and Applications: General},
  archive   = {C_IJCAI},
  author    = {Tobia Boschi and Francesca Bonin and Rodrigo Ordonez-Hurtado and Cécile Rousseau and Alessandra Pascale and John Dinsmore},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/795},
  month     = {8},
  pages     = {7188-7196},
  title     = {Functional graph convolutional networks: A unified multi-task and multi-modal learning framework to facilitate health and social-care insights},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Empathy and AI: Achieving equitable microtransit for
underserved communities. <em>IJCAI</em>, 7179–7187. (<a
href="https://doi.org/10.24963/ijcai.2024/794">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper describes a newly launched project that will produce a new approach to public microtransit for underserved communities. Public microtransit cannot rely on pricing signals to manage demand, and current approaches face the challenges of simultaneously being underutilized and overextended. This project conceives of the setting as a sociotechnical system. Its main idea is to engage users through AI agents in conjunction with platform constraints to find solutions that purely technical conceptions cannot find. The project was specified over an intense series of discussions with key stakeholders (riders, city government, and nongovernmental agencies) and brings together expertise in the disciplines of AI, Operations Research, Urban Planning, Psychology, and Community Development. The project will culminate in a pilot study, results from which will facilitate the transfer of its technology to additional communities. Keywords: Agent-based and Multi-agent Systems: General AI Ethics, Trust, Fairness: General Multidisciplinary Topics and Applications: General},
  archive   = {C_IJCAI},
  author    = {Eleni Bardaka and Pascal Van Hentenryck and Crystal Chen Lee and Christopher B. Mayhorn and Kai Monast and Samitha Samaranayake and Munindar P. Singh},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/794},
  month     = {8},
  pages     = {7179-7187},
  title     = {Empathy and AI: Achieving equitable microtransit for underserved communities},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Transfer learning using inaccurate physics rule for
streamflow prediction. <em>IJCAI</em>, 7170–7178. (<a
href="https://doi.org/10.24963/ijcai.2024/793">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Accurate streamflow prediction is critical for ensuring water supply and detecting floods, while also providing essential hydrological inputs for other scientific models in fields such as climate and agriculture. Recently, deep learning models have been shown to achieve state-of-the-art regionalization performance by building a global hydrologic model. These models predict streamflow given catchment physical characteristics and weather forcing data. However, these models are only focused on gauged basins and cannot adapt to ungaugaed basins, i.e., basins without training data. Prediction in Ungauged Basins (PUB) is considered one of the most important challenges in hydrology, as most basins in the United States and around the world have no observations. In this work, we propose a meta-transfer learning approach by enhancing imperfect physics equations that facilitate model adaptation. Intuitively, physical equations can often be used to regularize deep learning models to achieve robust regionalization performance under gauged scenarios, but they can be inaccurate due to the simplified representation of physics. We correct such uncertainty in physical equation by residual approximation and let these corrected equations guide the model training process. We evaluated the proposed method for predicting daily streamflow on the catchment attributes and meteorology for large-sample studies (CAMELS) dataset. The experiment results on hydrological data over 19 years demonstrate the effectiveness of the proposed method in ungauged scenarios. Keywords: Multidisciplinary Topics and Applications: General Data Mining: General},
  archive   = {C_IJCAI},
  author    = {Tianshu Bao and Taylor Thomas Johnson and Xiaowei Jia},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/793},
  month     = {8},
  pages     = {7170-7178},
  title     = {Transfer learning using inaccurate physics rule for streamflow prediction},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Using causal inference to investigate contraceptive
discontinuation in sub-saharan africa. <em>IJCAI</em>, 7161–7169. (<a
href="https://doi.org/10.24963/ijcai.2024/792">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Discontinuation rates vary by family planning method and across socio-economic contexts. Understanding these variations and their causes is paramount for developing and implementing policies aimed at curbing discontinuation rates. Randomized controlled trials (RCTs) are ideal for obtaining this information, but this design can be extremely expensive and logistically complex. The ongoing collection of comprehensive data sets, such as Demographic and Health Surveys (DHS data), when combined with machine learning methods, present an alternative and relatively cost-effective means of evidence gathering for policy development. Here, we use causal inference to estimate the effect of injectable contraceptive use on discontinuation over the 12-month period that follows its adoption. To that aim, we use retrospective observational data from seven sub-Saharan African countries captured by the DHS’ Contraceptive Calendar. We use machine learning methods to characterize data regions that share common covariate support. We find that the use of injectables increased the risk of discontinuation in four of the seven countries analyzed. Consistent with existing literature, we find that concerns with the side-effects of injectables appear to be the most frequent reason for discontinuation. However, these risks decreased after adjusting for socio-economic factors. As risk estimates may not apply uniformly within populations, we characterized the sub-populations for robust estimations by their geographical region, level of unmet needs, marital status, level of education, and age of first sex. Keywords: Multidisciplinary Topics and Applications: General Machine Learning: General},
  archive   = {C_IJCAI},
  author    = {Victor Akinwande and Megan MacGregor and Celia Cintas and Ehud Karavani and Dennis Wei and Kush R. Varshney and Pablo Nepomnaschy},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/792},
  month     = {8},
  pages     = {7161-7169},
  title     = {Using causal inference to investigate contraceptive discontinuation in sub-saharan africa},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Automated essay scoring using discourse external knowledge.
<em>IJCAI</em>, 7154–7160. (<a
href="https://doi.org/10.24963/ijcai.2024/791">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Automated Essay Scoring (AES) task is an important NLP research problem given its significance for the education ecosystem. Recently, researchers started to apply a hybrid approach to this task. This hybrid approach incorporates into a deep learning model expert features that assess a particular dimension of the essay. Motivated by these successes, we propose to automatically assess essays using a hybrid approach that relies on external discourse knowledge. Our proposed model consists of using transformer-based embeddings to generate semantic representations of essays. Then, we incorporate several discourse features into these representations. Finally, we apply a linear classifier to generate the final score. To evaluate the effectiveness of this approach, we have conducted extensive experiments using the Automated Student Assessment Prize dataset (ASAP). The performance of the proposed model has been evaluated using the Quadratic Weighted Kappa (QWK) metric. The experimental results demonstrate the effectiveness of this approach in comparison with several existing solutions in literature. Keywords: Natural Language Processing: General Multidisciplinary Topics and Applications: General Knowledge Representation and Reasoning: General},
  archive   = {C_IJCAI},
  author    = {Nisrine Ait Khayi and Vasile Rus},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/791},
  month     = {8},
  pages     = {7154-7160},
  title     = {Automated essay scoring using discourse external knowledge},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). CausalNET: Unveiling causal structures on event sequences
by topology-informed causal attention. <em>IJCAI</em>, 7144–7152. (<a
href="https://doi.org/10.24963/ijcai.2024/790">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Causal discovery on event sequences holds a pivotal significance across domains such as healthcare, finance, and industrial systems. The crux of this endeavor lies in unraveling causal structures among event types, typically portrayed as directed acyclic graphs (DAGs). Nonetheless, prevailing methodologies often grapple with untenable assumptions and intricate optimization hurdles. To address these challenges, we present a novel model named CausalNET. At the heart of CausalNET is a special prediction module based on the Transformer architecture, which prognosticates forthcoming events by leveraging historical occurrences, with its predictive prowess amplified by a trainable causal graph engineered to fathom causal relationships among event types. Further, to augment the predictive paradigm, we devise a causal decay matrix to encapsulate the reciprocal influence of events upon each other within the topological network. During training, we alternatively refine the prediction module and fine-tune the causal graph. Comprehensive evaluation on a spectrum of real-world and synthetic datasets underscores the superior performance and scalability of CausalNET, which marks a promising step forward in the realm of causal discovery. Code and Appendix are available at https://github.com/CGCL-codes/CausalNET. Keywords: Uncertainty in AI: UAI: Causality, structural causal models and causal inference Machine Learning: ML: Causality},
  archive   = {C_IJCAI},
  author    = {Hua Zhu and Hong Huang and Kehan Yin and Zejun Fan and Hai Jin and Bang Liu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/790},
  month     = {8},
  pages     = {7144-7152},
  title     = {CausalNET: Unveiling causal structures on event sequences by topology-informed causal attention},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Proportion-based sensitivity analysis of uncontrolled
confounding bias in causal inference. <em>IJCAI</em>, 7136–7143. (<a
href="https://doi.org/10.24963/ijcai.2024/789">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Uncontrolled confounding bias causes a spurious relationship between an exposure variable and an outcome variable and precludes reliable evaluation of the causal effect from observed data.Thus, it is important to observe a sufficient set of confounders to reliably evaluate the causal effect.However, there is no statistical method for judging whether an available set of covariates is sufficient to derive a reliable estimator for the causal effect.To address this problem, we focus on the fact that the mean squared error (MSE) of the outcome variable with respect to the average causal risk can be described as the sum of &quot;the conditional variance of the outcome variable given the exposure variable&quot; and &quot;the square of the uncontrolled confounding bias&quot;.We then propose a novel sensitivity analysis, namely, the proportion-based sensitivity analysis of uncontrolled confounding bias in causal effects (PSA) in which the sensitivity parameter is formulated as the proportion of &quot;the square of the uncontrolled confounding bias&quot; to the MSE, and we clarify some properties.We also demonstrate the applicability of the PSA through two case studies. Keywords: Uncertainty in AI: UAI: Causality, structural causal models and causal inference},
  archive   = {C_IJCAI},
  author    = {Haruka Yoshida and Manabu Kuroki},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/789},
  month     = {8},
  pages     = {7136-7143},
  title     = {Proportion-based sensitivity analysis of uncontrolled confounding bias in causal inference},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dirichlet-based uncertainty quantification for personalized
federated learning with improved posterior networks. <em>IJCAI</em>,
7127–7135. (<a href="https://doi.org/10.24963/ijcai.2024/788">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In modern federated learning, one of the main challenges is to account for inherent heterogeneity and the diverse nature of data distributions for different clients. This problem is often addressed by introducing personalization of the models towards the data distribution of the particular client. However, a personalized model might be unreliable when applied to the data that is not typical for this client. Eventually, it may perform worse for these data than the non-personalized global model trained in a federated way on the data from all the clients. This paper presents a new approach to federated learning that allows selecting a model from global and personalized ones that would perform better for a particular input point. It is achieved through a careful modeling of predictive uncertainties that helps to detect local and global in- and out-of-distribution data and use this information to select the model that is confident in a prediction. The comprehensive experimental evaluation on the popular real-world image datasets shows the superior performance of the model in the presence of out-of-distribution data while performing on par with state-of-the-art personalized federated learning algorithms in the standard scenarios. Keywords: Uncertainty in AI: UAI: Bayesian networks Machine Learning: ML: Bayesian learning Machine Learning: ML: Federated learning Machine Learning: ML: Probabilistic machine learning},
  archive   = {C_IJCAI},
  author    = {Nikita Kotelevskii and Samuel Horváth and Karthik Nandakumar and Martin Takac and Maxim Panov},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/788},
  month     = {8},
  pages     = {7127-7135},
  title     = {Dirichlet-based uncertainty quantification for personalized federated learning with improved posterior networks},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Online learning of capacity-based preference models.
<em>IJCAI</em>, 7118–7126. (<a
href="https://doi.org/10.24963/ijcai.2024/787">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In multicriteria decision making, sophisticated decision models often involve a non-additive set function (named capacity) to define the weights of all subsets of criteria. This makes it possible to model criteria interactions, leaving room for a diversity of attitudes in criteria aggregation. Fitting a capacity-based decision model to a given Decision Maker is a challenging problem and several batch learning methods have been proposed in the literature to derive the capacity from a database of preference examples. In this paper, we introduce an online algorithm for learning a sparse representation of the capacity, designed for decision contexts where preference examples become available sequentially. Our method based on regularized dual averaging is also well fitted to decision contexts involving a large number of preference examples or a large number of criteria. Moreover, we propose a variant making it possible to include normative constraints on the capacity (e.g., monotonicity, supermodularity) while preserving scalability, based on the alternating direction method of multipliers. Keywords: Uncertainty in AI: UAI: Decision and utility theory Machine Learning: ML: Learning preferences or rankings Machine Learning: ML: Online learning},
  archive   = {C_IJCAI},
  author    = {Margot Herin and Patrice Perny and Nataliya Sokolovska},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/787},
  month     = {8},
  pages     = {7118-7126},
  title     = {Online learning of capacity-based preference models},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Individual causal structure learning from population data.
<em>IJCAI</em>, 7109–7117. (<a
href="https://doi.org/10.24963/ijcai.2024/786">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Learning the causal structure of each individual plays a crucial role in neuroscience, biology, and so on. Existing methods consider data from each individual separately, which may yield inaccurate causal structure estimations in limited samples. To leverage more samples, we consider incorporating data from all individuals as population data. We observe that the variables of all individuals are influenced by the common environment variables they share. These shared environment variables can be modeled as latent variables and serve as a bridge connecting data from different individuals. In particular, we propose an Individual Linear Acyclic Model (ILAM) for each individual from population data, which models the individual&#39;s variables as being linearly influenced by their parents, in addition to environment variables and noise terms. Theoretical analysis shows that the model is identifiable when all environment variables are non-Gaussian, or even if some are Gaussian with an adequate diversity in the variance of noises for each individual. We then develop an individual causal structures learning method based on the Share Independence Component Analysis technique. Experimental results on synthetic and real-world data demonstrate the correctness of the method even when the sample size of each individual&#39;s data is small. Keywords: Uncertainty in AI: UAI: Causality, structural causal models and causal inference},
  archive   = {C_IJCAI},
  author    = {Wei Chen and Xiaokai Huang and Zijian Li and Ruichu Cai and Zhiyi Huang and Zhifeng Hao},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/786},
  month     = {8},
  pages     = {7109-7117},
  title     = {Individual causal structure learning from population data},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Anytime sorting algorithms. <em>IJCAI</em>, 7101–7108. (<a
href="https://doi.org/10.24963/ijcai.2024/785">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper addresses the anytime sorting problem, aiming to develop algorithms providing tentative estimates of the sorted list at each execution step. Comparisons are treated as steps, and the Spearman&#39;s footrule metric evaluates estimation accuracy. We propose a general approach for making any sorting algorithm anytime and introduce two new algorithms: multizip sort and Corsort. Simulations showcase the superior performance of both algorithms compared to existing methods. Multizip sort keeps a low global complexity, while Corsort produces intermediate estimates surpassing previous algorithms. Keywords: Uncertainty in AI: UAI: Decision and utility theory Uncertainty in AI: UAI: Uncertainty representations},
  archive   = {C_IJCAI},
  author    = {Emma Caizergues and François Durand and Fabien Mathieu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/785},
  month     = {8},
  pages     = {7101-7108},
  title     = {Anytime sorting algorithms},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new paradigm for counterfactual reasoning in fairness and
recourse. <em>IJCAI</em>, 7092–7100. (<a
href="https://doi.org/10.24963/ijcai.2024/784">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Counterfactuals underpin numerous techniques for auditing and understanding artificial intelligence (AI) systems. The traditional paradigm for counterfactual reasoning in this literature is the interventional counterfactual, where hypothetical interventions are imagined and simulated. For this reason, the starting point for causal reasoning about legal protections and demographic data in AI is an imagined intervention on a legally-protected characteristic, such as ethnicity, race, gender, disability, age, etc. We ask, for example, what would have happened had your race been different? An inherent limitation of this paradigm is that some demographic interventions — like interventions on race — may not be well-defined or translate into the formalisms of interventional counterfactuals. In this work, we explore a new paradigm based instead on the backtracking counterfactual, where rather than imagine hypothetical interventions on legally-protected characteristics, we imagine alternate initial conditions while holding these characteristics fixed. We ask instead, what would explain a counterfactual outcome for you as you actually are or could be? This alternate framework allows us to address many of the same social concerns, but to do so while asking fundamentally different questions that do not rely on demographic interventions. Keywords: Uncertainty in AI: UAI: Causality, structural causal models and causal inference AI Ethics, Trust, Fairness: ETF: Fairness and diversity AI Ethics, Trust, Fairness: ETF: Moral decision making Machine Learning: ML: Causality},
  archive   = {C_IJCAI},
  author    = {Lucius E.J. Bynum and Joshua R. Loftus and Julia Stoyanovich},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/784},
  month     = {8},
  pages     = {7092-7100},
  title     = {A new paradigm for counterfactual reasoning in fairness and recourse},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improved evolutionary algorithms for submodular maximization
with cost constraints. <em>IJCAI</em>, 7082–7090. (<a
href="https://doi.org/10.24963/ijcai.2024/783">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present an evolutionary algorithm evo-SMC for the problem of Submodular Maximization under Cost constraints (SMC). Our algorithm achieves 1/2-approximation with a high probability 1-1/n within O(n2 K) iterations, where K denotes the maximum size of a feasible solution set with cost constraint B. To the best of our knowledge, this is the best approximation guarantee offered by evolutionary algorithms for this problem. We further refine evo-SMC and develop st-evo-SMC. This stochastic version yields a significantly faster algorithm while maintaining the approximation ratio of 1/2, with probability 1-epsilon. The required number of iterations reduces to O(nK log(1/epsilon)/p), where the user defined parameters p represents the stochasticity probability, and epsilon denotes the error threshold. Finally, the empirical evaluations carried out through extensive experimentation substantiate the efficiency and effectiveness of our proposed algorithms. Our algorithms consistently outperform existing methods, producing higher-quality solutions. Keywords: Search: S: Evolutionary computation Machine Learning: ML: Optimization Search: S: Combinatorial search and optimisation Machine Learning: ML: Evolutionary learning},
  archive   = {C_IJCAI},
  author    = {Yanhui Zhu and Samik Basu and A. Pavan},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/783},
  month     = {8},
  pages     = {7082-7090},
  title     = {Improved evolutionary algorithms for submodular maximization with cost constraints},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Practical anytime algorithms for judicious partitioning of
active directory attack graphs. <em>IJCAI</em>, 7074–7081. (<a
href="https://doi.org/10.24963/ijcai.2024/782">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Given a directed graph, a set of source nodes, a target node and a budget, we study the problem of maximizing the number of source nodes disconnected from the target node by removing edges not exceeding the budget. Our model is mainly motivated by a cyber security use case where we need to minimize the attack surface of a Windows Active Directory system. In these high-profile attacks, the attackers first compromise a source (i.e., a compromised user node) and then laterally move to a destination (i.e., a high-privileged admin node). Our aim is to minimize the number of users with a path to the admin. We first prove that the problem is NP-hard. Algorithms for exact optimality usually struggle to converge on graphs that approach real-world network scales and therefore are not practical for usage. In light of this, we study anytime algorithms that return an acceptable result whenever the algorithm is terminated, and can improve optimality by allowing longer computational time. We observe the source connectivity of directed graphs, based on which we propose a novel anytime algorithm---the spiral algorithm. We also develop two Monte Carlo Tree Search (MCTS) algorithms as a baseline to study the performance of typical anytime algorithms for our problem, and show that the spiral algorithm improves the optimality at a significantly faster speed and therefore exhibits better anytime behavior compared with MCTS. Keywords: Search: S: Combinatorial search and optimisation Multidisciplinary Topics and Applications: MTA: Security and privacy},
  archive   = {C_IJCAI},
  author    = {Yumeng Zhang and Max Ward and Hung Nguyen},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/782},
  month     = {8},
  pages     = {7074-7081},
  title     = {Practical anytime algorithms for judicious partitioning of active directory attack graphs},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Online submodular maximization via adaptive thresholds.
<em>IJCAI</em>, 7065–7073. (<a
href="https://doi.org/10.24963/ijcai.2024/781">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Submodular function maximization has been studied extensively in recent years due to its numerous applications in machine learning and artificial intelligence. We study a natural online variant of this problem on massive streaming data in which elements arrive one-by-one and the algorithm has to maintain a solution under cardinality constraint, i.e., k. Upon arrival of an element, the algorithm to maximize a monotone submodular function has to decide whether to accept the element and may replace a previously chosen element. Existing algorithms cannot simultaneously achieve optimal performance in terms of competitive ratio, memory complexity and running time. Also, the algorithm with best competitive ratio performs poorly in practice. In this paper, we propose a new algorithm OnlineAdaptive with optimal performance by exploiting adaptive thresholds to decide the acceptance of arriving elements by replacement. We prove that the competitive ratio of OnlineAdaptive is at least 1/4, and the ratio is about 0.2959 when k&gt;=4 and approaches 0.3178 when k tends to infinity. In addition, OnlineAdaptive only needs O(k) memory and just performs one oracle per element. Experiments on diverse datasets confirm that OnlineAdaptive outperforms existing algorithms in both quality and efficiency. Keywords: Search: S: Combinatorial search and optimisation Search: S: Heuristic search},
  archive   = {C_IJCAI},
  author    = {Zhengchen Yang and Jiping Zheng},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/781},
  month     = {8},
  pages     = {7065-7073},
  title     = {Online submodular maximization via adaptive thresholds},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exactly solving minimum dominating set and its
generalization. <em>IJCAI</em>, 7056–7064. (<a
href="https://doi.org/10.24963/ijcai.2024/780">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Minimum Dominating Set Problem (MDSP) is an important NP-Hard optimization problem with many applications in various domains. This paper designs two exact algorithms for MDSP that use the same Branch-and-Bound framework. However, one uses LP relaxations as lower bounds for pruning the search space, and the other one is a pure combinatorial algorithm. The two algorithms possess a distinct advantage. Performance experiments on standard test datasets reveal that our combinatorial algorithm is over 1000 times faster than the previous state-of-the-art exact algorithm presented in IJCAI 2023, and our LP Relaxation algorithm can even enhance the speed of our combinatorial algorithm by over 100 times. However, our combinatorial algorithm still outperform the LP Relaxation algorithm on very dense graphs. Keywords: Search: S: Combinatorial search and optimisation},
  archive   = {C_IJCAI},
  author    = {Ziliang Xiong and Mingyu Xiao},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/780},
  month     = {8},
  pages     = {7056-7064},
  title     = {Exactly solving minimum dominating set and its generalization},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A swap relaxation-based local search for the latin square
completion problem. <em>IJCAI</em>, 7047–7055. (<a
href="https://doi.org/10.24963/ijcai.2024/779">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Latin square completion (LSC) problem aims to assign n symbols to the empty cells of a partially filled Latin square such that in each row and each column, each symbol appears exactly once. In this paper, we propose a swap relaxation-based fast local search algorithm called SRLS for solving the LSC problem. First, it introduces a novel search space definition, which forbids row conflicts based on which a swap-based neighborhood is defined. Second, a color domain relaxation technique is employed in the swap-based neighborhood by temporarily accepting the violation of some constraints to connect high-quality solutions. Third, two effective scoring functions are adopted to select neighborhood moves minimizing the number of conflicting edges as well as the number of color domain violations. Finally, SRLS employs an adaptive restart mechanism to balance the exploitation and exploration of the search. Extensive experiments on 1819 public benchmark instances demonstrate that SRLS outperforms the state-of-the-art algorithms in the literature in terms of both success rate and computational efficiency. Keywords: Search: S: Local search Search: S: Heuristic search Search: S: Meta-reasoning and meta-heuristics Search: S: Combinatorial search and optimisation},
  archive   = {C_IJCAI},
  author    = {Zhenxuan Xie and Zhipeng Lü and Zhouxing Su and Chu-Min Li and Junwen Ding and Yuxuan Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/779},
  month     = {8},
  pages     = {7047-7055},
  title     = {A swap relaxation-based local search for the latin square completion problem},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ReinforceNS: Reinforcement learning-based multi-start
neighborhood search for solving the traveling thief problem.
<em>IJCAI</em>, 7038–7046. (<a
href="https://doi.org/10.24963/ijcai.2024/778">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Traveling Thief Problem (TTP) is a challenging combinatorial optimization problem with broad practical applications. TTP combines two NP-hard problems: the Traveling Salesman Problem (TSP) and Knapsack Problem (KP). While a number of machine learning and deep learning based algorithms have been developed for TSP and KP, there is limited research dedicated to TTP. In this paper, we present the first reinforcement learning based multi-start neighborhood search algorithm, denoted by ReinforceNS, for solving TTP. To accelerate the search, we employ a pre-processing procedure for neighborhood reduction. A TSP routing and an iterated greedy packing are independently utilized to construct a high-quality initial solution, further improved by a reinforcement learning based neighborhood search. Additionally, a post-optimization procedure is devised for continued solution improvement. We conduct extensive experiments on 60 commonly used benchmark instances with 76 to 33810 cities in the literature. The experimental results demonstrate that our proposed ReinforceNS algorithm outperforms three state-of-the-art algorithms in terms of solution quality with the same time limit. In particular, ReinforceNS achieves 12 new results for 18 instances publicly reported in a recent TTP competition. We also perform an additional experiment to validate the effectiveness of the reinforcement learning strategy. Keywords: Search: S: Search and machine learning Machine Learning: ML: Reinforcement learning Search: S: Heuristic search},
  archive   = {C_IJCAI},
  author    = {Tao Wu and Huachao Cui and Tao Guan and Yuesong Wang and Yan Jin},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/778},
  month     = {8},
  pages     = {7038-7046},
  title     = {ReinforceNS: Reinforcement learning-based multi-start neighborhood search for solving the traveling thief problem},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Nukplex: An efficient local search algorithm for maximum
k-plex problem. <em>IJCAI</em>, 7029–7037. (<a
href="https://doi.org/10.24963/ijcai.2024/777">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The maximum k-plex problem (MKPP) is an significant relaxation version of the maximum clique problem with extensive applications. Recently, lots of researchers have proposed many heuristic algorithms based on various methods to solve the MKPP. In this work, to further improve the performance of solving the MKPP, we propose an efficient local search algorithm based on three main ideas. First, we propose a relaxed bounded configuration checking strategy that considers two kinds of historical searching information to relax the restricted strength of configuration checking and the forbidden condition of candidate vertices for the operation Add, respectively. Second, we present a novel solution information-based vertex selection strategy based on two kinds of solution information to select high-quality candidate vertices. Third, we define the solution core and then introduce a core-based perturbation strategy to help the algorithm jump out of local optima. The experimental results show that the proposed algorithm significantly outperforms the state-of-the-art MKPP algorithms in almost all the instances. Keywords: Search: S: Local search Search: S: Heuristic search},
  archive   = {C_IJCAI},
  author    = {Rui Sun and Yiyuan Wang and Shimao Wang and Hui Li and Ximing Li and Minghao Yin},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/777},
  month     = {8},
  pages     = {7029-7037},
  title     = {Nukplex: An efficient local search algorithm for maximum K-plex problem},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Theoretical study on multi-objective heuristic search.
<em>IJCAI</em>, 7021–7028. (<a
href="https://doi.org/10.24963/ijcai.2024/776">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper provides a theoretical study on Multi-Objective Heuristic Search. We first classify states in the state space into must-expand, maybe-expand, and never-expand states and then transfer these definitions to nodes in the search tree. We then formalize a framework that generalizes A* to Multi-Objective Search. We study different ways to order nodes under this framework and their relation to traditional tie-breaking policies and provide theoretical findings. Finally, we study and empirically compare different ordering functions. Keywords: Search: S: Heuristic search Search: S: Other Search: General},
  archive   = {C_IJCAI},
  author    = {Shawn Skyler and Shahaf Shperberg and Dor Atzmon and Ariel Felner and Oren Salzman and Shao-Hung Chan and Han Zhang and Sven Koenig and William Yeoh and Carlos Hernandez Ulloa},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/776},
  month     = {8},
  pages     = {7021-7028},
  title     = {Theoretical study on multi-objective heuristic search},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Maintaining diversity provably helps in evolutionary
multimodal optimization. <em>IJCAI</em>, 7012–7020. (<a
href="https://doi.org/10.24963/ijcai.2024/775">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the real world, there exist a class of optimization problems that multiple (local) optimal solutions in the solution space correspond to a single point in the objective space. In this paper, we theoretically show that for such multimodal problems, a simple method that considers the diversity of solutions in the solution space can benefit the search in evolutionary algorithms (EAs). Specifically, we prove that the proposed method, working with crossover, can help enhance the exploration, leading to polynomial or even exponential acceleration on the expected running time. This result is derived by rigorous running time analysis in both single-objective and multi-objective scenarios, including (mu+1)-GA solving the widely studied single-objective problem, Jump, and NSGA-II and SMS-EMOA (two well-established multi-objective EAs) solving the widely studied bi-objective problem, OneJumpZeroJump. Experiments are also conducted to validate the theoretical results. We hope that our results may encourage the exploration of diversity maintenance in the solution space for multi-objective optimization, where existing EAs usually only consider the diversity in the objective space and can easily be trapped in local optima. Keywords: Search: S: Evolutionary computation},
  archive   = {C_IJCAI},
  author    = {Shengjie Ren and Zhijia Qiu and Chao Bian and Miqing Li and Chao Qian},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/775},
  month     = {8},
  pages     = {7012-7020},
  title     = {Maintaining diversity provably helps in evolutionary multimodal optimization},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Expected work search: Combining win rate and proof size
estimation. <em>IJCAI</em>, 7003–7011. (<a
href="https://doi.org/10.24963/ijcai.2024/774">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose Expected Work Search (EWS), a new game solving algorithm. EWS combines win rate estimation, as used in Monte Carlo Tree Search, with proof size estimation, as used in Proof Number Search. The search efficiency of EWS stems from minimizing a novel notion of Expected Work, which predicts the expected computation required to solve a position. EWS outperforms traditional solving algorithms on the games of Go and Hex. For Go, we present the first solution to the empty 5x5 board with the commonly used positional superko ruleset. For Hex, our algorithm solves the empty 8x8 board in under 4 minutes. Experiments show that EWS succeeds both with and without extensive domain-specific knowledge. Keywords: Search: S: Heuristic search Search: S: Applications Search: S: Game playing},
  archive   = {C_IJCAI},
  author    = {Owen Randall and Martin Müller and Ting-Han Wei and Ryan Hayward},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/774},
  month     = {8},
  pages     = {7003-7011},
  title     = {Expected work search: Combining win rate and proof size estimation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Quality-diversity algorithms can provably be helpful for
optimization. <em>IJCAI</em>, 6994–7002. (<a
href="https://doi.org/10.24963/ijcai.2024/773">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Quality-Diversity (QD) algorithms are a new type of Evolutionary Algorithms (EAs), aiming to find a set of high-performing, yet diverse solutions. They have found many successful applications in reinforcement learning and robotics, helping improve the robustness in complex environments. Furthermore, they often empirically find a better overall solution than traditional search algorithms which explicitly search for a single highest-performing solution. However, their theoretical analysis is far behind, leaving many fundamental questions unexplored. In this paper, we try to shed some light on the optimization ability of QD algorithms via rigorous runtime analysis. By comparing the popular QD algorithm MAP-Elites with (\mu+1)-EA (a typical EA focusing on finding better objective values only), we prove that on two NP-hard problem classes with wide applications, i.e., monotone approximately submodular maximization with a size constraint, and set cover, MAP-Elites can achieve the (asymptotically) optimal polynomial-time approximation ratio, while (\mu+1)-EA requires exponential expected time on some instances. This provides theoretical justification for that QD algorithms can be helpful for optimization, and discloses that the simultaneous search for high-performing solutions with diverse behaviors can provide stepping stones to good overall solutions and help avoid local optima. Keywords: Search: S: Evolutionary computation},
  archive   = {C_IJCAI},
  author    = {Chao Qian and Ke Xue and Ren-Jian Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/773},
  month     = {8},
  pages     = {6994-7002},
  title     = {Quality-diversity algorithms can provably be helpful for optimization},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Finding increasingly large extremal graphs with AlphaZero
and tabu search. <em>IJCAI</em>, 6985–6993. (<a
href="https://doi.org/10.24963/ijcai.2024/772">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This work proposes a new learning-to-search benchmark and uses AI to discover new mathematical knowledge related to an open conjecture of Erdos (1975) in extremal graph theory. The problem is to find graphs with a given size (number of nodes) that maximize the number of edges without having 3- or 4-cycles. We formulate this as a sequential decision-making problem and compare AlphaZero, a neural network-guided tree search, with tabu search, a heuristic local search method. Using either method, by introducing a curriculum---jump-starting the search for larger graphs using good graphs found at smaller sizes---we improve the state-of-the-art lower bounds for several sizes. We also propose a flexible graph-generation environment and a permutation-invariant network architecture for learning to search in the space of graphs. Keywords: Search: S: Search and machine learning Multidisciplinary Topics and Applications: MTA: Other Search: S: Local search Search: S: Combinatorial search and optimisation},
  archive   = {C_IJCAI},
  author    = {Abbas Mehrabian and Ankit Anand and Hyunjik Kim and Nicolas Sonnerat and Matej Balog and Gheorghe Comanici and Tudor Berariu and Andrew Lee and Anian Ruoss and Anna Bulanova and Daniel Toyama and Sam Blackwell and Bernardino Romera Paredes and Petar Veličković and Laurent Orseau and Joonkyung Lee and Anurag Murty Naredla and Doina Precup and Adam Zsolt Wagner},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/772},
  month     = {8},
  pages     = {6985-6993},
  title     = {Finding increasingly large extremal graphs with AlphaZero and tabu search},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Prompt learning for generalized vehicle routing.
<em>IJCAI</em>, 6976–6984. (<a
href="https://doi.org/10.24963/ijcai.2024/771">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Neural combinatorial optimization (NCO) is a promising learning-based approach to solving various vehicle routing problems without much manual algorithm design. However, the current NCO methods mainly focus on the in-distribution performance, while the real-world problem instances usually come from different distributions. A costly fine-tuning approach or generalized model retraining from scratch could be needed to tackle the out-of-distribution instances. Unlike the existing methods, this work investigates an efficient prompt learning approach in NCO for cross-distribution adaptation. To be concrete, we propose a novel prompt learning method to facilitate fast zero-shot adaptation of a pre-trained model to solve routing problem instances from different distributions. The proposed model learns a set of prompts among various distributions and then selects the best-matched one to prompt a pre-trained attention model for each problem instance. Extensive experiments show that the proposed prompt learning approach facilitates the fast adaptation of pre-trained routing models. It also outperforms existing generalized models on both in-distribution prediction and zero-shot generalization to a diverse set of new tasks. Our code implementation is available online at https://github.com/FeiLiu36/PromptVRP. Keywords: Search: S: Search and machine learning Machine Learning: ML: Applications Search: S: Combinatorial search and optimisation},
  archive   = {C_IJCAI},
  author    = {Fei Liu and Xi Lin and Weiduo Liao and Zhenkun Wang and Qingfu Zhang and Xialiang Tong and Mingxuan Yuan},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/771},
  month     = {8},
  pages     = {6976-6984},
  title     = {Prompt learning for generalized vehicle routing},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Peptide vaccine design by evolutionary multi-objective
optimization. <em>IJCAI</em>, 6967–6975. (<a
href="https://doi.org/10.24963/ijcai.2024/770">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Peptide vaccines are growing in significance for fighting diverse diseases. Machine learning has improved the identification of peptides that can trigger immune responses, and the main challenge of peptide vaccine design now lies in selecting an effective subset of peptides due to the allelic diversity among individuals. Previous works mainly formulated this task as a constrained optimization problem, aiming to maximize the expected number of peptide-Major Histocompatibility Complex (peptide-MHC) bindings across a broad range of populations by selecting a subset of diverse peptides with limited size; and employed a greedy algorithm, whose performance, however, may be limited due to the greedy nature. In this paper, we propose a new framework PVD-EMO based on Evolutionary Multi-objective Optimization, which reformulates Peptide Vaccine Design as a bi-objective optimization problem that maximizes the expected number of peptide-MHC bindings and minimizes the number of selected peptides simultaneously, and employs a Multi-Objective Evolutionary Algorithm (MOEA) to solve it. We also incorporate warm-start and repair strategies into MOEAs to improve efficiency and performance. We prove that the warm-start strategy ensures that PVD-EMO maintains the same worst-case approximation guarantee as the previous greedy algorithm, and meanwhile, the EMO framework can help avoid local optima. Experiments on a peptide vaccine design for COVID-19, caused by the SARS-CoV-2 virus, demonstrate the superiority of PVD-EMO. Keywords: Search: S: Evolutionary computation Multidisciplinary Topics and Applications: MTA: Health and medicine Search: S: Applications},
  archive   = {C_IJCAI},
  author    = {Dan-Xuan Liu and Yi-Heng Xu and Chao Qian},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/770},
  month     = {8},
  pages     = {6967-6975},
  title     = {Peptide vaccine design by evolutionary multi-objective optimization},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cross-problem learning for solving vehicle routing problems.
<em>IJCAI</em>, 6958–6966. (<a
href="https://doi.org/10.24963/ijcai.2024/769">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Existing neural heuristics often train a deep architecture from scratch for each specific vehicle routing problem (VRP), ignoring the transferable knowledge across different VRP variants. This paper proposes the cross-problem learning to assist heuristics training for different downstream VRP variants. Particularly, we modularize neural architectures for complex VRPs into 1) the backbone Transformer for tackling the travelling salesman problem (TSP), and 2) the additional lightweight modules for processing problem-specific features in complex VRPs. Accordingly, we propose to pre-train the backbone Transformer for TSP, and then apply it in the process of fine-tuning the Transformer models for each target VRP variant. On the one hand, we fully fine-tune the trained backbone Transformer and problem-specific modules simultaneously. On the other hand, we only fine-tune small adapter networks along with the modules, keeping the backbone Transformer still. Extensive experiments on typical VRPs substantiate that 1) the full fine-tuning achieves significantly better performance than the one trained from scratch, and 2) the adapter-based fine-tuning also delivers comparable performance while being notably parameter-efficient. Furthermore, we empirically demonstrate the favorable effect of our method in terms of cross-distribution application and versatility. Keywords: Search: S: Search and machine learning Machine Learning: ML: Applications Search: S: Combinatorial search and optimisation},
  archive   = {C_IJCAI},
  author    = {Zhuoyi Lin and Yaoxin Wu and Bangjian Zhou and Zhiguang Cao and Wen Song and Yingqian Zhang and Senthilnath Jayavelu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/769},
  month     = {8},
  pages     = {6958-6966},
  title     = {Cross-problem learning for solving vehicle routing problems},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ParaILP: A parallel local search framework for integer
linear programming with cooperative evolution mechanism. <em>IJCAI</em>,
6949–6957. (<a href="https://doi.org/10.24963/ijcai.2024/768">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The integer linear programming (ILP) problem is a fundamental research topic in operations research, and the local search method is an important class of algorithms for quickly solving many combinatorial optimization problems. With rapidly increasing computing power, parallelism turns out to be a promising approach to enhancing the efficiency of problem-solving. However, rare studies investigate parallel local search algorithms for solving the general ILP problem. We propose the first parallel local search framework (ParaILP) for solving the general ILP problem, based on two novel ideas: a new initialization method named polarity initialization to construct different initial solutions for local search threads and a cooperative evolution mechanism for managing and generating high-quality solutions using information shared by different threads. Extensive experiments demonstrate that ParaILP is significantly better than the state-of-the-art academic parallel solvers FiberSCIP and HiGHS, and is competitive with the state-of-the-art commercial parallel solver Gurobi. Experiments are also conducted to analyze the parallelization scalability and the effectiveness of our techniques. Keywords: Search: S: Local search Search: S: Evolutionary computation},
  archive   = {C_IJCAI},
  author    = {Peng Lin and Mengchuan Zou and Zhihan Chen and Shaowei Cai},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/768},
  month     = {8},
  pages     = {6949-6957},
  title     = {ParaILP: A parallel local search framework for integer linear programming with cooperative evolution mechanism},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Concentration tail-bound analysis of coevolutionary and
bandit learning algorithms. <em>IJCAI</em>, 6940–6948. (<a
href="https://doi.org/10.24963/ijcai.2024/767">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Runtime analysis, as a branch of the theory of AI, studies how the number of iterations algorithms take before finding a solution (its runtime) depends on the design of the algorithm and the problem structure. Drift analysis is a state-of-the-art tool for estimating the runtime of randomised algorithms, such as bandit and evolutionary algorithms. Drift refers roughly to the expected progress towards the optimum per iteration. This paper considers the problem of deriving concentration tail-bounds on the runtime of algorithms. It provides a novel drift theorem that gives precise exponential tail-bounds given positive, weak, zero and even negative drift. Previously, such exponential tail bounds were missing in the case of weak, zero, or negative drift. Our drift theorem can be used to prove a strong concentration of the runtime/regret of algorithms in AI. For example, we prove that the regret of the RWAB bandit algorithm is highly concentrated, while previous analyses only considered the expected regret. This means that the algorithm obtains the optimum within a given time frame with high probability, i.e. a form of algorithm reliability. Moreover, our theorem implies that the time needed by the co-evolutionary algorithm RLS-PD to obtain a Nash equilibrium in a Bilinear max-min-benchmark problem is highly concentrated. However, we also prove that the algorithm forgets the Nash equilibrium, and the time until this occurs is highly concentrated. This highlights a weakness in the RLS-PD which should be addressed by future work. Keywords: Search: S: Evolutionary computation Search: S: Heuristic search Search: S: Other},
  archive   = {C_IJCAI},
  author    = {Per Kristian Lehre and Shishen Lin},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/767},
  month     = {8},
  pages     = {6940-6948},
  title     = {Concentration tail-bound analysis of coevolutionary and bandit learning algorithms},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MARCO: A memory-augmented reinforcement framework for
combinatorial optimization. <em>IJCAI</em>, 6931–6939. (<a
href="https://doi.org/10.24963/ijcai.2024/766">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Neural Combinatorial Optimization (NCO) is an emerging domain where deep learning techniques are employed to address combinatorial optimization problems as a standalone solver. Despite their potential, existing NCO methods often suffer from inefficient search space exploration, frequently leading to local optima entrapment or redundant exploration of previously visited states. This paper introduces a versatile framework, referred to as Memory-Augmented Reinforcement for Combinatorial Optimization (MARCO), that can be used to enhance both constructive and improvement methods in NCO through an innovative memory module. MARCO stores data collected throughout the optimization trajectory and retrieves contextually relevant information at each state. This way, the search is guided by two competing criteria: making the best decision in terms of the quality of the solution and avoiding revisiting already explored solutions. This approach promotes a more efficient use of the available optimization budget. Moreover, thanks to the parallel nature of NCO models, several search threads can run simultaneously, all sharing the same memory module, enabling an efficient collaborative exploration. Empirical evaluations, carried out on the maximum cut, maximum independent set and travelling salesman problems, reveal that the memory module effectively increases the exploration, enabling the model to discover diverse, higher-quality solutions. MARCO achieves good performance in a low computational cost, establishing a promising new direction in the field of NCO. Keywords: Search: S: Combinatorial search and optimisation Search: S: Search and machine learning},
  archive   = {C_IJCAI},
  author    = {Andoni I. Garmendia and Quentin Cappart and Josu Ceberio and Alexander Mendiburu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/766},
  month     = {8},
  pages     = {6931-6939},
  title     = {MARCO: A memory-augmented reinforcement framework for combinatorial optimization},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Feedback-based adaptive crossover-rate in evolutionary
computation. <em>IJCAI</em>, 6923–6930. (<a
href="https://doi.org/10.24963/ijcai.2024/765">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose a novel approach to improve multi-objective evolutionary algorithms by modifying crossover operations. Our approach uses a modifiable cross distribution and virtual point to rebalance the probability distribution of all crossover options. This design reduces runtime for typical pseudo-Boolean functions. Experiments and analysis show our approach effectively optimizes bi-objective problems COCZ and LOTZ in Θ(n) time during crossover, outperforming conventional crossover multi-objective evolutionary algorithms (C-MOEA) which require O(n log n) steps. For the tri-objective problem Hierarchical-COCZ, our approach guarantees an expected runtime of Θ(n2 log n), while C-MOEA needs at least Ω(n2 log n) and at most O(n2 log2 n) steps. Keywords: Search: S: Evolutionary computation Machine Learning: ML: Evolutionary learning},
  archive   = {C_IJCAI},
  author    = {Xiaoyuan Guan and Tianyi Yang and Chunliang Zhao and Yuren Zhou},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/765},
  month     = {8},
  pages     = {6923-6930},
  title     = {Feedback-based adaptive crossover-rate in evolutionary computation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards generalizable neural solvers for vehicle routing
problems via ensemble with transferrable local policy. <em>IJCAI</em>,
6914–6922. (<a href="https://doi.org/10.24963/ijcai.2024/764">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Machine learning has been adapted to help solve NP-hard combinatorial optimization problems. One prevalent way is learning to construct solutions by deep neural networks, which has been receiving more and more attention due to the high efficiency and less requirement for expert knowledge. However, many neural construction methods for Vehicle Routing Problems~(VRPs) focus on synthetic problem instances with specified node distributions and limited scales, leading to poor performance on real-world problems which usually involve complex and unknown node distributions together with large scales. To make neural VRP solvers more practical, we design an auxiliary policy that learns from the local transferable topological features, named local policy, and integrate it with a typical construction policy (which learns from the global information of VRP instances) to form an ensemble policy. With joint training, the aggregated policies perform cooperatively and complementarily to boost generalization. The experimental results on two well-known benchmarks, TSPLIB and CVRPLIB, of travelling salesman problem and capacitated VRP show that the ensemble policy significantly improves both cross-distribution and cross-scale generalization performance, and even performs well on real-world problems with several thousand nodes. Keywords: Search: S: Search and machine learning Machine Learning: ML: Reinforcement learning Search: S: Combinatorial search and optimisation},
  archive   = {C_IJCAI},
  author    = {Chengrui Gao and Haopu Shang and Ke Xue and Dong Li and Chao Qian},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/764},
  month     = {8},
  pages     = {6914-6922},
  title     = {Towards generalizable neural solvers for vehicle routing problems via ensemble with transferrable local policy},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An archive can bring provable speed-ups in multi-objective
evolutionary algorithms. <em>IJCAI</em>, 6905–6913. (<a
href="https://doi.org/10.24963/ijcai.2024/763">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the area of multi-objective evolutionary algorithms (MOEAs), there is a trend of using an archive to store non-dominated solutions generated during the search. This is because 1) MOEAs may easily end up with the final population containing inferior solutions that are dominated by other solutions discarded during the search process and 2) the population that has a commensurable size of the problem&#39;s Pareto front is often not practical. In this paper, we theoretically show, for the first time, that using an archive can guarantee speed-ups for MOEAs. Specifically, we prove that for two well-established MOEAs (NSGA-II and SMS-EMOA) on two commonly studied problems (OneMinMax and LeadingOnesTrailingZeroes), using an archive brings a polynomial acceleration on the expected running time. The reason is that with an archive, the size of the population can reduce to a small constant; there is no need for the population to keep all the Pareto optimal solutions found. This contrasts existing theoretical studies for MOEAs where a population with a commensurable size of the problem&#39;s Pareto front is needed. The findings in this paper not only provide a theoretical confirmation for an increasingly popular practice in the design of MOEAs, but can also be beneficial to the theory community towards studying more practical MOEAs. Keywords: Search: S: Evolutionary computation},
  archive   = {C_IJCAI},
  author    = {Chao Bian and Shengjie Ren and Miqing Li and Chao Qian},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/763},
  month     = {8},
  pages     = {6905-6913},
  title     = {An archive can bring provable speed-ups in multi-objective evolutionary algorithms},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ClothPPO: A proximal policy optimization enhancing framework
for robotic cloth manipulation with observation-aligned action spaces.
<em>IJCAI</em>, 6895–6903. (<a
href="https://doi.org/10.24963/ijcai.2024/762">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Vision-based robotic cloth unfolding has made great progress recently. However, prior works predominantly rely on value learning and have not fully explored policy-based techniques. Recently, the success of reinforcement learning on the large language model has shown that the policy gradient algorithm can enhance policy with huge action space. In this paper, we introduce ClothPPO, a framework that employs a policy gradient algorithm based on actor-critic architecture to enhance a pre-trained model with huge 10^6 action spaces aligned with observation in the task of unfolding clothes. To this end, we redefine the cloth manipulation problem as a partially observable Markov decision process. A supervised pre-training stage is employed to train a baseline model of our policy. In the second stage, the Proximal Policy Optimization (PPO) is utilized to guide the supervised model within the observation-aligned action space. By optimizing and updating the strategy, our proposed method increases the garment&#39;s surface area for cloth unfolding under the soft-body manipulation task. Experimental results show that our proposed framework can further improve the unfolding performance of other state-of-the-art methods. Our project is available at https://vpx-ecnu.github.io/ClothPPO-website/. Keywords: Robotics: ROB: Learning in robotics Robotics: ROB: Manipulation Robotics: ROB: Perception Machine Learning: ML: Reinforcement learning},
  archive   = {C_IJCAI},
  author    = {Libing Yang and Yang Li and Long Chen},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/762},
  month     = {8},
  pages     = {6895-6903},
  title     = {ClothPPO: A proximal policy optimization enhancing framework for robotic cloth manipulation with observation-aligned action spaces},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MAS-SAM: Segment any marine animal with aggregated features.
<em>IJCAI</em>, 6886–6894. (<a
href="https://doi.org/10.24963/ijcai.2024/761">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, Segment Anything Model (SAM) shows exceptional performance in generating high-quality object masks and achieving zero-shot image segmentation. However, as a versatile vision model, SAM is primarily trained with large-scale natural light images. In underwater scenes, it exhibits substantial performance degradation due to the light scattering and absorption. Meanwhile, the simplicity of the SAM&#39;s decoder might lead to the loss of fine-grained object details. To address the above issues, we propose a novel feature learning framework named MAS-SAM for marine animal segmentation, which involves integrating effective adapters into the SAM&#39;s encoder and constructing a pyramidal decoder. More specifically, we first build a new SAM&#39;s encoder with effective adapters for underwater scenes. Then, we introduce a Hypermap Extraction Module (HEM) to generate multi-scale features for a comprehensive guidance. Finally, we propose a Progressive Prediction Decoder (PPD) to aggregate the multi-scale features and predict the final segmentation results. When grafting with the Fusion Attention Module (FAM), our method enables to extract richer marine information from global contextual cues to fine-grained local details. Extensive experiments on four public MAS datasets demonstrate that our MAS-SAM can obtain better results than other typical segmentation methods. The source code is available at https://github.com/Drchip61/MAS-SAM. Keywords: Robotics: ROB: Applications Robotics: ROB: Perception Robotics: ROB: Robotics and vision},
  archive   = {C_IJCAI},
  author    = {Tianyu Yan and Zifu Wan and Xinhao Deng and Pingping Zhang and Yang Liu and Huchuan Lu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/761},
  month     = {8},
  pages     = {6886-6894},
  title     = {MAS-SAM: Segment any marine animal with aggregated features},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). DVPE: Divided view position embedding for multi-view 3D
object detection. <em>IJCAI</em>, 6877–6885. (<a
href="https://doi.org/10.24963/ijcai.2024/760">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Sparse query-based paradigms have achieved significant success in multi-view 3D detection for autonomous vehicles. Current research faces challenges in balancing between enlarging receptive fields and reducing interference when aggregating multi-view features. Moreover, different poses of cameras present challenges in training global attention models. To address these problems, this paper proposes a divided view method, in which features are modeled globally via the visibility cross-attention mechanism, but interact only with partial features in a divided local virtual space. This effectively reduces interference from other irrelevant features and alleviates the training difficulties of the transformer by decoupling the position embedding from camera poses. Additionally, 2D historical RoI features are incorporated into the object-centric temporal modeling to utilize high-level visual semantic information. The model is trained using a one-to-many assignment strategy to facilitate stability. Our framework, named DVPE, achieves state-of-the-art performance (57.2% mAP and 64.5% NDS) on the nuScenes test set.Codes will be available at https://github.com/dop0/DVPE. Keywords: Robotics: ROB: Robotics and vision Computer Vision: CV: 3D computer vision Computer Vision: CV: Recognition (object detection, categorization) Robotics: ROB: Perception},
  archive   = {C_IJCAI},
  author    = {Jiasen Wang and Zhenglin Li and Ke Sun and Xianyuan Liu and Yang Zhou},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/760},
  month     = {8},
  pages     = {6877-6885},
  title     = {DVPE: Divided view position embedding for multi-view 3D object detection},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new guaranteed outlier removal method based on plane
constraints for large-scale LiDAR point cloud registration.
<em>IJCAI</em>, 6868–6876. (<a
href="https://doi.org/10.24963/ijcai.2024/759">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we present a novel registration method based on plane constraints for large-scale LiDAR point clouds, effectively decoupling rotation estimation and translation estimation. For rotation estimation, we propose an outlier removal method that combines coarse filtering with rotation-invariant constraints and refined filtering based on computational geometric consistency checks, effectively pruning outliers and robustly estimating accurate relative rotations from plane normals. In translation estimation, we propose a component-wise method based on plane translation constraints to efficiently estimate relative translations. The robustness and effectiveness of our proposed method are empirically validated on three popular LiDAR point cloud datasets. The experimental results convincingly demonstrate that our approach achieves state-of-the-art performance. Keywords: Robotics: ROB: Robotics and vision Computer Vision: CV: 3D computer vision Computer Vision: CV: Scene analysis and understanding Robotics: ROB: Perception},
  archive   = {C_IJCAI},
  author    = {Gang Ma and Hui Wei and Runfeng Lin and Jialiang Wu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/759},
  month     = {8},
  pages     = {6868-6876},
  title     = {A new guaranteed outlier removal method based on plane constraints for large-scale LiDAR point cloud registration},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). RealDex: Towards human-like grasping for robotic dexterous
hand. <em>IJCAI</em>, 6859–6867. (<a
href="https://doi.org/10.24963/ijcai.2024/758">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we introduce RealDex, a pioneering dataset capturing authentic dexterous hand grasping motions infused with human behavioral patterns, enriched by multi-view and multimodal visual data. Utilizing a teleoperation system, we seamlessly synchronize human-robot hand poses in real time. This collection of human-like motions is crucial for training dexterous hands to mimic human movements more naturally and precisely. RealDex holds immense promise in advancing humanoid robot for automated perception, cognition, and manipulation in real-world scenarios. Moreover, we introduce a cutting-edge dexterous grasping motion generation framework, which aligns with human experience and enhances real-world applicability through effectively utilizing Multimodal Large Language Models. Extensive experiments have demonstrated the superior performance of our method on RealDex and other open datasets. The dataset and associated code are available at https://4dvlab.github.io/RealDex_page/. Keywords: Robotics: ROB: Learning in robotics Robotics: ROB: Manipulation Robotics: ROB: Robotics and vision},
  archive   = {C_IJCAI},
  author    = {Yumeng Liu and Yaxun Yang and Youzhuo Wang and Xiaofei Wu and Jiamin Wang and Yichen Yao and Sören Schwertfeger and Sibei Yang and Wenping Wang and Jingyi Yu and Xuming He and Yuexin Ma},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/758},
  month     = {8},
  pages     = {6859-6867},
  title     = {RealDex: Towards human-like grasping for robotic dexterous hand},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). HVOFusion: Incremental mesh reconstruction using hybrid
voxel octree. <em>IJCAI</em>, 6850–6858. (<a
href="https://doi.org/10.24963/ijcai.2024/757">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Incremental scene reconstruction is essential to the navigation in robotics. Most of the conventional methods typically make use of either TSDF (truncated signed distance functions) volume or neural networks to implicitly represent the surface. Due to the voxel representation or involving with time-consuming sampling, they have difficulty in balancing speed, memory storage, and surface quality. In this paper, we propose a novel hybrid voxel-octree approach to effectively fuse octree with voxel structures so that we can take advantage of both implicit surface and explicit triangular mesh representation. Such sparse structure preserves triangular faces in the leaf nodes and produces partial meshes sequentially for incremental reconstruction. This storage scheme allows us to naturally optimize the mesh in explicit 3D space to achieve higher surface quality. We iteratively deform the mesh towards the target and recovers vertex colors by optimizing a shading model. Experimental results on several datasets show that our proposed approach is capable of quickly and accurately reconstructing a scene with realistic colors. Code is available at https://github.com/Frankuzi/HVOFusion Keywords: Robotics: ROB: Localization, mapping, state estimation Computer Vision: CV: 3D computer vision Computer Vision: CV: Applications Robotics: ROB: Robotics and vision},
  archive   = {C_IJCAI},
  author    = {Shaofan Liu and Junbo Chen and Jianke Zhu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/757},
  month     = {8},
  pages     = {6850-6858},
  title     = {HVOFusion: Incremental mesh reconstruction using hybrid voxel octree},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Physics-informed trajectory prediction for autonomous
driving under missing observation. <em>IJCAI</em>, 6841–6849. (<a
href="https://doi.org/10.24963/ijcai.2024/756">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper introduces a novel trajectory prediction approach for autonomous vehicles (AVs), adeptly addressing the challenges of missing observations and the need for adherence to physical laws in real-world driving environments. This study proposes a hierarchical two-stage trajectory prediction model for AVs. In the first stage we propose the Wavelet Reconstruction Network, an innovative tool expertly crafted for reconstructing missing observations, offering optional integration with state-of-the-art models to enhance their robustness. Additionally, the second stage of the model features the Wave Fusion Encoder, a quantum mechanics-inspired innovation for sophisticated vehicle interaction modeling. By incorporating the Kinematic Bicycle Model, we ensure that our predictions align with realistic vehicular kinematics. Complementing our methodological advancements, we introduce MoCAD-missing, a comprehensive real-world traffic dataset, alongside enhanced versions of the NGSIM and HighD datasets, designed to facilitate rigorous testing in environments with missing observations. Extensive evaluations demonstrate that our approach markedly outperforms existing methods, achieving high accuracy even in scenarios with up to 75% missing observations. Keywords: Robotics: ROB: Other Planning and Scheduling: PS: Planning under uncertainty},
  archive   = {C_IJCAI},
  author    = {Haicheng Liao and Chengyue Wang and Zhenning Li and Yongkang Li and Bonan Wang and Guofa Li and Chengzhong Xu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/756},
  month     = {8},
  pages     = {6841-6849},
  title     = {Physics-informed trajectory prediction for autonomous driving under missing observation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Integrating intent understanding and optimal behavior
planning for behavior tree generation from human instructions.
<em>IJCAI</em>, 6832–6840. (<a
href="https://doi.org/10.24963/ijcai.2024/755">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Robots executing tasks following human instructions in domestic or industrial environments essentially require both adaptability and reliability. Behavior Tree (BT) emerges as an appropriate control architecture for these scenarios due to its modularity and reactivity. Existing BT generation methods, however, either do not involve interpreting natural language or cannot theoretically guarantee the BTs&#39; success. This paper proposes a two-stage framework for BT generation, which first employs large language models (LLMs) to interpret goals from high-level instructions, then constructs an efficient goal-specific BT through the Optimal Behavior Tree Expansion Algorithm (OBTEA). We represent goals as well-formed formulas in first-order logic, effectively bridging intent understanding and optimal behavior planning. Experiments in the service robot validate the proficiency of LLMs in producing grammatically correct and accurately interpreted goals, demonstrate OBTEA&#39;s superiority over the baseline BT Expansion algorithm in various metrics, and finally confirm the practical deployability of our framework. The project website is https://dids-ei.github.io/Project/LLM-OBTEA. Keywords: Robotics: ROB: Behavior and control Planning and Scheduling: PS: Robot planning Robotics: ROB: Human robot interaction},
  archive   = {C_IJCAI},
  author    = {Xinglin Chen and Yishuai Cai and Yunxin Mao and Minglong Li and Wenjing Yang and Weixia Xu and Ji Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/755},
  month     = {8},
  pages     = {6832-6840},
  title     = {Integrating intent understanding and optimal behavior planning for behavior tree generation from human instructions},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Zeta*-SIPP: Improved time-optimal any-angle safe-interval
path planning. <em>IJCAI</em>, 6823–6830. (<a
href="https://doi.org/10.24963/ijcai.2024/754">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Any-angle path planning is an extension of traditional path-planning algorithms that aims to generate smoother and shorter paths in graphs by allowing any-angle moves between vertices, rather than being restricted by edges. Many any-angle path-planning algorithms have been proposed, such as Theta*, Block A* and Anya, but most of them are designed only for static environments, which is not applicable when dynamic obstacles are present. Time-Optimal Any-Angle Safe-Interval Path Planning (TO-AA-SIPP) was developed to fill this gap, which can find an optimal collision-free any-angle path that minimizes the traversal time. However, as indicated by its authors, TO-AA-SIPP may not be efficient enough to be used in multi-agent pathfinding (MAPF). Therefore, this paper presents a new algorithm Zeta*-SIPP to improve TO-AA-SIPP by means of 1) reducing useless search nodes that have no contribution to finding optimal solutions, and 2) introducing Field of View (FoV) instead of Line of Sight (LoS) to speed up visibility checks with static obstacles. Benchmark experiments showed that Zeta*-SIPP reduced the computation time of TO-AA-SIPP by around 70%-90% on average. Keywords: Planning and Scheduling: PS: Planning algorithms Robotics: ROB: Motion and path planning Agent-based and Multi-agent Systems: MAS: Multi-agent planning Search: S: Heuristic search},
  archive   = {C_IJCAI},
  author    = {Yiyuan Zou and Clark Borst},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/754},
  month     = {8},
  pages     = {6823-6830},
  title     = {Zeta*-SIPP: Improved time-optimal any-angle safe-interval path planning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A better approximation for bipartite traveling tournament in
inter-league sports scheduling. <em>IJCAI</em>, 6814–6822. (<a
href="https://doi.org/10.24963/ijcai.2024/753">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The bipartite traveling tournament problem (BTTP) was initially introduced by Hoshino and Kawarabayashi (AAAI 2011) to address inter-league sports scheduling, which aims to design a feasible bipartite tournament between two n-team leagues under some constraints such that the total traveling distance of all participating teams is minimized. Since its introduction, several heuristic methods have been developed to design feasible schedules for NBA, NPB and so on. In terms of solution quality with a theoretical guarantee, previously only a (2+ε) approximation is known for the case that n≡0 (mod 3). Whether there are similar results for the cases that n≡1 (mod 3) and n≡2 (mod 3) was asked in the literature. In this paper, we answer this question positively by proposing a (3/2+ε)-approximation algorithm for any n and any constant ε&gt;0, which also improves the previous ratio for the case that n≡0 (mod 3). Keywords: Planning and Scheduling: PS: Scheduling Planning and Scheduling: PS: Routing Planning and Scheduling: PS: Theoretical foundations of planning},
  archive   = {C_IJCAI},
  author    = {Jingyang Zhao and Mingyu Xiao},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/753},
  month     = {8},
  pages     = {6814-6822},
  title     = {A better approximation for bipartite traveling tournament in inter-league sports scheduling},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improved approximation algorithms for capacitated location
routing. <em>IJCAI</em>, 6805–6813. (<a
href="https://doi.org/10.24963/ijcai.2024/752">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Capacitated Location Routing Problem is an important planning and routing problem in logistics, which generalizes the capacitated vehicle routing problem and the uncapacitated facility location problem. In this problem, we are given a set of depots and a set of customers where each depot has an opening cost and each customer has a demand, and we need to use minimum cost to open some depots and route capacitated vehicles in the opened depots to satisfy all customers&#39; demand. In this paper, we propose a 4.169-approximation algorithm for this problem, improving the best-known 4.38-approximation ratio (Transportation Science 2013). Moreover, if the demand of each customer is allowed to be delivered by multiple tours, we propose a more refined 4.092-approximation algorithm. Experimental study on benchmark instances shows that the quality of our computed solutions is better than that of previous algorithms and is also much closer to optimality than the provable approximation factor. Keywords: Planning and Scheduling: PS: Routing Planning and Scheduling: PS: Planning algorithms Planning and Scheduling: PS: Theoretical foundations of planning},
  archive   = {C_IJCAI},
  author    = {Jingyang Zhao and Mingyu Xiao and Shunwang Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/752},
  month     = {8},
  pages     = {6805-6813},
  title     = {Improved approximation algorithms for capacitated location routing},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Laying the foundations for solving FOND HTN problems:
Grounding, search, heuristics (and benchmark problems). <em>IJCAI</em>,
6796–6804. (<a href="https://doi.org/10.24963/ijcai.2024/751">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Building upon recent advancements in formalising Fully Observable Non-Deterministic (FOND) Hierarchical Task Network (HTN) planning, we present the first approach to find strong solutions for HTN problems with uncertainty in action outcomes. We present a search algorithm, along with a compilation that relaxes a FOND HTN problem to a deterministic one. This allows the utilisation of existing grounders and heuristics from the deterministic HTN planning literature. Keywords: Planning and Scheduling: PS: Hierarchical planning Planning and Scheduling: PS: Planning algorithms Planning and Scheduling: PS: Planning under uncertainty Planning and Scheduling: PS: Search in planning and scheduling},
  archive   = {C_IJCAI},
  author    = {Mohammad Yousefi and Pascal Bercher},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/751},
  month     = {8},
  pages     = {6796-6804},
  title     = {Laying the foundations for solving FOND HTN problems: Grounding, search, heuristics (and benchmark problems)},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Scalable landmark hub labeling for optimal and bounded
suboptimal pathfinding. <em>IJCAI</em>, 6788–6795. (<a
href="https://doi.org/10.24963/ijcai.2024/750">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Hub Labeling and A* are two well-established algorithms for shortest path computation in large graphs. Hub Labeling offers excellent query times for distance computation, but at the cost of a high space consumption for label storage. Landmark-based A* search requires less space but answers queries much slower. Recently, Landmark Hub Labeling (LHL) has been proposed, which combines both concepts and achieves a smaller space consumption than Hub Labeling and also much better query times than A*. However, the known algorithms for computing a LHL do not scale to large graphs, limiting its applicability. In this paper, we devise novel algorithms for LHL construction that work on graphs with millions of edges. We also further improve the LHL query answering algorithm and investigate how to reduce the space consumption of labeling techniques by performing bounded suboptimal pathfinding. In an extensive experimental study, we demonstrate the effectiveness of our methods and illuminate that sensible trade-offs between space consumption, query time, and path quality can be achieved with LHL. Keywords: Planning and Scheduling: PS: Routing Multidisciplinary Topics and Applications: MTA: Transportation Search: S: Applications Search: S: Combinatorial search and optimisation},
  archive   = {C_IJCAI},
  author    = {Sabine Storandt},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/750},
  month     = {8},
  pages     = {6788-6795},
  title     = {Scalable landmark hub labeling for optimal and bounded suboptimal pathfinding},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Information-theoretic opacity-enforcement in markov decision
processes. <em>IJCAI</em>, 6779–6787. (<a
href="https://doi.org/10.24963/ijcai.2024/749">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The paper studies information-theoretic opacity, an information-flow privacy property, in a setting involving two agents: A planning agent who controls a stochastic system and an observer who partially observes the system states. The goal of the observer is to infer some secret, represented by a random variable, from its partial observations, while the goal of the planning agent is to make the secret maximally opaque to the observer while achieving a satisfactory total return. Modeling the stochastic system using a Markov decision process, two classes of opacity properties are considered---Last-state opacity is to ensure that the observer is uncertain if the last state is in a specific set and initial-state opacity is to ensure that the observer is unsure of the realization of the initial state. As the measure of opacity, we employ the Shannon conditional entropy capturing the information about the secret revealed by the observable. Then, we develop primal-dual policy gradient methods for opacity-enforcement planning subject to constraints on total returns. We propose novel algorithms to compute the policy gradient of entropy for each observation, leveraging message passing within the hidden Markov models. This gradient computation enables us to have stable and fast convergence. We demonstrate our solution of opacity-enforcement control through a grid world example. Keywords: Planning and Scheduling: PS: Planning with Incomplete Information Planning and Scheduling: PS: Markov decisions processes Planning and Scheduling: PS: Planning algorithms Planning and Scheduling: PS: Planning under uncertainty},
  archive   = {C_IJCAI},
  author    = {Chongyang Shi and Yuheng Bu and Jie Fu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/749},
  month     = {8},
  pages     = {6779-6787},
  title     = {Information-theoretic opacity-enforcement in markov decision processes},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust reward placement under uncertainty. <em>IJCAI</em>,
6770–6778. (<a href="https://doi.org/10.24963/ijcai.2024/748">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider a problem of placing generators of rewards to be collected by randomly moving agents in a network. In many settings, the precise mobility pattern may be one of several possible, based on parameters outside our control, such as weather conditions. The placement should be robust to this uncertainty, to gain a competent total reward across possible networks. To study such scenarios, we introduce the Robust Reward Placement problem (RRP). Agents move randomly by a Markovian Mobility Model with a predetermined set of locations whose connectivity is chosen adversarially from a known set Π of candidates. We aim to select a set of reward states within a budget that maximizes the minimum ratio, among all candidates in Π, of the collected total reward over the optimal collectable reward under the same candidate. We prove that RRP is NP-hard and inapproximable, and develop Ψ-Saturate, a pseudo-polynomial time algorithm that achieves an ϵ-additive approximation by exceeding the budget constraint by a factor that scales as O(ln |Π|/ϵ). In addition, we present several heuristics, most prominently one inspired by a dynamic programming algorithm for the max–min 0–1 KNAPSACK problem. We corroborate our theoretical analysis with an experimental evaluation on synthetic and real data. Keywords: Planning and Scheduling: PS: Planning under uncertainty Data Mining: DM: Networks Planning and Scheduling: PS: Markov decisions processes Search: S: Combinatorial search and optimisation},
  archive   = {C_IJCAI},
  author    = {Petros Petsinis and Kaichen Zhang and Andreas Pavlogiannis and Jingbo Zhou and Panagiotis Karras},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/748},
  month     = {8},
  pages     = {6770-6778},
  title     = {Robust reward placement under uncertainty},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On using admissible bounds for learning forward search
heuristics. <em>IJCAI</em>, 6761–6769. (<a
href="https://doi.org/10.24963/ijcai.2024/747">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In recent years, there has been growing interest in utilizing modern machine learning techniques to learn heuristic functions for forward search algorithms. Despite this, there has been little theoretical understanding of what they should learn, how to train them, and why we do so. This lack of understanding has resulted in the adoption of diverse training targets (suboptimal vs optimal costs vs admissible heuristics) and loss functions (e.g., square vs absolute errors) in the literature. In this work, we focus on how to effectively utilize the information provided by admissible heuristics in heuristic learning. We argue that learning from poly-time admissible heuristics by minimizing mean square errors (MSE) is not the correct approach, since its result is merely a noisy, inadmissible copy of an efficiently computable heuristic. Instead, we propose to model the learned heuristic as a truncated gaussian, where admissible heuristics are used not as training targets but as lower bounds of this distribution. This results in a different loss function from the MSE commonly employed in the literature, which implicitly models the learned heuristic as a gaussian distribution. We conduct experiments where both MSE and our novel loss function are applied to learning a heuristic from optimal plan costs. Results show that our proposed method converges faster during training and yields better heuristics. Keywords: Planning and Scheduling: PS: Learning in planning and scheduling Machine Learning: ML: Knowledge-aided learning Search: S: Heuristic search Machine Learning: ML: Neuro-symbolic methods},
  archive   = {C_IJCAI},
  author    = {Carlos Núñez-Molina and Masataro Asai and Pablo Mesejo and Juan Fernandez-Olivares},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/747},
  month     = {8},
  pages     = {6761-6769},
  title     = {On using admissible bounds for learning forward search heuristics},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ConstrainedZero: Chance-constrained POMDP planning using
learned probabilistic failure surrogates and adaptive safety
constraints. <em>IJCAI</em>, 6752–6760. (<a
href="https://doi.org/10.24963/ijcai.2024/746">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {To plan safely in uncertain environments, agents must balance utility with safety constraints. Safe planning problems can be modeled as a chance-constrained partially observable Markov decision process (CC-POMDP) and solutions often use expensive rollouts or heuristics to estimate the optimal value and action-selection policy. This work introduces the ConstrainedZero policy iteration algorithm that solves CC-POMDPs in belief space by learning neural network approximations of the optimal value and policy with an additional network head that estimates the failure probability given a belief. This failure probability guides safe action selection during online Monte Carlo tree search (MCTS). To avoid overemphasizing search based on the failure estimates, we introduce Δ-MCTS, which uses adaptive conformal inference to update the failure threshold during planning. The approach is tested on a safety-critical POMDP benchmark, an aircraft collision avoidance system, and the sustainability problem of safe CO₂ storage. Results show that by separating safety constraints from the objective we can achieve a target level of safety without optimizing the balance between rewards and costs. Keywords: Planning and Scheduling: PS: POMDPs Machine Learning: ML: Partially observable reinforcement learning and POMDPs Planning and Scheduling: PS: Planning under uncertainty},
  archive   = {C_IJCAI},
  author    = {Robert J. Moss and Arec Jamgochian and Johannes Fischer and Anthony Corso and Mykel J. Kochenderfer},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/746},
  month     = {8},
  pages     = {6752-6760},
  title     = {ConstrainedZero: Chance-constrained POMDP planning using learned probabilistic failure surrogates and adaptive safety constraints},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Approximate dec-POMDP solving using multi-agent a*.
<em>IJCAI</em>, 6743–6751. (<a
href="https://doi.org/10.24963/ijcai.2024/745">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present an A*-based algorithm to compute policies for finite-horizon Dec-POMDPs. Our goal is to sacrifice optimality in favor of scalability for larger horizons. The main ingredients of our approach are (1) using clustered sliding window memory, (2) pruning the A* search tree, and (3) using novel A* heuristics. Our experiments show competitive performance to the state-of-the-art. Moreover, for multiple benchmarks, we achieve superior performance. In addition, we provide an A* algorithm that finds upper bounds for the optimum, tailored towards problems with long horizons. The main ingredient is a new heuristic that periodically reveals the state, thereby limiting the number of reachable beliefs. Our experiments demonstrate the efficacy and scalability of the approach. Keywords: Planning and Scheduling: PS: Planning under uncertainty Agent-based and Multi-agent Systems: MAS: Multi-agent planning Planning and Scheduling: PS: POMDPs},
  archive   = {C_IJCAI},
  author    = {Wietze Koops and Sebastian Junges and Nils Jansen},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/745},
  month     = {8},
  pages     = {6743-6751},
  title     = {Approximate dec-POMDP solving using multi-agent a*},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning generalized policies for fully observable
non-deterministic planning domains. <em>IJCAI</em>, 6733–6742. (<a
href="https://doi.org/10.24963/ijcai.2024/744">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {General policies represent reactive strategies for solving large families of planning problems like the infinite collection of solvable instances from a given domain. Methods for learning such policies from a collection of small training instances have been developed successfully for classical domains. In this work, we extend the formulations and the resulting combinatorial methods for learning general policies over fully observable, non-deterministic (FOND) domains. We also evaluate the resulting approach experimentally over a number of benchmark domains in FOND planning, present the general policies that result in some of these domains, and prove their correctness. The method for learning general policies for FOND planning can actually be seen as an alternative planning FOND planning method that searches for solutions not in the given state space but in an abstract state space defined by features that must be learned as well. Keywords: Planning and Scheduling: PS: Learning in planning and scheduling Planning and Scheduling: PS: Planning under uncertainty},
  archive   = {C_IJCAI},
  author    = {Till Hofmann and Hector Geffner},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/744},
  month     = {8},
  pages     = {6733-6742},
  title     = {Learning generalized policies for fully observable non-deterministic planning domains},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Guiding GBFS through learned pairwise rankings.
<em>IJCAI</em>, 6724–6732. (<a
href="https://doi.org/10.24963/ijcai.2024/743">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose a new approach based on ranking to learn to guide Greedy Best-First Search (GBFS). As previous ranking approaches, ours is based on the observation that directly learning a heuristic function is overly restrictive, and that GBFS is capable of efficiently finding good plans for a much more flexible class of total quasi-orders over states. In order to learn an optimal ranking function, we introduce a new ranking framework capable of leveraging any neural network regression model and efficiently handling the training data through batching. Compared with previous ranking approaches for planning, ours does not require complex loss functions and allows training on states outside the optimal plan with minimal overhead. Our experiments on the domains of the latest planning competition learning track show that our approach substantially improves the coverage of the underlying neural network models without degrading plan quality. Keywords: Planning and Scheduling: PS: Learning in planning and scheduling},
  archive   = {C_IJCAI},
  author    = {Mingyu Hao and Felipe Trevizan and Sylvie Thiébaux and Patrick Ferber and Jörg Hoffmann},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/743},
  month     = {8},
  pages     = {6724-6732},
  title     = {Guiding GBFS through learned pairwise rankings},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Scalable ultrafast almost-optimal euclidean shortest paths.
<em>IJCAI</em>, 6716–6723. (<a
href="https://doi.org/10.24963/ijcai.2024/742">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider the problem of computing high-quality Euclidean shortest paths amidst obstacles on a large scale. By transferring and adapting speed-up techniques from the road network setting, we are able to compute source target paths for problem instances with several million obstacle vertices within few milliseconds after moderate preprocessing. We show experimentally that for small instances where optimal solutions are easily available on average our computed paths are less than 0.3% longer than the optimum. For large instances a new lower-bounding technique shows that on average our computed paths are less than 2% longer than the optimum paths. We compare our approach with the current state-of-the-art on problem instances derived from the OpenStreetMap project. Keywords: Planning and Scheduling: PS: Routing Multidisciplinary Topics and Applications: MTA: Transportation Planning and Scheduling: PS: Applications Search: S: Combinatorial search and optimisation},
  archive   = {C_IJCAI},
  author    = {Stefan Funke and Daniel Koch and Claudius Proissl and Axel Schneewind and Armin Weiß and Felix Weitbrecht},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/742},
  month     = {8},
  pages     = {6716-6723},
  title     = {Scalable ultrafast almost-optimal euclidean shortest paths},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Solving long-run average reward robust MDPs via stochastic
games. <em>IJCAI</em>, 6707–6715. (<a
href="https://doi.org/10.24963/ijcai.2024/741">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Markov decision processes (MDPs) provide a standard framework for sequential decision making under uncertainty. However, MDPs do not take uncertainty in transition probabilities into account. Robust Markov decision processes (RMDPs) address this shortcoming of MDPs by assigning to each transition an uncertainty set rather than a single probability value. In this work, we consider polytopic RMDPs in which all uncertainty sets are polytopes and study the problem of solving long-run average reward polytopic RMDPs. We present a novel perspective on this problem and show that it can be reduced to solving long-run average reward turn-based stochastic games with finite state and action spaces. This reduction allows us to derive several important consequences that were hitherto not known to hold for polytopic RMDPs. First, we derive new computational complexity bounds for solving long-run average reward polytopic RMDPs, showing for the first time that the threshold decision problem for them is in NP and coNP and that they admit a randomized algorithm with sub-exponential expected runtime. Second, we present Robust Polytopic Policy Iteration (RPPI), a novel policy iteration algorithm for solving long-run average reward polytopic RMDPs. Our experimental evaluation shows that RPPI is much more efficient in solving long-run average reward polytopic RMDPs compared to state-of-the-art methods based on value iteration. Keywords: Planning and Scheduling: PS: Markov decisions processes Agent-based and Multi-agent Systems: MAS: Formal verification, validation and synthesis Planning and Scheduling: PS: Planning under uncertainty Planning and Scheduling: PS: Theoretical foundations of planning},
  archive   = {C_IJCAI},
  author    = {Krishnendu Chatterjee and Ehsan Kafshdar Goharshady and Mehrdad Karrabi and Petr Novotný and Đorđe Žikelić},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/741},
  month     = {8},
  pages     = {6707-6715},
  title     = {Solving long-run average reward robust MDPs via stochastic games},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Imprecise probabilities meet partial observability: Game
semantics for robust POMDPs. <em>IJCAI</em>, 6697–6706. (<a
href="https://doi.org/10.24963/ijcai.2024/740">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Partially observable Markov decision processes (POMDPs) rely on the key assumption that probability distributions are precisely known. Robust POMDPs (RPOMDPs) alleviate this concern by defining imprecise probabilities, referred to as uncertainty sets. While robust MDPs have been studied extensively, work on RPOMDPs is limited and primarily focuses on algorithmic solution methods. We expand the theoretical understanding of RPOMDPs by showing that 1) different assumptions on the uncertainty sets affect optimal policies and values; 2) RPOMDPs have a partially observable stochastic game (POSG) semantic; and 3) the same RPOMDP with different assumptions leads to semantically different POSGs and, thus, different policies and values. These novel semantics for RPOMDPs give access to results for POSGs, studied in game theory; concretely, we show the existence of a Nash equilibrium. Finally, we classify the existing RPOMDP literature using our semantics, clarifying under which uncertainty assumptions these existing works operate. Keywords: Planning and Scheduling: PS: POMDPs Agent-based and Multi-agent Systems: MAS: Formal verification, validation and synthesis Uncertainty in AI: UAI: Sequential decision making},
  archive   = {C_IJCAI},
  author    = {Eline M. Bovy and Marnix Suilen and Sebastian Junges and Nils Jansen},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/740},
  month     = {8},
  pages     = {6697-6706},
  title     = {Imprecise probabilities meet partial observability: Game semantics for robust POMDPs},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TFCD: Towards multi-modal sarcasm detection via
training-free counterfactual debiasing. <em>IJCAI</em>, 6687–6695. (<a
href="https://doi.org/10.24963/ijcai.2024/739">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-modal sarcasm detection (MSD), which aims to identify whether a given sample with multi-modal information (i.e., text and image) is sarcastic, has garnered widespread attention. Recent approaches focus on designing sophisticated architectures or mechanisms to extract sarcastic cues from entire or local image and text features. Nevertheless, a long-overlooked issue is that current MSD task invariably suffers from unintended dataset biases, especially the statistical label bias and sarcasmless word bias. Concretely, such harmful biases are confounders that may mislead existing models to learn spurious correlations, significantly limiting models&#39; performance. To tackle this issue, this paper proposes a Training-Free Counterfactual Debiasing framework TFCD, which first formulates the causalities among variables in MSD via a tailored causal graph. Then, TFCD extracts biases from the conventionally-trained model by generating counterfactual utterances and contexts and mitigates them using element-wise subtraction. Extensive experiments on two benchmarks demonstrate the effectiveness of the proposed TFCD. Remarkably, TFCD requires neither data balancing nor model modifications, and thus can be seamlessly integrated into diverse state-of-the-art approaches and achieve considerable improvement margins. Keywords: Natural Language Processing: NLP: Sentiment analysis, stylistic analysis, and argument mining},
  archive   = {C_IJCAI},
  author    = {Zhihong Zhu and Xianwei Zhuang and Yunyan Zhang and Derong Xu and Guimin Hu and Xian Wu and Yefeng Zheng},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/739},
  month     = {8},
  pages     = {6687-6695},
  title     = {TFCD: Towards multi-modal sarcasm detection via training-free counterfactual debiasing},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Joint multimodal aspect sentiment analysis with aspect
enhancement and syntactic adaptive learning. <em>IJCAI</em>, 6678–6686.
(<a href="https://doi.org/10.24963/ijcai.2024/738">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As an important task in sentiment analysis, joint multimodal aspect sentiment analysis (JMASA) has received increasing attention in recent years. However, previous approaches either i) directly fuse multimodal data without fully exploiting the correlation between multimodal input data, or ii) equally utilize the dependencies of words in the text for sentiment analysis, ignoring the differences in the importance of different words. To address these limitations, we propose a joint multimodal sentiment analysis method based on Aspect Enhancement and Syntactic Adaptive Learning (AESAL). Specifically, we construct an aspect enhancement pre-training task to enable the model to fully learn the correlation of aspects between multimodal input data. In order to capture the differences in the importance of different words in the text, we design a syntactic adaptive learning mechanism. First, we construct different syntactic dependency graphs based on the distance between words to learn global and local information in the text. Second, we use a multi-channel adaptive graph convolutional network to maintain the uniqueness of each modality while fusing the correlations between different modalities. Experimental results on benchmark datasets show that our method outperforms state-of-the-art methods. Keywords: Natural Language Processing: NLP: Sentiment analysis, stylistic analysis, and argument mining Computer Vision: CV: Multimodal learning},
  archive   = {C_IJCAI},
  author    = {Linlin Zhu and Heli Sun and Qunshu Gao and Tingzhou Yi and Liang He},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/738},
  month     = {8},
  pages     = {6678-6686},
  title     = {Joint multimodal aspect sentiment analysis with aspect enhancement and syntactic adaptive learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MultifacetEval: Multifaceted evaluation to probe LLMs in
mastering medical knowledge. <em>IJCAI</em>, 6669–6677. (<a
href="https://doi.org/10.24963/ijcai.2024/737">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Large language models (LLMs) have excelled across domains, also delivering notable performance on the medical evaluation benchmarks, such as MedQA. However, there still exists a significant gap between the reported performance and the practical effectiveness in real-world medical scenarios. In this paper, we aim to explore the causes of this gap by employing a multifaceted examination schema to systematically probe the actual mastery of medical knowledge by current LLMs. Specifically, we develop a novel evaluation framework MultifacetEval to examine the degree and coverage of LLMs in encoding and mastering medical knowledge at multiple facets (comparison, rectification, discrimination, and verification) concurrently. Based on the MultifacetEval framework, we construct two multifaceted evaluation datasets: MultiDiseK (by producing questions from a clinical disease knowledge base) and MultiMedQA (by rephrasing each question from a medical benchmark MedQA into multifaceted questions). The experimental results on these multifaceted datasets demonstrate that the extent of current LLMs in mastering medical knowledge is far below their performance on existing medical benchmarks, suggesting that they lack depth, precision, and comprehensiveness in mastering medical knowledge. Consequently, current LLMs are not yet ready for application in real-world medical tasks. The codes and datasets are available at https://github.com/THUMLP/MultifacetEval. Keywords: Natural Language Processing: NLP: Language models Natural Language Processing: NLP: Applications},
  archive   = {C_IJCAI},
  author    = {Yuxuan Zhou and Xien Liu and Chen Ning and Ji Wu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/737},
  month     = {8},
  pages     = {6669-6677},
  title     = {MultifacetEval: Multifaceted evaluation to probe LLMs in mastering medical knowledge},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Making LLMs as fine-grained relation extraction data
augmentor. <em>IJCAI</em>, 6660–6668. (<a
href="https://doi.org/10.24963/ijcai.2024/736">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Relation Extraction (RE) identifies relations between entities in text, typically relying on supervised models that demand abundant high-quality data. Various approaches, including Data Augmentation (DA), have been proposed as promising solutions for addressing low-resource challenges in RE. However, existing DA methods in RE often struggle to ensure consistency and contextual diversity in generated data due to the fine-grained nature of RE. Inspired by the extensive generative capabilities of large language models (LLMs), we introduce a novel framework named ConsistRE, aiming to maintain context consistency in RE. ConsistRE initiates by collecting a substantial corpus from external resources and employing statistical algorithms and semantics to identify keyword hints closely related to relation instances. These keyword hints are subsequently integrated as contextual constraints in sentence generation, ensuring the preservation of relation dependence and diversity with LLMs. Additionally, we implement syntactic dependency selection to enhance the syntactic structure of the generated sentences. Experimental results from the evaluation of SemEval, TACRED, and TACREV datasets unequivocally demonstrate that ConsistRE outperforms other baselines in F1 values by 1.76%, 3.92%, and 2.53%, respectively, particularly when operating under low-resource experimental conditions. Keywords: Natural Language Processing: NLP: Language generation Natural Language Processing: NLP: Information extraction Natural Language Processing: NLP: Information retrieval and text mining Natural Language Processing: NLP: Resources and evaluation},
  archive   = {C_IJCAI},
  author    = {Yifan Zheng and Wenjun Ke and Qi Liu and Yuting Yang and Ruizhuo Zhao and Dacheng Feng and Jianwei Zhang and Zhi Fang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/736},
  month     = {8},
  pages     = {6660-6668},
  title     = {Making LLMs as fine-grained relation extraction data augmentor},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generate synthetic text approximating the private
distribution with differential privacy. <em>IJCAI</em>, 6651–6659. (<a
href="https://doi.org/10.24963/ijcai.2024/735">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Due to the potential leakage of sensitive information in text, there is a societal call for feeding privacy-preserving text to model training. Recently, a lot of work showed that using synthetic text with differential privacy, rather than private text, can provide a strong privacy protection. However, achieving higher semantic similarity between synthetic and private text has not been thoroughly investigated. In this paper, we propose an approach that combines the iteratively optimized mindset from genetic algorithms to align the distribution of synthetic text with that of private text. Furthermore, not only does the final synthetic text meet the requirements of privacy protection, but also has a high level of quality. Through comparisons with various baselines on different datasets, we demonstrate that our synthetic text can closely match the utility of private text, while providing privacy protection standards robust enough to resist membership inference attacks from malicious users. Keywords: Natural Language Processing: NLP: Language models Multidisciplinary Topics and Applications: MTA: Security and privacy},
  archive   = {C_IJCAI},
  author    = {Wenhao Zhao and Shaoyang Song and Chunlai Zhou},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/735},
  month     = {8},
  pages     = {6651-6659},
  title     = {Generate synthetic text approximating the private distribution with differential privacy},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). KG-CoT: Chain-of-thought prompting of large language models
over knowledge graphs for knowledge-aware question answering.
<em>IJCAI</em>, 6642–6650. (<a
href="https://doi.org/10.24963/ijcai.2024/734">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Large language models (LLMs) encounter challenges such as hallucination and factual errors in knowledge-intensive tasks. One the one hand, LLMs sometimes struggle to generate reliable answers based on the black-box parametric knowledge, due to the lack of responsible knowledge. Moreover, fragmented knowledge facts extracted by knowledge retrievers fail to provide explicit and coherent reasoning paths for improving LLM reasoning. To address these challenges, we propose KG-CoT, a novel knowledge-augmented paradigm that leverages a small-scale step-by-step graph reasoning model to reason over knowledge graphs (KGs) and utilizes a reasoning path generation method to generate chains of reasoning with high confidence for large-scale LLMs. Extensive experiments demonstrate that our KG-CoT significantly improves the performance of LLMs on knowledge-intensive question answering tasks, such as multi-hop, single-hop, and open-domain question answering benchmarks, without fine-tuning LLMs. KG-CoT outperforms the CoT prompting as well as prior retrieval-augmented and knowledge base question answering baselines. Moreover, KG-CoT can reduce the number of API calls and cost and generalize to various LLM backbones in a lightweight plug-and-play manner. Keywords: Natural Language Processing: NLP: Question answering Natural Language Processing: NLP: Language generation},
  archive   = {C_IJCAI},
  author    = {Ruilin Zhao and Feng Zhao and Long Wang and Xianzhi Wang and Guandong Xu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/734},
  month     = {8},
  pages     = {6642-6650},
  title     = {KG-CoT: Chain-of-thought prompting of large language models over knowledge graphs for knowledge-aware question answering},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). InstructEdit: Instruction-based knowledge editing for large
language models. <em>IJCAI</em>, 6633–6641. (<a
href="https://doi.org/10.24963/ijcai.2024/733">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Knowledge editing for large language models can offer an efficient solution to alter a model’s behavior without negatively impacting the overall performance. However, the current approaches encounter issues with limited generalizability across tasks, necessitating one distinct editor for each task, significantly hindering the broader applications. To address this, we take the first step to analyze the multi-task generalization issue in knowledge editing. Specifically, we develop an instruction-based editing technique, termed InstructEdit, which facilitates the editor&#39;s adaptation to various task performances simultaneously using simple instructions. With only one unified editor for each LLM, we empirically demonstrate that InstructEdit can improve the editor&#39;s control, leading to an average 14.86% increase in Reliability in multi-task editing setting. Furthermore, experiments involving holdout unseen task illustrate that InstructEdit consistently surpass previous strong baselines. To further investigate the underlying mechanisms of instruction-based knowledge editing, we analyze the principal components of the editing gradient directions, which unveils that instructions can help control optimization direction with stronger OOD generalization. Keywords: Natural Language Processing: NLP: Language models Natural Language Processing: NLP: Applications},
  archive   = {C_IJCAI},
  author    = {Ningyu Zhang and Bozhong Tian and Siyuan Cheng and Xiaozhuan Liang and Yi Hu and Kouying Xue and Yanjie Gou and Xi Chen and Huajun Chen},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/733},
  month     = {8},
  pages     = {6633-6641},
  title     = {InstructEdit: Instruction-based knowledge editing for large language models},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Modeling selective feature attention for lightweight text
matching. <em>IJCAI</em>, 6624–6632. (<a
href="https://doi.org/10.24963/ijcai.2024/732">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Representation-based Siamese networks have risen to popularity in lightweight text matching due to their low deployment and inference costs. While word-level attention mechanisms have been implemented within Siamese networks to improve performance, we propose Feature Attention (FA), a novel downstream block designed to enrich the modeling of dependencies among embedding features. Employing &quot;squeeze-and-excitation&quot; techniques, the FA block dynamically adjusts the emphasis on individual features, enabling the network to concentrate more on features that significantly contribute to the final classification. Building upon FA, we introduce a dynamic &quot;selection&quot; mechanism called Selective Feature Attention (SFA), which leverages a stacked BiGRU Inception structure. The SFA block facilitates multi-scale semantic extraction by traversing different stacked BiGRU layers, encouraging the network to selectively concentrate on semantic information and embedding features across varying levels of abstraction. Both the FA and SFA blocks offer a seamless integration capability with various Siamese networks, showcasing a plug-and-play characteristic. Experimental evaluations conducted across diverse text matching baselines and benchmarks underscore the indispensability of modeling feature attention and the superiority of the &quot;selection&quot; mechanism. Keywords: Natural Language Processing: NLP: Natural language semantics Machine Learning: ML: Attention models Machine Learning: ML: Deep learning architectures Natural Language Processing: NLP: Embeddings},
  archive   = {C_IJCAI},
  author    = {Jianxiang Zang and Hui Liu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/732},
  month     = {8},
  pages     = {6624-6632},
  title     = {Modeling selective feature attention for lightweight text matching},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning label dependencies for visual information
extraction. <em>IJCAI</em>, 6615–6623. (<a
href="https://doi.org/10.24963/ijcai.2024/731">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Visual Information Extraction (VIE), which aims to extract structured information from visually rich document images, has drawn much attention due to its wide applications in document understanding. However, previous methods often treat the VIE task as a sequence labeling problem and ignore the label correlations in the sequence, which may significantly degrade their performance. To address this issue, this paper proposes a novel framework to exploit the potential of label correlations to improve the VIE models&#39; performance. Its key idea is to learn the label dependency of entities, and use it to regularize the label sequence. Specifically, to capture the label dependency of entities, a label transformer is pre-trained to assign a higher likelihood to the label sequence that respects the label patterns of document layouts. During testing stages, an inference transformer is used to predict the label sequence by considering not only the features of each entity but also the likelihood of the label sequence evaluated by the label transformer. Our framework can be combined with existing popular VIE models such as LayoutLM and GeoLayoutLM. Extensive experiments on public datasets have demonstrated the effectiveness of our framework. Keywords: Natural Language Processing: NLP: Applications Natural Language Processing: NLP: Information extraction},
  archive   = {C_IJCAI},
  author    = {Minghong Yao and Liansheng Zhuang and Houqiang Li and Jiuchang Wei},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/731},
  month     = {8},
  pages     = {6615-6623},
  title     = {Learning label dependencies for visual information extraction},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Vision-fused attack: Advancing aggressive and stealthy
adversarial text against neural machine translation. <em>IJCAI</em>,
6606–6614. (<a href="https://doi.org/10.24963/ijcai.2024/730">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {While neural machine translation (NMT) models achieve success in our daily lives, they show vulnerability to adversarial attacks. Despite being harmful, these attacks also offer benefits for interpreting and enhancing NMT models, thus drawing increased research attention. However, existing studies on adversarial attacks are insufficient in both attacking ability and human imperceptibility due to their sole focus on the scope of language. This paper proposes a novel vision-fused attack (VFA) framework to acquire powerful adversarial text, i.e., more aggressive and stealthy. Regarding the attacking ability, we design the vision-merged solution space enhancement strategy to enlarge the limited semantic solution space, which enables us to search for adversarial candidates with higher attacking ability. For human imperceptibility, we propose the perception-retained adversarial text selection strategy to align the human text-reading mechanism. Thus, the finally selected adversarial text could be more deceptive. Extensive experiments on various models, including large language models (LLMs) like LLaMA and GPT-3.5, strongly support that VFA outperforms the comparisons by large margins (up to 81%/14% improvements on ASR/SSIM). Keywords: Natural Language Processing: NLP: Machine translation and multilinguality AI Ethics, Trust, Fairness: ETF: Safety and robustness Machine Learning: ML: Trustworthy machine learning},
  archive   = {C_IJCAI},
  author    = {Yanni Xue and Haojie Hao and Jiakai Wang and Qiang Sheng and Renshuai Tao and Yu Liang and Pu Feng and Xianglong Liu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/730},
  month     = {8},
  pages     = {6606-6614},
  title     = {Vision-fused attack: Advancing aggressive and stealthy adversarial text against neural machine translation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Incorporating schema-aware description into document-level
event extraction. <em>IJCAI</em>, 6597–6605. (<a
href="https://doi.org/10.24963/ijcai.2024/729">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Document-level event extraction (DEE) aims to extract the structured event information from a given document, facing two critical challenges: (1) event arguments always scatter across sentences (arguments-scattering); (2) multiple events can co-occur in one document (multi-event). Most recent studies mainly follow two simplified settings to ease the challenges: one simplifies DEE with the no-trigger-words design (NDEE), and the other focuses on event argument extraction (DEAE), a sub-task of DEE. However, the former excludes trigger extraction and suffers from error propagation in the sub-tasks. The latter relies heavily on the gold triggers as prerequisites and struggles to distinguish multiple arguments playing the same role in different events. To address the limitations above, we propose a novel joint trigger and argument extraction paradigm SEELE to enhance the DEE model via incorporating SchEma-awarE descriptions into Document-Level Event extraction. Specifically, the schema-aware descriptions are leveraged from two aspects: (1) guiding the attention mechanism among event-aware tokens across sentences, which relieves arguments-scattering without error propagation; (2) performing the fine-grained contrastive learning to distinguish different events, which mitigates multi-event without gold triggers. Extensive experiments show the superiority of SEELE, achieving notable improvements (2.1% to 9.7% F1) on three NDEE datasets and competitive performance on two DEAE datasets. Our code is available at https://github.com/TheoryRhapsody/SEELE. Keywords: Natural Language Processing: NLP: Information extraction},
  archive   = {C_IJCAI},
  author    = {Zijie Xu and Peng Wang and Wenjun Ke and Guozheng Li and Jiajun Liu and Ke Ji and Xiye Chen and Chenxiao Wu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/729},
  month     = {8},
  pages     = {6597-6605},
  title     = {Incorporating schema-aware description into document-level event extraction},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TaD: A plug-and-play task-aware decoding method to better
adapt LLMs on downstream tasks. <em>IJCAI</em>, 6587–6596. (<a
href="https://doi.org/10.24963/ijcai.2024/728">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Fine-tuning pre-trained models on downstream tasks is a common practice in leveraging large language models (LLMs) today. A critical issue is how to adapt pre-trained models to downstream tasks better, thereby enhancing their performance. This paper introduces Task-aware Decoding (TaD), a plug-and-play method that exploits the difference in probability distributions before and after fine-tuning to boost the performance of LLMs on downstream tasks. The proposed TaD argues that the difference between the pre-finetuning probability distribution and the post-finetuning one represents the direction from common knowledge towards specific downstream-task knowledge. Aligning the final output probability distribution to that direction can probably result in superior downstream task performance, compared to the original fine-tuned model. Experiments on various datasets across four different task categories well demonstrate TaD&#39;s effectiveness on different LLMs, i.e., GPT, BLOOM, and LLaMA, with different fine-tuning methods. Moreover, further experiments reveal that TaD better enhances model performance in data-scarce scenarios. Keywords: Natural Language Processing: NLP: Language generation Natural Language Processing: NLP: Applications Natural Language Processing: NLP: Language models},
  archive   = {C_IJCAI},
  author    = {Xinhao Xu and Hui Chen and Zijia Lin and Jungong Han and Lixing Gong and Guoxin Wang and Yongjun Bao and Guiguang Ding},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/728},
  month     = {8},
  pages     = {6587-6596},
  title     = {TaD: A plug-and-play task-aware decoding method to better adapt LLMs on downstream tasks},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). It ain’t that bad: Understanding the mysterious performance
drop in OOD generalization for generative transformer models.
<em>IJCAI</em>, 6578–6586. (<a
href="https://doi.org/10.24963/ijcai.2024/727">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Large language models (LLMs) have achieved remarkable proficiency on solving diverse problems. However, their generalization ability is not always satisfying and the generalization problem is common for generative transformer models in general. Researchers take basic mathematical tasks like n-digit addition or multiplication as important perspectives for investigating their generalization behaviors. It is observed that when training models on n-digit operations (e.g., additions) in which both input operands are n-digit in length, models generalize successfully on unseen n-digit inputs (in-distribution (ID) generalization), but fail miserably on longer, unseen cases (out-of-distribution (OOD) generalization). We bring this unexplained performance drop into attention and ask whether there is systematic OOD generalization. Towards understanding LLMs, we train various smaller language models which may share the same underlying mechanism. We discover that the strong ID generalization stems from structured representations, while behind the unsatisfying OOD performance, the models still exhibit clear learned algebraic structures. Specifically, these models map unseen OOD inputs to outputs with learned equivalence relations in the ID domain, which we call the equivalence generalization. These findings deepen our knowledge regarding the generalizability of generative models including LLMs, and provide insights into potential avenues for improvement. Keywords: Natural Language Processing: NLP: Interpretability and analysis of models for NLP AI Ethics, Trust, Fairness: ETF: Explainability and interpretability Knowledge Representation and Reasoning: KRR: Learning and reasoning},
  archive   = {C_IJCAI},
  author    = {Xingcheng Xu and Zihao Pan and Haipeng Zhang and Yanqing Yang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/727},
  month     = {8},
  pages     = {6578-6586},
  title     = {It ain’t that bad: Understanding the mysterious performance drop in OOD generalization for generative transformer models},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Attention based document-level relation extraction with
none class ranking loss. <em>IJCAI</em>, 6569–6577. (<a
href="https://doi.org/10.24963/ijcai.2024/726">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Through document-level relation extraction (RE), the analysis of the global relation between entities in the text is feasible, and more comprehensive and accurate semantic information can be obtained. In document-level RE, the model needs to infer the implicit relations between two entities in different sentences. To obtain more semantic information, existing methods mainly focus on exploring entity representations. However, they ignore the correlations and indivisibility between relations, entities and contexts. Furthermore, current methods only independently estimate the cases of predefined relations, ignoring the case of &quot;no relation&#39;&#39;, which results in poor prediction. To address the above issues, we propose a document-level RE method based on attention mechanisms, which considers the case of &quot;no relation&#39;&#39;. Specifically, our approach leverages graph attention and multi-head attention networks to capture the correlations and indivisibility among relations, entities, and contexts, respectively. In addition, a novel multi-label loss function that promotes large margins in label confidence scores between each predefined class and the none class is employed to improve the prediction performance. Extensive experiments conducted on benchmarking datasets demonstrate that our proposed method outperforms the state-of-the-art baselines with higher accuracy. Keywords: Natural Language Processing: NLP: Information extraction Natural Language Processing: NLP: Embeddings},
  archive   = {C_IJCAI},
  author    = {Xiaolong Xu and Chenbin Li and Haolong Xiang and Lianyong Qi and Xuyun Zhang and Wanchun Dou},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/726},
  month     = {8},
  pages     = {6569-6577},
  title     = {Attention based document-level relation extraction with none class ranking loss},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning to solve geometry problems via simulating human
dual-reasoning process. <em>IJCAI</em>, 6559–6568. (<a
href="https://doi.org/10.24963/ijcai.2024/725">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Geometry Problem Solving (GPS), which is a classic and challenging math problem, has attracted much attention in recent years. It requires a solver to comprehensively understand both text and diagram, master essential geometry knowledge, and appropriately apply it in reasoning. However, existing works follow a paradigm of neural machine translation and only focus on enhancing the capability of encoders, which neglects the essential characteristics of human geometry reasoning. In this paper, inspired by dual-process theory, we propose a Dual-Reasoning Geometry Solver (DualGeoSolver) to simulate the dual-reasoning process of humans for GPS. Specifically, we construct two systems in DualGeoSolver, namely Knowledge System and Inference System. Knowledge System controls an implicit reasoning process, which is responsible for providing diagram information and geometry knowledge according to a step-wise reasoning goal generated by Inference System. Inference System conducts an explicit reasoning process, which specifies the goal in each reasoning step and applies the knowledge to generate program tokens for resolving it. The two systems carry out the above process iteratively, which behaves more in line with human cognition. We conduct extensive experiments on two benchmark datasets, GeoQA and GeoQA+. The results demonstrate the superiority of DualGeoSolver in both solving accuracy and robustness from explicitly modeling human reasoning process and knowledge application. Keywords: Natural Language Processing: NLP: Question answering Knowledge Representation and Reasoning: KRR: Learning and reasoning},
  archive   = {C_IJCAI},
  author    = {Tong Xiao and Jiayu Liu and Zhenya Huang and Jinze Wu and Jing Sha and Shijin Wang and Enhong Chen},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/725},
  month     = {8},
  pages     = {6559-6568},
  title     = {Learning to solve geometry problems via simulating human dual-reasoning process},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). HyDiscGAN: A hybrid distributed cGAN for audio-visual
privacy preservation in multimodal sentiment analysis. <em>IJCAI</em>,
6550–6558. (<a href="https://doi.org/10.24963/ijcai.2024/724">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multimodal Sentiment Analysis (MSA) aims to identify speakers&#39; sentiment tendencies in multimodal video content, raising serious concerns about privacy risks associated with multimodal data, such as voiceprints and facial images. Recent distributed collaborative learning has been verified as an effective paradigm for privacy preservation in multimodal tasks. However, they often overlook the privacy distinctions among different modalities, struggling to strike a balance between performance and privacy preservation. Consequently, it poses an intriguing question of maximizing multimodal utilization to improve performance while simultaneously protecting necessary modalities. This paper forms the first attempt at modality-specified (i.e., audio and visual) privacy preservation in MSA tasks. We propose a novel Hybrid Distributed cross-modality cGAN framework (HyDiscGAN), which learns multimodality alignment to generate fake audio and visual features conditioned on shareable de-identified textual data. The objective is to leverage the fake features to approximate real audio and visual content to guarantee privacy preservation while effectively enhancing performance. Extensive experiments show that compared with the state-of-the-art MSA model, HyDiscGAN can achieve superior or competitive performance while preserving privacy. Keywords: Natural Language Processing: NLP: Sentiment analysis, stylistic analysis, and argument mining Machine Learning: ML: Multi-modal learning Multidisciplinary Topics and Applications: MTA: Security and privacy},
  archive   = {C_IJCAI},
  author    = {Zhuojia Wu and Qi Zhang and Duoqian Miao and Kun Yi and Wei Fan and Liang Hu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/724},
  month     = {8},
  pages     = {6550-6558},
  title     = {HyDiscGAN: A hybrid distributed cGAN for audio-visual privacy preservation in multimodal sentiment analysis},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unified evidence enhancement inference framework for fake
news detection. <em>IJCAI</em>, 6541–6549. (<a
href="https://doi.org/10.24963/ijcai.2024/723">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The current approaches for fake news detection are mainly devoted to extracting candidate evidence from comments (or external articles) and establishing interactive reasoning with the news itself to verify the falsehood of the news. However, they still have several drawbacks: 1) The interaction object is coarse-grained, which mainly drives the entire news to participate in interaction, but ignores the learning of potential suspicious segments in news; 2) The reasoning ways are relatively single, making it difficult to explore the various possible correlations between news and candidate evidence. To this end, we propose Unified Evidence Enhancement Inference framework (UEEI) to discover and infer high-quality evidence to reveal the false parts of news for detection. Specifically, UEEI first promotes the interaction fusion between comments and news from the perspectives of semantic and emotion, thereby learning potential suspicious fragments in news. Then, the model constructs entity-level and relationship-level retrievals to screen sufficient candidate evidence from external sources. Finally, we measure coherence between suspicious fragments and candidate evidence by multi-view reasoning, and further infer explainable evidence that discovers the false parts of news. Experiments on three public datasets confirm the effectiveness and interpretability of our UEEI. Keywords: Natural Language Processing: NLP: Applications Game Theory and Economic Paradigms: GTEP: Computational social choice Multidisciplinary Topics and Applications: MTA: Social sciences},
  archive   = {C_IJCAI},
  author    = {Lianwei Wu and Linyong Wang and Yongqiang Zhao},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/723},
  month     = {8},
  pages     = {6541-6549},
  title     = {Unified evidence enhancement inference framework for fake news detection},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sentence-level or token-level? A comprehensive study on
knowledge distillation. <em>IJCAI</em>, 6531–6540. (<a
href="https://doi.org/10.24963/ijcai.2024/722">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Knowledge distillation, transferring knowledge from a teacher model to a student model, has emerged as a powerful technique in neural machine translation for compressing models or simplifying training targets. Knowledge distillation encompasses two primary methods: sentence-level distillation and token-level distillation. In sentence-level distillation, the student model is trained to align with the output of the teacher model, which can alleviate the training difficulty and give student model a comprehensive understanding of global structure. Differently, token-level distillation requires the student model to learn the output distribution of the teacher model, facilitating a more fine-grained transfer of knowledge. Studies have revealed divergent performances between sentence-level and token-level distillation across different scenarios, leading to the confusion on the empirical selection of knowledge distillation methods. In this study, we argue that token-level distillation, with its more complex objective (i.e., distribution), is better suited for “simple” scenarios, while sentence-level distillation excels in “complex” scenarios. To substantiate our hypothesis, we systematically analyze the performance of distillation methods by varying the model size of student models, the complexity of text, and the difficulty of decoding procedure. While our experimental results validate our hypothesis, defining the complexity level of a given scenario remains a challenging task. So we further introduce a novel hybrid method that combines token-level and sentence-level distillation through a gating mechanism, aiming to leverage the advantages of both individual methods. Experiments demonstrate that the hybrid method surpasses the performance of token-level or sentence-level distillation methods and the previous works by a margin, demonstrating the effectiveness of the proposed hybrid method. Keywords: Natural Language Processing: NLP: Machine translation and multilinguality Natural Language Processing: NLP: Interpretability and analysis of models for NLP Natural Language Processing: NLP: Other Natural Language Processing: NLP: Summarization},
  archive   = {C_IJCAI},
  author    = {Jingxuan Wei and Linzhuang Sun and Yichong Leng and Xu Tan and Bihui Yu and Ruifeng Guo},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/722},
  month     = {8},
  pages     = {6531-6540},
  title     = {Sentence-level or token-level? a comprehensive study on knowledge distillation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Beyond what if: Advancing counterfactual text generation
with structural causal modeling. <em>IJCAI</em>, 6522–6530. (<a
href="https://doi.org/10.24963/ijcai.2024/721">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Exploring the realms of counterfactuals, this paper introduces a versatile approach in text generation using structural causal models (SCM), broadening the scope beyond traditional singular causal studies to encompass complex, multi-layered relationships. To comprehensively explore these intricate, multi-layered causal relationships in text generation, we introduce a generalized approach based on the structural causal model (SCM), adept at handling complex causal interactions in a spectrum ranging from everyday stories to financial reports.Specifically, our method begins by disentangling each component of the text into pairs of latent variables, representing elements that remain unchanged and those subject to variation. Subsequently, counterfactual interventions are applied to these latent variables, facilitating the generation of outcomes that are influenced by complex causal dynamics. Extensive experiments have been conducted on both a public story generation dataset and a specially constructed dataset in the financial domain. The experimental results demonstrate that our approach achieves state-of-the-art performance across a range of automatic and human evaluation criteria, underscoring its effectiveness and versatility in diverse text generation contexts. Keywords: Natural Language Processing: NLP: Language generation Machine Learning: ML: Causality Natural Language Processing: NLP: Applications},
  archive   = {C_IJCAI},
  author    = {Ziao Wang and Xiaofeng Zhang and Hongwei Du},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/721},
  month     = {8},
  pages     = {6522-6530},
  title     = {Beyond what if: Advancing counterfactual text generation with structural causal modeling},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Purpose enhanced reasoning through iterative prompting:
Uncover latent robustness of ChatGPT on code comprehension.
<em>IJCAI</em>, 6513–6521. (<a
href="https://doi.org/10.24963/ijcai.2024/720">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Code comments are crucial for gaining in-depth insights to facilitate code comprehension. The key to obtaining these insights lies in precisely summarizing the main purpose of the code. Recent approaches on code comment generation lie in prompting large language models (LLMs) such as ChatGPT, instead of training/fine-tuning specific models. Although ChatGPT demonstrates an impressive performance in code comprehension, it still suffers from robustness challenges in consistently producing high-quality code comments. This is because ChatGPT prioritizes the semantics of code tokens, which makes it vulnerable to commonly encountered benign perturbations such as variable name replacements. This study proposes a modular prompting paradigm Perthept to effectively mitigate the negative effects caused by such minor perturbations. Perthept iteratively enhances the reasoning depth to reach the main purpose of the code. Perthept demonstrates robustness under the scenario where there is stochasticity or unreliability in ChatGPT&#39;s responses. We give a comprehensive evaluation across four public datasets to show the consistent robustness improvement with our proposed methodology over other models. Keywords: Natural Language Processing: NLP: Summarization Natural Language Processing: NLP: Tools},
  archive   = {C_IJCAI},
  author    = {Yi Wang and Qidong Zhao and Dongkuan Xu and Xu Liu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/720},
  month     = {8},
  pages     = {6513-6521},
  title     = {Purpose enhanced reasoning through iterative prompting: Uncover latent robustness of ChatGPT on code comprehension},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). NegativePrompt: Leveraging psychology for large language
models enhancement via negative emotional stimuli. <em>IJCAI</em>,
6504–6512. (<a href="https://doi.org/10.24963/ijcai.2024/719">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Large Language Models (LLMs) have become integral to a wide spectrum of applications, ranging from traditional computing tasks to advanced artificial intelligence (AI) applications. This widespread adoption has spurred extensive research into LLMs across various disciplines, including the social sciences. Notably, studies have revealed that LLMs possess emotional intelligence, which can be further developed through positive emotional stimuli. This discovery raises an intriguing question: can negative emotions similarly influence LLMs, potentially enhancing their performance? In response to this question, we introduce NegativePrompt, a novel approach underpinned by psychological principles, involving ten specifically designed negative emotional stimuli. We embark on rigorous experimental evaluations of five LLMs including Flan-T5-Large, Vicuna, Llama 2, ChatGPT, and GPT-4, across a set of 45 tasks. The results are revealing: NegativePrompt markedly enhances the performance of LLMs, evidenced by relative improvements of 12.89% in Instruction Induction tasks and 46.25% in BIG-Bench tasks. Moreover, we conduct attention visualization experiments to decipher the underlying mechanisms of NegativePrompt&#39;s influence. Our research contributes significantly to the understanding of LLMs and emotion interaction, demonstrating the practical efficacy of NegativePrompt as an emotion-driven method and offering novel insights for the enhancement of LLMs in real-world applications. The code is available at https://github.com/wangxu0820/NegativePrompt. Keywords: Natural Language Processing: NLP: Language models Natural Language Processing: NLP: Applications},
  archive   = {C_IJCAI},
  author    = {Xu Wang and Cheng Li and Yi Chang and Jindong Wang and Yuan Wu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/719},
  month     = {8},
  pages     = {6504-6512},
  title     = {NegativePrompt: Leveraging psychology for large language models enhancement via negative emotional stimuli},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Two-stage semi-supervised speaker recognition with gated
label learning. <em>IJCAI</em>, 6495–6503. (<a
href="https://doi.org/10.24963/ijcai.2024/718">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Speaker recognition technologies have been successfully applied in diverse domains, benefiting from the advance of deep learning. Nevertheless, current efforts are still subject to the lack of labeled data. Such issues have been attempted in computer vision, through semi-supervised learning (SSL) that assigns pseudo labels for unlabeled data, undertaking the role of labeled ones. Through our empirical evaluations, the state-of-the-art SSL methods show unsatisfactory performance in speaker recognition tasks, due to the imbalance between the quantity and quality of pseudo labels. Therefore, in this work, we propose a two-stage SSL framework, with the aim to address the data scarcity challenge. We first construct an initial contrastive learning network, where the encoder outputs the embedding representation of utterances. Furthermore, we construct an iterative holistic semi-supervised learning network that involves a clustering strategy to assign pseudo labels, and a gated label learning (GLL) strategy to further select reliable pseudo-label data. Systematical evaluations show that our proposed framework achieves superior performance in speaker recognition than the state-of-the-art methods, matching the performance of supervised learning. Keywords: Natural Language Processing: NLP: Speech Machine Learning: ML: Semi-supervised learning},
  archive   = {C_IJCAI},
  author    = {Xingmei Wang and Jiaxiang Meng and Kong Aik Lee and Boquan Li and Jinghan Liu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/718},
  month     = {8},
  pages     = {6495-6503},
  title     = {Two-stage semi-supervised speaker recognition with gated label learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Correct and optimal: The regular expression inference
challenge. <em>IJCAI</em>, 6486–6494. (<a
href="https://doi.org/10.24963/ijcai.2024/717">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose regular expression inference (REI) as a challenge for code/language modelling, and the wider machine learning community. REI is a supervised machine learning (ML) and program optimisation task, and poses the problem of finding minimal regular expressions from examples: Given two finite sets of strings P and N and a cost function cost(·), the task is to generate an expression r that accepts all strings in P and rejects all strings in N , while no other such expression r′ exists with cost(r′) &lt; cost(r). REI has advantages as a challenge problem: (i) regular expressions are well-known, widely used, and a natural idealisation of code; (ii) REI’s asymptotic worst-case complexity is well understood; (iii) REI has a small number of easy to understand parameters (e.g. P or N cardinality, string lengths of examples, or the cost function); this lets us easily finetune REI-hardness; (iv) REI, with its emphasis on optimisation, is an unsolved problem for deep learning based ML. Recently, an REI solver was implemented on GPUs, using program synthesis techniques. This enabled, for the first time, fast generation of minimal regular expressions for complex REI instances. Building on this advance, we generate and publish the first large-scale datasets for REI, and devise and evaluate several initial heuristic and machine learning baselines. We invite the community to participate and explore ML methods that learn to solve REI problems. We believe that progress in REI directly translates to progress in code/language modelling. Keywords: Natural Language Processing: NLP: Resources and evaluation Machine Learning: ML: Applications Machine Learning: ML: Other Natural Language Processing: NLP: Other},
  archive   = {C_IJCAI},
  author    = {Mojtaba Valizadeh and Philip John Gorinski and Ignacio Iacobacci and Martin Berger},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/717},
  month     = {8},
  pages     = {6486-6494},
  title     = {Correct and optimal: The regular expression inference challenge},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Contextualized speech recognition: Rethinking second-pass
rescoring with generative large language models. <em>IJCAI</em>,
6478–6485. (<a href="https://doi.org/10.24963/ijcai.2024/716">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Automatic Speech Recognition (ASR) systems have witnessed notable advancements in recent years. Contextualized ASR tasks require recognizing speech not as isolated utterances but within the broader context in which they occur. Conventional approaches often employ a second-pass paradigm to re-rank initial transcriptions, yet they risk propagating errors across candidate hypotheses, thereby compromising recognition precision. In this study, we introduce a novel framework that diverges from typical second-pass rescoring methods. Given n-best hypotheses, we leverage prompting with a large language model for contextualized second-pass generation. Besides pursuing higher accuracy, we aim to explore the performance boundaries without substantially altering the underlying pre-trained speech and language models. We investigate the effectiveness of the proposed paradigm through zero-shot prompting and strategic low-rank adaptation tuning. On the multi-accent spoken reading comprehension benchmark SQuAD-SRC, both prompting and fine-tuned models outperform the 1-best ASR hypothesis, achieving notable relative Word Error Rate (WER) improvements of 13.6% and 45.9%, respectively. The results suggest that the proposed approach enhances transcription accuracy and contextual understanding. Keywords: Natural Language Processing: NLP: Speech},
  archive   = {C_IJCAI},
  author    = {Yixuan Tang and Anthony K. H. Tung},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/716},
  month     = {8},
  pages     = {6478-6485},
  title     = {Contextualized speech recognition: Rethinking second-pass rescoring with generative large language models},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Decoupling breaks data barriers: A decoupled pre-training
framework for multi-intent spoken language understanding.
<em>IJCAI</em>, 6469–6477. (<a
href="https://doi.org/10.24963/ijcai.2024/715">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-intent Spoken Language Understanding (Multi-intent SLU) can extract multiple intents in a single utterance, gaining increasing attention. Nevertheless, current multi-intent SLU approaches still heavily rely on large amounts of annotated multi-intent SLU data, which makes it hard to be satisfied in real-world scenarios without sufficient data. Motivated by this, we introduce a novel decoupled pre-training framework (DPF) to address the data-scarcity problem, achieving to leverage of abundant multi-intent-free SLU data to enhance multi-intent SLU. Specifically, DPF first decouples the multi-intent SLU task into two abilities: (1) task-agnostic ability to locate the task-agnostic slot entity span and (2) task-specific ability to predict the task-specific slot and intent labels simultaneously. The key insight of DPF is that such decomposition allows us to design a two-stage decoupled pre-training procedure to enhance both task-agnostic ability and task-specific ability with abundant multi-intent-free SLU data (i.e., NER and single-intent SLU data), respectively. Experimental results on two standard benchmarks (e.g., MixATIS and MixSNIPS) demonstrate the effectiveness of DPF by achieving superior performance. In addition, extensive analyses reveal that utilizing the multi-intent-free data can effectively enhance multi-intent SLU. Keywords: Natural Language Processing: NLP: Dialogue and interactive systems},
  archive   = {C_IJCAI},
  author    = {Libo Qin and Qiguang Chen and Jingxuan Zhou and Qinzheng Li and Chunlin Lu and Wanxiang Che},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/715},
  month     = {8},
  pages     = {6469-6477},
  title     = {Decoupling breaks data barriers: A decoupled pre-training framework for multi-intent spoken language understanding},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Memorizing documents with guidance in large language models.
<em>IJCAI</em>, 6460–6468. (<a
href="https://doi.org/10.24963/ijcai.2024/714">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Training data plays a pivotal role in AI models. Large language models (LLMs) are trained with massive amounts of documents, and their parameters hold document-related contents. Recently, several studies identified content-specific locations in LLMs by examining the parameters. Instead of the post hoc interpretation, we propose another approach. We propose document-wise memory architecture to track document memories in training. The proposed architecture maps document representations to memory entries, which softly mask memories in the forward process of LLMs. Additionally, we propose document guidance loss, which increases the likelihood of text with document memories and reduces the likelihood of the text with the memories of other documents. Experimental results on Wikitext-103-v1 with Pythia-1B show that the proposed methods provide different memory entries for documents and high recall of document-related content in generation with trained document-wise memories. Keywords: Natural Language Processing: NLP: Language models Natural Language Processing: NLP: Embeddings Natural Language Processing: NLP: Interpretability and analysis of models for NLP Natural Language Processing: NLP: Language generation},
  archive   = {C_IJCAI},
  author    = {Bumjin Park and Jaesik Choi},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/714},
  month     = {8},
  pages     = {6460-6468},
  title     = {Memorizing documents with guidance in large language models},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Innovative directional encoding in speech processing:
Leveraging spherical harmonics injection for multi-channel speech
enhancement. <em>IJCAI</em>, 6451–6459. (<a
href="https://doi.org/10.24963/ijcai.2024/713">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-channel speech enhancement leverages multiple microphones to extract target speech signals amid background noise. Effectively utilizing directional cues is key for robust enhancement. While deep learning shows promise for multi-channel speech processing, most methods operate on short-time Fourier transform (STFT) coefficients directly. We propose using spherical harmonics transform (SHT) coefficients as auxiliary inputs to models. which concisely represent spatial distributions. SHT allows signals from varying numbers of microphones to be converted into coefficients of a consistent dimension. The proposed technique enables a single model to generalize to microphone arrays with varying configurations, rather than requiring a specialized model for each array layout. We present two architectures with SHT-based auxiliary inputs: parallel and serial. Specifically, the parallel model contains two encoders - one for STFT and another for SHT. By fusing both encoders&#39; outputs in the decoder to estimate the enhanced STFT, it effectively incorporates spatial context. For the serial approach, we first apply SHT to the signals and then take STFT of the transformed signals as network inputs. Evaluations of the TIMIT dataset under fluctuating noise and reverberation demonstrate our model outperforms established benchmarks. Remarkably, these results are attained with reduced computations and parameters. Furthermore, experiments on the MS-SNSD dataset show the proposed method can enhance the generalization ability of networks. The source code is publicly accessible at https://github.com/Pandade1997/SH_injection. Keywords: Natural Language Processing: NLP: Information extraction Machine Learning: ML: Applications Machine Learning: ML: Representation learning Machine Learning: ML: Trustworthy machine learning},
  archive   = {C_IJCAI},
  author    = {Jiahui Pan and Pengjie Shen and Hui Zhang and Xueliang Zhang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/713},
  month     = {8},
  pages     = {6451-6459},
  title     = {Innovative directional encoding in speech processing: Leveraging spherical harmonics injection for multi-channel speech enhancement},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Contrastive representation learning for self-supervised
taxonomy completion. <em>IJCAI</em>, 6442–6450. (<a
href="https://doi.org/10.24963/ijcai.2024/712">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Taxonomy completion, a self-supervised task, aims to add new concepts to an existing taxonomy by attaching them to appropriate hypernym and hyponym pairs. Researchers have proposed several approaches to capture the essential relationships in taxonomy using semantic or structural information. However, they either construct training signals from a single view or simply use a random sampling strategy, making it insufficient to capture various relations in taxonomic structure and learn quality representations. To address this, we propose CoSTC, a contrastive learning framework that captures diverse relations and improves representations for taxonomy completion. It uses two contrasting views, namely intra-view and inter-view, to provide rich self-supervised signals. In intra-view contrasting, we exploit the correlations within queries and within positions by performing instance-level discrimination task. In inter-view contrasting, we use a sampling strategy that considers diversity and hardness to select representative pairs, enhancing the learning of fine-grained query-position relations. Experimental results on three datasets verify the effectiveness of our approach. Our code is available at https://github.com/nyh-a/CoSTC. Keywords: Natural Language Processing: NLP: Information extraction},
  archive   = {C_IJCAI},
  author    = {Yuhang Niu and Hongyuan Xu and Ciyi Liu and Yanlong Wen and Xiaojie Yuan},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/712},
  month     = {8},
  pages     = {6442-6450},
  title     = {Contrastive representation learning for self-supervised taxonomy completion},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ScreenAgent: A vision language model-driven computer control
agent. <em>IJCAI</em>, 6433–6441. (<a
href="https://doi.org/10.24963/ijcai.2024/711">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Large Language Models (LLM) can invoke a variety of tools and APIs to complete complex tasks. The computer, as the most powerful and universal tool, could potentially be controlled by a trained LLM agent. Powered by the computer, we can hopefully build a more generalized agent to assist humans in various daily digital works. In this paper, we construct an environment for a Vision Language Model (VLM) agent to interact with a real computer screen. Within this environment, the agent can observe screenshots and manipulate the Graphical User Interface (GUI) by outputting mouse and keyboard actions. We also design an automated control pipeline that includes planning, acting, and reflecting phases, guiding the agent to continuously interact with the environment and complete multi-step tasks. Additionally, we construct the ScreenAgent Dataset, which collects screenshots and action sequences when completing daily computer tasks. Finally, we train a model, ScreenAgent, which achieves comparable computer control capabilities to GPT-4V and demonstrated more precise UI positioning capabilities. Our attempts could inspire further research on building a generalist LLM agent. The code and more detailed information are at https://github.com/niuzaisheng/ScreenAgent. Keywords: Natural Language Processing: NLP: Dialogue and interactive systems Agent-based and Multi-agent Systems: MAS: Human-agent interaction Computer Vision: CV: Vision, language and reasoning Natural Language Processing: NLP: Resources and evaluation},
  archive   = {C_IJCAI},
  author    = {Runliang Niu and Jindong Li and Shiqi Wang and Yali Fu and Xiyu Hu and Xueyuan Leng and He Kong and Yi Chang and Qi Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/711},
  month     = {8},
  pages     = {6433-6441},
  title     = {ScreenAgent: A vision language model-driven computer control agent},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Putting back the stops: Integrating syntax with neural topic
models. <em>IJCAI</em>, 6424–6432. (<a
href="https://doi.org/10.24963/ijcai.2024/710">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Syntax and semantics are two key concepts for language understanding. Topic models typically represent the semantics of a text corpus, while removing syntactic information during preprocessing. Without preprocessing, the generated topics become uninterpretable because the syntactic words dominate generated topics. To learn interpretable topics while keeping valuable syntactic information, we propose a novel framework that can simultaneously learn both syntactic and semantic topics from the corpus without requiring any preprocessing. A context network leverages textual dependencies to distinguish between syntactic and semantic words, while a composite VAE topic model learns two sets of topics. We demonstrate on seven datasets that our proposed method effectively captures both syntactic and semantic representations of a corpus while outperforming state-of-the-art neural topic models and statistical topic models in terms of topic quality. Keywords: Natural Language Processing: NLP: Interpretability and analysis of models for NLP Machine Learning: ML: Applications Machine Learning: ML: Generative models Natural Language Processing: NLP: Information extraction},
  archive   = {C_IJCAI},
  author    = {Mayank Nagda and Sophie Fellenz},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/710},
  month     = {8},
  pages     = {6424-6432},
  title     = {Putting back the stops: Integrating syntax with neural topic models},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Separate in the speech chain: Cross-modal conditional
audio-visual target speech extraction. <em>IJCAI</em>, 6415–6423. (<a
href="https://doi.org/10.24963/ijcai.2024/709">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The integration of visual cues has revitalized the performance of the target speech extraction task, elevating it to the forefront of the field. Nevertheless, this multi-modal learning paradigm often encounters the challenge of modality imbalance. In audio-visual target speech extraction tasks, the audio modality tends to dominate, potentially overshadowing the importance of visual guidance. To tackle this issue, we propose AVSepChain, drawing inspiration from the speech chain concept. Our approach partitions the audio-visual target speech extraction task into two stages: speech perception and speech production. In the speech perception stage, audio serves as the dominant modality, while visual information acts as the conditional modality. Conversely, in the speech production stage, the roles are reversed. This transformation of modality status aims to alleviate the problem of modality imbalance. Additionally, we introduce a contrastive semantic matching loss to ensure that the semantic information conveyed by the generated speech aligns with the semantic information conveyed by lip movements during the speech production stage. Through extensive experiments conducted on multiple benchmark datasets for audio-visual target speech extraction, we showcase the superior performance achieved by our proposed method. Keywords: Natural Language Processing: NLP: Speech Machine Learning: ML: Multi-modal learning},
  archive   = {C_IJCAI},
  author    = {Zhaoxi Mu and Xinyu Yang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/709},
  month     = {8},
  pages     = {6415-6423},
  title     = {Separate in the speech chain: Cross-modal conditional audio-visual target speech extraction},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Span-based unified named entity recognition framework via
contrastive learning. <em>IJCAI</em>, 6406–6414. (<a
href="https://doi.org/10.24963/ijcai.2024/708">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Traditional Named Entity Recognition (NER) models are typically designed for domain-specific datasets and limited to fixed predefined types, resulting in difficulty generalizing to new domains. Recently, prompt-based generative methods attempt to mitigate this constraint by training models jointly on diverse datasets and extract specified entities via prompt instructions. However, due to autoregressive structure, these methods cannot directly model entity span and suffer from slow sequential decoding. To address these issues, we propose a novel Span-based Unified NER framework via contrastive learning (SUNER), which aligns text span and entity type representations in a shared semantic space to extract entities in parallel. Specifically, we first extract mention spans without considering entity types to better generalize across datasets. Then, by leveraging the power of contrastive learning and well-designed entity marker structure, we map candidate spans and their textual type descriptions into the same vector representation space to differentiate entities across domains. Extensive experiments on both supervised and zero/few-shot settings demonstrate that proposed SUNER model achieves better performance and higher efficiency than previous state-of-the-art unified NER models. Keywords: Natural Language Processing: NLP: Named entities Natural Language Processing: NLP: Information extraction},
  archive   = {C_IJCAI},
  author    = {Hongli Mao and Xian-Ling Mao and Hanlin Tang and Yu-Ming Shang and Xiaoyan Gao and Ao-Jie Ma and Heyan Huang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/708},
  month     = {8},
  pages     = {6406-6414},
  title     = {Span-based unified named entity recognition framework via contrastive learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Prompt-enhanced network for hateful meme classification.
<em>IJCAI</em>, 6397–6405. (<a
href="https://doi.org/10.24963/ijcai.2024/707">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The dynamic expansion of social media has led to an inundation of hateful memes on media platforms, accentuating the growing need for efficient identification and removal. Acknowledging the constraints of conventional multimodal hateful meme classification, which heavily depends on external knowledge and poses the risk of including irrelevant or redundant content, we developed Pen—a prompt-enhanced network framework based on the prompt learning approach. Specifically, after constructing the sequence through the prompt method and encoding it with a language model, we performed region information global extraction on the encoded sequence for multi-view perception. By capturing global information about inference instances and demonstrations, Pen facilitates category selection by fully leveraging sequence information. This approach significantly improves model classification accuracy. Additionally, to bolster the model&#39;s reasoning capabilities in the feature space, we introduced prompt-aware contrastive learning into the framework to improve the quality of sample feature distributions. Through extensive ablation experiments on two public datasets, we evaluate the effectiveness of the Pen framework, concurrently comparing it with state-of-the-art model baselines. Our research findings highlight that Pen surpasses manual prompt methods, showcasing superior generalization and classification accuracy in hateful meme classification tasks. Our code is available at https://github.com/juszzi/Pen. Keywords: Natural Language Processing: NLP: Text classification Machine Learning: ML: Clustering Machine Learning: ML: Feature extraction, selection and dimensionality reduction Natural Language Processing: NLP: Language models},
  archive   = {C_IJCAI},
  author    = {Junxi Liu and Yanyan Feng and Jiehai Chen and Yun Xue and Fenghuan Li},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/707},
  month     = {8},
  pages     = {6397-6405},
  title     = {Prompt-enhanced network for hateful meme classification},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Improving zero-shot cross-lingual transfer via progressive
code-switching. <em>IJCAI</em>, 6388–6396. (<a
href="https://doi.org/10.24963/ijcai.2024/706">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Code-switching is a data augmentation scheme mixing words from multiple languages into source lingual text. It has achieved considerable generalization performance of cross-lingual transfer tasks by aligning cross-lingual contextual word representations. However, uncontrolled and over-replaced code-switching would augment dirty samples to model training. In other words, the excessive code-switching text samples will negatively hurt the models&#39; cross-lingual transferability. To this end, we propose a Progressive Code-Switching (PCS) method to gradually generate moderately difficult code-switching examples for the model to discriminate from easy to hard. The idea is to incorporate progressively the preceding learned multilingual knowledge using easier code-switching data to guide model optimization on succeeding harder code-switching data. Specifically, we first design a difficulty measurer to measure the impact of replacing each word in a sentence based on the word relevance score. Then a code-switcher generates the code-switching data of increasing difficulty via a controllable temperature variable. In addition, a training scheduler decides when to sample harder code-switching data for model training. Experiments show our model achieves state-of-the-art results on three different zero-shot cross-lingual transfer tasks across ten languages. Keywords: Natural Language Processing: NLP: Machine translation and multilinguality Natural Language Processing: NLP: Applications},
  archive   = {C_IJCAI},
  author    = {Zhuoran Li and Chunming Hu and Junfan Chen and Zhijun Chen and Xiaohui Guo and Richong Zhang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/706},
  month     = {8},
  pages     = {6388-6396},
  title     = {Improving zero-shot cross-lingual transfer via progressive code-switching},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). LocMoE: A low-overhead MoE for large language model
training. <em>IJCAI</em>, 6377–6387. (<a
href="https://doi.org/10.24963/ijcai.2024/705">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Mixtures-of-Experts (MoE) model is a widespread distributed and integrated learning method for large language models (LLM), which is favored due to its ability to sparsify and expand models efficiently. However, the performance of MoE is limited by load imbalance and high latency of All-to-All communication, along with relatively redundant computation owing to large expert capacity. Load imbalance may result from existing routing policies that consistently tend to select certain experts. The frequent inter-node communication in the All-to-All procedure also significantly prolongs the training time. To alleviate the above performance problems, we propose a novel routing strategy that combines load balance and locality by converting partial inter-node communication to that of intra-node. Notably, we elucidate that there is a minimum threshold for expert capacity, calculated through the maximal angular deviation between the gating weights of the experts and the assigned tokens. We port these modifications on the PanGu-Σ model based on the MindSpore framework with multi-level routing and conduct experiments on Ascend clusters. The experiment results demonstrate that the proposed LocMoE reduces training time per epoch by 12.68% to 22.24% compared to classical routers, such as hash router and switch router, without impacting the model accuracy. Keywords: Natural Language Processing: NLP: Language models Natural Language Processing: NLP: Interpretability and analysis of models for NLP Natural Language Processing: NLP: Other},
  archive   = {C_IJCAI},
  author    = {Jing Li and Zhijie Sun and Xuan He and Li Zeng and Yi Lin and Entong Li and Binfan Zheng and Rongqian Zhao and Xin Chen},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/705},
  month     = {8},
  pages     = {6377-6387},
  title     = {LocMoE: A low-overhead MoE for large language model training},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Recall, retrieve and reason: Towards better in-context
relation extraction. <em>IJCAI</em>, 6368–6376. (<a
href="https://doi.org/10.24963/ijcai.2024/704">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Relation extraction (RE) aims to identify relations between entities mentioned in texts. Although large language models (LLMs) have demonstrated impressive in-context learning (ICL) abilities in various tasks, they still suffer from poor performances compared to most supervised fine-tuned RE methods. Utilizing ICL for RE with LLMs encounters two challenges: (1) retrieving good demonstrations from training examples, and (2) enabling LLMs exhibit strong ICL abilities in RE. On the one hand, retrieving good demonstrations is a non-trivial process in RE, which easily results in low relevance regarding entities and relations. On the other hand, ICL with an LLM achieves poor performance in RE while RE is different from language modeling in nature or the LLM is not large enough. In this work, we propose a novel recall-retrieve-reason RE framework that synergizes LLMs with retrieval corpora (training examples) to enable relevant retrieving and reliable in-context reasoning. Specifically, we distill the consistently ontological knowledge from training datasets to let LLMs generate relevant entity pairs grounded by retrieval corpora as valid queries. These entity pairs are then used to retrieve relevant training examples from the retrieval corpora as demonstrations for LLMs to conduct better ICL via instruction tuning. Extensive experiments on different LLMs and RE datasets demonstrate that our method generates relevant and valid entity pairs and boosts ICL abilities of LLMs, achieving competitive or new state-of-the-art performance on sentence-level RE compared to previous supervised fine-tuning methods and ICL-based methods. Keywords: Natural Language Processing: NLP: Information extraction},
  archive   = {C_IJCAI},
  author    = {Guozheng Li and Peng Wang and Wenjun Ke and Yikai Guo and Ke Ji and Ziyu Shang and Jiajun Liu and Zijie Xu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/704},
  month     = {8},
  pages     = {6368-6376},
  title     = {Recall, retrieve and reason: Towards better in-context relation extraction},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Empirical analysis of dialogue relation extraction with
large language models. <em>IJCAI</em>, 6359–6367. (<a
href="https://doi.org/10.24963/ijcai.2024/703">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Dialogue relation extraction (DRE) aims to extract relations between two arguments within a dialogue, which is more challenging than standard RE due to the higher person pronoun frequency and lower information density in dialogues. However, existing DRE methods still suffer from two serious issues: (1) hard to capture long and sparse multi-turn information, and (2) struggle to extract golden relations based on partial dialogues, which motivates us to discover more effective methods that can alleviate the above issues. We notice that the rise of large language models (LLMs) has sparked considerable interest in evaluating their performance across diverse tasks. To this end, we initially investigate the capabilities of different LLMs in DRE, considering both proprietary models and open-source models. Interestingly, we discover that LLMs significantly alleviate two issues in existing DRE methods. Generally, we have following findings: (1) scaling up model size substantially boosts the overall DRE performance and achieves exceptional results, tackling the difficulty of capturing long and sparse multi-turn information; (2) LLMs encounter with much smaller performance drop from entire dialogue setting to partial dialogue setting compared to existing methods; (3) LLMs deliver competitive or superior performances under both full-shot and few-shot settings compared to current state-of-the-art; (4) LLMs show modest performances on inverse relations but much stronger improvements on general relations, and they can handle dialogues of various lengths especially for longer sequences. Keywords: Natural Language Processing: NLP: Information extraction},
  archive   = {C_IJCAI},
  author    = {Guozheng Li and Zijie Xu and Ziyu Shang and Jiajun Liu and Ke Ji and Yikai Guo},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/703},
  month     = {8},
  pages     = {6359-6367},
  title     = {Empirical analysis of dialogue relation extraction with large language models},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Meta in-context learning makes large language models better
zero and few-shot relation extractors. <em>IJCAI</em>, 6350–6358. (<a
href="https://doi.org/10.24963/ijcai.2024/702">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Relation extraction (RE) is an important task that aims to identify the relationships between entities in texts. While large language models (LLMs) have revealed remarkable in-context learning (ICL) capability for general zero and few-shot learning, recent studies indicate that current LLMs still struggle with zero and few-shot RE. Previous studies are mainly dedicated to design prompt formats and select good examples for improving ICL-based RE. Although both factors are vital for ICL, if one can fundamentally boost the ICL capability of LLMs in RE, the zero and few-shot RE performance via ICL would be significantly improved. To this end, we introduce Micre (Meta In-Context learning of LLMs for Relation Extraction), a new meta-training framework for zero and few-shot RE where an LLM is tuned to do ICL on a diverse collection of RE datasets (i.e., learning to learn in context for RE). Through meta-training, the model becomes more effectively to learn a new RE task in context by conditioning on a few training examples with no parameter updates or task-specific templates at inference time, enabling better zero and few-shot task generalization. We experiment Micre on various LLMs with different model scales and 12 public RE datasets, and then evaluate it on unseen RE benchmarks under zero and few-shot settings. Micre delivers comparable or superior performance compared to a range of baselines including supervised fine-tuning and typical in-context learning methods. We find that the gains are particular significant for larger model scales, and using a diverse set of the meta-training RE datasets is key to improvements. Empirically, we show that Micre can transfer the relation semantic knowledge via relation label name during inference on target RE datasets. Keywords: Natural Language Processing: NLP: Information extraction},
  archive   = {C_IJCAI},
  author    = {Guozheng Li and Peng Wang and Jiajun Liu and Yikai Guo and Ke Ji and Ziyu Shang and Zijie Xu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/702},
  month     = {8},
  pages     = {6350-6358},
  title     = {Meta in-context learning makes large language models better zero and few-shot relation extractors},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reframing spatial reasoning evaluation in language models: A
real-world simulation benchmark for qualitative reasoning.
<em>IJCAI</em>, 6342–6349. (<a
href="https://doi.org/10.24963/ijcai.2024/701">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Spatial reasoning plays a vital role in both human cognition and machine intelligence, prompting new research into language models&#39; (LMs) capabilities in this regard. However, existing benchmarks reveal shortcomings in evaluating qualitative spatial reasoning (QSR). These benchmarks typically present oversimplified scenarios or unclear natural language descriptions, hindering effective evaluation. We present a novel benchmark for assessing QSR in LMs, which is grounded in realistic 3D simulation data, offering a series of diverse room layouts with various objects and their spatial relationships. This approach provides a more detailed and context-rich narrative for spatial reasoning evaluation, diverging from traditional, toy-task-oriented scenarios. Our benchmark encompasses a broad spectrum of qualitative spatial relationships, including topological, directional, and distance relations. These are presented with different viewing points, varied granularities, and density of relation constraints to mimic real-world complexities. A key contribution is our logic-based consistency-checking tool, which enables the assessment of multiple plausible solutions, aligning with real-world scenarios where spatial relationships are often open to interpretation. Our benchmark evaluation of advanced LMs reveals their strengths and limitations in spatial reasoning. They face difficulties with multi-hop spatial reasoning and interpreting a mix of different view descriptions, pointing to areas for future improvement. Keywords: Natural Language Processing: NLP: Resources and evaluation Knowledge Representation and Reasoning: KRR: Qualitative, geometric, spatial, and temporal reasoning Constraint Satisfaction and Optimization: CSO: Applications Knowledge Representation and Reasoning: KRR: Learning and reasoning},
  archive   = {C_IJCAI},
  author    = {Fangjun Li and David C. Hogg and Anthony G. Cohn},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/701},
  month     = {8},
  pages     = {6342-6349},
  title     = {Reframing spatial reasoning evaluation in language models: A real-world simulation benchmark for qualitative reasoning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bridge to non-barrier communication: Gloss-prompted
fine-grained cued speech gesture generation with diffusion model.
<em>IJCAI</em>, 6333–6341. (<a
href="https://doi.org/10.24963/ijcai.2024/700">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Cued Speech (CS) is an advanced visual phonetic encoding system that integrates lip reading with hand codings, enabling people with hearing impairments to communicate efficiently. CS video generation aims to produce specific lip and gesture movements of CS from audio or text inputs. The main challenge is that given limited CS data, we strive to simultaneously generate fine-grained hand and finger movements, as well as lip movements, meanwhile the two kinds of movements need to be asynchronously aligned. Existing CS generation methods are fragile and prone to poor performance due to template-based statistical models and careful hand-crafted pre-processing to fit the models. Therefore, we propose a novel Gloss-prompted Diffusion-based CS Gesture generation framework (called GlossDiff). Specifically, to integrate additional linguistic rules knowledge into the model. we first introduce a bridging instruction called Gloss, which is an automatically generated descriptive text to establish a direct and more delicate semantic connection between spoken language and CS gestures. Moreover, we first suggest rhythm is an important paralinguistic feature for CS to improve the communication efficacy. Therefore, we propose a novel Audio-driven Rhythmic Module (ARM) to learn rhythm that matches audio speech. Moreover, in this work, we design, record, and publish the first Chinese CS dataset with four CS cuers. Extensive experiments demonstrate that our method quantitatively and qualitatively outperforms current state-of-the-art (SOTA) methods. We will release the code and data at glossdiff.github.io/. Keywords: Natural Language Processing: NLP: Speech Computer Vision: CV: Applications},
  archive   = {C_IJCAI},
  author    = {Wentao Lei and Li Liu and Jun Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/700},
  month     = {8},
  pages     = {6333-6341},
  title     = {Bridge to non-barrier communication: Gloss-prompted fine-grained cued speech gesture generation with diffusion model},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LLMem: Estimating GPU memory usage for fine-tuning
pre-trained LLMs. <em>IJCAI</em>, 6324–6332. (<a
href="https://doi.org/10.24963/ijcai.2024/699">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Fine-tuning pre-trained large language models (LLMs) with limited hardware presents challenges due to GPU memory constraints. Various distributed fine-tuning methods have been proposed to alleviate memory constraints on GPU. However, determining the most effective method for achieving rapid fine-tuning while preventing GPU out-of-memory issues in a given environment remains unclear. To address this challenge, we introduce LLMem, a solution that estimates the GPU memory consumption when applying distributed fine-tuning methods across multiple GPUs and identifies the optimal method. We conduct GPU memory usage estimation prior to fine-tuning, leveraging the fundamental structure of transformer-based decoder models and the memory usage distribution of each method. Experimental results show that LLMem accurately estimates peak GPU memory usage on a single GPU, with an error rate of up to 1.6%. Additionally, it shows an average error rate of 3.0% when applying distributed fine-tuning methods to LLMs with more than a billion parameters on multi-GPU setups. Keywords: Natural Language Processing: NLP: Language models Machine Learning: ML: Deep learning architectures},
  archive   = {C_IJCAI},
  author    = {Taeho Kim and Yanming Wang and Vatshank Chaturvedi and Lokesh Gupta and Seyeon Kim and Yongin Kwon and Sangtae Ha},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/699},
  month     = {8},
  pages     = {6324-6332},
  title     = {LLMem: Estimating GPU memory usage for fine-tuning pre-trained LLMs},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Domain-hierarchy adaptation via chain of iterative reasoning
for few-shot hierarchical text classification. <em>IJCAI</em>,
6315–6323. (<a href="https://doi.org/10.24963/ijcai.2024/698">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, various pre-trained language models (PLMs) have been proposed to prove their impressive performances on a wide range of few-shot tasks. However, limited by the unstructured prior knowledge in PLMs, it is difficult to maintain consistent performance on complex hierarchically dependent tasks, especially when the downstream data is extremely scarce. The main challenge is how to transfer the unstructured semantic space in PLMs to the downstream domain hierarchy. Unlike previous work on hierarchical text classification (HTC) which directly performs multi-label classification or uses graph neural network (GNN) to inject label hierarchy, in this work, we study the HTC problem under a few-shot setting to adapt knowledge in PLMs from an unstructured manner to the downstream hierarchy. Technically, we design a simple yet effective method named Hierarchical Iterative Conditional Random Field (HierICRF) to search the most domain-challenging directions and exquisitely crafts domain-hierarchy adaptation as a hierarchical iterative language modeling problem, and then it encourages the model to make hierarchical consistency self-correction during the inference, thereby achieving knowledge transfer with hierarchical consistency preservation. We perform HierICRF on various architectures, and extensive experiments on two popular HTC datasets demonstrate that prompt with HierICRF significantly boosts the few-shot HTC performance with an average Micro-F1 by 28.80% to 1.50% and Macro-F1 by 36.29% to 1.5% over the previous state-of-the-art (SOTA) baselines under few-shot settings (1-&gt;16), while remaining SOTA hierarchical consistency performance. Keywords: Natural Language Processing: NLP: Applications Natural Language Processing: NLP: Text classification},
  archive   = {C_IJCAI},
  author    = {Ke Ji and Peng Wang and Wenjun Ke and Guozheng Li and Jiajun Liu and Jingsheng Gao and Ziyu Shang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/698},
  month     = {8},
  pages     = {6315-6323},
  title     = {Domain-hierarchy adaptation via chain of iterative reasoning for few-shot hierarchical text classification},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Natural language decomposition and interpretation of complex
utterances. <em>IJCAI</em>, 6306–6314. (<a
href="https://doi.org/10.24963/ijcai.2024/697">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Designing natural language interfaces has historically required collecting supervised data to translate user requests into carefully designed intent representations. This requires enumerating and labeling a long tail of user requests, which is challenging. At the same time, large language models (LLMs) encode knowledge about goals and plans that can help conversational assistants interpret user requests requiring numerous steps to complete. We introduce an approach to handle complex-intent-bearing utterances from a user via a process of hierarchical natural language decomposition and interpretation. Our approach uses a pre-trained language model to decompose a complex utterance into a sequence of simpler natural language steps and interprets each step using the language-to-program model designed for the interface. To test our approach, we collect and release DeCU —a new NL-to-program benchmark to evaluate Decomposition of Complex Utterances. Experiments show that the proposed approach enables the interpretation of complex utterances with almost no complex training data, while outperforming standard few-shot prompting approaches. Keywords: Natural Language Processing: NLP: Dialogue and interactive systems Natural Language Processing: NLP: Language grounding Natural Language Processing: NLP: Natural language semantics},
  archive   = {C_IJCAI},
  author    = {Harsh Jhamtani and Hao Fang and Patrick Xia and Eran Levy and Jacob Andreas and Benjamin Van Durme},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/697},
  month     = {8},
  pages     = {6306-6314},
  title     = {Natural language decomposition and interpretation of complex utterances},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GRASP: A novel benchmark for evaluating language GRounding
and situated physics understanding in multimodal language models.
<em>IJCAI</em>, 6297–6305. (<a
href="https://doi.org/10.24963/ijcai.2024/696">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper presents GRASP, a novel benchmark to evaluate the language grounding and physical understanding capabilities of video-based multimodal large language models (LLMs). This evaluation is accomplished via a two-tier approach leveraging Unity simulations. The first level tests for language grounding by assessing a model&#39;s ability to relate simple textual descriptions with visual information. The second level evaluates the model&#39;s understanding of &quot;Intuitive Physics&quot; principles, such as object permanence and continuity. In addition to releasing the benchmark, we use it to evaluate several state-of-the-art multimodal LLMs. Our evaluation reveals significant shortcomings in the language grounding and intuitive physics capabilities of these models. Although they exhibit at least some grounding capabilities, particularly for colors and shapes, these capabilities depend heavily on the prompting strategy. At the same time, all models perform below or at the chance level of 50% in the Intuitive Physics tests, while human subjects are on average 80% correct. These identified limitations underline the importance of using benchmarks like GRASP to monitor the progress of future models in developing these competencies. Keywords: Natural Language Processing: NLP: Resources and evaluation Computer Vision: CV: Vision, language and reasoning Natural Language Processing: NLP: Language grounding},
  archive   = {C_IJCAI},
  author    = {Serwan Jassim and Mario Holubar and Annika Richter and Cornelius Wolff and Xenia Ohmer and Elia Bruni},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/696},
  month     = {8},
  pages     = {6297-6305},
  title     = {GRASP: A novel benchmark for evaluating language GRounding and situated physics understanding in multimodal language models},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ECR-chain: Advancing generative language models to better
emotion-cause reasoners through reasoning chains. <em>IJCAI</em>,
6288–6296. (<a href="https://doi.org/10.24963/ijcai.2024/695">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Understanding the process of emotion generation is crucial for analyzing the causes behind emotions. Causal Emotion Entailment (CEE), an emotion-understanding task, aims to identify the causal utterances in a conversation that stimulate the emotions expressed in a target utterance. However, current works in CEE mainly focus on modeling semantic and emotional interactions in conversations, neglecting the exploration of the emotion-generation process. This hinders the models from deeply understanding emotions, restricting their ability to produce explainable predictions. In this work, inspired by the emotion generation process of &quot;stimulus-appraisal-emotion&quot; in the cognitive appraisal theory, we introduce a step-by-step reasoning method, Emotion-Cause Reasoning Chain (ECR-Chain), to infer the stimulus from the target emotional expressions in conversations. Specifically, we first introduce the ECR-Chain to ChatGPT via few-shot prompting, which significantly improves its performance on the CEE task. We further propose an automated construction process to utilize ChatGPT in building an ECR-Chain set, which can enhance the reasoning abilities of smaller models through supervised training and assist the Vicuna-7B model in achieving state-of-the-art CEE performance. Moreover, our methods can enable these generative language models to effectively perform emotion-cause reasoning in an explainable manner. Our code, data and more details are at https://github.com/hzp3517/ECR-Chain. Keywords: Natural Language Processing: NLP: Sentiment analysis, stylistic analysis, and argument mining},
  archive   = {C_IJCAI},
  author    = {Zhaopei Huang and Jinming Zhao and Qin Jin},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/695},
  month     = {8},
  pages     = {6288-6296},
  title     = {ECR-chain: Advancing generative language models to better emotion-cause reasoners through reasoning chains},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ADELT: Transpilation between deep learning frameworks.
<em>IJCAI</em>, 6279–6287. (<a
href="https://doi.org/10.24963/ijcai.2024/694">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose the Adversarial DEep Learning Transpiler (ADELT), a novel approach to source-to-source transpilation between deep learning frameworks. ADELT uniquely decouples code skeleton transpilation and API keyword mapping. For code skeleton transpilation, it uses few-shot prompting on large language models (LLMs), while for API keyword mapping, it uses contextual embeddings from a code-specific BERT. These embeddings are trained in a domain-adversarial setup to generate a keyword translation dictionary. ADELT is trained on an unlabeled web-crawled deep learning corpus, without relying on any hand-crafted rules or parallel data. It outperforms state-of-the-art transpilers, improving pass@1 rate by 16.2 pts and 15.0 pts for PyTorch-Keras and PyTorch-MXNet transpilation pairs respectively. We provide open access to our code at https://github.com/gonglinyuan/adelt Keywords: Natural Language Processing: NLP: Applications Machine Learning: ML: Adversarial machine learning Natural Language Processing: NLP: Language models Natural Language Processing: NLP: Machine translation and multilinguality},
  archive   = {C_IJCAI},
  author    = {Linyuan Gong and Jiayi Wang and Alvin Cheung},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/694},
  month     = {8},
  pages     = {6279-6287},
  title     = {ADELT: Transpilation between deep learning frameworks},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Large language models are not strong abstract reasoners.
<em>IJCAI</em>, 6270–6278. (<a
href="https://doi.org/10.24963/ijcai.2024/693">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Large Language Models have shown tremendous performance on a large variety of natural language processing tasks, ranging from text comprehension to common sense reasoning. However, the mechanisms responsible for this success remain opaque, and it is unclear whether LLMs can achieve human-like cognitive capabilities or whether these models are still fundamentally circumscribed. Abstract reasoning is a fundamental task for cognition, consisting of finding and applying a general pattern from few data. Evaluating deep neural architectures on this task could give insight into their potential limitations regarding reasoning and their broad generalisation abilities, yet this is currently an under-explored area. In this paper, we introduce a new benchmark for evaluating language models beyond memorization on abstract reasoning tasks. We perform extensive evaluations of state-of-the-art LLMs, showing that they currently achieve very limited performance in contrast with other natural language tasks, even when applying techniques that have been shown to improve performance on other NLP tasks. We argue that guiding LLM generation to follow causal paths could help improve the generalisation and reasoning abilities of LLMs. Keywords: Natural Language Processing: NLP: Language models Machine Learning: ML: Evaluation Machine Learning: ML: Robustness Natural Language Processing: NLP: Question answering},
  archive   = {C_IJCAI},
  author    = {Gaël Gendron and Qiming Bao and Michael Witbrock and Gillian Dobbie},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/693},
  month     = {8},
  pages     = {6270-6278},
  title     = {Large language models are not strong abstract reasoners},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Position debiasing fine-tuning for causal perception in
long-term dialogue. <em>IJCAI</em>, 6261–6269. (<a
href="https://doi.org/10.24963/ijcai.2024/692">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The core of the dialogue system is to generate relevant, informative, and human-like responses based on extensive dialogue history. Recently, dialogue generation domain has seen mainstream adoption of large language models (LLMs), due to its powerful capability in generating utterances. However, there is a natural deficiency for such models, that is, inherent position bias, which may lead them to pay more attention to the nearby utterances instead of causally relevant ones, resulting in generating irrelevant and generic responses in long-term dialogue. To alleviate such problem, in this paper, we propose a novel method, named Causal Perception long-term Dialogue framework (CPD), which employs perturbation-based causal variable discovery method to extract casually relevant utterances from the dialogue history and enhances model causal perception during fine-tuning. Specifically, a local-position awareness method is proposed in CPD for inter-sentence position correlation elimination, which helps models extract causally relevant utterances based on perturbations. Then, a casual-perception fine-tuning strategy is also proposed, to enhance the capability of discovering the causal invariant factors, by differently perturbing causally relevant and non-casually relevant ones for response generation. Experimental results on two datasets prove that our proposed method can effectively alleviate the position bias for multiple LLMs and achieve significant progress compared with existing baselines. Keywords: Natural Language Processing: NLP: Dialogue and interactive systems},
  archive   = {C_IJCAI},
  author    = {Shixuan Fan and Wei Wei and Wendi Li and Xian-Ling Mao and Wenfeng Xie and Dangyang Chen},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/692},
  month     = {8},
  pages     = {6261-6269},
  title     = {Position debiasing fine-tuning for causal perception in long-term dialogue},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving pseudo labels with global-local denoising
framework for cross-lingual named entity recognition. <em>IJCAI</em>,
6252–6260. (<a href="https://doi.org/10.24963/ijcai.2024/691">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Cross-lingual named entity recognition (NER) aims to train an NER model for the target language leveraging only labeled source language data and unlabeled target language data. Prior approaches either perform label projection on translated source language data or employ a source model to assign pseudo labels for target language data and train a target model on these pseudo-labeled data to generalize to the target language. However, these automatic labeling procedures inevitably introduce noisy labels, thus leading to a performance drop. In this paper, we propose a Global-Local Denoising framework (GLoDe) for cross-lingual NER. Specifically, GLoDe introduces a progressive denoising strategy to rectify incorrect pseudo labels by leveraging both global and local distribution information in the semantic space. The refined pseudo-labeled target language data significantly improves the model&#39;s generalization ability. Moreover, previous methods only consider improving the model with language-agnostic features, however, we argue that target language-specific features are also important and should never be ignored. To this end, we employ a simple auxiliary task to achieve this goal. Experimental results on two benchmark datasets with six target languages demonstrate that our proposed GLoDe significantly outperforms current state-of-the-art methods. Keywords: Natural Language Processing: NLP: Named entities Natural Language Processing: NLP: Information extraction},
  archive   = {C_IJCAI},
  author    = {Zhuojun Ding and Wei Wei and Xiaoye Qu and Dangyang Chen},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/691},
  month     = {8},
  pages     = {6252-6260},
  title     = {Improving pseudo labels with global-local denoising framework for cross-lingual named entity recognition},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MMVQA: A comprehensive dataset for investigating multipage
multimodal information retrieval in PDF-based visual question answering.
<em>IJCAI</em>, 6243–6251. (<a
href="https://doi.org/10.24963/ijcai.2024/690">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Document Question Answering (QA) presents a challenge in understanding visually-rich documents (VRD), particularly with lengthy textual content. Existing studies primarily focus on real-world documents with sparse text, while challenges persist in comprehending the hierarchical semantic relations among multiple pages to locate multimodal components. The paper introduces PDF-MVQA, tailored for research journal articles, encompassing multiple pages and multimodal retrieval. Our approach aims to retrieve entire paragraphs containing answers or visually rich document entities like tables and figures. The main contribution is introducing a comprehensive PDF Document VQA dataset, allowing the examination of semantically hierarchical layout structures in text-dominant documents. We also present new VRD-QA frameworks to grasp textual contents and relations among document layouts simultaneously, extending page-level understanding to the entire multi-page document. We aim to enhance the capabilities of existing vision-and-language models in handling challenges posed by text-dominant documents in VRD-QA. Code and Appendix are in https://github.com/adlnlp/pdfmvqa Keywords: Natural Language Processing: NLP: Applications Natural Language Processing: NLP: Resources and evaluation Natural Language Processing: NLP: Information extraction},
  archive   = {C_IJCAI},
  author    = {Yihao Ding and Kaixuan Ren and Jiabin Huang and Siwen Luo and Soyeon Caren Han},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/690},
  month     = {8},
  pages     = {6243-6251},
  title     = {MMVQA: A comprehensive dataset for investigating multipage multimodal information retrieval in PDF-based visual question answering},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generating more audios for end-to-end spoken language
understanding. <em>IJCAI</em>, 6234–6242. (<a
href="https://doi.org/10.24963/ijcai.2024/689">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {End-to-end spoken language understanding (SLU) aims to directly capture the comprehensive semantics from the given spoken utterance without generating any transcript. Since the transcripts might not always be available, Textless SLU is attracting increasing attention, which could eliminate the need for transcripts but often does not perform as well as SLU models trained with transcripts. In this paper, we focus on the scenarios where the transcripts are not available and propose a framework GMA-SLU to generate more audios according to the labels. In order to alleviate the modality gap between text and audio, two language models are developed and discrete tokens are utilized as a bridge, where the first language model utilizes labels to generate semantic tokens and the second language model adopts these obtained semantic tokens and the acoustic tokens of source audios to generate the synthetic audios. All the experiments are conducted on the monolingual SLU dataset SLURP and the multilingual SLU dataset MINDS-14. Experimental results show that our method outperforms the previous best Textless End-to-end SLU models and can obtain the comparable performance with the models trained with the assistance of the corresponding transcripts. Keywords: Natural Language Processing: NLP: Dialogue and interactive systems},
  archive   = {C_IJCAI},
  author    = {Xuxin Cheng and Yuexian Zou},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/689},
  month     = {8},
  pages     = {6234-6242},
  title     = {Generating more audios for end-to-end spoken language understanding},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Continual multimodal knowledge graph construction.
<em>IJCAI</em>, 6225–6233. (<a
href="https://doi.org/10.24963/ijcai.2024/688">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Current Multimodal Knowledge Graph Construction (MKGC) models struggle with the real-world dynamism of continuously emerging entities and relations, often succumbing to catastrophic forgetting—loss of previously acquired knowledge. This study introduces benchmarks aimed at fostering the development of the continual MKGC domain. We further introduce the MSPT framework, designed to surmount the shortcomings of existing MKGC approaches during multimedia data processing. MSPT harmonizes the retention of learned knowledge (stability) and the integration of new data (plasticity), outperforming current continual learning and multimodal methods. Our results confirm MSPT&#39;s superior performance in evolving knowledge environments, showcasing its capacity to navigate the balance between stability and plasticity. Keywords: Natural Language Processing: NLP: Information extraction Data Mining: DM: Knowledge graphs and knowledge base completion Natural Language Processing: NLP: Named entities},
  archive   = {C_IJCAI},
  author    = {Xiang Chen and Jingtian Zhang and Xiaohan Wang and Ningyu Zhang and Tongtong Wu and Yuxiang Wang and Yongheng Wang and Huajun Chen},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/688},
  month     = {8},
  pages     = {6225-6233},
  title     = {Continual multimodal knowledge graph construction},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FactCHD: Benchmarking fact-conflicting hallucination
detection. <em>IJCAI</em>, 6216–6224. (<a
href="https://doi.org/10.24963/ijcai.2024/687">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Despite their impressive generative capabilities, LLMs are hindered by fact-conflicting hallucinations in real-world applications. The accurate identification of hallucinations in texts generated by LLMs, especially in complex inferential scenarios, is a relatively unexplored area. To address this gap, we present FactCHD, a dedicated benchmark designed for the detection of fact-conflicting hallucinations from LLMs. FactCHD features a diverse dataset that spans various factuality patterns, including vanilla, multi-hop, comparison, and set operation. A distinctive element of FactCHD is its integration of fact-based evidence chains, significantly enhancing the depth of evaluating the detectors&#39; explanations. Experiments on different LLMs expose the shortcomings of current approaches in detecting factual errors accurately. Furthermore, we introduce TRUTH-TRIANGULATOR which synthesizes reflective considerations by tool-enhanced ChatGPT and LoRA-tuning based on Llama2, aiming to yield more credible detection through the amalgamation of predictive results and evidence. Keywords: Natural Language Processing: NLP: Resources and evaluation Natural Language Processing: NLP: Applications},
  archive   = {C_IJCAI},
  author    = {Xiang Chen and Duanzheng Song and Honghao Gui and Chenxi Wang and Ningyu Zhang and Yong Jiang and Fei Huang and Chengfei Lyu and Dan Zhang and Huajun Chen},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/687},
  month     = {8},
  pages     = {6216-6224},
  title     = {FactCHD: Benchmarking fact-conflicting hallucination detection},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PEACH: Pretrained-embedding explanation across contextual
and hierarchical structure. <em>IJCAI</em>, 6207–6215. (<a
href="https://doi.org/10.24963/ijcai.2024/686">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this work, we propose a novel tree-based explanation technique, PEACH (Pretrained-embedding Explanation Across Contextual and Hierarchical Structure), that can explain how text-based documents are classified by using any pretrained contextual embeddings in a tree-based human-interpretable manner. Note that PEACH can adopt any contextual embeddings of the PLMs as a training input for the decision tree. Using the proposed PEACH, we perform a comprehensive analysis of several contextual embeddings on nine different NLP text classification benchmarks. This analysis demonstrates the flexibility of the model by appling several PLM contextual embeddings, its attribute selections, scaling, and clustering methods. Furthermore, we show the utility of explanations by visualising the feature selection and important trend of text classification via human-interpretable word-cloud-based trees, which clearly identify model mistakes and assist in dataset debugging. Besides interpretability, PEACH outperforms or is similar to those from pretrained models. Code and Appendix are in https://github.com/adlnlp/peach. Keywords: Natural Language Processing: NLP: Interpretability and analysis of models for NLP Knowledge Representation and Reasoning: KRR: Other},
  archive   = {C_IJCAI},
  author    = {Feiqi Cao and Soyeon Caren Han and Hyunsuk Chung},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/686},
  month     = {8},
  pages     = {6207-6215},
  title     = {PEACH: Pretrained-embedding explanation across contextual and hierarchical structure},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards automatic composition of ASP programs from natural
language specifications. <em>IJCAI</em>, 6198–6206. (<a
href="https://doi.org/10.24963/ijcai.2024/685">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper moves the first step towards automating the composition of Answer Set Programming (ASP) specifications. In particular, the following contributions are provided: (i) A dataset focused on graph-related problem specifications, designed to develop and assess tools for ASP automatic coding; (ii) A two-step architecture, implemented in the NL2ASP tool, for generating ASP programs from natural language specifications. NL2ASP uses neural machine translation to transform natural language into Controlled Natural Language (CNL) statements. Subsequently, CNL statements are converted into ASP code using the CNL2ASP tool. An experimental analysis confirms the viability of the approach. Keywords: Natural Language Processing: NLP: Applications Knowledge Representation and Reasoning: KRR: Logic programming Machine Learning: ML: Generative models},
  archive   = {C_IJCAI},
  author    = {Manuel Borroto Santana and Irfan Kareem and Francesco Ricca},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/685},
  month     = {8},
  pages     = {6198-6206},
  title     = {Towards automatic composition of ASP programs from natural language specifications},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SEMANTIFY: Unveiling memes with robust interpretability
beyond input attribution. <em>IJCAI</em>, 6189–6197. (<a
href="https://doi.org/10.24963/ijcai.2024/684">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Memes, initially created for humor and social commentary, have transformed into platforms for offensive online content. Detecting such content is crucial; however, existing deep learning-based meme offensiveness classifiers lack transparency, functioning as opaque black-box systems. While Integrated Gradient and similar input-attribution interpretability methods exist, they often yield inadequate and irrelevant keywords. To bridge this gap, we introduce SEMANTIFY, a novel system featuring a theoretically grounded multi-step filtering process. SEMANTIFY extracts meaningful &quot;tokens&quot; from a predefined vocabulary, generating a pertinent and comprehensive set of interpretable keywords. These extracted keywords reveal the model&#39;s awareness of hidden meanings in memes, enhancing transparency. Evaluation of SEMANTIFY using interpretability metrics, including &#39;leakage-adjusted simulatability,&#39; demonstrates its superiority over various baselines by up to 2.5 points. Human evaluation of &#39;relatedness&#39; and &#39;exhaustiveness&#39; of extracted keywords further validates its effectiveness. Additionally, a qualitative analysis of extracted keywords serves as a case study, unveiling model error cases and their reasons. SEMANTIFY contributes to the advancement of more interpretable multimodal systems for meme offensiveness detection, fostering trust for real-world applications. Keywords: Natural Language Processing: NLP: Interpretability and analysis of models for NLP AI Ethics, Trust, Fairness: ETF: Societal impact of AI AI Ethics, Trust, Fairness: ETF: Trustworthy AI},
  archive   = {C_IJCAI},
  author    = {Dibyanayan Bandyopadhyay and Asmit Ganguly and Baban Gain and Asif Ekbal},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/684},
  month     = {8},
  pages     = {6189-6197},
  title     = {SEMANTIFY: Unveiling memes with robust interpretability beyond input attribution},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MEDVOC: Vocabulary adaptation for fine-tuning pre-trained
language models on medical text summarization. <em>IJCAI</em>,
6180–6188. (<a href="https://doi.org/10.24963/ijcai.2024/683">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This work presents a dynamic vocabulary adaptation strategy, MEDVOC, for fine-tuning pre-trained language models (PLMs) like BertSumAbs, BART, and PEGASUS for improved medical text summarization. In contrast to existing domain adaptation approaches in summarization, MEDVOC treats vocabulary as an optimizable parameter and optimizes the PLM vocabulary based on fragment score conditioned only on the downstream task&#39;s reference summaries. Unlike previous works on vocabulary adaptation (limited only to classification tasks), optimizing vocabulary based on summarization tasks requires an extremely costly intermediate fine-tuning step on large summarization datasets. To that end, our novel fragment score-based hyperparameter search very significantly reduces this fine-tuning time --- from 450 days to less than 2 days on average. Furthermore, while previous works on vocabulary adaptation are often primarily tied to single PLMs, MEDVOC is designed to be deployable across multiple PLMs (with varying model vocabulary sizes, pre-training objectives, and model sizes) --- bridging the limited vocabulary overlap between the biomedical literature domain and PLMs. MEDVOC outperforms baselines by 15.74% in terms of Rouge-L in zero-shot setting and shows gains of 17.29% in high Out-Of-Vocabulary (OOV) concentrations. Our human evaluation shows MEDVOC generates more faithful medical summaries (88% compared to 59% in baselines). Keywords: Natural Language Processing: NLP: Summarization Machine Learning: ML: Generative models Multidisciplinary Topics and Applications: MTA: Health and medicine Natural Language Processing: NLP: Language generation},
  archive   = {C_IJCAI},
  author    = {Gunjan Balde and Soumyadeep Roy and Mainack Mondal and Niloy Ganguly},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/683},
  month     = {8},
  pages     = {6180-6188},
  title     = {MEDVOC: Vocabulary adaptation for fine-tuning pre-trained language models on medical text summarization},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Vision-based discovery of nonlinear dynamics for 3D moving
target. <em>IJCAI</em>, 6170–6178. (<a
href="https://doi.org/10.24963/ijcai.2024/682">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Data-driven discovery of governing equations has kindled significant interests in many science and engineering areas. Existing studies primarily focus on uncovering equations that govern nonlinear dynamics based on direct measurement of the system states (e.g., trajectories). Limited efforts have been placed on distilling governing laws of dynamics directly from videos for moving targets in a 3D space. To this end, we propose a vision-based approach to automatically uncover governing equations of nonlinear dynamics for 3D moving targets via raw videos recorded by a set of cameras. The approach is composed of three key blocks: (1) a target tracking module that extracts plane pixel motions of the moving target in each video, (2) a Rodrigues&#39; rotation formula-based coordinate transformation learning module that reconstructs the 3D coordinates with respect to a predefined reference point, and (3) a spline-enhanced library-based sparse regressor that uncovers the underlying governing law of dynamics. This framework is capable of effectively handling the challenges associated with measurement data, e.g., noise in the video, imprecise tracking of the target that causes data missing, etc. The efficacy of our method has been demonstrated through multiple sets of synthetic videos considering different nonlinear dynamics. Keywords: Multidisciplinary Topics and Applications: MTA: Physical sciences Computer Vision: CV: Applications Computer Vision: CV: Motion and tracking Machine Learning: ML: Regression},
  archive   = {C_IJCAI},
  author    = {Zitong Zhang and Yang Liu and Hao Sun},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/682},
  month     = {8},
  pages     = {6170-6178},
  title     = {Vision-based discovery of nonlinear dynamics for 3D moving target},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Heterogeneous causal metapath graph neural network for
gene-microbe-disease association prediction. <em>IJCAI</em>, 6161–6169.
(<a href="https://doi.org/10.24963/ijcai.2024/681">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The recent focus on microbes in human medicine highlights their potential role in the genetic framework of diseases. To decode the complex interactions among genes, microbes, and diseases, computational predictions of gene-microbe-disease (GMD) associations are crucial. Existing methods primarily address gene-disease and microbe-disease associations, but the more intricate triple-wise GMD associations remain less explored. In this paper, we propose a Heterogeneous Causal Metapath Graph Neural Network (HCMGNN) to predict GMD associations. HCMGNN constructs a heterogeneous graph linking genes, microbes, and diseases through their pairwise associations, and utilizes six predefined causal metapaths to extract directed causal subgraphs, which facilitate the multi-view analysis of causal relations among three entity types. Within each subgraph, we employ a causal semantic sharing message passing network for node representation learning, coupled with an attentive fusion method to integrate these representations for predicting GMD associations. Our extensive experiments show that HCMGNN effectively predicts GMD associations and addresses association sparsity issue by enhancing the graph&#39;s semantics and structure. Keywords: Multidisciplinary Topics and Applications: MTA: Bioinformatics Multidisciplinary Topics and Applications: MTA: Health and medicine},
  archive   = {C_IJCAI},
  author    = {Kexin Zhang and Feng Huang and Luotao Liu and Zhankun Xiong and Hongyu Zhang and Yuan Quan and Wen Zhang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/681},
  month     = {8},
  pages     = {6161-6169},
  title     = {Heterogeneous causal metapath graph neural network for gene-microbe-disease association prediction},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A deep reinforcement learning approach to balance viewport
prediction and video transmission in 360° video streaming.
<em>IJCAI</em>, 6152–6160. (<a
href="https://doi.org/10.24963/ijcai.2024/680">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {360° video streaming has seen tremendous growth in past years. However, our measurement reveals a dilemma that severely limits QoE. On the one hand, viewport prediction requires the shortest possible prediction distance for high predicting accuracy; On the other hand, video transmission requires more buffered data to compensate for bandwidth fluctuations otherwise substantial playback rebuffering would be incurred. Since no existing method can break this dilemma, the QoE optimization was naturally bottlenecked. This work tackles this challenge by developing QUTA – a novel learning-based streaming system. Specifically, our measurement shows that three kinds of internal streaming parameters have significant impacts on the prediction distance, namely, download pause, data rate threshold, and playback rate. On top of this, we design a new long-term-planning (LTP) learning method that tunes the parameters dynamically based on the network and streaming context. Evaluations with large-scale streaming trace data show that QUTA not only improves the prediction accuracy and QoE by up to 68.4% but also exhibits strong robustness. Keywords: Multidisciplinary Topics and Applications: MTA: Transportation},
  archive   = {C_IJCAI},
  author    = {Guanghui Zhang and Jing Guo},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/680},
  month     = {8},
  pages     = {6152-6160},
  title     = {A deep reinforcement learning approach to balance viewport prediction and video transmission in 360° video streaming},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distribution-independent cell type identification for
single-cell RNA-seq data. <em>IJCAI</em>, 6143–6151. (<a
href="https://doi.org/10.24963/ijcai.2024/679">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Automatic cell type annotation aims to transfer the label knowledge from label-abundant reference data to label-scarce target data, which makes encouraging progress in single-cell RNA-seq data analysis. While previous works have focused on classifying close-set cells and detecting open-set cells during testing, it is still essential to be able to classify unknown cell types as human beings. Additionally, few efforts have been devoted to addressing the challenge of common long-tail dilemma in cell type annotation data. Therefore, in this paper, we propose an innovative distribution-independent universal cell type identification framework called scDET from the perspective of autonomously equilibrated dual-consultative contrastive learning. Our model can generate fine-grained predictions for both close-set and open-set cell types in a long-tailed open-world environment. scDET consists of a contrastive-learning branch and a pseudo-labeling branch, which work collaboratively to provide interactive supervision. Specifically, the contrastive-learning branch provides reliable distribution estimation to regularize the predictions of the pseudo-labeling branch, which in turn guides itself through self-balanced knowledge transfer and a designed novel soft contrastive loss. Extensive experimental results on various evaluation datasets demonstrate the superior performance of scDET over other state-of-the-art single-cell clustering and annotation methods. Keywords: Multidisciplinary Topics and Applications: MTA: Bioinformatics Multidisciplinary Topics and Applications: MTA: Other},
  archive   = {C_IJCAI},
  author    = {Yuyao Zhai and Liang Chen and Minghua Deng},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/679},
  month     = {8},
  pages     = {6143-6151},
  title     = {Distribution-independent cell type identification for single-cell RNA-seq data},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Trade when opportunity comes: Price movement forecasting via
locality-aware attention and iterative refinement labeling.
<em>IJCAI</em>, 6134–6142. (<a
href="https://doi.org/10.24963/ijcai.2024/678">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Price movement forecasting, aimed at predicting financial asset trends based on current market information, has achieved promising advancements through machine learning (ML) methods. Most existing ML methods, however, struggle with the extremely low signal-to-noise ratio and stochastic nature of financial data, often mistaking noises for real trading signals without careful selection of potentially profitable samples. To address this issue, we propose LARA, a novel price movement forecasting framework with two main components: Locality-Aware Attention (LA-Attention) and Iterative Refinement Labeling (RA-Labeling). (1) LA-Attention, enhanced by metric learning techniques, automatically extracts the potentially profitable samples through masked attention scheme and task-specific distance metrics. (2) RA-Labeling further iteratively refines the noisy labels of potentially profitable samples, and combines the learned predictors robust to the unseen and noisy samples. In a set of experiments on three real-world financial markets: stocks, cryptocurrencies, and ETFs, LARA significantly outperforms several machine learning based methods on the Qlib quantitative investment platform. Extensive ablation studies confirm LARA&#39;s superior ability in capturing more reliable trading opportunities. Keywords: Multidisciplinary Topics and Applications: MTA: Finance Machine Learning: ML: Applications},
  archive   = {C_IJCAI},
  author    = {Liang Zeng and Lei Wang and Hui Niu and Ruchen Zhang and Ling Wang and Jian Li},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/678},
  month     = {8},
  pages     = {6134-6142},
  title     = {Trade when opportunity comes: Price movement forecasting via locality-aware attention and iterative refinement labeling},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Domain adaptive and fine-grained anomaly detection for
single-cell sequencing data and beyond. <em>IJCAI</em>, 6125–6133. (<a
href="https://doi.org/10.24963/ijcai.2024/677">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Fined-grained anomalous cell detection from affected tissues is critical for clinical diagnosis and pathological research. Single-cell sequencing data provide unprecedented opportunities for this task. However, current anomaly detection methods struggle to handle domain shifts prevalent in multi-sample and multi-domain single-cell sequencing data, leading to suboptimal performance. Moreover, these methods fall short of distinguishing anomalous cells into pathologically distinct subtypes. In response, we propose ACSleuth, a novel, reconstruction deviation-guided generative framework that integrates the detection, domain adaptation, and fine-grained annotating of anomalous cells into a methodologically cohesive workflow. Notably, we present the first theoretical analysis of using reconstruction deviations output by generative models for anomaly detection in lieu of domain shifts. This analysis informs us to develop a novel and superior maximum mean discrepancy-based anomaly scorer in ACSleuth. Extensive benchmarks over various single-cell data and other types of tabular data demonstrate ACSleuth&#39;s superiority over the state-of-the-art methods in identifying and subtyping anomalies in multi-sample and multi-domain contexts. Our code is available at https://github.com/Catchxu/ACsleuth. Keywords: Multidisciplinary Topics and Applications: MTA: Bioinformatics Data Mining: DM: Anomaly/outlier detection Machine Learning: ML: Applications},
  archive   = {C_IJCAI},
  author    = {Kaichen Xu and Yueyang Ding and Suyang Hou and Weiqiang Zhan and Nisang Chen and Jun Wang and Xiaobo Sun},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/677},
  month     = {8},
  pages     = {6125-6133},
  title     = {Domain adaptive and fine-grained anomaly detection for single-cell sequencing data and beyond},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RSAP-DFM: Regime-shifting adaptive posterior dynamic factor
model for stock returns prediction. <em>IJCAI</em>, 6116–6124. (<a
href="https://doi.org/10.24963/ijcai.2024/676">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As the latest development of asset pricing research, how to use machine learning to improve the performance of factor models has become a topic of concern in recent years. The variability of the instantaneous macro environment brings great difficulties to quantitative investment, so the extended factor model must learn how to self-adapt to extract the macro pattern from the massive stock volume and price information, and how to continuously map the extracted macro pattern to the stock investment is also an open question. To this end, we propose the first continuous regime-based dynamic factor model, RSAP-DFM, which adaptively extracts continuous macroeconomic information and completes the dynamic explicit mapping of stock returns for the first time through dual regime shifting, while the adversarial posterior factors effectively correct the mapping deviation of prior factors. In addition, our model integrates an innovative two-stage optimization algorithm and normally distributed sampling, which further enhances the robustness of the model. Performance on three real stock datasets validates the validity of our model, which exceeds any previous methods available. Keywords: Multidisciplinary Topics and Applications: MTA: Finance Machine Learning: ML: Applications},
  archive   = {C_IJCAI},
  author    = {Quanzhou Xiang and Zhan Chen and Qi Sun and Rujun Jiang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/676},
  month     = {8},
  pages     = {6116-6124},
  title     = {RSAP-DFM: Regime-shifting adaptive posterior dynamic factor model for stock returns prediction},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An image-enhanced molecular graph representation learning
framework. <em>IJCAI</em>, 6107–6115. (<a
href="https://doi.org/10.24963/ijcai.2024/675">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Extracting rich molecular representation is a crucial prerequisite for accurate drug discovery. Recent molecular representation learning methods achieve impressive progress, but the paradigm of learning from a single modality gradually encounters the bottleneck of limited representation capabilities. In this work, we fully consider the rich visual information contained in 3D conformation molecular images (i.e., texture, shadow, color and planar spatial information) and distill graph-based models for more discriminative drug discovery. Specifically, we propose an image-enhanced molecular graph representation learning framework that leverages multi-view molecular images rendered from 3D conformations to boost molecular graph representations. To extract useful auxiliary knowledge from multi-view images, we design a teacher, which is pre-trained on 2 million molecules with conformations through five meticulously designed pre-training tasks. To transfer knowledge from teacher to graph-based students, we pose an efficient cross-modal knowledge distillation strategy with knowledge enhancer and task enhancer. It is worth noting that the distillation architecture of IEM can be directly integrated into existing graph-based models, and significantly improves the capabilities of these models (e.g. GIN, EdgePred, GraphMVP, MoleBERT) for molecular representation learning. In particular, GraphMVP and MoleBERT equipped with IEM achieve new state-of-the-art performance on MoleculeNet benchmark, achieving average 73.89% and 73.81% ROC-AUC, respectively. Code is available at https://github.com/HongxinXiang/IEM. Keywords: Multidisciplinary Topics and Applications: MTA: Bioinformatics Machine Learning: ML: Knowledge-aided learning Machine Learning: ML: Self-supervised Learning Machine Learning: ML: Representation learning},
  archive   = {C_IJCAI},
  author    = {Hongxin Xiang and Shuting Jin and Jun Xia and Man Zhou and Jianmin Wang and Li Zeng and Xiangxiang Zeng},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/675},
  month     = {8},
  pages     = {6107-6115},
  title     = {An image-enhanced molecular graph representation learning framework},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning-based tracking-before-detect for RF-based
unconstrained indoor human tracking. <em>IJCAI</em>, 6098–6106. (<a
href="https://doi.org/10.24963/ijcai.2024/674">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Existing efforts on human tracking using wireless signal are primarily focused on constrained scenarios with only a few individuals in empty spaces. However, in practical unconstrained scenarios with severe interference and attenuation, accurate multi-person tracking has been intractable. In this paper, we propose NeuralTBD, utilizing the capability of deep models and advancement of Tracking-Before-Detect (TBD) methodology to achieve accurate human tracking. TBD is a classical tracking methodology from signal processing accumulating measurement in time domain to distinguish target traces from interference, which however relies on handcrafted shape/motion models, impeding efficacy in complex indoor scenarios. To tackle this challenge, we build an end-to-end learning-based TBD framework leverages the advanced modeling capabilities of deep models to significantly enhance the performance of TBD. To evaluate NeuralTBD, we collect an RF-based tracking dataset in unconstrained scenarios, which encompasses 4 million annotated radar frames with up to 19 individuals acting in 6 different scenarios. NeuralTBD realizes a 70% improvement in performance compared to conventional TBD methods. To our knowledge, this is the first attempt dealing with RF-based unconstrained human tracking. The code and dataset will be released. Keywords: Multidisciplinary Topics and Applications: MTA: Sensor networks and smart cities Multidisciplinary Topics and Applications: MTA: Ubiquitous computing cystems},
  archive   = {C_IJCAI},
  author    = {Zhi Wu and Dongheng Zhang and Zixin Shang and Yuqin Yuan and Hanqin Gong and Binquan Wang and Zhi Lu and Yadong Li and Yang Hu and Qibin Sun and Yan Chen},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/674},
  month     = {8},
  pages     = {6098-6106},
  title     = {Learning-based tracking-before-detect for RF-based unconstrained indoor human tracking},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Are watermarks bugs for deepfake detectors? Rethinking
proactive forensics. <em>IJCAI</em>, 6089–6097. (<a
href="https://doi.org/10.24963/ijcai.2024/673">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {AI-generated content has accelerated the topic of media synthesis, particularly Deepfake, which can manipulate our portraits for positive or malicious purposes. Before releasing these threatening face images, one promising forensics solution is the injection of robust watermarks to track their own provenance. However, we argue that current watermarking models, originally devised for genuine images, may harm the deployed Deepfake detectors when directly applied to forged images, since the watermarks are prone to overlap with the forgery signals used for detection. To bridge this gap, we thus propose AdvMark, on behalf of proactive forensics, to exploit the adversarial vulnerability of passive detectors for good. Specifically, AdvMark serves as a plug-and-play procedure for fine-tuning any robust watermarking into adversarial watermarking, to enhance the forensic detectability of watermarked images; meanwhile, the watermarks can still be extracted for provenance tracking. Extensive experiments demonstrate the effectiveness of the proposed AdvMark, leveraging robust watermarking to fool Deepfake detectors, which can help improve the accuracy of downstream Deepfake detection without tuning the in-the-wild detectors. We believe this work will shed some light on the harmless proactive forensics against Deepfake. Keywords: Multidisciplinary Topics and Applications: MTA: Security and privacy Computer Vision: CV: Biometrics, face, gesture and pose recognition},
  archive   = {C_IJCAI},
  author    = {Xiaoshuai Wu and Xin Liao and Bo Ou and Yuling Liu and Zheng Qin},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/673},
  month     = {8},
  pages     = {6089-6097},
  title     = {Are watermarks bugs for deepfake detectors? rethinking proactive forensics},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A semi-supervised molecular learning framework for activity
cliff estimation. <em>IJCAI</em>, 6080–6088. (<a
href="https://doi.org/10.24963/ijcai.2024/672">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Machine learning (ML) enables accurate and fast molecular property predictions, which is of interest in drug discovery and material design. Their success is based on the principle of similarity at its heart, assuming that similar molecules exhibit close properties. However, activity cliffs challenge this principle, and their presence leads to a sharp decline in the performance of existing ML algorithms, particularly graph-based methods. To overcome this obstacle under a low-data scenario, we propose a novel semi-supervised learning (SSL) method dubbed SemiMol, which employs predictions on numerous unannotated data as pseudo-signals for subsequent training. Specifically, we introduce an additional instructor model to evaluate the accuracy and trustworthiness of proxy labels because existing pseudo-labeling approaches require probabilistic outputs to reveal the model&#39;s confidence and fail to be applied in regression tasks. Moreover, we design a self-adaptive curriculum learning algorithm to progressively move the target model toward hard samples at a controllable pace. Extensive experiments on 30 activity cliff datasets demonstrate that SemiMol significantly enhances graph-based ML architectures and outpasses state-of-the-art pretraining and SSL baselines. Keywords: Multidisciplinary Topics and Applications: MTA: Health and medicine Multidisciplinary Topics and Applications: MTA: Life sciences Humans and AI: HAI: Applications},
  archive   = {C_IJCAI},
  author    = {Fang Wu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/672},
  month     = {8},
  pages     = {6080-6088},
  title     = {A semi-supervised molecular learning framework for activity cliff estimation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ZeroDDI: A zero-shot drug-drug interaction event prediction
method with semantic enhanced learning and dual-modal uniform alignment.
<em>IJCAI</em>, 6071–6079. (<a
href="https://doi.org/10.24963/ijcai.2024/671">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Drug-drug interactions (DDIs) can result in various pharmacological changes, which can be categorized into different classes known as DDI events (DDIEs). In recent years, previously unobserved/unseen DDIEs have been emerging, posing a new classification task when unseen classes have no labelled instances in the training stage, which is formulated as a zero-shot DDIE prediction (ZS-DDIE) task. However, existing computational methods are not directly applicable to ZS-DDIE, which has two primary challenges: obtaining suitable DDIE representations and handling the class imbalance issue. To overcome these challenges, we propose a novel method named ZeroDDI for the ZS-DDIE task. Specifically, we design a biological semantic enhanced DDIE representation learning module, which emphasizes the key biological semantics and distills discriminative molecular substructure-related semantics for DDIE representation learning. Furthermore, we propose a dual-modal uniform alignment strategy to distribute drug pair representations and DDIE semantic representations uniformly in unit sphere and align the matched ones, which can mitigate the issue of class imbalance. Extensive experiments showed that ZeroDDI surpasses the baselines and indicate that it is a promising tool for detecting unseen DDIEs. Our code has been released in https://github.com/wzy-Sarah/ZeroDDI. Keywords: Multidisciplinary Topics and Applications: MTA: Bioinformatics Multidisciplinary Topics and Applications: MTA: Health and medicine},
  archive   = {C_IJCAI},
  author    = {Ziyan Wang and Zhankun Xiong and Feng Huang and Xuan Liu and Wen Zhang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/671},
  month     = {8},
  pages     = {6071-6079},
  title     = {ZeroDDI: A zero-shot drug-drug interaction event prediction method with semantic enhanced learning and dual-modal uniform alignment},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MediTab: Scaling medical tabular data predictors via data
consolidation, enrichment, and refinement. <em>IJCAI</em>, 6062–6070.
(<a href="https://doi.org/10.24963/ijcai.2024/670">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Tabular data prediction has been employed in medical applications such as patient health risk prediction. However, existing methods usually revolve around the algorithm design while overlooking the significance of data engineering. Medical tabular datasets frequently exhibit significant heterogeneity across different sources, with limited sample sizes per source. As such, previous predictors are often trained on manually curated small datasets that struggle to generalize across different tabular datasets during inference. This paper proposes to scale medical tabular data predictors (MediTab) to various tabular inputs with varying features. The method uses a data engine that leverages large language models (LLMs) to consolidate tabular samples to overcome the barrier across tables with distinct schema. It also aligns out-domain data with the target task using a &quot;learn, annotate, and refinement&#39;&#39; pipeline. The expanded training data then enables the pre-trained MediTab to infer for arbitrary tabular input in the domain without fine-tuning, resulting in significant improvements over supervised baselines: it reaches an average ranking of 1.57 and 1.00 on 7 patient outcome prediction datasets and 3 trial outcome prediction datasets, respectively. In addition, MediTab exhibits impressive zero-shot performances: it outperforms supervised XGBoost models by 8.9% and 17.2% on average in two prediction tasks, respectively. Keywords: Multidisciplinary Topics and Applications: MTA: Health and medicine Multidisciplinary Topics and Applications: MTA: Bioinformatics Multidisciplinary Topics and Applications: MTA: Life sciences},
  archive   = {C_IJCAI},
  author    = {Zifeng Wang and Chufan Gao and Cao Xiao and Jimeng Sun},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/670},
  month     = {8},
  pages     = {6062-6070},
  title     = {MediTab: Scaling medical tabular data predictors via data consolidation, enrichment, and refinement},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). Improving paratope and epitope prediction by multi-modal
contrastive learning and interaction informativeness estimation.
<em>IJCAI</em>, 6053–6061. (<a
href="https://doi.org/10.24963/ijcai.2024/669">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Accurately predicting antibody-antigen binding residues, i.e., paratopes and epitopes, is crucial in antibody design. However, existing methods solely focus on uni-modal data (either sequence or structure), disregarding the complementary information present in multi-modal data, and most methods predict paratopes and epitopes separately, overlooking their specific spatial interactions. In this paper, we propose a novel Multi-modal contrastive learning and Interaction informativeness estimation-based method for Paratope and Epitope prediction, named MIPE, by using both sequence and structure data of antibodies and antigens. MIPE implements a multi-modal contrastive learning strategy, which maximizes representations of binding and non-binding residues within each modality and meanwhile aligns uni-modal representations towards effective modal representations. To exploit the spatial interaction information, MIPE also incorporates an interaction informativeness estimation that computes the estimated interaction matrices between antibodies and antigens, thereby approximating them to the actual ones. Extensive experiments demonstrate the superiority of our method in predicting paratopes and epitopes compared to baselines. Additionally, the ablation studies and visualizations demonstrate the superiority of MIPE owing to the better representations acquired through multi-modal contrastive learning and the interaction patterns comprehended by the interaction informativeness estimation. Keywords: Multidisciplinary Topics and Applications: MTA: Bioinformatics Multidisciplinary Topics and Applications: MTA: Health and medicine},
  archive   = {C_IJCAI},
  author    = {Zhiwei Wang and Yongkang Wang and Wen Zhang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/669},
  month     = {8},
  pages     = {6053-6061},
  title     = {Improving paratope and epitope prediction by multi-modal contrastive learning and interaction informativeness estimation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). BeyondVision: An EMG-driven micro hand gesture recognition
based on dynamic segmentation. <em>IJCAI</em>, 6044–6052. (<a
href="https://doi.org/10.24963/ijcai.2024/668">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Hand gesture recognition (HGR) plays a pivotal role in natural and intuitive human-computer interactions. Recent HGR methods focus on recognizing gestures from vision-based images or videos. However, vision-based methods are limited in recognizing micro hand gestures (MHGs) (e.g., pinch within 1cm) and gestures with occluded fingers. To address these issues, combined with the electromyography (EMG) technique, we propose BeyondVision, an EMG-driven MHG recognition system based on deep learning. BeyondVision consists of a wristband-style EMG sampling device and a tailored lightweight neural network BV-Net that can accurately translate EMG signals of MHGs to control commands in real-time. Moreover, we propose a post-processing mechanism and a weight segmentation algorithm to effectively improve the accuracy rate of MHG recognition. Subjective and objective experimental results show that our approach achieves over 95% average recognition rate, 2000Hz sampling frequency, and real-time micro gesture recognition. Our technique has been applied in a commercially available product, introduced at: https://github.com/tyc333/NoBarriers. Keywords: Multidisciplinary Topics and Applications: MTA: AI hardware Computer Vision: CV: Biometrics, face, gesture and pose recognition Machine Learning: ML: Applications Multidisciplinary Topics and Applications: MTA: Interactive entertainment},
  archive   = {C_IJCAI},
  author    = {Nana Wang and Jianwei Niu and Xuefeng Liu and Dongqin Yu and Guogang Zhu and Xinghao Wu and Mingliang Xu and Hao Su},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/668},
  month     = {8},
  pages     = {6044-6052},
  title     = {BeyondVision: An EMG-driven micro hand gesture recognition based on dynamic segmentation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-TA: Multilevel temporal augmentation for robust septic
shock early prediction. <em>IJCAI</em>, 6035–6043. (<a
href="https://doi.org/10.24963/ijcai.2024/667">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Early predicting the onset of a disease is critical to timely and accurate clinical decision-making, where a model determines whether a patient will develop the disease n hours later. While deep learning algorithms have demonstrated great success using multivariate irregular time-series data such as electronic health records (EHRs), they often lack temporal robustness due to data scarcity problems becoming more prominent at multilevel as n increases. At event-level, the decreasing number of available events per trajectory increases uncertainty in anticipating future disease behavior. At trajectory-level, the scarcity of patient trajectories limits diversity in the training population, hindering the model&#39;s generalization. This work introduces Multi-TA, a multilevel temporal augmentation framework that leverages BERT-based temporal EHRs representation learning and a unified data augmentation approach, effectively addressing data scarcity issues at both event and trajectory levels. Validated on two real-world EHRs for septic shock, Multi-TA outperforms mixup and GAN-based state-of-the-art models across eight prediction windows, demonstrating improved temporal robustness. Further, we provide in-depth analyses on data augmentation. Keywords: Multidisciplinary Topics and Applications: MTA: Health and medicine Machine Learning: ML: Robustness Machine Learning: ML: Time series and data streams Natural Language Processing: NLP: Applications},
  archive   = {C_IJCAI},
  author    = {Hyunwoo Sohn and Kyungjin Park and Baekkwan Park and Min Chi},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/667},
  month     = {8},
  pages     = {6035-6043},
  title     = {Multi-TA: Multilevel temporal augmentation for robust septic shock early prediction},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic many-objective molecular optimization: Unfolding
complexity with objective decomposition and progressive optimization.
<em>IJCAI</em>, 6026–6034. (<a
href="https://doi.org/10.24963/ijcai.2024/666">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Molecular discovery has received significant attention across various scientific fields by enabling the creation of novel chemical compounds. In recent years, the majority of studies have approached this process as a multi-objective optimization problem. Despite notable advancements, most methods optimize only up to four molecular objectives and are mainly designed for scenarios with a predetermined number of objectives. However, in real-world applications, the number of molecular objectives can be more than four (many-objective) and additional objectives may be introduced over time (dynamic-objective). To fill this gap, we propose DyMol, the first method designed to tackle the dynamic many-objective molecular optimization problem by utilizing a novel divide-and-conquer approach combined with a decomposition strategy. Additionally, we comprehensively integrate convergence, Pareto diversity, and structural diversity into the optimization process to provide efficient exploration of the search space. We validate the superior performance of our method using the practical molecular optimization (PMO) benchmark. The source code and supplementary material are available online. Keywords: Multidisciplinary Topics and Applications: MTA: Bioinformatics Multidisciplinary Topics and Applications: MTA: Health and medicine},
  archive   = {C_IJCAI},
  author    = {Dong-Hee Shin and Young-Han Son and Deok-Joong Lee and Ji-Wung Han and Tae-Eui Kam},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/666},
  month     = {8},
  pages     = {6026-6034},
  title     = {Dynamic many-objective molecular optimization: Unfolding complexity with objective decomposition and progressive optimization},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SACNN: Self attention-based convolutional neural network for
fraudulent behaviour detection in sports. <em>IJCAI</em>, 6017–6025. (<a
href="https://doi.org/10.24963/ijcai.2024/665">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Doping practices in sports by unscrupulous athletes have been an important societal issue for several decades. Recently, sample swapping has been raised as a potential practice performed by athletes to swap their doped samples with clean samples to evade the positive doping test. So far, the only proven method to detect such cases is by performing DNA analysis on samples. However, it is expensive and time-consuming, which goes beyond the budgetary limits of anti-doping organisations when implementing to all the samples collected during sports events. Therefore, in this paper, we propose a self attention-based convolutional neural network (SACNN) that incorporates both spatial and temporal behaviour of the longitudinal profile and generates embedding maps for solving the fraud detection problem in sports. We conduct extensive experiments on the real-world datasets. The result shows that SACNN outperforms other state-of-the-art baseline models for sequential anomaly detection. Moreover, we conduct a study with domain experts on real-world profiles using both DNA analysis and our proposed method; the result demonstrates the effectiveness of our proposed method and the impact it could bring to the society. Keywords: Multidisciplinary Topics and Applications: MTA: Sports Machine Learning: ML: Applications AI Ethics, Trust, Fairness: ETF: Societal impact of AI},
  archive   = {C_IJCAI},
  author    = {Maxx Richard Rahman and Lotfy Abdel Khaliq and Thomas Piper and Hans Geyer and Tristan Equey and Norbert Baume and Reid Aikin and Wolfgang Maass},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/665},
  month     = {8},
  pages     = {6017-6025},
  title     = {SACNN: Self attention-based convolutional neural network for fraudulent behaviour detection in sports},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MacMic: Executing iceberg orders via hierarchical
reinforcement learning. <em>IJCAI</em>, 6008–6016. (<a
href="https://doi.org/10.24963/ijcai.2024/664">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In recent years, there has been a growing interest in applying reinforcement learning (RL) techniques to order execution owing to RL’s strong sequential decision-making ability. However, realistic order execution tasks usually involve a large fine-grained action space and a long trading duration. The former hinders the RL agents from efficient exploration. The latter increases the task complexity, since the agent must capture price advantages throughout the day as well as micro changes within a few seconds on the limited order books. In addressing these challenges, we propose MacMic, a novel Hierarchical RL-based order execution approach that captures market patterns and executes orders from different temporal scales. MacMic employs a high-level agent to split the parent order into smaller slices at coarse-grained time steps. Then a low-level agent is adopted to execute these slices by placing fixed-size sub-orders at a continuous time. Besides, to balance the multifaceted objectives of the two tasks, MacMic pretrains a causal stacking hidden Markov model (SHMM) to obtain both effective macro-level and micro-level market states. Comprehensive experimental results on 200 stocks across the US and China A-share markets validate the effectiveness of the proposed method. Keywords: Multidisciplinary Topics and Applications: MTA: Finance Machine Learning: ML: Reinforcement learning Machine Learning: ML: Representation learning},
  archive   = {C_IJCAI},
  author    = {Hui Niu and Siyuan Li and Jian Li},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/664},
  month     = {8},
  pages     = {6008-6016},
  title     = {MacMic: Executing iceberg orders via hierarchical reinforcement learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). IMM: An imitative reinforcement learning approach with
predictive representation learning for automatic market making.
<em>IJCAI</em>, 5999–6007. (<a
href="https://doi.org/10.24963/ijcai.2024/663">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Market making (MM) via Reinforcement Learning (RL) has attracted significant attention in financial trading. Most existing RL-based MM methods focus on optimizing single-price level strategies which fail at frequent order cancellations and loss of queue priority. By comparison, strategies involving multiple price levels align better with actual trading scenarios. However, given the complexity that multi-price level RL strategies involve a comprehensive trading action space, the challenge of effectively training RL persists. Inspired by the effective workflow of professional human market makers, we propose Imitative Market Maker (IMM), a novel RL framework leveraging knowledge from both suboptimal signal-based experts and direct policy interactions. Our framework starts with introducing effective state and action formulations that well encode information about multiprice level orders. Furthermore, IMM integrates a representation learning unit capable of capturing both short- and long-term market trends to mitigate adverse selection risk. Subsequently, IMM designs an expert strategy based on predictive signals, and trains the agent through the integration of RL and imitation learning techniques to achieve efficient learning. Extensive experimental results on four real-world market datasets demonstrate the superiority of IMM against current RL-based MM strategies. Keywords: Multidisciplinary Topics and Applications: MTA: Finance Machine Learning: ML: Reinforcement learning Machine Learning: ML: Representation learning},
  archive   = {C_IJCAI},
  author    = {Hui Niu and Siyuan Li and Jiahao Zheng and Zhouchi Lin and Bo An and Jian Li and Jian Guo},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/663},
  month     = {8},
  pages     = {5999-6007},
  title     = {IMM: An imitative reinforcement learning approach with predictive representation learning for automatic market making},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Searching for programmatic policies in semantic spaces.
<em>IJCAI</em>, 5990–5998. (<a
href="https://doi.org/10.24963/ijcai.2024/662">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Syntax-guided synthesis is commonly used to generate programs encoding policies. In this approach, the set of programs, that can be written in a domain-specific language defines the search space, and an algorithm searches within this space for programs that encode strong policies. In this paper, we propose an alternative method for synthesizing programmatic policies, where we search within an approximation of the language&#39;s semantic space. We hypothesized that searching in semantic spaces is more sample-efficient compared to syntax-based spaces. Our rationale is that the search is more efficient if the algorithm evaluates different agent behaviors as it searches through the space, a feature often missing in syntax-based spaces. This is because small changes in the syntax of a program often do not result in different agent behaviors. We define semantic spaces by learning a library of programs that present different agent behaviors. Then, we approximate the semantic space by defining a neighborhood function for local search algorithms, where we replace parts of the current candidate program with programs from the library. We evaluated our hypothesis in a real-time strategy game called MicroRTS. Empirical results support our hypothesis that searching in semantic spaces can be more sample-efficient than searching in syntax-based spaces. Keywords: Multidisciplinary Topics and Applications: MTA: Computer games Multidisciplinary Topics and Applications: MTA: Game playing},
  archive   = {C_IJCAI},
  author    = {Rubens O. Moraes and Levi H. S. Lelis},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/662},
  month     = {8},
  pages     = {5990-5998},
  title     = {Searching for programmatic policies in semantic spaces},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards geometric normalization techniques in SE(3)
equivariant graph neural networks for physical dynamics simulations.
<em>IJCAI</em>, 5981–5989. (<a
href="https://doi.org/10.24963/ijcai.2024/661">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {SE(3) equivariance is a fundamental property that is highly desirable to maintain in physical dynamics modeling. This property ensures neural outputs to remain robust when the inputs are translated or rotated. Recently, there have been several proposals for SE(3) equivariant graph neural networks (GNNs) that have shown promising results in simulating particle dynamics. However, existing works have neglected an important issue that current SE(3) equivariant GNNs cannot scale to large particle systems. Although some simple normalization techniques are already in use to stabilize the training dynamics of equivariant graph networks, they actually break the SE(3) equivariance of the architectures. In this work, we first show the numerical instability of training equivariant GNNs on large particle systems and then analyze some existing normalization strategies adopted in modern works. We propose a new normalization layer called GeoNorm, which can satisfy the SE(3) equivariance and simultaneously stabilize the training process. We conduct comprehensive experiments on N-body system simulation tasks with larger particle system sizes. The experimental results demonstrate that GeoNorm successfully preserves the SE(3) equivariance compared to baseline techniques and stabilizes the training dynamics of SE(3) equivariant GNNs on large systems. Keywords: Multidisciplinary Topics and Applications: MTA: Physical sciences Machine Learning: ML: Deep learning architectures Machine Learning: ML: Geometric learning Machine Learning: ML: Sequence and graph learning},
  archive   = {C_IJCAI},
  author    = {Ziqiao Meng and Liang Zeng and Zixing Song and Tingyang Xu and Peilin Zhao and Irwin King},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/661},
  month     = {8},
  pages     = {5981-5989},
  title     = {Towards geometric normalization techniques in SE(3) equivariant graph neural networks for physical dynamics simulations},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhanced DouDiZhu card game strategy using oracle guiding
and adaptive deep monte carlo method. <em>IJCAI</em>, 5972–5980. (<a
href="https://doi.org/10.24963/ijcai.2024/660">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep Reinforcement Learning (DRL) exhibits significant advancements in games with both perfect and imperfect information, such as Go, Chess, Texas Hold&#39;em, and Dota2. However, DRL encounters considerable challenges when tackling card game DouDiZhu because of the imperfect information, large state-action space, and the sparse reward issue. This paper presents OADMCDou, which combines Oracle Guiding and Adaptive Deep Monte Carlo Method to address the challenges in DouDiZhu. Oracle Guiding trains an Oracle agent with both imperfect and perfect information, gradually reducing reliance on imperfect information to transition to a standard agent. Adaptive Deep Monte Carlo uses gradient weight clipping and constrains the magnitude of updates to prevent extreme policy updates. We conduct extensive experiments to evaluate the effectiveness of the proposed methods, demonstrating OADMCDou&#39;s superior performance over the state-of-the-art DouDiZhu AI, DouZero. This superiority over DouZero is reflected in two metrics: a 95% confidence interval of 0.104 ± 0.041 for performance, and a 28.6% reduction in loss. Keywords: Multidisciplinary Topics and Applications: MTA: Entertainment Multidisciplinary Topics and Applications: MTA: Computer games Multidisciplinary Topics and Applications: MTA: Game playing Agent-based and Multi-agent Systems: MAS: Other},
  archive   = {C_IJCAI},
  author    = {Qian Luo and Tien Ping Tan and Daochen Zha and Tianqiao Zhang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/660},
  month     = {8},
  pages     = {5972-5980},
  title     = {Enhanced DouDiZhu card game strategy using oracle guiding and adaptive deep monte carlo method},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing multimodal knowledge graph representation learning
through triple contrastive learning. <em>IJCAI</em>, 5963–5971. (<a
href="https://doi.org/10.24963/ijcai.2024/659">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multimodal knowledge graphs incorporate multimodal information rather than pure symbols, which significantly enhance the representation of knowledge graphs and their capacity to understand the world. Despite these advancements, existing multimodal fusion techniques still face significant challenges in representing modalities and fully integrating the diverse attributes of entities, particularly when dealing with more than one modality. To address this issue, this article proposes a Knowledge Graph Multimodal Representation Learning (KG-MRI) method. This method utilizes foundation models to represent different modalities and incorporates a triple contrastive learning model and a dual-phase training strategy to effectively fuse the different modalities with knowledge graph embeddings. We conducted comprehensive comparisons with several different knowledge graph embedding methods to validate the effectiveness of our KG-MRI model. Furthermore validation on a real-world Non-Alcohol Fatty Liver Disease (NAFLD) cohort demonstrated that the vector representations learned through our methodology possess enhanced representational capabilities, showing promise for broader applications in complex multimodal environments. Keywords: Multidisciplinary Topics and Applications: MTA: Bioinformatics Data Mining: DM: Knowledge graphs and knowledge base completion Machine Learning: ML: Multi-modal learning Multidisciplinary Topics and Applications: MTA: Life sciences},
  archive   = {C_IJCAI},
  author    = {Yuxing Lu and Weichen Zhao and Nan Sun and Jinzhuo Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/659},
  month     = {8},
  pages     = {5963-5971},
  title     = {Enhancing multimodal knowledge graph representation learning through triple contrastive learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SCTrans: Multi-scale scRNA-seq sub-vector completion
transformer for gene-selective cell type annotation. <em>IJCAI</em>,
5954–5962. (<a href="https://doi.org/10.24963/ijcai.2024/658">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Cell type annotation is pivotal to single-cell RNA sequencing data (scRNA-seq)-based biological and medical analysis, e.g., identifying biomarkers, exploring cellular heterogeneity, and understanding disease mechanisms. The previous annotation methods typically learn a nonlinear mapping to infer cell type from gene expression vectors, and thus fall short in discovering and associating salient genes with specific cell types. To address this issue, we propose a multi-scale scRNA-seq Sub-vector Completion Transformer, and our model is referred to as SCTrans. Considering that the expressiveness of gene sub-vectors is richer than that of individual genes, we perform multi-scale partitioning on gene vectors followed by masked sub-vector completion, conditioned on unmasked ones. Toward this end, the multi-scale sub-vectors are tokenized, and the intrinsic contextual relationships are modeled via self-attention computation and conditional contrastive regularization imposed on an encoding transformer. By performing mutual learning between the encoder and an additional lightweight counterpart, the salient tokens can be distinguished from the others. As a result, we can perform gene-selective cell type annotation, which contributes to our superior performance over state-of-the-art annotation methods. Keywords: Multidisciplinary Topics and Applications: MTA: Bioinformatics Computer Vision: CV: Applications Data Mining: DM: Applications},
  archive   = {C_IJCAI},
  author    = {Lu Lin and Wen Xue and Xindian Wei and Wenjun Shen and Cheng Liu and Si Wu and Hau San Wong},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/658},
  month     = {8},
  pages     = {5954-5962},
  title     = {SCTrans: Multi-scale scRNA-seq sub-vector completion transformer for gene-selective cell type annotation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MFTraj: Map-free, behavior-driven trajectory prediction for
autonomous driving. <em>IJCAI</em>, 5945–5953. (<a
href="https://doi.org/10.24963/ijcai.2024/657">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper introduces a trajectory prediction model tailored for autonomous driving, focusing on capturing complex interactions in dynamic traffic scenarios without reliance on high-definition maps. The model, termed MFTraj, harnesses historical trajectory data combined with a novel dynamic geometric graph-based behavior-aware module. At its core, an adaptive structure-aware interactive graph convolutional network captures both positional and behavioral features of road users, preserving spatial-temporal intricacies. Enhanced by a linear attention mechanism, the model achieves computational efficiency and reduced parameter overhead. Evaluations on the Argoverse, NGSIM, HighD, and MoCAD datasets underscore MFTraj&#39;s robustness and adaptability, outperforming numerous benchmarks even in data-challenged scenarios without the need for additional information such as HD maps or vectorized maps. Importantly, it maintains competitive performance even in scenarios with substantial missing data (12.5%-50%), outperforming most existing state-of-the-art models. The results and methodology suggest a significant advancement in autonomous driving trajectory prediction, paving the way for safer and efficient autonomous systems. Keywords: Multidisciplinary Topics and Applications: MTA: Transportation Agent-based and Multi-agent Systems: MAS: Applications Agent-based and Multi-agent Systems: MAS: Multi-agent planning Robotics: ROB: Other},
  archive   = {C_IJCAI},
  author    = {Haicheng Liao and Zhenning Li and Chengyue Wang and Huanming Shen and Dongping Liao and Bonan Wang and Guofa Li and Chengzhong Xu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/657},
  month     = {8},
  pages     = {5945-5953},
  title     = {MFTraj: Map-free, behavior-driven trajectory prediction for autonomous driving},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A cognitive-driven trajectory prediction model for
autonomous driving in mixed autonomy environments. <em>IJCAI</em>,
5936–5944. (<a href="https://doi.org/10.24963/ijcai.2024/656">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As autonomous driving technology progresses, the need for precise trajectory prediction models becomes paramount. This paper introduces an innovative model that infuses cognitive insights into trajectory prediction, focusing on perceived safety and dynamic decision-making. Distinct from traditional approaches, our model excels in analyzing interactions and behavior patterns in mixed autonomy traffic scenarios. We introduce the Macao Connected Autonomous Driving (MoCAD) dataset as part of our contributions, which adds value to its complex urban driving scenarios. Our model represents a significant leap forward, achieving marked performance improvements on several key datasets. Specifically, it surpasses existing benchmarks with gains of 16.2% on the Next Generation Simulation (NGSIM), 27.4% on the Highway Drone (HighD), and 19.8% on the MoCAD dataset. Our proposed model shows exceptional proficiency in handling corner cases, essential for real-world applications. Moreover, its robustness is evident in scenarios with missing or limited data, outperforming most of the state-of-the-art baselines. This adaptability and resilience position our model as a viable tool for real-world autonomous driving systems, heralding a new standard in vehicle trajectory prediction for enhanced safety and efficiency. Keywords: Multidisciplinary Topics and Applications: MTA: Transportation Agent-based and Multi-agent Systems: MAS: Human-agent interaction Planning and Scheduling: PS: Applications Robotics: ROB: Motion and path planning},
  archive   = {C_IJCAI},
  author    = {Haicheng Liao and Zhenning Li and Chengyue Wang and Bonan Wang and Hanlin Kong and Yanchen Guan and Guofa Li and Zhiyong Cui},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/656},
  month     = {8},
  pages     = {5936-5944},
  title     = {A cognitive-driven trajectory prediction model for autonomous driving in mixed autonomy environments},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). OUCopula: Bi-channel multi-label copula-enhanced
adapter-based CNN for myopia screening based on OU-UWF images.
<em>IJCAI</em>, 5927–5935. (<a
href="https://doi.org/10.24963/ijcai.2024/655">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Myopia screening using cutting-edge ultra-widefield (UWF) fundus imaging is potentially significant for ophthalmic outcomes. Current multidisciplinary research between ophthalmology and deep learning (DL) concentrates primarily on disease classification and diagnosis using single-eye images, largely ignoring joint modeling and prediction for Oculus Uterque (OU, both eyes). Inspired by the complex relationships between OU and the high correlation between the (continuous) outcome labels (Spherical Equivalent and Axial Length), we propose a framework of copula-enhanced adapter convolutional neural network (CNN) learning with OU UWF fundus images (OUCopula) for joint prediction of multiple clinical scores. We design a novel bi-channel multi-label CNN which can (1) take bi-channel image inputs subject to both high correlation and heterogeneity (by sharing the same backbone network and employing adapters to parameterize the channel-wise discrepancy), and (2) incorporate correlation information between continuous output labels (using a copula). Solid experiments show that OUCopula achieves satisfactory performance in myopia score prediction compared to backbone models. Moreover, OUCopula can far exceed the performance of models constructed for single-eye inputs. Importantly, our study also hints at the potential extension of the bi-channel model to a multi-channel paradigm and the generalizability of OUCopula across various backbone CNNs. The code and the supplementary materials are available at: github.com/Charley-HUANG/OUCopula. Keywords: Multidisciplinary Topics and Applications: MTA: Bioinformatics Computer Vision: CV: Biomedical image analysis Machine Learning: ML: Multi-label learning Multidisciplinary Topics and Applications: MTA: Health and medicine},
  archive   = {C_IJCAI},
  author    = {Yang Li and Qiuyi Huang and Chong Zhong and Danjuan Yang and Meiyan Li and A.H. Welsh and Aiyi Liu and Bo Fu and Catherine C. Liu and Xingtao Zhou},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/655},
  month     = {8},
  pages     = {5927-5935},
  title     = {OUCopula: Bi-channel multi-label copula-enhanced adapter-based CNN for myopia screening based on OU-UWF images},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing length generalization for attention based
knowledge tracing models with linear biases. <em>IJCAI</em>, 5918–5926.
(<a href="https://doi.org/10.24963/ijcai.2024/654">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Knowledge tracing (KT) is the task of predicting students&#39; future performance based on their historical learning interaction data. With the rapid advancement of attention mechanisms, many attention based KT models are developed. However, existing attention based KT models exhibit performance drops as the number of student interactions increases beyond the number of interactions on which the KT models are trained. We refer to this as the length generalization of KT model. In this paper, we propose stableKT to enhance length generalization that is able to learn from short sequences and maintain high prediction performance when generalizing on long sequences. Furthermore, we design a multi-head aggregation module to capture the complex relationships between questions and the corresponding knowledge components (KCs) by combining dot-product attention and hyperbolic attention. Experimental results on three public educational datasets show that our model exhibits robust capability of length generalization and outperforms all baseline models in terms of AUC. To encourage reproducible research, we make our data and code publicly available at https://pykt.org. Keywords: Multidisciplinary Topics and Applications: MTA: Education Humans and AI: HAI: Computer-aided education},
  archive   = {C_IJCAI},
  author    = {Xueyi Li and Youheng Bai and Teng Guo and Zitao Liu and Yaying Huang and Xiangyu Zhao and Feng Xia and Weiqi Luo and Jian Weng},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/654},
  month     = {8},
  pages     = {5918-5926},
  title     = {Enhancing length generalization for attention based knowledge tracing models with linear biases},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stochastic neural simulator for generalizing dynamical
systems across environments. <em>IJCAI</em>, 5909–5917. (<a
href="https://doi.org/10.24963/ijcai.2024/653">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Neural simulators for modeling complex dynamical systems have been extensively studied for various real-world applications, such as weather forecasting, ocean current prediction, and computational fluid dynamics simulation. Although they have demonstrated powerful fitting and predicting, most existing models are only built to learn single-system dynamics. Several advanced researches have considered learning dynamics across environments, which can exploit the potential commonalities among the dynamics across environments and adapt to new environments. However, these methods still are prone to scarcity problems where per-environment data is sparse or limited. Therefore, we propose a novel CoNDP (Context-Informed Neural ODE Processes) to achieve learning system dynamics from sparse observations across environments. It can fully use contextual information of each environment to better capture the intrinsic commonalities across environments and distinguishable differences among environments while modeling uncertainty of system evolution, producing more accurate predictions. Intensive experiments are conducted on five complex dynamical systems in various fields. Results show that the proposed CoNDP can achieve optimal results compared with common neural simulators and state-of-the-art cross-environmental models. Keywords: Multidisciplinary Topics and Applications: MTA: Physical sciences Machine Learning: ML: Time series and data streams},
  archive   = {C_IJCAI},
  author    = {Liu Jiaqi and Jiaxu Cui and Jiayi Yang and Bo Yang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/653},
  month     = {8},
  pages     = {5909-5917},
  title     = {Stochastic neural simulator for generalizing dynamical systems across environments},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Privacy-preserving UCB decision process verification via
zk-SNARKs. <em>IJCAI</em>, 5900–5908. (<a
href="https://doi.org/10.24963/ijcai.2024/652">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With the increasingly widespread application of machine learning, how to strike a balance between protecting the privacy of data and algorithm parameters and ensuring the verifiability of machine learning has always been a challenge. This study explores the intersection of reinforcement learning and data privacy, specifically addressing the Multi-Armed Bandit (MAB) problem with the Upper Confidence Bound (UCB) algorithm. We introduce zkUCB, an innovative algorithm that employs the Zero-Knowledge Succinct Non-Interactive Argument of Knowledge (zk-SNARKs) to enhance UCB. zkUCB is carefully designed to safeguard the confidentiality of training data and algorithmic parameters, ensuring transparent UCB decision-making. Experiments highlight zkUCB&#39;s superior performance, attributing its enhanced reward to judicious quantization bit usage that reduces information entropy in the decision-making process. zkUCB&#39;s proof size and verification time scale linearly with the execution steps of zkUCB. This showcases zkUCB&#39;s adept balance between data security and operational efficiency. This approach contributes significantly to the ongoing discourse on reinforcing data privacy in complex decision-making processes, offering a promising solution for privacy-sensitive applications. Keywords: Multidisciplinary Topics and Applications: MTA: Security and privacy Machine Learning: ML: Multi-armed bandits Machine Learning: ML: Trustworthy machine learning},
  archive   = {C_IJCAI},
  author    = {Xikun Jiang and He Lyu and Chenhao Ying and Yibin Xu and Boris Düdder and Yuan Luo},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/652},
  month     = {8},
  pages     = {5900-5908},
  title     = {Privacy-preserving UCB decision process verification via zk-SNARKs},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Vertical symbolic regression via deep policy gradient.
<em>IJCAI</em>, 5891–5899. (<a
href="https://doi.org/10.24963/ijcai.2024/651">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Vertical Symbolic Regression (VSR) has recently been proposed to expedite the discovery of symbolic equations with many independent variables from experimental data. VSR reduces the search spaces following the vertical discovery path by building from reduced-form equations involving a subset of variables to all variables. While deep neural networks have shown promise in enhancing symbolic regression, directly integrating VSR with deep networks faces challenges such as gradient propagation and engineering complexities due to the tree representation of expressions. We propose Vertical Symbolic Regression using Deep Policy Gradient (VSR-DPG) and demonstrate that VSR-DPG can recover ground-truth equations involving multiple input variables, significantly beyond both deep reinforcement learning-based approaches and previous VSR variants. Our VSR-DPG models symbolic regression as a sequential decision-making process, in which equations are built from repeated applications of grammar rules. The integrated deep model is trained to maximize a policy gradient objective. Experimental results demonstrate that our VSR-DPG significantly outperforms popular baselines in identifying both algebraic equations and ordinary differential equations on a series of benchmarks. Keywords: Multidisciplinary Topics and Applications: MTA: Physical sciences Machine Learning: ML: Symbolic methods},
  archive   = {C_IJCAI},
  author    = {Nan Jiang and Md Nasim and Yexiang Xue},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/651},
  month     = {8},
  pages     = {5891-5899},
  title     = {Vertical symbolic regression via deep policy gradient},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ATTA: Adaptive test-time adaptation for multi-modal sleep
stage classification. <em>IJCAI</em>, 5882–5890. (<a
href="https://doi.org/10.24963/ijcai.2024/650">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Sleep stage classification is crucial for sleep quality assessment and disease diagnosis. Although some recent studies have made great strides in sleep stage classification performance, direct application to multi-modal sleep data with cross-domain distributional variations still poses challenges: 1) How to retain the sleep knowledge acquired by the model from the source domain during cross-domain adaptation to avoid catastrophic forgetting. 2) How to evaluate the contribution of different modalities in identifying specific sleep stages to serve test-time adaptation (TTA). 3) How to dynamically adapt the sleep model to different distribution shift in data domains of different subjects. To address these challenges, we propose an Adaptive Test-Time Adaptation (ATTA) method, a multi-modal test-time adaptation method for sleep stage classification. Specifically, the intra-modal retained-adaptive module is proposed for adapting to the target domain data while retaining the sleep knowledge acquired from the source domain to avoid catastrophic forgetting. The inter-modal contribution assessment module is designed to adaptively assess the contribution of each modality to the identification of specific sleep stages. Furthermore, the adaptive learning rate strategy utilizes a memory bank to record data from different subjects during testing, and based on this, it measures the differences between the target subject and those in the memory bank. According to the difference, the model adapts to the subject samples with different learning rates. We conduct experiments on mutual migration on two sleep datasets, SleepEDF and SHHS. The results show that our ATTA method outperforms state-of-the-art baselines in sleep stage classification. Keywords: Multidisciplinary Topics and Applications: MTA: Health and medicine Machine Learning: ML: Applications Humans and AI: HAI: Brain sciences Machine Learning: ML: Time series and data streams},
  archive   = {C_IJCAI},
  author    = {Ziyu Jia and Xihao Yang and Chenyang Zhou and Haoyang Deng and Tianzi Jiang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/650},
  month     = {8},
  pages     = {5882-5890},
  title     = {ATTA: Adaptive test-time adaptation for multi-modal sleep stage classification},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Personalized heart disease detection via ECG digital twin
generation. <em>IJCAI</em>, 5872–5881. (<a
href="https://doi.org/10.24963/ijcai.2024/649">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Heart diseases rank among the leading causes of global mortality, demonstrating a crucial need for early diagnosis and intervention. Most traditional electrocardiogram (ECG) based automated diagnosis methods are trained at population level, neglecting the customization of personalized ECGs to enhance individual healthcare management. A potential solution to address this limitation is to employ digital twins to simulate symptoms of diseases in real patients. In this paper, we present an innovative prospective learning approach for personalized heart disease detection, which generates digital twins of healthy individuals&#39; anomalous ECGs and enhances the model sensitivity to the personalized symptoms. In our approach, a vector quantized feature separator is proposed to locate and isolate the disease symptom and normal segments in ECG signals with ECG report guidance. Thus, the ECG digital twins can simulate specific heart diseases used to train a personalized heart disease detection model. Experiments demonstrate that our approach not only excels in generating high-fidelity ECG signals but also improves personalized heart disease detection. Moreover, our approach ensures robust privacy protection, safeguarding patient data in model development. The code can be found at https://github.com/huyjj/LAVQ-Editor. Keywords: Multidisciplinary Topics and Applications: MTA: Health and medicine Machine Learning: ML: Applications Machine Learning: ML: Generative models},
  archive   = {C_IJCAI},
  author    = {Yaojun Hu and Jintai Chen and Lianting Hu and Dantong Li and Jiahuan Yan and Haochao Ying and Huiying Liang and Jian Wu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/649},
  month     = {8},
  pages     = {5872-5881},
  title     = {Personalized heart disease detection via ECG digital twin generation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Delocate: Detection and localization for deepfake videos
with randomly-located tampered traces. <em>IJCAI</em>, 5862–5871. (<a
href="https://doi.org/10.24963/ijcai.2024/648">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deepfake videos are becoming increasingly realistic, showing few tampering traces on facial areas that vary between frames. Consequently, existing Deepfake detection methods struggle to detect unknown domain Deepfake videos while accurately locating the tampered region. To address this limitation, we propose Delocate, a novel Deepfake detection model that can both recognize and localize unknown domain Deepfake videos. Our method consists of two stages named recovering and localization. In the recovering stage, the model randomly masks regions of interest (ROIs) and reconstructs real faces without tampering traces, leading to a relatively good recovery effect for real faces and a poor recovery effect for fake faces. In the localization stage, the output of the recovery phase and the forgery ground truth mask serve as supervision to guide the forgery localization process. This process strategically emphasizes the recovery phase of fake faces with poor recovery, facilitating the localization of tampered regions. Our extensive experiments on four widely used benchmark datasets demonstrate that Delocate not only excels in localizing tampered areas but also enhances cross-domain detection performance. Keywords: Multidisciplinary Topics and Applications: MTA: Security and privacy Computer Vision: CV: Biometrics, face, gesture and pose recognition},
  archive   = {C_IJCAI},
  author    = {Juan Hu and Xin Liao and Difei Gao and Satoshi Tsutsui and Qian Wang and Zheng Qin and Mike Zheng Shou},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/648},
  month     = {8},
  pages     = {5862-5871},
  title     = {Delocate: Detection and localization for deepfake videos with randomly-located tampered traces},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Physics-informed neural networks: Minimizing residual loss
with wide networks and effective activations. <em>IJCAI</em>, 5853–5861.
(<a href="https://doi.org/10.24963/ijcai.2024/647">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The residual loss in Physics-Informed Neural Networks (PINNs) alters the simple recursive relation of layers in a feed-forward neural network by applying a differential operator, resulting in a loss landscape that is inherently different from those of common supervised problems. Therefore, relying on the existing theory leads to unjustified design choices and suboptimal performance. In this work, we analyze the residual loss by studying its characteristics at critical points to find the conditions that result in effective training of PINNs. Specifically, we first show that under certain conditions, the residual loss of PINNs can be globally minimized by a wide neural network. Furthermore, our analysis also reveals that an activation function with well-behaved high-order derivatives plays a crucial role in minimizing the residual loss. In particular, to solve a k-th order PDE, the k-th derivative of the activation function should be bijective. The established theory paves the way for designing and choosing effective activation functions for PINNs and explains why periodic activations have shown promising performance in certain cases. Finally, we verify our findings by conducting a set of experiments on several PDEs. Our code is publicly available at https://github.com/nimahsn/pinns_tf2. Keywords: Multidisciplinary Topics and Applications: MTA: Physical sciences Machine Learning: ML: Applications},
  archive   = {C_IJCAI},
  author    = {Nima Hosseini Dashtbayaz and Ghazal Farhani and Boyu Wang and Charles X. Ling},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/647},
  month     = {8},
  pages     = {5853-5861},
  title     = {Physics-informed neural networks: Minimizing residual loss with wide networks and effective activations},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamicity-aware social bot detection with dynamic graph
transformers. <em>IJCAI</em>, 5844–5852. (<a
href="https://doi.org/10.24963/ijcai.2024/646">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Detecting social bots has evolved into a pivotal yet intricate task, aimed at combating the dissemination of misinformation and preserving the authenticity of online interactions. While earlier graph-based approaches, which leverage topological structure of social networks, yielded notable outcomes, they overlooked the inherent dynamicity of social networks -- In reality, they largely depicted the social network as a static graph and solely relied on its most recent state. Due to the absence of dynamicity modeling, such approaches are vulnerable to evasion, particularly when advanced social bots interact with other users to camouflage identities and escape detection. To tackle these challenges, we propose BotDGT, a novel framework that not only considers the topological structure, but also effectively incorporates dynamic nature of social network. Specifically, we characterize a social network as a dynamic graph. A structural module is employed to acquire topological information from each historical snapshot. Additionally, a temporal module is proposed to integrate historical context and model the evolving behavior patterns exhibited by social bots and legitimate users. Experimental results demonstrate the superiority of BotDGT against the leading methods that neglected the dynamic nature of social networks in terms of accuracy, recall, and F1-score. Keywords: Multidisciplinary Topics and Applications: MTA: Web and social networks Data Mining: DM: Mining graphs Data Mining: DM: Mining text, web, social media},
  archive   = {C_IJCAI},
  author    = {Buyun He and Yingguang Yang and Qi Wu and Hao Liu and Renyu Yang and Hao Peng and Xiang Wang and Yong Liao and Pengyuan Zhou},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/646},
  month     = {8},
  pages     = {5844-5852},
  title     = {Dynamicity-aware social bot detection with dynamic graph transformers},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). InstructME: An instruction guided music edit framework with
latent diffusion models. <em>IJCAI</em>, 5835–5843. (<a
href="https://doi.org/10.24963/ijcai.2024/645">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Music editing primarily entails the modification of instrument tracks or remixing in the whole, which offers a novel reinterpretation of the original piece through a series of operations. These music processing methods hold immense potential across various applications but demand substantial expertise. Prior methodologies, although effective for image and audio modifications, falter when directly applied to music. This is attributed to music&#39;s distinctive data nature, where such methods can inadvertently compromise the intrinsic harmony and coherence of music. In this paper, we develop InstructME, an Instruction guided Music Editing and remixing framework based on latent diffusion models. Our framework fortifies the U-Net with multi-scale aggregation in order to maintain consistency before and after editing. In addition, we introduce chord progression matrix as condition information and incorporate it in the semantic space to improve melodic harmony while editing. For accommodating extended musical pieces, InstructME employs a chunk transformer, enabling it to discern long-term temporal dependencies within music sequences. We tested InstructME in instrument-editing, remixing, and multi-round editing. Both subjective and objective evaluations indicate that our proposed method significantly surpasses preceding systems in music quality, text relevance and harmony. Demo samples are available at https://musicedit.github.io Keywords: Multidisciplinary Topics and Applications: MTA: Arts and creativity Multidisciplinary Topics and Applications: MTA: Other},
  archive   = {C_IJCAI},
  author    = {Bing Han and Junyu Dai and Weituo Hao and Xinyan He and Dong Guo and Jitong Chen and Yuxuan Wang and Yanmin Qian and Xuchen Song},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/645},
  month     = {8},
  pages     = {5835-5843},
  title     = {InstructME: An instruction guided music edit framework with latent diffusion models},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing fine-grained urban flow inference via incremental
neural operator. <em>IJCAI</em>, 5826–5834. (<a
href="https://doi.org/10.24963/ijcai.2024/644">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Fine-grained urban flow inference (FUFI), which involves inferring fine-grained flow maps from their coarse-grained counterparts, is of tremendous interest in the realm of sustainable urban traffic services. To address the FUFI, existing solutions mainly concentrate on investigating spatial dependencies, introducing external factors, reducing excessive memory costs, etc., -- while rarely considering the catastrophic forgetting (CF) problem. Motivated by recent operator learning, we present an Urban Neural Operator solution with Incremental learning (UNOI), primarily seeking to learn grained-invariant solutions for FUFI in addition to addressing CF. Specifically, we devise an urban neural operator (UNO) in UNOI that learns mappings between approximation spaces by treating the different-grained flows as continuous functions, allowing a more flexible capture of spatial correlations. Furthermore, the phenomenon of CF behind time-related flows could hinder the capture of flow dynamics. Thus, UNOI mitigates CF concerns as well as privacy issues by placing UNO blocks in two incremental settings, i.e., flow-related and task-related. Experimental results on large-scale real-world datasets demonstrate the superiority of our proposed solution against the baselines. Keywords: Multidisciplinary Topics and Applications: MTA: Sensor networks and smart cities Data Mining: DM: Applications Data Mining: DM: Mining spatial and/or temporal data Multidisciplinary Topics and Applications: MTA: Transportation},
  archive   = {C_IJCAI},
  author    = {Qiang Gao and Xiaolong Song and Li Huang and Goce Trajcevski and Fan Zhou and Xueqin Chen},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/644},
  month     = {8},
  pages     = {5826-5834},
  title     = {Enhancing fine-grained urban flow inference via incremental neural operator},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). VF-detector: Making multi-granularity code changes on
vulnerability fix detector robust to mislabeled changes. <em>IJCAI</em>,
5817–5825. (<a href="https://doi.org/10.24963/ijcai.2024/643">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As software development projects increasingly rely on open-source software, users face the risk of security vulnerabilities from third-party libraries. To address label and character noise in code changes, we present VF-Detector to automatically identifying bug-fix commits in actual noise development environment. VF-Detector consists of three componments: Data Pre-processing (DP), Vulnerability Confidence Computation (VCC) and Confidence Learning Denoising (CLD). The DP component is responsible for preprocessing code change data. The VCC component calculates code change confidence value for each bug-fix by extracting features at various granularity levels. The CLD component removes noise and enhances model robustness by pruning noisy data with confidence values and performing effort-aware adjustments. Experimental results demonstrate VF-Detector&#39;s superiority over state-of-the-art methods in EffortCost@L and Popt@L metrics on Java and Python datasets. The improvements were 6.5% and 5% for Java, and 23.4% and 17.8% for Python. Keywords: Multidisciplinary Topics and Applications: MTA: Software engineering Agent-based and Multi-agent Systems: MAS: Trust and reputation Data Mining: DM: Applications Machine Learning: ML: Applications},
  archive   = {C_IJCAI},
  author    = {Zhenkan Fu and Shikai Guo and Hui Li and Rong Chen and Xiaochen Li and He Jiang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/643},
  month     = {8},
  pages     = {5817-5825},
  title     = {VF-detector: Making multi-granularity code changes on vulnerability fix detector robust to mislabeled changes},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MMGNN: A molecular merged graph neural network for
explainable solvation free energy prediction. <em>IJCAI</em>, 5808–5816.
(<a href="https://doi.org/10.24963/ijcai.2024/642">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we address the challenge of accurately modeling and predicting Gibbs free energy in solute-solvent interactions, a pivotal yet complex aspect in the field of chemical modeling. Traditional approaches, primarily relying on deep learning models, face limitations in capturing the intricate dynamics of these interactions. To overcome these constraints, we introduce a novel framework, molecular modeling graph neural network (MMGNN), which more closely mirrors real-world chemical processes.Specifically, MMGNN explicitly models atomic interactions such as hydrogen bonds by initially forming indiscriminate connections between intermolecular atoms, which are then refined using an attention-based aggregation method, tailoring to specific solute-solvent pairs. To address the challenges of non-interactive or repulsive atomic interactions, MMGNN incorporates interpreters for nodes and edges in the merged graph, enhancing explainability and reducing redundancy. MMGNN stands as the first framework to explicitly align with real chemical processes, providing a more accurate and scientifically sound approach to modeling solute-solvent interactions. The infusion of explainability allows for the extraction of key subgraphs, which are pivotal for further research in solute-solvent dynamics. Extensive experimental validation confirms the efficacy and enhanced explainability of MMGNN. Keywords: Multidisciplinary Topics and Applications: MTA: Bioinformatics Data Mining: DM: Applications Machine Learning: ML: Applications},
  archive   = {C_IJCAI},
  author    = {Wenjie Du and Shuai Zhang and Di Wu and Jun Xia and Ziyuan Zhao and Junfeng Fang and Yang Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/642},
  month     = {8},
  pages     = {5808-5816},
  title     = {MMGNN: A molecular merged graph neural network for explainable solvation free energy prediction},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Linear-time optimal deadlock detection for efficient
scheduling in multi-track railway networks. <em>IJCAI</em>, 5799–5807.
(<a href="https://doi.org/10.24963/ijcai.2024/641">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The railway scheduling problem requires the computation of an operable timetable that satisfies constraints involving railway infrastructure and resource occupancy times, while minimising average delay over a set of events. Since this problem is computationally hard, practical solutions typically roll out feasible (but suboptimal) schedules one step at a time, by choosing which train to move next in every step. The choices made by such algorithms are necessarily myopic, and incur the risk of driving the system to a deadlock. To escape deadlocks, the predominant approach is to stay away from states flagged as potentially unsafe by some fast-to-compute rule R. While many choices of R guarantee deadlock avoidance, they are suboptimal in the sense of also flagging some safe states as unsafe. In this paper, we revisit the literature on process scheduling and describe a rule R0 that is (i) necessary and sufficient for deadlock detection when the network has at least two tracks in each resource (station / track section), (ii) computable in linear time, and (iii) yields lower delays when combined with existing scheduling algorithms on both synthetic and real data sets from Indian Railways. Keywords: Multidisciplinary Topics and Applications: MTA: Transportation Planning and Scheduling: PS: Applications Planning and Scheduling: PS: Markov decisions processes Planning and Scheduling: PS: Scheduling},
  archive   = {C_IJCAI},
  author    = {Hastyn Doshi and Ayush Tripathi and Keshav Agarwal and Harshad Khadilkar and Shivaram Kalyanakrishnan},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/641},
  month     = {8},
  pages     = {5799-5807},
  title     = {Linear-time optimal deadlock detection for efficient scheduling in multi-track railway networks},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Geometry-guided conditional adaptation for surrogate models
of large-scale 3D PDEs on arbitrary geometries. <em>IJCAI</em>,
5790–5798. (<a href="https://doi.org/10.24963/ijcai.2024/640">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep learning surrogate models aim to accelerate the solving of partial differential equations (PDEs) and have achieved certain promising results. Although several main-stream models through neural operator learning have been applied to delve into PDEs on varying geometries, they were designed to map the complex geometry to a latent uniform grid, which is still challenging to learn by the networks with general architectures. In this work, we rethink the critical factors of PDE solutions and propose a novel model-agnostic framework, called 3D Geometry-Guided Conditional adaptation (3D-GeoCA), for solving PDEs on arbitrary 3D geometries. Starting with a 3D point cloud geometry encoder, 3D-GeoCA can extract the essential and robust representations of any kind of geometric shapes, which conditionally guides the adaptation of hidden features in the surrogate model. We conduct experiments on two public computational fluid dynamics datasets, the Shape-Net Car and Ahmed-Body dataset, using several surrogate models as the backbones with various point cloud geometry encoders to simulate corresponding large-scale Reynolds Average Navier-Stokes equations. Equipped with 3D-GeoCA, these backbone models can reduce the L-2 error by a large margin. Moreover, this 3D-GeoCA is model-agnostic so that it can be applied to any surrogate model. Keywords: Multidisciplinary Topics and Applications: MTA: Physical sciences Computer Vision: CV: 3D computer vision Computer Vision: CV: Transfer, low-shot, semi- and un- supervised learning Machine Learning: ML: Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Jingyang Deng and Xingjian Li and Haoyi Xiong and Xiaoguang Hu and Jinwen Ma},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/640},
  month     = {8},
  pages     = {5790-5798},
  title     = {Geometry-guided conditional adaptation for surrogate models of large-scale 3D PDEs on arbitrary geometries},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Shadow-free membership inference attacks: Recommender
systems are more vulnerable than you thought. <em>IJCAI</em>, 5781–5789.
(<a href="https://doi.org/10.24963/ijcai.2024/639">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recommender systems have been successfully applied in many applications. Nonetheless, recent studies demonstrate that recommender systems are vulnerable to membership inference attacks (MIAs), leading to the leakage of users’ membership privacy. However, existing MIAs relying on shadow training suffer a large performance drop when the attacker lacks knowledge of the training data distribution and the model architecture of the target recommender system. To better understand the privacy risks of recommender systems, we propose shadow-free MIAs that directly leverage a user’s recommendations for membership inference. Without shadow training, the proposed attack can conduct MIAs efficiently and effectively under a practice scenario where the attacker is given only black-box access to the target recommender system. The proposed attack leverages an intuition that the recommender system personalizes a user’s recommendations if his historical interactions are used by it. Thus, an attacker can infer membership privacy by determining whether the recommendations are more similar to the interactions or the general popular items. We conduct extensive experiments on benchmark datasets across various recommender systems. Remarkably, our attack achieves far better attack accuracy with low false positive rates than baselines while with a much lower computational cost. Keywords: Multidisciplinary Topics and Applications: MTA: Security and privacy AI Ethics, Trust, Fairness: ETF: Safety and robustness AI Ethics, Trust, Fairness: ETF: Trustworthy AI},
  archive   = {C_IJCAI},
  author    = {Xiaoxiao Chi and Xuyun Zhang and Yan Wang and Lianyong Qi and Amin Beheshti and Xiaolong Xu and Kim-Kwang Raymond Choo and Shuo Wang and Hongsheng Hu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/639},
  month     = {8},
  pages     = {5781-5789},
  title     = {Shadow-free membership inference attacks: Recommender systems are more vulnerable than you thought},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Federated prompt learning for weather foundation models on
devices. <em>IJCAI</em>, 5772–5780. (<a
href="https://doi.org/10.24963/ijcai.2024/638">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {On-device intelligence for weather forecasting uses local deep learning models to analyze weather patterns without centralized cloud computing, holds significance for supporting human activates. Federated Learning is a promising solution for such forecasting by enabling collaborative model training without sharing raw data. However, it faces three main challenges that hinder its reliability: (1) data heterogeneity among devices due to geographic differences; (2) data homogeneity within individual devices and (3) communication overload from sending large model parameters for collaboration. To address these challenges, this paper propose Federated Prompt learning for Weather Foundation Models on Devices (FedPoD), which enables devices to obtain highly customized models while maintaining communication efficiency. Concretely, our Adaptive Prompt Tuning leverages lightweight prompts guide frozen foundation model to generate more precise predictions, also conducts prompt-based multi-level communication to encourage multi-source knowledge fusion and regulate optimization. Additionally, Dynamic Graph Modeling constructs graphs from prompts, prioritizing collaborative training among devices with similar data distributions to against heterogeneity. Extensive experiments demonstrates FedPoD leads the performance among state-of-the-art baselines across various setting in real-world on-device weather forecasting datasets. Keywords: Multidisciplinary Topics and Applications: MTA: Energy, environment and sustainability Machine Learning: ML: Applications Machine Learning: ML: Federated learning Data Mining: DM: Mining heterogenous data},
  archive   = {C_IJCAI},
  author    = {Shengchao Chen and Guodong Long and Tao Shen and Jing Jiang and Chengqi Zhang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/638},
  month     = {8},
  pages     = {5772-5780},
  title     = {Federated prompt learning for weather foundation models on devices},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Predictive modeling with temporal graphical representation
on electronic health records. <em>IJCAI</em>, 5763–5771. (<a
href="https://doi.org/10.24963/ijcai.2024/637">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep learning-based predictive models, leveraging Electronic Health Records (EHR), are receiving increasing attention in healthcare. An effective representation of a patient&#39;s EHR should hierarchically encompass both the temporal relationships between historical visits and medical events, and the inherent structural information within these elements. Existing patient representation methods can be roughly categorized into sequential representation and graphical representation. The sequential representation methods focus only on the temporal relationships among longitudinal visits. On the other hand, the graphical representation approaches, while adept at extracting the graph-structured relationships between various medical events, fall short in effectively integrate temporal information. To capture both types of information, we model a patient&#39;s EHR as a novel temporal heterogeneous graph. This graph includes historical visits nodes and medical events nodes. It propagates structured information from medical event nodes to visit nodes and utilizes time-aware visit nodes to capture changes in the patient&#39;s health status. Furthermore, we introduce a novel temporal graph transformer (TRANS) that integrates temporal edge features, global positional encoding, and local structural encoding into heterogeneous graph convolution, capturing both temporal and structural information. We validate the effectiveness of TRANS through extensive experiments on three real-world datasets. The results show that our proposed approach achieves state-of-the-art performance. Keywords: Multidisciplinary Topics and Applications: MTA: Health and medicine Data Mining: DM: Applications},
  archive   = {C_IJCAI},
  author    = {Jiayuan Chen and Changchang Yin and Yuanlong Wang and Ping Zhang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/637},
  month     = {8},
  pages     = {5763-5771},
  title     = {Predictive modeling with temporal graphical representation on electronic health records},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Balancing multimodal learning via online logit modulation.
<em>IJCAI</em>, 5753–5761. (<a
href="https://doi.org/10.24963/ijcai.2024/636">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multimodal learning is provably superior to unimodal learning. However, in practice, the best-performing unimodal networks often outperform jointly trained multimodal networks. This phenomenon can be attributed to the varying convergence and generalization rates across different modalities, leading to the dominance of one modality and causing underfitting of other modalities in simple multimodal joint training. To mitigate this issue, we propose two key ingredients: i) disentangling the learning of unimodal features and multimodal interaction through an intermediate representation fusion block; ii) modulating the logits of different modalities via dynamic coefficients during training to align their magnitudes with the target values, referred to as online logit modulation (OLM). Remarkably, OLM is model-agnostic and can be seamlessly integrated with most existing multimodal training frameworks. Empirical evidence shows that our approach brings significant enhancements over baselines on a wide range of multimodal tasks, covering video, audio, text, image, and depth modalities. Keywords: Machine Learning: ML: Optimization Computer Vision: CV: Multimodal learning Machine Learning: ML: Applications Machine Learning: ML: Attention models},
  archive   = {C_IJCAI},
  author    = {Daoming Zong and Chaoyue Ding and Baoxiang Li and Jiakui Li and Ken Zheng},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/636},
  month     = {8},
  pages     = {5753-5761},
  title     = {Balancing multimodal learning via online logit modulation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). PrivSGP-VR: Differentially private variance-reduced
stochastic gradient push with tight utility bounds. <em>IJCAI</em>,
5743–5752. (<a href="https://doi.org/10.24963/ijcai.2024/635">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we propose a differentially private decentralized learning method (termed PrivSGP-VR) which employs stochastic gradient push with variance reduction and guarantees (epsilon, delta)-differential privacy (DP) for each node. Our theoretical analysis shows that, under DP Gaussian noise with constant variance, PrivSGP-VR achieves a sub-linear convergence rate of O(1/sqrt(nK)), where n and K are the number of nodes and iterations, respectively, which is independent of stochastic gradient variance, and achieves a linear speedup with respect to n. Leveraging the moments accountant method, we further derive an optimal K to maximize the model utility under certain privacy budget in decentralized settings. With this optimized K, PrivSGP-VR achieves a tight utility bound of O(sqrt(d*log(1/delta))/(sqrt(n)*J*epsilon)), where J and d are the number of local samples and the dimension of decision variable, respectively, which matches that of the server-client distributed counterparts, and exhibits an extra factor of 1/sqrt(n) improvement compared to that of the existing decentralized counterparts, such as A(DP)2SGD. Extensive experiments corroborate our theoretical findings, especially in terms of the maximized utility with optimized K, in fully decentralized settings. Keywords: Machine Learning: ML: Trustworthy machine learning Agent-based and Multi-agent Systems: MAS: Multi-agent learning Machine Learning: ML: Federated learning Machine Learning: ML: Optimization},
  archive   = {C_IJCAI},
  author    = {Zehan Zhu and Yan Huang and Xin Wang and Jinming Xu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/635},
  month     = {8},
  pages     = {5743-5752},
  title     = {PrivSGP-VR: Differentially private variance-reduced stochastic gradient push with tight utility bounds},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Efficient tuning and inference for large language models on
textual graphs. <em>IJCAI</em>, 5734–5742. (<a
href="https://doi.org/10.24963/ijcai.2024/634">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Rich textual and topological information of textual graphs need to be modeled in real-world applications such as webpages, e-commerce, and academic articles. Practitioners have been long following the path of adopting a shallow text encoder and a subsequent graph neural network (GNN) to solve this problem. In light of recent advancements in large language models (LLMs), it is apparent that integrating LLMs for enhanced textual encoding can substantially improve the performance of textual graphs. Nevertheless, the efficiency of these methods poses a significant challenge. In this paper, we propose ENGINE, a parameter- and memory-efficient fine-tuning method for textual graphs with an LLM encoder. The key insight is to combine the LLMs and GNNs through a tunable side structure, which significantly reduces the training complexity without impairing the joint model&#39;s capacity. Extensive experiments on textual graphs demonstrate our method&#39;s effectiveness by achieving the best model performance, meanwhile having the lowest training cost compared to previous methods. Moreover, we introduce two variants with caching and dynamic early exit to further enhance training and inference speed. Specifically, caching accelerates ENGINE&#39;s training by 12x, and dynamic early exit achieves up to 5x faster inference with a negligible performance drop (at maximum 1.17% relevant drop across 7 datasets). Our codes are available at: https://github.com/ZhuYun97/ENGINE. Keywords: Machine Learning: ML: Sequence and graph learning Data Mining: DM: Mining graphs Natural Language Processing: NLP: Language models Machine Learning: ML: Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Yun Zhu and Yaoke Wang and Haizhou Shi and Siliang Tang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/634},
  month     = {8},
  pages     = {5734-5742},
  title     = {Efficient tuning and inference for large language models on textual graphs},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). VMFER: Von mises-fisher experience resampling based on
uncertainty of gradient directions for policy improvement.
<em>IJCAI</em>, 5725–5733. (<a
href="https://doi.org/10.24963/ijcai.2024/633">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Reinforcement Learning (RL) is a widely employed technique in decision-making problems, encompassing two fundamental operations -- policy evaluation and policy improvement. Enhancing learning efficiency remains a key challenge in RL, with many efforts focused on using ensemble critics to boost policy evaluation efficiency. However, when using multiple critics, the actor in the policy improvement process can obtain different gradients. Previous studies have combined these gradients without considering their disagreements. Therefore, optimizing the policy improvement process is crucial to enhance learning efficiency. This study focuses on investigating the impact of gradient disagreements caused by ensemble critics on policy improvement. We introduce the concept of uncertainty of gradient directions as a means to measure the disagreement among gradients utilized in the policy improvement process. Through measuring the disagreement among gradients, we find that transitions with lower uncertainty of gradient directions are more reliable in the policy improvement process. Building on this analysis, we propose a method called von Mises-Fisher Experience Resampling (vMFER), which optimizes the policy improvement process by resampling transitions and assigning higher confidence to transitions with lower uncertainty of gradient directions. Our experiments demonstrate that vMFER significantly outperforms the benchmark and is particularly well-suited for ensemble structures in RL. Keywords: Machine Learning: ML: Reinforcement learning},
  archive   = {C_IJCAI},
  author    = {Yiwen Zhu and Jinyi Liu and Wenya Wei and Qianyi Fu and Yujing Hu and Zhou Fang and Bo An and Jianye Hao and Tangjie Lv and Changjie Fan},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/633},
  month     = {8},
  pages     = {5725-5733},
  title     = {VMFER: Von mises-fisher experience resampling based on uncertainty of gradient directions for policy improvement},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). FedTAD: Topology-aware data-free knowledge distillation for
subgraph federated learning. <em>IJCAI</em>, 5716–5724. (<a
href="https://doi.org/10.24963/ijcai.2024/632">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Subgraph federated learning (subgraph-FL) is a new distributed paradigm that facilitates the collaborative training of graph neural networks (GNNs) by multi-client subgraphs. Unfortunately, a significant challenge of subgraph-FL arises from subgraph heterogeneity, which stems from node and topology variation, causing the impaired performance of the global GNN. Despite various studies, they have not yet thoroughly investigated the impact mechanism of subgraph heterogeneity. To this end, we decouple node and topology variation, revealing that they correspond to differences in label distribution and structure homophily. Remarkably, these variations lead to significant differences in the class-wise knowledge reliability of multiple local GNNs, misguiding the model aggregation with varying degrees. Building on this insight, we propose topology-aware data-free knowledge distillation technology (FedTAD), enhancing reliable knowledge transfer from the local model to the global model. Extensive experiments on six public datasets consistently demonstrate the superiority of FedTAD over state-of-the-art baselines. Keywords: Machine Learning: ML: Sequence and graph learning Machine Learning: ML: Classification Machine Learning: ML: Federated learning},
  archive   = {C_IJCAI},
  author    = {Yinlin Zhu and Xunkai Li and Zhengyu Wu and Di Wu and Miao Hu and Rong-Hua Li},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/632},
  month     = {8},
  pages     = {5716-5724},
  title     = {FedTAD: Topology-aware data-free knowledge distillation for subgraph federated learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AnchorGT: Efficient and flexible attention architecture for
scalable graph transformers. <em>IJCAI</em>, 5707–5715. (<a
href="https://doi.org/10.24963/ijcai.2024/631">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph Transformers (GTs) have significantly advanced the field of graph representation learning by overcoming the limitations of message-passing graph neural networks (GNNs) and demonstrating promising performance and expressive power. However, the quadratic complexity of self-attention mechanism in GTs has limited their scalability, and previous approaches to address this issue often suffer from expressiveness degradation or lack of versatility. To address this issue, we propose AnchorGT, a novel attention architecture for GTs with global receptive field and almost linear complexity, which serves as a flexible building block to improve the scalability of a wide range of GT models. Inspired by anchor-based GNNs, we employ structurally important k-dominating node set as anchors and design an attention mechanism that focuses on the relationship between individual nodes and anchors, while retaining the global receptive field for all nodes. With its intuitive design, AnchorGT can easily replace the attention module in various GT models with different network architectures and structural encodings, resulting in reduced computational overhead without sacrificing performance. In addition, we theoretically prove that AnchorGT attention can be strictly more expressive than Weisfeiler-Lehman test, showing its superiority in representing graph structures. Our experiments on three state-of-the-art GT models demonstrate that their AnchorGT variants can achieve similar results while being faster and significantly more memory efficient. Keywords: Machine Learning: ML: Sequence and graph learning},
  archive   = {C_IJCAI},
  author    = {Wenhao Zhu and Guojie Song and Liang Wang and Shaoguo Liu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/631},
  month     = {8},
  pages     = {5707-5715},
  title     = {AnchorGT: Efficient and flexible attention architecture for scalable graph transformers},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Towards sharper risk bounds for minimax problems.
<em>IJCAI</em>, 5698–5706. (<a
href="https://doi.org/10.24963/ijcai.2024/630">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Minimax problems have achieved success in machine learning such as adversarial training, robust optimization, reinforcement learning. For theoretical analysis, current optimal excess risk bounds, which are composed by generalization error and optimization error, present 1/n-rates in strongly-convex-strongly-concave (SC-SC) settings. Existing studies mainly focus on minimax problems with specific algorithms for optimization error, with only a few studies on generalization performance, which limit better excess risk bounds. In this paper, we study the generalization bounds measured by the gradients of primal functions using uniform localized convergence. We obtain a sharper high probability generalization error bound for nonconvex-strongly-concave (NC-SC) stochastic minimax problems. Furthermore, we provide dimension-independent results under Polyak-Lojasiewicz condition for the outer layer. Based on our generalization error bound, we analyze some popular algorithms such as empirical saddle point (ESP), gradient descent ascent (GDA) and stochastic gradient descent ascent (SGDA). We derive better excess primal risk bounds with further reasonable assumptions, which, to the best of our knowledge, are n times faster than exist results in minimax problems. Keywords: Machine Learning: ML: Learning theory Machine Learning: ML: Adversarial machine learning Machine Learning: ML: Reinforcement learning Machine Learning: ML: Robustness},
  archive   = {C_IJCAI},
  author    = {Bowei Zhu and Shaojie Li and Yong Liu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/630},
  month     = {8},
  pages     = {5698-5706},
  title     = {Towards sharper risk bounds for minimax problems},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SDformer: Transformer with spectral filter and dynamic
attention for multivariate time series long-term forecasting.
<em>IJCAI</em>, 5689–5697. (<a
href="https://doi.org/10.24963/ijcai.2024/629">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Transformer has gained widespread adoption in modeling time series due to the exceptional ability of its self-attention mechanism in capturing long-range dependencies. However, when processing time series data with numerous variates, the vanilla self-attention mechanism tends to distribute attention weights evenly and smoothly, causing row-homogenization in attention maps and further hampering time series forecasting. To tackle this issue, we propose an advanced Transformer architecture entitled SDformer, which designs two novel modules, Spectral-Filter-Transform (SFT) and Dynamic-Directional-Attention (DDA), and integrates them into the encoder of Transformer to achieve more intensive attention allocation. Specifically, the SFT module utilizes the Fast Fourier Transform to select the most prominent frequencies, along with a Hamming Window to smooth and denoise the filtered series data; The DDA module applies a specialized kernel function to the query and key vectors projected from the denoised data, concentrating this innovative attention mechanism more effectively on the most informative variates to obtain a sharper attention distribution. These two modules jointly enable attention weights to be more salient among numerous variates, which in turn enhances the attention&#39;s ability to capture multivariate correlations, improving the performance in forecasting. Extensive experiments on public datasets demonstrate its superior performance over other state-of-the-art models. Code is available at https://github.com/zhouziyu02/SDformer. Keywords: Machine Learning: ML: Time series and data streams Data Mining: DM: Mining spatial and/or temporal data Machine Learning: ML: Attention models},
  archive   = {C_IJCAI},
  author    = {Ziyu Zhou and Gengyu Lyu and Yiming Huang and Zihao Wang and Ziyu Jia and Zhen Yang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/629},
  month     = {8},
  pages     = {5689-5697},
  title     = {SDformer: Transformer with spectral filter and dynamic attention for multivariate time series long-term forecasting},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Rethinking centered kernel alignment in knowledge
distillation. <em>IJCAI</em>, 5680–5688. (<a
href="https://doi.org/10.24963/ijcai.2024/628">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Knowledge distillation has emerged as a highly effective method for bridging the representation discrepancy between large-scale models and lightweight models. Prevalent approaches involve leveraging appropriate metrics to minimize the divergence or distance between the knowledge extracted from the teacher model and the knowledge learned by the student model. Centered Kernel Alignment (CKA) is widely used to measure representation similarity and has been applied in several knowledge distillation methods. However, these methods are complex and fail to uncover the essence of CKA, thus not answering the question of how to use CKA to achieve simple and effective distillation properly. This paper first provides a theoretical perspective to illustrate the effectiveness of CKA, which decouples CKA to the upper bound of Maximum Mean Discrepancy (MMD) and a constant term. Drawing from this, we propose a novel Relation-Centered Kernel Alignment (RCKA) framework, which practically establishes a connection between CKA and MMD. Furthermore, we dynamically customize the application of CKA based on the characteristics of each task, with less computational source yet comparable performance than the previous methods. The extensive experiments on the CIFAR-100, ImageNet-1k, and MS-COCO demonstrate that our method achieves state-of-the-art performance on almost all teacher-student pairs for image classification and object detection, validating the effectiveness of our approaches. Our code is available in https://github.com/Klayand/PCKA. Keywords: Machine Learning: ML: Deep learning architectures Computer Vision: CV: Recognition (object detection, categorization) Computer Vision: CV: Representation learning Machine Learning: ML: Representation learning},
  archive   = {C_IJCAI},
  author    = {Zikai Zhou and Yunhang Shen and Shitong Shao and Linrui Gong and Shaohui Lin},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/628},
  month     = {8},
  pages     = {5680-5688},
  title     = {Rethinking centered kernel alignment in knowledge distillation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Large language model as a policy teacher for training
reinforcement learning agents. <em>IJCAI</em>, 5671–5679. (<a
href="https://doi.org/10.24963/ijcai.2024/627">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent studies have uncovered the potential of Large Language Models (LLMs) in addressing complex sequential decision-making tasks through the provision of high-level instructions. However, LLM-based agents lack specialization in tackling specific target problems, particularly in real-time dynamic environments. Additionally, deploying an LLM-based agent in practical scenarios can be both costly and time-consuming. On the other hand, reinforcement learning (RL) approaches train agents that specialize in the target task but often suffer from low sampling efficiency and high exploration costs. In this paper, we introduce a novel framework that addresses these challenges by training a smaller, specialized student RL agent using instructions from an LLM-based teacher agent. By incorporating the guidance from the teacher agent, the student agent can distill the prior knowledge of the LLM into its own model. Consequently, the student agent can be trained with significantly less data. Moreover, through further training with environment feedback, the student agent surpasses the capabilities of its teacher for completing the target task. We conducted experiments on challenging MiniGrid and Habitat environments, specifically designed for embodied AI research, to evaluate the effectiveness of our framework. The results clearly demonstrate that our approach achieves superior performance compared to strong baseline methods. Our code is available at https://github.com/ZJLAB-AMMI/LLM4Teach. Keywords: Machine Learning: ML: Reinforcement learning Natural Language Processing: NLP: Language models Uncertainty in AI: UAI: Sequential decision making},
  archive   = {C_IJCAI},
  author    = {Zihao Zhou and Bin Hu and Chenyang Zhao and Pu Zhang and Bin Liu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/627},
  month     = {8},
  pages     = {5671-5679},
  title     = {Large language model as a policy teacher for training reinforcement learning agents},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning in CubeRes model space for anomaly detection in 3D
GPR data. <em>IJCAI</em>, 5662–5670. (<a
href="https://doi.org/10.24963/ijcai.2024/626">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Three-dimensional Ground Penetrating Radar (3D GPR) data offer comprehensive views of the subsurface, yet identifying and classifying underground anomalies from this data is challenging due to limitations like scarce training data and variable underground environments. In response, we introduce learning in the Cube Reservoir Network (CubeRes) model space for efficient and accurate subsurface anomaly detection. CubeRes, incorporating three reservoirs, captures the dynamics in both horizontal and vertical directions inherent in the 3D GPR data. Fitting the data with CubeRes, representing the data with the compact fitted model, and measuring the difference between models by a proposed parameterized model metric, the original data is transformed from the data space to the CubeRes model space. Subsequently, we introduce an optimization strategy in this model space, aimed at bolstering fitting accuracy and improving category discrimination. This enhancement facilitates a more nuanced differentiation of dynamics across various GPR data categories, thereby enabling effective classification on the models rather than the original data. Experiments on real-world data validate our method&#39;s effectiveness and superiority, particularly in data-limited scenarios. Keywords: Machine Learning: ML: Applications Machine Learning: ML: Classification Machine Learning: ML: Recurrent networks},
  archive   = {C_IJCAI},
  author    = {Xiren Zhou and Shikang Liu and Ao Chen and Huanhuan Chen},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/626},
  month     = {8},
  pages     = {5662-5670},
  title     = {Learning in CubeRes model space for anomaly detection in 3D GPR data},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Boosting model resilience via implicit adversarial data
augmentation. <em>IJCAI</em>, 5653–5661. (<a
href="https://doi.org/10.24963/ijcai.2024/625">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Data augmentation plays a pivotal role in enhancing and diversifying training data. Nonetheless, consistently improving model performance in varied learning scenarios, especially those with inherent data biases, remains challenging. To address this, we propose to augment the deep features of samples by incorporating their adversarial and anti-adversarial perturbation distributions, enabling adaptive adjustment in the learning difficulty tailored to each sample’s specific characteristics. We then theoretically reveal that our augmentation process approximates the optimization of a surrogate loss function as the number of augmented copies increases indefinitely. This insight leads us to develop a meta-learning-based framework for optimizing classifiers with this novel loss, introducing the effects of augmentation while bypassing the explicit augmentation process. We conduct extensive experiments across four common biased learning scenarios: long-tail learning, generalized long-tail learning, noisy label learning, and subpopulation shift learning. The empirical results demonstrate that our method consistently achieves state-of-the-art performance, highlighting its broad adaptability. Keywords: Machine Learning: ML: Classification Data Mining: DM: Class imbalance and unequal cost Machine Learning: ML: Meta-learning Machine Learning: ML: Robustness},
  archive   = {C_IJCAI},
  author    = {Xiaoling Zhou and Wei Ye and Zhemg Lee and Rui Xie and Shikun Zhang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/625},
  month     = {8},
  pages     = {5653-5661},
  title     = {Boosting model resilience via implicit adversarial data augmentation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Denoising-aware contrastive learning for noisy time series.
<em>IJCAI</em>, 5644–5652. (<a
href="https://doi.org/10.24963/ijcai.2024/624">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Time series self-supervised learning (SSL) aims to exploit unlabeled data for pre-training to mitigate the reliance on labels. Despite the great success in recent years, there is limited discussion on the potential noise in the time series, which can severely impair the performance of existing SSL methods. To mitigate the noise, the de facto strategy is to apply conventional denoising methods before model training. However, this pre-processing approach may not fully eliminate the effect of noise in SSL for two reasons: (i) the diverse types of noise in time series make it difficult to automatically determine suitable denoising methods; (ii) noise can be amplified after mapping raw data into latent space. In this paper, we propose denoising-aware contrastive learning (DECL), which uses contrastive learning objectives to mitigate the noise in the representation and automatically selects suitable denoising methods for every sample. Extensive experiments on various datasets verify the effectiveness of our method. The code is open-sourced. Keywords: Machine Learning: ML: Self-supervised Learning Machine Learning: ML: Classification Machine Learning: ML: Representation learning Machine Learning: ML: Time series and data streams},
  archive   = {C_IJCAI},
  author    = {Shuang Zhou and Daochen Zha and Xiao Shen and Xiao Huang and Rui Zhang and Korris Chung},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/624},
  month     = {8},
  pages     = {5644-5652},
  title     = {Denoising-aware contrastive learning for noisy time series},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Delve into base-novel confusion: Redundancy exploration for
few-shot class-incremental learning. <em>IJCAI</em>, 5635–5643. (<a
href="https://doi.org/10.24963/ijcai.2024/623">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Few-shot class-incremental learning (FSCIL) aims to acquire knowledge from novel classes with limited samples while retaining information about base classes. Existing methods address catastrophic forgetting and overfitting by freezing the feature extractor during novel-class learning. However, these methods usually tend to cause the confusion between base and novel classes, i.e., classifying novel-class samples into base classes.In this paper, we delve into this phenomenon to study its cause and solution. We first interpret the confusion as the collision between the novel-class and the base-class region in the feature space.Then, we find the collision is caused by the label-irrelevant redundancies within the base-class feature and pixel space. Through qualitative and quantitative experiments, we identify this redundancy as the shortcut in the base-class training, which can be decoupled to alleviate the collision. Based on this analysis, to alleviate the collision between base and novel classes, we propose a method for FSCIL named Redundancy Decoupling and Integration (RDI). RDI first decouples redundancies from base-class space to shrink the intra-base-class feature space. Then, it integrates the redundancies as a dummy class to enlarge the inter-base-class feature space. This process effectively compresses the base-class feature space, creating buffer space for novel classes and alleviating the model&#39;s confusion between the base and novel classes. Extensive experiments across benchmark datasets, including CIFAR-100, miniImageNet, and CUB-200-2011 demonstrate that our method achieves state-of-the-art performance. Keywords: Machine Learning: ML: Incremental learning Machine Learning: ML: Few-shot learning},
  archive   = {C_IJCAI},
  author    = {Haichen Zhou and Yixiong Zou and Ruixuan Li and Yuhua Li and Kui Xiao},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/623},
  month     = {8},
  pages     = {5635-5643},
  title     = {Delve into base-novel confusion: Redundancy exploration for few-shot class-incremental learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SCAT: A time series forecasting with spectral central
alternating transformers. <em>IJCAI</em>, 5626–5634. (<a
href="https://doi.org/10.24963/ijcai.2024/622">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Time series forecasting has essential applications across various domains. For instance, forecasting power time series can optimize energy usage and bolster grid stability and reliability. Existing models based on transformer architecture are limited to classical design, ignoring the impact of spatial information and noise on model architecture design. Therefore, we propose an atypical design of Transformer-based models for multivariate time series forecasting. This design consists of two critical components: (i) spectral clustering center of time series employed as the focal point for attention computation; (ii) alternating attention mechanism wherein each query transformer is compatible with spectral clustering centers, executing attention at the sequence level instead of the token level. The alternating design has a two-fold benefit: firstly, it eliminates the uncertainty noise present in the dependent variable sequence of the channel input, and secondly, it incorporates the Euclidean distance to mitigate the impact of extreme values on the attention matrix, thereby aligning predictions more closely to the sequence&#39;s natural progression. Experiments on ten real-world datasets, encompassing Wind, Electricity, Weather, and others, demonstrate that our Spectral Central Alternating Transformer (SCAT) outperforms state-of-the-art methods (SOTA) by an average of 42.8% in prediction performance in power time series forecasting. Keywords: Machine Learning: ML: Time series and data streams},
  archive   = {C_IJCAI},
  author    = {Chengjie Zhou and Chao Che and Pengfei Wang and Qiang Zhang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/622},
  month     = {8},
  pages     = {5626-5634},
  title     = {SCAT: A time series forecasting with spectral central alternating transformers},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cross-view contrastive fusion for enhanced molecular
property prediction. <em>IJCAI</em>, 5617–5625. (<a
href="https://doi.org/10.24963/ijcai.2024/621">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Machine learning based molecular property prediction has been a hot topic in the field of computer aided drug discovery (CADD). However, current MPP methods face two prominent challenges: 1) single-view MPP methods do not sufficiently exploit the complementary information of molecular data across multiple views, generally producing suboptimal performance, and 2) most existing multi-view MPP methods ignore the disparities in data quality among different views, inadvertently introducing the risk of models being overshadowed by inferior views. To address the above challenges, we introduce a novel cross-view contrastive fusion for enhanced molecular property prediction method (MolFuse). First, we extract intricate molecular semantics and structures from both sequence and graph views to leverage the complementarity of multi-view data. Then, MolFuse employs two distinct graphs, the atomic graph and chemical bond graph, to enhance the representation of the molecular graph, allow us to integrate both the fundamental backbone attributes and the nuanced shape characteristics. Notably, we incorporate a dual learning mechanism to refine the initial feature representations, and global features are obtained by maximizing the coherence among diverse view-specific molecular representations for the downstream task. The overall learning processes are combined into a unified optimization problem for iterative training. Experiments on multiple benchmark datasets demonstrate the superiority of our MolFuse. Keywords: Machine Learning: ML: Multi-view learning Data Mining: DM: Mining graphs Multidisciplinary Topics and Applications: MTA: Bioinformatics},
  archive   = {C_IJCAI},
  author    = {Yan Zheng and Song Wu and Junyu Lin and Yazhou Ren and Jing He and Xiaorong Pu and Lifang He},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/621},
  month     = {8},
  pages     = {5617-5625},
  title     = {Cross-view contrastive fusion for enhanced molecular property prediction},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Constrained intrinsic motivation for reinforcement learning.
<em>IJCAI</em>, 5608–5616. (<a
href="https://doi.org/10.24963/ijcai.2024/620">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper investigates two fundamental problems that arise when utilizing Intrinsic Motivation (IM) for reinforcement learning in Reward-Free Pre-Training (RFPT) tasks and Exploration with Intrinsic Motivation (EIM) tasks: 1) how to design an effective intrinsic objective in RFPT tasks, and 2) how to reduce the bias introduced by the intrinsic objective in EIM tasks. Existing IM methods suffer from static skills, limited state coverage, sample inefficiency in RFPT tasks, and suboptimality in EIM tasks. To tackle these problems, we propose Constrained Intrinsic Motivation (CIM) for RFPT and EIM tasks, respectively: 1) CIM for RFPT maximizes the lower bound of the conditional state entropy subject to an alignment constraint on the state encoder network for efficient dynamic and diverse skill discovery and state coverage maximization; 2) CIM for EIM leverages constrained policy optimization to adaptively adjust the coefficient of the intrinsic objective to mitigate the distraction from the intrinsic objective. In various MuJoCo robotics environments, we empirically show that CIM for RFPT greatly surpasses fifteen IM methods for unsupervised skill discovery in terms of skill diversity, state coverage, and fine-tuning performance. Additionally, we showcase the effectiveness of CIM for EIM in redeeming intrinsic rewards when task rewards are exposed from the beginning. Our code is available at https://github.com/x-zheng16/CIM. Keywords: Machine Learning: ML: Reinforcement learning Robotics: ROB: Behavior and control Robotics: ROB: Learning in robotics},
  archive   = {C_IJCAI},
  author    = {Xiang Zheng and Xingjun Ma and Chao Shen and Cong Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/620},
  month     = {8},
  pages     = {5608-5616},
  title     = {Constrained intrinsic motivation for reinforcement learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning robust classifiers with self-guided spurious
correlation mitigation. <em>IJCAI</em>, 5599–5607. (<a
href="https://doi.org/10.24963/ijcai.2024/619">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep neural classifiers tend to rely on spurious correlations between spurious attributes of inputs and targets to make predictions, which could jeopardize their generalization capability. Training classifiers robust to spurious correlations typically relies on annotations of spurious correlations in data, which are often expensive to get. In this paper, we tackle an annotation-free setting and propose a self-guided spurious correlation mitigation framework. Our framework automatically constructs fine-grained training labels tailored for a classifier obtained with empirical risk minimization to improve its robustness against spurious correlations. The fine-grained training labels are formulated with different prediction behaviors of the classifier identified in a novel spuriousness embedding space. We construct the space with automatically detected conceptual attributes and a novel spuriousness metric which measures how likely a class-attribute correlation is exploited for predictions. We demonstrate that training the classifier to distinguish different prediction behaviors reduces its reliance on spurious correlations without knowing them a priori and outperforms prior methods on five real-world datasets. Keywords: Machine Learning: ML: Robustness Machine Learning: ML: Knowledge-aided learning},
  archive   = {C_IJCAI},
  author    = {Guangtao Zheng and Wenqian Ye and Aidong Zhang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/619},
  month     = {8},
  pages     = {5599-5607},
  title     = {Learning robust classifiers with self-guided spurious correlation mitigation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Protecting split learning by potential energy loss.
<em>IJCAI</em>, 5590–5598. (<a
href="https://doi.org/10.24963/ijcai.2024/618">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As a practical privacy-preserving learning method, split learning has drawn much attention in academia and industry. However, its security is constantly being questioned since the intermediate results are shared during training and inference. In this paper, we focus on the privacy leakage from the forward embeddings of split learning. Specifically, since the forward embeddings contain too much information about the label, the attacker can either use a few labeled samples to fine-tune the top model or perform unsupervised attacks such as clustering to infer the true labels from the forward embeddings. To prevent such kind of privacy leakage, we propose the potential energy loss to make the forward embeddings more &#39;complicated&#39;, by pushing embeddings of the same class towards the decision boundary. Therefore, it is hard for the attacker to learn from the forward embeddings. Experiment results show that our method significantly lowers the performance of both fine-tuning attacks and clustering attacks. Keywords: Machine Learning: ML: Federated learning AI Ethics, Trust, Fairness: ETF: Safety and robustness Multidisciplinary Topics and Applications: MTA: Security and privacy},
  archive   = {C_IJCAI},
  author    = {Fei Zheng and Chaochao Chen and Lingjuan Lyu and Xinyi Fu and Xing Fu and Weiqiang Wang and Xiaolin Zheng and Jianwei Yin},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/618},
  month     = {8},
  pages     = {5590-5598},
  title     = {Protecting split learning by potential energy loss},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards robust multi-label learning against dirty label
noise. <em>IJCAI</em>, 5581–5589. (<a
href="https://doi.org/10.24963/ijcai.2024/617">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In multi-label learning, one of the major challenges is that the data are associated with label noise including the random noisy labels (e.g., data encoding errors) and noisy labels created by annotators (e.g., missing, extra, or error label), where noise is promoted by different structures (e.g., gaussian, sparse or subjective). Existing methods are tailored to handle noise with one specific structure. However, they lack of consideration of the fact that the data are always with dirty noisy labels, simutaneously gaussian, sparse and subjective, in real applications. In this paper, we formalize the multi-label learning with dirty noise as a new learning problem, namely Noisy Multi-label Learning (NML). To solve the NML problem, we decompose a corrupted label matrix as the noise matrix plus a true label matrix (maybe high-rank). For the noise matrix, a mixed norm penalty is developed as regularizer for dirty noise distribution. Under this norm, the conditions required for exact noise recovery are provided theoretically. For the true label matrix that is not necessarily low-rank, we apply a non-linear mapping to ensure its low-rankness such that the high-order label correlation can be utilized. Experimental results show that the proposed method outperforms the state-of-the-art methods significantly. Keywords: Machine Learning: ML: Multi-label learning Machine Learning: ML: Optimization Machine Learning: ML: Weakly supervised learning},
  archive   = {C_IJCAI},
  author    = {Yuhai Zhao and Yejiang Wang and Zhengkui Wang and Wen Shan and Miaomiao Huang and Meixia Wang and Min Huang and Xingwei Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/617},
  month     = {8},
  pages     = {5581-5589},
  title     = {Towards robust multi-label learning against dirty label noise},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). NanoAdapt: Mitigating negative transfer in test time
adaptation with extremely small batch sizes. <em>IJCAI</em>, 5572–5580.
(<a href="https://doi.org/10.24963/ijcai.2024/616">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Test Time Adaptation (TTA) has garnered significant attention in recent years, with the research focus on addressing distribution shifts during test time. As one fundamental component of many TTA methods, the Batch Normalization (BN) layer plays a crucial role in enabling the model adaptability. However, existing BN strategies can prove detrimental when the batch size is (extremely) small. In numerous real-world scenarios, limited hardware resources or just-in-time demand often necessitates adjusting models with very small batch sizes, making existing methods less practical. In this paper, we first showcase and thoroughly analyze the negative transfer phenomenon in previous TTA methods encountering extremely small batch sizes. Subsequently, we propose a novel batch size-agnostic method called NanoAdapt to effectively mitigate the negative transfer even with batch size 1. NanoAdapt is composed of three key components: a dynamic BN calibration strategy that leverages historical information and the Taylor series to refine the statistics estimations, an entropy-weighted gradient accumulation strategy that uses the entropy of each sample&#39;s label prediction to weigh and accumulate the loss for backpropagation, and a novel proxy computation graph to capture the sample interactions. Extensive experiments are conducted to validate the superiority of NanoAdapt, showing its consistent efficacy in improving existing TTA methods. Keywords: Machine Learning: ML: Multi-task and transfer learning Computer Vision: CV: Transfer, low-shot, semi- and un- supervised learning},
  archive   = {C_IJCAI},
  author    = {Shiji Zhao and Shao-Yuan Li and Sheng-Jun Huang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/616},
  month     = {8},
  pages     = {5572-5580},
  title     = {NanoAdapt: Mitigating negative transfer in test time adaptation with extremely small batch sizes},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ENOTO: Improving offline-to-online reinforcement learning
with q-ensembles. <em>IJCAI</em>, 5563–5571. (<a
href="https://doi.org/10.24963/ijcai.2024/615">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Offline reinforcement learning (RL) is a learning paradigm where an agent learns from a fixed dataset of experience. However, learning solely from a static dataset can limit the performance due to the lack of exploration. To overcome it, offline-to-online RL combines offline pre-training with online fine-tuning, which enables the agent to further refine its policy by interacting with the environment in real-time. Despite its benefits, existing offline-to-online RL methods suffer from performance degradation and slow improvement during the online phase. To tackle these challenges, we propose a novel framework called ENsemble-based Offline-To-Online (ENOTO) RL. By increasing the number of Q-networks, we seamlessly bridge offline pre-training and online fine-tuning without degrading performance. Moreover, to expedite online performance enhancement, we appropriately loosen the pessimism of Q-value estimation and incorporate ensemble-based exploration mechanisms into our framework. Experimental results demonstrate that ENOTO can substantially improve the training stability, learning efficiency, and final performance of existing offline RL methods during online fine-tuning on a range of locomotion and navigation tasks, significantly outperforming existing offline-to-online RL methods. Keywords: Machine Learning: ML: Reinforcement learning Machine Learning: ML: Ensemble methods Machine Learning: ML: Offline reinforcement learning Machine Learning: ML: Online learning},
  archive   = {C_IJCAI},
  author    = {Kai Zhao and Jianye Hao and Yi Ma and Jinyi Liu and Yan Zheng and Zhaopeng Meng},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/615},
  month     = {8},
  pages     = {5563-5571},
  title     = {ENOTO: Improving offline-to-online reinforcement learning with Q-ensembles},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Active deep multi-view clustering. <em>IJCAI</em>,
5554–5562. (<a href="https://doi.org/10.24963/ijcai.2024/614">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep multi-view clustering has been widely studied. However, since it is an unsupervised task, where no labels are used to guide the training, it is still unreliable especially when handling complicated data. Although deep semi-supervised multi-view clustering can alleviate this problem by using some supervised information, the supervised information is often pregiven or randomly selected. Unfortunately, as we know, the clustering performance highly depends on the quality of the supervised information and most of the semi-supervised methods ignore the supervised information selection. To tackle this problem, in this paper, we propose a novel active deep multi-view clustering method, which can actively select important data for querying human annotations. In this method, we carefully design a fusion module, an active selection module, a supervised module, and an unsupervised module, and integrate them into a unified framework seamlessly. In this framework, we can obtain a more reliable clustering result with as few annotations as possible. The extensive experiments on benchmark data sets show that our method can outperform state-of-the-art unsupervised and semi-supervised methods, demonstrating the effectiveness and superiority of the proposed method. The code is available at https://github.com/wodedazhuozi/ADMC . Keywords: Machine Learning: ML: Multi-view learning Machine Learning: ML: Active learning Machine Learning: ML: Multi-modal learning},
  archive   = {C_IJCAI},
  author    = {Helin Zhao and Wei Chen and Peng Zhou},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/614},
  month     = {8},
  pages     = {5554-5562},
  title     = {Active deep multi-view clustering},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reconfigurability-aware selection for contrastive active
domain adaptation. <em>IJCAI</em>, 5545–5553. (<a
href="https://doi.org/10.24963/ijcai.2024/613">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Active domain adaptation (ADA) aims to label a small portion of target samples to drastically improve the adaptation performance. The existing ADA methods mostly rely on the output of domain discriminator or the original prediction probability to design sample selection strategies and do not fully explore the semantic information of source and target domain features, which may lead to selecting the valueless target samples. Moreover, most of them require complex network structures (such as introducing additional domain discriminator, multiple classifiers, or loss predictors) and multiple query functions. In this work, we propose a concise but effective ADA method called Reconfigurability-Aware Selection for Contrastive active domain adaptation (RASC). With the reconfigurability-aware sample selection strategy, RASC can select the most valuable target samples for annotation in the presence of domain shift. To better utilize the selected target samples, we further design a contrastive learning-based gradual active domain adaptation framework. In addition, we propose a variant of RASC called RASC-Ob, which uses a simpler sample annotation method and supplements the learning of misclassified samples. Extensive experimental results on multiple benchmarks demonstrate the superiority of RASC. Keywords: Machine Learning: ML: Multi-task and transfer learning Machine Learning: ML: Semi-supervised learning},
  archive   = {C_IJCAI},
  author    = {Zeyu Zhang and Chun Shen and Shuai Lü and Shaojie Zhang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/613},
  month     = {8},
  pages     = {5545-5553},
  title     = {Reconfigurability-aware selection for contrastive active domain adaptation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pre-training general user representation with multi-type APP
behaviors. <em>IJCAI</em>, 5535–5544. (<a
href="https://doi.org/10.24963/ijcai.2024/612">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In numerous user-centric services on mobile applications (apps), accurately mining user interests and generating effective user representations are paramount. Traditional approaches, which often involve training task-specific user representations, are becoming increasingly impractical due to their high computational costs and limited adaptability. This paper introduces a novel solution to this challenge: the Multi-type App-usage Fusion Network (MAFN). MAFN innovatively pre-trains universal user representations, leveraging multi-type app behaviors to overcome key limitations in existing methods. We address two primary challenges: 1) the varying frequency of user behaviors (ranging from low-frequency actions like (un)installations to high-frequency yet insightful app launches); and 2) the integration of multi-type behaviors to form a cohesive representation. Our approach involves the creation of novel pre-training tasks that harness self-supervised signals from diverse app behaviors, capturing both long-term and short-term user interests. MAFN&#39;s unique fusion approach effectively amalgamates these interests into a unified vector space, facilitating the development of a versatile, general-purpose user representation. With a practical workflow, extensive experiments with three typical downstream tasks on real-world datasets verify the effectiveness of our approach. Keywords: Machine Learning: ML: Representation learning Data Mining: DM: Mining heterogenous data Machine Learning: ML: Self-supervised Learning Machine Learning: ML: Applications},
  archive   = {C_IJCAI},
  author    = {Yuren Zhang and Min Hou and Kai Zhang and Yuqing Yuan and Chao Song and Zhihao Ye and Enhong Chen and Yang Yu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/612},
  month     = {8},
  pages     = {5535-5544},
  title     = {Pre-training general user representation with multi-type APP behaviors},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Personalized federated learning for cross-city traffic
prediction. <em>IJCAI</em>, 5526–5534. (<a
href="https://doi.org/10.24963/ijcai.2024/611">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Traffic prediction plays an important role in urban computing. However, many cities face data scarcity due to low levels of urban development. Although many approaches transfer knowledge from data-rich cities to data-scarce cities, the centralized training paradigm cannot uphold data privacy. For the sake of inter-city data privacy, Federated Learning has been used, which follows a decentralized training paradigm to enhance traffic knowledge of data-scarce cities. However, spatio-temporal data heterogeneity causes client drift, leading to unsatisfactory traffic prediction performance. In this work, we propose a novel personalized Federated learning method for Cross-city Traffic Prediction (pFedCTP). It learns traffic knowledge from multiple data-rich source cities and transfers the knowledge to a data-scarce target city while preserving inter-city data privacy. In the core of pFedCTP lies a Spatio-Temporal Neural Network (ST-Net) for clients to learn traffic representation. We decouple the ST-Net to learn space-independent traffic patterns to overcome cross-city spatial heterogeneity. Besides, pFedCTP adaptively interpolates the layer-wise global and local parameters to deal with temporal heterogeneity across cities. Extensive experiments on four real-world traffic datasets demonstrate significant advantages of pFedCTP over representative state-of-the-art methods. Keywords: Machine Learning: ML: Federated learning Data Mining: DM: Mining spatial and/or temporal data Multidisciplinary Topics and Applications: MTA: Transportation},
  archive   = {C_IJCAI},
  author    = {Yu Zhang and Hua Lu and Ning Liu and Yonghui Xu and Qingzhong Li and Lizhen Cui},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/611},
  month     = {8},
  pages     = {5526-5534},
  title     = {Personalized federated learning for cross-city traffic prediction},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Visual attention prompted prediction and learning.
<em>IJCAI</em>, 5517–5525. (<a
href="https://doi.org/10.24963/ijcai.2024/610">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Visual explanation (attention)-guided learning uses not only labels but also explanations to guide the model reasoning process. While visual attention-guided learning has shown promising results, it requires a large number of explanation annotations that are time-consuming to prepare. However, in many real-world situations, it is usually desired to prompt the model with visual attention without model retraining. For example, when doing AI-assisted cancer classification on a medical image, users (e.g., clinicians) can provide the AI model with visual attention prompts on which areas are indispensable and which are precluded. Despite its promising objectives, achieving visual attention-prompted prediction presents several major challenges: 1) How can the visual prompt be effectively integrated into the model&#39;s reasoning process? 2) How should the model handle samples that lack visual prompts? 3) What is the impact on the model&#39;s performance when a visual prompt is imperfect? This paper introduces a novel framework for visual attention prompted prediction and learning, utilizing visual prompts to steer the model&#39;s reasoning process. To improve performance in non-prompted situations and align it with prompted scenarios, we propose a co-training approach for both non-prompted and prompted models, ensuring they share similar parameters and activation. Additionally, for instances where the visual prompt does not encompass the entire input image, we have developed innovative attention prompt refinement methods. These methods interpolate the incomplete prompts while maintaining alignment with the model&#39;s explanations. Extensive experiments on four datasets demonstrate the effectiveness of our proposed framework in enhancing predictions for samples both with and without prompt. Keywords: Machine Learning: ML: Knowledge-aided learning Humans and AI: HAI: Human-AI collaboration Machine Learning: ML: Explainable/Interpretable machine learning Machine Learning: ML: Multi-task and transfer learning},
  archive   = {C_IJCAI},
  author    = {Yifei Zhang and Bo Pan and Siyi Gu and Guangji Bai and Meikang Qiu and Xiaofeng Yang and Liang Zhao},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/610},
  month     = {8},
  pages     = {5517-5525},
  title     = {Visual attention prompted prediction and learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fine-grained analysis of stability and generalization for
stochastic bilevel optimization. <em>IJCAI</em>, 5508–5516. (<a
href="https://doi.org/10.24963/ijcai.2024/609">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Stochastic bilevel optimization (SBO) has been integrated into many machine learning paradigms recently including hyperparameter optimization, meta learning, reinforcement learning, etc. Along with the wide range of applications, there have been abundant studies on concerning the computing behaviors of SBO. However, the generalization guarantees of SBO methods are far less understood from the lens of statistical learning theory. In this paper, we provide a systematical generalization analysis of the first-order gradient-based bilevel optimization methods. Firstly, we establish the quantitative connections between the on-average argument stability and the generalization gap of SBO methods. Then, we derive the upper bounds of on-average argument stability for single timescale stochastic gradient descent (SGD) and two timescale SGD, where three settings (nonconvex-nonconvex (NC-NC), convex-convex (C-C) and strongly-convex-strongly-convex (SC-SC)) are considered respectively. Experimental analysis validates our theoretical findings. Compared with the previous algorithmic stability analysis, our results do not require the re-initialization of the inner-level parameters before each iteration and are suit for more general objective functions. Keywords: Machine Learning: ML: Learning theory},
  archive   = {C_IJCAI},
  author    = {Xuelin Zhang and Hong Chen and Bin Gu and Tieliang Gong and Feng Zheng},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/609},
  month     = {8},
  pages     = {5508-5516},
  title     = {Fine-grained analysis of stability and generalization for stochastic bilevel optimization},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Skip-timeformer: Skip-time interaction transformer for long
sequence time-series forecasting. <em>IJCAI</em>, 5499–5507. (<a
href="https://doi.org/10.24963/ijcai.2024/608">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent studies have raised questions about the suitability of the Transformer architecture for long sequence time-series forecasting. These forecasting models leverage Transformers to capture dependencies between multiple time steps in a time series, with embedding tokens composed of data from individual time steps. However, challenges arise when applying Transformers to predict long sequences with strong periodicity, leading to performance degradation and increased computational burden. Furthermore, embedding tokens formed one time step at a time may struggle to reveal meaningful information in long sequences, failing to capture correlations between different time steps. In this study, we propose Skip-Timeformer, a Transformer-based model that utilizes a skip-time interaction for long sequence time-series forecasting. Specifically, we decompose the time series into multiple subsequences based on different time intervals, embedding various time steps into variable tokens across multiple sequences. The skip-time interaction mechanism utilizes these variable tokens to capture dependencies in the skip-time dimension. Additionally, skip-time interaction is employed to learn dependencies between sequences missed by multiple skip time steps. The Skip-Timeformer model demonstrates state-of-the-art performance on various real-world datasets, further enhancing the long sequence forecasting capabilities of the Transformer variations and better adapting to arbitrary lookback windows. Keywords: Machine Learning: ML: Time series and data streams},
  archive   = {C_IJCAI},
  author    = {Wenchang Zhang and Hua Wang and Fan Zhang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/608},
  month     = {8},
  pages     = {5499-5507},
  title     = {Skip-timeformer: Skip-time interaction transformer for long sequence time-series forecasting},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploring cross-domain few-shot classification via
frequency-aware prompting. <em>IJCAI</em>, 5490–5498. (<a
href="https://doi.org/10.24963/ijcai.2024/607">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Cross-Domain Few-Shot Learning has witnessed great stride with the development of meta-learning. However, most existing methods pay more attention to learning domain-adaptive inductive bias (meta-knowledge) through feature-wise manipulation or task diversity improvement while neglecting the phenomenon that deep networks tend to rely more on high-frequency cues to make the classification decision, which thus degenerates the robustness of learned inductive bias since high-frequency information is vulnerable and easy to be disturbed by noisy information. Hence in this paper, we make one of the first attempts to propose a Frequency-Aware Prompting method with mutual attention for Cross-Domain Few-Shot classification, which can let networks simulate the human visual perception of selecting different frequency cues when facing new recognition tasks. Specifically, a frequency-aware prompting mechanism is first proposed, in which high-frequency components of the decomposed source image are switched either with normal distribution sampling or zeroing to get frequency-aware augment samples. Then, a mutual attention module is designed to learn generalizable inductive bias under CD-FSL settings. More importantly, the proposed method is a plug-and-play module that can be directly applied to most off-the-shelf CD-FLS methods. Experimental results on CD-FSL benchmarks demonstrate the effectiveness of our proposed method as well as robustly improve the performance of existing CD-FLS methods. Resources at https://github.com/tinkez/FAP_CDFSC. Keywords: Machine Learning: ML: Classification Machine Learning: ML: Few-shot learning Machine Learning: ML: Meta-learning Machine Learning: ML: Multi-task and transfer learning},
  archive   = {C_IJCAI},
  author    = {Tiange Zhang and Qing Cai and Feng Gao and Lin Qi and Junyu Dong},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/607},
  month     = {8},
  pages     = {5490-5498},
  title     = {Exploring cross-domain few-shot classification via frequency-aware prompting},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). CONC: Complex-noise-resistant open-set node classification
with adaptive noise detection. <em>IJCAI</em>, 5481–5489. (<a
href="https://doi.org/10.24963/ijcai.2024/606">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As a popular task in graph learning, node classification seeks to assign labels to nodes, taking into account both their features and connections. However, an important challenge for its application in real-world scenarios is the presence of newly-emerged out-of-distribution samples and noisy samples, which affect the quality and robustness of learned classifiers. Out-of-distribution (OOD) samples are often found in both the training and testing phases. Such samples don’t belong to any known categories. These OOD samples are considered as outliers (OOD noise) when they appear during training, and are recognized as open-set samples during the testing. Meanwhile, in-distribution (IND) noisy data, i.e., known class samples with wrong labels, are also prevalent and inevitably degrade a model’s performance. The challenge of open-set learning with complex IND and OOD noise remains largely unexplored, particularly when dealing with non-IID graph data. To address these challenges, this paper introduces a novel complex-noise-resistant open-set node classification approach, designed for open-set graph data containing both IND and OOD noisy nodes. Specifically, a trustworthiness learner is adopted to learn the trustworthiness rates of the feature and label for each node while a decoder and an open-set classifier are trained to reconstruct the structure of a node and to predict its category simultaneously with the guidance of node trustworthiness. The experimental results demonstrate the superiority of our method. Keywords: Machine Learning: ML: Classification Data Mining: DM: Anomaly/outlier detection Data Mining: DM: Applications},
  archive   = {C_IJCAI},
  author    = {Qin Zhang and Jiexin Lu and Xiaowei Li and Huisi Wu and Shirui Pan and Junyang Chen},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/606},
  month     = {8},
  pages     = {5481-5489},
  title     = {CONC: Complex-noise-resistant open-set node classification with adaptive noise detection},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning from long-tailed noisy data with sample selection
and balanced loss. <em>IJCAI</em>, 5471–5480. (<a
href="https://doi.org/10.24963/ijcai.2024/605">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The success of deep learning depends on large-scale and well-curated training data, while data in real-world applications are commonly long-tailed and noisy. Existing methods are usually dependent on label frequency to tackle class imbalance, while the model bias on different classes is not directly related to label frequency and the true label frequency is inaccessible under label noise. To solve this, we propose a robust method for learning from long-tailed noisy data with sample selection and balanced loss. Specifically, we separate the noisy training data into clean labeled set and unlabeled set with sample selection, and train the deep neural network in a semi-supervised manner with a balanced loss based on model bias. Extensive experiments on benchmarks demonstrate that our method outperforms existing state-of-the-art methods. Keywords: Machine Learning: ML: Classification},
  archive   = {C_IJCAI},
  author    = {Lefan Zhang and Zhang-Hao Tian and Wujun Zhou and Wei Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/605},
  month     = {8},
  pages     = {5471-5480},
  title     = {Learning from long-tailed noisy data with sample selection and balanced loss},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LSPAN: Spectrally localized augmentation for graph
consistency learning. <em>IJCAI</em>, 5462–5470. (<a
href="https://doi.org/10.24963/ijcai.2024/604">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph-based consistency principle has been successfully applied to many semi-supervised problems in machine learning. Its performance largely depends on the quality of augmented graphs, which has been recently proven that revealing graph properties and maintaining the invariance of graphs are crucial for good performance. However, existing topology- or feature-based augmentation methods are spectrally non-localized -- important spectrums are disturbed throughout the entire frequency range, and their invariance may not be well preserved. Efforts on this issue remain to be limited. This paper proposes a simple yet effective model called Localized SPectral AugmentatioN (LSPAN), which perturbs a concentrated part of graph spectrum with equivalent intensity using Fourier orthogonality, so as to enhance graph spectrum preservation as well as model prediction. Moreover, it also avoids the significant training time of inverse Fourier transform. Extensive empirical evaluation on real-world datasets clearly shows the performance gain of spectrally localized augmentation, as well as its good convergence and efficiency compared to existing graph methods. Keywords: Machine Learning: ML: Semi-supervised learning Machine Learning: ML: Active learning Machine Learning: ML: Classification Machine Learning: ML: Multi-task and transfer learning},
  archive   = {C_IJCAI},
  author    = {Heng-Kai Zhang and Yi-Ge Zhang and Zhi Zhou and Yu-Feng Li},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/604},
  month     = {8},
  pages     = {5462-5470},
  title     = {LSPAN: Spectrally localized augmentation for graph consistency learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Federated adaptation for foundation model-based
recommendations. <em>IJCAI</em>, 5453–5461. (<a
href="https://doi.org/10.24963/ijcai.2024/603">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With the recent success of large language models, particularly foundation models with generalization abilities, applying foundation models for recommendations becomes a new paradigm to improve existing recommendation systems. It becomes a new open challenge to enable the foundation model to capture user preference changes in a timely manner with reasonable communication and computation costs while preserving privacy. This paper proposes a novel federated adaptation mechanism to enhance the foundation model-based recommendation system in a privacy-preserving manner. Specifically, each client will learn a lightweight personalized adapter using its private data. The adapter then collaborates with pre-trained foundation models to provide recommendation service efficiently with fine-grained manners. Importantly, users&#39; private behavioral data remains secure as it is not shared with the server. This data localization-based privacy preservation is embodied via the federated learning framework. The model can ensure that shared knowledge is incorporated into all adapters while simultaneously preserving each user&#39;s personal preferences. Experimental results on four benchmark datasets demonstrate our method&#39;s superior performance. The code is available. Keywords: Machine Learning: ML: Federated learning Data Mining: DM: Privacy-preserving data mining Data Mining: DM: Recommender systems},
  archive   = {C_IJCAI},
  author    = {Chunxu Zhang and Guodong Long and Hongkuan Guo and Xiao Fang and Yang Song and Zhaojie Liu and Guorui Zhou and Zijian Zhang and Yang Liu and Bo Yang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/603},
  month     = {8},
  pages     = {5453-5461},
  title     = {Federated adaptation for foundation model-based recommendations},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Efficient multi-view unsupervised feature selection with
adaptive structure learning and inference. <em>IJCAI</em>, 5443–5452.
(<a href="https://doi.org/10.24963/ijcai.2024/602">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As data with diverse representations become high-dimensional, multi-view unsupervised feature selection has been an important learning paradigm. Generally, existing methods encounter the following challenges: (i) traditional solutions either concatenate different views or introduce extra parameters to weight them, affecting the performance and applicability; (ii) emphasis is typically placed on graph construction, yet disregarding the clustering information of data; (iii) exploring the similarity structure of all samples from the original features is suboptimal and extremely time-consuming. To solve this dilemma, we propose an efficient multi-view unsupervised feature selection (EMUFS) to construct bipartite graphs between samples and anchors. Specifically, a parameter-free manner is devised to collaboratively fuse the membership matrices and graphs to learn the compatible structure information across all views, naturally balancing different views. Moreover, EMUFS leverages the similarity relations of data in the feature subspace induced by l2,0-norm to dynamically update the graph. Accordingly, the cluster information of anchors can be accurately propagated to samples via the graph structure and further guide feature selection, enhancing the quality of selected features and the computational costs in solution processes. A convergent optimization is developed to solve the formulated problem, and experiments demonstrate the effectiveness and efficiency of EMUFS. Keywords: Machine Learning: ML: Multi-view learning Machine Learning: ML: Clustering Machine Learning: ML: Feature extraction, selection and dimensionality reduction Machine Learning: ML: Unsupervised learning},
  archive   = {C_IJCAI},
  author    = {Chenglong Zhang and Yang Fang and Xinyan Liang and Han Zhang and Peng Zhou and Xingyu Wu and Jie Yang and Bingbing Jiang and Weiguo Sheng},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/602},
  month     = {8},
  pages     = {5443-5452},
  title     = {Efficient multi-view unsupervised feature selection with adaptive structure learning and inference},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Continual multi-view clustering with consistent anchor
guidance. <em>IJCAI</em>, 5434–5442. (<a
href="https://doi.org/10.24963/ijcai.2024/601">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-view clustering (MVC) has recently attracted much attention. Most existing approaches are designed for fixed multi-view data, and cannot deal with the common streaming data in real world. In this paper, we address this problem by proposing a consistent Anchor guided Continual MVC (ACMVC) method in a two-stage way. In initial learning stage, a low-rank anchor graph based model is constructed. In continual learning stage, to leverage the historical knowledge, the multi-level anchor information is reused to refine the model via adding consistency regularization. It not only provides prior knowledge to enhance the exploration on current data, but also captures the similarity relationship between previous and current data, enabling a comprehensive exploitation on streaming data. The proposed model can be optimized efficiently with linear time and space complexity. Experiments demonstrate the effectiveness and efficiency of our method compared with some state-of-the-art approaches. Keywords: Machine Learning: ML: Multi-view learning Machine Learning: ML: Clustering Machine Learning: ML: Unsupervised learning Data Mining: DM: Mining data streams},
  archive   = {C_IJCAI},
  author    = {Chao Zhang and Deng Xu and Xiuyi Jia and Chunlin Chen and Huaxiong Li},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/601},
  month     = {8},
  pages     = {5434-5442},
  title     = {Continual multi-view clustering with consistent anchor guidance},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Task-agnostic self-distillation for few-shot action
recognition. <em>IJCAI</em>, 5425–5433. (<a
href="https://doi.org/10.24963/ijcai.2024/600">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Task-oriented matching is one of the core aspects of few-shot Action Recognition. Most previous works leverage the metric features within the support and query sets of individual tasks, without considering the metric information across different matching tasks. This oversight represents a significant limitation in this task. Specifically, the task-specific metric feature can decrease the generalization ability and ignore the general matching feature applicable across different tasks. To address these challenges, we propose a novel meta-distillation framework for few-shot action recognition that learns the task-agnostic metric features and generalizes them to different tasks. First, to extract the task-agnostic metric information, we design a task-based self-distillation framework to learn the metric features from the training process progressively. Additionally, to enable the model with fine-grained matching capabilities, we design a multi-dimensional distillation module that extracts more detailed relations from the temporal, spatial, and channel dimensions within video pairs and improves the representative performance of metric features for each individual task. After that, the few-shot predictions can be obtained by feeding the embedded task-agnostic metric features to a common feature matcher. Extensive experimental results on standard datasets demonstrate our method’s superior performance compared to existing state-of-the-art methods. Keywords: Machine Learning: ML: Few-shot learning Computer Vision: CV: Action and behavior recognition Machine Learning: ML: Meta-learning},
  archive   = {C_IJCAI},
  author    = {Bin Zhang and Yuanjie Dang and Peng Chen and Ronghua Liang and Nan Gao and Ruohong Huan and Xiaofei He},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/600},
  month     = {8},
  pages     = {5425-5433},
  title     = {Task-agnostic self-distillation for few-shot action recognition},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FedES: Federated early-stopping for hindering memorizing
heterogeneous label noise. <em>IJCAI</em>, 5416–5424. (<a
href="https://doi.org/10.24963/ijcai.2024/599">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Federated learning (FL) facilitates collaborative model training across distributed clients while maintaining privacy. Federated noisy label learning (FNLL) is more of a challenge for data inaccessibility and noise heterogeneity. Existing works primarily assume clients are either noisy or clean, which may lack the flexibility to adapt to diverse label noise across different clients, especially when entirely clean or noisy clients are not the majority. To address this, we propose a general noise-robust federated learning framework called Federated Early-Stopping (FedES), which adaptively updates critical parameters of each local model based on their noise rates, thereby avoiding overfitting to noisy labels. FedES is composed of two stages: federated noise estimation and parameter-adaptive local updating \&amp; global aggregation. We introduce a signed distance based on local and global gradients during a federated round to estimate clients&#39; noise rates without requiring additional information. Based on this measure, we employ various degrees of early-stopping during local updating on the clients, and further, a noise-aware global aggregation is employed to achieve noise-robust learning. Extensive experiments conducted on varying synthetic and real-world label noise demonstrate the superior performance of FedES over the state-of-the-art methods. Keywords: Machine Learning: ML: Federated learning Machine Learning: ML: Applications Machine Learning: ML: Weakly supervised learning},
  archive   = {C_IJCAI},
  author    = {Bixiao Zeng and Xiaodong Yang and Yiqiang Chen and Zhiqi Shen and Hanchao Yu and Yingwei Zhang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/599},
  month     = {8},
  pages     = {5416-5424},
  title     = {FedES: Federated early-stopping for hindering memorizing heterogeneous label noise},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). BoostDream: Efficient refining for high-quality text-to-3D
generation from multi-view diffusion. <em>IJCAI</em>, 5407–5415. (<a
href="https://doi.org/10.24963/ijcai.2024/598">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Witnessing the evolution of text-to-image diffusion models, significant strides have been made in text-to-3D generation. Currently, two primary paradigms dominate the field of text-to-3D: the feed-forward generation solutions, capable of swiftly producing 3D assets but often yielding coarse results, and the Score Distillation Sampling (SDS) based solutions, known for generating high-fidelity 3D assets albeit at a slower pace. The synergistic integration of these methods holds substantial promise for advancing 3D generation techniques. In this paper, we present BoostDream, a highly efficient plug-and-play 3D refining method designed to transform coarse 3D assets into high-quality. The BoostDream framework comprises three distinct processes: (1) We introduce 3D model distillation that fits differentiable representations from the 3D assets obtained through feed-forward generation. (2) A novel multi-view SDS loss is designed, which utilizes a multi-view aware 2D diffusion model to refine the 3D assets. (3) We propose to use prompt and multi-view consistent normal maps as guidance in refinement. Our extensive experiment is conducted on different differentiable 3D representations, revealing that BoostDream excels in generating high-quality 3D assets rapidly, overcoming the Janus problem compared to conventional SDS-based methods. This breakthrough signifies a substantial advancement in both the efficiency and quality of 3D generation processes. Keywords: Machine Learning: ML: Generative models Computer Vision: CV: 3D computer vision Multidisciplinary Topics and Applications: MTA: Arts and creativity},
  archive   = {C_IJCAI},
  author    = {Yonghao Yu and Shunan Zhu and Huai Qin and Haorui Li},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/598},
  month     = {8},
  pages     = {5407-5415},
  title     = {BoostDream: Efficient refining for high-quality text-to-3D generation from multi-view diffusion},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bandits with concave aggregated reward. <em>IJCAI</em>,
5398–5406. (<a href="https://doi.org/10.24963/ijcai.2024/597">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-armed bandit is a simple but powerful algorithmic framework, and many effective algorithms have been proposed for various online models. In numerous applications, the decision-maker faces diminishing marginal utility. With non-linear aggregations, those algorithms often have poor regret bounds. Motivated by this, we study a bandit problem with diminishing marginal utility, which we termed the bandits with concave aggregated reward(BCAR). To tackle this problem, we propose two algorithms SW-BCAR and SWUCB-BCAR. Through theoretical analysis, we establish the effectiveness of these algorithms in addressing the BCAR issue. Extensive simulations demonstrate that our algorithms achieve better results than the most advanced bandit algorithms. Keywords: Machine Learning: ML: Multi-armed bandits},
  archive   = {C_IJCAI},
  author    = {Yingqi Yu and Sijia Zhang and Shaoang Li and Lan Zhang and Wei Xie and Xiang-Yang Li},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/597},
  month     = {8},
  pages     = {5398-5406},
  title     = {Bandits with concave aggregated reward},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). EC-SNN: Splitting deep spiking neural networks for edge
devices. <em>IJCAI</em>, 5389–5397. (<a
href="https://doi.org/10.24963/ijcai.2024/596">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep Spiking Neural Networks (SNNs), as an advanced form of SNNs characterized by their multi-layered structure, have recently achieved significant breakthroughs in performance across various domains. The biological plausibility and energy efficiency of SNNs naturally align with the requisites of edge computing (EC) scenarios, thereby prompting increased interest among researchers to explore the migration of these deep SNN models onto edge devices such as sensors and smartphones. However, the progress of migration work has been notably challenging due to the influence of the substantial increase in model parameters and the demanding computational requirements in practical applications. In this work, we propose a deep SNN splitting framework named EC-SNN to run the intricate SNN models on edge devices. We first partition the full SNN models into smaller sub-models to allocate their model parameters on multiple edge devices. Then, we provide a channel-wise pruning method to reduce the size of each sub-model, thereby further reducing the computational load. We design extensive experiments on six datasets (i.e., four non-neuromorphic and two neuromorphic datasets) to substantiate that our approach can significantly diminish the inference execution latency on edge devices and reduce the overall energy consumption per deployed device with an average reduction of 60.7% and 27.7% respectively while keeping the effectiveness of the accuracy. Keywords: Machine Learning: ML: Applications Humans and AI: HAI: Applications Machine Learning: ML: Deep learning architectures Machine Learning: ML: Feature extraction, selection and dimensionality reduction},
  archive   = {C_IJCAI},
  author    = {Di Yu and Xin Du and Linshan Jiang and Wentao Tong and Shuiguang Deng},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/596},
  month     = {8},
  pages     = {5389-5397},
  title     = {EC-SNN: Splitting deep spiking neural networks for edge devices},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pointsoup: High-performance and extremely
low-decoding-latency learned geometry codec for large-scale point cloud
scenes. <em>IJCAI</em>, 5380–5388. (<a
href="https://doi.org/10.24963/ijcai.2024/595">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Despite considerable progress being achieved in point cloud geometry compression, there still remains a challenge in effectively compressing large-scale scenes with sparse surfaces. Another key challenge lies in reducing decoding latency, a crucial requirement in real-world application. In this paper, we propose Pointsoup, an efficient learning-based geometry codec that attains high-performance and extremely low-decoding-latency simultaneously. Inspired by conventional Trisoup codec, a point model-based strategy is devised to characterize local surfaces. Specifically, skin features are embedded from local windows via an attention-based encoder, and dilated windows are introduced as cross-scale priors to infer the distribution of quantized features in parallel. During decoding, features undergo fast refinement, followed by a folding-based point generator that reconstructs point coordinates with fairly fast speed. Experiments show that Pointsoup achieves state-of-the-art performance on multiple benchmarks with significantly lower decoding complexity, i.e., up to 90~160× faster than the G-PCCv23 Trisoup decoder on a comparatively low-end platform (e.g., one RTX 2080Ti). Furthermore, it offers variable-rate control with a single neural model (2.9MB), which is attractive for industrial practitioners. Keywords: Machine Learning: ML: Geometric learning Computer Vision: CV: 3D computer vision Multidisciplinary Topics and Applications: MTA: Real-time systems Robotics: ROB: Robotics and vision},
  archive   = {C_IJCAI},
  author    = {Kang You and Kai Liu and Li Yu and Pan Gao and Dandan Ding},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/595},
  month     = {8},
  pages     = {5380-5388},
  title     = {Pointsoup: High-performance and extremely low-decoding-latency learned geometry codec for large-scale point cloud scenes},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FedSSA: Semantic similarity-based aggregation for efficient
model-heterogeneous personalized federated learning. <em>IJCAI</em>,
5371–5379. (<a href="https://doi.org/10.24963/ijcai.2024/594">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Federated learning (FL) is a privacy-preserving collaboratively machine learning paradigm. Traditional FL requires all data owners (a.k.a. FL clients) to train the same local model. This design is not well-suited for scenarios involving data and/or system heterogeneity. Model-Heterogeneous Personalized FL (MHPFL) has emerged to address this challenge. Existing MHPFL approaches often rely on a public dataset with the same nature as the learning task, or incur high computation and communication costs. To address these limitations, we propose the Federated Semantic Similarity Aggregation (FedSSA) approach for supervised classification tasks, which splits each client&#39;s model into a heterogeneous (structure-different) feature extractor and a homogeneous (structure-same) classification header. It performs local-to-global knowledge transfer via semantic similarity-based header parameter aggregation. In addition, global-to-local knowledge transfer is achieved via an adaptive parameter stabilization strategy which fuses the seen-class parameters of historical local headers with that of the latest global header for each client. FedSSA does not rely on public datasets, while only requiring partial header parameter transmission to save costs. Theoretical analysis proves the convergence of FedSSA. Extensive experiments present that FedSSA achieves up to 3.62% higher accuracy, 15.54 times higher communication efficiency, and 15.52 times higher computational efficiency compared to 7 state-of-the-art MHPFL baselines. Keywords: Machine Learning: ML: Federated learning},
  archive   = {C_IJCAI},
  author    = {Liping Yi and Han Yu and Zhuan Shi and Gang Wang and Xiaoguang Liu and Lizhen Cui and Xiaoxiao Li},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/594},
  month     = {8},
  pages     = {5371-5379},
  title     = {FedSSA: Semantic similarity-based aggregation for efficient model-heterogeneous personalized federated learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bridging the gap: Learning pace synchronization for
open-world semi-supervised learning. <em>IJCAI</em>, 5362–5370. (<a
href="https://doi.org/10.24963/ijcai.2024/593">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In open-world semi-supervised learning, a machine learning model is tasked with uncovering novel categories from unlabeled data while maintaining performance on seen categories from labeled data. The central challenge is the substantial learning gap between seen and novel categories, as the model learns the former faster due to accurate supervisory information. Moreover, capturing the semantics of unlabeled novel category samples is also challenging due to the missing label information. To address the above issues, we introduce 1) the adaptive synchronizing marginal loss which imposes class-specific negative margins to alleviate the model bias towards seen classes, and 2) the pseudo-label contrastive clustering which exploits pseudo-labels predicted by the model to group unlabeled data from the same category together in the output space. Extensive experiments on benchmark datasets demonstrate that previous approaches may significantly hinder novel class learning, whereas our method strikingly balances the learning pace between seen and novel classes, achieving a remarkable 3% average accuracy increase on the ImageNet dataset. Importantly, we find that fine-tuning the self-supervised pre-trained model significantly boosts the performance, which is overlooked in prior literature. Our code is available at https://github.com/yebo0216best/LPS-main. Keywords: Machine Learning: ML: Semi-supervised learning Machine Learning: ML: Weakly supervised learning},
  archive   = {C_IJCAI},
  author    = {Bo Ye and Kai Gan and Tong Wei and Min-Ling Zhang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/593},
  month     = {8},
  pages     = {5362-5370},
  title     = {Bridging the gap: Learning pace synchronization for open-world semi-supervised learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A deep probabilistic spatiotemporal framework for dynamic
graph representation learning with application to brain disorder
identification. <em>IJCAI</em>, 5353–5361. (<a
href="https://doi.org/10.24963/ijcai.2024/592">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent applications of pattern recognition techniques on brain connectome classification using functional connectivity (FC) are shifting towards acknowledging the non-Euclidean topology and dynamic aspects of brain connectivity across time. In this paper, a deep spatiotemporal variational Bayes (DSVB) framework is proposed to learn time-varying topological structures in dynamic FC networks for identifying autism spectrum disorder (ASD) in human participants. The framework incorporates a spatial-aware recurrent neural network with an attention-based message passing scheme to capture rich spatiotemporal patterns across dynamic FC networks. To overcome model overfitting on limited training datasets, an adversarial training strategy is introduced to learn graph embedding models that generalize well to unseen brain networks. Evaluation on the ABIDE resting-state functional magnetic resonance imaging dataset shows that our proposed framework substantially outperforms state-of-the-art methods in identifying patients with ASD. Dynamic FC analyses with DSVB-learned embeddings reveal apparent group differences between ASD and healthy controls in brain network connectivity patterns and switching dynamics of brain states. Keywords: Machine Learning: ML: Learning graphical models Machine Learning: ML: Probabilistic machine learning Machine Learning: ML: Adversarial machine learning Multidisciplinary Topics and Applications: MTA: Health and medicine},
  archive   = {C_IJCAI},
  author    = {Sin-Yee Yap and Junn Yong Loo and Chee-Ming Ting and Fuad Noman and Raphaël C.-W. Phan and Adeel Razi and David L. Dowe},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/592},
  month     = {8},
  pages     = {5353-5361},
  title     = {A deep probabilistic spatiotemporal framework for dynamic graph representation learning with application to brain disorder identification},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Boosting efficiency in task-agnostic exploration through
causal knowledge. <em>IJCAI</em>, 5344–5352. (<a
href="https://doi.org/10.24963/ijcai.2024/591">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The effectiveness of model training heavily relies on the quality of available training resources. However, budget constraints often impose limitations on data collection efforts. To tackle this challenge, we introduce causal exploration in this paper, a strategy that leverages the underlying causal knowledge for both data collection and model training. We, in particular, focus on enhancing the sample efficiency and reliability of the world model learning within the domain of task-agnostic reinforcement learning. During the exploration phase, the agent actively selects actions expected to yield causal insights most beneficial for world model training. Concurrently, the causal knowledge is acquired and incrementally refined with the ongoing collection of data. We demonstrate that causal exploration aids in learning accurate world models using fewer data and provide theoretical guarantees for its convergence. Empirical experiments, on both synthetic data and real-world applications, further validate the benefits of causal exploration. The source code is available at https://github.com/CMACH508/CausalExploration. Keywords: Machine Learning: ML: Reinforcement learning Machine Learning: ML: Active learning Machine Learning: ML: Causality Uncertainty in AI: UAI: Causality, structural causal models and causal inference},
  archive   = {C_IJCAI},
  author    = {Yupei Yang and Biwei Huang and Shikui Tu and Lei Xu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/591},
  month     = {8},
  pages     = {5344-5352},
  title     = {Boosting efficiency in task-agnostic exploration through causal knowledge},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). VCformer: Variable correlation transformer with inherent
lagged correlation for multivariate time series forecasting.
<em>IJCAI</em>, 5335–5343. (<a
href="https://doi.org/10.24963/ijcai.2024/590">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multivariate time series (MTS) forecasting has been extensively applied across diverse domains, such as weather prediction and energy consumption. However, current studies still rely on the vanilla point-wise self-attention mechanism to capture cross-variable dependencies, which is inadequate in extracting the intricate cross-correlation implied between variables. To fill this gap, we propose Variable Correlation Transformer (VCformer), which utilizes Variable Correlation Attention (VCA) module to mine the correlations among variables. Specifically, based on the stochastic process theory, VCA calculates and integrates the cross-correlation scores corresponding to different lags between queries and keys, thereby enhancing its ability to uncover multivariate relationships. Additionally, inspired by Koopman dynamics theory, we also develop Koopman Temporal Detector (KTD) to better address non-stationarity in time series. The two key components enable VCformer to extract both multivariate correlations and temporal dependencies. Our extensive experiments on eight real-world datasets demonstrate the effectiveness of VCformer, achieving top-tier performance compared to other state-of-the-art baseline models. Code is available at this repository: https://github.com/CSyyn/VCformer. Keywords: Machine Learning: ML: Time series and data streams Machine Learning: ML: Attention models},
  archive   = {C_IJCAI},
  author    = {Yingnan Yang and Qingling Zhu and Jianyong Chen},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/590},
  month     = {8},
  pages     = {5335-5343},
  title     = {VCformer: Variable correlation transformer with inherent lagged correlation for multivariate time series forecasting},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Navigating continual test-time adaptation with symbiosis
knowledge. <em>IJCAI</em>, 5326–5334. (<a
href="https://doi.org/10.24963/ijcai.2024/589">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Continual test-time domain adaptation seeks to adapt the source pre-trained model to a continually changing target domain without incurring additional data acquisition or labeling costs. Unfortunately, existing mainstream methods may result in a detrimental cycle. This is attributed to noisy pseudo-labels caused by the domain shift, which immediately negatively impacts the model&#39;s knowledge. The long-term accumulation of these negative effects exacerbates the model&#39;s difficulty in generalizing to future domain shifts and contributes to catastrophic forgetting. To address these challenges, this paper introduces a Dual-stream Network that independently optimizes different parameters in each stream to capture symbiotic knowledge from continual domains, thereby ensuring generalization while enhancing instantaneous discrimination. Furthermore, to prevent catastrophic forgetting, a weighted soft parameter alignment method is designed to leverage knowledge from the source model. Finally, efforts are made to calibrate and explore reliable supervision signals to mitigate instantaneous negative optimization. These include label calibration with prior knowledge, label selection using self-adaptive confidence thresholds, and a soft-weighted contrastive module for capturing potential semantics. Extensive experimental results demonstrate that our method achieves state-of-the-art performance on several benchmark datasets. Keywords: Machine Learning: ML: Unsupervised learning Computer Vision: CV: Transfer, low-shot, semi- and un- supervised learning},
  archive   = {C_IJCAI},
  author    = {Xu Yang and Moqi Li and Jie Yin and Kun Wei and Cheng Deng},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/589},
  month     = {8},
  pages     = {5326-5334},
  title     = {Navigating continual test-time adaptation with symbiosis knowledge},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Approximate algorithms for k-sparse wasserstein barycenter
with outliers. <em>IJCAI</em>, 5316–5325. (<a
href="https://doi.org/10.24963/ijcai.2024/588">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Wasserstein Barycenter (WB) is one of the most fundamental optimization problems in optimal transportation. Given a set of distributions, the goal of WB is to find a new distribution that minimizes the average Wasserstein distance to them. The problem becomes even harder if we restrict the solution to be “k-sparse”. In this paper, we study the k-sparse WB problem in the presence of outliers, which is a more practical setting since real-world data often contains noise. Existing WB algorithms cannot be directly extended to handle the case with outliers, and thus it is urgently needed to develop some novel ideas. First, we investigate the relation between k-sparse WB with outliers and the clustering (with outliers) problems. In particular, we propose a clustering based LP method that yields constant approximation factor for the k-sparse WB with outliers problem. Further, we utilize the coreset technique to achieve the (1+ε)-approximation factor for any ε&gt;0, if the dimensionality is not high. Finally, we conduct the experiments for our proposed algorithms and illustrate their efficiencies in practice. Keywords: Machine Learning: ML: Optimization Data Mining: DM: Anomaly/outlier detection Machine Learning: ML: Clustering},
  archive   = {C_IJCAI},
  author    = {Qingyuan Yang and Hu Ding},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/588},
  month     = {8},
  pages     = {5316-5325},
  title     = {Approximate algorithms for k-sparse wasserstein barycenter with outliers},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic against dynamic: An open-set self-learning
framework. <em>IJCAI</em>, 5307–5315. (<a
href="https://doi.org/10.24963/ijcai.2024/587">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In open set recognition, existing methods generally learn statically fixed decision boundaries to reject unknown classes. Though they have achieved promising results, such decision boundaries are evidently insufficient for universal unknown classes in dynamic and open scenarios as they can potentially appear at any position in the feature space. Moreover, these methods just simply reject unknown class samples during testing without any effective utilization for them. In fact, such samples completely can constitute the true instantiated representation of the unknown classes to further enhance the model&#39;s performance. To address these issues, this paper proposes a novel dynamic against dynamic idea, i.e., dynamic method against dynamic changing open-set world, where an open-set self-learning (OSSL) framework is correspondingly developed. OSSL starts with a good closed-set classifier trained by known classes and utilizes available test samples for model adaptation during testing, thus gaining the adaptability to changing data distributions. In particular, a novel self-matching module is designed for OSSL, which can achieve the adaptation in automatically identifying known class samples while rejecting unknown class samples which are further utilized to enhance the discriminability of the model as the instantiated representation of unknown classes. Our method establishes new performance milestones respectively in almost all standard and cross-data benchmarks. Keywords: Machine Learning: ML: Supervised Learning Computer Vision: CV: Machine learning for vision Machine Learning: ML: Classification},
  archive   = {C_IJCAI},
  author    = {Haifeng Yang and Chuanxing Geng and Pong C. Yuen and Songcan Chen},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/587},
  month     = {8},
  pages     = {5307-5315},
  title     = {Dynamic against dynamic: An open-set self-learning framework},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reinforcement learning from diverse human preferences.
<em>IJCAI</em>, 5298–5306. (<a
href="https://doi.org/10.24963/ijcai.2024/586">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The complexity of designing reward functions has been a major obstacle to the wide application of deep reinforcement learning (RL) techniques. Describing an agent&#39;s desired behaviors and properties can be difficult, even for experts. A new paradigm called reinforcement learning from human preferences (or preference-based RL) has emerged as a promising solution, in which reward functions are learned from human preference labels among behavior trajectories. However, existing methods for preference-based RL are limited by the need for accurate oracle preference labels. This paper addresses this limitation by developing a method for learning from diverse human preferences. The key idea is to stabilize reward learning through regularization and correction in a latent space. To ensure temporal consistency, a strong constraint is imposed on the reward model that forces its latent space to be close to a non-parameterized distribution. Additionally, a confidence-based reward model ensembling method is designed to generate more stable and reliable predictions. The proposed method is tested on a variety of tasks in DMcontrol and Meta-world and has shown consistent and significant improvements over existing preference-based RL algorithms when learning from diverse feedback, paving the way for real-world applications of RL methods. Keywords: Machine Learning: ML: Reinforcement learning Machine Learning: ML: Applications},
  archive   = {C_IJCAI},
  author    = {Wanqi Xue and Bo An and Shuicheng Yan and Zhongwen Xu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/586},
  month     = {8},
  pages     = {5298-5306},
  title     = {Reinforcement learning from diverse human preferences},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). FBLG: A local graph based approach for handling dual skewed
non-IID data in federated learning. <em>IJCAI</em>, 5289–5297. (<a
href="https://doi.org/10.24963/ijcai.2024/585">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In real-world situations, federated learning often needs to process non-IID (non-independent and identically distributed) data with multiple skews, causing inadequate model performance. Existing federated learning methods mainly focus on addressing the problem with a single skew of non-IID, and hence the performance of global models can be degraded when faced with dual skewed non-IID data caused by heterogeneous label distributions and sample sizes among clients. To address the problem with dual skewed non-IID data, in this paper, we propose a federated learning algorithm based on local graph, named FBLG. Specifically, to address the label distribution skew, we firstly construct a local graph based on clients&#39; local losses and Jensen-Shannon (JS) divergence, so that similar clients can be selected for aggregation to ensure a highly consistent global model. Afterwards, to address the sample size skew, we design the objective function to favor clients with more samples as models trained with more samples tend to carry more useful information. Experiments on four datasets with dual skewed non-IID data demonstrate FBLG outperforms nine baseline methods and achieves up to 9% improvement in accuracy. Simultaneously, both theoretical analysis and experiments show FBLG can converge quickly. Keywords: Machine Learning: ML: Federated learning Machine Learning: ML: Classification Machine Learning: ML: Optimization Machine Learning: ML: Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Yi Xu and Ying Li and Haoyu Luo and Xiaoliang Fan and Xiao Liu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/585},
  month     = {8},
  pages     = {5289-5297},
  title     = {FBLG: A local graph based approach for handling dual skewed non-IID data in federated learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FedFa: A fully asynchronous training paradigm for federated
learning. <em>IJCAI</em>, 5281–5288. (<a
href="https://doi.org/10.24963/ijcai.2024/584">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Federated learning has been identified as an efficient decentralized training paradigm for scaling the machine learning model training on a large number of devices while guaranteeing the data privacy of the trainers. FedAvg has become a foundational parameter update strategy for federated learning, which has been promising to eliminate the effect of the heterogeneous data across clients and guarantee convergence. However, the synchronization parameter update barriers for each communication round during the training significant time on waiting, slowing down the training procedure. Therefore, recent state-of-the-art solutions propose using semi-asynchronous approaches to mitigate the waiting time cost with guaranteed convergence. Nevertheless, emerging semi-asynchronous approaches are unable to eliminate the waiting time completely. We propose a full asynchronous training paradigm called FedFa, which can guarantee model convergence and eliminate the waiting time completely for federated learning by using a few buffered results on the server for parameter updating. Further, we provide theoretical proof of the convergence rate for our proposed FedFa. Extensive experimental results indicate our approach effectively improves the training performance of federated learning by up to 6x and 4x speedup compared to the state-of-the-art synchronous and semi-asynchronous strategies while retaining high accuracy in both IID and Non-IID scenarios. Keywords: Machine Learning: ML: Federated learning Multidisciplinary Topics and Applications: MTA: Software engineering},
  archive   = {C_IJCAI},
  author    = {Haotian Xu and Zhaorui Zhang and Sheng Di and Benben Liu and Khalid Ayed Alharthi and Jiannong Cao},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/584},
  month     = {8},
  pages     = {5281-5288},
  title     = {FedFa: A fully asynchronous training paradigm for federated learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Minimizing weighted counterfactual regret with optimistic
online mirror descent. <em>IJCAI</em>, 5272–5280. (<a
href="https://doi.org/10.24963/ijcai.2024/583">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Counterfactual regret minimization (CFR) is a family of algorithms for effectively solving imperfect-information games. It decomposes the total regret into counterfactual regrets, utilizing local regret minimization algorithms, such as Regret Matching (RM) or RM+, to minimize them. Recent research establishes a connection between Online Mirror Descent (OMD) and RM+, paving the way for an optimistic variant PRM+ and its extension PCFR+. However, PCFR+ assigns uniform weights for each iteration when determining regrets, leading to substantial regrets when facing dominated actions. This work explores minimizing weighted counterfactual regret with optimistic OMD, resulting in a novel CFR variant PDCFR+. It integrates PCFR+ and Discounted CFR (DCFR) in a principled manner, swiftly mitigating negative effects of dominated actions and consistently leveraging predictions to accelerate convergence. Theoretical analyses prove that PDCFR+ converges to a Nash equilibrium, particularly under distinct weighting schemes for regrets and average strategies. Experimental results demonstrate PDCFR+&#39;s fast convergence in common imperfect-information games. The code is available at https://github.com/rpSebastian/PDCFRPlus. Keywords: Machine Learning: ML: Game Theory Game Theory and Economic Paradigms: GTEP: Noncooperative games},
  archive   = {C_IJCAI},
  author    = {Hang Xu and Kai Li and Bingyun Liu and Haobo Fu and Qiang Fu and Junliang Xing and Jian Cheng},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/583},
  month     = {8},
  pages     = {5272-5280},
  title     = {Minimizing weighted counterfactual regret with optimistic online mirror descent},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Trusted multi-view learning with label noise.
<em>IJCAI</em>, 5263–5271. (<a
href="https://doi.org/10.24963/ijcai.2024/582">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-view learning methods often focus on improving decision accuracy while neglecting the decision uncertainty, which significantly restricts their applications in safety-critical applications. To address this issue, researchers propose trusted multi-view methods that learn the class distribution for each instance, enabling the estimation of classification probabilities and uncertainty. However, these methods heavily rely on high-quality ground-truth labels. This motivates us to delve into a new generalized trusted multi-view learning problem: how to develop a reliable multi-view learning model under the guidance of noisy labels? We propose a trusted multi-view noise refining method to solve this problem. We first construct view-opinions using evidential deep neural networks, which consist of belief mass vectors and uncertainty estimates. Subsequently, we design view-specific noise correlation matrices that transform the original opinions into noisy opinions aligned with the noisy labels. Considering label noises originating from low-quality data features and easily-confused classes, we ensure that the diagonal elements of these matrices are inversely proportional to the uncertainty, while incorporating class relations into the off-diagonal elements. Finally, we aggregate the noisy opinions and employ a generalized maximum likelihood loss on the aggregated opinion for model training, guided by the noisy labels. We empirically compare TMNR with state-of-the-art trusted multi-view learning and label noise learning baselines on 5 publicly available datasets. Experiment results show that TMNR outperforms baseline methods on accuracy, reliability and robustness. The code and appendix are released at https://github.com/YilinZhang107/TMNR. Keywords: Machine Learning: ML: Multi-view learning Machine Learning: ML: Classification Machine Learning: ML: Trustworthy machine learning Machine Learning: ML: Multi-modal learning},
  archive   = {C_IJCAI},
  author    = {Cai Xu and Yilin Zhang and Ziyu Guan and Wei Zhao},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/582},
  month     = {8},
  pages     = {5263-5271},
  title     = {Trusted multi-view learning with label noise},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploring learngene via stage-wise weight sharing for
initializing variable-sized models. <em>IJCAI</em>, 5254–5262. (<a
href="https://doi.org/10.24963/ijcai.2024/581">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In practice, we usually need to build variable-sized models adapting for diverse resource constraints in different application scenarios, where weight initialization is an important step prior to training. The Learngene framework, introduced recently, firstly learns one compact part termed as learngene from a large well-trained model, after which learngene is expanded to initialize variable-sized models. In this paper, we start from analysing the importance of guidance for the expansion of well-trained learngene layers, inspiring the design of a simple but highly effective Learngene approach termed SWS (Stage-wise Weight Sharing), where both learngene layers and their learning process critically contribute to providing knowledge and guidance for initializing models at varying scales. Specifically, to learn learngene layers, we build an auxiliary model comprising multiple stages where the layer weights in each stage are shared, after which we train it through distillation. Subsequently, we expand these learngene layers containing stage information at their corresponding stage to initialize models of variable depths. Extensive experiments on ImageNet-1K demonstrate that SWS achieves consistent better performance compared to many models trained from scratch, while reducing around 6.6× total training costs. In some cases, SWS performs better only after 1 epoch tuning. When initializing variable-sized models adapting for different resource constraints, SWS achieves better results while reducing around 20× parameters stored to initialize these models and around 10× pre-training costs, in contrast to the pre-training and fine-tuning approach. Keywords: Machine Learning: ML: Deep learning architectures Machine Learning: ML: Classification},
  archive   = {C_IJCAI},
  author    = {Shi-Yu Xia and Wenxuan Zhu and Xu Yang and Xin Geng},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/581},
  month     = {8},
  pages     = {5254-5262},
  title     = {Exploring learngene via stage-wise weight sharing for initializing variable-sized models},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AllMatch: Exploiting all unlabeled data for semi-supervised
learning. <em>IJCAI</em>, 5245–5253. (<a
href="https://doi.org/10.24963/ijcai.2024/580">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Existing semi-supervised learning algorithms adopt pseudo-labeling and consistency regulation techniques to introduce supervision signals for unlabeled samples. To overcome the inherent limitation of threshold-based pseudo-labeling, prior studies have attempted to align the confidence threshold with the evolving learning status of the model, which is estimated through the predictions made on the unlabeled data. In this paper, we further reveal that classifier weights can reflect the differentiated learning status across categories and consequently propose a class-specific adaptive threshold mechanism. Additionally, considering that even the optimal threshold scheme cannot resolve the problem of discarding unlabeled samples, a binary classification consistency regulation approach is designed to distinguish candidate classes from negative options for all unlabeled samples. By combining the above strategies, we present a novel SSL algorithm named AllMatch, which achieves improved pseudo-label accuracy and a 100% utilization ratio for the unlabeled data. We extensively evaluate our approach on multiple benchmarks, encompassing both balanced and imbalanced settings. The results demonstrate that AllMatch consistently outperforms existing state-of-the-art methods. Keywords: Machine Learning: ML: Semi-supervised learning},
  archive   = {C_IJCAI},
  author    = {Zhiyu Wu and Jinshi Cui},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/580},
  month     = {8},
  pages     = {5245-5253},
  title     = {AllMatch: Exploiting all unlabeled data for semi-supervised learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Large language model-enhanced algorithm selection: Towards
comprehensive algorithm representation. <em>IJCAI</em>, 5235–5244. (<a
href="https://doi.org/10.24963/ijcai.2024/579">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Algorithm selection, a critical process of automated machine learning, aims to identify the most suitable algorithm for solving a specific problem prior to execution. Mainstream algorithm selection techniques heavily rely on problem features, while the role of algorithm features remains largely unexplored. Due to the intrinsic complexity of algorithms, effective methods for universally extracting algorithm information are lacking. This paper takes a significant step towards bridging this gap by introducing Large Language Models (LLMs) into algorithm selection for the first time. By comprehending the code text, LLM not only captures the structural and semantic aspects of the algorithm, but also demonstrates contextual awareness and library function understanding. The high-dimensional algorithm representation extracted by LLM, after undergoing a feature selection module, is combined with the problem representation and passed to the similarity calculation module. The selected algorithm is determined by the matching degree between a given problem and different algorithms. Extensive experiments validate the performance superiority of the proposed model and the efficacy of each key module. Furthermore, we present a theoretical upper bound on model complexity, showcasing the influence of algorithm representation and feature selection modules. This provides valuable theoretical guidance for the practical implementation of our method. Keywords: Machine Learning: ML: Automated machine learning Search: S: Algorithm portfolios and configuration Machine Learning: ML: Applications Natural Language Processing: NLP: Language models},
  archive   = {C_IJCAI},
  author    = {Xingyu Wu and Yan Zhong and Jibin Wu and Bingbing Jiang and Kay Chen Tan},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/579},
  month     = {8},
  pages     = {5235-5244},
  title     = {Large language model-enhanced algorithm selection: Towards comprehensive algorithm representation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TAI++: Text as image for multi-label image classification by
co-learning transferable prompt. <em>IJCAI</em>, 5226–5234. (<a
href="https://doi.org/10.24963/ijcai.2024/578">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The recent introduction of prompt tuning based on pre-trained vision-language models has dramatically improved the performance of multi-label image classification. However, some existing strategies that have been explored still have drawbacks, i.e., either exploiting massive labeled visual data at a high cost or using text data only for text prompt tuning and thus failing to learn the diversity of visual knowledge. Hence, the application scenarios of these methods are limited. In this paper, we propose a pseudo-visual prompt (PVP) module for implicit visual prompt tuning to address this problem. Specifically, we first learn the pseudo-visual prompt for each category, mining diverse visual knowledge by the well-aligned space of pre-trained vision-language models. Then, a co-learning strategy with a dual-adapter module is designed to transfer visual knowledge from pseudo-visual prompt to text prompt, enhancing their visual representation abilities. Experimental results on VOC2007, MS-COCO, and NUSWIDE datasets demonstrate that our method can surpass state-of-the-art (SOTA) methods across various settings for multi-label image classification tasks. The code is available at https://github.com/njustkmg/PVP. Keywords: Machine Learning: ML: Multi-label learning Computer Vision: CV: Multimodal learning Machine Learning: ML: Multi-modal learning},
  archive   = {C_IJCAI},
  author    = {Xiangyu Wu and Qing-Yuan Jiang and Yang Yang and Yi-Feng Wu and Qing-Guo Chen and Jianfeng Lu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/578},
  month     = {8},
  pages     = {5226-5234},
  title     = {TAI++: Text as image for multi-label image classification by co-learning transferable prompt},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Synthesizing programmatic policy for generalization within
task domain. <em>IJCAI</em>, 5217–5225. (<a
href="https://doi.org/10.24963/ijcai.2024/577">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep reinforcement learning struggles to generalize across tasks that remain unseen during training. Consider a neural process observed in humans and animals, where they not only learn new solutions but also deduce shared subroutines. These subroutines can be applied to tasks involving similar states to improve efficiency. Inspired by this phenomenon, we consider synthesizing a programmatic policy characterized by a conditional branch structure, which is capable of capturing subroutines and state patterns. This enables the learned policy to generalize to unseen tasks. The architecture of the programmatic policy is synthesized based on a context-free grammar. Such a grammar supports a nested If-Then-Else derivation and the incorporation of Recurrent Neural Network. The programmatic policy is trained across tasks in a domain through a meta-learning algorithm. We evaluate our approach in benchmarks, adapted from PDDLGym for task planning and Pybullet for robotic manipulation. Experimental results showcase the effectiveness of our approach across diverse benchmarks. Moreover, the learned policy demonstrates the ability to generalize to tasks that were not seen during training. Keywords: Machine Learning: ML: Reinforcement learning Robotics: ROB: Learning in robotics},
  archive   = {C_IJCAI},
  author    = {Tianyi Wu and Liwei Shen and Zhen Dong and Xin Peng and Wenyun Zhao},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/577},
  month     = {8},
  pages     = {5217-5225},
  title     = {Synthesizing programmatic policy for generalization within task domain},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). PACIA: Parameter-efficient adapter for few-shot molecular
property prediction. <em>IJCAI</em>, 5208–5216. (<a
href="https://doi.org/10.24963/ijcai.2024/576">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Molecular property prediction (MPP) plays a crucial role in biomedical applications, but it often encounters challenges due to a scarcity of labeled data. Existing works commonly adopt gradient-based strategy to update a large amount of parameters for task-level adaptation. However, the increase of adaptive parameters can lead to overfitting and poor performance. Observing that graph neural network (GNN) performs well as both encoder and predictor, we propose PACIA, a parameter-efficient GNN adapter for few-shot MPP. We design a unified adapter to generate a few adaptive parameters to modulate the message passing process of GNN. We then adopt a hierarchical adaptation mechanism to adapt the encoder at task-level and the predictor at query-level by the unified GNN adapter. Extensive results show that PACIA obtains the state-of-the-art performance in few-shot MPP problems, and our proposed hierarchical adaptation mechanism is rational and effective. Keywords: Machine Learning: ML: Applications Machine Learning: ML: Few-shot learning},
  archive   = {C_IJCAI},
  author    = {Shiguang Wu and Yaqing Wang and Quanming Yao},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/576},
  month     = {8},
  pages     = {5208-5216},
  title     = {PACIA: Parameter-efficient adapter for few-shot molecular property prediction},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). From optimization to generalization: Fair federated learning
against quality shift via inter-client sharpness matching.
<em>IJCAI</em>, 5199–5207. (<a
href="https://doi.org/10.24963/ijcai.2024/575">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Due to escalating privacy concerns, federated learning has been recognized as a vital approach for training deep neural networks with decentralized medical data. In practice, it is challenging to ensure consistent imaging quality across various institutions, often attributed to equipment malfunctions affecting a minority of clients. This imbalance in image quality can cause the federated model to develop an inherent bias towards higher-quality images, thus posing a severe fairness issue. In this study, we pioneer the identification and formulation of this new fairness challenge within the context of the imaging quality shift. Traditional methods for promoting fairness in federated learning predominantly focus on balancing empirical risks across diverse client distributions. This strategy primarily facilitates fair optimization across different training data distributions, yet neglects the crucial aspect of generalization. To address this, we introduce a solution termed Federated learning with Inter-client Sharpness Matching (FedISM). FedISM enhances both local training and global aggregation by incorporating sharpness-awareness, aiming to harmonize the sharpness levels across clients for fair generalization. Our empirical evaluations, conducted using the widely-used ICH and ISIC 2019 datasets, establish FedISM&#39;s superiority over current state-of-the-art federated learning methods in promoting fairness. Code is available at https://github.com/wnn2000/FFL4MIA. Keywords: Machine Learning: ML: Federated learning AI Ethics, Trust, Fairness: ETF: Fairness and diversity Computer Vision: CV: Bias, fairness and privacy Computer Vision: CV: Biomedical image analysis},
  archive   = {C_IJCAI},
  author    = {Nannan Wu and Zhuo Kuang and Zengqiang Yan and Li Yu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/575},
  month     = {8},
  pages     = {5199-5207},
  title     = {From optimization to generalization: Fair federated learning against quality shift via inter-client sharpness matching},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards sharper generalization bounds for adversarial
contrastive learning. <em>IJCAI</em>, 5190–5198. (<a
href="https://doi.org/10.24963/ijcai.2024/574">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, the enhancement on the adversarial robustness of machine learning algorithms has gained significant attention across various application domains. Given the widespread label scarcity issue in real-world data, adversarial contrastive learning (ACL) has been proposed to adversarially train robust models using unlabeled data. Despite the empirical success, its generalization behavior remains poorly understood and far from being well-characterized. This paper aims to address this issue from a learning theory perspective. We establish novel high-probability generalization bounds for the general Lipschitz loss functions. The derived bounds scale O(log(k)) with respect to the number of negative samples k, which improves the existing linear dependency bounds. Our results are generally applicable to many prediction models, including linear models and deep neural networks. In particular, we obtain an optimistic generalization bound O(1/n) under the smoothness assumption of the loss function on the sample size n. To the best of our knowledge, this is the first fast-rate bound valid for ACL. Empirical evaluations on real-world datasets verify our theoretical findings. Keywords: Machine Learning: ML: Adversarial machine learning Machine Learning: ML: Learning theory Machine Learning: ML: Self-supervised Learning},
  archive   = {C_IJCAI},
  author    = {Wen Wen and Han Li and Tieliang Gong and Hong Chen},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/574},
  month     = {8},
  pages     = {5190-5198},
  title     = {Towards sharper generalization bounds for adversarial contrastive learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PDENNEval: A comprehensive evaluation of neural network
methods for solving PDEs. <em>IJCAI</em>, 5181–5189. (<a
href="https://doi.org/10.24963/ijcai.2024/573">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The rapid development of neural network (NN) methods for solving partial differential equations (PDEs) has created an urgent need for evaluation and comparison of these methods. In this study, we propose PDENNEval, a comprehensive and systematic evaluation of 12 NN methods for PDEs. These methods are classified into function learning type and operator learning type based on their different mathematical foundations. The evaluation is implemented using a diverse dataset comprising 19 distinct PDE problems selected from various scientific fields such as fluid, materials, finance, and electromagnetic. Several evaluation results are reported, aiming to provide guidance for further research in this field. Our code and data are publicly available at https://github.com/zhouzy36/PDENNEval. Keywords: Machine Learning: ML: Evaluation Machine Learning: ML: Applications Multidisciplinary Topics and Applications: MTA: Physical sciences},
  archive   = {C_IJCAI},
  author    = {Ping Wei and Menghan Liu and Jianhuan Cen and Ziyang Zhou and Liao Chen and Qingsong Zou},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/573},
  month     = {8},
  pages     = {5181-5189},
  title     = {PDENNEval: A comprehensive evaluation of neural network methods for solving PDEs},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cross-talk reduction. <em>IJCAI</em>, 5171–5180. (<a
href="https://doi.org/10.24963/ijcai.2024/572">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {While far-field multi-talker mixtures are recorded, each speaker can wear a close-talk microphone so that close-talk mixtures can be recorded at the same time. Although each close-talk mixture has a high signal-to-noise ratio (SNR) of the wearer, it has a very limited range of applications, as it also contains significant cross-talk speech by other speakers and is not clean enough. In this context, we propose a novel task named \textit{cross-talk reduction} (CTR) which aims at reducing cross-talk speech, and a novel solution named CTRnet which is based on unsupervised or weakly-supervised neural speech separation. In unsupervised CTRnet, close-talk and far-field mixtures are stacked as input for a DNN to estimate the close-talk speech of each speaker. It is trained in an unsupervised, discriminative way such that the DNN estimate for each speaker can be linearly filtered to cancel out the speaker&#39;s cross-talk speech captured at other microphones. In weakly-supervised CTRnet, we assume the availability of each speaker&#39;s activity timestamps during training, and leverage them to improve the training of unsupervised CTRnet. Evaluation results on a simulated two-speaker CTR task and on a real-recorded conversational speech separation and recognition task show the effectiveness and potential of CTRnet. Keywords: Machine Learning: ML: Unsupervised learning Machine Learning: ML: Weakly supervised learning Machine Learning: ML: Applications Natural Language Processing: NLP: Speech},
  archive   = {C_IJCAI},
  author    = {Zhong-Qiu Wang and Anurag Kumar and Shinji Watanabe},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/572},
  month     = {8},
  pages     = {5171-5180},
  title     = {Cross-talk reduction},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Nonconvex multiview subspace clustering framework with
efficient method designs and theoretical analysis. <em>IJCAI</em>,
5162–5170. (<a href="https://doi.org/10.24963/ijcai.2024/571">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-view subspace clustering (MvSC) is one of the most effective methods for understanding and processing high-dimensional data. However, existing MvSC methods still have two shortcomings: (1) they adopt the nuclear norm as the low-rank constraint, which makes it impossible to fully exploit the mutually complementary subspace information, and (2) they do not handle disjoint and confounding points carefully, which may degrade the purity and distinctiveness of cross-view fusion. To address these issues, in this paper we propose a novel MvSC model with nonconvex ℓq regularization. Specially, our proposed model can not only effectively capture the intrinsic global low-rank structure, but also accurately cluster disjoint and confounding data samples into corresponding subspaces. Then, an efficient algorithm is developed with convergence guarantee. Furthermore, we prove that the sequence generated by our proposed algorithm converges to the desirable Karush-Kuhn-Tucker (KKT) critical point. Extensive experiments on various datasets verify the superiority of our proposed model. MATLAB code is available at https://github.com/wangzhi-swu/NLRSC-MvSC. Keywords: Machine Learning: ML: Clustering Machine Learning: ML: Matrix/tensor methods Machine Learning: ML: Multi-view learning Machine Learning: ML: Optimization},
  archive   = {C_IJCAI},
  author    = {Zhi Wang and Zhuo Liu and Dong Hu and Tao Jia},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/571},
  month     = {8},
  pages     = {5162-5170},
  title     = {Nonconvex multiview subspace clustering framework with efficient method designs and theoretical analysis},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Subgraph pooling: Tackling negative transfer on graphs.
<em>IJCAI</em>, 5153–5161. (<a
href="https://doi.org/10.24963/ijcai.2024/570">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Transfer learning aims to enhance performance on a target task by using knowledge from related tasks. However, when the source and target tasks are not closely aligned, it can lead to reduced performance, known as negative transfer. Unlike in image or text data, we find that negative transfer could commonly occur in graph-structured data, even when source and target graphs have semantic similarities. Specifically, we identify that structural differences significantly amplify the dissimilarities in the node embeddings across graphs. To mitigate this, we bring a new insight in this paper: for semantically similar graphs, although structural differences lead to significant distribution shift in node embeddings, their impact on subgraph embeddings could be marginal. Building on this insight, we introduce Subgraph Pooling (SP) by aggregating nodes sampled from a k-hop neighborhood and Subgraph Pooling++ (SP++) by a random walk, to mitigate the impact of graph structural differences on knowledge transfer. We theoretically analyze the role of SP in reducing graph discrepancy and conduct extensive experiments to evaluate its superiority under various settings. The proposed SP methods are effective yet elegant, which can be easily applied on top of any backbone Graph Neural Networks (GNNs). Our code and data are available at: https://github.com/Zehong-Wang/Subgraph-Pooling. Keywords: Machine Learning: ML: Sequence and graph learning Data Mining: DM: Mining graphs Machine Learning: ML: Multi-task and transfer learning Machine Learning: ML: Semi-supervised learning},
  archive   = {C_IJCAI},
  author    = {Zehong Wang and Zheyuan Zhang and Chuxu Zhang and Yanfang Ye},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/570},
  month     = {8},
  pages     = {5153-5161},
  title     = {Subgraph pooling: Tackling negative transfer on graphs},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Atomic recovery property for multi-view subspace-preserving
recovery. <em>IJCAI</em>, 5144–5152. (<a
href="https://doi.org/10.24963/ijcai.2024/569">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As the theoretical underpinnings for subspace clustering and classification, subspace-preserving recovery has attracted intensive attention in recent years. However, previous theoretical advances for subspace-preserving recovery only focus on the single-view data and most of them are based on conditions that are only sufficient. In this paper, we propose a necessary and sufficient condition referred to as Atomic Recovery Property (ARP) for multi-view subspace-preserving recovery. To this end, we generalize the atomic norm from single-view data to multi-view data and define the Multi-view Atomic Norm (MAN). Our another contribution is to provide a geometrically more interpretable characterization of ARP with respect to the unit ball of MAN. Based on the proposed multi-view subspace-preserving recovery theory, we also derive novel theoretical results for multi-view subspace clustering and classification, respectively. Keywords: Machine Learning: ML: Clustering Machine Learning: ML: Classification Machine Learning: ML: Matrix/tensor methods Machine Learning: ML: Multi-view learning},
  archive   = {C_IJCAI},
  author    = {Yulong Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/569},
  month     = {8},
  pages     = {5144-5152},
  title     = {Atomic recovery property for multi-view subspace-preserving recovery},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Self-adaptive extreme penalized loss for imbalanced time
series prediction. <em>IJCAI</em>, 5135–5143. (<a
href="https://doi.org/10.24963/ijcai.2024/568">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Forecasting time series in imbalanced data presents a significant research challenge that requires considerable attention. Although there are specialized techniques available to tackle imbalanced time series prediction, existing approaches tend to prioritize extreme predictions at the expense of compromising the forecasting accuracy of normal samples. We in this paper propose an extreme penalized loss function that relaxes the constraint on overestimating extreme events, thereby imposing great penalties on both normal and underestimating extreme events. In addition, we provide a self-adaptive way for setting the hyperparameters of the loss function. Then, both the proposed loss function and an attention module are integrated with LSTM networks in a decomposition-based framework. Extensive experiments conducted on real-world datasets demonstrate the superiority of our framework compared to other state-of-the-art approaches for both time series prediction and block maxima prediction tasks. Keywords: Machine Learning: ML: Time series and data streams},
  archive   = {C_IJCAI},
  author    = {Yiyang Wang and Yuchen Han and Yuhan Guo},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/568},
  month     = {8},
  pages     = {5135-5143},
  title     = {Self-adaptive extreme penalized loss for imbalanced time series prediction},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Scale and direction guided GAN for inertial sensor signal
enhancement. <em>IJCAI</em>, 5126–5134. (<a
href="https://doi.org/10.24963/ijcai.2024/567">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Inertial sensors, serving as attitude and motion sensing components, are extensively used in various portable devices spanning consumer electronics, sports health, aerospace, etc. However, the severe intrinsic errors of inertial sensors greatly restrict their capability to implement advanced functions, such as motion tracking and semantic recognition. Although generative models hold significant potential for signal enhancement, unsupervised or weakly-supervised generative methods may not achieve ideal generation results due to the absence of guidance from paired data. To address this, we propose a scale and direction-guided generative adversarial network (SDG-GAN), which provides dual guidance mechanisms for GAN with unpaired data across two practical application scenarios. In the unsupervised scenario where only unpaired signals of varying quality are available, our scale-guided GAN (SG-GAN) forces the generator to learn high-quality signal characteristics at different scales simultaneously via the proposed self-supervised zoom constraint, thereby facilitating multi-scale interactive learning. In the weakly-supervised scenario, where additional experimental equipment can provide some motion information, our direction-guided GAN (DG-GAN) introduces auxiliary tasks to supervise signal generation while avoiding interference from auxiliary tasks on the main generation task. Extensive experiments demonstrate that both the unsupervised SG-GAN and the weakly-supervised DG-GAN significantly outperform all comparison methods, including fully-supervised approaches. The combined SDG-GAN achieves remarkable results, enabling unimaginable tasks based on the original inertial signal, such as 3D motion tracking. Keywords: Machine Learning: ML: Generative models Machine Learning: ML: Unsupervised learning Machine Learning: ML: Weakly supervised learning Multidisciplinary Topics and Applications: MTA: Sensor networks and smart cities},
  archive   = {C_IJCAI},
  author    = {Yifeng Wang and Yi Zhao},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/567},
  month     = {8},
  pages     = {5126-5134},
  title     = {Scale and direction guided GAN for inertial sensor signal enhancement},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Self-supervised learning for enhancing spatial awareness in
free-hand sketches. <em>IJCAI</em>, 5117–5125. (<a
href="https://doi.org/10.24963/ijcai.2024/566">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Free-hand sketch, as a versatile medium of communication, can be viewed as a collection of strokes arranged in a spatial layout to convey a concept. Due to the abstract nature of the sketches, changes in stroke position may make them difficult to recognize. Recently, Graphic sketch representations are effective in representing sketches. However, existing methods overlook the significance of the spatial layout of strokes and the phenomenon of strokes being drawn in the wrong positions is common. Therefore, we developed a self-supervised task to correct stroke placement and investigate the impact of spatial layout on learning sketch representations. For this task, we propose a spatially aware method, named SketchGloc, utilizing multiple graphs for graphic sketch representations. This method utilizes grids for each stroke to describe the spatial layout with other strokes, allowing for the construction of multiple graphs. Unlike other methods that rely on a single graph, this design conveys more detailed spatial layout information and alleviates the impact of misplaced strokes. The experimental results demonstrate that our model outperforms existing methods in both our proposed task and the traditional controllable sketch synthesis task. Additionally, we found that SketchGloc can learn more robust representations under our proposed task setting. The source code is available at https://github.com/CMACH508/SketchGloc. Keywords: Machine Learning: ML: Generative models Computer Vision: CV: Representation learning Humans and AI: HAI: Applications Multidisciplinary Topics and Applications: MTA: Arts and creativity},
  archive   = {C_IJCAI},
  author    = {Xin Wang and Tengjie Li and Sicong Zang and Shikui Tu and Lei Xu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/566},
  month     = {8},
  pages     = {5117-5125},
  title     = {Self-supervised learning for enhancing spatial awareness in free-hand sketches},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Joint input and output coordination for class-incremental
learning. <em>IJCAI</em>, 5108–5116. (<a
href="https://doi.org/10.24963/ijcai.2024/565">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Incremental learning is nontrivial due to severe catastrophic forgetting. Although storing a small amount of data on old tasks during incremental learning is a feasible solution, current strategies still do not 1) adequately address the class bias problem, and 2) alleviate the mutual interference between new and old tasks, and 3) consider the problem of class bias within tasks. In light of the above issues, we analyze the cause of class bias in incremental learning, as well as the drawbacks of existing approaches, and propose a joint input and output coordination (JIOC) mechanism to address these issues. This mechanism assigns different weights to different categories of data according to the gradient of the output score, and uses knowledge distillation (KD) to reduce the mutual interference between the outputs of old and new tasks. The proposed mechanism is general and flexible, and can be incorporated into different incremental learning approaches that use memory storage. Extensive experiments show that our mechanism can significantly improve their performance. Keywords: Machine Learning: ML: Incremental learning},
  archive   = {C_IJCAI},
  author    = {Shuai Wang and Yibing Zhan and Yong Luo and Han Hu and Wei Yu and Yonggang Wen and Dacheng Tao},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/565},
  month     = {8},
  pages     = {5108-5116},
  title     = {Joint input and output coordination for class-incremental learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A grassmannian manifold self-attention network for signal
classification. <em>IJCAI</em>, 5099–5107. (<a
href="https://doi.org/10.24963/ijcai.2024/564">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the community of artificial intelligence, significant progress has been made in encoding sequential data using deep learning techniques. Nevertheless, how to effectively mine useful information from channel dimensions remains a major challenge, as these features have a submanifold structure. Linear subspace, the basic element of the Grassmannian manifold, has proven to be an effective manifold-valued feature descriptor in statistical representation. Besides, the Euclidean self-attention mechanism has shown great success in capturing long-range relationships of data. Inspired by these facts, we extend the self-attention mechanism to the Grassmannian manifold. Our framework can effectively characterize the spatiotemporal fluctuations of sequential data encoded in the Grassmannian manifold. Extensive experimental results on three benchmarking datasets (a drone recognition dataset and two EEG signal classification datasets) demonstrate the superiority of our method over the state-of-the-art. The code and supplementary material for this work can be found at https://github.com/ChenHu-ML/GDLNet. Keywords: Machine Learning: ML: Attention models Machine Learning: ML: Classification Machine Learning: ML: Geometric learning},
  archive   = {C_IJCAI},
  author    = {Rui Wang and Chen Hu and Ziheng Chen and Xiao-Jun Wu and Xiaoning Song},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/564},
  month     = {8},
  pages     = {5099-5107},
  title     = {A grassmannian manifold self-attention network for signal classification},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Reconstruction weighting principal component analysis with
fusion contrastive learning. <em>IJCAI</em>, 5091–5098. (<a
href="https://doi.org/10.24963/ijcai.2024/563">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Principal component analysis (PCA) is a popular unsupervised dimensionality reduction method to extract the principal components of data. However, there are two problems with the existing PCA: (1) Traditional PCA methods treat each sample equally and ignore sample differences. (2) They fail to extract the discriminative features required by recognition tasks. To overcome these problems, we incorporate contrastive learning to develop a novel weighted PCA algorithm. Specifically, our method weights the reconstruction error of individual samples to reduce the influence of outliers. Besides, it integrates contrastive learning into PCA to increase inter-class distances and reduce intra-class distance, which helps to improve PCA&#39;s discriminative capability. We further develop an unsupervised strategy to select positive and negative samples, which eliminates pseudo-negative samples guided by clustering labels. Specifically, it employs confidence level to distinguish positive and negative samples. Consequently, our method achieves higher recognition accuracy on benchmark datasets. Keywords: Machine Learning: ML: Feature extraction, selection and dimensionality reduction Computer Vision: CV: Recognition (object detection, categorization) Computer Vision: CV: Representation learning Machine Learning: ML: Classification},
  archive   = {C_IJCAI},
  author    = {Qianqian Wang and Meiling Liu and Wei Feng and Mengping Jiang and Haiming Xu and Quanxue Gao},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/563},
  month     = {8},
  pages     = {5091-5098},
  title     = {Reconstruction weighting principal component analysis with fusion contrastive learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Finite-time convergence rates of decentralized local
markovian stochastic approximation. <em>IJCAI</em>, 5082–5090. (<a
href="https://doi.org/10.24963/ijcai.2024/562">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Markovian stochastic approximation has recently aroused a great deal of interest in many fields; however, it is not well understood in decentralized settings. Decentralized Markovian stochastic approximation is far more challenging than its single-agent counterpart due to the complex coupling structure between decentralized communication and Markovian noise-corrupted local updates. In this paper, a decentralized local markovian stochastic approximation (DLMSA) algorithm has been proposed and attains a near-optimal convergence rate. Specifically, we first provide a local variant of decentralized Markovian stochastic approximation so that each agent performs multiple local updates and then periodically communicate with its neighbors. Furthermore, we propose DLMSA with compressed communication (C-DLMSA) for further reducing the communication overhead. In this way, each agent only needs to communicate compressed information (e.g., sign compression) with its neighbors. We show that C-DLMSA enjoys the same convergence rate as that of the original DLMSA. Finally, we verify our theoretical results by applying our methods to solve multi-task reinforcement learning problems over multi-agent systems. Keywords: Machine Learning: ML: Optimization},
  archive   = {C_IJCAI},
  author    = {Pengfei Wang and Nenggan Zheng},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/562},
  month     = {8},
  pages     = {5082-5090},
  title     = {Finite-time convergence rates of decentralized local markovian stochastic approximation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Strengthening layer interaction via dynamic layer attention.
<em>IJCAI</em>, 5073–5081. (<a
href="https://doi.org/10.24963/ijcai.2024/561">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In recent years, employing layer attention to enhance interaction among hierarchical layers has proven to be a significant advancement in building network structures. In this paper, we delve into the distinction between layer attention and the general attention mechanism, noting that existing layer attention methods achieve layer interaction on fixed feature maps in a static manner. These static layer attention methods limit the ability for context feature extraction among layers. To restore the dynamic context representation capability of the attention mechanism, we propose a Dynamic Layer Attention (DLA) architecture. The DLA comprises dual paths, where the forward path utilizes an improved recurrent neural network block, named Dynamic Sharing Unit (DSU), for context feature extraction. The backward path updates features using these shared context representations. Finally, the attention mechanism is applied to these dynamically refreshed feature maps among layers. Experimental results demonstrate the effectiveness of the proposed DLA architecture, outperforming other state-of-the-art methods in image recognition and object detection tasks. Additionally, the DSU block has been evaluated as an efficient plugin in the proposed DLA architecture. The code is available at https://github.com/tunantu/Dynamic-Layer-attention. Keywords: Machine Learning: ML: Attention models Computer Vision: CV: Recognition (object detection, categorization) Computer Vision: CV: Representation learning Machine Learning: ML: Theory of deep learning},
  archive   = {C_IJCAI},
  author    = {Kaishen Wang and Xun Xia and Jian Liu and Zhang Yi and Tao He},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/561},
  month     = {8},
  pages     = {5073-5081},
  title     = {Strengthening layer interaction via dynamic layer attention},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hacking task confounder in meta-learning. <em>IJCAI</em>,
5064–5072. (<a href="https://doi.org/10.24963/ijcai.2024/560">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Meta-learning enables rapid generalization to new tasks by learning knowledge from various tasks. It is intuitively assumed that as the training progresses, a model will acquire richer knowledge, leading to better generalization performance. However, our experiments reveal an unexpected result: there is negative knowledge transfer between tasks, affecting generalization performance. To explain this phenomenon, we conduct Structural Causal Models (SCMs) for causal analysis. Our investigation uncovers the presence of spurious correlations between task-specific causal factors and labels in meta-learning. Furthermore, the confounding factors differ across different batches. We refer to these confounding factors as ``Task Confounders&quot;. Based on these findings, we propose a plug-and-play Meta-learning Causal Representation Learner (MetaCRL) to eliminate task confounders. It encodes decoupled generating factors from multiple tasks and utilizes an invariant-based bi-level optimization mechanism to ensure their causality for meta-learning. Extensive experiments on various benchmark datasets demonstrate that our work achieves state-of-the-art (SOTA) performance. The code is provided in https://github.com/WangJingyao07/MetaCRL. Keywords: Machine Learning: ML: Meta-learning Computer Vision: CV: Transfer, low-shot, semi- and un- supervised learning Machine Learning: ML: Causality Machine Learning: ML: Few-shot learning},
  archive   = {C_IJCAI},
  author    = {Jingyao Wang and Yi Ren and Zeen Song and Jianqi Zhang and Changwen Zheng and Wenwen Qiang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/560},
  month     = {8},
  pages     = {5064-5072},
  title     = {Hacking task confounder in meta-learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Contrastive and view-interaction structure learning for
multi-view clustering. <em>IJCAI</em>, 5055–5063. (<a
href="https://doi.org/10.24963/ijcai.2024/559">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Existing Deep Multi-view Clustering (DMVC) approaches typically concentrate on capturing consensus semantics from multiple views, where contrastive learning is widely used to align view-specific representations of each view. Unfortunately, view-specific representations are extracted from the content information of the corresponding instance, neglecting the relationships among different instances. Furthermore, existing contrastive loss imports numerous false negative pairs that conflict with the clustering objectives. In response to these challenges, we propose a contraStive and viEw-interaction stRucture learning framework for multI-viEw cluStering (SERIES). Our method takes into account the structural relations among instances and boosts the contrastive loss to improve intra-class compactness. Meanwhile, a cross-view dual relation generation mechanism is introduced to achieve the consensus structural graph across multiple views for clustering. Specifically, we initially acquire view-specific representations using multiple graph autoencoders to exploit both content information and structural information. Furthermore, to pull together the same cluster instances, a soft negative pair aware contrastive loss is employed to distinguish the dissimilar instances while attracting similar instances. Thereafter, the view-specific representations are fed into cross-view dual relation generation layers to generate the affinity matrices of each other, aiming to reveal a consistent structural graph across various views. Extensive experiments conducted on six benchmarks illustrate the superiority of our method compared to other state-of-the-art approaches. Keywords: Machine Learning: ML: Multi-view learning Machine Learning: ML: Clustering},
  archive   = {C_IJCAI},
  author    = {Jing Wang and Songhe Feng},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/559},
  month     = {8},
  pages     = {5055-5063},
  title     = {Contrastive and view-interaction structure learning for multi-view clustering},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MOSER: Learning sensory policy for task-specific viewpoint
via view-conditional world model. <em>IJCAI</em>, 5046–5054. (<a
href="https://doi.org/10.24963/ijcai.2024/558">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Reinforcement learning from visual observations is a challenging problem with many real-world applications. Existing algorithms mostly rely on a single observation from a well-designed fixed camera that requires human knowledge. Recent studies learn from different viewpoints with multiple fixed cameras, but this incurs high computation and storage costs and may not guarantee the coverage of the optimal viewpoint. To alleviate these limitations, we propose a straightforward View-conditional Partially Observable Markov Decision Processes (VPOMDPs) assumption and develop a new method, the MOdel-based SEnsor controlleR (MOSER). MOSER jointly learns a view-conditional world model (VWM) to simulate the environment, a sensory policy to control the camera, and a motor policy to complete tasks. We design intrinsic rewards from the VWM without additional modules to guide the sensory policy to adjust the camera parameters. Experiments on locomotion and manipulation tasks demonstrate that MOSER autonomously discovers task-specific viewpoints and significantly outperforms most baseline methods. Keywords: Machine Learning: ML: Reinforcement learning Machine Learning: ML: Model-based and model learning reinforcement learning Machine Learning: ML: Partially observable reinforcement learning and POMDPs},
  archive   = {C_IJCAI},
  author    = {Shenghua Wan and Hai-Hang Sun and Le Gan and De-Chuan Zhan},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/558},
  month     = {8},
  pages     = {5046-5054},
  title     = {MOSER: Learning sensory policy for task-specific viewpoint via view-conditional world model},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Interpretable tensor fusion. <em>IJCAI</em>, 5037–5045. (<a
href="https://doi.org/10.24963/ijcai.2024/557">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Conventional machine learning methods are predominantly designed to predict outcomes based on a single data type. However, practical applications may encompass data of diverse types, such as text, images, and audio. We introduce interpretable tensor fusion (InTense), a multimodal learning method training a neural network to simultaneously learn multiple data representations and their interpretable fusion. InTense can separately capture both linear combinations and multiplicative interactions of the data types, thereby disentangling higher-order interactions from the individual effects of each modality. InTense provides interpretability out of the box by assigning relevance scores to modalities and their associations, respectively. The approach is theoretically grounded and yields meaningful relevance scores on multiple synthetic and real-world datasets. Experiments on four real-world datasets show that InTense outperforms existing state-of-the-art multimodal interpretable approaches in terms of accuracy and interpretability. Keywords: Machine Learning: ML: Explainable/Interpretable machine learning Machine Learning: ML: Multi-modal learning Machine Learning: ML: Representation learning Natural Language Processing: NLP: Sentiment analysis, stylistic analysis, and argument mining},
  archive   = {C_IJCAI},
  author    = {Saurabh Varshneya and Antoine Ledent and Philipp Liznerski and Andriy Balinskyy and Purvanshi Mehta and Waleed Mustafa and Marius Kloft},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/557},
  month     = {8},
  pages     = {5037-5045},
  title     = {Interpretable tensor fusion},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Proximal curriculum with task correlations for deep
reinforcement learning. <em>IJCAI</em>, 5027–5036. (<a
href="https://doi.org/10.24963/ijcai.2024/556">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Curriculum design for reinforcement learning (RL) can speed up an agent&#39;s learning process and help it learn to perform well on complex tasks. However, existing techniques typically require domain-specific hyperparameter tuning, involve expensive optimization procedures for task selection, or are suitable only for specific learning objectives. In this work, we consider curriculum design in contextual multi-task settings where the agent&#39;s final performance is measured w.r.t. a target distribution over complex tasks. We base our curriculum design on the Zone of Proximal Development concept, which has proven to be effective in accelerating the learning process of RL agents for uniform distribution over all tasks. We propose a novel curriculum, ProCuRL-Target, that effectively balances the need for selecting tasks that are not too difficult for the agent while progressing the agent&#39;s learning toward the target distribution via leveraging task correlations. We theoretically justify the task selection strategy of ProCuRL-Target by analyzing a simple learning setting with REINFORCE learner model. Our experimental results across various domains with challenging target task distributions affirm the effectiveness of our curriculum strategy over state-of-the-art baselines in accelerating the training process of deep RL agents. Keywords: Machine Learning: ML: Reinforcement learning Planning and Scheduling: PS: Markov decisions processes},
  archive   = {C_IJCAI},
  author    = {Georgios Tzannetos and Parameswaran Kamalaruban and Adish Singla},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/556},
  month     = {8},
  pages     = {5027-5036},
  title     = {Proximal curriculum with task correlations for deep reinforcement learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enabling mixed effects neural networks for diverse,
clustered data using monte carlo methods. <em>IJCAI</em>, 5018–5026. (<a
href="https://doi.org/10.24963/ijcai.2024/555">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Neural networks often assume independence among input data samples, disregarding correlations arising from inherent clustering patterns in real-world datasets (e.g., due to different sites or repeated measurements). Recently, mixed effects neural networks (MENNs) which separate cluster-specific &#39;random effects&#39; from cluster-invariant &#39;fixed effects&#39; have been proposed to improve generalization and interpretability for clustered data. However, existing methods only allow for approximate quantification of cluster effects and are limited to regression and binary targets with only one clustering feature. We present MC-GMENN, a novel approach employing Monte Carlo techniques to train Generalized Mixed Effects Neural Networks. We empirically demonstrate that MC-GMENN outperforms existing mixed effects deep learning models in terms of generalization performance, time complexity, and quantification of inter-cluster variance. Additionally, MC-GMENN is applicable to a wide range of datasets, including multi-class classification tasks with multiple high-cardinality categorical features. For these datasets, we show that MC-GMENN outperforms conventional encoding and embedding methods, simultaneously offering a principled methodology for interpreting the effects of clustering patterns. Keywords: Machine Learning: ML: Deep learning architectures Machine Learning: ML: Classification Machine Learning: ML: Explainable/Interpretable machine learning Machine Learning: ML: Probabilistic machine learning},
  archive   = {C_IJCAI},
  author    = {Andrej Tschalzev and Paul Nitschke and Lukas Kirchdorfer and Stefan Lüdtke and Christian Bartelt and Heiner Stuckenschmidt},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/555},
  month     = {8},
  pages     = {5018-5026},
  title     = {Enabling mixed effects neural networks for diverse, clustered data using monte carlo methods},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Redefining contributions: Shapley-driven federated learning.
<em>IJCAI</em>, 5009–5017. (<a
href="https://doi.org/10.24963/ijcai.2024/554">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Federated learning (FL) has emerged as a pivotal approach in machine learning, enabling multiple participants to collaboratively train a global model without sharing raw data. While FL finds applications in various domains such as healthcare and finance, it is challenging to ensure global model convergence when participants do not contribute equally and/or honestly. To overcome this challenge, principled mechanisms are required to evaluate the contributions made by individual participants in the FL setting. Existing solutions for contribution assessment rely on general accuracy evaluation, often failing to capture nuanced dynamics and class-specific influences. This paper proposes a novel contribution assessment method called ShapFed for fine-grained evaluation of participant contributions in FL. Our approach uses Shapley values from cooperative game theory to provide a granular understanding of class-specific influences. Based on ShapFed, we introduce a weighted aggregation method called ShapFed-WA, which outperforms conventional federated averaging, especially in class-imbalanced scenarios. Personalizing participant updates based on their contributions further enhances collaborative fairness by delivering differentiated models commensurate with the participant contributions. Experiments on CIFAR-10, Chest X-Ray, and Fed-ISIC2019 datasets demonstrate the effectiveness of our approach in improving utility, efficiency, and fairness in FL systems. The code can be found at \href{https://github.com/tnurbek/shapfed}{https://github.com/tnurbek/shapfed}. Keywords: Machine Learning: ML: Federated learning Computer Vision: CV: Bias, fairness and privacy Machine Learning: ML: Trustworthy machine learning AI Ethics, Trust, Fairness: ETF: Trustworthy AI},
  archive   = {C_IJCAI},
  author    = {Nurbek Tastan and Samar Fares and Toluwani Aremu and Samuel Horváth and Karthik Nandakumar},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/554},
  month     = {8},
  pages     = {5009-5017},
  title     = {Redefining contributions: Shapley-driven federated learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unlearning from weakly supervised learning. <em>IJCAI</em>,
5000–5008. (<a href="https://doi.org/10.24963/ijcai.2024/553">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Machine unlearning provides users with the right to remove their privacy data from a well-trained model. Existing approaches of machine unlearning mainly focus on exploring data removing within supervised learning (SL) tasks. However, weakly supervised learning (WSL) is more applicable to real-world scenarios since collecting WSL data is less laborious than collecting fully supervised data. In this paper, we first propose a machine unlearning approach for WSL by updating the model parameters. Motivated by the uniform distributions of untrained model predictions, we derive a formulated target to force the model&#39;s predictions of removed data to be indistinguishable. This encourages the model to forget its ability to recognize features of data slated for unlearning. Moreover, we employ formulated targets to transform the classification unlearning into the convex regression, which can significantly reduce computational cost and avoid extra information storage during the training process. Additionally, we discuss how to design a target to ensure the models&#39; predictions of removed data being indistinguishable in different learning scenarios, e.g., SL or WSL. As the flexibility in formulating targets, the proposed approach effectively deals with the WSL problem while still excels in SL models. Empirical studies show the superiority of the proposed approach. Keywords: Machine Learning: ML: Weakly supervised learning Machine Learning: ML: Other},
  archive   = {C_IJCAI},
  author    = {Yi Tang and Yi Gao and Yong-gang Luo and Ju-Cheng Yang and Miao Xu and Min-Ling Zhang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/553},
  month     = {8},
  pages     = {5000-5008},
  title     = {Unlearning from weakly supervised learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A bias-free revenue-maximizing bidding strategy for data
consumers in auction-based federated learning. <em>IJCAI</em>,
4991–4999. (<a href="https://doi.org/10.24963/ijcai.2024/552">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Auction-based Federated Learning (AFL) is a burgeoning research area. However, existing bidding strategies for AFL data consumers (DCs) primarily focus on maximizing expected accumulated utility, disregarding the more complex goal of revenue maximization. They also only consider winning bids, leading to biased estimates by overlooking information from losing bids. To address these issues, we propose a Bias-free Revenue-maximizing Federated bidding strategy for DCs in AFL (BR-FEDBIDDER). Our theoretical exploration of the relationships between Return on Investment (ROI), bid costs, and utility, and their impact on overall revenue underscores the complexity of maximizing revenue solely by prioritizing ROI enhancement. Leveraging these insights, BR-FEDBIDDER optimizes bid costs with any given ROI constraint. In addition, we incorporate an auxiliary task of winning probability estimation into the framework to achieve bias-free learning by leveraging bid records from historical bid requests, including both winning and losing ones. Extensive experiments on six widely used benchmark datasets show that BR-FEDBIDDER outperforms eight state-of-the-art methods, surpassing the best-performing baseline by 5.66%, 6.08% and 2.44% in terms of the total revenue, ROI, and test accuracy of the resulting FL models, respectively. Keywords: Machine Learning: ML: Federated learning},
  archive   = {C_IJCAI},
  author    = {Xiaoli Tang and Han Yu and Zengxiang Li and Xiaoxiao Li},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/552},
  month     = {8},
  pages     = {4991-4999},
  title     = {A bias-free revenue-maximizing bidding strategy for data consumers in auction-based federated learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dual calibration-based personalised federated learning.
<em>IJCAI</em>, 4982–4990. (<a
href="https://doi.org/10.24963/ijcai.2024/551">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Personalized federated learning (PFL) is designed for scenarios with non-independent and identically distributed (non-IID) client data. Existing model mixup-based methods, one of the main approaches of PFL, can only extract either global or personalized features during training, thereby limiting effective knowledge sharing among clients. To address this limitation, we propose the Dual Calibration-based PFL (DC-PFL). It divides local models into a heterogeneous feature extractor and a homogeneous classifier. The FL server utilizes mean and covariance representations from clients&#39; feature extractors to train a global generalized classifier, facilitating information exchange while preserving privacy. To enhance personalization and convergence, we design a feature extractor-level calibration method with an auxiliary loss for local models to refine feature extractors using global knowledge. Furthermore, DC-PFL refines the global classifier through the global classifier-level calibration, utilizing sample representations derived from an approximate Gaussian distribution model specific to each class. This method precludes the need to transmit original data representations, further enhancing privacy preservation. Extensive experiments on widely used benchmark datasets demonstrate that DC-PFL outperforms eight state-of-the-art methods, surpassing the best-performing baseline by 1.22% and 9.22% in terms of accuracy on datasets CIFAR-10 and CIFAR-100, respectively. Keywords: Machine Learning: ML: Federated learning},
  archive   = {C_IJCAI},
  author    = {Xiaoli Tang and Han Yu and Run Tang and Chao Ren and Anran Li and Xiaoxiao Li},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/551},
  month     = {8},
  pages     = {4982-4990},
  title     = {Dual calibration-based personalised federated learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploiting conjugate label information for multi-instance
partial-label learning. <em>IJCAI</em>, 4973–4981. (<a
href="https://doi.org/10.24963/ijcai.2024/550">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-instance partial-label learning (MIPL) addresses scenarios where each training sample is represented as a multi-instance bag associated with a candidate label set containing one true label and several false positives. Existing MIPL algorithms have primarily focused on mapping multi-instance bags to candidate label sets for disambiguation, disregarding the intrinsic properties of the label space and the supervised information provided by non-candidate label sets. In this paper, we propose an algorithm named ELIMIPL, i.e., Exploiting conjugate Label Information for Multi-Instance Partial-Label learning, which exploits the conjugate label information to improve the disambiguation performance. To achieve this, we extract the label information embedded in both candidate and non-candidate label sets, incorporating the intrinsic properties of the label space. Experimental results obtained from benchmark and real-world datasets demonstrate the superiority of the proposed ELIMIPL over existing MIPL algorithms and other well-established partial-label learning algorithms. Keywords: Machine Learning: ML: Weakly supervised learning Machine Learning: ML: Classification},
  archive   = {C_IJCAI},
  author    = {Wei Tang and Weijia Zhang and Min-Ling Zhang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/550},
  month     = {8},
  pages     = {4973-4981},
  title     = {Exploiting conjugate label information for multi-instance partial-label learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep hierarchical graph alignment kernels. <em>IJCAI</em>,
4964–4972. (<a href="https://doi.org/10.24963/ijcai.2024/549">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Typical R-convolution graph kernels invoke the kernel functions that decompose graphs into non-isomorphic substructures and compare them. However, overlooking implicit similarities and topological position information between those substructures limits their performances. In this paper, we introduce Deep Hierarchical Graph Alignment Kernels (DHGAK) to resolve this problem. Specifically, the relational substructures are hierarchically aligned to cluster distributions in their deep embedding space. The substructures belonging to the same cluster are assigned the same feature map in the Reproducing Kernel Hilbert Space (RKHS), where graph feature maps are derived by kernel mean embedding. Theoretical analysis guarantees that DHGAK is positive semi-definite and has linear separability in the RKHS. Comparison with state-of-the-art graph kernels on various benchmark datasets demonstrates the effectiveness and efficiency of DHGAK. The code is available at Github (https://github.com/EWesternRa/DHGAK). Keywords: Machine Learning: ML: Kernel methods},
  archive   = {C_IJCAI},
  author    = {Shuhao Tang and Hao Tian and Xiaofeng Cao and Wei Ye},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/549},
  month     = {8},
  pages     = {4964-4972},
  title     = {Deep hierarchical graph alignment kernels},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Perturbation guiding contrastive representation learning for
time series anomaly detection. <em>IJCAI</em>, 4955–4963. (<a
href="https://doi.org/10.24963/ijcai.2024/548">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Time series anomaly detection is a critical task with applications in various domains. Due to annotation challenges, self-supervised methods have become the mainstream approach for time series anomaly detection in recent years. However, current contrastive methods categorize data perturbations into binary classes, normal or anomaly, which lack clarity on the specific impact of different perturbation methods. Inspired by the hypothesis that &quot;the higher the probability of misclassifying perturbation types, the higher the probability of anomalies&quot;, we propose PCRTA, our approach firstly devises a perturbation classifier to learn the pseudo-labels of data perturbations. Furthermore, for addressing &quot;class collapse issue&quot; in contrastive learning, we propose a perturbation guiding positive and negative samples selection strategy by introducing learnable perturbation classification networks. Extensive experiments on six realworld datasets demonstrate the significant superiority of our model over thirteen state-of-the-art competitors, and obtains average 5.14%, 8.24% improvement in F1 score and AUC-PR, respectively. Keywords: Machine Learning: ML: Representation learning Machine Learning: ML: Self-supervised Learning Machine Learning: ML: Time series and data streams Machine Learning: ML: Unsupervised learning},
  archive   = {C_IJCAI},
  author    = {Liaoyuan Tang and Zheng Wang and Guanxiong He and Rong Wang and Feiping Nie},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/548},
  month     = {8},
  pages     = {4955-4963},
  title     = {Perturbation guiding contrastive representation learning for time series anomaly detection},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive order q-learning. <em>IJCAI</em>, 4946–4954. (<a
href="https://doi.org/10.24963/ijcai.2024/547">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper revisits the estimation bias control problem of Q-learning, motivated by the fact that the estimation bias is not always evil, i.e., some environments benefit from overestimation bias or underestimation bias, while others suffer from these biases. Different from previous coarse-grained bias control methods, this paper proposes a fine-grained bias control algorithm called Order Q-learning. It uses the order statistic of multiple independent Q-tables to control bias and flexibly meet the personalized bias needs of different environments, i.e., the bias can vary from underestimation bias to overestimation bias as one selects a higher order Q-value. We derive the expected estimation bias and its lower bound and upper bound. They reveal that the expected estimation bias is inversely proportional to the number of Q-tables and proportional to the index of order statistic function. To show the versatility of Order Q-learning, we design an adaptive parameter adjustment strategy, leading to AdaOrder (Adaptive Order) Q-learning. It adaptively selects the number of Q-tables and the index of order statistic function via the number of visits to state-action pair and the average Q-value. We extend Order Q-learning and AdaOrder Q-learning to the large scale setting with function approximation, leading to Order DQN and AdaOrder DQN, respectively. Finally, we consider two experiment settings: deep reinforcement learning experiments show that our method outperforms several SOTA baselines drastically; tabular MDP experiments reveal fundamental insights into why our method can achieve superior performance.Our supplementary file can be found in https://1drv.ms/f/s!Atddp1iaDmL2gjv31CaGquw5WwYI. Keywords: Machine Learning: ML: Reinforcement learning},
  archive   = {C_IJCAI},
  author    = {Tao Tan and Hong Xie and Defu Lian},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/547},
  month     = {8},
  pages     = {4946-4954},
  title     = {Adaptive order Q-learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust contrastive multi-view kernel clustering.
<em>IJCAI</em>, 4938–4945. (<a
href="https://doi.org/10.24963/ijcai.2024/546">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-view kernel clustering (MKC) aims to fully reveal the consistency and complementarity of multiple views in a potential Hilbert space, thereby enhancing clustering performance. The clustering results of most MKC methods are highly sensitive to the quality of the constructed kernels, as traditional methods independently compute kernel matrices for each view without fully considering complementary information across views. In previous contrastive multi-view kernel learning, the goal was to bring cross-view instances of the same sample closer during the kernel construction process while pushing apart instances across samples to achieve a comprehensive integration of cross-view information. However, its inherent drawback is the potential inappropriate amplification of distances between different instances of the same clusters (i.e., false negative pairs) during the training process, leading to a reduction in inter-class discriminability. To address this challenge, we propose a Robust Contrastive multi-view kernel Learning approach (R-CMK) against false negative pairs. It partitions negative pairs into different intervals based on distance or similarity, and for false negative pairs, reverses their optimization gradient. This effectively avoids further amplification of distances for false negative pairs while simultaneously pushing true negative pairs farther apart. We conducted comprehensive experiments on various MKC methods to validate the effectiveness of the proposed method. The code is available at https://github.com/Duo-laimi/rcmk_main. Keywords: Machine Learning: ML: Multi-view learning Machine Learning: ML: Clustering Machine Learning: ML: Kernel methods},
  archive   = {C_IJCAI},
  author    = {Peng Su and Yixi Liu and Shujian Li and Shudong Huang and Jiancheng Lv},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/546},
  month     = {8},
  pages     = {4938-4945},
  title     = {Robust contrastive multi-view kernel clustering},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Offline reinforcement learning with behavioral supervisor
tuning. <em>IJCAI</em>, 4929–4937. (<a
href="https://doi.org/10.24963/ijcai.2024/545">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Offline reinforcement learning (RL) algorithms are applied to learn performant, well-generalizing policies when provided with a static dataset of interactions. Many recent approaches to offline RL have seen substantial success, but with one key caveat: they demand substantial per-dataset hyperparameter tuning to achieve reported performance which requires policy rollouts in the environment to evaluate; this can rapidly become cumbersome. Furthermore, substantial tuning requirements can hamper the adoption of these algorithms in practical domains. In this paper, we present TD3 with Behavioral Supervisor Tuning (TD3-BST), an algorithm that trains an uncertainty model and uses it to guide the policy to select actions within the dataset support. TD3-BST can learn more effective policies from offline datasets compared to prior methods and achieves the best performance across challenging benchmarks without requiring per-dataset tuning. Keywords: Machine Learning: ML: Offline reinforcement learning Machine Learning: ML: Reinforcement learning},
  archive   = {C_IJCAI},
  author    = {Padmanaba Srinivasan and William Knottenbelt},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/545},
  month     = {8},
  pages     = {4929-4937},
  title     = {Offline reinforcement learning with behavioral supervisor tuning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning pareto set for multi-objective continuous robot
control. <em>IJCAI</em>, 4920–4928. (<a
href="https://doi.org/10.24963/ijcai.2024/544">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {For a control problem with multiple conflicting objectives, there exists a set of Pareto-optimal policies called the Pareto set instead of a single optimal policy. When a multi-objective control problem is continuous and complex, traditional multi-objective reinforcement learning (MORL) algorithms search for many Pareto-optimal deep policies to approximate the Pareto set, which is quite resource-consuming. In this paper, we propose a simple and resource-efficient MORL algorithm that learns a continuous representation of the Pareto set in a high-dimensional policy parameter space using a single hypernet. The learned hypernet can directly generate various well-trained policy networks for different user preferences. We compare our method with two state-of-the-art MORL algorithms on seven multi-objective continuous robot control problems. Experimental results show that our method achieves the best overall performance with the least training parameters. An interesting observation is that the Pareto set is well approximated by a curved line or surface in a high-dimensional parameter space. This observation will provide insight for researchers to design new MORL algorithms. Keywords: Machine Learning: ML: Reinforcement learning Machine Learning: ML: Optimization Robotics: ROB: Learning in robotics},
  archive   = {C_IJCAI},
  author    = {Tianye Shu and Ke Shang and Cheng Gong and Yang Nan and Hisao Ishibuchi},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/544},
  month     = {8},
  pages     = {4920-4928},
  title     = {Learning pareto set for multi-objective continuous robot control},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning with posterior sampling for revenue management
under time-varying demand. <em>IJCAI</em>, 4911–4919. (<a
href="https://doi.org/10.24963/ijcai.2024/543">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper discusses the revenue management (RM) problem to maximize revenue by pricing items or services. One challenge in this problem is that the demand distribution is unknown and varies over time in real applications such as airline and retail industries. In particular, the time-varying demand has not been well studied under scenarios of unknown demand due to the difficulty of jointly managing the remaining inventory and estimating the demand. To tackle this challenge, we first introduce an episodic generalization of the RM problem motivated by typical application scenarios. We then propose a computationally efficient algorithm based on posterior sampling, which effectively optimizes prices by solving linear programming. We derive a Bayesian regret upper bound of this algorithm for general models where demand parameters can be correlated between time periods, while also deriving a regret lower bound for generic algorithms. Our empirical study shows that the proposed algorithm performs better than other benchmark algorithms and comparably to the optimal policy in hindsight. We also propose a heuristic modification of the proposed algorithm, which further efficiently learns the pricing policy in the experiments. An extended version of this paper with appendixes is available at: http://arxiv.org/abs/2405.04910. Keywords: Machine Learning: ML: Online learning Machine Learning: ML: Bayesian learning Machine Learning: ML: Multi-armed bandits},
  archive   = {C_IJCAI},
  author    = {Kazuma Shimizu and Junya Honda and Shinji Ito and Shinji Nakadai},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/543},
  month     = {8},
  pages     = {4911-4919},
  title     = {Learning with posterior sampling for revenue management under time-varying demand},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A context-enhanced framework for sequential graph reasoning.
<em>IJCAI</em>, 4902–4910. (<a
href="https://doi.org/10.24963/ijcai.2024/542">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The paper studies sequential reasoning over graph-structured data, which stands as a fundamental task in various trending fields like automated math problem solving and neural graph algorithm learning, attracting a lot of research interest. Simultaneously managing both sequential and graph-structured information in such tasks presents a notable challenge. Over recent years, many neural architectures in the literature have emerged to tackle the issue. In this work, we generalize the existing architectures and propose a context-enhanced framework. The crucial innovation is that the reasoning of each step does not only rely on the outcome of the preceding step but also leverages the aggregation of information from more historical outcomes. The idea stems from our observation that in sequential graph reasoning, each step&#39;s outcome has a much stronger inner connection with each other compared to traditional seq-to-seq tasks. We show that the framework can effectively integrate with the existing methods, enhancing their reasoning abilities. Empirical evaluations are conducted on the challenging CLRS Reasoning Benchmark, and the results demonstrate that the proposed framework significantly improves the performance of existing architectures, yielding state-of-the-art results across the majority of the datasets within the benchmark. Keywords: Machine Learning: ML: Sequence and graph learning},
  archive   = {C_IJCAI},
  author    = {Shuo Shi and Chao Peng and Chenyang Xu and Zhengfeng Yang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/542},
  month     = {8},
  pages     = {4902-4910},
  title     = {A context-enhanced framework for sequential graph reasoning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Estimating conditional average treatment effects via
sufficient representation learning. <em>IJCAI</em>, 4894–4901. (<a
href="https://doi.org/10.24963/ijcai.2024/541">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Estimating the conditional average treatment effects (CATE) is very important in causal inference and has a wide range of applications across many fields. In the estimation process of CATE, the unconfoundedness assumption is typically required to ensure the identifiability of the regression problems. When estimating CATE using high-dimensional data, there have been many variable selection methods and neural network approaches based on representation learning, while these methods do not provide a way to verify whether the subset of variables after dimensionality reduction or the learned representations still satisfy the unconfoundedness assumption during the estimation process, which can lead to ineffective estimates of the treatment effects. Additionally, these methods typically use data from only the treatment or control group when estimating the regression functions for each group. This paper proposes a novel neural network approach named CrossNet to learn a sufficient representation for the features, based on which we then estimate the CATE, where cross indicates that in estimating the regression functions, we used data from their own group as well as cross-utilized data from another group. Numerical simulations and empirical results demonstrate that our method outperforms the competitive approaches. Keywords: Machine Learning: ML: Regression Machine Learning: ML: Causality Machine Learning: ML: Representation learning Machine Learning: ML: Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Pengfei Shi and Wei Zhong and Xinyu Zhang and Ningtao Wang and Xing Fu and Weiqiang Wang and Yin Jin},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/541},
  month     = {8},
  pages     = {4894-4901},
  title     = {Estimating conditional average treatment effects via sufficient representation learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Predictive accuracy-based active learning for medical image
segmentation. <em>IJCAI</em>, 4885–4893. (<a
href="https://doi.org/10.24963/ijcai.2024/540">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Active learning is considered a viable solution to alleviate the contradiction between the high dependency of deep learning-based segmentation methods on annotated data and the expensive pixel-level annotation cost of medical images. However, most existing methods suffer from unreliable uncertainty assessment and the struggle to balance diversity and informativeness, leading to poor performance in segmentation tasks. In response, we propose an efficient Predictive Accuracy-based Active Learning (PAAL) method for medical image segmentation, first introducing predictive accuracy to define uncertainty. Specifically, PAAL mainly consists of an Accuracy Predictor (AP) and a Weighted Polling Strategy (WPS). The former is an attached learnable module that can accurately predict the segmentation accuracy of unlabeled samples relative to the target model with the predicted posterior probability. The latter provides an efficient hybrid querying scheme by combining predicted accuracy and feature representation, aiming to ensure the uncertainty and diversity of the acquired samples. Extensive experiment results on multiple datasets demonstrate the superiority of PAAL. PAAL achieves comparable accuracy to fully annotated data while reducing annotation costs by approximately 50% to 80%, showcasing significant potential in clinical applications. The code is available at https://github.com/shijun18/PAAL-MedSeg. Keywords: Machine Learning: ML: Active learning Computer Vision: CV: Biomedical image analysis Computer Vision: CV: Segmentation Uncertainty in AI: UAI: Uncertainty representations},
  archive   = {C_IJCAI},
  author    = {Jun Shi and Shulan Ruan and Ziqi Zhu and Minfan Zhao and Hong An and Xudong Xue and Bing Yan},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/540},
  month     = {8},
  pages     = {4885-4893},
  title     = {Predictive accuracy-based active learning for medical image segmentation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). EMOTE: An explainable architecture for modelling the other
through empathy. <em>IJCAI</em>, 4876–4884. (<a
href="https://doi.org/10.24963/ijcai.2024/539">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Empathy allows us to assume others are like us and have goals analogous to our own. This can also at times be applied to multi-agent games - e.g. Agent 1&#39;s attraction to green balls is analogous to Agent 2&#39;s attraction to red balls. Drawing inspiration from empathy, we propose EMOTE, a simple and explainable inverse reinforcement learning (IRL) approach designed to model another agent&#39;s action-value function and from it, infer a unique reward function. This is done by referencing the learning agent&#39;s own action value function, removing the need to maintain independent action-value estimates for the modelled agents whilst simultaneously addressing the ill-posed nature of IRL by inferring a unique reward function. We experiment on minigrid environments showing EMOTE: (a) produces more consistent reward estimates relative to other IRL baselines (b) is robust in scenarios with composite reward and action-value functions (c) produces human-interpretable states, helping to explain how the agent views other agents. Keywords: Machine Learning: ML: Multiagent Reinforcement Learning Agent-based and Multi-agent Systems: MAS: Multi-agent learning AI Ethics, Trust, Fairness: ETF: Explainability and interpretability Machine Learning: ML: Reinforcement learning},
  archive   = {C_IJCAI},
  author    = {Manisha Senadeera and Thommen Karimpanal George and Stephan Jacobs and Sunil Gupta and Santu Rana},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/539},
  month     = {8},
  pages     = {4876-4884},
  title     = {EMOTE: An explainable architecture for modelling the other through empathy},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust losses for decision-focused learning. <em>IJCAI</em>,
4868–4875. (<a href="https://doi.org/10.24963/ijcai.2024/538">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Optimization models used to make discrete decisions often contain uncertain parameters that are context-dependent and estimated through prediction. To account for the quality of the decision made based on the prediction, decision-focused learning (end-to-end predict-then-optimize) aims at training the predictive model to minimize regret, i.e., the loss incurred by making a suboptimal decision. Despite the challenge of the gradient of this loss w.r.t. the predictive model parameters being zero almost everywhere for optimization problems with a linear objective, effective gradient-based learning approaches have been proposed to minimize the expected loss, using the empirical loss as a surrogate. However, empirical regret can be an ineffective surrogate because empirical optimal decisions can vary substantially from expected optimal decisions. To understand the impact of this deficiency, we evaluate the effect of aleatoric and epistemic uncertainty on the accuracy of empirical regret as a surrogate. Next, we propose three novel loss functions that approximate expected regret more robustly. Experimental results show that training two state-of-the-art decision-focused learning approaches using robust regret losses improves test-sample empirical regret in general while keeping computational time equivalent relative to the number of training epochs. Keywords: Machine Learning: ML: Robustness Constraint Satisfaction and Optimization: CSO: Constraint optimization problems Machine Learning: ML: Regression Machine Learning: ML: Optimization},
  archive   = {C_IJCAI},
  author    = {Noah Schutte and Krzysztof Postek and Neil Yorke-Smith},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/538},
  month     = {8},
  pages     = {4868-4875},
  title     = {Robust losses for decision-focused learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hyperparameter optimization can even be harmful in
off-policy learning and how to deal with it. <em>IJCAI</em>, 4860–4867.
(<a href="https://doi.org/10.24963/ijcai.2024/537">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {There has been a growing interest in off-policy evaluation in the literature such as recommender systems and personalized medicine. We have so far seen significant progress in developing estimators aimed at accurately estimating the effectiveness of counterfactual policies based on biased logged data. However, there are many cases where those estimators are used not only to evaluate the value of decision making policies but also to search for the best hyperparameters from a large candidate space. This work explores the latter hyperparameter optimization (HPO) task for off-policy learning. We empirically show that naively applying an unbiased estimator of the generalization performance as a surrogate objective in HPO can cause an unexpected failure, merely pursuing hyperparameters whose generalization performance is greatly overestimated. We then propose simple and computationally efficient corrections to the typical HPO procedure to deal with the aforementioned issues simultaneously. Empirical investigations demonstrate the effectiveness of our proposed HPO algorithm in situations where the typical procedure fails severely. Keywords: Machine Learning: ML: Causality Machine Learning: ML: Hyperparameter optimization Machine Learning: ML: Multi-armed bandits Uncertainty in AI: UAI: Causality, structural causal models and causal inference},
  archive   = {C_IJCAI},
  author    = {Yuta Saito and Masahiro Nomura},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/537},
  month     = {8},
  pages     = {4860-4867},
  title     = {Hyperparameter optimization can even be harmful in off-policy learning and how to deal with it},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Partial optimal transport based out-of-distribution
detection for open-set semi-supervised learning. <em>IJCAI</em>,
4851–4859. (<a href="https://doi.org/10.24963/ijcai.2024/536">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Semi-supervised learning (SSL) is a machine learning paradigm that utilizes both labeled and unlabeled data to enhance the performance of learning tasks. However, SSL methods operate under the assumption that the label spaces of labeled and unlabeled data are identical, which may not hold in open-world applications. In such scenarios, the unlabeled data may contain novel categories that were not presented in the labeled training data, essentially outliers. This specific challenge is referred to as the Open-set Semi-supervised Learning (OSSL) problem. In OSSL, a pivotal concern is the detection of out-of-distribution (OOD) samples within unlabeled data. Existing methods often struggle to provide effective OOD detection strategies, especially when dealing with datasets comprising a large number of training categories. In response to this challenge, we model the OOD detection problem in OSSL as a partial optimal transport (POT) problem. With POT theory, we devise a mass score function to measure the likelihood of a sample being an outlier, which enables a binary classifier for OOD detection. Further, we put forward an OOD loss, enabling the seamless integration of the binary classifier and off-the-shelf SSL methods under OSSL settings, all within an end-to-end training framework. We extensively evaluate our proposal under various datasets and OSSL configurations, consistently demonstrating the superior performance of our proposal. Codes are available at https://github.com/ryl0427/Code_for_POT_OSSL. Keywords: Machine Learning: ML: Semi-supervised learning Machine Learning: ML: Optimization Machine Learning: ML: Robustness},
  archive   = {C_IJCAI},
  author    = {Yilong Ren and Chuanwen Feng and Xike Xie and S. Kevin Zhou},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/536},
  month     = {8},
  pages     = {4851-4859},
  title     = {Partial optimal transport based out-of-distribution detection for open-set semi-supervised learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic weighted graph fusion for deep multi-view
clustering. <em>IJCAI</em>, 4842–4850. (<a
href="https://doi.org/10.24963/ijcai.2024/535">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {By exploring complex graph information hidden in data from multiple views, multi-view clustering based on graph neural network significantly enhances the clustering performance and has drawn increasing attention in recent years. Although considerable progress has been made, most existing GNN based MVC models merely consider the explicit presence of graph structure in raw data and ignore that latent graphs of different views also provide specific information for the clustering task. We propose dynamic weighted graph fusion for deep multi-view clustering (DFMVC) to address this issue. Specifically, DFMVC learns embedded features via deep autoencoders and then constructs latent graphs for each individual view. Then, it concatenates the embedded features of all views to form a global feature to leverage complementary information, as well as generates a fusion graph via combining all latent graphs to accurately capture the topological information among samples. Based on the informative fusion graph and global features, the graph convolution module is adopted to derive a representation with global comprehensive information, which is further used to generate pseudo-label information. In a self-supervised manner, such information guides each view to dynamically learn discriminative features and latent graphs. Extensive experimental results demonstrate the efficacy of DFMVC. Keywords: Machine Learning: ML: Multi-view learning Machine Learning: ML: Clustering},
  archive   = {C_IJCAI},
  author    = {Yazhou Ren and Jingyu Pu and Chenhang Cui and Yan Zheng and Xinyue Chen and Xiaorong Pu and Lifang He},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/535},
  month     = {8},
  pages     = {4842-4850},
  title     = {Dynamic weighted graph fusion for deep multi-view clustering},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dual expert distillation network for generalized zero-shot
learning. <em>IJCAI</em>, 4833–4841. (<a
href="https://doi.org/10.24963/ijcai.2024/534">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Zero-shot learning has consistently yielded remarkable progress via modeling nuanced one-to-one visual-attribute correlation. Existing studies resort to refining a uniform mapping function to align and correlate the sample regions and subattributes, ignoring two crucial issues: 1) the inherent asymmetry of attributes; and 2) the unutilized channel information. This paper addresses these issues by introducing a simple yet effective approach, dubbed Dual Expert Distillation Network (DEDN), where two experts are dedicated to coarse- and fine-grained visual-attribute modeling, respectively. Concretely, one coarse expert, namely cExp, has a complete perceptual scope to coordinate visual-attribute similarity metrics across dimensions, and moreover, another fine expert, namely fExp, consists of multiple specialized subnetworks, each corresponds to an exclusive set of attributes. Two experts cooperatively distill from each other to reach a mutual agreement during training. Meanwhile, we further equip DEDN with a newly designed backbone network, i.e., Dual Attention Network (DAN), which incorporates both region and channel attention information to fully exploit and leverage visual semantic knowledge. Extensive experiments on various benchmark datasets indicate a new state-of-the-art. The code is available at github.com/zjrao/DEDN. Keywords: Machine Learning: ML: Cost-sensitive learning Machine Learning: ML: Few-shot learning},
  archive   = {C_IJCAI},
  author    = {Zhijie Rao and Jingcai Guo and Xiaocheng Lu and Jingming Liang and Jie Zhang and Haozhao Wang and Kang Wei and Xiaofeng Cao},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/534},
  month     = {8},
  pages     = {4833-4841},
  title     = {Dual expert distillation network for generalized zero-shot learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). What makes models compositional? A theoretical view.
<em>IJCAI</em>, 4824–4832. (<a
href="https://doi.org/10.24963/ijcai.2024/533">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Compositionality is thought to be a key component of language, and various compositional benchmarks have been developed to empirically probe the compositional generalization of existing sequence processing models. These benchmarks often highlight failures of existing models, but it is not clear why these models fail in this way. In this paper, we seek to theoretically understand the role the compositional structure of the models plays in these failures and how this structure relates to their expressivity and sample complexity. We propose a general neuro-symbolic definition of compositional functions and their compositional complexity. We then show how various existing general and special purpose sequence processing models (such as recurrent, convolution and attention-based ones) fit this definition and use it to analyze their compositional complexity. Finally, we provide theoretical guarantees for the expressivity and systematic generalization of compositional models that explicitly depend on our proposed definition and highlighting factors which drive poor empirical performance. Keywords: Machine Learning: ML: Neuro-symbolic methods Machine Learning: ML: Learning theory Machine Learning: ML: Theory of deep learning Natural Language Processing: NLP: Interpretability and analysis of models for NLP},
  archive   = {C_IJCAI},
  author    = {Parikshit Ram and Tim Klinger and Alexander G. Gray},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/533},
  month     = {8},
  pages     = {4824-4832},
  title     = {What makes models compositional? a theoretical view},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Let’s start over: Retraining with selective samples for
generalized category discovery. <em>IJCAI</em>, 4815–4823. (<a
href="https://doi.org/10.24963/ijcai.2024/532">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Generalized Category Discovery (GCD) presents a realistic and challenging problem in open-world learning. Given a par- tially labeled dataset, GCD aims to categorize unlabeled data by leveraging visual knowledge from the labeled data, where the unlabeled data includes both known and unknown classes. Existing methods based on parametric/non-parametric classi- fiers attempt to generate pseudo-labels/relationships for the unlabeled data to enhance representation learning. However, the lack of ground-truth labels for novel classes often leads to noisy pseudo-labels/relationships, resulting in suboptimal representation learning. This paper introduces a novel method using Nearest Neighbor Distance-aware Label Consistency sample selection. It creates class-consistent subsets for novel class sample clusters from the current GCD method, acting as “pseudo-labeled sets” to mitigate representation bias. We propose progressive supervised representation learning with selected samples to optimize the trade-off between quantity and purity in each subset. Our method is versatile and appli- cable to various GCD methods, whether parametric or non- parametric. We conducted extensive experiments on multiple generic and fine-grained image classification datasets to eval- uate the effectiveness of our approach. The results demon- strate the superiority of our method in achieving improved performance in generalized category discovery tasks. Keywords: Machine Learning: ML: Clustering Computer Vision: CV: Transfer, low-shot, semi- and un- supervised learning Machine Learning: ML: Classification Computer Vision: CV: Recognition (object detection, categorization)},
  archive   = {C_IJCAI},
  author    = {Zhimao Peng and Enguang Wang and Xialei Liu and Ming-Ming Cheng},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/532},
  month     = {8},
  pages     = {4815-4823},
  title     = {Let’s start over: Retraining with selective samples for generalized category discovery},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FedPFT: Federated proxy fine-tuning of foundation models.
<em>IJCAI</em>, 4806–4814. (<a
href="https://doi.org/10.24963/ijcai.2024/531">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Adapting Foundation Models (FMs) for down- stream tasks through Federated Learning (FL) emerges a promising strategy for protecting data privacy and valuable FMs. Existing methods fine- tune FM by allocating sub-FM to clients in FL, however, leading to suboptimal performance due to insufficient tuning and inevitable error accumula- tions of gradients. In this paper, we propose Feder- ated Proxy Fine-Tuning (FedPFT), a novel method enhancing FMs adaptation in downstream tasks through FL by two key modules. First, the sub-FM construction module employs a layer-wise com- pression approach, facilitating comprehensive FM fine-tuning across all layers by emphasizing those crucial neurons. Second, the sub-FM alignment module conducts a two-step distillations—layer- level and neuron-level—before and during FL fine- tuning respectively, to reduce error of gradient by accurately aligning sub-FM with FM under theo- retical guarantees. Experimental results on seven commonly used datasets (i.e., four text and three vi- sion) demonstrate the superiority of FedPFT. Our code is available at https://github.com/pzp-dzd/FedPFT. Keywords: Machine Learning: ML: Federated learning Machine Learning: ML: Trustworthy machine learning Multidisciplinary Topics and Applications: MTA: Security and privacy},
  archive   = {C_IJCAI},
  author    = {Zhaopeng Peng and Xiaoliang Fan and Yufan Chen and Zheng Wang and Shirui Pan and Chenglu Wen and Ruisheng Zhang and Cheng Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/531},
  month     = {8},
  pages     = {4806-4814},
  title     = {FedPFT: Federated proxy fine-tuning of foundation models},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mean aggregator is more robust than robust aggregators under
label poisoning attacks. <em>IJCAI</em>, 4797–4805. (<a
href="https://doi.org/10.24963/ijcai.2024/530">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Robustness to malicious attacks is of paramount importance for distributed learning. Existing works often consider the classical Byzantine attacks model, which assumes that some workers can send arbitrarily malicious messages to the server and disturb the aggregation steps of the distributed learning process. To defend against such worst-case Byzantine attacks, various robust aggregators have been proven effective and much superior to the often-used mean aggregator. In this paper, we show that robust aggregators are too conservative for a class of weak but practical malicious attacks, as known as label poisoning attacks, where the sample labels of some workers are poisoned. Surprisingly, we are able to show that the mean aggregator is more robust than the state-of-the-art robust aggregators in theory, given that the distributed data are sufficiently heterogeneous. In fact, the learning error of the mean aggregator is proven to be optimal in order. Experimental results corroborate our theoretical findings, demonstrating the superiority of the mean aggregator under label poisoning attacks. Keywords: Machine Learning: ML: Federated learning Machine Learning: ML: Optimization},
  archive   = {C_IJCAI},
  author    = {Jie Peng and Weiyu Li and Qing Ling},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/530},
  month     = {8},
  pages     = {4797-4805},
  title     = {Mean aggregator is more robust than robust aggregators under label poisoning attacks},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cross-view diversity embedded consensus learning for
multi-view clustering. <em>IJCAI</em>, 4788–4796. (<a
href="https://doi.org/10.24963/ijcai.2024/529">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-view clustering (MVC) has garnered significant attention in recent studies. In this paper, we propose a novel MVC method, named CCL-MVC. The novel method constructs a cross-order neighbor tensor of multi-view data to recover a low-rank essential tensor, preserves noise-free, comprehensive, and complementary cross-order relationships among the samples. Furthermore, it constructs a consensus representation matrix by fusing the low-rank essential tensor with auto-adjusted cross-view diversity embedding, fully exploiting both consensus and discriminative information of the data. An effective optimization algorithm is developed, which is theoretically guaranteed to converge. Extensive experimental results confirm the effectiveness of the proposed method. Keywords: Machine Learning: ML: Multi-view learning Machine Learning: ML: Clustering},
  archive   = {C_IJCAI},
  author    = {Chong Peng and Kai Zhang and Yongyong Chen and Chenglizhao Chen and Qiang Cheng},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/529},
  month     = {8},
  pages     = {4788-4796},
  title     = {Cross-view diversity embedded consensus learning for multi-view clustering},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Probabilistically robust watermarking of neural networks.
<em>IJCAI</em>, 4778–4787. (<a
href="https://doi.org/10.24963/ijcai.2024/528">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As deep learning (DL) models are widely and effectively used in Machine Learning as a Service (MLaaS) platforms, there is a rapidly growing interest in DL watermarking techniques that can be used to confirm the ownership of a particular model. Unfortunately, these methods usually produce watermarks susceptible to model stealing attacks. In our research, we introduce a novel trigger set-based watermarking approach that demonstrates resilience against functionality stealing attacks, particularly those involving extraction and distillation. Our approach does not require additional model training and can be applied to any model architecture. The key idea of our method is to compute the trigger set, which is transferable between the source model and the set of proxy models with a high probability. In our experimental study, we show that if the probability of the set being transferable is reasonably high, it can be effectively used for ownership verification of the stolen model. We evaluate our method on multiple benchmarks and show that our approach outperforms current state-of-the-art watermarking techniques in all considered experimental setups. Keywords: Machine Learning: ML: Adversarial machine learning AI Ethics, Trust, Fairness: ETF: Safety and robustness AI Ethics, Trust, Fairness: ETF: Trustworthy AI Uncertainty in AI: UAI: Applications},
  archive   = {C_IJCAI},
  author    = {Mikhail Pautov and Nikita Bogdanov and Stanislav Pyatkin and Oleg Rogov and Ivan Oseledets},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/528},
  month     = {8},
  pages     = {4778-4787},
  title     = {Probabilistically robust watermarking of neural networks},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A prior-information-guided residual diffusion model for
multi-modal PET synthesis from MRI. <em>IJCAI</em>, 4769–4777. (<a
href="https://doi.org/10.24963/ijcai.2024/527">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Alzheimer&#39;s disease (AD) leads to abnormalities in various biomarkers (i.e., amyloid-β and tau proteins), which makes PET imaging (which can detect these biomarkers) essential in AD diagnosis. However, the high radiation risk of PET imaging limits its scanning number within a short period, presenting challenges to the joint multi-biomarker diagnosis of AD. In this paper, we propose a novel unified model to simultaneously synthesize multi-modal PET images from MRI, to achieve low-cost and time-efficient joint multi-biomarker diagnosis of AD. Specifically, we incorporate residual learning into the diffusion model to emphasize inter-domain differences between PET and MRI, thereby forcing each modality to maximally reconstruct its modality-specific details. Furthermore, we leverage prior information, such as age and gender, to guide the diffusion model in synthesizing PET images with semantic consistency, enhancing their diagnostic value. Additionally, we develop an intra-domain difference loss to ensure that the intra-domain differences among synthesized PET images closely match those among real PET images, promoting more accurate synthesis, especially at the modality-specific information. Extensive experiments conducted on the ADNI dataset demonstrate that our method achieves superior performance both quantitatively and qualitatively compared to the state-of-the-art methods. All codes for this study have been uploaded to GitHub (https://github.com/Ouzaixin/ResDM). Keywords: Machine Learning: ML: Generative models Machine Learning: ML: Deep learning architectures Machine Learning: ML: Multi-modal learning Machine Learning: ML: Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Zaixin Ou and Caiwen Jiang and Yongsheng Pan and Yuanwang Zhang and Zhiming Cui and Dinggang Shen},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/527},
  month     = {8},
  pages     = {4769-4777},
  title     = {A prior-information-guided residual diffusion model for multi-modal PET synthesis from MRI},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FedGCS: A generative framework for efficient client
selection in federated learning via gradient-based optimization.
<em>IJCAI</em>, 4760–4768. (<a
href="https://doi.org/10.24963/ijcai.2024/526">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Federated Learning faces significant challenges in statistical and system heterogeneity, along with high energy consumption, necessitating efficient client selection strategies. Traditional approaches, including heuristic and learning-based methods, fall short of addressing these complexities holistically. In response, we propose FedGCS, a novel generative client selection framework that innovatively recasts the client selection process as a generative task. Drawing inspiration from the methodologies used in large language models, FedGCS efficiently encodes abundant decision-making knowledge within a continuous representation space, enabling efficient gradient-based optimization to search for optimal client selection that will be finally output via generation. The framework comprises four steps: (1) automatic collection of diverse “selection-score” pair data using classical client selection methods; (2) training an encoder-evaluator-decoder framework on this data to construct a continuous representation space; (3) employing gradient-based optimization in this space for optimal client selection; (4) generating the final optimal client selection via using beam search for the well-trained decoder. FedGCS outperforms traditional methods by being more comprehensive, generalizable, and efficient, simultaneously optimizing for model performance, latency, and energy consumption. The effectiveness of FedGCS is proven through extensive experimental analyses. Keywords: Machine Learning: ML: Federated learning Data Mining: DM: Applications Data Mining: DM: Other Machine Learning: ML: Applications},
  archive   = {C_IJCAI},
  author    = {Zhiyuan Ning and Chunlin Tian and Meng Xiao and Wei Fan and Pengyang Wang and Li Li and Pengfei Wang and Yuanchun Zhou},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/526},
  month     = {8},
  pages     = {4760-4768},
  title     = {FedGCS: A generative framework for efficient client selection in federated learning via gradient-based optimization},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ROME: Robust multi-modal density estimator. <em>IJCAI</em>,
4751–4759. (<a href="https://doi.org/10.24963/ijcai.2024/525">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The estimation of probability density functions is a fundamental problem in science and engineering. However, common methods such as kernel density estimation (KDE) have been demonstrated to lack robustness, while more complex methods have not been evaluated in multi-modal estimation problems. In this paper, we present ROME (RObust Multi-modal Estimator), a non-parametric approach for density estimation which addresses the challenge of estimating multi-modal, non-normal, and highly correlated distributions. ROME utilizes clustering to segment a multi-modal set of samples into multiple uni-modal ones and then combines simple KDE estimates obtained for individual clusters in a single multi-modal estimate. We compared our approach to state-of-the-art methods for density estimation as well as ablations of ROME, showing that it not only outperforms established methods but is also more robust to a variety of distributions. Our results demonstrate that ROME can overcome the issues of over-fitting and over-smoothing exhibited by other estimators. Keywords: Machine Learning: ML: Evaluation Machine Learning: ML: Probabilistic machine learning},
  archive   = {C_IJCAI},
  author    = {Anna Mészáros and Julian F. Schumann and Javier Alonso-Mora and Arkady Zgonnikov and Jens Kober},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/525},
  month     = {8},
  pages     = {4751-4759},
  title     = {ROME: Robust multi-modal density estimator},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning label-specific multiple local metrics for
multi-label classification. <em>IJCAI</em>, 4742–4750. (<a
href="https://doi.org/10.24963/ijcai.2024/524">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-label metric learning serve as an effective strategy to facilitate multi-label classification, aiming to learn better similarity metrics from multi-label examples. Existing multi-label metric learning approaches learn consistent metrics across all multi-label instances in the label space. However, such consistent metric learning approaches are suboptimal as they neglect the nonlinear distribution characteristics of multi-label instances. In this paper, we present LSMM, a label-specific multi-metric learning framework for multi-label classification, where nonlinear distribution characteristics of multi-label examples are considered by learning label-specific multiple local metrics for different instances on the shoulder of a global one. Specifically, multi-label instances within each label space can be divided into several disjoint partitions through either semantic-based or cluster-based partition strategies, in each of which a local metric is trained to separate the instances locally. Besides, a global metric is introduced to implicitly exploit high-order label correlations across all labels. The combination of the global metric and label-specific local metrics is utilized to measure the semantic similarities between multi-label instances in each label space, under which similar intra-class instances are pushed closer and inter-class instances are pulled apart. Comprehensive experiments on benchmark multi-label data sets validate the superiority of LSMM in learning effective similarity metrics for multi-label classification. Keywords: Machine Learning: ML: Classification Machine Learning: ML: Multi-label learning},
  archive   = {C_IJCAI},
  author    = {Jun-Xiang Mao and Jun-Yi Hang and Min-Ling Zhang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/524},
  month     = {8},
  pages     = {4742-4750},
  title     = {Learning label-specific multiple local metrics for multi-label classification},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning embeddings for sequential tasks using population of
agents. <em>IJCAI</em>, 4733–4741. (<a
href="https://doi.org/10.24963/ijcai.2024/523">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present an information-theoretic framework to learn fixed-dimensional embeddings for tasks in reinforcement learning. We leverage the idea that two tasks are similar if observing an agent&#39;s performance on one task reduces our uncertainty about its performance on the other. This intuition is captured by our information-theoretic criterion which uses a diverse agent population as an approximation for the space of agents to measure similarity between tasks in sequential decision-making settings. In addition to qualitative assessment, we empirically demonstrate the effectiveness of our techniques based on task embeddings by quantitative comparisons against strong baselines on two application scenarios: predicting an agent&#39;s performance on a new task by observing its performance on a small quiz of tasks, and selecting tasks with desired characteristics from a given set of options. Keywords: Machine Learning: ML: Reinforcement learning Machine Learning: ML: Multi-task and transfer learning Machine Learning: ML: Representation learning},
  archive   = {C_IJCAI},
  author    = {Mridul Mahajan and Georgios Tzannetos and Goran Radanovic and Adish Singla},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/523},
  month     = {8},
  pages     = {4733-4741},
  title     = {Learning embeddings for sequential tasks using population of agents},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deciphering the projection head: Representation evaluation
self-supervised learning. <em>IJCAI</em>, 4724–4732. (<a
href="https://doi.org/10.24963/ijcai.2024/522">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Self-supervised learning (SSL) aims to learn the intrinsic features of data without labels. Despite the diverse SSL architectures, the projection head always plays an important role in improving downstream task performance. In this study, we systematically investigate the role of the projection head in SSL. We find that the projection head targets the uniformity aspect, which maps samples into uniform distribution and enables the encoder to focus on extracting semantic features. Drawing on this insight, we propose a Representation Evaluation Design (RED) in SSL models in which a shortcut connection between the representation and the projection vectors is built. Our extensive experiments with different architectures (including SimCLR, MoCo-V2, and SimSiam) on various datasets demonstrate that the RED-SSL consistently outperforms their baseline counterparts in downstream tasks. Furthermore, the RED-SSL learned representations exhibit superior robustness to previously unseen augmentations and out-of-distribution data. Keywords: Machine Learning: ML: Self-supervised Learning Machine Learning: ML: Explainable/Interpretable machine learning Machine Learning: ML: Representation learning},
  archive   = {C_IJCAI},
  author    = {Jiajun Ma and Tianyang Hu and Wenjia Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/522},
  month     = {8},
  pages     = {4724-4732},
  title     = {Deciphering the projection head: Representation evaluation self-supervised learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Common-individual semantic fusion for multi-view multi-label
learning. <em>IJCAI</em>, 4715–4723. (<a
href="https://doi.org/10.24963/ijcai.2024/521">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In Multi-View Multi-Label Learning, each instance is described by several heterogeneous features and associated with multiple valid labels simultaneously. Existing methods mainly focus on leveraging feature-level view fusion to capture a common representation for multi-label classifier induction. In this paper, we take a new perspective and propose a new semantic-level fusion model named Common-Individual Semantic Fusion Multi-View Multi-Label Learning Method (CISF). Different from previous feature-level fusion model, our proposed method directly focuses on semantic-level view fusion and simultaneously take both the common semantic across different views and the individual semantic of each specific view into consideration. Specifically, we first assume each view involves some common semantic labels while owns a few exclusive semantic labels. Then, the common and exclusive semantic labels are separately forced to be consensus and diverse to excavate the consistences and complementarities among different views. Afterwards, we introduce the low-rank and sparse constraint to highlight the label co-occurrence relationship of common semantics and the view-specific expression of individual semantics. We provide theoretical guarantee for the strict convexity of our method by properly setting parameters. Extensive experiments on various data sets have verified the superiority of our method. Keywords: Machine Learning: ML: Multi-label learning Machine Learning: ML: Classification Machine Learning: ML: Multi-view learning Machine Learning: ML: Weakly supervised learning},
  archive   = {C_IJCAI},
  author    = {Gengyu Lyu and Weiqi Kang and Haobo Wang and Zheng Li and Zhen Yang and Songhe Feng},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/521},
  month     = {8},
  pages     = {4715-4723},
  title     = {Common-individual semantic fusion for multi-view multi-label learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Rank and align: Towards effective source-free graph domain
adaptation. <em>IJCAI</em>, 4706–4714. (<a
href="https://doi.org/10.24963/ijcai.2024/520">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph neural networks (GNNs) have achieved impressive performance in graph domain adaptation. However, extensive source graphs could be unavailable in real-world scenarios due to privacy and storage concerns. To this end, we investigate an underexplored yet practical problem of source-free graph domain adaptation, which transfers knowledge from source models instead of source graphs to a target domain. To solve this problem, we introduce a novel GNN-based approach called Rank and Align (RNA), which ranks graph similarities with spectral seriation for robust semantics learning, and aligns inharmonic graphs with harmonic graphs which close to the source domain for subgraph extraction. In particular, to overcome label scarcity, we employ the spectral seriation algorithm to infer the robust pairwise rankings, which can guide semantic learning using a similarity learning objective. To depict distribution shifts, we utilize spectral clustering and the silhouette coefficient to detect harmonic graphs, which the source model can easily classify. To reduce potential domain discrepancy, we extract domain-invariant subgraphs from inharmonic graphs by an adversarial edge sampling process, which guides the invariant learning of GNNs. Extensive experiments on several benchmark datasets demonstrate the effectiveness of our proposed RNA. Keywords: Machine Learning: ML: Multi-task and transfer learning Data Mining: DM: Mining graphs},
  archive   = {C_IJCAI},
  author    = {Junyu Luo and Zhiping Xiao and Yifan Wang and Xiao Luo and Jingyang Yuan and Wei Ju and Langechuan Liu and Ming Zhang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/520},
  month     = {8},
  pages     = {4706-4714},
  title     = {Rank and align: Towards effective source-free graph domain adaptation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Simple contrastive multi-view clustering with data-level
fusion. <em>IJCAI</em>, 4697–4705. (<a
href="https://doi.org/10.24963/ijcai.2024/519">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Previous deep multi-view clustering methods usually design un-shared encoders to explore the cluster information among multi-view data, but they are difficult to customize the encoders for individual views and easily increase information loss. To address these issues, we propose a simple yet effective contrastive multi-view clustering framework. Specifically, different from using feature-level fusion in previous methods, we first propose a data-level fusion method to fuse multi-view information, which produces a fused data to replace all views and thus avoids customizing networks for different views. Then, we simulate the data noise and unavailability in multiple views to design two kinds of data augmentation for the fused data, making a shared encoder with simple contrastive learning to learn robust features and achieve the interaction across views. As a result, our method is a general framework and we base on it to conduct feature clustering and end-to-end clustering. Extensive experiments demonstrate that our method can explore the discriminative information in multi-view data and achieve superior clustering performance. Keywords: Machine Learning: ML: Multi-view learning Machine Learning: ML: Clustering Machine Learning: ML: Multi-modal learning Machine Learning: ML: Self-supervised Learning},
  archive   = {C_IJCAI},
  author    = {Caixuan Luo and Jie Xu and Yazhou Ren and Junbo Ma and Xiaofeng Zhu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/519},
  month     = {8},
  pages     = {4697-4705},
  title     = {Simple contrastive multi-view clustering with data-level fusion},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The orthogonality of weight vectors: The key characteristics
of normalization and residual connections. <em>IJCAI</em>, 4687–4695.
(<a href="https://doi.org/10.24963/ijcai.2024/518">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Normalization and residual connections find extensive application within the intricate architecture of deep neural networks, contributing significantly to their heightened performance. Nevertheless, the precise factors responsible for this elevated performance have remained elusive. Our theoretical investigations have unveiled a noteworthy revelation: the utilization of normalization and residual connections results in an enhancement of the orthogonality within the weight vectors of deep neural networks. This, in turn, induces the Gram matrix of neural network weights to exhibit a pronounced tendency towards strict diagonal dominance, thereby amplifying the neural network&#39;s capacity for feature learning. Meanwhile, we have designed the parameters independence index (PII) to precisely characterize the orthogonality of parameter vectors. In tandem with our theoretical findings, we undertook empirical validations through experiments conducted on prevalent network models, including fully connected networks (FNNs), convolutional neural networks (CNNs), Transformers, pre-trained language models(PLMs) and large language models (LLMs) composed of Transformers. Finally, we have found that a fine-tuning technique (LoRA) preserves the orthogonality of parameter vectors, a revelation that carries importance within the framework of fine-tuning techniques for LLMs. Keywords: Machine Learning: ML: Explainable/Interpretable machine learning Machine Learning: ML: Deep learning architectures},
  archive   = {C_IJCAI},
  author    = {Zhixing Lu and Yuanyuan Sun and Zhihao Yang and Qin Zhou and Hongfei Lin},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/518},
  month     = {8},
  pages     = {4687-4695},
  title     = {The orthogonality of weight vectors: The key characteristics of normalization and residual connections},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Implicit prompt learning for image denoising.
<em>IJCAI</em>, 4678–4686. (<a
href="https://doi.org/10.24963/ijcai.2024/517">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, various deep denoising methods have been proposed to solve the insufficient feature problem in image denoising. These methods can be mainly classified into two categories: (1) Injecting learnable tensors into denoising backbone to supplement feature, which is effective to some extent but may cause serious over-fitting. (2) Using diverse natural images from large image datasets to synthesize noisy images and pre-train denoising models, which can bring model generalization but require large model size and expensive training costs. To address these issues, this paper proposes Implicit Prompt Learning for Image Denoising (IPLID) method to flexibly generate adaptive prompts without meticulously designing them. Specifically, we first introduce an efficient Linear Prompt (LP) block with ultra-few parameters to produce dynamic prompts for both different stages and samples in denoising procedure. We further propose an efficient Compact Feature Fusion (CFF) block to process previous multi-level prompted denoising feature to reconstruct the denoising images. Finally, to further efficiently and effectively produce satisfactory prompt and denoising performance, a Gradient Accumulation (GA) learning scheme is proposed. Experiments on multiple benchmarks showed that the proposed IPLID achieves competitive results with only 1 percent of pre-trained backbone parameters, outperforming classical denoising methods in both efficiency and quality of restored images. Keywords: Machine Learning: ML: Knowledge-aided learning},
  archive   = {C_IJCAI},
  author    = {Yao Lu and Bo Jiang and Guangming Lu and Bob Zhang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/517},
  month     = {8},
  pages     = {4678-4686},
  title     = {Implicit prompt learning for image denoising},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Alleviating imbalanced pseudo-label distribution:
Self-supervised multi-source domain adaptation with label-specific
confidence. <em>IJCAI</em>, 4669–4677. (<a
href="https://doi.org/10.24963/ijcai.2024/516">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The existing self-supervised Multi-Source Domain Adaptation (MSDA) methods often suffer an imbalanced characteristic among the distribution of pseudo-labels. Such imbalanced characteristic results in many labels with too many or too few pseudo-labeled samples on the target domain, referred to as easy-to-learn label and hard-to-learn label, respectively. Both of these labels hurt the generalization performance on the target domain. To alleviate this problem, in this paper we propose a novel multi-source domain adaptation method, namely Self-Supervised multi-Source Domain Adaptation with Label-specific Confidence (S3DA-LC). Specifically, we estimate the label-specific confidences, i.e., the learning difficulties of labels, and adopt them to generate the pseudo-labels for target samples, enabling to simultaneously constrain and enrich the pseudo supervised signals for easy-to-learn and hard-to-learn labels. We evaluate S3DA-LC on several benchmark datasets, indicating its superior performance compared with the existing MSDA baselines. Keywords: Machine Learning: ML: Multi-task and transfer learning Machine Learning: ML: Classification Machine Learning: ML: Self-supervised Learning},
  archive   = {C_IJCAI},
  author    = {Shuai Lü and Meng Kang and Ximing Li},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/516},
  month     = {8},
  pages     = {4669-4677},
  title     = {Alleviating imbalanced pseudo-label distribution: Self-supervised multi-source domain adaptation with label-specific confidence},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LEAP: Optimization hierarchical federated learning on
non-IID data with coalition formation game. <em>IJCAI</em>, 4660–4668.
(<a href="https://doi.org/10.24963/ijcai.2024/515">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Although Hierarchical Federated Learning (HFL) utilizes edge servers (ESs) to alleviate communication burdens, its model performance will be degraded by non-IID data and limited communication resources. Current works often assume that data is uniformly distributed, which however contradicts the heterogeneity of IoT. Solutions involving additional model training to check the data distribution inevitably increase computational costs and the risk of privacy leakage. The challenges in solving these issues are how to reduce the impact of non-IID data without involving raw data, and how to rationalize the communication resource allocation for addressing straggler problem. To tackle these challenges, we propose a novel optimization method based on coaLition formation gamE and grAdient Projection, called LEAP. Specifically, we combine edge data distribution with coalition formation game innovatively to adjust the correlations between clients and ESs dynamically, ensuring optimal correlations. We further capture the client heterogeneity to achieve the rational bandwidth allocation from coalition perception and determine the optimal transmission power within specified delay constraints at the client level. Experimental results on four real datasets show that LEAP is able to achieve 20.62% improvement in model accuracy compared to the state-of-the-art baselines. Moreover, LEAP effectively reduces transmission energy consumption by at least about 2.24 times. Keywords: Machine Learning: ML: Evaluation Agent-based and Multi-agent Systems: MAS: Resource allocation Game Theory and Economic Paradigms: GTEP: Mechanism design Machine Learning: ML: Game Theory},
  archive   = {C_IJCAI},
  author    = {Jianfeng Lu and Yue Chen and Shuqin Cao and Longbiao Chen and Wei Wang and Yun Xin},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/515},
  month     = {8},
  pages     = {4660-4668},
  title     = {LEAP: Optimization hierarchical federated learning on non-IID data with coalition formation game},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Revisiting neural networks for continual learning: An
architectural perspective. <em>IJCAI</em>, 4651–4659. (<a
href="https://doi.org/10.24963/ijcai.2024/514">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Efforts to overcome catastrophic forgetting have primarily centered around developing more effective Continual Learning (CL) methods. In contrast, less attention was devoted to analyzing the role of network architecture design (e.g., network depth, width, and components) in contributing to CL. This paper seeks to bridge this gap between network architecture design and CL, and to present a holistic study on the impact of network architectures on CL. This work considers architecture design at the network scaling level, i.e., width and depth, and also at the network components, i.e., skip connections, global pooling layers, and down-sampling. In both cases, we first derive insights through systematically exploring how architectural designs affect CL. Then, grounded in these insights, we craft a specialized search space for CL and further propose a simple yet effective ArchCraft method to steer a CL-friendly architecture, namely, this method recrafts AlexNet/ResNet into AlexAC/ResAC. Experimental validation across various CL settings and scenarios demonstrates that improved architectures are parameter-efficient, achieving state-of-the-art performance of CL while being 86%, 61%, and 97% more compact in terms of parameters than the naive CL architecture in Task IL and Class IL. Code is available at https://github.com/byyx666/ArchCraft. Keywords: Machine Learning: ML: Incremental learning Computer Vision: CV: Machine learning for vision},
  archive   = {C_IJCAI},
  author    = {Aojun Lu and Tao Feng and Hangjie Yuan and Xiaotian Song and Yanan Sun},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/514},
  month     = {8},
  pages     = {4651-4659},
  title     = {Revisiting neural networks for continual learning: An architectural perspective},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Self-supervised weighted information bottleneck for
multi-view clustering. <em>IJCAI</em>, 4643–4650. (<a
href="https://doi.org/10.24963/ijcai.2024/513">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-view clustering (MVC) is a long-standing topic in machine learning and data mining community, focusing on investigating and utilizing the relationships among views for final consistent data cluster structure discovery. Generally, weighted MVC is one of the popular methods working by learning and applying the view weight/importance on each view for fully exploring the complementary information across views. However, most existing weighted MVCs only consider the quality of each view, ignoring the vital role of pseudo label self-supervision information in weight learning. In this work, we propose a novel self-supervised weighted information bottleneck (SWIB) method for solving the multi-view clustering problem. It combines the weighted information from different views based on information bottleneck theory, and the view weight learning mechanism is newly designed by simultaneously taking into accounting both the quality of view-contained information and the self-supervised information on the data partition of each view. Experimental results on multi-view text, multi-feature image, multi-angle video, and multi-modal text-image dataset as well as large-scale datasets show the superiority of the SWIB method. To our knowledge, this is the first work incorporating the self-supervised learning into weighted multi-view clustering. Keywords: Machine Learning: ML: Multi-view learning Machine Learning: ML: Clustering Machine Learning: ML: Multi-modal learning Machine Learning: ML: Unsupervised learning},
  archive   = {C_IJCAI},
  author    = {Zhengzheng Lou and Chaoyang Zhang and Hang Xue and Yangdong Ye and Qinglei Zhou and Shizhe Hu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/513},
  month     = {8},
  pages     = {4643-4650},
  title     = {Self-supervised weighted information bottleneck for multi-view clustering},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A behavior-aware approach for deep reinforcement learning in
non-stationary environments without known change points. <em>IJCAI</em>,
4634–4642. (<a href="https://doi.org/10.24963/ijcai.2024/512">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep reinforcement learning is used in various domains, but usually under the assumption that the environment has stationary conditions like transitions and state distributions. When this assumption is not met, performance suffers. For this reason, tracking continuous environmental changes and adapting to unpredictable conditions is challenging yet crucial because it ensures that systems remain reliable and flexible in practical scenarios. Our research introduces Behavior-Aware Detection and Adaptation (BADA), an innovative framework that merges environmental change detection with behavior adaptation. The key inspiration behind our method is that policies exhibit different global behaviors in changing environments. Specifically, environmental changes are identified by analyzing variations between behaviors using Wasserstein distances without manually set thresholds. The model adapts to the new environment through behavior regularization based on the extent of changes. The results of a series of experiments demonstrate better performance relative to several current algorithms. This research also indicates significant potential for tackling this long-standing challenge. Keywords: Machine Learning: ML: Reinforcement learning},
  archive   = {C_IJCAI},
  author    = {Zihe Liu and Jie Lu and Guangquan Zhang and Junyu Xuan},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/512},
  month     = {8},
  pages     = {4634-4642},
  title     = {A behavior-aware approach for deep reinforcement learning in non-stationary environments without known change points},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An NCDE-based framework for universal representation
learning of time series. <em>IJCAI</em>, 4623–4633. (<a
href="https://doi.org/10.24963/ijcai.2024/511">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Exploiting self-supervised learning (SSL) to extract the universal representations of time series could not only capture the natural properties of time series but also offer huge help to the downstream tasks. Nevertheless, existing time series representation learning (TSRL) methods face challenges in attaining universality. Indeed, existing methods relying solely on one SSL strategy (either contrastive learning (CL) or generative) often fall short in capturing rich semantic information for various downstream tasks. Moreover, time series exhibit diverse distributions and inherent characteristics, particularly with the common occurrence of missing values, posing a notable challenge for existing backbones in effectively handling such diverse time series data. To bridge these gaps, we propose CTRL, a framework for universal TSRL. For the first time, we employ Neural Controlled Differential Equation (NCDE) as the backbone for TSRL, which captures the continuous processes and exhibits robustness to missing data. Additionally, a dual-task SSL strategy, integrating both reconstruction and contrasting tasks, is proposed to enrich the semantic information of the learned representations. Furthermore, novel hard negative construction and false negative elimination mechanisms are proposed to improve sampling efficiency and reduce sampling bias in CL. Finally, extensive experiments demonstrate the superiority of CTRL in forecasting, classification, and imputation tasks, particularly its outstanding robustness to missing data. Keywords: Machine Learning: ML: Representation learning Machine Learning: ML: Self-supervised Learning Machine Learning: ML: Time series and data streams},
  archive   = {C_IJCAI},
  author    = {Zihan Liu and Bowen Du and Junchen Ye and Xianqing Wen and Leilei Sun},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/511},
  month     = {8},
  pages     = {4623-4633},
  title     = {An NCDE-based framework for universal representation learning of time series},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LongVQ: Long sequence modeling with vector quantization on
structured memory. <em>IJCAI</em>, 4614–4622. (<a
href="https://doi.org/10.24963/ijcai.2024/510">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Transformer models have been successful in various sequence processing tasks, but the self-attention mechanism&#39;s computational cost limits its practicality for long sequences. Although there are existing attention variants that improve computational efficiency, they have a limited ability to abstract global information effectively based on their hand-crafted mixing strategies. On the other hand, state-space models (SSMs) are tailored for long sequences but cannot capture complicated local information. Therefore, the combination of them as a unified token mixer is a trend in recent long-sequence models. However, the linearized attention degrades performance significantly even when equipped with SSMs. To address the issue, we propose a new method called LongVQ. LongVQ uses the vector quantization (VQ) technique to compress the global abstraction as a length-fixed codebook, enabling the linear-time computation of the attention matrix. This technique effectively maintains dynamic global and local patterns, which helps to complement the lack of long-range dependency issues. Our experiments on the Long Range Arena benchmark, autoregressive language modeling, and image and speech classification demonstrate the effectiveness of LongVQ. Our model achieves significant improvements over other sequence models, including variants of Transformers, Convolutions, and recent State Space Models. Keywords: Machine Learning: ML: Deep learning architectures Machine Learning: ML: Representation learning Natural Language Processing: NLP: Embeddings},
  archive   = {C_IJCAI},
  author    = {Zicheng Liu and Li Wang and Siyuan Li and Zedong Wang and Haitao Lin and Stan Z. Li},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/510},
  month     = {8},
  pages     = {4614-4622},
  title     = {LongVQ: Long sequence modeling with vector quantization on structured memory},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Resolving word vagueness with scenario-guided adapter for
natural language inference. <em>IJCAI</em>, 4605–4613. (<a
href="https://doi.org/10.24963/ijcai.2024/509">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Natural Language Inference (NLI) is a crucial task in natural language processing that involves determining the relationship between two sentences, typically referred to as the premise and the hypothesis. However, traditional NLI models solely rely on the semantic information inherent in independent sentences and lack relevant situational visual information, which can hinder a complete understanding of the intended meaning of the sentences due to the ambiguity and vagueness of language. To address this challenge, we propose an innovative ScenaFuse adapter that simultaneously integrates large-scale pre-trained linguistic knowledge and relevant visual information for NLI tasks. Specifically, we first design an image-sentence interaction module to incorporate visuals into the attention mechanism of the pre-trained model, allowing the two modalities to interact comprehensively. Furthermore, we introduce an image-sentence fusion module that can adaptively integrate visual information from images and semantic information from sentences. By incorporating relevant visual information and leveraging linguistic knowledge, our approach bridges the gap between language and vision, leading to improved understanding and inference capabilities in NLI tasks. Extensive benchmark experiments demonstrate that our proposed ScenaFuse, a scenario-guided approach, consistently boosts NLI performance. Keywords: Machine Learning: ML: Multi-modal learning Data Mining: DM: Mining text, web, social media Knowledge Representation and Reasoning: KRR: Learning and reasoning},
  archive   = {C_IJCAI},
  author    = {Yonghao Liu and Mengyu Li and Di Liang and Ximing Li and Fausto Giunchiglia and Lan Huang and Xiaoyue Feng and Renchu Guan},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/509},
  month     = {8},
  pages     = {4605-4613},
  title     = {Resolving word vagueness with scenario-guided adapter for natural language inference},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Provable acceleration of nesterov’s accelerated gradient
method over heavy ball method in training over-parameterized neural
networks. <em>IJCAI</em>, 4596–4604. (<a
href="https://doi.org/10.24963/ijcai.2024/508">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Due to its simplicity and efficiency, the first-order gradient method has been extensively employed in training neural networks. Although the optimization problem of the neural network is non-convex, recent research has proved that the first-order method is capable of attaining a global minimum during training over-parameterized neural networks, where the number of parameters is significantly larger than that of training instances. Momentum methods, including the heavy ball (HB) method and Nesterov&#39;s accelerated gradient (NAG) method, are the workhorse of first-order gradient methods owning to their accelerated convergence. In practice, NAG often exhibits superior performance than HB. However, current theoretical works fail to distinguish their convergence difference in training neural networks. To fill this gap, we consider the training problem of the two-layer ReLU neural network under over-parameterization and random initialization. Leveraging high-resolution dynamical systems and neural tangent kernel (NTK) theory, our result not only establishes tighter upper bounds of the convergence rate for both HB and NAG, but also provides the first theoretical guarantee for the acceleration of NAG over HB in training neural networks. Finally, we validate our theoretical results on three benchmark datasets. Keywords: Machine Learning: ML: Theory of deep learning Machine Learning: ML: Optimization},
  archive   = {C_IJCAI},
  author    = {Xin Liu and Wei Tao and Wei Li and Dazhi Zhan and Jun Wang and Zhisong Pan},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/508},
  month     = {8},
  pages     = {4596-4604},
  title     = {Provable acceleration of nesterov’s accelerated gradient method over heavy ball method in training over-parameterized neural networks},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MICRO: Model-based offline reinforcement learning with a
conservative bellman operator. <em>IJCAI</em>, 4587–4595. (<a
href="https://doi.org/10.24963/ijcai.2024/507">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Offline reinforcement learning (RL) faces a significant challenge of distribution shift. Model-free offline RL penalizes the Q value for out-of-distribution (OOD) data or constrains the policy closed to the behavior policy to tackle this problem, but this inhibits the exploration of the OOD region. Model-based offline RL, which uses the trained environment model to generate more OOD data and performs conservative policy optimization within that model, has become an effective method for this problem. However, the current model-based algorithms rarely consider agent robustness when incorporating conservatism into policy. Therefore, the new model-based offline algorithm with a conservative Bellman operator (MICRO) is proposed. This method trades off performance and robustness via introducing the robust Bellman operator into the algorithm. Compared with previous model-based algorithms with robust adversarial models, MICRO can significantly reduce the computation cost by only choosing the minimal Q value in the state uncertainty set. Extensive experiments demonstrate that MICRO outperforms prior RL algorithms in offline RL benchmark and is considerably robust to adversarial perturbations. Keywords: Machine Learning: ML: Reinforcement learning Machine Learning: ML: Model-based and model learning reinforcement learning Machine Learning: ML: Offline reinforcement learning Machine Learning: ML: Robustness},
  archive   = {C_IJCAI},
  author    = {Xiao-Yin Liu and Xiao-Hu Zhou and Guotao Li and Hao Li and Mei-Jiang Gui and Tian-Yu Xiang and De-Xing Huang and Zeng-Guang Hou},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/507},
  month     = {8},
  pages     = {4587-4595},
  title     = {MICRO: Model-based offline reinforcement learning with a conservative bellman operator},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Meta-learning via PAC-bayesian with data-dependent prior:
Generalization bounds from local entropy. <em>IJCAI</em>, 4578–4586. (<a
href="https://doi.org/10.24963/ijcai.2024/506">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Meta-learning accelerates the learning process on unseen learning tasks by acquiring prior knowledge through previous related tasks. The PAC-Bayesian theory provides a theoretical framework to analyze the generalization of meta-learning to unseen tasks. However, previous works still encounter two notable limitations: (1) they merely focus on the data-free priors, which often result in inappropriate regularization and loose generalization bounds; (2) more importantly, their optimization process usually involves nested optimization problems, incurring significant computational costs. To address these issues, we derive new generalization bounds and introduce a novel PAC-Bayesian framework for meta-learning that integrates data-dependent priors. This framework enables the extraction of optimal posteriors for each task in closed form, thereby allowing us to minimize generalization bounds incorporated data-dependent priors with only a simple local entropy. The resulting algorithm, which employs SGLD for sampling from the optimal posteriors, is stable, efficient, and computationally lightweight, eliminating the need for nested optimization. Extensive experimental results demonstrate that our proposed method outperforms the other baselines. Keywords: Machine Learning: ML: Bayesian learning Machine Learning: ML: Meta-learning},
  archive   = {C_IJCAI},
  author    = {Shiyu Liu and Wei Shi and Zenglin Xu and Shaogao Lv and Yehong Zhang and Hui Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/506},
  month     = {8},
  pages     = {4578-4586},
  title     = {Meta-learning via PAC-bayesian with data-dependent prior: Generalization bounds from local entropy},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dual semantic fusion hashing for multi-label cross-modal
retrieval. <em>IJCAI</em>, 4569–4577. (<a
href="https://doi.org/10.24963/ijcai.2024/505">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Cross-modal hashing (CMH) has been widely used for multi-modal retrieval tasks due to its low storage cost and fast query speed. Although existing CMH methods achieve promising performance, most of them mainly rely on coarse-grained supervision information (\ie pairwise similarity matrix) to measure the semantic similarities between all instances, ignoring the impact of multi-label distribution. To address this issue, we construct fine-grained semantic similarity to explore the cluster-level semantic relationships between multi-label data, and propose a new dual semantic fusion hashing (DSFH) for multi-label cross-modal retrieval. Specifically, we first learn the modal-specific representation and consensus hash codes, thereby merging the specificity with consistency. Then, we fuse the coarse-grained and fine-grained semantics to mine multiple-level semantic relationships, thereby enhancing hash codes discrimination. Extensive experiments on three benchmarks demonstrate the superior performance of our DSFH compared with 16 state-of-the-art methods. Keywords: Machine Learning: ML: Multi-modal learning Machine Learning: ML: Multi-view learning},
  archive   = {C_IJCAI},
  author    = {Kaiming Liu and Yunhong Gong and Yu Cao and Zhenwen Ren and Dezhong Peng and Yuan Sun},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/505},
  month     = {8},
  pages     = {4569-4577},
  title     = {Dual semantic fusion hashing for multi-label cross-modal retrieval},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards counterfactual fairness-aware domain generalization
in changing environments. <em>IJCAI</em>, 4560–4568. (<a
href="https://doi.org/10.24963/ijcai.2024/504">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recognizing domain generalization as a commonplace challenge in machine learning, data distribution might progressively evolve across a continuum of sequential domains in practical scenarios. While current methodologies primarily concentrate on bolstering model effectiveness within these new domains, they tend to neglect issues of fairness throughout the learning process. In response, we propose an innovative framework known as Disentanglement for Counterfactual Fairness-aware Domain Generalization (DCFDG). This approach adeptly removes domain-specific information and sensitive information from the embedded representation of classification features. To scrutinize the intricate interplay between semantic information, domain-specific information, and sensitive attributes, we systematically partition the exogenous factors into four latent variables. By incorporating fairness regularization, we utilize semantic information exclusively for classification purposes. Empirical validation on synthetic and authentic datasets substantiates the efficacy of our approach, demonstrating elevated accuracy levels while ensuring the preservation of fairness amidst the evolving landscape of continuous domains. Keywords: Machine Learning: ML: Time series and data streams AI Ethics, Trust, Fairness: ETF: Fairness and diversity Machine Learning: ML: Causality Machine Learning: ML: Generative models},
  archive   = {C_IJCAI},
  author    = {Yujie Lin and Chen Zhao and Minglai Shao and Baoluo Meng and Xujiang Zhao and Haifeng Chen},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/504},
  month     = {8},
  pages     = {4560-4568},
  title     = {Towards counterfactual fairness-aware domain generalization in changing environments},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Scalable federated unlearning via isolated and coded
sharding. <em>IJCAI</em>, 4551–4559. (<a
href="https://doi.org/10.24963/ijcai.2024/503">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Federated unlearning has emerged as a promising paradigm to erase the client-level data effect without affecting the performance of collaborative learning models. However, the federated unlearning process often introduces extensive storage overhead and consumes substantial computational resources, thus hindering its implementation in practice. To address this issue, this paper proposes a scalable federated unlearning framework based on isolated sharding and coded computing. We first divide distributed clients into multiple isolated shards across stages to reduce the number of clients being affected. Then, to reduce the storage overhead of the central server, we develop a coded computing mechanism by compressing the model parameters across different shards. In addition, we provide the theoretical analysis of time efficiency and storage effectiveness for the isolated and coded sharding. Finally, extensive experiments on two typical learning tasks, i.e., classification and generation, demonstrate that our proposed framework can achieve better performance than three state-of-the-art frameworks in terms of accuracy, retraining time, storage overhead, and F1 scores for resisting membership inference attacks. Keywords: Machine Learning: ML: Federated learning Machine Learning: ML: Trustworthy machine learning},
  archive   = {C_IJCAI},
  author    = {Yijing Lin and Zhipeng Gao and Hongyang Du and Dusit Niyato and Gui Gui and Shuguang Cui and Jinke Ren},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/503},
  month     = {8},
  pages     = {4551-4559},
  title     = {Scalable federated unlearning via isolated and coded sharding},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). BATON: Aligning text-to-audio model using human preference
feedback. <em>IJCAI</em>, 4542–4550. (<a
href="https://doi.org/10.24963/ijcai.2024/502">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With the development of AI-Generated Content (AIGC), text-to-audio models are gaining widespread attention. However, it is challenging for these models to generate audio aligned with human preference due to the inherent information density of natural language and limited model understanding ability. To alleviate this issue, we formulate the BATON, the first framework specifically designed to enhance the alignment between generated audio and text prompt using human preference feedback. Our BATON comprises three key stages: Firstly, we curated a dataset containing both prompts and the corresponding generated audio, which was then annotated based on human feedback. Secondly, we introduced a reward model using the constructed dataset, which can mimic human preference by assigning rewards to input text-audio pairs. Finally, we employed the reward model to fine-tune an off-the-shelf text-to-audio model. The experiment results demonstrate that our BATON can significantly improve the generation quality of the original text-to-audio models, concerning audio integrity, temporal relationship, and alignment with human preference. Project page is available at https://baton2024.github.io. Keywords: Machine Learning: ML: Generative models Multidisciplinary Topics and Applications: MTA: Arts and creativity Natural Language Processing: NLP: Speech},
  archive   = {C_IJCAI},
  author    = {Huan Liao and Haonan Han and Kai Yang and Tianjiao Du and Rui Yang and Qinmei Xu and Zunnan Xu and Jingquan Liu and Jiasheng Lu and Xiu Li},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/502},
  month     = {8},
  pages     = {4542-4550},
  title     = {BATON: Aligning text-to-audio model using human preference feedback},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). FedConPE: Efficient federated conversational bandits with
heterogeneous clients. <em>IJCAI</em>, 4533–4541. (<a
href="https://doi.org/10.24963/ijcai.2024/501">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Conversational recommender systems have emerged as a potent solution for efficiently eliciting user preferences. These systems interactively present queries associated with &quot;key terms&quot; to users and leverage user feedback to estimate user preferences more efficiently. Nonetheless, most existing algorithms adopt a centralized approach. In this paper, we introduce FedConPE, a phase elimination-based federated conversational bandit algorithm, where M agents collaboratively solve a global contextual linear bandit problem with the help of a central server while ensuring secure data management. To effectively coordinate all the clients and aggregate their collected data, FedConPE uses an adaptive approach to construct key terms that minimize uncertainty across all dimensions in the feature space. Furthermore, compared with existing federated linear bandit algorithms, FedConPE offers improved computational and communication efficiency as well as enhanced privacy protections. Our theoretical analysis shows that FedConPE is minimax near-optimal in terms of cumulative regret. We also establish upper bounds for communication costs and conversation frequency. Comprehensive evaluations demonstrate that FedConPE outperforms existing conversational bandit algorithms while using fewer conversations. Keywords: Machine Learning: ML: Multi-armed bandits Data Mining: DM: Recommender systems Machine Learning: ML: Federated learning Machine Learning: ML: Online learning},
  archive   = {C_IJCAI},
  author    = {Zhuohua Li and Maoli Liu and John C. S. Lui},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/501},
  month     = {8},
  pages     = {4533-4541},
  title     = {FedConPE: Efficient federated conversational bandits with heterogeneous clients},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient offline meta-reinforcement learning via robust
task representations and adaptive policy generation. <em>IJCAI</em>,
4524–4532. (<a href="https://doi.org/10.24963/ijcai.2024/500">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Zero-shot adaptation is crucial for agents facing new tasks. Offline Meta-Reinforcement Learning (OMRL), utilizing offline multi-task datasets to train policies, offers a way to attain this ability. Although most OMRL methods construct task representations via contrastive learning and merge them with states for policy input, these methods may have inherent problems. Specifically, integrating task representations with states for policy input limits learning efficiency, due to failing to leverage the similarities among tasks. Moreover, uniformly sampling an equal number of negative samples from different tasks in contrastive learning can hinder differentiation of more similar tasks, potentially diminishing task representation robustness. In this paper, we introduce an OMRL algorithm to tackle the aforementioned issues. We design a network structure for efficient learning by leveraging task similarity. It features shared lower layers for common feature extraction with a hypernetworks-driven upper layer, customized to process features per task&#39;s attributes. Furthermore, to achieve robust task representations for generating task-specific control policies, we utilize contrastive learning and introduce a novel method to construct negative sample pairs based on task similarity. Experimental results show that our method notably boosts learning efficiency and zero-shot adaptation in new tasks, surpassing previous methods across multiple challenging domains. Keywords: Machine Learning: ML: Reinforcement learning Machine Learning: ML: Meta-learning Machine Learning: ML: Offline reinforcement learning Robotics: ROB: Learning in robotics},
  archive   = {C_IJCAI},
  author    = {Zhengwei Li and Zhenyang Lin and Yurou Chen and Zhiyong Liu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/500},
  month     = {8},
  pages     = {4524-4532},
  title     = {Efficient offline meta-reinforcement learning via robust task representations and adaptive policy generation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). Efficiency calibration of implicit regularization in deep
networks via self-paced curriculum-driven singular value selection.
<em>IJCAI</em>, 4515–4523. (<a
href="https://doi.org/10.24963/ijcai.2024/499">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The generalization of neural networks has been a major focus of research in deep learning. It is often interpreted as an implicit bias towards solutions with specific properties. Especially, in practical applications, it has been observed that linear neural networks (LNN) tend to favor low-rank solutions for matrix completion tasks. However, most existing methods rely on increasing the depth of the neural network to enhance the low rank of solutions, resulting in higher complexity. In this paper, we propose a new explicit regularization method that calibrates the implicit bias towards low-rank trends in matrix completion tasks. Our approach automatically incorporates smaller singular values into the training process using a self-paced learning strategy, gradually restoring matrix information. By jointly using both implicit and explicit regularization, we effectively capture the low-rank structure of LNN and accelerate its convergence. We also analyze how our proposed penalty term interacts with implicit regularization and provide theoretical guarantees for our new model. To evaluate the effectiveness of our method, we conduct a series of experiments on both simulated and real-world data. Our experimental results clearly demonstrate that our method has better robustness and generalization ability compared with other methods. Keywords: Machine Learning: ML: Representation learning Data Mining: DM: Recommender systems Machine Learning: ML: Theory of deep learning},
  archive   = {C_IJCAI},
  author    = {Zhe Li and Shuo Chen and Jian Yang and Lei Luo},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/499},
  month     = {8},
  pages     = {4515-4523},
  title     = {Efficiency calibration of implicit regularization in deep networks via self-paced curriculum-driven singular value selection},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Angluin-style learning of deterministic büchi and co-büchi
automata. <em>IJCAI</em>, 4506–4514. (<a
href="https://doi.org/10.24963/ijcai.2024/498">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {While recently developed Angluin-style learning algorithms for omega-automata have much in common with her classic DFA learning algorithm, there is a huge difference in the cost of the equivalence queries about the target automata. For omega-regular languages, the target is to learn nondeterministic Buchi automata (NBAs) through the vehicle of Families of DFAs (FDFAs). While the cost of equivalence queries is usually idealised as constant in learning, it makes a practical difference that the language equivalence checking about the learned NBAs is computationally hard. We develop efficient techniques for the cases, where we learn deterministic Buchi automata (DBAs) or deterministic co-Buchi automata (DCAs). This is based on the observation that some classes of FDFAs can be used to learn DBAs for DBA recognisable languages, rather than having to resort to nondeterministic ones. We believe that the restriction to DBAs and DCAs in equivalence queries also makes our algorithm more appealing to realistic applications, as the operations are cheap---NL---for DBAs and DCAs. Keywords: Machine Learning: ML: Active learning Knowledge Representation and Reasoning: KRR: Automated reasoning and theorem proving Knowledge Representation and Reasoning: KRR: Learning and reasoning Machine Learning: ML: Model-based and model learning reinforcement learning},
  archive   = {C_IJCAI},
  author    = {Yong Li and Sven Schewe and Qiyi Tang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/498},
  month     = {8},
  pages     = {4506-4514},
  title     = {Angluin-style learning of deterministic büchi and co-büchi automata},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Causality-enhanced discreted physics-informed neural
networks for predicting evolutionary equations. <em>IJCAI</em>,
4497–4505. (<a href="https://doi.org/10.24963/ijcai.2024/497">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Physics-informed neural networks (PINNs) have shown promising potential for solving partial differential equations (PDEs) using deep learning. However, PINNs face training difficulties for evolutionary PDEs, particularly for dynamical systems whose solutions exhibit multi-scale or turbulent behavior over time. The reason is that PINNs may violate the temporal causality property since all the temporal features in the PINNs loss are trained simultaneously. This paper proposes to use implicit time differencing schemes to enforce temporal causality, and use transfer learning to sequentially update the PINNs in space as surrogates for PDE solutions in different time frames. The evolving PINNs are better able to capture the varying complexities of the evolutionary equations, while only requiring minor updates between adjacent time frames. Our method is theoretically proven to be convergent if the time step is small and each PINN in different time frames is well-trained. In addition, we provide state-of-the-art (SOTA) numerical results for a variety of benchmarks for which existing PINNs formulations may fail or be inefficient. We demonstrate that the proposed method improves the accuracy of PINNs approximation for evolutionary PDEs and improves efficiency by a factor of 4–40x. The code is available at https://github.com/SiqiChen9/TL-DPINNs. Keywords: Machine Learning: ML: Applications Machine Learning: ML: Causality Machine Learning: ML: Deep learning architectures Machine Learning: ML: Regression},
  archive   = {C_IJCAI},
  author    = {Ye Li and Siqi Chen and Bin Shan and Sheng-Jun Huang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/497},
  month     = {8},
  pages     = {4497-4505},
  title     = {Causality-enhanced discreted physics-informed neural networks for predicting evolutionary equations},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fast unpaired multi-view clustering. <em>IJCAI</em>,
4488–4496. (<a href="https://doi.org/10.24963/ijcai.2024/496">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Anchor based pair-wised multi-view clustering often assumes multi-view data are paired, and has demonstrated significant advancements in recent years. However, this presumption is easily violated, and data is commonly unpaired fully in practical applications due to the influence of data collection and storage processes. Addressing unpaired large-scale multi-view data through anchor learning remains a research gap. The absence of pairing in multi-view data disrupts the consistency and complementarity of multiple views, posing significant challenges in learning powerful and meaningful anchors and bipartite graphs from unpaired multi-view data. To tackle this challenge, this study proposes a novel Fast Unpaired Multi-view Clustering (FUMC) framework for fully unpaired large-scale multi-view data. Specifically, FUMC first designs an inverse local manifold learning paradigm to guide the learned anchors for effective pairing and balancing, ensuring alignment, fairness, and power in unpaired multi-view data. Meanwhile, a novel bipartite graph matching framework is developed to align unpaired bipartite graphs, creating a consistent bipartite graph from unpaired multi-view data. The efficacy, efficiency, and superiority of our FUMC are corroborated through extensive evaluations on numerous benchmark datasets with shallow and deep SOTA methods. Keywords: Machine Learning: ML: Multi-view learning Machine Learning: ML: Clustering},
  archive   = {C_IJCAI},
  author    = {Xingfeng Li and Yuangang Pan and Yinghui Sun and Quansen Sun and Ivor Tsang and Zhenwen Ren},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/496},
  month     = {8},
  pages     = {4488-4496},
  title     = {Fast unpaired multi-view clustering},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). WPML3CP: Wasserstein partial multi-label learning with dual
label correlation perspectives. <em>IJCAI</em>, 4479–4487. (<a
href="https://doi.org/10.24963/ijcai.2024/495">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Partial multi-label learning (PMLL) refers to a weakly-supervised classification problem, where each instance is associated with a set of candidate labels, covering its ground-truth labels but also with irrelevant ones. The current methodology of PMLL is to estimate the ground-truth confidences of candidate labels, i.e., the likelihood of a candidate label being a ground-truth one, and induce the multi-label predictor with them, rather than the candidate labels. In this paper, we aim to estimate precise ground-truth confidences by leveraging precise label correlations, which are also required to estimate. To this end, we propose to capture label correlations from both measuring and modeling perspectives. Specifically, we measure the loss between ground-truth confidences and predictions by employing the Wasserstein distance involving label correlations; and form a label correlation-aware regularization to constraint predictive parameters. The two techniques are coupled to promote precise estimations of label correlations. Upon these ideas, we propose a novel PMLL method, namely Wasserstein Partial Multi-Label Learning with dual Label Correlation Perspectives (WPML3CP). We conduct extensive experiments on several benchmark datasets. Empirical results demonstrate that WPML3CP can outperform the existing PMLL baselines. Keywords: Machine Learning: ML: Weakly supervised learning Machine Learning: ML: Classification Machine Learning: ML: Self-supervised Learning},
  archive   = {C_IJCAI},
  author    = {Ximing Li and Yuanchao Dai and Bing Wang and Changchun Li and Renchu Guan and Fangming Gu and Jihong Ouyang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/495},
  month     = {8},
  pages     = {4479-4487},
  title     = {WPML3CP: Wasserstein partial multi-label learning with dual label correlation perspectives},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). No regularization is needed: Efficient and effective
incomplete label distribution learning. <em>IJCAI</em>, 4470–4478. (<a
href="https://doi.org/10.24963/ijcai.2024/494">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In reality, it is laborious to obtain complete label degrees, giving birth to Incomplete Label Distribution Learning (InLDL), where some degrees are missing. Existing InLDL methods often assume that degrees are uniformly random missing. However, it is often not the case in practice, which arises the first issue. Besides, they often adopt explicit regularization to compensate the incompleteness, leading to burdensome parameter tuning and extra computation, causing the second issue. To address the first issue, we adopt a more practical setting, i.e., small degrees are more prone to be missing, since large degrees are likely to catch more attention. To tackle the second issue, we argue that label distribution itself already contains abundant knowledge, such as label correlation and ranking order, thus it may have provided enough prior for learning. It is precisely because existing methods overlook such a prior that leads to the forced adoption of explicit regularization. By directly utilizing the label degrees prior, we design a properly weighted objective function, exempting the need from explicit regularization. Moreover, we provide rigorous theoretical analysis, revealing in principle that the weighting plays an implicit regularization role. To sum up, our method has four advantages, it is 1) model selection free; 2) with closed-form solution (sub-problem) and easy-to-implement (a few lines of codes); 3) with linear computational complexity in the number of samples, thus scalable to large datasets; 4) competitive with state-of-the-arts in both random and non-random missing scenarios. Keywords: Machine Learning: ML: Multi-label learning Machine Learning: ML: Weakly supervised learning},
  archive   = {C_IJCAI},
  author    = {Xiang Li and Songcan Chen},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/494},
  month     = {8},
  pages     = {4470-4478},
  title     = {No regularization is needed: Efficient and effective incomplete label distribution learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SketchEdit: Editing freehand sketches at the stroke-level.
<em>IJCAI</em>, 4461–4469. (<a
href="https://doi.org/10.24963/ijcai.2024/493">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent sketch synthesis methods have demonstrated the capability of generating lifelike outcomes. However, these methods directly encode the entire sketches making it challenging to decouple the strokes from the sketches and have difficulty in controlling local sketch synthesis, e.g., stroke editing. Besides, the sketch editing task encounters the issue of accurately positioning the edited strokes, because users may not be able to draw on the exact position and the same stroke may appear in various locations in different sketches. We propose SketchEdit to realize flexible editing of sketches at the stroke-level for the first time. To tackle the challenge of decoupling strokes, SketchEdit divides a drawing sequence of a sketch into a series of strokes based on the pen state, aligns the stroke segments to have the same starting position, and learns the embeddings of every stroke by a proposed stroke encoder. Moreover, we overcome the problem of stroke placement via a diffusion process, which progressively generates the locations for the strokes to be synthesized, using the stroke features as the guiding condition. Experiments demonstrate that SketchEdit is effective for stroke-level sketch editing and sketch reconstruction. The source code is publicly available at https://github.com/CMACH508/SketchEdit/. Keywords: Machine Learning: ML: Generative models Computer Vision: CV: Applications Computer Vision: CV: Image and video synthesis and generation Computer Vision: CV: Representation learning},
  archive   = {C_IJCAI},
  author    = {Tengjie Li and Shikui Tu and Lei Xu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/493},
  month     = {8},
  pages     = {4461-4469},
  title     = {SketchEdit: Editing freehand sketches at the stroke-level},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Prompt learning with extended kalman filter for pre-trained
language models. <em>IJCAI</em>, 4452–4460. (<a
href="https://doi.org/10.24963/ijcai.2024/492">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Prompt learning has gained popularity as a means to leverage the knowledge embedded in pre-trained language models (PLMs) for NLP tasks while using a limited number of trainable parameters. While it has shown promise in tasks like sentiment classification and natural language inference, generating suitable prompts for PLMs, as opposed to human prompts, remains a challenge. In this paper, we introduce an abstraction of the prompt learning process using an extended Kalman filter. Our approach, called Conditional Extended Kalman Filter based on Neural Networks (CEKFNN), effectively infers more appropriate prompt tokens by enhancing the classic extended Kalman filter with PLM&#39;s contextual representation power. Specifically, CEKFNN learns transition and emission functions from PLM embeddings of input sentences to infer latent prompt tokens. We refine CEKFNN using an alternate-training approach, retraining a PLM&#39;s emission function with prompt tokens inferred by prompt models (PMs), as well as the initial and transition functions. PLM&#39;s output labels assist in PMs&#39; training. When updating the pre-trained language model (PLM), we use an adapter approach with few trainable parameters, leaving PLM parameters frozen. We evaluate CEKFNN across open-source PLMs, demonstrating performance improvements over state-of-the-art methods while using a limited number of trainable parameters. It shows that CEKFNN performs on-par or better than fine-tuning, which requires updating all parameters in the PLM. Keywords: Machine Learning: ML: Deep learning architectures Machine Learning: ML: Bayesian learning Natural Language Processing: NLP: Language models Planning and Scheduling: PS: Markov decisions processes},
  archive   = {C_IJCAI},
  author    = {Quan Li and Xike Xie and Chao Wang and S. Kevin Zhou},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/492},
  month     = {8},
  pages     = {4452-4460},
  title     = {Prompt learning with extended kalman filter for pre-trained language models},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DarkFed: A data-free backdoor attack in federated learning.
<em>IJCAI</em>, 4443–4451. (<a
href="https://doi.org/10.24963/ijcai.2024/491">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Federated learning (FL) has been demonstrated to be susceptible to backdoor attacks. However, existing academic studies on FL backdoor attacks rely on a high proportion of real clients with main task-related data, which is impractical. In the context of real-world industrial scenarios, even the simplest defense suffices to defend against the state-of-the-art attack, 3DFed. A practical FL backdoor attack remains in a nascent stage of development. To bridge this gap, we present DarkFed. Initially, we emulate a series of fake clients, thereby achieving the attacker proportion typical of academic research scenarios. Given that these emulated fake clients lack genuine training data, we further propose a data-free approach to backdoor FL. Specifically, we delve into the feasibility of injecting a backdoor using a shadow dataset. Our exploration reveals that impressive attack performance can be achieved, even when there is a substantial gap between the shadow dataset and the main task dataset. This holds true even when employing synthetic data devoid of any semantic information as the shadow dataset. Subsequently, we strategically construct a series of covert backdoor updates in an optimized manner, mimicking the properties of benign updates, to evade detection by defenses. A substantial body of empirical evidence validates the tangible effectiveness of DarkFed. Keywords: Machine Learning: ML: Federated learning Computer Vision: CV: Adversarial learning, adversarial attack and defense methods Machine Learning: ML: Adversarial machine learning},
  archive   = {C_IJCAI},
  author    = {Minghui Li and Wei Wan and Yuxuan Ning and Shengshan Hu and Lulu Xue and Leo Yu Zhang and Yichen Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/491},
  month     = {8},
  pages     = {4443-4451},
  title     = {DarkFed: A data-free backdoor attack in federated learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Continual multi-objective reinforcement learning via reward
model rehearsal. <em>IJCAI</em>, 4434–4442. (<a
href="https://doi.org/10.24963/ijcai.2024/490">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-objective reinforcement learning (MORL) approaches address real-world problems with multiple objectives by learning policies maximizing returns weighted by different user preferences. Typical methods assume the objectives remain unchanged throughout the agent&#39;s lifetime. However, in some real-world situations, the agent may encounter dynamically changing learning objectives, i.e., different vector-valued reward functions at different learning stages. This issue has not been considered in problem formulation or algorithm design. To address this issue, we formalize the setting as a continual MORL (CMORL) problem for the first time, accounting for the evolution of objectives throughout the learning process. Subsequently, we propose Continual Multi-Objective Reinforcement Learning via Reward Model Rehearsal (CORe3), incorporating a dynamic agent network for rapid adaptation to new objectives. Moreover, we develop a reward model rehearsal technique to recover the reward signals for previous objectives, thus alleviating catastrophic forgetting. Experiments on four CMORL benchmarks showcase that CORe3 effectively learns policies satisfying different preferences on all encountered objectives, and outperforms the best baseline by 171%, highlighting the capability of CORe3 to handle situations with evolving objectives. Keywords: Machine Learning: ML: Reinforcement learning Machine Learning: ML: Incremental learning Machine Learning: ML: Optimization},
  archive   = {C_IJCAI},
  author    = {Lihe Li and Ruotong Chen and Ziqian Zhang and Zhichao Wu and Yi-Chen Li and Cong Guan and Yang Yu and Lei Yuan},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/490},
  month     = {8},
  pages     = {4434-4442},
  title     = {Continual multi-objective reinforcement learning via reward model rehearsal},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DWLR: Domain adaptation under label shift for wearable
sensor. <em>IJCAI</em>, 4425–4433. (<a
href="https://doi.org/10.24963/ijcai.2024/489">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Wearable sensors play a crucial role in real-world scenarios, such as human activity recognition, sleep monitoring and electrocardiogram monitoring. However, deploying classifiers on them is challenged by distribution shifts across users and devices. Unsupervised domain adaptation (UDA) is proposed to address this, yet existing methods mostly focus on feature distribution shift, neglecting the potential misclassification due to label shift. In this paper, we propose Domain adaptation under label shift for Wearable sensor with Learnable Reweighting (DWLR) to handle both feature and label shifts. Specifically, DWLR employs learnable reweighting to align label distributions between source and target domains. It incorporates elements of information gain during the reweighting process to counter potential distribution shift that could emerge from over-reliance on data with high-confidence pseudo labels. Importantly, since wearable sensor data is time-series data, and can be subjected to distribution shifts originating from either the time domain, the frequency domain, or both, DWLR performs reweighting and alignment separately in these two domains to more robustly handle potential feature distribution shifts. Extensive experiments on three distinct wearable sensor datasets demonstrate the effectiveness of DWLR, yielding a remarkable average performance improvement of 5.85%. Keywords: Machine Learning: ML: Time series and data streams Machine Learning: ML: Adversarial machine learning Machine Learning: ML: Classification Machine Learning: ML: Deep learning architectures},
  archive   = {C_IJCAI},
  author    = {Juren Li and Yang Yang and Youmin Chen and Jianfeng Zhang and Zeyu Lai and Lujia Pan},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/489},
  month     = {8},
  pages     = {4425-4433},
  title     = {DWLR: Domain adaptation under label shift for wearable sensor},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A density-driven iterative prototype optimization for
transductive few-shot learning. <em>IJCAI</em>, 4416–4424. (<a
href="https://doi.org/10.24963/ijcai.2024/488">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Few-shot learning (FSL) poses a considerable challenge since it aims to improve the model generalization ability with limited labeled data. Previous works usually attempt to construct class-specific prototypes and then predict novel classes using these prototypes. However, the feature distribution represented by the limited labeled data is coarse-grained, leading to large information gap between the labeled and unlabeled data as well as biases in the prototypes. In this paper, we investigate the correlation between sample quality and density, and propose a Density-driven Iterative Prototype Optimization to acquire high-quality prototypes, and further improve few-shot learning performance. Specifically, the proposed method consists of two optimization strategies. The similarity-evaluating strategy is for capturing the information gap between the labeled and unlabeled data by reshaping the feature manifold for the novel feature distribution. The density-driven strategy is proposed to iteratively refine the prototypes in the direction of density growth. The proposed method could reach or even exceed the state-of-the-art performance on four benchmark datasets, including mini-ImageNet, tiered-ImageNet, CUB, and CIFAR-FS. The code will be available soon at https://github.com/tailofcat/DIPO. Keywords: Machine Learning: ML: Few-shot learning Computer Vision: CV: Transfer, low-shot, semi- and un- supervised learning},
  archive   = {C_IJCAI},
  author    = {Jingcong Li and Chunjin Ye and Fei Wang and Jiahui Pan},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/488},
  month     = {8},
  pages     = {4416-4424},
  title     = {A density-driven iterative prototype optimization for transductive few-shot learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Combinatorial routing for neural trees. <em>IJCAI</em>,
4407–4415. (<a href="https://doi.org/10.24963/ijcai.2024/487">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Neural trees benefit from the high-level representation of neural networks and the interpretability of decision trees. Therefore, the existing works on neural trees perform outstandingly on various tasks such as architecture search. However, these works require every router to provide only one successor for each sample, causing the predictions to be dominated by the elite branch and its derivative architectures. To break this branch dominance, we propose the combinatorial routing neural tree method, termed CombRo. Unlike the previous methods employing unicast routing, CombRo performs multicast schema in each iteration, allowing the features to be routed to any combination of successors at every non-leaf. The weights of each architecture are then evaluated accordingly. We update the weights by training the routing subnetwork, and the architecture with the top weight is selected in the final step. We compare CombRo with the existing algorithms on 3 public image datasets, demonstrating its superior performance in terms of accuracy. Visualization results further validate the effectiveness of the multicast routing schema. Code is available at https://github.com/JiahaoLi-gdut/CombRo. Keywords: Machine Learning: ML: Deep learning architectures Computer Vision: CV: Machine learning for vision Machine Learning: ML: Classification Machine Learning: ML: Ensemble methods},
  archive   = {C_IJCAI},
  author    = {Jiahao Li and Ruichu Cai and Yuguang Yan},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/487},
  month     = {8},
  pages     = {4407-4415},
  title     = {Combinatorial routing for neural trees},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hypergraph self-supervised learning with sampling-efficient
signals. <em>IJCAI</em>, 4398–4406. (<a
href="https://doi.org/10.24963/ijcai.2024/486">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Self-supervised learning (SSL) provides a promising alternative for representation learning on hypergraphs without costly labels. However, existing hypergraph SSL models are mostly based on contrastive methods with the instance-level discrimination strategy, suffering from two significant limitations: (1) They select negative samples arbitrarily, which is unreliable in deciding similar and dissimilar pairs, causing training bias. (2) They often require a large number of negative samples, resulting in expensive computational costs. To address the above issues, we propose SE-HSSL, a hypergraph SSL framework with three sampling-efficient self-supervised signals. Specifically, we introduce two sampling-free objectives leveraging the canonical correlation analysis as the node-level and group-level self-supervised signals. Additionally, we develop a novel hierarchical membership-level contrast objective motivated by the cascading overlap relationship in hypergraphs, which can further reduce membership sampling bias and improve the efficiency of sample utilization. Through comprehensive experiments on 7 real-world hypergraphs, we demonstrate the superiority of our approach over the state-of-the-art method in terms of both effectiveness and efficiency. Keywords: Machine Learning: ML: Self-supervised Learning Data Mining: DM: Mining graphs},
  archive   = {C_IJCAI},
  author    = {Fan Li and Xiaoyang Wang and Dawei Cheng and Wenjie Zhang and Ying Zhang and Xuemin Lin},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/486},
  month     = {8},
  pages     = {4398-4406},
  title     = {Hypergraph self-supervised learning with sampling-efficient signals},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unbiased active semi-supervised binary classification
models. <em>IJCAI</em>, 4389–4397. (<a
href="https://doi.org/10.24963/ijcai.2024/485">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Active learning is known to be a well-motivated algorithm that aims to maximize model performance with relatively small data, but it introduces sampling bias due to active selection. To adjust the bias, current literature utilizes corrective weights in a supervised learning approach. However, those methods consider only a small amount of actively sampled data and thus estimation efficiency can be improved using unsampled data together. In this paper, we develop an actively improved augmented estimation equation (AI-AEE) based on corrective weights as well as imputation models that allow us to leverage unlabeled data. The asymptotic distribution of the proposed estimator as the solution to the AI-AEE is derived, and an optimal sampling scheme to minimize the asymptotic mean squared error of the estimator is proposed. We then propose a general practical algorithm for training prediction models in the active and semi-supervised learning framework. The superiority of our method is demonstrated on synthetic and real data examples. Keywords: Machine Learning: ML: Active learning Machine Learning: ML: Regression Machine Learning: ML: Semi-supervised learning},
  archive   = {C_IJCAI},
  author    = {JooChul Lee and Weidong Ma and Ziyang Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/485},
  month     = {8},
  pages     = {4389-4397},
  title     = {Unbiased active semi-supervised binary classification models},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Toward a manifold-preserving temporal graph network in
hyperbolic space. <em>IJCAI</em>, 4380–4388. (<a
href="https://doi.org/10.24963/ijcai.2024/484">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Hyperbolic geometry provides an ideal setting to represent the scale-free or hierarchical characteristics of an input graph naturally. Utilizing hyperbolic geometry for learning dynamic graph representation has gained a growing interest in recent years. However, the majority of hyperbolic-based approaches rely on tangent spaces to perform graph operations, which could distort the structure of the dynamic graph when the graph grows over time. To avoid the distortion in tangent space, we propose a Hyperbolic Manifold-Preserving Temporal Graph Network that works directly on the hyperbolic manifold. The model includes a graph convolution module for learning the spatial dependencies, an attention architecture for capturing the temporal properties, and a gated recurrent unit for extracting the spatio-temporal relationships. By evaluating on diverse real-world dynamic graphs, our model has achieved significant improvements in link prediction and new link prediction tasks, in comparison with other baselines. Keywords: Machine Learning: ML: Sequence and graph learning Machine Learning: ML: Geometric learning Data Mining: DM: Mining graphs Data Mining: DM: Mining spatial and/or temporal data},
  archive   = {C_IJCAI},
  author    = {Viet Quan Le and Viet Cuong Ta},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/484},
  month     = {8},
  pages     = {4380-4388},
  title     = {Toward a manifold-preserving temporal graph network in hyperbolic space},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A de-singularity subgradient approach for the extended weber
location problem. <em>IJCAI</em>, 4370–4379. (<a
href="https://doi.org/10.24963/ijcai.2024/483">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The extended Weber location problem is a classical optimization problem that has inspired some new works in several machine learning scenarios recently. However, most existing algorithms may get stuck due to the singularity at the data points when the power of the cost function 1\&lt;= q&lt;2, such as the widely-used iterative Weiszfeld approach. In this paper, we establish a de-singularity subgradient approach for this problem. We also provide a complete proof of convergence which has fixed some incomplete statements of the proofs for some previous Weiszfeld algorithms. Moreover, we deduce a new theoretical result of superlinear convergence for the iteration sequence in a special case where the minimum point is a singular point. We conduct extensive experiments in a real-world machine learning scenario to show that the proposed approach solves the singularity problem, produces the same results as in the non-singularity cases, and shows a reasonable rate of linear convergence. The results also indicate that the q-th power case (1 Keywords: Machine Learning: ML: Optimization Constraint Satisfaction and Optimization: CSO: Solvers and tools Constraint Satisfaction and Optimization: CSO: Other Keywords: Machine Learning: ML: Optimization Constraint Satisfaction and Optimization: CSO: Solvers and tools Constraint Satisfaction and Optimization: CSO: Other},
  archive   = {C_IJCAI},
  author    = {Zhao-Rong Lai and Xiaotian Wu and Liangda Fang and Ziliang Chen},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/483},
  month     = {8},
  pages     = {4370-4379},
  title     = {A de-singularity subgradient approach for the extended weber location problem},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep neural networks via complex network theory: A
perspective. <em>IJCAI</em>, 4361–4369. (<a
href="https://doi.org/10.24963/ijcai.2024/482">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep Neural Networks (DNNs) can be represented as graphs whose links and vertices iteratively process data and solve tasks sub-optimally. Complex Network Theory (CNT), merging statistical physics with graph theory, provides a method for interpreting neural networks by analysing their weights and neuron structures. However, classic works adapt CNT metrics that only permit a topological analysis as they do not account for the effect of the input data. In addition, CNT metrics have been applied to a limited range of architectures, mainly including Fully Connected neural networks. In this work, we extend the existing CNT metrics with measures that sample from the DNNs&#39; training distribution, shifting from a purely topological analysis to one that connects with the interpretability of deep learning. For the novel metrics, in addition to the existing ones, we provide a mathematical formalisation for Fully Connected, AutoEncoder, Convolutional and Recurrent neural networks, of which we vary the activation functions and the number of hidden layers. We show that these metrics differentiate DNNs based on the architecture, the number of hidden layers, and the activation function. Our contribution provides a method rooted in physics for interpreting DNNs that offers insights beyond the traditional input-output relationship and the CNT topological analysis. Keywords: Machine Learning: ML: Explainable/Interpretable machine learning Machine Learning: ML: Applications Machine Learning: ML: Other},
  archive   = {C_IJCAI},
  author    = {Emanuele La Malfa and Gabriele La Malfa and Giuseppe Nicosia and Vito Latora},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/482},
  month     = {8},
  pages     = {4361-4369},
  title     = {Deep neural networks via complex network theory: A perspective},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards a framework for learning of algorithms: The case of
learned comparison sorts. <em>IJCAI</em>, 4353–4360. (<a
href="https://doi.org/10.24963/ijcai.2024/481">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Designing algorithms is cumbersome and error-prone. This, among other things, has increasingly led to efforts to extend or even replace designing algorithms with machine learning models. While previous research has demonstrated that some machine learning models possess Turing-completeness, the findings are largely theoretical, and solutions for specific algorithmic tasks remain unclear. With this in mind, we investigate the feasibility of learning representations of classical algorithms from data on their execution, enabling their application to different inputs. We propose a novel and general framework for algorithm learning consisting of a model of computation that facilitates algorithm analysis across various levels of abstraction. We formalize the problem of learning an algorithm using an algebraic approach for graph traversal. We apply this framework to comparison sorts and evaluate the inferred machine learning models&#39; performance, demonstrating the applicability of the approach in terms of accuracy and sensitivity. Keywords: Machine Learning: ML: Applications Machine Learning: ML: Classification Machine Learning: ML: Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Philipp Kunz and Ilche Georgievski and Marco Aiello},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/481},
  month     = {8},
  pages     = {4353-4360},
  title     = {Towards a framework for learning of algorithms: The case of learned comparison sorts},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Look-ahead search on top of policy networks in imperfect
information games. <em>IJCAI</em>, 4344–4352. (<a
href="https://doi.org/10.24963/ijcai.2024/480">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Search in test time is often used to improve the performance of reinforcement learning algorithms. Performing theoretically sound search in fully adversarial two-player games with imperfect information is notoriously difficult and requires a complicated training process. We present a method for adding test-time search to an arbitrary policy-gradient algorithm that learns from sampled trajectories. Besides the policy network, the algorithm trains an additional critic network, which estimates the expected values of players following various transformations of the policies given by the policy network. These values are then used for depth-limited search. We show how the values from this critic can create a value function for imperfect information games. Moreover, they can be used to compute the summary statistics necessary to start the search from an arbitrary decision point in the game. The presented algorithm is scalable to very large games since it does not require any search during train time. We evaluate the algorithm&#39;s performance when trained along Regularized Nash Dynamics, and we evaluate the benefit of using the search in the standard benchmark game of Leduc hold&#39;em, multiple variants of imperfect information Goofspiel, and Battleships. Keywords: Machine Learning: ML: Multiagent Reinforcement Learning Agent-based and Multi-agent Systems: MAS: Multi-agent learning Search: S: Game playing Search: S: Local search},
  archive   = {C_IJCAI},
  author    = {Ondřej Kubíček and Neil Burch and Viliam Lisý},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/480},
  month     = {8},
  pages     = {4344-4352},
  title     = {Look-ahead search on top of policy networks in imperfect information games},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ROCES: Robust class expression synthesis in description
logics via iterative sampling. <em>IJCAI</em>, 4335–4343. (<a
href="https://doi.org/10.24963/ijcai.2024/479">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider the problem of class expression learning using cardinality-minimal sets of examples. Recent class expression learning approaches employ deep neural networks and have demonstrated tremendous performance improvements in execution time and quality of the computed solutions. However, they lack generalization capabilities when it comes to the number of examples used in a learning problem, i.e., they often perform poorly on unseen learning problems where only a few examples are given. In this work, we propose a generalization of the classical class expression learning problem to address the limitations above. In short, our generalized learning problem (GLP) forces learning systems to solve the classical class expression learning problem using the smallest possible subsets of examples, thereby improving the learning systems&#39; ability to solve unseen learning problems with arbitrary numbers of examples. Moreover, we develop ROCES, a learning algorithm for synthesis-based approaches to solve GLP. Experimental results suggest that post training, ROCES outperforms existing synthesis-based approaches on out-of-distribution learning problems while remaining highly competitive overall. Keywords: Machine Learning: ML: Neuro-symbolic methods Knowledge Representation and Reasoning: KRR: Description logics and ontologies Knowledge Representation and Reasoning: KRR: Learning and reasoning Machine Learning: ML: Explainable/Interpretable machine learning},
  archive   = {C_IJCAI},
  author    = {N&#39;Dah Jean Kouagou and Stefan Heindorf and Caglar Demir and Axel-Cyrille Ngonga Ngomo},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/479},
  month     = {8},
  pages     = {4335-4343},
  title     = {ROCES: Robust class expression synthesis in description logics via iterative sampling},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploiting multi-label correlation in label distribution
learning. <em>IJCAI</em>, 4326–4334. (<a
href="https://doi.org/10.24963/ijcai.2024/478">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Label Distribution Learning (LDL) is a novel machine learning paradigm that assigns label distribution to each instance. Numerous LDL methods proposed to leverage label correlation in the learning process to solve the exponential-sized output space; among these, many exploited the low-rank structure of label distribution to capture label correlation. However, recent research has unveiled that label distribution matrices typically maintain full rank, posing a challenge to approaches relying on low-rank label correlation. Notably, low-rank label correlation finds widespread adoption in multi-label learning (MLL) literature due to the often low-rank nature of multi-label matrices. Inspired by that, we introduce an auxiliary MLL process within the LDL framework, focusing on capturing low-rank label correlation within this auxiliary MLL component rather than the LDL itself. By doing so, we adeptly exploited low-rank label correlation in our LDL methods. We conduct comprehensive experiments and demonstrate that our methods are superior to existing LDL methods. Besides, the ablation studies justify the advantages of exploiting low-rank label correlation in the auxiliary MLL. Keywords: Machine Learning: ML: Multi-label learning Machine Learning: ML: Applications Machine Learning: ML: Classification},
  archive   = {C_IJCAI},
  author    = {Zhiqiang Kou and Jing Wang and Jiawei Tang and Yuheng Jia and Boyu Shi and Xin Geng},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/478},
  month     = {8},
  pages     = {4326-4334},
  title     = {Exploiting multi-label correlation in label distribution learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient and stable offline-to-online reinforcement
learning via continual policy revitalization. <em>IJCAI</em>, 4317–4325.
(<a href="https://doi.org/10.24963/ijcai.2024/477">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In offline Reinforcement Learning (RL), the pre-trained policies are utilized for initialization and subsequent online fine-tuning. However, existing methods suffer from instability and low sample efficiency compared to pure online learning. This paper identifies these limitations stemming from direct policy initialization using offline-trained policy models. We propose Continual Policy Revitalization (CPR) as a novel efficient, stable fine-tuning method. CPR incorporates a periodic policy revitalization technique, restoring the overtrained policy network to full learning capacity while ensuring stable initial performance. This approach enables fine-tuning without being adversely affected by low-quality pre-trained policies. In contrast to previous research, CPR initializes the new policy with an adaptive policy constraint in policy optimization. Such optimization keeps the new policy close to behavior policy constructed from historical policies. This contributes to stable policy improvement and optimal converged performance. Practically, CPR can seamlessly integrate into existing offline RL algorithms with minimal modification. We empirically validate the effectiveness of our method through extensive experiments, demonstrating substantial improvements in learning stability and efficiency compared to previous approaches. Our code is available at https://github.com/LAMDA-RL/CPR. Keywords: Machine Learning: ML: Reinforcement learning Machine Learning: ML: Offline reinforcement learning},
  archive   = {C_IJCAI},
  author    = {Rui Kong and Chenyang Wu and Chen-Xiao Gao and Zongzhang Zhang and Ming Li},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/477},
  month     = {8},
  pages     = {4317-4325},
  title     = {Efficient and stable offline-to-online reinforcement learning via continual policy revitalization},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning causally disentangled representations via the
principle of independent causal mechanisms. <em>IJCAI</em>, 4308–4316.
(<a href="https://doi.org/10.24963/ijcai.2024/476">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Learning disentangled causal representations is a challenging problem that has gained significant attention recently due to its implications for extracting meaningful information for downstream tasks. In this work, we define a new notion of causal disentanglement from the perspective of independent causal mechanisms. We propose ICM-VAE, a framework for learning causally disentangled representations supervised by causally related observed labels. We model causal mechanisms using nonlinear learnable flow-based diffeomorphic functions to map noise variables to latent causal variables. Further, to promote the disentanglement of causal factors, we propose a causal disentanglement prior learned from auxiliary labels and the latent causal structure. We theoretically show the identifiability of causal factors and mechanisms up to permutation and elementwise reparameterization. We empirically demonstrate that our framework induces highly disentangled causal factors, improves interventional robustness, and is compatible with counterfactual generation. Keywords: Machine Learning: ML: Representation learning Machine Learning: ML: Causality Machine Learning: ML: Generative models},
  archive   = {C_IJCAI},
  author    = {Aneesh Komanduri and Yongkai Wu and Feng Chen and Xintao Wu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/476},
  month     = {8},
  pages     = {4308-4316},
  title     = {Learning causally disentangled representations via the principle of independent causal mechanisms},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pareto inverse reinforcement learning for diverse expert
policy generation. <em>IJCAI</em>, 4300–4307. (<a
href="https://doi.org/10.24963/ijcai.2024/475">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Data-driven offline reinforcement learning and imitation learning approaches have been gaining popularity in addressing sequential decision-making problems. Yet, these approaches rarely consider learning Pareto-optimal policies from a limited pool of expert datasets. This becomes particularly marked due to practical limitations in obtaining comprehensive datasets for all preferences, where multiple conflicting objectives exist and each expert might hold a unique optimization preference for these objectives. In this paper, we adapt inverse reinforcement learning (IRL) by using reward distance estimates for regularizing the discriminator. This enables progressive generation of a set of policies that accommodate diverse preferences on the multiple objectives, while using only two distinct datasets, each associated with a different expert preference. In doing so, we present a Pareto IRL framework (ParIRL) that establishes a Pareto policy set from these limited datasets. In the framework, the Pareto policy set is then distilled into a single, preference-conditioned diffusion model, thus allowing users to immediately specify which expert&#39;s patterns they prefer. Through experiments, we show that ParIRL outperforms other IRL algorithms for various multi-objective control tasks, achieving the dense approximation of the Pareto frontier. We also demonstrate the applicability of ParIRL with autonomous driving in CARLA. Keywords: Machine Learning: ML: Reinforcement learning},
  archive   = {C_IJCAI},
  author    = {Woo Kyung Kim and Minjong Yoo and Honguk Woo},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/475},
  month     = {8},
  pages     = {4300-4307},
  title     = {Pareto inverse reinforcement learning for diverse expert policy generation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). HyQ: Hardware-friendly post-training quantization for
CNN-transformer hybrid networks. <em>IJCAI</em>, 4291–4299. (<a
href="https://doi.org/10.24963/ijcai.2024/474">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Hybrid models that combine CNNs and ViTs have recently emerged as state-of-the-art computer vision models. To efficiently deploy these hybrid models on resource-constrained mobile/edge devices, quantization is emerging as a promising solution. However, post-training quantization (PTQ), which does not require retraining or labeled data, has not been extensively studied for hybrid models. In this study, we propose a novel PTQ technique specialized for CNN-transformer hybrid models by considering the hardware design of hybrid models on AI accelerators such as GPUs and FPGAs. First, we introduce quantization-aware distribution scaling to address the large outliers caused by inter-channel variance in convolution layers. Furthermore, in the transformer block, we propose approximating the integer-only softmax with a linear function. This approach allows us to avoid costly FP32/INT32 multiplications, resulting in more efficient computations. Experimental results show that the proposed quantization method with INT8 precision demonstrated a 0.39% accuracy drop compared with the FP32 baseline on MobileViT-s with the ImageNet-1k dataset. Furthermore, when implemented on the FPGA platform, the proposed linear softmax achieved significant resource savings, reducing the look-up table and flip-flop usage by 1.8 ~ 2.1x and 1.3 ~ 1.9x, respectively, compared with the existing second-order polynomial approximation. The code is available at https://github.com/IDSL-SeoulTech/HyQ. Keywords: Machine Learning: ML: Optimization Computer Vision: CV: Machine learning for vision Computer Vision: CV: Recognition (object detection, categorization) Machine Learning: ML: Deep learning architectures},
  archive   = {C_IJCAI},
  author    = {Nam Joon Kim and Jongho Lee and Hyun Kim},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/474},
  month     = {8},
  pages     = {4291-4299},
  title     = {HyQ: Hardware-friendly post-training quantization for CNN-transformer hybrid networks},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Offline policy learning via skill-step abstraction for
long-horizon goal-conditioned tasks. <em>IJCAI</em>, 4282–4290. (<a
href="https://doi.org/10.24963/ijcai.2024/473">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Goal-conditioned (GC) policy learning often faces a challenge arising from the sparsity of rewards, when confronting long-horizon goals. To address the challenge, we explore skill-based GC policy learning in offline settings, where skills are acquired from existing data and long-horizon goals are decomposed into sequences of near-term goals that align with these skills. Specifically, we present an `offline GC policy learning via skill-step abstraction&#39; framework (GLvSA) tailored for tackling long-horizon GC tasks affected by goal distribution shifts. In the framework, a GC policy is progressively learned offline in conjunction with the incremental modeling of skill-step abstractions on the data. We also devise a GC policy hierarchy that not only accelerates GC policy learning within the framework but also allows for parameter-efficient fine-tuning of the policy. Through experiments with the maze and Franka kitchen environments, we demonstrate the superiority and efficiency of our GLvSA framework in adapting GC policies to a wide range of long-horizon goals. The framework achieves competitive zero-shot and few-shot adaptation performance, outperforming existing GC policy learning and skill-based methods. Keywords: Machine Learning: ML: Reinforcement learning},
  archive   = {C_IJCAI},
  author    = {Donghoon Kim and Minjong Yoo and Honguk Woo},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/473},
  month     = {8},
  pages     = {4282-4290},
  title     = {Offline policy learning via skill-step abstraction for long-horizon goal-conditioned tasks},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Integrating vision-language semantic graphs in multi-view
clustering. <em>IJCAI</em>, 4273–4281. (<a
href="https://doi.org/10.24963/ijcai.2024/472">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In recent years, a variety of graph learning-based multi-view clustering (MVC) methods have emerged. However, these methods continue to face challenges in extracting latent features from real-world data, particularly in scenarios involving high-resolution color images and high-dimensional features. This task is notably difficult in cases where images are visually similar yet semantically diverse. To address this issue, we present a novel large-scale pre-trained model for multi-view clustering, named Integrate Vision-Language Semantic Graphs in Multi-View Clustering (IVSGMV), which harnesses the capabilities of visual-language pre-training models to enhance clustering performance and confronts issues in the unsupervised tuning of pre-trained models for multi-view data. We introduce an effective unsupervised approach for creating semantic graphs from image multi-view datasets using pre-trained encoders. Our method addresses the inherent spatial noise and imbalance in these encoders by employing graph filters and a joint process that integrates both image node and edge features. Additionally, we demonstrate the application of our approach to multi-view image clustering on extensive datasets, notably the high-resolution MVImgNet, achieving an impressive 82% accuracy. Furthermore, our method extends the zero-shot capabilities of large-scale pre-trained models, resulting in good performance in clustering tasks on untrained multi-view datasets. Keywords: Machine Learning: ML: Multi-view learning Machine Learning: ML: Clustering Machine Learning: ML: Multi-modal learning},
  archive   = {C_IJCAI},
  author    = {JunLong Ke and Zichen Wen and Yechenhao Yang and Chenhang Cui and Yazhou Ren and Xiaorong Pu and Lifang He},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/472},
  month     = {8},
  pages     = {4273-4281},
  title     = {Integrating vision-language semantic graphs in multi-view clustering},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Scaling up unbiased search-based symbolic regression.
<em>IJCAI</em>, 4264–4272. (<a
href="https://doi.org/10.24963/ijcai.2024/471">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In a regression task, a function is learned from labeled data to predict the labels at new data points. The goal is to achieve small prediction errors. In symbolic regression, the goal is more ambitious, namely, to learn an interpretable function that makes small prediction errors. This additional goal largely rules out the standard approach used in regression, that is, reducing the learning problem to learning parameters of an expansion of basis functions by optimization. Instead, symbolic regression methods search for a good solution in a space of symbolic expressions. To cope with the typically vast search space, most symbolic regression methods make implicit, or sometimes even explicit, assumptions about its structure. Here, we argue that the only obvious structure of the search space is that it contains small expressions, that is, expressions that can be decomposed into a few subexpressions. We show that systematically searching spaces of small expressions finds solutions that are more accurate and more robust against noise than those obtained by state-of-the-art symbolic regression methods. In particular, systematic search outperforms state-of-the-art symbolic regressors in terms of its ability to recover the true underlying symbolic expressions on established benchmark data sets. Keywords: Machine Learning: ML: Symbolic methods Machine Learning: ML: Explainable/Interpretable machine learning Machine Learning: ML: Regression Search: S: Search and machine learning},
  archive   = {C_IJCAI},
  author    = {Paul Kahlmeyer and Joachim Giesen and Michael Habeck and Henrik Voigt},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/471},
  month     = {8},
  pages     = {4264-4272},
  title     = {Scaling up unbiased search-based symbolic regression},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Temporal domain generalization via learning instance-level
evolving patterns. <em>IJCAI</em>, 4255–4263. (<a
href="https://doi.org/10.24963/ijcai.2024/470">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Temporal Domain Generalization (TDG) aims at learning models under temporally evolving data distributions and achieving generalization to unseen future data distributions following the evolving trend. Existing advanced TDG methods learn the evolving patterns through the collective behaviors observed at the population-level of instances, such as time-varying statistics and parameters, tending to overlook the impact of individual-level instance evolving processes on the decision boundary. However, a major obstacle is that datasets at different timestamps may comprise unrelated instances and there is no inherent existence of the instance-level evolving trajectories, which hinders us from learning how the decision boundary changes. To address the above challenges, we propose a Continuous-Time modelling Optimal Transport trajectories (CTOT) framework in this paper. Specifically, we utilize optimal transport to align the data distributions between each pair of adjacent source domains to construct instance evolving trajectories. Subsequently, they are modelled by a continuous-time model and extrapolated to generate future virtual instances, which help the model to adapt its decision boundary to the future domain. Extensive experiments on multiple classification and regression benchmarks demonstrate the effectiveness of the proposed CTOT framework. The code and appendix are both available on https://github.com/JinYujie99/CTOT. Keywords: Machine Learning: ML: Multi-task and transfer learning Machine Learning: ML: Classification Machine Learning: ML: Incremental learning Machine Learning: ML: Regression},
  archive   = {C_IJCAI},
  author    = {Yujie Jin and Zhibang Yang and Xu Chu and Liantao Ma},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/470},
  month     = {8},
  pages     = {4255-4263},
  title     = {Temporal domain generalization via learning instance-level evolving patterns},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). EFEVD: Enhanced feature extraction for smart contract
vulnerability detection. <em>IJCAI</em>, 4246–4254. (<a
href="https://doi.org/10.24963/ijcai.2024/469">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Because of the wide deployment of smart contracts, smart contract vulnerabilities pose a challenging risk to blockchain security. Currently, deep learning-based vulnerability detection is a very attractive solution due to its ability to identify complex patterns and features. The existing methods mainly consider the contract code content features, expert knowledge patterns, and contract code modalities. To further enhance smart contract vulnerability detection, this paper attempts to identify community features from smart contracts with similar semantic and syntactic structures, and shared features from two related vulnerability detection tasks, vulnerability classification and localization. The experimental results verify that the proposed approach significantly outperforms the state-of-the-art methods in terms of accuracy, recall, precision, and F1-score. Keywords: Machine Learning: ML: Feature extraction, selection and dimensionality reduction Data Mining: DM: Exploratory data mining Multidisciplinary Topics and Applications: MTA: Security and privacy},
  archive   = {C_IJCAI},
  author    = {Chi Jiang and Xihan Liu and Shenao Wang and Jinzhuo Liu and Yin Zhang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/469},
  month     = {8},
  pages     = {4246-4254},
  title     = {EFEVD: Enhanced feature extraction for smart contract vulnerability detection},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). QFormer: An efficient quaternion transformer for image
denoising. <em>IJCAI</em>, 4237–4245. (<a
href="https://doi.org/10.24963/ijcai.2024/468">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Since Deep Convolutional Neural Networks (DCNNs) and Vision Transformer perform well in learning generalizable image priors from large-scale data, these models have been widely used in image denoising tasks. However, vanilla DCNNs and Transformer suffer from two problems. First, the vanilla DCNNs and Transformer only accumulate the output along the channel axis, ignoring the internal relationship among channels. This results in the severely inadequate color structure representation retrieved from color images. Secondly, the DCNNs or Transformer-based image denoising models usually have a large number of parameters, high computational complexity, and slow inference speed. To resolve these issues, this paper proposes a highly-efficient Quaternion Transformer (QFormer) for image denoising. Specifically, the proposed Quaternion Transformer Block (QTB) simplifies the typical Transformer from a multi-branch structure to an elaborately sequential structure mainly with quaternion transformations, to alternately capture both long-range dependencies and local contextual features with color structure information. Furthermore, the proposed QTB can also avoid considerable element-wise multiplications of computing the self-attention matrices. Thus, our QTB can significantly reduce the computational complexity and its sequential structure can further improve the practical inference speed. Comprehensive experiments demonstrate that the proposed QFormer produces state-of-the-art results in both denoising performance and efficiency. We hope that our work will encourage further research to explore the Quaternion Transformer architecture for image denoising tasks. Keywords: Machine Learning: ML: Knowledge-aided learning},
  archive   = {C_IJCAI},
  author    = {Bo Jiang and Yao Lu and Guangming Lu and Bob Zhang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/468},
  month     = {8},
  pages     = {4237-4245},
  title     = {QFormer: An efficient quaternion transformer for image denoising},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Label distribution learning from logical label.
<em>IJCAI</em>, 4228–4236. (<a
href="https://doi.org/10.24963/ijcai.2024/467">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Label distribution learning (LDL) is an effective method to predict the label description degree (a.k.a. label distribution) of a sample. However, annotating label distribution (LD) for training samples is extremely costly. So recent studies often first use label enhancement (LE) to generate the estimated label distribution from the logical label and then apply external LDL algorithms on the recovered label distribution to predict the label distribution for unseen samples. But this step-wise manner overlooks the possible connections between LE and LDL. Moreover, the existing LE approaches may assign some description degrees to invalid labels. To solve the above problems, we propose a novel method to learn an LDL model directly from the logical label, which unifies LE and LDL into a joint model, and avoids the drawbacks of the previous LE methods. We also give the generalization error bound of our method and theoretically prove that directly learning an LDL model from the logical labels is feasible. Extensive experiments on various datasets prove that the proposed approach can construct a reliable LDL model directly from the logical label, and produce more accurate label distribution than the state-of-the-art LE methods. The code and the supplementary file can be found in https://github.com/seutjw/DLDL. Keywords: Machine Learning: ML: Multi-label learning Constraint Satisfaction and Optimization: CSO: Constraint optimization problems Machine Learning: ML: Optimization},
  archive   = {C_IJCAI},
  author    = {Yuheng Jia and Jiawei Tang and Jiahao Jiang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/467},
  month     = {8},
  pages     = {4228-4236},
  title     = {Label distribution learning from logical label},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CAP: A context-aware neural predictor for NAS.
<em>IJCAI</em>, 4219–4227. (<a
href="https://doi.org/10.24963/ijcai.2024/466">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Neural predictors are effective in boosting the time-consuming performance evaluation stage in neural architecture search (NAS), owing to their direct estimation of unseen architectures. Despite the effectiveness, training a powerful neural predictor with fewer annotated architectures remains a huge challenge. In this paper, we propose a context-aware neural predictor (CAP) which only needs a few annotated architectures for training based on the contextual information from the architectures. Specifically, the input architectures are encoded into graphs and the predictor infers the contextual structure around the nodes inside each graph. Then, enhanced by the proposed context-aware self-supervised task, the pre-trained predictor can obtain expressive and generalizable representations of architectures. Therefore, only a few annotated architectures are sufficient for training. Experimental results in different search spaces demonstrate the superior performance of CAP compared with state-of-the-art neural predictors. In particular, CAP can rank architectures precisely at the budget of only 172 annotated architectures in NAS-Bench-101. Moreover, CAP can help find promising architectures in both NAS-Bench-101 and DARTS search spaces on the CIFAR-10 dataset, serving as a useful navigator for NAS to explore the search space efficiently. Keywords: Machine Learning: ML: Evaluation Machine Learning: ML: Automated machine learning},
  archive   = {C_IJCAI},
  author    = {Han Ji and Yuqi Feng and Yanan Sun},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/466},
  month     = {8},
  pages     = {4219-4227},
  title     = {CAP: A context-aware neural predictor for NAS},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Symplectic neural gaussian processes for meta-learning
hamiltonian dynamics. <em>IJCAI</em>, 4210–4218. (<a
href="https://doi.org/10.24963/ijcai.2024/465">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose a meta-learning method for modeling Hamiltonian dynamics from a limited number of data. Although Hamiltonian neural networks have been successfully used for modeling dynamics that obey the energy conservation law, they require many data to achieve high performance. The proposed method meta-learns our neural network-based model using datasets in various dynamical systems, such that our model can predict vector fields of unseen systems. In our model, a system representation is inferred from given small data using an encoder network. Then, the system-specific vector field is predicted by modeling the Hamiltonian using a Gaussian process (GP) with neural network-based mean and kernel functions that depend on the inferred system representation. This GP-based Hamiltonian allows us to analytically obtain predictions that are adapted to small data while imposing the constraint of the conservation law. The neural networks are shared across systems, which enables us to learn knowledge from multiple systems, and use it for unseen systems. In our experiments, we demonstrate that the proposed method outperforms existing methods for predicting dynamics from a small number of observations in target systems. Keywords: Machine Learning: ML: Meta-learning Multidisciplinary Topics and Applications: MTA: Physical sciences},
  archive   = {C_IJCAI},
  author    = {Tomoharu Iwata and Yusuke Tanaka},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/465},
  month     = {8},
  pages     = {4210-4218},
  title     = {Symplectic neural gaussian processes for meta-learning hamiltonian dynamics},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An efficient prototype-based clustering approach for edge
pruning in graph neural networks to battle over-smoothing.
<em>IJCAI</em>, 4201–4209. (<a
href="https://doi.org/10.24963/ijcai.2024/464">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Topology augmentation is a popular strategy to address the issue of over-smoothing in graph neural networks (GNNs). To prevent potential distortion of node representations, an essential principle is to enhance the separability between embeddings of nodes from different classes while preserving smoothness among nodes of the same class. However, differentiating between inter-class and intra-class edges becomes arduous when class labels are unavailable or the graph is partially labeled. While clustering offers an alternative for identifying closely connected groups of nodes, traditional clustering methods face challenges when applied to GNNs in terms of accuracy, efficiency, adaptability, and scalability to diverse graphs. To address these limitations, we introduce ClusterDrop, which uses learnable prototypes for efficient clustering and incorporates supervised signals to enhance accuracy and adaptability across different graphs. Experiments on six datasets with varying graph structures demonstrate its effectiveness in alleviating over-smoothing and enhancing GNN performance. Keywords: Machine Learning: ML: Sequence and graph learning Data Mining: DM: Mining graphs Data Mining: DM: Networks},
  archive   = {C_IJCAI},
  author    = {Yuyang Huang and Wenjing Lu and Yang Yang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/464},
  month     = {8},
  pages     = {4201-4209},
  title     = {An efficient prototype-based clustering approach for edge pruning in graph neural networks to battle over-smoothing},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unified view imputation and feature selection learning for
incomplete multi-view data. <em>IJCAI</em>, 4192–4200. (<a
href="https://doi.org/10.24963/ijcai.2024/463">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Although multi-view unsupervised feature selection (MUFS) is an effective technology for reducing dimensionality in machine learning, existing methods cannot directly deal with incomplete multi-view data where some samples are missing in certain views. These methods should first apply predetermined values to impute missing data, then perform feature selection on the complete dataset. Separating imputation and feature selection processes fails to capitalize on the potential synergy where local structural information gleaned from feature selection could guide the imputation, thereby improving the feature selection performance in turn. Additionally, previous methods only focus on leveraging samples&#39; local structure information, while ignoring the intrinsic locality of the feature space. To tackle these problems, a novel MUFS method, called UNified view Imputation and Feature selectIon lEaRning (UNIFIER), is proposed. UNIFIER explores the local structure of multi-view data by adaptively learning similarity-induced graphs from both the sample and feature spaces. Then, UNIFIER dynamically recovers the missing views, guided by the sample and feature similarity graphs during the feature selection procedure. Furthermore, the half-quadratic minimization technique is used to automatically weight different instances, alleviating the impact of outliers and unreliable restored data. Comprehensive experimental results demonstrate that UNIFIER outperforms other state-of-the-art methods. Keywords: Machine Learning: ML: Feature extraction, selection and dimensionality reduction Machine Learning: ML: Unsupervised learning},
  archive   = {C_IJCAI},
  author    = {Yanyong Huang and Zongxin Shen and Tianrui Li and Fengmao Lv},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/463},
  month     = {8},
  pages     = {4192-4200},
  title     = {Unified view imputation and feature selection learning for incomplete multi-view data},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep multi-dimensional classification with pairwise
dimension-specific features. <em>IJCAI</em>, 4183–4191. (<a
href="https://doi.org/10.24963/ijcai.2024/462">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In multi-dimensional classification (MDC), each instance is associated with multiple class variables characterizing the semantics of objects from different dimensions. To consider the dependencies among class variables and the specific characteristics contained in different semantic dimensions, a novel deep MDC approach named PIST is proposed to jointly deal with the two issues via learning pairwise dimension-specific features. Specifically, PIST conducts pairwise grouping to model the dependencies between each pair of class variables, which are more reliable with limited training samples. For extracting pairwise dimension-specific features, PIST weights the feature embedding with a feature importance vector, which is learned via utilizing a global loss measurement based on intra-class and inter-class covariance. Final prediction w.r.t. each dimension is determined by combining the joint probabilities related to this dimension. Comparative studies with eleven real-world MDC data sets clearly validate the effectiveness of the proposed approach. Keywords: Machine Learning: ML: Classification Machine Learning: ML: Multi-label learning},
  archive   = {C_IJCAI},
  author    = {Teng Huang and Bin-Bin Jia and Min-Ling Zhang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/462},
  month     = {8},
  pages     = {4183-4191},
  title     = {Deep multi-dimensional classification with pairwise dimension-specific features},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Negative-binomial randomized gamma dynamical systems for
heterogeneous overdispersed count time sequences. <em>IJCAI</em>,
4174–4182. (<a href="https://doi.org/10.24963/ijcai.2024/461">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Modeling count-valued time sequences has been receiving growing interests because count time sequences naturally arise in physical and social domains. Poisson gamma dynamical systems (PGDSs) are newly-developed methods, which can well capture the expressive latent transition structure and bursty dynamics behind count sequences. In particular, PGDSs demonstrate superior performance in terms of data imputation and prediction, compared with canonical linear dynamical system (LDS) based methods. Despite these advantages, PGDS cannot capture the heterogeneous overdispersed behaviours of the underlying dynamic processes. To mitigate this defect, we propose a negative-binomial-randomized gamma Markov process, which not only significantly improves the predictive performance of the proposed dynamical system, but also facilitates the fast convergence of the inference algorithm. Moreover, we develop methods to estimate both factor-structured and graph-structured transition dynamics, which enable us to infer more explainable latent structure, compared with PGDSs. Finally, we demonstrate the explainable latent structure learned by the proposed method, and show its superior performance in imputing missing data and forecasting future observations, compared with the related models. Keywords: Machine Learning: ML: Time series and data streams Machine Learning: ML: Bayesian learning Machine Learning: ML: Probabilistic machine learning Uncertainty in AI: UAI: Tractable probabilistic models},
  archive   = {C_IJCAI},
  author    = {Rui Huang and Sikun Yang and Heinz Koeppl},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/461},
  month     = {8},
  pages     = {4174-4182},
  title     = {Negative-binomial randomized gamma dynamical systems for heterogeneous overdispersed count time sequences},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LeRet: Language-empowered retentive network for time series
forecasting. <em>IJCAI</em>, 4165–4173. (<a
href="https://doi.org/10.24963/ijcai.2024/460">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Time series forecasting (TSF) plays a pivotal role in many real-world applications. Recently, the utilization of Large Language Models (LLM) in TSF has demonstrated exceptional predictive performance, surpassing most task-specific forecasting models. The success of LLM-based forecasting methods underscores the importance of causal dependence modeling and pre-trained knowledge transfer. However, challenges persist in directly applying LLM to TSF, i.e., the unacceptable parameter scales for resource-intensive model optimization, and the significant gap of feature space between structural numerical time series and natural language. To this end, we propose LeRet, a Language-empowered Retentive network for TSF. Technically, inspired by the causal extraction in LLM, we propose a causal dependence learner, enhanced by a patch-level pre-training task, to capture sequential causal evolution. To minimize the gap between numeric and language, we initialize a language description protocol for time series and design a TS-related language knowledge extractor to learn from language description, avoiding training with large-scale parameters. Finally, we dedicatedly achieve a Language-TS Modality Integrator for the fusion of two types data, and enable language-empowered sequence forecasting. Extensive evaluations demonstrate the effectiveness of our LeRet, especially reveal superiority on few-shot, and zero-shot forecasting tasks. Code is available at https://github.com/hqh0728/LeRet. Keywords: Machine Learning: ML: Time series and data streams Data Mining: DM: Applications Machine Learning: ML: Applications Machine Learning: ML: Regression},
  archive   = {C_IJCAI},
  author    = {Qihe Huang and Zhengyang Zhou and Kuo Yang and Gengyu Lin and Zhongchao Yi and Yang Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/460},
  month     = {8},
  pages     = {4165-4173},
  title     = {LeRet: Language-empowered retentive network for time series forecasting},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multimodal representation distribution learning for medical
image segmentation. <em>IJCAI</em>, 4156–4164. (<a
href="https://doi.org/10.24963/ijcai.2024/459">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Medical image segmentation is one of the most critical tasks in medical image analysis. However, the performance of existing methods is limited by the lack of high-quality labeled data due to the expensive data annotation. To alleviate this limitation, we propose a novel multi-modal learning method for medical image segmentation. In our method, medical text annotation is incorporated to compensate for the quality deficiency in image data. Moreover, previous multi-modal fusion methods ignore the commonalities and differences between different modalities. Ideally, the fused features should maximize valuable information while minimizing redundant information. To achieve this goal, we propose a multimodal feature distribution learning method. It is adopted to model the commonalities and differences between text and image. Since medical image segmentation needs to predict detailed segmentation boundaries, we also design a prompt encoder to achieve fine-grained segmentation. Experimental results on three datasets show that the proposed method obtains superior segmentation performance. Source codes will be available at https://github.com/GPIOX/Multimodal.git. Keywords: Machine Learning: ML: Multi-modal learning Computer Vision: CV: Segmentation Computer Vision: CV: Representation learning},
  archive   = {C_IJCAI},
  author    = {Chao Huang and Weichao Cai and Qiuping Jiang and Zhihua Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/459},
  month     = {8},
  pages     = {4156-4164},
  title     = {Multimodal representation distribution learning for medical image segmentation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Practical hybrid gradient compression for federated learning
systems. <em>IJCAI</em>, 4147–4155. (<a
href="https://doi.org/10.24963/ijcai.2024/458">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The high communication cost is a major challenge in the federated learning (FL) training process. Several methods have been proposed to reduce communication costs on the uplink channel, primarily sparsification-based methods, which have overlooked the impact of downlink channels. However, model accuracy and communication cost issues arise when applying them in practical FL applications, especially when the bandwidth is limited both on the uplink and downlink channels. In this paper, we propose a novel secure-FL-compatible hybrid gradient compression framework (HGC) that handles both uplink and downlink communication. Specifically, HGC identifies and exploits three types of redundancies in the FL training process. With proposed optimization methods based on compression ratio correction and dynamic momentum correction, HGC improves the trade-off between communication cost and model performance. The extensive theoretical and empirical analysis demonstrates the effectiveness of our framework in achieving a high compression ratio for both uplink and downlink communications with negligible loss of model accuracy, surpassing the state-of-the-art compression methods. Keywords: Machine Learning: ML: Federated learning},
  archive   = {C_IJCAI},
  author    = {Sixu Hu and Linshan Jiang and Bingsheng He},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/458},
  month     = {8},
  pages     = {4147-4155},
  title     = {Practical hybrid gradient compression for federated learning systems},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Feature norm regularized federated learning: Utilizing data
disparities for model performance gains. <em>IJCAI</em>, 4136–4146. (<a
href="https://doi.org/10.24963/ijcai.2024/457">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Federated learning (FL) is a machine learning paradigm that aggregates knowledge and utilizes computational power from multiple participants to train a global model. However, a commonplace challenge—non-independent and identically distributed (non-i.i.d.) data across participants—can lead to significant divergence in model updates, thus diminishing training efficacy. In this paper, we propose the Feature Norm Regularized Federated Learning (FNR-FL) algorithm to tackle the non-i.i.d challenge. FNR-FL incorporates class average feature norms into the loss function by a straightforward yet effective regularization strategy. The core idea of FNR-FL is to penalize the deviations in the update directions of local models caused by the non-i.i.d data. Theoretically, we provide convergence guarantees for FNR-FL when training under non-i.i.d scenarios. Practically, our comprehensive experimental evaluations demonstrate that FNR-FL significantly outperforms existing FL algorithms in terms of test accuracy, and maintains a competitive convergence rate with lower communication overhead and shorter duration. Compared to FedAvg, FNR-FL exhibits a 66.24% improvement in accuracy and an 11.40% reduction in training time, underscoring its enhanced effectiveness and efficiency. The code is available on GitHub at: https://github.com/LonelyMoonDesert/FNR-FL. Keywords: Machine Learning: ML: Federated learning Machine Learning: ML: Optimization Machine Learning: ML: Robustness Machine Learning: ML: Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Ke Hu and Liyao Xiang and Peng Tang and Weidong Qiu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/457},
  month     = {8},
  pages     = {4136-4146},
  title     = {Feature norm regularized federated learning: Utilizing data disparities for model performance gains},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamically anchored prompting for task-imbalanced continual
learning. <em>IJCAI</em>, 4127–4135. (<a
href="https://doi.org/10.24963/ijcai.2024/456">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Existing continual learning literature relies heavily on a strong assumption that tasks arrive with a balanced data stream, which is often unrealistic in real-world applications. In this work, we explore task-imbalanced continual learning (TICL) scenarios where the distribution of task data is non-uniform across the whole learning process. We find that imbalanced tasks significantly challenge the capability of models to control the trade-off between stability and plasticity from the perspective of recent prompt-based continual learning methods. On top of the above finding, we propose Dynamically Anchored Prompting (DAP), a prompt-based method that only maintains a single general prompt to adapt to the shifts within a task stream dynamically. This general prompt is regularized in the prompt space with two specifically designed prompt anchors, called boosting anchor and stabilizing anchor, to balance stability and plasticity in TICL. Remarkably, DAP achieves this balance by only storing a prompt across the data stream, therefore offering a substantial advantage in rehearsal-free CL. Extensive experiments demonstrate that the proposed DAP results in 4.5% to 15% absolute improvements over state-of-the-art methods on benchmarks under task-imbalanced settings. Our code is available at https://github.com/chenxing6666/DAP. Keywords: Machine Learning: ML: Incremental learning Computer Vision: CV: Recognition (object detection, categorization) Data Mining: DM: Class imbalance and unequal cost Machine Learning: ML: Classification},
  archive   = {C_IJCAI},
  author    = {Chenxing Hong and Yan Jin and Zhiqi Kang and Yizhou Chen and Mengke Li and Yang Lu and Hanzi Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/456},
  month     = {8},
  pages     = {4127-4135},
  title     = {Dynamically anchored prompting for task-imbalanced continual learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). EPIC: Graph augmentation with edit path interpolation via
learnable cost. <em>IJCAI</em>, 4116–4126. (<a
href="https://doi.org/10.24963/ijcai.2024/455">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Data augmentation plays a critical role in improving model performance across various domains, but it becomes challenging with graph data due to their complex and irregular structure. To address this issue, we propose EPIC (Edit Path Interpolation via learnable Cost), a novel interpolation-based method for augmenting graph datasets. To interpolate between two graphs lying in an irregular domain, EPIC leverages the concept of graph edit distance, constructing an edit path that represents the transformation process between two graphs via edit operations. Moreover, our method introduces a context-sensitive cost model that accounts for the importance of specific edit operations formulated through a learning framework. This allows for a more nuanced transformation process, where the edit distance is not merely count-based but reflects meaningful graph attributes. With randomly sampled graphs from the edit path, we enrich the training set to enhance the generalization capability of classification models. Experimental evaluations across several benchmark datasets demonstrate that our approach outperforms existing augmentation techniques in many tasks. Keywords: Machine Learning: ML: Sequence and graph learning},
  archive   = {C_IJCAI},
  author    = {Jaeseung Heo and Seungbeom Lee and Sungsoo Ahn and Dongwoo Kim},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/455},
  month     = {8},
  pages     = {4116-4126},
  title     = {EPIC: Graph augmentation with edit path interpolation via learnable cost},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SAEIR: Sequentially accumulated entropy intrinsic reward for
cooperative multi-agent reinforcement learning with sparse reward.
<em>IJCAI</em>, 4107–4115. (<a
href="https://doi.org/10.24963/ijcai.2024/454">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-agent reinforcement learning (MARL) performs well for solving complex cooperative tasks when the scenarios have well-defined dense rewards. However, there are usually sparse reward settings in many real-world multi-agent systems, which makes it difficult for MARL algorithms to successfully learn an effective strategy. To tackle this problem, we propose a novel sequentially accumulated entropy intrinsic reward named SAEIR, which utilizes the entropy of multi-agent system as a bonus to accelerate learning. Specifically, the multi-scale hypergraph critic is proposed to obtain high-order system state representation, which also enhances the ability to effectively evaluate the action produced by the actor. Based on the comprehensive and compact system state representation, the orderliness of multi-agent systems can be measured to determine the highly valuable states for adding entropy-based intrinsic rewards which leads to a highly efficient learning process. Empirical results demonstrate that our proposed method achieves state-of-the-art performance in several complex cooperative multi-agent environments with sparse reward settings. Keywords: Machine Learning: ML: Multiagent Reinforcement Learning Agent-based and Multi-agent Systems: MAS: Coordination and cooperation Agent-based and Multi-agent Systems: MAS: Multi-agent learning},
  archive   = {C_IJCAI},
  author    = {Xin He and Hongwei Ge and Yaqing Hou and Jincheng Yu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/454},
  month     = {8},
  pages     = {4107-4115},
  title     = {SAEIR: Sequentially accumulated entropy intrinsic reward for cooperative multi-agent reinforcement learning with sparse reward},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). BlockEcho: Retaining long-range dependencies for imputing
block-wise missing data. <em>IJCAI</em>, 4098–4106. (<a
href="https://doi.org/10.24963/ijcai.2024/453">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Block-wise missing data poses significant challenges in real-world data imputation tasks. Compared to scattered missing data, block-wise gaps exacerbate adverse effects on subsequent analytic and machine learning tasks, as the lack of local neighboring elements significantly reduces the interpolation capability and predictive power. However, this issue has not received adequate attention. Most SOTA matrix completion methods appeared less effective, primarily due to overreliance on neighboring elements for predictions. We systematically analyze the issue and propose a novel matrix completion method &quot;BlockEcho&quot; for a more comprehensive solution. This method creatively integrates Matrix Factorization (MF) within Generative Adversarial Networks (GAN) to explicitly retain long-distance inter-element relationships in the original matrix. Besides, we incorporate an additional discriminator for GAN, comparing the generator&#39;s intermediate progress with pre-trained MF results to constrain high-order feature distributions. Subsequently, we evaluate BlockEcho on public datasets across three domains. Results demonstrate superior performance over both traditional and SOTA methods when imputing block-wise missing data, especially at higher missing rates. The advantage also holds for scattered missing data at high missing rates. We also contribute on the analyses in providing theoretical justification on the optimality and convergence of fusing MF and GAN for missing block data. Keywords: Machine Learning: ML: Generative models Data Mining: DM: Other},
  archive   = {C_IJCAI},
  author    = {Qiao Han and Mingqian Li and Yao Yang and Yiteng Zhai},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/453},
  month     = {8},
  pages     = {4098-4106},
  title     = {BlockEcho: Retaining long-range dependencies for imputing block-wise missing data},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). InfoMatch: Entropy neural estimation for semi-supervised
image classification. <em>IJCAI</em>, 4089–4097. (<a
href="https://doi.org/10.24963/ijcai.2024/452">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Semi-supervised image classification, leveraging pseudo supervision and consistency regularization, has demonstrated remarkable success. However, the ongoing challenge lies in fully exploiting the potential of unlabeled data. To address this, we employ information entropy neural estimation to utilize the potential of unlabeled samples. Inspired by contrastive learning, the entropy is estimated by maximizing a lower bound on mutual information across different augmented views. Moreover, we theoretically analyze that the information entropy of the posterior of an image classifier is approximated by maximizing the likelihood function of the softmax predictions. Guided by these insights, we optimize our model from both perspectives to ensure that the predicted probability distribution closely aligns with the ground-truth distribution. Given the theoretical connection to information entropy, we name our method InfoMatch. Through extensive experiments, we show its superior performance. The source code is available at https://github.com/kunzhan/InfoMatch. Keywords: Machine Learning: ML: Semi-supervised learning Machine Learning: ML: Self-supervised Learning Machine Learning: ML: Unsupervised learning Computer Vision: CV: Representation learning},
  archive   = {C_IJCAI},
  author    = {Qi Han and Zhibo Tian and Chengwei Xia and Kun Zhan},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/452},
  month     = {8},
  pages     = {4089-4097},
  title     = {InfoMatch: Entropy neural estimation for semi-supervised image classification},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Online sampling and decision making with low entropy.
<em>IJCAI</em>, 4080–4088. (<a
href="https://doi.org/10.24963/ijcai.2024/451">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Suppose we are given an integer k and n boxes, labeled 1,2,…,n by an adversary, each containing a single number chosen from an unknown distribution; the n distributions not necessarily identical. We have to choose an order to sequentially open the boxes, and each time we open the next box in this order, we learn the number inside. If we reject a number in a box, the box cannot be recalled. Our goal is to accept k of these numbers, without necessarily opening all boxes, such that the accepted numbers are the k largest numbers in the boxes (thus their sum is maximized). This problem, sometimes called a free order multiple-choice secretary problem, is one of the classic examples of online decision making problems. A natural approach to solve such problems is to sample elements in random order; however, as indicated in several sources, e.g., Turan et al. NIST 2015 [35], Bierhorst et al. Nature 2018 [10], pure randomness is hard to get in reality. Thus, pseudorandomness has to be used, with a small entropy. We show that with a very small O(log log n) entropy an almost-optimal approximation of the value of k largest numbers can be selected, with only a polynomially small additive error, for k 1. Keywords: Machine Learning: ML: Online learning Machine Learning: ML: Learning theory Machine Learning: ML: Sequence and graph learning},
  archive   = {C_IJCAI},
  author    = {Mohammad Taghi Hajiaghayi and Dariusz R. Kowalski and Piotr Krysta and Jan Olkowski},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/451},
  month     = {8},
  pages     = {4080-4088},
  title     = {Online sampling and decision making with low entropy},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sample quality heterogeneity-aware federated causal
discovery through adaptive variable space selection. <em>IJCAI</em>,
4071–4079. (<a href="https://doi.org/10.24963/ijcai.2024/450">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Federated causal discovery (FCD) aims to uncover causal relationships among variables from decentralized data across multiple clients, while preserving data privacy. In practice, the sample quality of each client&#39;s local data may vary across different variable spaces, referred to as sample quality heterogeneity. Thus, data from different clients might be suitable for learning different causal relationships among variables. Model aggregated under existing FCD methods requires the entire model parameters from each client, thereby being unable to handle the sample quality heterogeneity issue. In this paper, we propose the Federated Adaptive Causal Discovery (FedACD) method to bridge this gap. During federated model aggregation, it adaptively selects the causal relationships learned under the &quot;good&quot; variable space (i.e., one with high-quality samples) from each client, while masking those learned under the &quot;bad&quot; variable space (i.e., one with low-quality samples). This way, each client only needs to send the optimal learning results to the server, achieving accurate FCD. Extensive experiments on various types of datasets demonstrate significant advantages of FedACD over existing methods. The source code is available at https://github.com/Xianjie-Guo/FedACD. Keywords: Machine Learning: ML: Federated learning Knowledge Representation and Reasoning: KRR: Causality Machine Learning: ML: Causality Uncertainty in AI: UAI: Causality, structural causal models and causal inference},
  archive   = {C_IJCAI},
  author    = {Xianjie Guo and Kui Yu and Hao Wang and Lizhen Cui and Han Yu and Xiaoxiao Li},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/450},
  month     = {8},
  pages     = {4071-4079},
  title     = {Sample quality heterogeneity-aware federated causal discovery through adaptive variable space selection},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ParsNets: A parsimonious composition of orthogonal and
low-rank linear networks for zero-shot learning. <em>IJCAI</em>,
4062–4070. (<a href="https://doi.org/10.24963/ijcai.2024/449">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper provides a novel parsimonious yet efficient design for zero-shot learning (ZSL), dubbed ParsNets, in which we are interested in learning a composition of on-device friendly linear networks, each with orthogonality and low-rankness properties, to achieve equivalent or better performance against deep models. Concretely, we first refactor the core module of ZSL, i.e., the visual-semantics mapping function, into several base linear networks that correspond to diverse components of the semantic space, wherein the complex nonlinearity can be collapsed into simple local linearities. Then, to facilitate the generalization of local linearities, we construct a maximal margin geometry on the learned features by enforcing low-rank constraints on intra-class samples and high-rank constraints on inter-class samples, resulting in orthogonal subspaces for different classes. To enhance the model&#39;s adaptability and counterbalance the over-/under-fittings, a set of sample-wise indicators is employed to select a sparse subset from these base linear networks to form a composite semantic predictor for each sample. Notably, maximal margin geometry can guarantee the diversity of features and, meanwhile, local linearities guarantee efficiency. Thus, our ParsNets can generalize better to unseen classes and can be deployed flexibly on resource-constrained devices. Keywords: Machine Learning: ML: Cost-sensitive learning Machine Learning: ML: Ensemble methods Machine Learning: ML: Few-shot learning Machine Learning: ML: Learning sparse models},
  archive   = {C_IJCAI},
  author    = {Jingcai Guo and Qihua Zhou and Xiaocheng Lu and Ruibin Li and Ziming Liu and Jie Zhang and Bo Han and Junyang Chen and Xin Xie and Song Guo},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/449},
  month     = {8},
  pages     = {4062-4070},
  title     = {ParsNets: A parsimonious composition of orthogonal and low-rank linear networks for zero-shot learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). P2P: Transforming from point supervision to explicit visual
prompt for object detection and segmentation. <em>IJCAI</em>, 4053–4061.
(<a href="https://doi.org/10.24963/ijcai.2024/448">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Point-supervised vision tasks, including detection and segmentation, aiming to learn a network that transforms from points to pseudo labels, have attracted much attention in recent years. However, the lack of precise object size and boundary annotations in the point-supervised condition results in a large performance gap between point- and fully-supervised methods. In this paper, we propose a novel iterative learning framework, Point to Prompt (P2P), for point-supervised object detection and segmentation, with the key insight of transforming from point supervision to explicit visual prompt of the foundation model. The P2P is formulated as an iterative refinement process of two stages: Semantic Explicit Prompt Generation (SEPG) and Prompt Guided Spatial Refinement (PGSR). Specifically, SEPG serves as a prompt generator for generating semantic-explicit prompts from point input via a group-based learning strategy. In the PGSR stage, prompts guide the visual foundation model to further refine the object regions, by leveraging the outstanding generalization ability of the foundation model. The two stages are iterated multiple times to improve the quality of predictions progressively. Experimental results on multiple datasets demonstrate that P2P achieves SOTA performance in both detection and segmentation tasks, further narrowing the performance gap with fully-supervised methods. The source code and supplementary material can be found at https://github.com/guangqian-guo/P2P. Keywords: Machine Learning: ML: Weakly supervised learning Computer Vision: CV: Recognition (object detection, categorization) Computer Vision: CV: Segmentation},
  archive   = {C_IJCAI},
  author    = {Guangqian Guo and Dian Shao and Chenguang Zhu and Sha Meng and Xuan Wang and Shan Gao},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/448},
  month     = {8},
  pages     = {4053-4061},
  title     = {P2P: Transforming from point supervision to explicit visual prompt for object detection and segmentation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PoRank: A practical framework for learning to rank policies.
<em>IJCAI</em>, 4044–4052. (<a
href="https://doi.org/10.24963/ijcai.2024/447">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In many real-world scenarios, we need to select from a set of candidate policies before online deployment. Although existing Off-policy evaluation (OPE) methods can be used to estimate the online performance, they suffer from high variance. Fortunately, we care only about the ranking of the candidate policies, rather than their exact online rewards. Based on this, we propose a novel framework PoRank for learning to rank policies. In practice, learning to rank policies faces two main challenges: 1) generalization over the huge policy space and 2) lack of supervision signals. To overcome the first challenge, PoRank uses a Policy Comparison Transformer (PCT) for learning cross-policy representations, which capture the core discrepancies between policies and generalizes well across the whole policy space. The second challenge arises because learning to rank requires online comparisons of policies as ground-truth labels, whereas deploying policies online might be highly expensive. To overcome this, PoRank adopts a crowdsourcing based learning-to-rank (LTR) framework, where a set of OPE algorithms are employed to provide weak comparison labels. Experimental results show that PoRank not only outperforms baselines when the ground-truth labels are provided, but also achieves competitive performance when the ground-truth labels are unavailable. Keywords: Machine Learning: ML: Reinforcement learning},
  archive   = {C_IJCAI},
  author    = {Pengjie Gu and Mengchen Zhao and Xu He and Yi Cai and Bo An},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/447},
  month     = {8},
  pages     = {4044-4052},
  title     = {PoRank: A practical framework for learning to rank policies},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unlearning during learning: An efficient federated machine
unlearning method. <em>IJCAI</em>, 4035–4043. (<a
href="https://doi.org/10.24963/ijcai.2024/446">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In recent years, Federated Learning (FL) has garnered significant attention as a distributed machine learning paradigm. To facilitate the implementation of the &quot;right to be forgotten,&quot; the concept of federated machine unlearning (FMU) has also emerged. However, current FMU approaches often involve additional time-consuming steps and may not offer comprehensive unlearning capabilities, which renders them less practical in real FL scenarios. In this paper, we introduce FedAU, an innovative and efficient FMU framework aimed at overcoming these limitations. Specifically, FedAU incorporates a lightweight auxiliary unlearning module into the learning process and employs a straightforward linear operation to facilitate unlearning. This approach eliminates the requirement for extra time-consuming steps, rendering it well-suited for FL. Furthermore, FedAU exhibits remarkable versatility. It not only enables multiple clients to carry out unlearning tasks concurrently but also supports unlearning at various levels of granularity, including individual data samples, specific classes, and even at the client level. We conducted extensive experiments on MNIST, CIFAR10, and CIFAR100 datasets to evaluate the performance of FedAU. The results demonstrate that FedAU effectively achieves the desired unlearning effect while maintaining model accuracy. Keywords: Machine Learning: ML: Federated learning Multidisciplinary Topics and Applications: MTA: Security and privacy},
  archive   = {C_IJCAI},
  author    = {Hanlin Gu and Gongxi Zhu and Jie Zhang and Xinyuan Zhao and Yuxing Han and Lixin Fan and Qiang Yang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/446},
  month     = {8},
  pages     = {4035-4043},
  title     = {Unlearning during learning: An efficient federated machine unlearning method},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Temporal graph ODEs for irregularly-sampled time series.
<em>IJCAI</em>, 4025–4034. (<a
href="https://doi.org/10.24963/ijcai.2024/445">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Modern graph representation learning works mostly under the assumption of dealing with regularly sampled temporal graph snapshots, which is far from realistic, e.g., social networks and physical systems are characterized by continuous dynamics and sporadic observations. To address this limitation, we introduce the Temporal Graph Ordinary Differential Equation (TG-ODE) framework, which learns both the temporal and spatial dynamics from graph streams where the intervals between observations are not regularly spaced. We empirically validate the proposed approach on several graph benchmarks, showing that TG-ODE can achieve state-of-the-art performance in irregular graph stream tasks. Keywords: Machine Learning: ML: Sequence and graph learning Machine Learning: ML: Deep learning architectures Machine Learning: ML: Time series and data streams},
  archive   = {C_IJCAI},
  author    = {Alessio Gravina and Daniele Zambon and Davide Bacciu and Cesare Alippi},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/445},
  month     = {8},
  pages     = {4025-4034},
  title     = {Temporal graph ODEs for irregularly-sampled time series},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). History repeats itself: A baseline for temporal knowledge
graph forecasting. <em>IJCAI</em>, 4016–4024. (<a
href="https://doi.org/10.24963/ijcai.2024/444">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Temporal Knowledge Graph (TKG) Forecasting aims at predicting links in Knowledge Graphs for future timesteps based on a history of Knowledge Graphs. To this day, standardized evaluation protocols and rigorous comparison across TKG models are available, but the importance of simple baselines is often neglected in the evaluation, which prevents researchers from discerning actual and fictitious progress. We propose to close this gap by designing an intuitive baseline for TKG Forecasting based on predicting recurring facts. Compared to most TKG models, it requires little hyperparameter tuning and no iterative training. Further, it can help to identify failure modes in existing approaches. The empirical findings are quite unexpected: compared to 11 methods on five datasets, our baseline ranks first or third in three of them, painting a radically different picture of the predictive quality of the state of the art. Keywords: Machine Learning: ML: Sequence and graph learning Data Mining: DM: Knowledge graphs and knowledge base completion Machine Learning: ML: Evaluation},
  archive   = {C_IJCAI},
  author    = {Julia Gastinger and Christian Meilicke and Federico Errica and Timo Sztyler and Anett Schülke and Heiner Stuckenschmidt},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/444},
  month     = {8},
  pages     = {4016-4024},
  title     = {History repeats itself: A baseline for temporal knowledge graph forecasting},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exterior penalty policy optimization with penalty metric
network under constraints. <em>IJCAI</em>, 4007–4015. (<a
href="https://doi.org/10.24963/ijcai.2024/443">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In Constrained Reinforcement Learning (CRL), agents explore the environment to learn the optimal policy while satisfying constraints. The penalty function method has recently been studied as an effective approach for handling constraints, which imposes constraints penalties on the objective to transform the constrained problem into an unconstrained one. However, it is challenging to choose appropriate penalties that balance policy performance and constraint satisfaction efficiently. In this paper, we propose a theoretically guaranteed penalty function method, Exterior Penalty Policy Optimization (EPO), with adaptive penalties generated by a Penalty Metric Network (PMN). PMN responds appropriately to varying degrees of constraint violations, enabling efficient constraint satisfaction and safe exploration. We theoretically prove that EPO consistently improves constraint satisfaction with a convergence guarantee. We propose a new surrogate function and provide worst-case constraint violation and approximation error. In practice, we propose an effective smooth penalty function, which can be easily implemented with a first-order optimizer. Extensive experiments are conducted, showing that EPO outperforms the baselines in terms of policy performance and constraint satisfaction with a stable training process, particularly on complex tasks. Keywords: Machine Learning: ML: Reinforcement learning Constraint Satisfaction and Optimization: CSO: Constraint optimization problems Machine Learning: ML: Optimization Machine Learning: ML: Theory of deep learning},
  archive   = {C_IJCAI},
  author    = {Shiqing Gao and Jiaxin Ding and Luoyi Fu and Xinbing Wang and Chenghu Zhou},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/443},
  month     = {8},
  pages     = {4007-4015},
  title     = {Exterior penalty policy optimization with penalty metric network under constraints},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Spatial-temporal-decoupled masked pre-training for
spatiotemporal forecasting. <em>IJCAI</em>, 3998–4006. (<a
href="https://doi.org/10.24963/ijcai.2024/442">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Spatiotemporal forecasting techniques are significant for various domains such as transportation, energy, and weather. Accurate prediction of spatiotemporal series remains challenging due to the complex spatiotemporal heterogeneity. In particular, current end-to-end models are limited by input length and thus often fall into spatiotemporal mirage, i.e., similar input time series followed by dissimilar future values and vice versa. To address these problems, we propose a novel self-supervised pre-training framework Spatial-Temporal-Decoupled Masked Pre-training (STD-MAE) that employs two decoupled masked autoencoders to reconstruct spatiotemporal series along the spatial and temporal dimensions. Rich-context representations learned through such reconstruction could be seamlessly integrated by downstream predictors with arbitrary architectures to augment their performances. A series of quantitative and qualitative evaluations on four widely used benchmarks (PEMS03, PEMS04, PEMS07, and PEMS08) are conducted to validate the state-of-the-art performance of STD-MAE. Codes are available at https://github.com/Jimmy-7664/STD-MAE. Keywords: Machine Learning: ML: Time series and data streams Data Mining: DM: Mining spatial and/or temporal data Knowledge Representation and Reasoning: KRR: Qualitative, geometric, spatial, and temporal reasoning},
  archive   = {C_IJCAI},
  author    = {Haotian Gao and Renhe Jiang and Zheng Dong and Jinliang Deng and Yuxin Ma and Xuan Song},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/442},
  month     = {8},
  pages     = {3998-4006},
  title     = {Spatial-temporal-decoupled masked pre-training for spatiotemporal forecasting},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hard-thresholding meets evolution strategies in
reinforcement learning. <em>IJCAI</em>, 3989–3997. (<a
href="https://doi.org/10.24963/ijcai.2024/441">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Evolution Strategies (ES) have emerged as a competitive alternative for model-free reinforcement learning, showcasing exemplary performance in tasks like Mujoco and Atari. Notably, they shine in scenarios with imperfect reward functions, making them invaluable for real-world applications where dense reward signals may be elusive. Yet, an inherent assumption in ES—that all input features are task-relevant—poses challenges, especially when confronted with irrelevant features common in real-world problems. This work scrutinizes this limitation, particularly focusing on the Natural Evolution Strategies (NES) variant. We propose NESHT, a novel approach that integrates Hard-Thresholding (HT) with NES to champion sparsity, ensuring only pertinent features are employed. Backed by rigorous analysis and empirical tests, NESHT demonstrates its promise in mitigating the pitfalls of irrelevant features and shines in complex decision-making problems like noisy Mujoco and Atari tasks. Our code is available at https://github.com/cangcn/NES-HT. Keywords: Machine Learning: ML: Evolutionary learning Machine Learning: ML: Feature extraction, selection and dimensionality reduction Machine Learning: ML: Learning sparse models Machine Learning: ML: Optimization},
  archive   = {C_IJCAI},
  author    = {Chengqian Gao and William de Vazelhes and Hualin Zhang and Bin Gu and Zhiqiang Xu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/441},
  month     = {8},
  pages     = {3989-3997},
  title     = {Hard-thresholding meets evolution strategies in reinforcement learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Core-structures-guided multi-modal classification neural
architecture search. <em>IJCAI</em>, 3980–3988. (<a
href="https://doi.org/10.24963/ijcai.2024/440">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The multi-modal classification methods based on neural architecture search (NAS-MMC) can automatically learn a satisfied classifier from a given multi-modal search space. However, as the number of multi-modal features and fusion operators increases, the complexity of search space has increased dramatically. Rapidly identifying the satisfied fusion model from this vast space is very challenging. In this paper, we propose an efficient NAS-MMC method based on an idea of shrink-and-expansion search space, called core-structure-guided neural architecture search (CSG-NAS). Specifically, an evolutionary algorithm is first used to find core structures from a shrunk space (also called core structure search space) determined by high-quality features and fusion operators. Then a local search algorithm is used to find the optimal MMC model from the expanded space determined by the discovered core structures and the rest features as well as fusion operators. Moreover, a knowledge transfer strategy is introduced to further improve the overall performance and efficiency of the entire search process. Finally, extensive experimental results demonstrate the effectiveness of our CSG-NAS, attaining the superiority of classification performance, training efficiency and model complexity, compared to state-of-the-art ompetitors on several public benchmark multi-modal tasks. The source code is available at https://github.com/fupinhan123/CSG-NAS. Keywords: Machine Learning: ML: Multi-view learning Machine Learning: ML: Classification Machine Learning: ML: Evolutionary learning Machine Learning: ML: Multi-modal learning},
  archive   = {C_IJCAI},
  author    = {Pinhan Fu and Xinyan Liang and Tingjin Luo and Qian Guo and Yayu Zhang and Yuhua Qian},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/440},
  month     = {8},
  pages     = {3980-3988},
  title     = {Core-structures-guided multi-modal classification neural architecture search},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Efficient federated multi-view clustering with integrated
matrix factorization and k-means. <em>IJCAI</em>, 3971–3979. (<a
href="https://doi.org/10.24963/ijcai.2024/439">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-view clustering is a popular unsupervised multi-view learning method. Real-world multi-view data are often distributed across multiple entities, presenting a challenge for performing multi-view clustering. Federated learning provides a solution by enabling multiple entities to collaboratively train a global model. However, existing federated multi-view clustering methods usually conduct feature extraction and clustering in separate steps, potentially leading to a degradation in clustering performance. To address this issue and for the sake of efficiency, we propose a novel Federated Multi-View Clustering method with Integrated Matrix Factorization and K-Means (FMVC-IMK), which integrates matrix factorization and multi-view K-means into one step. Additionally, an adaptive weight is employed to balance the influence of data from each view. FMVC-IMK further incorporates a graph-based regularizer to preserve the original data&#39;s geometric structure within the learned global clustering structure. We also develop a federated optimization approach to collaboratively learn a global clustering result without sharing any original data. Experimental results on multiple datasets demonstrate the effectiveness of FMVC-IMK. Keywords: Machine Learning: ML: Federated learning Data Mining: DM: Privacy-preserving data mining Machine Learning: ML: Multi-view learning},
  archive   = {C_IJCAI},
  author    = {Wei Feng and Zhenwei Wu and Qianqian Wang and Bo Dong and Zhiqiang Tao and Quanxue Gao},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/439},
  month     = {8},
  pages     = {3971-3979},
  title     = {Efficient federated multi-view clustering with integrated matrix factorization and K-means},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Federated multi-view clustering via tensor factorization.
<em>IJCAI</em>, 3962–3970. (<a
href="https://doi.org/10.24963/ijcai.2024/438">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-view clustering is an effective method to process massive unlabeled multi-view data. Since data of different views may be collected and held by different parties, it becomes impractical to train a multi-view clustering model in a centralized way, for the sake of privacy. However, federated multi-view clustering is challenging because multi-view learning has to consider the complementary and consistent information between each view distributed across different clients. For another, efficiency is highly expected in federated scenarios. Therefore, we propose a novel federated multi-view clustering method with tensor factorization (TensorFMVC), which is built based on K-means and hence is more efficient. Besides, TensorFMVC avoids initializing centroids to address the performance degradation of K-means due to its sensitivity to centroid initialization. A three-order tensor stacked by cluster assignment matrices is introduced to exploit the complementary information and spatial structure of different views. Furthermore, we divide the optimization into several subproblems and develop a federated optimization approach to support cooperative model training. Extensive experiments on several datasets demonstrate that our proposed method exhibits superior performance in federated multi-view clustering. Keywords: Machine Learning: ML: Federated learning Machine Learning: ML: Multi-view learning},
  archive   = {C_IJCAI},
  author    = {Wei Feng and Zhenwei Wu and Qianqian Wang and Bo Dong and Zhiqiang Tao and Quanxue Gao},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/438},
  month     = {8},
  pages     = {3962-3970},
  title     = {Federated multi-view clustering via tensor factorization},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). VCC-INFUSE: Towards accurate and efficient selection of
unlabeled examples in semi-supervised learning. <em>IJCAI</em>,
3953–3961. (<a href="https://doi.org/10.24963/ijcai.2024/437">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Despite the progress of Semi-supervised Learning (SSL), existing methods fail to utilize unlabeled data effectively and efficiently. Many pseudo-label-based methods select unlabeled examples based on inaccurate confidence scores from the classifier. Most prior work also uses all available unlabeled data without pruning, making it difficult to handle large amounts of unlabeled data. To address these issues, we propose two methods: Variational Confidence Calibration (VCC) and Influence-Function-based Unlabeled Sample Elimination (INFUSE). VCC is a universal plugin for SSL confidence calibration, using a variational autoencoder to select more accurate pseudo labels based on three types of consistency scores. INFUSE is a data pruning method that constructs a core dataset of unlabeled examples under SSL. Our methods are effective in multiple datasets and settings, reducing classification error rates and saving training time. Together, VCC-INFUSE reduces the error rate of FlexMatch on the CIFAR-100 dataset by 1.08% while saving nearly half of the training time. Keywords: Machine Learning: ML: Semi-supervised learning},
  archive   = {C_IJCAI},
  author    = {Shijie Fang and Qianhan Feng and Tong Lin},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/437},
  month     = {8},
  pages     = {3953-3961},
  title     = {VCC-INFUSE: Towards accurate and efficient selection of unlabeled examples in semi-supervised learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep frequency derivative learning for non-stationary time
series forecasting. <em>IJCAI</em>, 3944–3952. (<a
href="https://doi.org/10.24963/ijcai.2024/436">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {While most time series are non-stationary, it is inevitable for models to face the distribution shift issue in time series forecasting. Existing solutions manipulate statistical measures (usually mean and std.) to adjust time series distribution. However, these operations can be theoretically seen as the transformation towards zero frequency component of the spectrum which cannot reveal full distribution information and would further lead to information utilization bottleneck in normalization, thus hindering forecasting performance. To address this problem, we propose to utilize the whole frequency spectrum to transform time series to make full use of data distribution from the frequency perspective. We present a deep frequency derivative learning framework, DERITS, for non-stationary time series forecasting. Specifically, DERITS is built upon a novel reversible transformation, namely Frequency Derivative Transformation (FDT) that makes signals derived in the frequency domain to acquire more stationary frequency representations. Then, we propose the Order-adaptive Fourier Convolution Network to conduct adaptive frequency filtering and learning. Furthermore, we organize DERITS as a parallel-stacked architecture for the multi-order derivation and fusion for forecasting. Finally, we conduct extensive experiments on several datasets which show the consistent superiority in both time series forecasting and shift alleviation. Keywords: Machine Learning: ML: Time series and data streams Data Mining: DM: Mining spatial and/or temporal data},
  archive   = {C_IJCAI},
  author    = {Wei Fan and Kun Yi and Hangting Ye and Zhiyuan Ning and Qi Zhang and Ning An},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/436},
  month     = {8},
  pages     = {3944-3952},
  title     = {Deep frequency derivative learning for non-stationary time series forecasting},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tolerating outliers: Gradient-based penalties for byzantine
robustness and inclusion. <em>IJCAI</em>, 3935–3943. (<a
href="https://doi.org/10.24963/ijcai.2024/435">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This work investigates the interplay between Robustness and Inclusion in the context of poisoning attacks targeting the convergence of Stochastic Gradient Descent (SGD). While robustness has received significant attention, the standard Byzantine defenses rely on the Independent and Identically Distributed (IID) assumption causing their performance to deteriorate on non-IID data distributions, even without any attack. This is largely due to these defenses being excessively cautious and discarding benign outliers. We introduce a penalty-based aggregation that accounts for the discrepancy between trusted clients and outliers. We propose the use of Linear Scalarization (LS) as an enhancing method to enable current defenses to simultaneously circumvent Byzantine attacks while also granting inclusion of outliers. This empowers existing defenses to not only counteract malicious adversaries effectively but also to incorporate outliers into the learning process. We conduct a theoretical analysis to demonstrate the convergence of our approach. Specifically, we establish the robustness and resilience of our method under standard assumptions. Empirical analysis further validates the viability of the proposed approach. Across mild to strong non-IID data splits, our method consistently either matches or surpasses the performance of current approaches in the literature, under state-of-the-art Byzantine attack scenarios. Keywords: Machine Learning: ML: Robustness AI Ethics, Trust, Fairness: ETF: Fairness and diversity Machine Learning: ML: Trustworthy machine learning},
  archive   = {C_IJCAI},
  author    = {Latifa Errami and El Houcine Bergou},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/435},
  month     = {8},
  pages     = {3935-3943},
  title     = {Tolerating outliers: Gradient-based penalties for byzantine robustness and inclusion},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Group-aware coordination graph for multi-agent reinforcement
learning. <em>IJCAI</em>, 3926–3934. (<a
href="https://doi.org/10.24963/ijcai.2024/434">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Cooperative Multi-Agent Reinforcement Learning (MARL) necessitates seamless collaboration among agents, often represented by an underlying relation graph. Existing methods for learning this graph primarily focus on agent-pair relations, neglecting higher-order relationships. While several approaches attempt to extend cooperation modelling to encompass behaviour similarities within groups, they commonly fall short in concurrently learning the latent graph, thereby constraining the information exchange among partially observed agents. To overcome these limitations, we present a novel approach to infer the Group-Aware Coordination Graph (GACG), which is designed to capture both the cooperation between agent pairs based on current observations and group-level dependencies from behaviour patterns observed across trajectories. This graph is further used in graph convolution for information exchange between agents during decision-making. To further ensure behavioural consistency among agents within the same group, we introduce a group distance loss, which promotes group cohesion and encourages specialization between groups. Our evaluations, conducted on StarCraft II micromanagement tasks, demonstrate GACG&#39;s superior performance. An ablation study further provides experimental evidence of the effectiveness of each component of our method. Keywords: Machine Learning: ML: Multiagent Reinforcement Learning Agent-based and Multi-agent Systems: MAS: Coordination and cooperation},
  archive   = {C_IJCAI},
  author    = {Wei Duan and Jie Lu and Junyu Xuan},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/434},
  month     = {8},
  pages     = {3926-3934},
  title     = {Group-aware coordination graph for multi-agent reinforcement learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SpecAR-net: Spectrogram analysis and representation network
for time series. <em>IJCAI</em>, 3917–3925. (<a
href="https://doi.org/10.24963/ijcai.2024/433">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Representing temporal-structured samples is essential for effective time series analysis tasks. So far, recurrent networks, convolution networks and transformer-style models have been successively applied in temporal data representation, yielding notable results. However, most existing methods primarily focus on modeling and representing the variation patterns within time series in the time domain. As a highly abstracted information entity, 1D time series couples various patterns such as trends, seasonality, and dramatic changes (instantaneous high dynamic), it is difficult to exploit these highly coupled properties merely by analysis tools on purely time domain. To this end, we present Spectrogram Analysis and Representation Network (SpecAR-Net). SpecAR-Net aims at learning more comprehensive representations by modeling raw time series in both time and frequency domain, where an efficient joint extraction of time-frequency features is achieved through a group of learnable 2D multi-scale parallel complex convolution blocks. Experimental results show that the SpecAR-Net achieves excellent performance on 5 major downstream tasks i.e., classification, anomaly detection, imputation, long- and short-term forecasting. Code and appendix are available at https://github.com/Dongyi2go/SpecAR_Net. Keywords: Machine Learning: ML: Representation learning Machine Learning: ML: Convolutional networks},
  archive   = {C_IJCAI},
  author    = {Yi Dong and Liwen Zhang and Youcheng Zhang and Shi Peng and Wen Chen and Zhe Ma},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/433},
  month     = {8},
  pages     = {3917-3925},
  title     = {SpecAR-net: Spectrogram analysis and representation network for time series},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). What hides behind unfairness? Exploring dynamics fairness in
reinforcement learning. <em>IJCAI</em>, 3908–3916. (<a
href="https://doi.org/10.24963/ijcai.2024/432">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In sequential decision-making problems involving sensitive attributes like race and gender, reinforcement learning (RL) agents must carefully consider long-term fairness while maximizing returns. Recent works have proposed many different types of fairness notions, but how unfairness arises in RL problems remains unclear. In this paper, we address this gap in the literature by investigating the sources of inequality through a causal lens. We first analyse the causal relationships governing the data generation process and decompose the effect of sensitive attributes on long-term well-being into distinct components. We then introduce a novel notion called dynamics fairness, which explicitly captures the inequality stemming from environmental dynamics, distinguishing it from those induced by decision-making or inherited from the past. This notion requires evaluating the expected changes in the next state and the reward induced by changing the value of the sensitive attribute while holding everything else constant. To quantitatively evaluate this counterfactual concept, we derive identification formulas that allow us to obtain reliable estimations from data. Extensive experiments demonstrate the effectiveness of the proposed techniques in explaining, detecting, and reducing inequality in reinforcement learning. We publicly release code at https://github.com/familyld/InsightFair. Keywords: Machine Learning: ML: Reinforcement learning AI Ethics, Trust, Fairness: ETF: Fairness and diversity Machine Learning: ML: Model-based and model learning reinforcement learning Machine Learning: ML: Trustworthy machine learning},
  archive   = {C_IJCAI},
  author    = {Zhihong Deng and Jing Jiang and Guodong Long and Chengqi Zhang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/432},
  month     = {8},
  pages     = {3908-3916},
  title     = {What hides behind unfairness? exploring dynamics fairness in reinforcement learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploring the inefficiency of heavy ball as momentum
parameter approaches 1. <em>IJCAI</em>, 3899–3907. (<a
href="https://doi.org/10.24963/ijcai.2024/431">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The heavy ball momentum method is a commonly used technique for accelerating training processes in the machine learning community. However, empirical evidence suggests that the convergence of stochastic gradient descent (SGD) with heavy ball may slow down when the momentum hyperparameter approaches 1. Despite this observation, there are no established theories or solutions to explain and address this issue. In this study, we provide the first theoretical result that elucidates why momentum slows down SGD as it tends to 1. To better understand this inefficiency, we focus on the quadratic convex objective in the analysis. Our findings show that momentum accelerates SGD when the scaling parameter is not very close to 1. Conversely, when the scaling parameter approaches 1, momentum impairs SGD and degrades its stability. Based on the theoretical findings, we propose a descending warmup technique for the heavy ball momentum, which exploits the advantages of the heavy ball method and overcomes the inefficiency problem when the momentum tends to 1. Numerical results demonstrate the effectiveness of the proposed SHB-DW algorithm. Keywords: Machine Learning: ML: Optimization Machine Learning: ML: Applications Machine Learning: ML: Learning theory},
  archive   = {C_IJCAI},
  author    = {Xiaoge Deng and Tao Sun and Dongsheng Li and Xicheng Lu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/431},
  month     = {8},
  pages     = {3899-3907},
  title     = {Exploring the inefficiency of heavy ball as momentum parameter approaches 1},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A conservative approach for few-shot transfer in
off-dynamics reinforcement learning. <em>IJCAI</em>, 3890–3898. (<a
href="https://doi.org/10.24963/ijcai.2024/430">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Off-dynamics Reinforcement Learning (ODRL) seeks to transfer a policy from a source environment to a target environment characterized by distinct yet similar dynamics. In this context, traditional RL agents depend excessively on the dynamics of the source environment, resulting in the discovery of policies that excel in this environment but fail to provide reasonable performance in the target one. In the few-shot framework, a limited number of transitions from the target environment are introduced to facilitate a more effective transfer. Addressing this challenge, we propose an innovative approach inspired by recent advancements in Imitation Learning and Conservative RL algorithms. This method introduces a penalty to regulate the trajectories generated by the source-trained policy. We evaluate our method across various environments representing diverse off-dynamics conditions, where access to the target environment is extremely limited. These experiments include high-dimensional systems relevant to real-world applications. Across most tested scenarios, our proposed method demonstrates performance improvements compared to existing baselines. Keywords: Machine Learning: ML: Reinforcement learning},
  archive   = {C_IJCAI},
  author    = {Paul Daoudi and Christophe Prieur and Bogdan Robu and Merwan Barlier and Ludovic Dos Santos},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/430},
  month     = {8},
  pages     = {3890-3898},
  title     = {A conservative approach for few-shot transfer in off-dynamics reinforcement learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). HypBO: Accelerating black-box scientific experiments using
experts’ hypotheses. <em>IJCAI</em>, 3881–3889. (<a
href="https://doi.org/10.24963/ijcai.2024/429">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Robotics and automation offer massive acceleration for solving intractable, multivariate scientific problems such as materials discovery, but the available search spaces can be dauntingly large. Bayesian optimization has emerged as a popular sample-efficient optimization engine, thriving in tasks where no analytic form of the target function/property is known. Here, we exploit expert human knowledge in the form of hypotheses to direct Bayesian searches more quickly to promising regions of chemical space. Previous methods have used underlying distributions derived from existing experimental measurements, which is unfeasible for new, unexplored scientific tasks. Also, such distributions cannot capture intricate hypotheses. Our proposed method uses expert human hypotheses to generate improved seed samples. Unpromising seeds are automatically discounted, while promising seeds are used to augment the surrogate model data, thus achieving better-informed sampling. This process continues in a global versus local search fashion, organized in a bilevel optimization framework. We validate the performance of our method on a range of synthetic functions and demonstrate its practical utility on a real chemical design task where the use of expert hypotheses accelerates the search performance significantly. Keywords: Machine Learning: ML: Optimization Humans and AI: HAI: Human-AI collaboration Knowledge Representation and Reasoning: KRR: Learning and reasoning Machine Learning: ML: Bayesian learning},
  archive   = {C_IJCAI},
  author    = {Abdoulatif Cissé and Xenophon Evangelopoulos and Sam Carruthers and Vladimir V. Gusev and Andrew I. Cooper},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/429},
  month     = {8},
  pages     = {3881-3889},
  title     = {HypBO: Accelerating black-box scientific experiments using experts’ hypotheses},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Structure-preserving physics-informed neural networks with
energy or lyapunov structure. <em>IJCAI</em>, 3872–3880. (<a
href="https://doi.org/10.24963/ijcai.2024/428">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, there has been growing interest in using physics-informed neural networks (PINNs) to solve differential equations. However, the preservation of structure, such as energy and stability, in a suitable manner has yet to be established. This limitation could be a potential reason why the learning process for PINNs is not always efficient and the numerical results may suggest nonphysical behavior. Besides, there is little research on their applications on downstream tasks. To address these issues, we propose structure-preserving PINNs to improve their performance and broaden their applications for downstream tasks. Firstly, by leveraging prior knowledge about the physical system, a structure‐preserving loss function is designed to assist the PINN in learning the underlying structure. Secondly, a framework that utilizes structure-preserving PINN for robust image recognition is proposed. Here, preserving the Lyapunov structure of the underlying system ensures the stability of the system. Experimental results demonstrate that the proposed method improves the numerical accuracy of PINNs for partial differential equations (PDEs). Furthermore, the robustness of the model against adversarial perturbations in image data is enhanced. Keywords: Machine Learning: ML: Deep learning architectures Computer Vision: CV: Adversarial learning, adversarial attack and defense methods Computer Vision: CV: Machine learning for vision Machine Learning: ML: Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Haoyu Chu and Yuto Miyatake and Wenjun Cui and Shikui Wei and Daisuke Furihata},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/428},
  month     = {8},
  pages     = {3872-3880},
  title     = {Structure-preserving physics-informed neural networks with energy or lyapunov structure},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Diversification of adaptive policy for effective offline
reinforcement learning. <em>IJCAI</em>, 3863–3871. (<a
href="https://doi.org/10.24963/ijcai.2024/427">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Offline Reinforcement Learning (RL) aims to learn policies from pre-collected datasets that capture only a subset of the environment&#39;s dynamics. The predominant approach has been to solve a constrained optimization formulation, which ensures that the policy visits state-action pairs within the support of the offline dataset. However, this approach has limited the ability to make decisions when the agent faces unknown parts of the environment at deployment time. To address the challenge of decision-making in out-of-support regions, model-based Bayes-adaptive approaches have been proposed by considering all dynamics models that could potentially be the true environment. Since it is generally infeasible to compute the posterior of all dynamics models based on the offline dataset, these approaches usually approximate the posterior by using a finite ensemble of highly probable dynamics models. Hence, the diversity of these models is the key to obtaining good policies. In this work, we propose MoDAP (Model-based Diverse Adaptive Policy Learning), an algorithm to enable the adaptive policy to make informed decisions in previously unexplored states. MoDAP adopts an iterative strategy that simultaneously training the policy and dynamics models. The policy optimization seeks to maximize expected returns across dynamics models, while the dynamics models are trained to promote policy diversification through the proposed information-theoretic objective. We evaluate MoDAP through experiments on the D4RL and NeoRL benchmarks, showcasing its performance superiority over state-of-the-art algorithms. Keywords: Machine Learning: ML: Offline reinforcement learning Machine Learning: ML: Model-based and model learning reinforcement learning},
  archive   = {C_IJCAI},
  author    = {Yunseon Choi and Li Zhao and Chuheng Zhang and Lei Song and Jiang Bian and Kee-Eung Kim},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/427},
  month     = {8},
  pages     = {3863-3871},
  title     = {Diversification of adaptive policy for effective offline reinforcement learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep embedding clustering driven by sample stability.
<em>IJCAI</em>, 3854–3862. (<a
href="https://doi.org/10.24963/ijcai.2024/426">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep clustering methods improve the performance of clustering tasks by jointly optimizing deep representation learning and clustering. While numerous deep clustering algorithms have been proposed, most of them rely on artificially constructed pseudo targets for performing clustering. This construction process requires some prior knowledge, and it is challenging to determine a suitable pseudo target for clustering. To address this issue, we propose a deep embedding clustering algorithm driven by sample stability (DECS), which eliminates the requirement of pseudo targets. Specifically, we start by constructing the initial feature space with an autoencoder and then learn the cluster-oriented embedding feature constrained by sample stability. The sample stability aims to explore the deterministic relationship between samples and all cluster centroids, pulling samples to their respective clusters and keeping them away from other clusters with high determinacy. We analyzed the convergence of the loss using Lipschitz continuity in theory, which verifies the validity of the model. The experimental results on five datasets illustrate that the proposed method achieves superior performance compared to state-of-the-art clustering approaches. Keywords: Machine Learning: ML: Clustering Machine Learning: ML: Convolutional networks Machine Learning: ML: Deep learning architectures Machine Learning: ML: Unsupervised learning},
  archive   = {C_IJCAI},
  author    = {Zhanwen Cheng and Feijiang Li and Jieting Wang and Yuhua Qian},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/426},
  month     = {8},
  pages     = {3854-3862},
  title     = {Deep embedding clustering driven by sample stability},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Automated CPU design by learning from input-output examples.
<em>IJCAI</em>, 3843–3853. (<a
href="https://doi.org/10.24963/ijcai.2024/425">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Designing a central processing unit (CPU) requires intensive manual work of talented experts to implement the circuit logic from design specifications. Although considerable progress has been made in electronic design automation (EDA) to relieve human efforts, all existing EDA tools require hand-crafted formal program codes (e.g., Verilog, Chisel, or C) as the input. To automate the CPU design without human programming, we are motivated to learn the CPU design from only input-output (IO) examples. The key challenge is that the learned CPU design should have almost zero tolerance for inaccuracy, which makes well-known approximate algorithms such as neural networks ineffective. We propose a new AI approach to generate the CPU design in the form of a large-scale Boolean function, from only external IO examples instead of formal program code. This approach employs a novel graph structure called Binary Speculative Diagram (BSD) to approximate the CPU-scale Boolean function accurately. We propose an efficient BSD expansion method based on Boolean Distance, a new metric to quantitatively measure the structural similarity between Boolean functions, gradually increasing the design accuracy up to 100%. Our approach generates an industrial-scale RISC-V CPU design within 5 hours, reducing the design cycle by about 1000x without human involvement. The taped-out chip, Enlightenment-1, the world&#39;s first CPU designed by AI, successfully runs the Linux operating system and performs comparably against the human-design Intel 80486SX CPU. Our approach even autonomously discovers human knowledge of the von Neumann architecture. Keywords: Machine Learning: ML: Applications},
  archive   = {C_IJCAI},
  author    = {Shuyao Cheng and Pengwei Jin and Qi Guo and Zidong Du and Rui Zhang and Xing Hu and Yongwei Zhao and Yifan Hao and Xiangtao Guan and Husheng Han and Zhengyue Zhao and Ximing Liu and Xishan Zhang and Yuejie Chu and Weilong Mao and Tianshi Chen and Yunji Chen},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/425},
  month     = {8},
  pages     = {3843-3853},
  title     = {Automated CPU design by learning from input-output examples},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Disentangling domain and general representations for time
series classification. <em>IJCAI</em>, 3834–3842. (<a
href="https://doi.org/10.24963/ijcai.2024/424">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Modeling time series data has become a very at tractive research topic due to its wide application, such as human activity recognition, financial forecasting and sensor-based automatic system monitoring. Recently deep learning models have shown great advances in modeling the time series data but they heavily depend on a large amount of labeled data. To avoid costly labeling, this paper explores domain adaptation from a labeled source domain to the unlabeled target domain on time series data. To achieve the goal, we propose a disentangled representation learning framework named CADT to disentangle the domain-invariant features from the domain-specific ones. Particularly, CADT is injected with a novel class-wise hypersphere loss to improve the generalization of the classifier from the source domain to the target domain. Intuitively, it restricts the source data of the same class within the same hypersphere and minimizes the radius of it, which in turn enlarges the margin between different classes and makes the decision boundary of both domains easier. We further devise several kinds of domain-preserving data augmentation methods to better capture the domain-specific patterns. Extensive experiments on two public datasets and two real-world applications demonstrate the effectiveness of the proposed model against several state-of-the-art baselines. Keywords: Machine Learning: ML: Time series and data streams Machine Learning: ML: Classification Machine Learning: ML: Deep learning architectures},
  archive   = {C_IJCAI},
  author    = {Youmin Chen and Xinyu Yan and Yang Yang and Jianfeng Zhang and Jing Zhang and Lujia Pan and Juren Li},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/424},
  month     = {8},
  pages     = {3834-3842},
  title     = {Disentangling domain and general representations for time series classification},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Boosting single positive multi-label classification with
generalized robust loss. <em>IJCAI</em>, 3825–3833. (<a
href="https://doi.org/10.24963/ijcai.2024/423">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-label learning (MLL) requires comprehensive multi-semantic annotations that is hard to fully obtain, thus often resulting in missing labels scenarios. In this paper, we investigate Single Positive Multi-label Learning (SPML), where each image is associated with merely one positive label. Existing SPML methods only focus on designing losses using mechanisms such as hard pseudo-labeling and robust losses, mostly leading to unacceptable false negatives. To address this issue, we first propose a generalized loss framework based on expected risk minimization to provide soft pseudo labels, and point out that the former losses can be seamlessly converted into our framework. In particular, we design a novel robust loss based on our framework, which enjoys flexible coordination between false positives and false negatives, and can additionally deal with the imbalance between positive and negative samples. Extensive experiments show that our approach can significantly improve SPML performance and outperform the vast majority of state-of-the-art methods on all the four benchmarks. Our code is available at https://github.com/yan4xi1/GRLoss. Keywords: Machine Learning: ML: Multi-label learning Machine Learning: ML: Classification Machine Learning: ML: Weakly supervised learning},
  archive   = {C_IJCAI},
  author    = {Yanxi Chen and Chunxiao Li and Xinyang Dai and Jinhuan Li and Weiyu Sun and Yiming Wang and Renyuan Zhang and Tinghe Zhang and Bo Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/423},
  month     = {8},
  pages     = {3825-3833},
  title     = {Boosting single positive multi-label classification with generalized robust loss},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Global optimality of single-timescale actor-critic under
continuous state-action space: A study on linear quadratic regulator.
<em>IJCAI</em>, 3816–3824. (<a
href="https://doi.org/10.24963/ijcai.2024/422">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Actor-critic methods have achieved state-of-the-art performance in various challenging tasks. However, theoretical understandings of their performance remain elusive and challenging. Existing studies mostly focus on practically uncommon variants such as double-loop or two-timescale stepsize actor-critic algorithms for simplicity. These results certify local convergence on finite state- or action- space only. We push the boundary to investigate the classic single-sample single-timescale actor-critic on continuous (infinite) state-action space, where we employ the canonical linear quadratic regulator (LQR) problem as a case study. We show that the popular single-timescale actor-critic can attain an epsilon-optimal solution with an order of epsilon to -2 sample complexity for solving LQR on the demanding continuous state-action space. Our work provides new insights into the performance of single-timescale actor-critic, which further bridges the gap between theory and practice. Keywords: Machine Learning: ML: Reinforcement learning Machine Learning: ML: Learning theory},
  archive   = {C_IJCAI},
  author    = {Xuyang Chen and Jingliang Duan and Lin Zhao},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/422},
  month     = {8},
  pages     = {3816-3824},
  title     = {Global optimality of single-timescale actor-critic under continuous state-action space: A study on linear quadratic regulator},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). EAT: Self-supervised pre-training with efficient audio
transformer. <em>IJCAI</em>, 3807–3815. (<a
href="https://doi.org/10.24963/ijcai.2024/421">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Audio self-supervised learning (SSL) pre-training, which aims to learn good representations from unlabeled audio, has made remarkable progress. However, the extensive computational demands during pre-training pose a significant barrier to the potential application and optimization of audio SSL models. In this paper, inspired by the success of data2vec 2.0 in image modality and Audio-MAE in audio modality, we introduce Efficient Audio Transformer (EAT) to further improve the effectiveness and efficiency in audio SSL. The proposed EAT adopts the bootstrap self-supervised training paradigm to the audio domain. A novel Utterance-Frame Objective (UFO) is designed to enhance the modeling capability of acoustic events. Furthermore, we reveal that the masking strategy is critical in audio SSL pre-training, and superior audio representations can be obtained with large inverse block masks. Experiment results demonstrate that EAT achieves state-of-the-art (SOTA) performance on a range of audio-related tasks, including AudioSet (AS-2M, AS-20K), ESC-50, and SPC-2, along with a significant pre-training speedup up to ~15x compared to existing audio SSL models. Keywords: Machine Learning: ML: Representation learning Machine Learning: ML: Self-supervised Learning Natural Language Processing: NLP: Speech},
  archive   = {C_IJCAI},
  author    = {Wenxi Chen and Yuzhe Liang and Ziyang Ma and Zhisheng Zheng and Xie Chen},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/421},
  month     = {8},
  pages     = {3807-3815},
  title     = {EAT: Self-supervised pre-training with efficient audio transformer},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Off-agent trust region policy optimization. <em>IJCAI</em>,
3798–3806. (<a href="https://doi.org/10.24963/ijcai.2024/420">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Leveraging the experiences of other agents offers a powerful mechanism to enhance policy optimization in multi-agent reinforcement learning (MARL). However, contemporary MARL algorithms often neglect experience sharing possibilities or adopt a simple approach via direct parameter sharing. Our work explores a refined off-agent learning framework that allows selective integration of experience from other agents to improve policy learning. Our investigation begins with a thorough assessment of current mechanisms for reusing experiences among heterogeneous agents, revealing that direct experience transfer may result in negative consequences. Moreover, even the experience of homogeneous agents requires modification before reusing. Our approach introduces off-agent adaptations to the multi-agent policy optimization methods, enabling effective and purposeful leverage of cross-agent experiences beyond conventional parameter sharing. Accompanying this, we provide a theoretical guarantee for an approximate monotonic improvement. Experiments conducted on the StarCraftII Multi-Agent Challenge (SMAC) and Google Research Football (GRF) demonstrate that our algorithms outperform state-of-the-art (SOTA) methods and achieve faster convergence, suggesting the viability of our approach for efficient experience reusing in MARL. Keywords: Machine Learning: ML: Multiagent Reinforcement Learning Machine Learning: ML: Partially observable reinforcement learning and POMDPs Machine Learning: ML: Reinforcement learning},
  archive   = {C_IJCAI},
  author    = {Ruiqing Chen and Xiaoyuan Zhang and Yali Du and Yifan Zhong and Zheng Tian and Fanglei Sun and Yaodong Yang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/420},
  month     = {8},
  pages     = {3798-3806},
  title     = {Off-agent trust region policy optimization},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Breaking barriers of system heterogeneity:
Straggler-tolerant multimodal federated learning via knowledge
distillation. <em>IJCAI</em>, 3789–3797. (<a
href="https://doi.org/10.24963/ijcai.2024/419">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Internet of Things (IoT) devices possess valuable yet private multimodal data, calling for a decentralized machine learning scheme. Though several multimodal federated learning (MFL) methods have been proposed, most of them merely overlook the system heterogeneity across IoT devices, resulting in the inadaptability to real world applications. Aiming at this, we conduct theoretical analysis and exploration experiments on straggler impacts and uncover the fact that stragglers caused by system heterogeneity are fatal to MFL, resulting in catastrophic time overhead. Motivated by this, we propose a novel Multimodal Federated Learning with Accelerated Knowledge Distillation (MFL-AKD) framework, which is the first attempt to integrate knowledge distillation to combat stragglers in complex multimodal federated scenarios. Concretely, given the pretrained large-scale vision-language models deployed in the central server, we apply a fast knowledge transfer mechanism to conduct early training of local models with part of the local data. The early-trained model is then enhanced through the distillation of the pretrained large model and further trained on the remaining data. Extensive experiments on two datasets for video moment retrieval and two datasets for image-text retrieval demonstrate that our method achieves superior results with high straggler robustness. Keywords: Machine Learning: ML: Multi-modal learning},
  archive   = {C_IJCAI},
  author    = {Jinqian Chen and Haoyu Tang and Junhao Cheng and Ming Yan and Ji Zhang and Mingzhu Xu and Yupeng Hu and Liqiang Nie},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/419},
  month     = {8},
  pages     = {3789-3797},
  title     = {Breaking barriers of system heterogeneity: Straggler-tolerant multimodal federated learning via knowledge distillation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning low-rank tensor cores with probabilistic
ℓ0-regularized rank selection for model compression. <em>IJCAI</em>,
3780–3788. (<a href="https://doi.org/10.24963/ijcai.2024/418">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Compressing deep neural networks is of great importance for real-world applications on resource-constrained devices. Tensor decomposition is one promising answer that retains the functionality and most of the expressive power of the original deep models by replacing the weights with their decomposed cores. Decomposition with optimal ranks can achieve a good compression-accuracy trade-off, but it is expensive to optimize due to its discrete and combinatorial nature. A common practice is to set all ranks equal and tune one hyperparameter, but it may significantly harm the flexibility and generalization. In this paper, we propose a novel automatic rank selection method for deep model compression that allows learning model weights and decomposition ranks simultaneously. We propose to penalize the ℓ0 (quasi-)norm of the slices of decomposed tensor cores during model training. To avoid combinatorial optimization, we develop a probabilistic formulation and apply an approximate Bernoulli gate to each of the slices of tensor cores, which can be implemented in an end-to-end and scalable framework via gradient descent. It enables the automatic rank selection to be incorporated with arbitrary tensor decompositions and neural network layers such as linear layers, convolutional layers, and embedding layers. Comprehensive experiments on various tasks, including image classification, text sentiment classification, and neural machine translation, demonstrate the superior effectiveness of the proposed method over baselines. Keywords: Machine Learning: ML: Matrix/tensor methods Machine Learning: ML: Learning sparse models},
  archive   = {C_IJCAI},
  author    = {Tianxiao Cao and Lu Sun and Canh Hao Nguyen and Hiroshi Mamitsuka},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/418},
  month     = {8},
  pages     = {3780-3788},
  title     = {Learning low-rank tensor cores with probabilistic ℓ0-regularized rank selection for model compression},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dual contrastive graph-level clustering with multiple
cluster perspectives alignment. <em>IJCAI</em>, 3770–3779. (<a
href="https://doi.org/10.24963/ijcai.2024/417">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph-level clustering, which is essential in medical, biomedical, and social network data analysis, aims to group a set of graphs into various clusters. However, existing methods generally rely on a single clustering criterion, e.g., $k$-means, which limits their abilities to fully exploit the complex Euclidean and structural information inherent in graphs. To bridge this gap, we propose a dual contrastive graph-level clustering (DCGLC) method in this paper. DCGLC leverages graph contrastive learning and introduces the Euclidian-based and subspace-based cluster heads to capture the cluster information from different cluster perspectives. To overcome the inconsistency estimations and fuse the cluster information of multiple cluster heads, we propose a contrastive mechanism to align the cluster information derived from them. The cluster-perspective contrast facilitates the capture of more comprehensive cluster information. Importantly, DCGLC is an end-to-end framework in which graph contrastive learning and cluster-perspective contrast are mutually improved. We demonstrate the superiority of DCGLC over the state-of-the-art baselines on numerous graph benchmarks. Keywords: Machine Learning: ML: Unsupervised learning Machine Learning: ML: Clustering},
  archive   = {C_IJCAI},
  author    = {Jinyu Cai and Yunhe Zhang and Jicong Fan and Yali Du and Wenzhong Guo},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/417},
  month     = {8},
  pages     = {3770-3779},
  title     = {Dual contrastive graph-level clustering with multiple cluster perspectives alignment},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LG-FGAD: An effective federated graph anomaly detection
framework. <em>IJCAI</em>, 3760–3769. (<a
href="https://doi.org/10.24963/ijcai.2024/416">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph anomaly detection (GAD), which aims to identify those graphs that are significantly different from other ones, has gained growing attention in many real-world scenarios. However, existing GAD methods are generally designed for centralized training, while in real-world collaboration, graph data is generally distributed across various clients and exhibits significant non-IID characteristics. To tackle this challenge, we propose a federated graph anomaly detection framework with local-global anomaly awareness (LG-FGAD). We first introduce a self-adversarial generation module and train a discriminator to identify the generated anomalous graphs from the normal graph. To enhance the anomaly awareness of the model, we propose to maximize/minimize the mutual information from local and global perspectives. Importantly, to alleviate the impact of non-IID problems in collaborative learning, we propose a dual knowledge distillation module. The knowledge distillation is conducted over both logits and embedding distributions, and only the student model engages in collaboration to preserve the personalization of each client. Empirical results on various types of real-world datasets prove the superiority of our method. Keywords: Machine Learning: ML: Unsupervised learning Data Mining: DM: Anomaly/outlier detection Machine Learning: ML: Federated learning},
  archive   = {C_IJCAI},
  author    = {Jinyu Cai and Yunhe Zhang and Jicong Fan and See-Kiong Ng},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/416},
  month     = {8},
  pages     = {3760-3769},
  title     = {LG-FGAD: An effective federated graph anomaly detection framework},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). With a little help from language: Semantic enhanced visual
prototype framework for few-shot learning. <em>IJCAI</em>, 3751–3759.
(<a href="https://doi.org/10.24963/ijcai.2024/415">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Few-shot learning (FSL) aims to recognize new categories given limited training samples. The core challenge is to avoid overfitting to the minimal data while ensuring good generalization to novel classes. One mainstream method employs prototypes from visual feature extractors as classifier weight and the performance depends on the quality of the prototype. Since different categories may have similar visual features, the visual prototype has limitations. This is because existing methods only learn a simple visual feature extractor during the pre-training stage but neglect the importance of a well-developed feature space for the prototype. We introduce the Semantic Enhanced Visual Prototype framework (SEVpro) to address this issue. SEVpro refines prototype learning from the pre-training stage and serves as a versatile plug-and-play framework for all prototype-based FSL methods. Specifically, we enhance prototype discriminability by transforming semantic embeddings into the visual space, aiding in separating categories with similar visual features. For novel class learning, we leverage knowledge from base classes and incorporate semantic information to elevate prototype quality further. Meanwhile, extensive experiments on FSL benchmarks and ablation studies demonstrate the superiority of our proposed SEVpro for FSL. Keywords: Machine Learning: ML: Few-shot learning Machine Learning: ML: Multi-modal learning},
  archive   = {C_IJCAI},
  author    = {Hecheng Cai and Yang Liu and Shudong Huang and Jiancheng Lv},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/415},
  month     = {8},
  pages     = {3751-3759},
  title     = {With a little help from language: Semantic enhanced visual prototype framework for few-shot learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Best arm identification with retroactively increased
sampling budget for more resource-efficient HPO. <em>IJCAI</em>,
3742–3750. (<a href="https://doi.org/10.24963/ijcai.2024/414">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Hyperparameter optimization (HPO) is indispensable for achieving optimal performance in machine learning tasks. A popular class of methods in this regard is based on Successive Halving (SHA), which casts HPO into a pure-exploration multi-armed bandit problem under finite sampling budget constraints. This is accomplished by considering hyperparameter configurations as arms and rewards as the negative validation losses. While enjoying theoretical guarantees as well as working well in practice, SHA comes, however, with several hyperparameters itself, one of which is the maximum budget that can be allocated to evaluate a single arm (hyperparameter configuration). Although there are already solutions to this meta hyperparameter optimization problem, such as the doubling trick or asynchronous extensions of SHA, these are either practically inefficient or lack theoretical guarantees. In this paper, we propose incremental SHA (iSHA), a synchronous extension of SHA, allowing to increase the maximum budget a posteriori while still enjoying theoretical guarantees. Our empirical analysis of HPO problems corroborates our theoretical findings and shows that iSHA is more resource-efficient than existing SHA-based approaches. Keywords: Machine Learning: ML: Multi-armed bandits Machine Learning: ML: Hyperparameter optimization Machine Learning: ML: Incremental learning},
  archive   = {C_IJCAI},
  author    = {Jasmin Brandt and Marcel Wever and Viktor Bengs and Eyke Hüllermeier},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/414},
  month     = {8},
  pages     = {3742-3750},
  title     = {Best arm identification with retroactively increased sampling budget for more resource-efficient HPO},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards exact computation of inductive bias. <em>IJCAI</em>,
3733–3741. (<a href="https://doi.org/10.24963/ijcai.2024/413">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Much research in machine learning involves finding appropriate inductive biases (e.g. convolutional neural networks, momentum-based optimizers, transformers) to promote generalization on tasks. However, quantification of the amount of inductive bias associated with these architectures and hyperparameters has been limited. We propose a novel method for efficiently computing the inductive bias required for generalization on a task with a fixed training data budget; formally, this corresponds to the amount of information required to specify well-generalizing models within a specific hypothesis space of models. Our approach involves modeling the loss distribution of random hypotheses drawn from a hypothesis space to estimate the required inductive bias for a task relative to these hypotheses. Unlike prior work, our method provides a direct estimate of inductive bias without using bounds and is applicable to diverse hypothesis spaces. Moreover, we derive approximation error bounds for our estimation approach in terms of the number of sampled hypotheses. Consistent with prior results, our empirical results demonstrate that higher dimensional tasks require greater inductive bias. We show that relative to other expressive model classes, neural networks as a model class encode large amounts of inductive bias. Furthermore, our measure quantifies the relative difference in inductive bias between different neural network architectures. Our proposed inductive bias metric provides an information-theoretic interpretation of the benefits of specific model architectures for certain tasks and provides a quantitative guide to developing tasks requiring greater inductive bias, thereby encouraging the development of more powerful inductive biases. Keywords: Machine Learning: ML: Learning theory Machine Learning: ML: Explainable/Interpretable machine learning Machine Learning: ML: Evaluation Machine Learning: ML: Other},
  archive   = {C_IJCAI},
  author    = {Akhilan Boopathy and William Yue and Jaedong Hwang and Abhiram Iyer and Ila Fiete},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/413},
  month     = {8},
  pages     = {3733-3741},
  title     = {Towards exact computation of inductive bias},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Contrastive general graph matching with adaptive
augmentation sampling. <em>IJCAI</em>, 3724–3732. (<a
href="https://doi.org/10.24963/ijcai.2024/412">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph matching has important applications in pattern recognition and beyond. Current approaches predominantly adopt supervised learning, demanding extensive labeled data which can be limited or costly. Meanwhile, self-supervised learning methods for graph matching often require additional side information such as extra categorical information and input features, limiting their application to the general case. Moreover, designing the optimal graph augmentations for self-supervised graph matching presents another challenge to ensure robustness and efficacy. To address these issues, we introduce a novel Graph-centric Contrastive framework for Graph Matching (GCGM), capitalizing on a vast pool of graph augmentations for contrastive learning, yet without needing any side information. Given the variety of augmentation choices, we further introduce a Boosting-inspired Adaptive Augmentation Sampler (BiAS), which adaptively selects more challenging augmentations tailored for graph matching. Through various experiments, our GCGM surpasses state-of-the-art self-supervised methods across various datasets, marking a significant step toward more effective, efficient and general graph matching. Keywords: Machine Learning: ML: Unsupervised learning Machine Learning: ML: Self-supervised Learning Machine Learning: ML: Sequence and graph learning},
  archive   = {C_IJCAI},
  author    = {Jianyuan Bo and Yuan Fang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/412},
  month     = {8},
  pages     = {3724-3732},
  title     = {Contrastive general graph matching with adaptive augmentation sampling},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Interpretable network visualizations: A human-in-the-loop
approach for post-hoc explainability of CNN-based image classification.
<em>IJCAI</em>, 3715–3723. (<a
href="https://doi.org/10.24963/ijcai.2024/411">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Transparency and explainability in image classification are essential for establishing trust in machine learning models and detecting biases and errors. State-of-the-art explainability methods generate saliency maps to show where a specific class is identified, without providing a detailed explanation of the model&#39;s decision process. Striving to address such a need, we introduce a post-hoc method that explains the entire feature extraction process of a Convolutional Neural Network. These explanations include a layer-wise representation of the features the model extracts from the input. Such features are represented as saliency maps generated by clustering and merging similar feature maps, to which we associate a weight derived by generalizing Grad-CAM for the proposed methodology. To further enhance these explanations, we include a set of textual labels collected through a gamified crowdsourcing activity and processed using NLP techniques and Sentence-BERT. Finally, we show an approach to generate global explanations by aggregating labels across multiple images. Keywords: Machine Learning: ML: Explainable/Interpretable machine learning Computer Vision: CV: Interpretability and transparency Humans and AI: HAI: Human computation and crowdsourcing},
  archive   = {C_IJCAI},
  author    = {Matteo Bianchi and Antonio De Santis and Andrea Tocchetti and Marco Brambilla},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/411},
  month     = {8},
  pages     = {3715-3723},
  title     = {Interpretable network visualizations: A human-in-the-loop approach for post-hoc explainability of CNN-based image classification},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Ansatz-agnostic exponential resource saving in variational
quantum algorithms using shallow shadows. <em>IJCAI</em>, 3706–3714. (<a
href="https://doi.org/10.24963/ijcai.2024/410">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Variational Quantum Algorithms (VQA) have been identified as a promising candidate for the demonstration of near-term quantum advantage in solving optimization tasks in chemical simulation, quantum information, and machine learning. The standard model of training requires a significant amount of quantum resources, which led researchers to use classical shadows to devise an alternative that consumes exponentially fewer quantum resources. However, the approach only works when the observables are local and the ansatz is the shallow Alternating Layered Ansatz (ALA), thus severely limiting its potential in solving problems such as quantum state preparation, where the ideal state might not be approximable with an ALA. In this work, we present a protocol based on shallow shadows that achieves similar levels of savings for almost any shallow ansatz studied in the literature, when combined with observables of low Frobenius norm. We show that two important applications in quantum information for which VQAs can be a powerful option, namely variational quantum state preparation and variational quantum circuit synthesis, are compatible with our protocol. We also experimentally demonstrate orders of magnitude improvement in comparison to the standard VQA model. Keywords: Machine Learning: ML: Other Machine Learning: ML: Optimization},
  archive   = {C_IJCAI},
  author    = {Afrad Basheer and Yuan Feng and Christopher Ferrie and Sanjiang Li},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/410},
  month     = {8},
  pages     = {3706-3714},
  title     = {Ansatz-agnostic exponential resource saving in variational quantum algorithms using shallow shadows},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Online learning with off-policy feedback in adversarial
MDPs. <em>IJCAI</em>, 3697–3705. (<a
href="https://doi.org/10.24963/ijcai.2024/409">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we face the challenge of online learning in adversarial Markov decision processes with off-policy feedback. In this setting, the learner chooses a policy, but, differently from the traditional on-policy setting, the environment is explored by means of a different, fixed, and possibly unknown policy (named colleague&#39;s policy). The off-policy feedback presents an additional issue that is not present in traditional settings: the learner is charged with the regret of its chosen policy but it observes only the rewards gained by the colleague&#39;s policy. First, we present a lower-bound for the setting we propose, which shows that the optimal dependency of the sublinear regret is w.r.t. the dissimilarity between the optimal policy in hindsight and the colleague&#39;s policy. Then, we propose novel algorithms that, by employing pessimistic estimators---commonly adopted in the off-line reinforcement learning literature---ensure sublinear regret bounds depending on the desired dissimilarity, even when the colleague&#39;s policy is unknown. Keywords: Machine Learning: ML: Online learning Machine Learning: ML: Reinforcement learning},
  archive   = {C_IJCAI},
  author    = {Francesco Bacchiocchi and Francesco Emanuele Stradi and Matteo Papini and Alberto Maria Metelli and Nicola Gatti},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/409},
  month     = {8},
  pages     = {3697-3705},
  title     = {Online learning with off-policy feedback in adversarial MDPs},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Deriving provably correct explanations for decision trees:
The impact of domain theories. <em>IJCAI</em>, 3688–3696. (<a
href="https://doi.org/10.24963/ijcai.2024/408">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We are interested in identifying the complexity of computing local explanations of various types given a decision tree, when the Boolean conditions used in the tree are not independent. This is usually the case when decision trees are learned from instances described using numerical or categorical attributes. In such a case, considering the domain theory indicating how the Boolean conditions occurring in the tree are logically connected is paramount to derive provably correct explanations. However, the nature of the domain theory may have a strong impact on the complexity of generating explanations. In this paper, we identify the complexity of deriving local explanations (abductive or contrastive) given a decision tree in the general case, and under several natural restrictions about the domain theory. Keywords: Machine Learning: ML: Explainable/Interpretable machine learning Knowledge Representation and Reasoning: KRR: Computational complexity of reasoning},
  archive   = {C_IJCAI},
  author    = {Gilles Audemard and Jean-Marie Lagniez and Pierre Marquis and Nicolas Szczepanski},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/408},
  month     = {8},
  pages     = {3688-3696},
  title     = {Deriving provably correct explanations for decision trees: The impact of domain theories},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). On the computation of example-based abductive explanations
for random forests. <em>IJCAI</em>, 3679–3687. (<a
href="https://doi.org/10.24963/ijcai.2024/407">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We show how to define and compute example-based abductive explanations. Such explanations are guaranteed to be 100% correct, fairly general, and persuasive enough since they cover sufficiently many reference instances furnished by the explainee. We prove that the latter coverage condition yields a complexity shift to the second level of the polynomial hierarchy. We present a CEGAR-based algorithm to derive such explanations, and show how to modify it to derive most anchored example-based abductive explanations, i.e., example-based abductive explanations that cover as many reference instances as possible. We also explain how to reduce example-based abductive explanations to get subset-minimal explanations. Experiments in the case of random forest classifiers show that our CEGAR-based algorithm is quite efficient in practice. Keywords: Machine Learning: ML: Explainable/Interpretable machine learning Constraint Satisfaction and Optimization: CSO: Applications Knowledge Representation and Reasoning: KRR: Computational complexity of reasoning},
  archive   = {C_IJCAI},
  author    = {Gilles Audemard and Jean-Marie Lagniez and Pierre Marquis and Nicolas Szczepanski},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/407},
  month     = {8},
  pages     = {3679-3687},
  title     = {On the computation of example-based abductive explanations for random forests},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cutting the black box: Conceptual interpretation of a deep
neural net with multi-modal embeddings and multi-criteria decision aid.
<em>IJCAI</em>, 3669–3678. (<a
href="https://doi.org/10.24963/ijcai.2024/406">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper tackles the concept-based explanation of neural models in computer vision, building upon the state of the art in Multi-Criteria Decision Aid (MCDA). The novelty of the approach is to leverage multi-modal embeddings from CLIP to bridge the gap between pixel-based and concept-based representations. The proposed Cut the Black Box (CB2) approach disentangles the latent representation of a trained pixel-based neural net, referred to as teacher model, along a 3-step process. Firstly, the pixel-based representation of the samples is mapped onto a conceptual representation using multi-modal embeddings. Secondly, an interpretable-by-design MCDA student model is trained by distillation from the teacher model, using the conceptual sample representation. Thirdly, the alignment of the teacher and student latent representations spells out the concepts relevant to explaining the teacher model. The empirical validation of the approach on ResNet, VGG, and VisionTransformer on Cifar-10, Cifar-100, Tiny ImageNet, and Fashion-MNIST showcases the effectiveness of the interpretations provided for the teacher models. The analysis reveals that decision-making predominantly relies on few concepts, thereby exposing potential bias in the teacher&#39;s decisions. Keywords: Machine Learning: ML: Explainable/Interpretable machine learning Computer Vision: CV: Interpretability and transparency Knowledge Representation and Reasoning: KRR: Preference modelling and preference-based reasoning Machine Learning: ML: Trustworthy machine learning},
  archive   = {C_IJCAI},
  author    = {Nicolas Atienza and Roman Bresson and Cyriaque Rousselot and Philippe Caillou and Johanne Cohen and Christophe Labreuche and Michele Sebag},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/406},
  month     = {8},
  pages     = {3669-3678},
  title     = {Cutting the black box: Conceptual interpretation of a deep neural net with multi-modal embeddings and multi-criteria decision aid},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Contrastive learning is not optimal for quasiperiodic time
series. <em>IJCAI</em>, 3661–3668. (<a
href="https://doi.org/10.24963/ijcai.2024/405">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Despite recent advancements in Self-Supervised Learning (SSL) for Time Series analysis, a noticeable gap persists between the anticipated achievements and actual performance. While these methods have demonstrated formidable generalization capabilities with minimal labels in various domains, their effectiveness in distinguishing between different classes based on a limited number of annotated records is notably lacking. Our hypothesis attributes this bottleneck to the prevalent use of Contrastive Learning, a shared training objective in previous state-of-the-art (SOTA) methods. By mandating distinctiveness between representations for negative pairs drawn from separate records, this approach compels the model to encode unique record-based patterns but simultaneously neglects changes occurring across the entire record. To overcome this challenge, we introduce Distilled Embedding for Almost-Periodic Time Series (DEAPS) in this paper, offering a non-contrastive method tailored for quasiperiodic time series, such as electrocardiogram (ECG) data. By avoiding the use of negative pairs, we not only mitigate the model&#39;s blindness to temporal changes but also enable the integration of a &quot;Gradual Loss (L_gra)&quot; function. This function guides the model to effectively capture dynamic patterns evolving throughout the record. The outcomes are promising, as DEAPS demonstrates a notable improvement of +10% over existing SOTA methods when just a few annotated records are presented to fit a Machine Learning (ML) model based on the learned representation. Keywords: Machine Learning: ML: Self-supervised Learning Machine Learning: ML: Time series and data streams Multidisciplinary Topics and Applications: MTA: Health and medicine},
  archive   = {C_IJCAI},
  author    = {Adrian Atienza and Jakob Bardram and Sadasivan Puthusserypady},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/405},
  month     = {8},
  pages     = {3661-3668},
  title     = {Contrastive learning is not optimal for quasiperiodic time series},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Contract scheduling with distributional and multiple advice.
<em>IJCAI</em>, 3652–3660. (<a
href="https://doi.org/10.24963/ijcai.2024/404">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Contract scheduling is a widely studied framework for designing real-time systems with interruptible capabilities. Previous work has showed that a prediction on the interruption time can help improve the performance of contract-based systems, however it has relied on a single prediction that is provided by a deterministic oracle. In this work, we introduce and study more general and realistic learning-augmented settings in which the prediction is in the form of a probability distribution, or it is given as a set of multiple possible interruption times. For both prediction settings, we design and analyze schedules which perform optimally if the prediction is accurate, while simultaneously guaranteeing the best worst-case performance if the prediction is adversarial. We also provide evidence that the resulting system is robust to prediction errors in the distributional setting. Last, we present an experimental evaluation that confirms the theoretical findings, and illustrates the performance improvements that can be attained in practice. Keywords: Machine Learning: ML: Optimization Planning and Scheduling: PS: Scheduling Planning and Scheduling: PS: Learning in planning and scheduling Uncertainty in AI: UAI: Sequential decision making},
  archive   = {C_IJCAI},
  author    = {Spyros Angelopoulos and Marcin Bienkowski and Christoph Dürr and Bertrand Simon},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/404},
  month     = {8},
  pages     = {3652-3660},
  title     = {Contract scheduling with distributional and multiple advice},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fine-tuning pre-trained models for robustness under noisy
labels. <em>IJCAI</em>, 3643–3651. (<a
href="https://doi.org/10.24963/ijcai.2024/403">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The presence of noisy labels in a training dataset can significantly impact the performance of machine learning models. In response to this issue, researchers have focused on identifying clean samples and reducing the influence of noisy labels. Recent works in this field have achieved notable success in terms of generalizability, albeit at the expense of extensive computing resources. Therefore, reducing computational costs remains a crucial challenge. Concurrently, in other research areas, there has been a focus on developing fine-tuning techniques to efficiently achieve high generalization performance. Despite their proven efficiently achievable generalization capabilities, these techniques have seen limited exploration from a label noise point of view. In this research, we aim to find an effective approach to fine-tune pre-trained models for noisy labeled datasets. To achieve this goal, we empirically investigate the characteristics of pre-trained models on noisy labels and propose an algorithm, named TURN. We present the results of extensive testing and demonstrate both efficient and improved denoising performance on various benchmarks, surpassing previous methods. Keywords: Machine Learning: ML: Robustness AI Ethics, Trust, Fairness: ETF: Safety and robustness Machine Learning: ML: Trustworthy machine learning},
  archive   = {C_IJCAI},
  author    = {Sumyeong Ahn and Sihyeon Kim and Jongwoo Ko and Se-Young Yun},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/403},
  month     = {8},
  pages     = {3643-3651},
  title     = {Fine-tuning pre-trained models for robustness under noisy labels},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). The trembling-hand problem for LTLf planning.
<em>IJCAI</em>, 3631–3641. (<a
href="https://doi.org/10.24963/ijcai.2024/402">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Consider an agent acting to achieve its temporal goal, but with a ``trembling hand&quot;. In this case, the agent may mistakenly instruct, with a certain (typically small) probability, actions that are not intended due to faults or imprecision in its action selection mechanism, thereby leading to possible goal failure. We study the trembling-hand problem in the context of reasoning about actions and planning for temporally extended goals expressed in Linear Temporal Logic on finite traces (LTLf), where we want to synthesize a strategy (aka plan) that maximizes the probability of satisfying the LTLf goal in spite of the trembling hand. We consider both deterministic and nondeterministic (adversarial) domains. We propose solution techniques for both cases by relying respectively on Markov Decision Processes and on Markov Decision Processes with Set-valued Transitions with LTLf objectives, where the set-valued probabilistic transitions capture both the nondeterminism from the environment and the possible action instruction errors from the agent. We formally show the correctness of our solution techniques and demonstrate their effectiveness experimentally through a proof-of-concept implementation. Keywords: Knowledge Representation and Reasoning: KRR: Reasoning about actions Agent-based and Multi-agent Systems: MAS: Formal verification, validation and synthesis Planning and Scheduling: PS: Markov decisions processes},
  archive   = {C_IJCAI},
  author    = {Pian Yu and Shufang Zhu and Giuseppe De Giacomo and Marta Kwiatkowska and Moshe Vardi},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/402},
  month     = {8},
  pages     = {3631-3641},
  title     = {The trembling-hand problem for LTLf planning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Explaining arguments’ strength: Unveiling the role of
attacks and supports. <em>IJCAI</em>, 3622–3630. (<a
href="https://doi.org/10.24963/ijcai.2024/401">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Quantitatively explaining the strength of arguments under gradual semantics has recently received increasing attention. Specifically, several works in the literature provide quantitative explanations by computing the attribution scores of arguments. These works disregard the importance of attacks and supports, even though they play an essential role when explaining arguments&#39; strength. In this paper, we propose a novel theory of Relation Attribution Explanations (RAEs), adapting Shapley values from game theory to offer fine-grained insights into the role of attacks and supports in quantitative bipolar argumentation towards obtaining the arguments&#39; strength. We show that RAEs satisfy several desirable properties. We also propose a probabilistic algorithm to approximate RAEs efficiently. Finally, we show the application value of RAEs in fraud detection and large language models case studies. Keywords: Knowledge Representation and Reasoning: KRR: Argumentation AI Ethics, Trust, Fairness: ETF: Explainability and interpretability},
  archive   = {C_IJCAI},
  author    = {Xiang Yin and Nico Potyka and Francesca Toni},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/401},
  month     = {8},
  pages     = {3622-3630},
  title     = {Explaining arguments’ strength: Unveiling the role of attacks and supports},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Temporal inductive logic reasoning over hypergraphs.
<em>IJCAI</em>, 3613–3621. (<a
href="https://doi.org/10.24963/ijcai.2024/400">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Inductive logic reasoning is a fundamental task in graph analysis, which aims to generalize patterns from data. This task has been extensively studied for traditional graph representations, such as knowledge graphs (KGs), using techniques like inductive logic programming (ILP). Existing ILP methods assume learning from KGs with static facts and binary relations. Beyond KGs, graph structures are widely present in other applications such as procedural instructions, scene graphs, and program executions. While ILP is beneficial for these applications, applying it to those graphs is nontrivial: they are more complex than KGs, which usually involve timestamps and n-ary relations, effectively a type of hypergraph with temporal events. In this work, we propose temporal inductive logic reasoning (TILR), an ILP method that reasons on temporal hypergraphs. To enable hypergraph reasoning, we introduce the multi-start random B-walk, a novel graph traversal method for hypergraphs. By combining it with a path-consistency algorithm, TILR learns logic rules by generalizing from both temporal and relational data. To address the lack of hypergraph benchmarks, we create and release two temporal hypergraph datasets: YouCook2-HG and nuScenes-HG. Experiments on these benchmarks demonstrate that TILR achieves superior reasoning capability over various strong baselines. Keywords: Knowledge Representation and Reasoning: KRR: Logic programming Data Mining: DM: Knowledge graphs and knowledge base completion},
  archive   = {C_IJCAI},
  author    = {Yuan Yang and Siheng Xiong and Ali Payani and James C. Kerce and Faramarz Fekri},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/400},
  month     = {8},
  pages     = {3613-3621},
  title     = {Temporal inductive logic reasoning over hypergraphs},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). NELLIE: A neuro-symbolic inference engine for grounded,
compositional, and explainable reasoning. <em>IJCAI</em>, 3602–3612. (<a
href="https://doi.org/10.24963/ijcai.2024/399">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Our goal is to develop a modern approach to answering questions via systematic reasoning where answers are supported by human interpretable proof trees grounded in an NL corpus of facts. Such a system would help alleviate the challenges of interpretability and hallucination with modern LMs, and the lack of grounding of current explanation methods (e.g., Chain-of-Thought). This paper proposes a new take on Prolog-based inference engines, where we replace handcrafted rules with a combination of neural language modeling, guided generation, and semiparametric dense retrieval. Our implementation, NELLIE, is the first system to demonstrate fully interpretable, end-to-end grounded QA as entailment tree proof search, going beyond earlier work explaining known-to-be-true facts from text. In experiments, NELLIE outperforms a similar-sized state-of-the-art reasoner while producing knowledge-grounded explanations. We also find NELLIE can exploit both semi-structured and NL text corpora to guide reasoning. Together these suggest a new way to jointly reap the benefits of both modern neural methods and traditional symbolic reasoning. Keywords: Knowledge Representation and Reasoning: KRR: Automated reasoning and theorem proving Knowledge Representation and Reasoning: KRR: Reasoning about knowledge and belief Natural Language Processing: NLP: Question answering Search: S: Other},
  archive   = {C_IJCAI},
  author    = {Nathaniel Weir and Peter Clark and Benjamin Van Durme},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/399},
  month     = {8},
  pages     = {3602-3612},
  title     = {NELLIE: A neuro-symbolic inference engine for grounded, compositional, and explainable reasoning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Structured d-DNNF is not closed under negation.
<em>IJCAI</em>, 3593–3601. (<a
href="https://doi.org/10.24963/ijcai.2024/398">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Both structured d-DNNF and SDD can be exponentially more succinct than OBDD. Moreover, SDD is essentially as tractable as OBDD. But this leaves left two important open questions. Firstly, does OBDD support more tractable transformations than structured d-DNNF? And secondly, is structured d-DNNF more succinct than SDD? In this paper, we answer both questions in the affirmative. For the first question we show that, unlike OBDD, structured d-DNNF does not support polytime negation, disjunction, or existential quantification operations. As a corollary, we deduce that there are functions with an equivalent polynomial-sized structured d-DNNF but with no such representation as an SDD, thus answering the second question. We also lift this second result to arithmetic circuits (AC) to show a succinctness gap between PSDD and the positive AC analogue to structured d-DNNF. Keywords: Knowledge Representation and Reasoning: KRR: Knowledge compilation},
  archive   = {C_IJCAI},
  author    = {Harry Vinall-Smeeth},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/398},
  month     = {8},
  pages     = {3593-3601},
  title     = {Structured d-DNNF is not closed under negation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A tensor-based formalization of the event calculus.
<em>IJCAI</em>, 3584–3592. (<a
href="https://doi.org/10.24963/ijcai.2024/397">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present a formalization of the Event Calculus (EC) in tensor spaces. The motivation for a tensor-based predicate calculus comes from the area of composite event recognition (CER). As a CER engine, we adopt a logic programming implementation of EC with optimizations for continuous narrative assimilation on data streams. We show how to evaluate EC rules algebraically and solve a linear equation to compute the corresponding models. We demonstrate the scalability of our approach with the use of large datasets from a real-world application domain, and show it outperforms significantly symbolic EC, in terms of processing time. Keywords: Knowledge Representation and Reasoning: KRR: Non-monotonic reasoning Knowledge Representation and Reasoning: KRR: Logic programming Knowledge Representation and Reasoning: KRR: Qualitative, geometric, spatial, and temporal reasoning Machine Learning: ML: Matrix/tensor methods},
  archive   = {C_IJCAI},
  author    = {Efthimis Tsilionis and Alexander Artikis and Georgios Paliouras},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/397},
  month     = {8},
  pages     = {3584-3592},
  title     = {A tensor-based formalization of the event calculus},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimisation and approximation in abstract argumentation:
The case of stable semantics. <em>IJCAI</em>, 3576–3583. (<a
href="https://doi.org/10.24963/ijcai.2024/396">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We analyse two soft notions of stable extensions in abstract argumentation, one that weakens the requirement of having full range and one that weakens the requirement of conflict-freeness. We then consider optimisation problems over these two notions that represent optimisation variants of the credulous reasoning problem with stable semantics. We investigate the computational complexity of these two problems in terms of the complexity of solving the optimisation problem exactly and in terms of approximation complexity. We also present some polynomial-time approximation algorithms for these optimisation problems and investigate their approximation quality experimentally. Keywords: Knowledge Representation and Reasoning: KRR: Argumentation Knowledge Representation and Reasoning: KRR: Computational complexity of reasoning},
  archive   = {C_IJCAI},
  author    = {Matthias Thimm},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/396},
  month     = {8},
  pages     = {3576-3583},
  title     = {Optimisation and approximation in abstract argumentation: The case of stable semantics},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the power and limitations of examples for description
logic concepts. <em>IJCAI</em>, 3567–3575. (<a
href="https://doi.org/10.24963/ijcai.2024/395">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Labeled examples (i.e., positive and negative examples) are an attractive medium for communicating complex concepts. They are useful for deriving concept expressions (such as in concept learning, interactive concept specification, and concept refinement) as well as for illustrating concept expressions to a user or domain expert. We investigate the power of labeled examples for describing description-logic concepts. Specifically, we systematically study the existence and efficient computability of finite characterizations, i.e. finite sets of labeled examples that uniquely characterize a single concept, for a wide variety of description logics between EL and ALCQI, both without an ontology and in the presence of a DL-Lite ontology. Finite characterizations are relevant for debugging purposes, and their existence is a necessary condition for exact learnability with membership queries. Keywords: Knowledge Representation and Reasoning: KRR: Learning and reasoning Knowledge Representation and Reasoning: KRR: Description logics and ontologies Machine Learning: ML: Learning theory},
  archive   = {C_IJCAI},
  author    = {Balder ten Cate and Raoul Koudijs and Ana Ozaki},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/395},
  month     = {8},
  pages     = {3567-3575},
  title     = {On the power and limitations of examples for description logic concepts},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Agentive permissions in multiagent systems. <em>IJCAI</em>,
3558–3566. (<a href="https://doi.org/10.24963/ijcai.2024/394">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper proposes to distinguish four forms of agentive permissions in multiagent settings. The main technical results are the complexity analysis of model checking, the semantic undefinability of modalities that capture these forms of permissions through each other, and a complete logical system capturing the interplay between these modalities. Keywords: Knowledge Representation and Reasoning: KRR: Reasoning about actions AI Ethics, Trust, Fairness: ETF: Moral decision making AI Ethics, Trust, Fairness: ETF: AI and law, governance, regulation AI Ethics, Trust, Fairness: ETF: Ethical, legal and societal issues},
  archive   = {C_IJCAI},
  author    = {Qi Shi},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/394},
  month     = {8},
  pages     = {3558-3566},
  title     = {Agentive permissions in multiagent systems},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The transformation logics. <em>IJCAI</em>, 3549–3557. (<a
href="https://doi.org/10.24963/ijcai.2024/393">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We introduce a new family of temporal logics designed to finely balance the trade-off between expressivity and complexity. Their key feature is the possibility of defining operators of a new kind that we call transformation operators. Some of them subsume existing temporal operators, while others are entirely novel. Of particular interest are transformation operators based on semigroups. They enable logics to harness the richness of semigroup theory, and we show them to yield logics capable of creating hierarchies of increasing expressivity and complexity which are non-trivial to characterise in existing logics. The result is a genuinely novel and yet unexplored landscape of temporal logics, each of them with the potential of matching the trade-off between expressivity and complexity required by specific applications. Keywords: Knowledge Representation and Reasoning: KRR: Knowledge representation languages Knowledge Representation and Reasoning: KRR: Computational complexity of reasoning Knowledge Representation and Reasoning: KRR: Qualitative, geometric, spatial, and temporal reasoning},
  archive   = {C_IJCAI},
  author    = {Alessandro Ronca},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/393},
  month     = {8},
  pages     = {3549-3557},
  title     = {The transformation logics},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards a principle-based framework for assessing the
contribution of formulas on the conflicts of knowledge bases.
<em>IJCAI</em>, 3541–3548. (<a
href="https://doi.org/10.24963/ijcai.2024/392">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Logical conflicts are likely to arise in logic-based intelligent systems. Managing these conflicts has been intensely studied in various parts of Artificial Intelligence (AI). So far, the AI research community has paid more attention to measuring the degree of inconsistency of knowledge bases. The key question we address in the present paper is how much a given formula contributes to the inconsistency of a knowledge base. Different such measures are studied and compared in a principle-based way against the backdrop of a list of desiderata. Two families of inconsistency measures are introduced and compared with measures from the literature: one is based on the notion of problematic formulas, while the other one is defined via the notion of free formulas in knowledge bases. Keywords: Knowledge Representation and Reasoning: KRR: Reasoning about knowledge and belief Knowledge Representation and Reasoning: KRR: Applications},
  archive   = {C_IJCAI},
  author    = {Badran Raddaoui and Christian Straßer and Said Jabbour},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/392},
  month     = {8},
  pages     = {3541-3548},
  title     = {Towards a principle-based framework for assessing the contribution of formulas on the conflicts of knowledge bases},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A logic for reasoning about aggregate-combine graph neural
networks. <em>IJCAI</em>, 3532–3540. (<a
href="https://doi.org/10.24963/ijcai.2024/391">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose a modal logic in which counting modalities appear in linear inequalities. We show that each formula can be transformed into an equivalent graph neural network (GNN). We also show that a broad class of GNNs can be transformed efficiently into a formula, thus significantly improving upon the literature about the logical expressiveness of GNNs. We also show that the satisfiability problem is PSPACE-complete. These results bring together the promise of using standard logical methods for reasoning about GNNs and their properties, particularly in applications such as GNN querying, equivalence checking, etc. We prove that such natural problems can be solved in polynomial space. Keywords: Knowledge Representation and Reasoning: KRR: Learning and reasoning Machine Learning: ML: Explainable/Interpretable machine learning Machine Learning: ML: Learning theory},
  archive   = {C_IJCAI},
  author    = {Pierre Nunn and Marco Sälzer and François Schwarzentruber and Nicolas Troquard},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/391},
  month     = {8},
  pages     = {3532-3540},
  title     = {A logic for reasoning about aggregate-combine graph neural networks},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Preferred reasoning in ABA by cycle-breaking.
<em>IJCAI</em>, 3523–3531. (<a
href="https://doi.org/10.24963/ijcai.2024/390">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We develop a fixed-parameter tractable (FPT) algorithm for skeptical preferred reasoning in assumption-based argumentation (ABA). To this end we make use of so-called backdoors, i.e. sets of assumptions that need to be evaluated s.t. the remaining ABA framework (ABAF) belongs to a computational beneficial sub-class. In order to identify such target classes, we employ a suitable notion of a dependency graph of an ABAF. We show that these graphs can be constructed in polynomial time and that one can efficiently check sufficient properties ensuring that reasoning in the underlying ABAF is tractable. After establishing the theoretical foundations, we test our implementation against the ASPforABA solver which convincingly won the ABA track of the ICCMA&#39;23 competition. As it turns out, our algorithm outperforms ASPforABA on instances with small backdoor sizes. Keywords: Knowledge Representation and Reasoning: KRR: Argumentation Knowledge Representation and Reasoning: KRR: Computational complexity of reasoning},
  archive   = {C_IJCAI},
  author    = {Kiet Nguyen Anh and Markus Ulbricht},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/390},
  month     = {8},
  pages     = {3523-3531},
  title     = {Preferred reasoning in ABA by cycle-breaking},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Revising beliefs and intentions in stochastic environments.
<em>IJCAI</em>, 3513–3522. (<a
href="https://doi.org/10.24963/ijcai.2024/389">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The development of autonomous agents operating in dynamic and stochastic environments requires theories and models of how beliefs and intentions are revised while taking their interplay into account. In this paper, we initiate the study of belief and intention revision in stochastic environments, where an agent&#39;s beliefs and intentions are specified in a decidable probabilistic temporal logic. We then provide general Katsuno &amp; Mendelzon-style representation theorems for both belief and intention revision, giving clear semantic characterizations of revision methods. Keywords: Knowledge Representation and Reasoning: KRR: Belief change Knowledge Representation and Reasoning: KRR: Reasoning about actions Knowledge Representation and Reasoning: KRR: Reasoning about knowledge and belief},
  archive   = {C_IJCAI},
  author    = {Nima Motamed and Natasha Alechina and Mehdi Dastani and Dragan Doder},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/389},
  month     = {8},
  pages     = {3513-3522},
  title     = {Revising beliefs and intentions in stochastic environments},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CPa-WAC: Constellation partitioning-based scalable weighted
aggregation composition for knowledge graph embedding. <em>IJCAI</em>,
3504–3512. (<a href="https://doi.org/10.24963/ijcai.2024/388">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Scalability and training time are crucial for any graph neural network model processing a knowledge graph (KG). While partitioning knowledge graphs helps reduce the training time, the prediction accuracy reduces significantly compared to training the model on the whole graph. In this paper, we propose CPa-WAC: a lightweight architecture that incorporates graph convolutional networks and modularity maximization-based constellation partitioning to harness the power of local graph topology. The proposed CPa-WAC method reduces the training time and memory cost of knowledge graph embedding, making the learning model scalable. The results from our experiments on standard databases, such as Wordnet and Freebase, show that by achieving meaningful partitioning, any knowledge graph can be broken down into subgraphs and processed separately to learn embeddings. Furthermore, these learned embeddings can be used for knowledge graph completion, retaining similar performance compared to training a GCN on the whole KG, while speeding up the training process by upto five times. Additionally, the proposed CPa-WAC method outperforms several other state-of-the-art KG in terms of prediction accuracy. Keywords: Knowledge Representation and Reasoning: KRR: Applications Uncertainty in AI: UAI: Graphical models Machine Learning: ML: Knowledge-aided learning Data Mining: DM: Knowledge graphs and knowledge base completion},
  archive   = {C_IJCAI},
  author    = {Sudipta Modak and Aakarsh Malhotra and Sarthak Malik and Anil Surisetty and Esam Abdel-Raheem},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/388},
  month     = {8},
  pages     = {3504-3512},
  title     = {CPa-WAC: Constellation partitioning-based scalable weighted aggregation composition for knowledge graph embedding},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Model-free preference elicitation. <em>IJCAI</em>,
3493–3503. (<a href="https://doi.org/10.24963/ijcai.2024/387">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In recommender systems, preference elicitation (PE) is an effective way to learn about a user&#39;s preferences to improve recommendation quality. Expected value of information (EVOI), a Bayesian technique that computes expected gain in user utility, has proven to be effective in selecting useful PE queries. Most EVOI methods use probabilistic models of user preferences and query responses to compute posterior utilities. By contrast, we develop model-free variants of EVOI that rely on function approximation to obviate the need for specific modeling assumptions. Specifically, we learn user response and utility models from existing data (often available in real-world recommender systems), which are used to estimate EVOI rather than relying on explicit probabilistic inference. We augment our approach by using online planning, specifically, Monte Carlo tree search, to further enhance our elicitation policies. We show that our approach offers significant improvement in recommendation quality over standard baselines on several PE tasks. Keywords: Knowledge Representation and Reasoning: KRR: Preference modelling and preference-based reasoning Data Mining: DM: Recommender systems Humans and AI: HAI: Personalization and user modeling},
  archive   = {C_IJCAI},
  author    = {Carlos Martin and Craig Boutilier and Ofer Meshi and Tuomas Sandholm},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/387},
  month     = {8},
  pages     = {3493-3503},
  title     = {Model-free preference elicitation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Constructive interpolation and concept-based beth
definability for description logics via sequents. <em>IJCAI</em>,
3484–3492. (<a href="https://doi.org/10.24963/ijcai.2024/386">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We introduce a constructive method applicable to a large number of description logics (DLs) for establishing the concept-based Beth definability property (CBP) based on sequent systems. Using the highly expressive DL RIQ as a case study, we introduce novel sequent calculi for RIQ-ontologies and show how certain interpolants can be computed from sequent calculus proofs, which permit the extraction of explicit definitions of implicitly definable concepts. To the best of our knowledge, this is the first sequent-based approach to computing interpolants and definitions within the context of DLs, as well as the first proof that RIQ enjoys the CBP. Moreover, due to the modularity of our sequent systems, our results hold for any restriction of RIQ, and are applicable to other DLs by suitable modifications. Keywords: Knowledge Representation and Reasoning: KRR: Description logics and ontologies Knowledge Representation and Reasoning: KRR: Automated reasoning and theorem proving},
  archive   = {C_IJCAI},
  author    = {Timothy S. Lyon and Jonas Karge},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/386},
  month     = {8},
  pages     = {3484-3492},
  title     = {Constructive interpolation and concept-based beth definability for description logics via sequents},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). First-order progression beyond local-effect and normal
actions. <em>IJCAI</em>, 3475–3483. (<a
href="https://doi.org/10.24963/ijcai.2024/385">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {One of the fundamental problems in reasoning about action is progression, which is to update a knowledge base according to the effects of an action into another knowledge base that retains all proper information. The problem is notoriously challenging, as in general, it requires second-order logic. Efforts have been made to find fragments where progression is first-order definable. Liu and Lakemeyer showed that for actions that have only local effects, progression is always first-order definable. They also generalized the result to so-called normal actions, that allow for non-local effects, as long as the affected fluent predicates only depend on local-effect ones, under certain restrictions on the knowledge base. In addition, they showed that for so-called proper+ knowledge bases, progression for normal actions can be efficient under reasonable assumptions. In this paper, we consider a larger class of theories, called the acyclic ones, that strictly subsumes normal actions. In such theories, dependencies between non-local effect fluent predicates are allowed, as long as they do not contain any cycles. We prove progression to be equally first-order definable for this class. Furthermore, under similar but stronger assumptions than those made by Liu and Lakemeyer, we show that progression is efficient as well. Keywords: Knowledge Representation and Reasoning: KRR: Reasoning about actions},
  archive   = {C_IJCAI},
  author    = {Daxin Liu and Jens Claßen},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/385},
  month     = {8},
  pages     = {3475-3483},
  title     = {First-order progression beyond local-effect and normal actions},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Regression residual reasoning with pseudo-labeled
contrastive learning for uncovering multiple complex compositional
relations. <em>IJCAI</em>, 3466–3474. (<a
href="https://doi.org/10.24963/ijcai.2024/384">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Abstract Visual Reasoning (AVR) has been widely studied in literature. Our study reveals that AVR models tend to rely on appearance matching rather than a genuine understanding of underlying rules. We hence develop a challenging benchmark, Multiple Complex Compositional Reasoning (MC2R), composed of diverse compositional rules on attributes with intentionally increased variations. It aims to identify two outliers from five given images, in contrast to single-answer questions in previous AVR tasks. To solve MC2R tasks, a Regression Residual Reasoning with Pseudo-labeled Contrastive Learning (R3PCL) is proposed, which first transforms the original problem by selecting three images following the same rule, and iteratively regresses one normal image by using the other two, allowing the model to gradually comprehend the underlying rules. The proposed PCL leverages a set of min-max operations to generate more reliable pseudo labels, and exploits contrastive learning with data augmentation on pseudo-labeled images to boost the discrimination and generalization of features. Experimental results on two AVR datasets show that the proposed R3PCL significantly outperforms state-of-the-art models. Keywords: Knowledge Representation and Reasoning: KRR: Learning and reasoning},
  archive   = {C_IJCAI},
  author    = {Chengtai Li and Yuting He and Jianfeng Ren and Ruibin Bai and Yitian Zhao and Heng Yu and Xudong Jiang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/384},
  month     = {8},
  pages     = {3466-3474},
  title     = {Regression residual reasoning with pseudo-labeled contrastive learning for uncovering multiple complex compositional relations},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Instantiations and computational aspects of non-flat
assumption-based argumentation. <em>IJCAI</em>, 3457–3465. (<a
href="https://doi.org/10.24963/ijcai.2024/383">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Most existing computational tools for assumption-based argumentation (ABA) focus on so-called flat frameworks, disregarding the more general case. In this paper, we study an instantiation-based approach for reasoning in possibly non-flat ABA. We make use of a semantics-preserving translation between ABA and bipolar argumentation frameworks (BAFs). By utilizing compilability theory, we establish that the constructed BAFs will in general be of exponential size. To keep the number of arguments and computational cost low, we present three ways of identifying redundant arguments. Moreover, we identify fragments of ABA which admit a poly-sized instantiation. We propose two algorithmic approaches for reasoning in non-flat ABA; the first utilizes the BAF instantiation while the second works directly without constructing arguments. An empirical evaluation shows that the former outperforms the latter on many instances, reflecting the lower complexity of BAF reasoning. This result is in contrast to flat ABA, where direct approaches dominate instantiation-based solvers. Keywords: Knowledge Representation and Reasoning: KRR: Argumentation Knowledge Representation and Reasoning: KRR: Computational complexity of reasoning},
  archive   = {C_IJCAI},
  author    = {Tuomo Lehtonen and Anna Rapberger and Francesca Toni and Markus Ulbricht and Johannes P. Wallner},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/383},
  month     = {8},
  pages     = {3457-3465},
  title     = {Instantiations and computational aspects of non-flat assumption-based argumentation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Extremal separation problems for temporal instance queries.
<em>IJCAI</em>, 3448–3456. (<a
href="https://doi.org/10.24963/ijcai.2024/382">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The separation problem for a class Q of database queries is to find a query in Q that distinguishes between a given set of ‘positive’ and ‘negative’ data examples. Separation provides explanations of examples and underpins the query-by-example paradigm to support database users in constructing and refining queries. As the space of all separating queries can be large, it is helpful to succinctly represent this space by means of its most specific (logically strongest) and general (weakest) members. We investigate this extremal separation problem for classes of instance queries formulated in linear temporal logic LTL with the operators conjunction, ‘next’, and ‘eventually’. Our results range from tight complexity bounds for verifying and counting extremal separators to algorithms computing them. Keywords: Knowledge Representation and Reasoning: KRR: Qualitative, geometric, spatial, and temporal reasoning Knowledge Representation and Reasoning: KRR: Learning and reasoning Multidisciplinary Topics and Applications: MTA: Databases},
  archive   = {C_IJCAI},
  author    = {Jean Christoph Jung and Vladislav Ryzhikov and Frank Wolter and Michael Zakharyaschev},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/382},
  month     = {8},
  pages     = {3448-3456},
  title     = {Extremal separation problems for temporal instance queries},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LLMs can find mathematical reasoning mistakes by pedagogical
chain-of-thought. <em>IJCAI</em>, 3439–3447. (<a
href="https://doi.org/10.24963/ijcai.2024/381">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Self-correction is emerging as a promising approach to mitigate the issue of hallucination in Large Language Models (LLMs). To facilitate effective self-correction, recent research has proposed mistake detection as its initial step. However, current literature suggests that LLMs often struggle with reliably identifying reasoning mistakes when using simplistic prompting strategies. To address this challenge, we introduce a unique prompting strategy, termed the Pedagogical Chain-of-Thought (PedCoT), which is specifically designed to guide the identification of reasoning mistakes, particularly mathematical reasoning mistakes. PedCoT consists of pedagogical principles for prompts (PPP) design, two-stage interaction process (TIP) and grounded PedCoT prompts, all inspired by the educational theory of the Bloom Cognitive Model (BCM). We evaluate our approach on two public datasets featuring math problems of varying difficulty levels. The experiments demonstrate that our zero-shot prompting strategy significantly outperforms strong baselines. The proposed method can achieve the goal of reliable mathematical mistake identification and provide a foundation for automatic math answer grading. The results underscore the significance of educational theory, serving as domain knowledge, in guiding prompting strategy design for addressing challenging tasks with LLMs effectively. Keywords: Knowledge Representation and Reasoning: KRR: Diagnosis and abductive reasoning Knowledge Representation and Reasoning: KRR: Automated reasoning and theorem proving Multidisciplinary Topics and Applications: MTA: Education},
  archive   = {C_IJCAI},
  author    = {Zhuoxuan Jiang and Haoyuan Peng and Shanshan Feng and Fan Li and Dongsheng Li},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/381},
  month     = {8},
  pages     = {3439-3447},
  title     = {LLMs can find mathematical reasoning mistakes by pedagogical chain-of-thought},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning big logical rules by joining small rules.
<em>IJCAI</em>, 3430–3438. (<a
href="https://doi.org/10.24963/ijcai.2024/380">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A major challenge in inductive logic programming is learning big rules. To address this challenge, we introduce an approach where we join small rules to learn big rules. We implement our approach in a constraint-driven system and use constraint solvers to efficiently join rules. Our experiments on many domains, including game playing and drug design, show that our approach can (i) learn rules with more than 100 literals, and (ii) drastically outperform existing approaches in terms of predictive accuracies. Keywords: Knowledge Representation and Reasoning: KRR: Logic programming Machine Learning: ML: Symbolic methods},
  archive   = {C_IJCAI},
  author    = {Céline Hocquette and Andreas Niskanen and Rolf Morel and Matti Järvisalo and Andrew Cropper},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/380},
  month     = {8},
  pages     = {3430-3438},
  title     = {Learning big logical rules by joining small rules},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning logic programs by discovering higher-order
abstractions. <em>IJCAI</em>, 3421–3429. (<a
href="https://doi.org/10.24963/ijcai.2024/379">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We introduce the higher-order refactoring problem, where the goal is to compress a logic program by discovering higher-order abstractions, such as map, filter, and fold. We implement our approach in Stevie, which formulates the refactoring problem as a constraint optimisation problem. Our experiments on multiple domains, including program synthesis and visual reasoning, show that refactoring can improve the learning performance of an inductive logic programming system, specifically improving predictive accuracies by 27% and reducing learning times by 47%. We also show that Stevie can discover abstractions that transfer to multiple domains. Keywords: Knowledge Representation and Reasoning: KRR: Logic programming Machine Learning: ML: Symbolic methods},
  archive   = {C_IJCAI},
  author    = {Céline Hocquette and Sebastijan Dumancic and Andrew Cropper},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/379},
  month     = {8},
  pages     = {3421-3429},
  title     = {Learning logic programs by discovering higher-order abstractions},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Semantics for non-flat assumption-based argumentation,
revisited. <em>IJCAI</em>, 3413–3420. (<a
href="https://doi.org/10.24963/ijcai.2024/378">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Assumption-based argumentation (ABA) is an argumentative formalism that allows for reasoning on the basis of defeasible assumptions and strict rules. Standard semantics for this formalism sometimes give rise to problematic behaviour in the presence of rules with assumptions in their heads. In this paper, we introduce a six-valued labelling semantics that overcomes these shortcomings while preserving all the usual properties of the standard Dung-style three-valued semantics for ABA frameworks, including existence of the complete semantics, uniqueness of the grounded semantics and preservation of the computational complexity of all main reasoning processes. Keywords: Knowledge Representation and Reasoning: KRR: Argumentation Knowledge Representation and Reasoning: KRR: Non-monotonic reasoning},
  archive   = {C_IJCAI},
  author    = {Jesse Heyninck and Ofer Arieli},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/378},
  month     = {8},
  pages     = {3413-3420},
  title     = {Semantics for non-flat assumption-based argumentation, revisited},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Quantitative claim-centric reasoning in logic-based
argumentation. <em>IJCAI</em>, 3404–3412. (<a
href="https://doi.org/10.24963/ijcai.2024/377">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Argumentation is a well-established formalism for nonmonotonic reasoning, with popular frameworks being Dung’s abstract argumentation (AFs) or logic-based argumentation (Besnard-Hunter’s framework). Structurally, a set of formulas forms support for a claim if it is consistent, subset-minimal, and implies the claim. Then, an argument comprises support and a claim. We observe that the computational task (ARG) of asking for support of a claim in a knowledge base is “brave”, since many claims with a single support are accepted. As a result, ARG falls short when it comes to the question of confidence in a claim, or claim strength. In this paper, we propose a concept for measuring the (acceptance) strength of claims, based on counting supports for a claim. Further, we settle classical and structural complexity of counting arguments favoring a given claim in propositional knowledge bases (KBs). We introduce quantitative reasoning to measure the strength of claims in a KB and to determine the relevance strength of a formula for a claim. Keywords: Knowledge Representation and Reasoning: KRR: Argumentation Knowledge Representation and Reasoning: KRR: Computational complexity of reasoning},
  archive   = {C_IJCAI},
  author    = {Markus Hecher and Yasir Mahmood and Arne Meier and Johannes Schmidt},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/377},
  month     = {8},
  pages     = {3404-3412},
  title     = {Quantitative claim-centric reasoning in logic-based argumentation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning conditional preference networks: An approach based
on the minimum description length principle. <em>IJCAI</em>, 3395–3403.
(<a href="https://doi.org/10.24963/ijcai.2024/376">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {CP-nets are a very expressive graphical model for the representation of preferences over combinatorial spaces. They are particularly well suited for settings where an important task is to compute the optimal completion of some partially specified alternative; this is for instance the case of interactive configurators, where preferences can be used, at every step of the interaction, to guide the decision maker towards a satisfactory configuration. Learning CP-nets turns out to be challenging when the input data has the form of pairwise comparisons between alternatives. Furthermore, this type of preference data is not commonly stored: it can be elicitated but this puts an additional burden on the decision maker. In this article, we propose a new method for learning CP-nets from sales history, a kind of data readily available in many e-commerce applications. The approach is based on the the minimum description length (MDL) principle. We show some theoretical properties of this learning task, namely its sample complexity and its NP-completeness, and we experiment this learning algorithm in a recommendation settings with a real sales history from a car maker. Keywords: Knowledge Representation and Reasoning: KRR: Preference modelling and preference-based reasoning Machine Learning: ML: Learning preferences or rankings},
  archive   = {C_IJCAI},
  author    = {Pierre-François Gimenez and Jérôme Mengin},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/376},
  month     = {8},
  pages     = {3395-3403},
  title     = {Learning conditional preference networks: An approach based on the minimum description length principle},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Finite groundings for ASP with functions: A journey through
consistency. <em>IJCAI</em>, 3386–3394. (<a
href="https://doi.org/10.24963/ijcai.2024/375">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Answer set programming (ASP) is a logic programming formalism used in various areas of artificial intelligence like combinatorial problem solving and knowledge representation and reasoning. It is known that enhancing ASP with function symbols makes basic reasoning problems highly undecidable. However, even in simple cases, state of the art reasoners, specifically those relying on a ground-and-solve approach, fail to produce a result. Therefore, we reconsider consistency as a basic reasoning problem for ASP. We show reductions that give an intuition for the high level of undecidability. These insights allow for a more fine-grained analysis where we characterize ASP programs as &quot;frugal&quot; and &quot;non-proliferous&quot;. For such programs, we are not only able to semi-decide consistency but we also propose a grounding procedure that yields finite groundings on more ASP programs with the concept of &quot;forbidden&quot; facts. Keywords: Knowledge Representation and Reasoning: KRR: Knowledge representation languages Knowledge Representation and Reasoning: KRR: Computational complexity of reasoning Knowledge Representation and Reasoning: KRR: Logic programming Knowledge Representation and Reasoning: KRR: Non-monotonic reasoning},
  archive   = {C_IJCAI},
  author    = {Lukas Gerlach and David Carral and Markus Hecher},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/375},
  month     = {8},
  pages     = {3386-3394},
  title     = {Finite groundings for ASP with functions: A journey through consistency},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Revisiting causal discovery from a complexity-theoretic
perspective. <em>IJCAI</em>, 3377–3385. (<a
href="https://doi.org/10.24963/ijcai.2024/374">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Causal discovery seeks to unveil causal relationships (represented as a so-called causal graph) from observational data. This paper investigates the complex relationship between the graph structure and the efficiency of constraint-based causal discovery algorithms. Our main contributions include (i) a near-tight characterization of which causal graphs admit a small d-separating set for each pair of vertices and thus can potentially be efficiently recovered by a constraint-based causal discovery algorithm, (ii) the explicit construction of a sequence of causal graphs on which the influential PC algorithm might need exponential time, although there is a small d-separating set between every pair of variables, and (iii) the formulation of a new causal discovery algorithm which achieves fixed-parameter running time by considering the maximum number of edge-disjoint paths between variables in the (undirected) super-structure as the parameter. A distinguishing feature of our investigation is that it is carried out within a more fine-grained model which more faithfully captures the infeasibility of performing accurate independence tests for large sets of conditioning variables. Keywords: Knowledge Representation and Reasoning: KRR: Causality Knowledge Representation and Reasoning: KRR: Computational complexity of reasoning},
  archive   = {C_IJCAI},
  author    = {Robert Ganian and Viktoriia Korchemna and Stefan Szeider},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/374},
  month     = {8},
  pages     = {3377-3385},
  title     = {Revisiting causal discovery from a complexity-theoretic perspective},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Improved encodings of acyclicity for translating answer set
programming into integer programming. <em>IJCAI</em>, 3369–3376. (<a
href="https://doi.org/10.24963/ijcai.2024/373">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this work, we introduce novel translations of Answer Set Programming (ASP) into Integer Programming (IP). While building upon a previously introduced IP translation, we revisit the translation of acyclicity constraints essential for capturing answer sets precisely. By leveraging vertex elimination graphs, we demonstrate that a new translation of acyclicity can yield integer programs with a more restrictive linear relaxation compared to previous methods. This enhancement enables IP solvers to prune the search space more efficiently. Furthermore, we show how acyclicity can be expressed more concisely in IP given any feedback vertex set of the underlying dependency graph. Experimental results underscore the improved efficiency of our methods over the previously implemented translation. The new vertex elimination based translation with Gurobi as the back-end solver turns out competitive against Clingo, a state-of-the-art native ASP solver, in a number of non-tight Answer Set Optimization (ASO) benchmarks. Keywords: Knowledge Representation and Reasoning: KRR: Logic programming Constraint Satisfaction and Optimization: CSO: Constraint optimization problems Constraint Satisfaction and Optimization: CSO: Constraint programming Constraint Satisfaction and Optimization: CSO: Constraint satisfaction},
  archive   = {C_IJCAI},
  author    = {Masood Feyzbakhsh Rankooh and Tomi Janhunen},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/373},
  month     = {8},
  pages     = {3369-3376},
  title     = {Improved encodings of acyclicity for translating answer set programming into integer programming},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Quantitative reasoning over incomplete abstract
argumentation frameworks. <em>IJCAI</em>, 3360–3368. (<a
href="https://doi.org/10.24963/ijcai.2024/372">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We introduce PERCVER and PERCACC, the problems asking for the percentages of the completions of an incomplete Abstract Argumentation Framework (iAAF) where a set of arguments S is an extension and an argument a is accepted, respectively. These problems give insights into the status of S and a more precise than the “traditional” verification and acceptance tests under the possible and necessary perspectives, that decide if S is an extension and a is accepted in at least one or every completion, respectively. As a first contribution, we investigate the relationship between the proposed framework and probabilistic AAFs (prAAFs) under the constellations approach (that, at first sight, seem to be suitable for starightforwardly encoding the quantitative reasoning underlying PERCVER and PERCACC). In this regard, we show that translating an iAAF into an equivalent prAAF requires a heavy computational cost: this backs the study of PERCVER and PERCACC as new distinguished problems. Then, we investigate the complexity of PERCVER and PERCACC, and we identify interesting islands of tractability. Keywords: Knowledge Representation and Reasoning: KRR: Argumentation Knowledge Representation and Reasoning: KRR: Computational complexity of reasoning},
  archive   = {C_IJCAI},
  author    = {Bettina Fazzinga and Sergio Flesca and Filippo Furfaro and Giuseppina Monterosso},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/372},
  month     = {8},
  pages     = {3360-3368},
  title     = {Quantitative reasoning over incomplete abstract argumentation frameworks},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the logic of theory change iteration of KM-update,
revised. <em>IJCAI</em>, 3351–3359. (<a
href="https://doi.org/10.24963/ijcai.2024/371">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Belief revision and update, two significant types of belief change, both focus on how an agent modifies her beliefs in presence of new information. The most striking difference between them is that the former studies the change of beliefs in a static world while the latter concentrates on a dynamically-changing world. The famous AGM and KM postulates were proposed to capture rational belief revision and update, respectively. However, both of them are too permissive to exclude some unreasonable changes in the iteration. In response to this weakness, the DP postulates and its extensions for iterated belief revision were presented. Furthermore, Ferme and Goncalves integrated these postulates in belief update. Unfortunately, some redundant components are included in the definitions of belief states and the faithful assignments for semantic characterizations. Moreover, their approach does not meet the desired property of iterated belief update. They also do not discuss the rationale of any DP postulate within the update context. This paper is intended to fix these deficiencies of Ferme and Goncalves’s approach. Firstly, we present a modification of the original KM postulates based on belief states, and propose the notion of faithful collective assignments of belief states to partial preorders. Subsequently, we migrate several well-known postulates for iterated belief revision to iterated belief update. Moreover, we provide the exact semantic characterizations based on partial preorders for each of the proposed postulates. Finally, we analyze the compatibility between the above iterated postulates and the KM postulates for belief update. Keywords: Knowledge Representation and Reasoning: KRR: Belief change Knowledge Representation and Reasoning: KRR: Reasoning about knowledge and belief},
  archive   = {C_IJCAI},
  author    = {Liangda Fang and Tong Zhu and Quanlong Guan and Junming Qiu and Zhao-Rong Lai and Weiqi Luo and Hai Wan},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/371},
  month     = {8},
  pages     = {3351-3359},
  title     = {On the logic of theory change iteration of KM-update, revised},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Computational aspects of progression for temporal
equilibrium logic. <em>IJCAI</em>, 3342–3350. (<a
href="https://doi.org/10.24963/ijcai.2024/370">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Temporal logic plays a crucial role in specifying and reasoning about dynamic systems, where temporal constraints and properties to be monitored are essential. Traditional approaches like LTL-monitoring assume monotonicity, which limits their applicability to scenarios involving non-monotonic temporal properties. We delve into complexity aspects of monitoring temporal specifications using non-monotonic Temporal Equilibrium Logic (TEL), a temporal extension of Answer Set Programming defined over Temporal Here and There Logic (THT) with a minimality criterion enforcing stable models. Notably, we study the complexity gap between monitoring properties in THT and TEL semantics, and the complexity of monitoring approximations based on progression, which is widely used in verification and in AI. In that, we pay particular attention to the fragment of temporal logic programs. Keywords: Knowledge Representation and Reasoning: KRR: Computational complexity of reasoning Knowledge Representation and Reasoning: KRR: Logic programming Knowledge Representation and Reasoning: KRR: Non-monotonic reasoning Agent-based and Multi-agent Systems: MAS: Formal verification, validation and synthesis},
  archive   = {C_IJCAI},
  author    = {Thomas Eiter and Davide Soldà},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/370},
  month     = {8},
  pages     = {3342-3350},
  title     = {Computational aspects of progression for temporal equilibrium logic},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Epistemic logic programs: Non-ground and counting
complexity. <em>IJCAI</em>, 3333–3341. (<a
href="https://doi.org/10.24963/ijcai.2024/369">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Answer Set Programming (ASP) is a prominent problem-modeling and solving framework, whose solutions are called answer sets. Epistemic logic programs (ELP) extend ASP to reason about all or some answer sets. Solutions to an ELP can be seen as consequences over multiple collections of answer sets, known as world views. While the complexity of propositional programs is well studied, the non-ground case remains open. This paper establishes the complexity of non-ground ELPs. We provide a comprehensive picture for well-known program fragments, which turns out to be complete for the class NEXPTIME with access to oracles up to SigmaP2. In the quantitative setting, we establish complexity results for counting complexity beyond #EXP. To mitigate high complexity, we establish results in case of bounded predicate arity, reaching up to the fourth level of the polynomial hierarchy. Finally, we provide ETH-tight runtime results for the parameter treewidth, which has applications in quantitative reasoning, where we reason on (marginal) probabilities of epistemic literals. Keywords: Knowledge Representation and Reasoning: KRR: Computational complexity of reasoning Knowledge Representation and Reasoning: KRR: Knowledge representation languages Knowledge Representation and Reasoning: KRR: Logic programming Knowledge Representation and Reasoning: KRR: Non-monotonic reasoning},
  archive   = {C_IJCAI},
  author    = {Thomas Eiter and Johannes K. Fichte and Markus Hecher and Stefan Woltran},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/369},
  month     = {8},
  pages     = {3333-3341},
  title     = {Epistemic logic programs: Non-ground and counting complexity},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Model checking causality. <em>IJCAI</em>, 3324–3332. (<a
href="https://doi.org/10.24963/ijcai.2024/368">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present a novel modal language for causal reasoning and interpret it by means of a semantics in which causal information is represented using causal bases in propositional form. The language includes modal operators of conditional causal necessity where the condition is a causal change operation. We provide a succinct formulation of model checking for our language and a model checking procedure based on a polysize reduction to QBF. We illustrate the expressiveness of our language through some examples and show that it allows us to represent and to formally verify a variety of concepts studied in the field of explainable AI including abductive explanation, intervention and actual cause. Keywords: Knowledge Representation and Reasoning: KRR: Causality Knowledge Representation and Reasoning: KRR: Knowledge representation languages},
  archive   = {C_IJCAI},
  author    = {Tiago de Lima and Emiliano Lorini},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/368},
  month     = {8},
  pages     = {3324-3332},
  title     = {Model checking causality},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Compilation and fast model counting beyond CNF.
<em>IJCAI</em>, 3315–3323. (<a
href="https://doi.org/10.24963/ijcai.2024/367">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Circuits in deterministic decomposable negation normal form (d-DNNF) are representations of Boolean functions that enable linear-time model counting. This paper strengthens our theoretical knowledge of what classes of functions can be efficiently transformed, or compiled, into d-DNNF. Our main contribution is the fixed-parameter tractable (FPT) compilation of conjunctions of specific constraints parameterized by incidence treewidth. This subsumes the known result for CNF. The constraints in question are all functions representable by constant-width ordered binary decision diagrams (OBDDs) for all variable orderings. For instance, this includes parity constraints and cardinality constraints with constant threshold. The running time of the FPT compilation is singly exponential in the incidence treewidth but hides large constants in the exponent. To balance that, we give a more efficient FPT algorithm for model counting that applies to a sub-family of the constraints and does not require compilation. Keywords: Knowledge Representation and Reasoning: KRR: Knowledge compilation},
  archive   = {C_IJCAI},
  author    = {Alexis de Colnet and Stefan Szeider and Tianwei Zhang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/367},
  month     = {8},
  pages     = {3315-3323},
  title     = {Compilation and fast model counting beyond CNF},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing controlled query evaluation through epistemic
policies. <em>IJCAI</em>, 3307–3314. (<a
href="https://doi.org/10.24963/ijcai.2024/366">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we propose the use of epistemic dependencies to express data protection policies in Controlled Query Evaluation (CQE), which is a form of confidentiality-preserving query answering over ontologies and databases. The resulting policy language goes significantly beyond those proposed in the literature on CQE so far, allowing for very rich and practically interesting forms of data protection rules. We show the expressive abilities of our framework and study the data complexity of CQE for (unions of) conjunctive queries when ontologies are specified in the Description Logic DL-LiteR. Interestingly, while we show that the problem is in general intractable, we prove tractability for the case of acyclic epistemic dependencies by providing a suitable query rewriting algorithm. The latter result paves the way towards the implementation and practical application of this new approach to CQE. Keywords: Knowledge Representation and Reasoning: KRR: Description logics and ontologies Knowledge Representation and Reasoning: KRR: Computational complexity of reasoning},
  archive   = {C_IJCAI},
  author    = {Gianluca Cima and Domenico Lembo and Lorenzo Marconi and Riccardo Rosati and Domenico Fabio Savo},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/366},
  month     = {8},
  pages     = {3307-3314},
  title     = {Enhancing controlled query evaluation through epistemic policies},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Temporal knowledge graph extrapolation via causal subhistory
identification. <em>IJCAI</em>, 3298–3306. (<a
href="https://doi.org/10.24963/ijcai.2024/365">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Temporal knowledge graph extrapolation has become a prominent area of study interest in recent years. Numerous methods for extrapolation have been put forth, mining query-relevant information from history to generate forecasts. However, existing approaches normally do not discriminate between causal and non-causal effects in reasoning; instead, they focus on analyzing the statistical correlation between the future events to be predicted and the historical data given, which may be deceptive and hinder the model&#39;s capacity to learn real causal information that actually affects the reasoning conclusions. To tackle it, we propose a novel approach called Causal Subhistory Identification (CSI), which focuses on extracting the causal subhistory for reasoning purposes from a large amount of historical data. CSI can improve the clarity and transparency of the reasoning process and more effectively convey the logic behind conclusions by giving priority to the causal subhistory and eliminating non-causal correlations. Extensive experiments demonstrate the remarkable potential of our CSI in the following aspects: superiority, improvement, explainability, and robustness. Keywords: Knowledge Representation and Reasoning: KRR: Learning and reasoning Data Mining: DM: Knowledge graphs and knowledge base completion Natural Language Processing: NLP: Applications},
  archive   = {C_IJCAI},
  author    = {Kai Chen and Ye Wang and Xin Song and Siwei Chen and Han Yu and Aiping Li},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/365},
  month     = {8},
  pages     = {3298-3306},
  title     = {Temporal knowledge graph extrapolation via causal subhistory identification},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Capturing knowledge graphs and rules with octagon
embeddings. <em>IJCAI</em>, 3289–3297. (<a
href="https://doi.org/10.24963/ijcai.2024/364">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Region based knowledge graph embeddings represent relations as geometric regions. This has the advantage that the rules which are captured by the model are made explicit, making it straightforward to incorporate prior knowledge and to inspect learned models. Unfortunately, existing approaches are severely restricted in their ability to model relational composition, and hence also their ability to model rules, thus failing to deliver on the main promise of region based models. With the aim of addressing these limitations, we investigate regions which are composed of axis-aligned octagons. Such octagons are particularly easy to work with, as intersections and compositions can be straightforwardly computed, while they are still sufficiently expressive to model arbitrary knowledge graphs. Among others, we also show that our octagon embeddings can properly capture a non-trivial class of rule bases. Finally, we show that our model achieves competitive experimental results. Keywords: Knowledge Representation and Reasoning: KRR: Learning and reasoning Data Mining: DM: Knowledge graphs and knowledge base completion Machine Learning: ML: Neuro-symbolic methods},
  archive   = {C_IJCAI},
  author    = {Victor Charpenay and Steven Schockaert},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/364},
  month     = {8},
  pages     = {3289-3297},
  title     = {Capturing knowledge graphs and rules with octagon embeddings},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Justifying argument acceptance with collective attacks:
Discussions and disputes. <em>IJCAI</em>, 3281–3288. (<a
href="https://doi.org/10.24963/ijcai.2024/363">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In formal argumentation one aims for intuitive and concise justifications for the acceptance of arguments. Discussion games and dispute trees are established methods to obtain such a justification. However, so far these techniques are based on instantiating the knowledge base into graph-based Dung style abstract argumentation frameworks (AFs). These instantiations are known to produce frameworks with a large number of arguments and thus also yield long discussion games and large dispute trees. To obtain more concise justifications for argument acceptance, we propose to instantiate the knowledge base as an argumentation framework with collective attacks (SETAF). Remarkably, this approach yields smaller frameworks compared to traditional AF instantiation, while exhibiting increased expressive power. We then introduce discussion games and dispute trees tailored to SETAFs, show that they correspond to credulous acceptance w.r.t. the well-known preferred semantics, analyze and tune them w.r.t. the size, and compare the two notions. Finally, we illustrate how our findings apply to assumption-based argumentation. Keywords: Knowledge Representation and Reasoning: KRR: Argumentation Knowledge Representation and Reasoning: KRR: Computational complexity of reasoning},
  archive   = {C_IJCAI},
  author    = {Giovanni Buraglio and Wolfgang Dvorak and Matthias König and Markus Ulbricht},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/363},
  month     = {8},
  pages     = {3281-3288},
  title     = {Justifying argument acceptance with collective attacks: Discussions and disputes},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning what to monitor: Using machine learning to improve
past STL monitoring. <em>IJCAI</em>, 3270–3280. (<a
href="https://doi.org/10.24963/ijcai.2024/362">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Monitoring is a runtime verification technique that can be used to check whether an execution of a system (trace) satisfies or not a given set of properties. Compared to other formal verification techniques, e.g., model checking, one needs to specify the properties to be monitored, but a complete model of the system is no longer necessary. First, we introduce the pure past fragment of Signal Temporal Logic (ppSTL), and we use it to define the monitorable safety (G(ppSTL)) and cosafety (F(ppSTL)) fragments of STL, which properly extend the commonly-used bounded-future fragment. Then, we devise a multi-objective genetic programming algorithm to automatically extend the set of properties to monitor on the basis of the history of failure traces collected over time. The framework resulting from the integration of the monitor and the learning algorithm is then experimentally validated on various public datasets. The outcomes of the experimentation confirm the effectiveness of the proposed solution. Keywords: Knowledge Representation and Reasoning: KRR: Learning and reasoning Machine Learning: ML: Explainable/Interpretable machine learning Knowledge Representation and Reasoning: KRR: Qualitative, geometric, spatial, and temporal reasoning Machine Learning: ML: Symbolic methods},
  archive   = {C_IJCAI},
  author    = {Andrea Brunello and Luca Geatti and Angelo Montanari and Nicola Saccomanno},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/362},
  month     = {8},
  pages     = {3270-3280},
  title     = {Learning what to monitor: Using machine learning to improve past STL monitoring},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Primal grammars driven automated induction. <em>IJCAI</em>,
3259–3269. (<a href="https://doi.org/10.24963/ijcai.2024/361">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Automated induction is a powerful method for the validation of critical systems. However, the inductive proof process faces major challenges: it is undecidable and diverges even with small examples. Previous methods have proposed ad-hoc heuristics to speculate on additional lemmas that hopefully stop the divergence. Although these methods have succeeded in proving interesting theorems, they have significant limitations: in particular, they often fail to find appropriate lemmas, and the lemmas they provide may not be valid. We present a new method that allows us to perform inductive proofs in conditional theories. This method automatically detects divergence in proof traces and derives primal grammars as well as new lemmas that schematize the divergent sequence. This new construction allows us to break the divergence and complete the proof. Our method is presented as a set of inference rules whose soundness and refutational completeness have been formally proved. Unlike previous methods, our method is fully automated and has no risk of over-generalization. Moreover, our technique for capturing and schematizing divergence represents the most general decidable schematization, with respect to description power, among all known schematizations. Our method has been implemented in C++ and successfully proved over fifty complex examples that fail with well-known theorem provers (e.g., ACL2, Isabelle, PVS, SPIKE) and related methods for handling divergence in proofs by induction. Our method represents a significant contribution to the field of automated reasoning as it can be integrated with existing automated and interactive inductive proof systems to enhance their performance. Moreover, it has the potential to substantially reduce the time needed for the verification of critical systems. Keywords: Knowledge Representation and Reasoning: KRR: Automated reasoning and theorem proving},
  archive   = {C_IJCAI},
  author    = {Adel Bouhoula and Miki Hermann},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/361},
  month     = {8},
  pages     = {3259-3269},
  title     = {Primal grammars driven automated induction},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bypassing the ASP bottleneck: Hybrid grounding by splitting
and rewriting. <em>IJCAI</em>, 3250–3258. (<a
href="https://doi.org/10.24963/ijcai.2024/360">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Answer Set Programming (ASP) is a key paradigm for problems in artificial intelligence and industrial contexts. In ASP, problems are modeled via a set of rules. Over the time this paradigm grew into a rich language, enabling complex rule types like aggregate expressions. Most practical ASP systems follow a ground-and-solve pattern, where rule schemes are grounded and resulting rules are solved. There, the so-called grounding bottleneck may prevent from solving, due to sheer grounding sizes. Recently body-decoupled grounding (BDG) demonstrated how to reduce grounding sizes by delegating effort to solving. However, BDG provides limited interoperability with traditional grounders and only covers simple rule types. In this work, we establish hybrid grounding — based on a novel splitting theorem that allows us to freely combine BDG with traditional grounders. To mitigate huge groundings in practice, we define rewriting procedures for efficiently deferring grounding effort of aggregates to solving. Our experimental results indicate that this approach is competitive, especially for instances, where traditional grounding fails. Keywords: Knowledge Representation and Reasoning: KRR: Logic programming Knowledge Representation and Reasoning: KRR: Applications Knowledge Representation and Reasoning: KRR: Computational complexity of reasoning Knowledge Representation and Reasoning: KRR: Non-monotonic reasoning},
  archive   = {C_IJCAI},
  author    = {Alexander Beiser and Markus Hecher and Kaan Unalan and Stefan Woltran},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/360},
  month     = {8},
  pages     = {3250-3258},
  title     = {Bypassing the ASP bottleneck: Hybrid grounding by splitting and rewriting},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Data complexity in expressive description logics with path
expressions. <em>IJCAI</em>, 3241–3249. (<a
href="https://doi.org/10.24963/ijcai.2024/359">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We investigate the data complexity of the satisfiability problem for the very expressive description logic ZOIQ (a.k.a. ALCHbSelfregOIQ) over quasi-forests and establish its NP-completeness. This completes the data complexity landscape for decidable fragments of ZOIQ, and reproves known results on decidable fragments of OWL2 (SR family). Using the same technique, we establish coNEXPTIME-completeness (w.r.t. the combined complexity) of the entailment problem of rooted queries in ZIQ. Keywords: Knowledge Representation and Reasoning: KRR: Description logics and ontologies Knowledge Representation and Reasoning: KRR: Computational complexity of reasoning},
  archive   = {C_IJCAI},
  author    = {Bartosz Bednarczyk},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/359},
  month     = {8},
  pages     = {3241-3249},
  title     = {Data complexity in expressive description logics with path expressions},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Effective approach to LTLf best-effort synthesis in
multi-tier environments. <em>IJCAI</em>, 3232–3240. (<a
href="https://doi.org/10.24963/ijcai.2024/358">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider an agent acting in a complex environment modeled through a multi-tiered specification, in which each tier adds nondeterminism in the environment response to the agent actions. In this setting, we devise an effective approach to best-effort synthesis, i.e., synthesizing agent strategies that win against a maximal set of possible environment responses in each tier. We do this in a setting where both the multi-tier environment and agent goal are specified in the linear temporal logic on finite traces (LTLf). While theoretical solution techniques based on automata on infinite trees have been developed previously, we completely side-step them here and focus on a DFA-based game-theoretic technique, which can be effectively implemented symbolically. Specifically, we present a provably correct algorithm that is based on solving separately DFA-based games for each tier and then combining the obtained solutions on-the-fly. This algorithm is linear, as opposed to being exponential, in the number of tiers and thus, it can graciously handle multi-tier environments formed of several tiers. Keywords: Knowledge Representation and Reasoning: KRR: Reasoning about actions Agent-based and Multi-agent Systems: MAS: Formal verification, validation and synthesis},
  archive   = {C_IJCAI},
  author    = {Benjamin Aminof and Giuseppe De Giacomo and Gianmarco Parretti and Sasha Rubin},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/358},
  month     = {8},
  pages     = {3232-3240},
  title     = {Effective approach to LTLf best-effort synthesis in multi-tier environments},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Higher-order argumentation frameworks: Principles and
gradual semantics. <em>IJCAI</em>, 3224–3231. (<a
href="https://doi.org/10.24963/ijcai.2024/357">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The paper investigates how to evaluate elements in complex argumentation frameworks, where both arguments and attacks are weighted and might be attacked by arguments. We propose the first gradual semantics that assign a numerical value to every argument and attack. The value represents the acceptance (seriousness) degree of an argument (attack). We start by highlighting various technical challenges facing semantics in such complex settings, including how to deal with attacks vs arguments, and how to combine their values. We present principles that describe different strategies offered to semantics to meet such challenges. Then, we introduce various semantics per strategy. For instance, some semantics evaluate attacks and arguments in the same way while others, called hybrid, treat them differently. Finally, the principles are used to compare the plethora of novel semantics. The final result is a catalogue of semantics with different formal guarantees and behaviours. Keywords: Knowledge Representation and Reasoning: KRR: Argumentation Knowledge Representation and Reasoning: KRR: Common-sense reasoning},
  archive   = {C_IJCAI},
  author    = {Leila Amgoud and Dragan Doder and Marie-Christine Lagasquie-Schiex},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/357},
  month     = {8},
  pages     = {3224-3231},
  title     = {Higher-order argumentation frameworks: Principles and gradual semantics},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AMO-aware aggregates in answer set programming.
<em>IJCAI</em>, 3215–3223. (<a
href="https://doi.org/10.24963/ijcai.2024/356">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Aggregates such as sum and count are among the most frequently used linguistic extensions of Answer Set Programming (ASP). At-most-one (AMO) constraints are a specific form of aggregates that excludes the simultaneous truth of multiple elements in a set. This article unleashes a powerful propagation strategy in case groups of elements in an aggregate are also involved in AMO constraints. In fact, the combined knowledge given by aggregates and AMO constraints significantly increases the effectiveness of search space pruning, resulting in sensible performance gains. Keywords: Knowledge Representation and Reasoning: KRR: Logic programming Knowledge Representation and Reasoning: KRR: Non-monotonic reasoning},
  archive   = {C_IJCAI},
  author    = {Mario Alviano and Carmine Dodaro and Salvatore Fiorentino and Marco Maratea},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/356},
  month     = {8},
  pages     = {3215-3223},
  title     = {AMO-aware aggregates in answer set programming},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). General epistemic abstract argumentation framework:
Semantics and complexity. <em>IJCAI</em>, 3206–3214. (<a
href="https://doi.org/10.24963/ijcai.2024/355">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Epistemic Abstract Argumentation Framework (EAAF) extends Dung&#39;s framework (AAF)---a central formalism in AI for modeling disputes among agents---by allowing the representation of epistemic knowledge. In particular, EAAF augments AAF with weak and strong epistemic attacks whose intuitive meaning is that an argument a defeats an argument b by means of a weak (resp. strong) epistemic attack if a is true in every (resp. at least one) extension. So far, the semantics of EAAF has been defined only for a restricted class of frameworks, namely acyclic EAAF, where epistemic attacks do not occur in any cycle. In this paper, we provide an intuitive semantics for (general) EAAF that naturally extends that for AAF as well as that for acyclic EAAF. After providing some fundamental properties and giving an algorithm that enables the computation of EAAF semantics, by relying on state-of-the-art AAF-solvers, we investigate the complexity of canonical argumentation problems. Keywords: Knowledge Representation and Reasoning: KRR: Argumentation},
  archive   = {C_IJCAI},
  author    = {Gianvincenzo Alfano and Sergio Greco and Francesco Parisi and Irina Trubitsyna},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/355},
  month     = {8},
  pages     = {3206-3214},
  title     = {General epistemic abstract argumentation framework: Semantics and complexity},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CausVSR: Causality inspired visual sentiment recognition.
<em>IJCAI</em>, 3196–3204. (<a
href="https://doi.org/10.24963/ijcai.2024/354">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Visual Sentiment Recognition (VSR) is an evolving field that aims to detect emotional tendencies within visual content. Despite its growing significance, detecting emotions depicted in visual content, such as images, faces challenges, notably the emergence of misleading or spurious correlations of the contextual information. In response to these challenges, we propose a causality inspired VSR approach, called CausVSR. CausVSR is rooted in the fundamental principles of Emotional Causality theory, mimicking the human process from receiving emotional stimuli to deriving emotional states. CausVSR takes a deliberate stride toward conquering the VSR challenges. It harnesses the power of a structural causal model, intricately designed to encapsulate the dynamic causal interplay between visual content and their corresponding pseudo sentiment regions. This strategic approach allows for a deep exploration of contextual information, elevating the accuracy of emotional inference. Additionally, CausVSR utilizes a global category elicitation module, strategically employed to execute front-door adjustment techniques, effectively detecting and handling spurious correlations. Experiments, conducted on four widely-used datasets, demonstrate CausVSR&#39;s superiority in enhancing emotion perception within VSR, surpassing existing methods. Keywords: Humans and AI: HAI: Cognitive modeling Computer Vision: CV: Machine learning for vision Computer Vision: CV: Recognition (object detection, categorization) Machine Learning: ML: Deep learning architectures},
  archive   = {C_IJCAI},
  author    = {Xinyue Zhang and Zhaoxia Wang and Hailing Wang and Jing Xiang and Chunwei Wu and Guitao Cao},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/354},
  month     = {8},
  pages     = {3196-3204},
  title     = {CausVSR: Causality inspired visual sentiment recognition},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dialogue cross-enhanced central engagement attention model
for real-time engagement estimation. <em>IJCAI</em>, 3187–3195. (<a
href="https://doi.org/10.24963/ijcai.2024/353">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Real-time engagement estimation has been an important research topic in human-computer interaction in recent years. The emergence of the NOvice eXpert Interaction (NOXI) dataset, enriched with frame-wise engagement annotations, has catalyzed a surge in research efforts in this domain. Existing feature sequence partitioning methods for ultra-long videos have encountered challenges including insufficient information utilization and repetitive inference. Moreover, those studies focus mainly on the target participants’ features without taking into account those of the interlocutor. To address these issues, we propose the center-based sliding window method to obtain feature subsequences. The core of these subsequences is modeled using our innovative Central Engagement Attention Model (CEAM). Additionally, we introduce the dialogue cross-enhanced module that effectively incorporates the interlocutor’s features via cross-attention. Our proposed method outperforms the current best model, achieving a substantial gain of 1.5% in coordination correlation coefficient (CCC) and establishing a new state-of-the-art result. Our source codes and model checkpoints are available at https://github.com/wujiekd/Dialogue-Cross-Enhanced-CEAM. Keywords: Humans and AI: HAI: Human-computer interaction Humans and AI: HAI: Computer-aided education Humans and AI: HAI: Personalization and user modeling},
  archive   = {C_IJCAI},
  author    = {Jun Yu and Keda Lu and Ji Zhao and Zhihong Wei and Iek-Heng Chu and Peng Chang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/353},
  month     = {8},
  pages     = {3187-3195},
  title     = {Dialogue cross-enhanced central engagement attention model for real-time engagement estimation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CoCoG: Controllable visual stimuli generation based on human
concept representations. <em>IJCAI</em>, 3178–3186. (<a
href="https://doi.org/10.24963/ijcai.2024/352">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A central question for cognitive science is to understand how humans process visual scenes, i.e, to uncover human low-dimensional concept representation space from high-dimensional visual stimuli. Generating visual stimuli with controlling concepts is the key. However, there are currently no generative models in AI to solve this problem. Here, we present the Concept based Controllable Generation (CoCoG) framework. CoCoG consists of two components, a simple yet efficient AI agent for extracting interpretable concept and predicting human decision-making in visual similarity judgment tasks, and a conditional generation model for generating visual stimuli given the concepts. We quantify the performance of CoCoG from two aspects, the human behavior prediction accuracy and the controllable generation ability. The experiments with CoCoG indicate that 1) the reliable concept embeddings in CoCoG allows to predict human behavior with 64.07% accuracy in the THINGS-similarity dataset; 2) CoCoG can generate diverse stimuli through the control of concepts; 3) CoCoG can manipulate human similarity judgment behavior by intervening key concepts. CoCoG offers visual objects with controlling concepts to advance our understanding of causality in human cognition. The code of CoCoG framework is available at https://github.com/ncclab-sustech/CoCoG. Keywords: Humans and AI: HAI: Cognitive systems Humans and AI: HAI: Cognitive modeling Humans and AI: HAI: Human-computer interaction},
  archive   = {C_IJCAI},
  author    = {Chen Wei and Jiachen Zou and Dietmar Heinke and Quanying Liu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/352},
  month     = {8},
  pages     = {3178-3186},
  title     = {CoCoG: Controllable visual stimuli generation based on human concept representations},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-scale context-aware networks based on fragment
association for human activity recognition. <em>IJCAI</em>, 3169–3177.
(<a href="https://doi.org/10.24963/ijcai.2024/351">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Sensor-based Human Activity Recognition (HAR) constitutes a key component of many artificial intelligence applications. Although deep feature extraction technology is constantly updated and iterated with excellent results, it is still a difficult task to find a balance between performance and computational efficiency. Through an in-depth exploration of the inherent characteristics of HAR data, we propose a lightweight feature perception model, which encompasses an internal feature extractor and a contextual feature perceiver. The model mainly consists of two stages. The first stage is a hierarchical multi-scale feature extraction module, which is composed of deep separable convolution and multi-head attention mechanism. This module serves to extract conventional features for Human Activity Recognition. After the feature goes through a fragment recombination operation, it is passed into the Context-Aware module of the second stage, which is based on Retentive Transformer and optimized by Dropkey method to efficiently extract the relationship between the feature fragments, so as to mine more valuable feature information. Importantly, this does not add too much complexity to the model, thereby preventing excessive resource consumption. We conducted extensive experimental validation on multiple publicly available HAR datasets. Keywords: Humans and AI: HAI: Applications Data Mining: DM: Networks},
  archive   = {C_IJCAI},
  author    = {Zhiqiong Wang and Hanyu Liu and Boyang Zhao and Qi Shen and Mingzhe Li and Ningfeng Que and Mingke Yan and Junchang Xin},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/351},
  month     = {8},
  pages     = {3169-3177},
  title     = {Multi-scale context-aware networks based on fragment association for human activity recognition},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Apprenticeship-inspired elegance: Synergistic knowledge
distillation empowers spiking neural networks for efficient single-eye
emotion recognition. <em>IJCAI</em>, 3160–3168. (<a
href="https://doi.org/10.24963/ijcai.2024/350">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We introduce a novel multimodality synergistic knowledge distillation scheme tailored for efficient single-eye motion recognition tasks. This method allows a lightweight, unimodal student spiking neural network (SNN) to extract rich knowledge from an event-frame multimodal teacher network. The core strength of this approach is its ability to utilize the ample, coarser temporal cues found in conventional frames for effective emotion recognition. Consequently, our method adeptly interprets both temporal and spatial information from the conventional frame domain, eliminating the need for specialized sensing devices, e.g., event-based camera. The effectiveness of our approach is thoroughly demonstrated using both existing and our compiled single-eye emotion recognition datasets, achieving unparalleled performance in accuracy and efficiency over existing state-of-the-art methods. Keywords: Humans and AI: HAI: Cognitive modeling Humans and AI: HAI: Cognitive systems},
  archive   = {C_IJCAI},
  author    = {Yang Wang and Haiyang Mei and Qirui Bao and Ziqi Wei and Mike Zheng Shou and Haizhou Li and Bo Dong and Xin Yang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/350},
  month     = {8},
  pages     = {3160-3168},
  title     = {Apprenticeship-inspired elegance: Synergistic knowledge distillation empowers spiking neural networks for efficient single-eye emotion recognition},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MetaJND: A meta-learning approach for just noticeable
difference estimation. <em>IJCAI</em>, 3151–3159. (<a
href="https://doi.org/10.24963/ijcai.2024/349">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The modeling of just noticeable difference (JND) in supervised learning for visual signals has made significant progress. However, existing JND models often suffer from limited generalization due to the need for large-scale training data and their constraints to certain image types. Moreover, these models primarily focus on a single RGB modality, ignoring the potential complementary impacts of multiple modalities. To address these challenges, we propose a new meta-learning approach for the JND modeling, called MetaJND. We introduce two key visual-sensitive modalities like saliency and depth, and leverage a self-attention mechanism for effective interdependence of multi-modal features. Additionally, we incorporate meta-learning for the modality alignment, facilitating dynamic weight generation. Furthermore, we perform hierarchical fusion through multi-layer channel and spatial feature rectification. Experimental results on four benchmark datasets demonstrate the effectiveness of our MetaJND. Moreover, we have also evaluated its performance in compression and watermarking applications, observing higher bit-rate savings and better watermark hiding capabilities. Keywords: Humans and AI: HAI: Cognitive modeling Humans and AI: HAI: Applications Humans and AI: HAI: Cognitive systems},
  archive   = {C_IJCAI},
  author    = {Miaohui Wang and Yukuan Zhu and Rong Zhang and Wuyuan Xie},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/349},
  month     = {8},
  pages     = {3151-3159},
  title     = {MetaJND: A meta-learning approach for just noticeable difference estimation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). One-step spiking transformer with a linear complexity.
<em>IJCAI</em>, 3142–3150. (<a
href="https://doi.org/10.24963/ijcai.2024/348">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Spiking transformers have recently emerged as a robust alternative in deep learning. One focus of this field is the reduction of energy consumption, given that spiking transformers require lengthy simulation timesteps and complex floating-point attention mechanisms. In this paper, we propose a one-step approach that requires only one timestep and is of linear complexity. The proposed One-step Spiking Transformer (OST) incorporates a Time Domain Compression and Compensation (TDCC) component, which can significantly mitigate the spatio-temporal overhead of spiking transformers. Another novel component in OST is the Spiking Linear Transformation (SLT), designed to greatly reduce the number of floating-point multiply-and-accumulate operations. Experiments on both static and neuromorphic images show that OST can perform as well as or better than SOTA methods with just one timestep, even for more difficult tasks. For instance, comparing with Spikeformer, OST gains 1.59% in accuracy on ImageNet, yet 40.27% more efficient, and gains 0.7% on DVS128 Gesture. The supplementary materials and source code are available at https://github.com/songxt3/OST. Keywords: Humans and AI: HAI: Cognitive modeling Humans and AI: HAI: Applications Machine Learning: General},
  archive   = {C_IJCAI},
  author    = {Xiaotian Song and Andy Song and Rong Xiao and Yanan Sun},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/348},
  month     = {8},
  pages     = {3142-3150},
  title     = {One-step spiking transformer with a linear complexity},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TIM: An efficient temporal interaction module for spiking
transformer. <em>IJCAI</em>, 3133–3141. (<a
href="https://doi.org/10.24963/ijcai.2024/347">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Spiking Neural Networks (SNNs), as the third generation of neural networks, have gained prominence for their biological plausibility and computational efficiency, especially in processing diverse datasets. The integration of attention mechanisms, inspired by advancements in neural network architectures, has led to the development of Spiking Transformers. These have shown promise in enhancing SNNs&#39; capabilities, particularly in the realms of both static and neuromorphic datasets. Despite their progress, a discernible gap exists in these systems, specifically in the Spiking Self Attention (SSA) mechanism&#39;s effectiveness in leveraging the temporal processing potential of SNNs. To address this, we introduce the Temporal Interaction Module (TIM), a novel, convolution-based enhancement designed to augment the temporal data processing abilities within SNN architectures. TIM&#39;s integration into existing SNN frameworks is seamless and efficient, requiring minimal additional parameters while significantly boosting their temporal information handling capabilities. Through rigorous experimentation, TIM has demonstrated its effectiveness in exploiting temporal information, leading to state-of-the-art performance across various neuromorphic datasets. The code is available at https://github.com/BrainCog-X/Brain-Cog/tree/main/examples/TIM. Keywords: Humans and AI: HAI: Cognitive modeling Computer Vision: CV: Recognition (object detection, categorization) Computer Vision: CV: Representation learning Humans and AI: HAI: Cognitive systems},
  archive   = {C_IJCAI},
  author    = {Sicheng Shen and Dongcheng Zhao and Guobin Shen and Yi Zeng},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/347},
  month     = {8},
  pages     = {3133-3141},
  title     = {TIM: An efficient temporal interaction module for spiking transformer},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ReliaAvatar: A robust real-time avatar animator with
integrated motion prediction. <em>IJCAI</em>, 3124–3132. (<a
href="https://doi.org/10.24963/ijcai.2024/346">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Efficiently estimating the full-body pose with minimal wearable devices presents a worthwhile research direction. Despite significant advancements in this field, most current research neglects to explore full-body avatar estimation under low-quality signal conditions, which is prevalent in practical usage. To bridge this gap, we summarize three scenarios that may be encountered in real-world applications: standard scenario, instantaneous data-loss scenario, and prolonged data-loss scenario, and propose a new evaluation benchmark. The solution we propose to address data-loss scenarios is integrating the full-body avatar pose estimation problem with motion prediction. Specifically, we present ReliaAvatar, a real-time, reliable avatar animator equipped with predictive modeling capabilities employing a dual-path architecture. ReliaAvatar operates effectively, with an impressive performance rate of 109 frames per second (fps). Extensive comparative evaluations on widely recognized benchmark datasets demonstrate ReliaAvatar&#39;s superior performance in both standard and low data-quality conditions. The code is available at https://github.com/MIV-XJTU/ReliaAvatar. Keywords: Humans and AI: HAI: Applications Humans and AI: HAI: Human-computer interaction Humans and AI: HAI: Personalization and user modeling Robotics: ROB: Human robot interaction},
  archive   = {C_IJCAI},
  author    = {Bo Qian and Zhenhuan Wei and Jiashuo Li and Xing Wei},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/346},
  month     = {8},
  pages     = {3124-3132},
  title     = {ReliaAvatar: A robust real-time avatar animator with integrated motion prediction},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DBPNet: Dual-branch parallel network with temporal-frequency
fusion for auditory attention detection. <em>IJCAI</em>, 3115–3123. (<a
href="https://doi.org/10.24963/ijcai.2024/345">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Auditory attention decoding (AAD) aims to recognize the attended speaker based on electroencephalography (EEG) signals in multi-talker environments. Most AAD methods only focus on the temporal or frequency domain, but neglect the relationships between these two domains, which results in the inability to simultaneously consider both time-varying and spectral-spatial information. To address this issue, this paper proposes a dual-branch parallel network with temporal-frequency fusion for AAD, named DBPNet, which consists of the temporal attentive branch and the frequency residual branch. Specifically, the temporal attentive branch aims to capture the time-varying features in the EEG time-series signal. The frequency residual branch aims to extract spectral-spatial features of multi-band EEG signals by the residual convolution. Finally, these dual branches are fused to consider both EEG signals time-varying and spectral-spatial features and get classification results. Experimental results show that compared with the best baseline, DBPNet achieves a relative improvement of 20.4% with a 0.1-second decision window for the MM-AAD dataset, but the number of trainable parameters is reduced by about 91 times. Keywords: Humans and AI: HAI: Brain sciences Humans and AI: HAI: Cognitive modeling},
  archive   = {C_IJCAI},
  author    = {Qinke Ni and Hongyu Zhang and Cunhang Fan and Shengbing Pei and Chang Zhou and Zhao Lv},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/345},
  month     = {8},
  pages     = {3115-3123},
  title     = {DBPNet: Dual-branch parallel network with temporal-frequency fusion for auditory attention detection},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Designing behavior-aware AI to improve the human-AI team
performance in AI-assisted decision making. <em>IJCAI</em>, 3106–3114.
(<a href="https://doi.org/10.24963/ijcai.2024/344">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With the rapid development of decision aids that are driven by AI models, the practice of AI-assisted decision making has become increasingly prevalent. To improve the human-AI team performance in decision making, earlier studies mostly focus on enhancing humans&#39; capability in better utilizing a given AI-driven decision aid. In this paper, we tackle this challenge through a complementary approach—we aim to train &quot;behavior-aware AI&quot; by adjusting the AI model underlying the decision aid to account for humans&#39; behavior in adopting AI advice. In particular, as humans are observed to accept AI advice more when their confidence in their own judgement is low, we propose to train AI models with a human-confidence-based instance weighting strategy, instead of solving the standard empirical risk minimization problem. Under an assumed, threshold-based model characterizing when humans will adopt the AI advice, we first derive the optimal instance weighting strategy for training AI models. We then validate the efficacy and robustness of our proposed method in improving the human-AI joint decision making performance through systematic experimentation on synthetic datasets. Finally, via randomized experiments with real human subjects along with their actual behavior in adopting the AI advice, we demonstrate that our method can significantly improve the decision making performance of the human-AI team in practice. Keywords: Humans and AI: HAI: Human-computer interaction Humans and AI: HAI: Human-AI collaboration Humans and AI: HAI: Personalization and user modeling Humans and AI: HAI: Human computation and crowdsourcing},
  archive   = {C_IJCAI},
  author    = {Syed Hasan Amin Mahmood and Zhuoran Lu and Ming Yin},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/344},
  month     = {8},
  pages     = {3106-3114},
  title     = {Designing behavior-aware AI to improve the human-AI team performance in AI-assisted decision making},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LitE-SNN: Designing lightweight and efficient spiking neural
network through spatial-temporal compressive network search and joint
optimization. <em>IJCAI</em>, 3097–3105. (<a
href="https://doi.org/10.24963/ijcai.2024/343">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Spiking Neural Networks (SNNs) mimic the information-processing mechanisms of the human brain and are highly energy-efficient, making them well-suited for low-power edge devices. However, the pursuit of accuracy in current studies leads to large, long-timestep SNNs, conflicting with the resource constraints of these devices. In order to design lightweight and efficient SNNs, we propose a new approach named LitE-SNN that incorporates both spatial and temporal compression into the automated network design process. Spatially, we present a novel Compressive Convolution block (CompConv) to expand the search space to support pruning and mixed-precision quantization. Temporally, we are the first to propose a compressive timestep search to identify the optimal number of timesteps under specific computation cost constraints. Finally, we formulate a joint optimization to simultaneously learn the architecture parameters and spatial-temporal compression strategies to achieve high performance while minimizing memory and computation costs. Experimental results on CIFAR-10, CIFAR-100, and Google Speech Command datasets demonstrate our proposed LitE-SNNs can achieve competitive or even higher accuracy with remarkably smaller model sizes and fewer computation costs. Keywords: Humans and AI: HAI: Cognitive modeling Humans and AI: HAI: Cognitive systems},
  archive   = {C_IJCAI},
  author    = {Qianhui Liu and Jiaqi Yan and Malu Zhang and Gang Pan and Haizhou Li},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/343},
  month     = {8},
  pages     = {3097-3105},
  title     = {LitE-SNN: Designing lightweight and efficient spiking neural network through spatial-temporal compressive network search and joint optimization},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Concept-level causal explanation method for brain function
network classification. <em>IJCAI</em>, 3087–3096. (<a
href="https://doi.org/10.24963/ijcai.2024/342">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Using deep models to classify brain functional networks (BFNs) for the auxiliary diagnosis and treatment of brain diseases has become increasingly popular. However, the unexplainability of deep models has seriously hindered their applications in computer-aided diagnosis. In addition, current explanation methods mostly focus on natural images, which cannot be directly used to explain the deep model for BFN classification. In this paper, we propose a concept-level causal explanation method for BFN classification called CLCEM. First, CLCEM employs the causal learning method to extract concepts that are meaningful to humans from BFNs. Second, it aggregates the same concepts to obtain the contribution of each concept to the model output. Finally, CLCEM adds the contribution of each concept to make a diagnosis. The experimental results show that our CLCEM can not only accurately identify brain regions related to specific brain diseases but also make decisions based on the concepts of these brain regions, which enables humans to understand the decision-making process without performance degradation. Keywords: Humans and AI: HAI: Brain sciences AI Ethics, Trust, Fairness: ETF: Explainability and interpretability Data Mining: DM: Networks Machine Learning: ML: Causality},
  archive   = {C_IJCAI},
  author    = {Jinduo Liu and Feipeng Wang and Junzhong Ji},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/342},
  month     = {8},
  pages     = {3087-3096},
  title     = {Concept-level causal explanation method for brain function network classification},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). VSGT: Variational spatial and gaussian temporal graph models
for EEG-based emotion recognition. <em>IJCAI</em>, 3078–3086. (<a
href="https://doi.org/10.24963/ijcai.2024/341">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Electroencephalogram (EEG), which directly reflects the emotional activity of the brain, has been increasingly utilized for emotion recognition. Most works exploit the spatial and temporal dependencies in EEG to learn emotional feature representations, but they still have two limitations to reach their full potential. First, prior knowledge is rarely used to capture the spatial dependency of brain regions. Second, the cross temporal dependency between consecutive time slices for different brain regions is ignored. To address these limitations, in this paper, we propose Variational Spatial and Gaussian Temporal (VSGT) graph models to investigate the spatial and temporal dependencies for EEG-based emotion recognition. The VSGT has two key components: Variational Spatial Encoder (VSE) and Gaussian Temporal Encoder (GTE). The VSE leverages the upper bound theorem to identify the dynamic spatial dependency based on prior knowledge by the variational Bayesian method. Besides, the GTE exploits the conditional Gaussian graph transform that computes comprehensive temporal dependency between consecutive time slices. Finally, the VSGT utilizes a recurrent structure to calculate the spatial and temporal dependencies for all time slices. Extensive experiments show the superiority of VSGT over state-of-the-art methods on multiple EEG datasets. Keywords: Humans and AI: HAI: Cognitive modeling Humans and AI: HAI: Brain sciences},
  archive   = {C_IJCAI},
  author    = {Chenyu Liu and Xinliang Zhou and Jiaping Xiao and Zhengri Zhu and Liming Zhai and Ziyu Jia and Yang Liu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/341},
  month     = {8},
  pages     = {3078-3086},
  title     = {VSGT: Variational spatial and gaussian temporal graph models for EEG-based emotion recognition},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-level disentangling network for cross-subject emotion
recognition based on multimodal physiological signals. <em>IJCAI</em>,
3069–3077. (<a href="https://doi.org/10.24963/ijcai.2024/340">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Emotion recognition based on multimodal physiological signals is attracting more and more attention. However, how to deal with the consistency and heterogeneity of multimodal physiological signals, as well as individual differences across subjects, pose two significant challenges. In this paper, we propose a Multi-level Disentangling Network named MDNet for cross-subject emotion recognition based on multimodal physiological signals. Specifically, MDNet consists of a modality-level disentangling module and a subject-level disentangling module. The modality-level disentangling module projects multimodal physiological signals into modality-invariant subspace and modality-specific subspace, capturing modality-invariant features and modality-specific features. The subject-level disentangling module separates subject-shared features and subject-private features among different subjects from multimodal data, which facilitates cross-subject emotion recognition. Experiments on two multimodal emotion datasets demonstrate that MDNet outperforms other state-of-the-art baselines. Keywords: Humans and AI: HAI: Applications Machine Learning: ML: Multi-modal learning Data Mining: DM: Mining spatial and/or temporal data},
  archive   = {C_IJCAI},
  author    = {Ziyu Jia and Fengming Zhao and Yuzhe Guo and Hairong Chen and Tianzi Jiang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/340},
  month     = {8},
  pages     = {3069-3077},
  title     = {Multi-level disentangling network for cross-subject emotion recognition based on multimodal physiological signals},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ScreenAI: A vision-language model for UI and infographics
understanding. <em>IJCAI</em>, 3058–3068. (<a
href="https://doi.org/10.24963/ijcai.2024/339">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Screen user interfaces (UIs) and infographics, sharing similar visual language and design principles, play important roles in human communication and human-machine interaction. We introduce ScreenAI, a vision-language model that specializes in UI and infographics understanding. Our model improves upon the PaLI architecture with the flexible patching strategy of pix2struct and is trained on a unique mixture of datasets. At the heart of this mixture is a novel screen annotation task in which the model has to identify the type and location of UI elements. We use these text annotations to describe screens to Large Language Models and automatically generate question-answering (QA), UI navigation, and summarization training datasets at scale. We run ablation studies to demonstrate the impact of these design choices. At only 5B parameters, ScreenAI achieves new state-of-the-art results on UI- and infographics-based tasks (Multipage DocVQA, WebSRC, and MoTIF), and new best-in-class performance on others (ChartQA, DocVQA, and InfographicVQA) compared to models of similar size. Finally, we release three new datasets: one focused on the screen annotation task and two others focused on question answering. Keywords: Humans and AI: HAI: Human-computer interaction Computer Vision: CV: Vision, language and reasoning Machine Learning: ML: Multi-modal learning Machine Learning: ML: Multi-task and transfer learning},
  archive   = {C_IJCAI},
  author    = {Gilles Baechler and Srinivas Sunkara and Maria Wang and Fedir Zubach and Hassan Mansoor and Vincent Etter and Victor Carbune and Jason Lin and Jindong Chen and Abhanshu Sharma},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/339},
  month     = {8},
  pages     = {3058-3068},
  title     = {ScreenAI: A vision-language model for UI and infographics understanding},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A complete landscape of EFX allocations on graphs: Goods,
chores and mixed manna. <em>IJCAI</em>, 3049–3056. (<a
href="https://doi.org/10.24963/ijcai.2024/338">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study envy-free up to any item (EFX) allocations on graphs where vertices and edges represent agents and items respectively. An agent is only interested in items that are incident to her and all other items have zero marginal values to her. Christodoulou et al. first proposed this setting and studied the case of goods. We extend this setting to the case of mixed manna where an item may be liked or disliked by its endpoint agents. In our problem, an agent has an arbitrary valuation over her incident items such that the items she likes have non-negative marginal values to her and those she dislikes have non-positive marginal values. We provide a complete study of the four notions of EFX for mixed manna in the literature, which differ by whether the removed item can have zero marginal value. We prove that an allocation that satisfies the notion of EFX where the virtually-removed item could always have zero marginal value may not exist and determining its existence is NP-complete, while one that satisfies any of the other three notions always exists and can be computed in polynomial time. We also prove that an orientation (i.e., a special allocation where each edge must be allocated to one of its endpoint agents) that satisfies any of the four notions may not exist, and determining its existence is NP-complete. Keywords: Game Theory and Economic Paradigms: GTEP: Fair division Game Theory and Economic Paradigms: GTEP: Computational social choice},
  archive   = {C_IJCAI},
  author    = {Yu Zhou and Tianze Wei and Minming Li and Bo Li},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/338},
  month     = {8},
  pages     = {3049-3056},
  title     = {A complete landscape of EFX allocations on graphs: Goods, chores and mixed manna},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). A strategic analysis of prepayments in financial credit
networks. <em>IJCAI</em>, 3040–3048. (<a
href="https://doi.org/10.24963/ijcai.2024/337">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In financial credit networks, prepayments enable a firm to settle its debt obligations ahead of an agreed-upon due date. Prepayments have a transformative impact on the structure of networks, influencing the financial well-being (utility) of individual firms. This study investigates prepayments from both theoretical and empirical perspectives. We first establish the computational complexity of finding prepayments that maximize welfare, assuming global coordination among firms in the financial network. Subsequently, our focus shifts to understanding the strategic behavior of individual firms in the presence of prepayments. We introduce a prepayment game where firms strategically make prepayments, delineating the existence of pure strategy Nash equilibria and analyzing the price of anarchy (stability) within this game. Recognizing the computational challenges associated with determining Nash equilibria in prepayment games, we use a simulation-based approach, known as empirical game-theoretic analysis (EGTA). Through EGTA, we are able to find Nash equilibria among a carefully-chosen set of heuristic strategies. By scrutinizing the equilibrium behavior of firms, we outline the characteristics of high-performing strategies for strategic prepayments and establish connections between our empirical and theoretical findings. Keywords: Game Theory and Economic Paradigms: GTEP: Noncooperative games Game Theory and Economic Paradigms: GTEP: Auctions and market-based systems},
  archive   = {C_IJCAI},
  author    = {Hao Zhou and Yongzhao Wang and Konstantinos Varsos and Nicholas Bishop and Rahul Savani and Anisoara Calinescu and Michael Wooldridge},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/337},
  month     = {8},
  pages     = {3040-3048},
  title     = {A strategic analysis of prepayments in financial credit networks},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exponential lower bounds on the double oracle algorithm in
zero-sum games. <em>IJCAI</em>, 3032–3039. (<a
href="https://doi.org/10.24963/ijcai.2024/336">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The double oracle algorithm is a popular method of solving games, because it is able to reduce computing equilibria to computing a series of best responses. However, its theoretical properties are not well understood. In this paper, we provide exponential lower bounds on the performance of the double oracle algorithm in both partially-observable stochastic games (POSGs) and extensive-form games (EFGs). Our results depend on what is assumed about the tiebreaking scheme---that is, which meta-Nash equilibrium or best response is chosen, in the event that there are multiple to pick from. In particular, for EFGs, our lower bounds require adversarial tiebreaking, whereas for POSGs, our lower bounds apply regardless of how ties are broken. Keywords: Game Theory and Economic Paradigms: GTEP: Noncooperative games},
  archive   = {C_IJCAI},
  author    = {Brian Hu Zhang and Tuomas Sandholm},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/336},
  month     = {8},
  pages     = {3032-3039},
  title     = {Exponential lower bounds on the double oracle algorithm in zero-sum games},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). How hard is it to impact the impact of your paper?
<em>IJCAI</em>, 3023–3031. (<a
href="https://doi.org/10.24963/ijcai.2024/335">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Consolidation-disruption index (CD index) is a new metric for qualitatively measuring the contribution of a patent or a research paper. We embark on the study of the complexity of the CD index manipulation problems, which model scenarios where scholars seek to enhance the CD indices of their papers through the merging, addition, or deletion of papers. We show that these problems are generally computationally hard, even when restricted to very realistic special cases. Specifically, we analyze how various parameters influence the parameterized complexity of these problems. Keywords: Game Theory and Economic Paradigms: GTEP: Computational social choice},
  archive   = {C_IJCAI},
  author    = {Yongjie Yang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/335},
  month     = {8},
  pages     = {3023-3031},
  title     = {How hard is it to impact the impact of your paper?},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improved approximation of weighted MMS fairness for
indivisible chores. <em>IJCAI</em>, 3014–3022. (<a
href="https://doi.org/10.24963/ijcai.2024/334">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study how to fairly allocate a set of indivisible chores among n agents who may have different weights corresponding to their involvement in completing these chores. We found that some of the existing fairness notions may place agents with lower weights at a disadvantage, which motivates us to explore weighted maximin share fairness (WMMS). While it is known that a WMMS allocation may not exist, no non-trivial approximation has been discovered thus far. In this paper, we first design a simple sequential picking algorithm that solely relies on the agents’ ordinal rankings of the items, which achieves an approximation ratio of O(log n). Then, for the case involving two agents, we improve the approximation ratio to (√3+1)/2 ≈1.366, and prove that it is optimal. We also consider an online setting when the items arrive one after another and design an O(√n)-competitive online algorithm given the valuations are normalized Keywords: Game Theory and Economic Paradigms: GTEP: Fair division},
  archive   = {C_IJCAI},
  author    = {Fangxiao Wang and Bo Li and Pinyan Lu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/334},
  month     = {8},
  pages     = {3014-3022},
  title     = {Improved approximation of weighted MMS fairness for indivisible chores},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mechanisms that play a game, not toss a coin.
<em>IJCAI</em>, 3005–3013. (<a
href="https://doi.org/10.24963/ijcai.2024/333">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Randomized mechanisms can have good normative properties compared to their deterministic counter-parts. However, randomized mechanisms are problematic in several ways such as in their verifiability. We propose here to de-randomize such mechanisms by having agents play a game instead of tossing a coin. The game is designed so agents play randomly, and this play injects “randomness” into the mechanism. Surprisingly this de-randomization retains many of the good normative properties of the original randomized mechanism but gives a mechanism that is deterministic and easy, for instance, to audit. We consider three general purpose methods to de-randomize mechanisms, and apply these to six different domains: voting, facility location, task allocation, school choice, peer selection, and resource allocation. We propose a number of novel de-randomized mechanisms for these six domains with good normative properties (such as equilibria in which agents sincerely report preferences over the original problem). In one domain, we additionally show that a new and desirable normative property emerges as a result of de-randomization.property emerges as a result of de-randomization. Keywords: Game Theory and Economic Paradigms: GTEP: Mechanism design Agent-based and Multi-agent Systems: MAS: Resource allocation Game Theory and Economic Paradigms: GTEP: Computational social choice Game Theory and Economic Paradigms: GTEP: Fair division},
  archive   = {C_IJCAI},
  author    = {Toby Walsh},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/333},
  month     = {8},
  pages     = {3005-3013},
  title     = {Mechanisms that play a game, not toss a coin},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Imperfect-recall games: Equilibrium concepts and their
complexity. <em>IJCAI</em>, 2994–3004. (<a
href="https://doi.org/10.24963/ijcai.2024/332">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We investigate optimal decision making under imperfect recall, that is, when an agent forgets information it once held before. An example is the absentminded driver game, as well as team games in which the members have limited communication capabilities. In the framework of extensive-form games with imperfect recall, we analyze the computational complexities of finding equilibria in multiplayer settings across three different solution concepts: Nash, multiselves based on evidential decision theory (EDT), and multiselves based on causal decision theory (CDT). We are interested in both exact and approximate solution computation. As special cases, we consider (1) single-player games, (2) two-player zero-sum games and relationships to maximin values, and (3) games without exogenous stochasticity (chance nodes). We relate these problems to the complexity classes PPAD, PLS, Σ_2^P, ∃R, and ∃∀R. Keywords: Game Theory and Economic Paradigms: GTEP: Noncooperative games},
  archive   = {C_IJCAI},
  author    = {Emanuel Tewolde and Brian Hu Zhang and Caspar Oesterheld and Manolis Zampetakis and Tuomas Sandholm and Paul Goldberg and Vincent Conitzer},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/332},
  month     = {8},
  pages     = {2994-3004},
  title     = {Imperfect-recall games: Equilibrium concepts and their complexity},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Game transformations that preserve nash equilibria or
best-response sets. <em>IJCAI</em>, 2984–2993. (<a
href="https://doi.org/10.24963/ijcai.2024/331">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we investigate under which conditions normal-form games are (guaranteed to be) strategically equivalent. First, we show for N -player games (N &gt;= 3) that (A) it is NP-hard to decide whether a given strategy is a best response to some strategy profile of the opponents, and that (B) it is co-NP-hard to decide whether two games have the same best-response sets. Combining that with known results from the literature, we move our attention to equivalence-preserving game transformations. It is a widely used fact that a positive affine (linear) transformation of the utility payoffs neither changes the best-response sets nor the Nash equilibrium set. We investigate which other game transformations also possess either of the following two properties when being applied to an arbitrary N-player game (N &gt;= 2): (i) The Nash equilibrium set stays the same; (ii) The best-response sets stay the same. For game transformations that operate player-wise and strategy-wise, we prove that (i) implies (ii) and that transformations with property (ii) must be positive affine. The resulting equivalence chain highlights the special status of positive affine transformations among all the transformation procedures that preserve key game-theoretic characteristics. Keywords: Game Theory and Economic Paradigms: GTEP: Noncooperative games Game Theory and Economic Paradigms: General},
  archive   = {C_IJCAI},
  author    = {Emanuel Tewolde and Vincent Conitzer},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/331},
  month     = {8},
  pages     = {2984-2993},
  title     = {Game transformations that preserve nash equilibria or best-response sets},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enabling sustainable freight forwarding network via
collaborative games. <em>IJCAI</em>, 2976–2983. (<a
href="https://doi.org/10.24963/ijcai.2024/330">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Freight forwarding plays a crucial role in facilitating global trade and logistics. However, as the freight forwarding market is extremely fragmented, freight forwarders often face the issue of not being able to fill the available shipping capacity. This recurrent issue motivates the creation of various freight forwarding networks that aim at exchanging capacities and demands so that the resource utilization of individual freight forwarders can be maximized. In this paper, we focus on how to design such a collaborative network based on collaborative game theory, with the Shapley value representing a fair scheme for profit sharing. Noting that the exact computation of Shapley values is intractable for large-scale real-world scenarios, we incorporate the observation that collaboration among two forwarders is only possible if their service routes and demands overlap. This leads to a new class of collaborative games called the Locally Collaborative Games (LCGs), where agents can only collaborate with their neighbors. We propose an efficient approach to compute Shapley values for LCGs, and numerically demonstrate that our approach significantly outperforms the state-of-the-art approach for a wide variety of network structures. Keywords: Game Theory and Economic Paradigms: GTEP: Cooperative games Multidisciplinary Topics and Applications: MTA: Transportation Agent-based and Multi-agent Systems: MAS: Applications},
  archive   = {C_IJCAI},
  author    = {Pang-Jin Tan and Shih-Fen Cheng and Richard Chen},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/330},
  month     = {8},
  pages     = {2976-2983},
  title     = {Enabling sustainable freight forwarding network via collaborative games},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Nonparametric detection of gerrymandering in multiparty
plurality elections. <em>IJCAI</em>, 2967–2975. (<a
href="https://doi.org/10.24963/ijcai.2024/329">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Partisan gerrymandering, i.e., manipulation of electoral district boundaries for political advantage, is one of the major challenges to election integrity in modern day democracies. Yet most of the existing methods for detecting partisan gerrymandering are narrowly tailored toward fully contested two-party elections, and fail if there are more parties or if the number of candidates per district varies. We propose a new method, applying nonparametric statistical learning to detect anomalies in the relation between (aggregate) votes and (aggregate) seats. Unlike in most of the existing methods, we propose to learn the standard of fairness in districting from empirical data rather than assume one a priori. Finally, we test the proposed methods against experimental data as well as real-life data from 17 countries employing the plurality (FPTP) system. Keywords: Game Theory and Economic Paradigms: GTEP: Computational social choice Multidisciplinary Topics and Applications: MTA: Social sciences},
  archive   = {C_IJCAI},
  author    = {Dariusz Stolicki and Wojciech Słomczyński and Stanisław Szufa},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/329},
  month     = {8},
  pages     = {2967-2975},
  title     = {Nonparametric detection of gerrymandering in multiparty plurality elections},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Computational complexity of verifying the group no-show
paradox. <em>IJCAI</em>, 2958–2966. (<a
href="https://doi.org/10.24963/ijcai.2024/328">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The (group) no-show paradox refers to the undesirable situation where a group of agents have incentive to abstain from voting to make the winner more favorable to them. To understand whether it is a critical concern in practice, in this paper, we take a computational approach by examining the computational complexity of verifying whether the group no-show paradox exists given agents&#39; preferences and the voting rule. We prove that, unfortunately, the verification problem is NP-hard to compute for some commonly studied voting rules, i.e., Copeland, maximin, single transferable vote, and all Condorcetified positional scoring rules such as Black&#39;s rule. We propose integer linear programming-based algorithms and a search-based algorithm for the verification problem for different voting rules. Experimental results on synthetic data illustrate that the former is efficient when the number of unique rankings in a profile is not too high, and the latter is efficient for a small number of agents. With the help of these algorithms, we observe that group no-show paradoxes rarely occur in real-world data. Keywords: Game Theory and Economic Paradigms: GTEP: Computational social choice},
  archive   = {C_IJCAI},
  author    = {Farhad Mohsin and Qishen Han and Sikai Ruan and Pin-Yu Chen and Francesca Rossi and Lirong Xia},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/328},
  month     = {8},
  pages     = {2958-2966},
  title     = {Computational complexity of verifying the group no-show paradox},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). What is best for students, numerical scores or letter
grades? <em>IJCAI</em>, 2949–2957. (<a
href="https://doi.org/10.24963/ijcai.2024/327">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study letter grading schemes, which are routinely employed for evaluating student performance. Typically, a numerical score obtained via one or more evaluations is converted into a letter grade (e.g., A+, B-, etc.) by associating a disjoint interval of numerical scores to each letter grade. We propose the first model for studying the (de)motivational effects of such grading on the students and, consequently, on their performance in future evaluations. We use the model to compare uniform letter grading schemes, in which the range of scores is divided into equal-length parts that are mapped to the letter grades, to numerical scoring, in which the score is not converted to any letter grade (equivalently, every score is its own letter grade). Theoretically, we identify realistic conditions under which numerical scoring is better than any uniform letter grading scheme. Our experiments confirm that this holds under even weaker conditions, but also find cases where the converse occurs. Keywords: Game Theory and Economic Paradigms: GTEP: Computational social choice},
  archive   = {C_IJCAI},
  author    = {Evi Micha and Shreyas Sekar and Nisarg Shah},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/327},
  month     = {8},
  pages     = {2949-2957},
  title     = {What is best for students, numerical scores or letter grades?},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Toward completing the picture of control in schulze and
ranked pairs elections. <em>IJCAI</em>, 2940–2948. (<a
href="https://doi.org/10.24963/ijcai.2024/326">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Both Schulze and ranked pairs are voting rules that satisfy many natural, desirable axioms. Many standard types of electoral control (with a chair seeking to change the outcome of an election by interfering with the election structure) have already been studied. However, for control by replacing candidates or voters and for (exact) multimode control that combines multiple standard attacks, many questions remain open. We solve a number of these open cases for Schulze and ranked pairs. In addition, we fix a flaw in the reduction of Menton and Singh showing that Schulze is resistant to constructive control by deleting candidates and re-establish a vulnerability result for destructive control by deleting candidates. In some of our proofs, we study variants of s-t vertex cuts in graphs that are related to our control problems. Keywords: Game Theory and Economic Paradigms: GTEP: Computational social choice},
  archive   = {C_IJCAI},
  author    = {Cynthia Maushagen and David Niclaus and Paul Nüsken and Jörg Rothe and Tessa Seeger},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/326},
  month     = {8},
  pages     = {2940-2948},
  title     = {Toward completing the picture of control in schulze and ranked pairs elections},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimizing prosumer policies in periodic double auctions
inspired by equilibrium analysis. <em>IJCAI</em>, 2931–2939. (<a
href="https://doi.org/10.24963/ijcai.2024/325">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider a periodic double auction (PDA) wherein the main participants are wholesale suppliers and brokers representing retailers. The suppliers are represented by a composite supply curve and the brokers are represented by individual bids. Additionally, the brokers can also participate in small-scale selling by placing individual asks; hence, they act as prosumers. Specifically, in a PDA, the prosumers who are net buyers have multiple opportunities to buy or sell multiple units of a commodity with the aim of minimising the cost of buying across multiple rounds of the PDA. Formulating optimal bidding strategies for such a PDA setting involves planning across current and future rounds while taking into account the bidding strategies of other agents. In this work, we propose Markov perfect Nash equilibrium (MPNE) policies for a setup where multiple prosumers with knowledge of the composite supply curve compete to procure commodities. Thereafter, the MPNE policies are used to develop an algorithm called MPNE-BBS for the case wherein the prosumers need to re-construct an approximate composite supply curve using past auction information. The efficacy of the proposed algorithm is demonstrated on the PowerTAC wholesale market simulator against several baselines and state-of-the-art bidding policies. Keywords: Game Theory and Economic Paradigms: GTEP: Auctions and market-based systems Agent-based and Multi-agent Systems: MAS: Agent theories and models Agent-based and Multi-agent Systems: MAS: Agent-based simulation and emergence Game Theory and Economic Paradigms: GTEP: Noncooperative games},
  archive   = {C_IJCAI},
  author    = {Bharat Manvi and Sanjay Chandlekar and Easwar Subramanian},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/325},
  month     = {8},
  pages     = {2931-2939},
  title     = {Optimizing prosumer policies in periodic double auctions inspired by equilibrium analysis},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Ordinal maximin guarantees for group fair division.
<em>IJCAI</em>, 2922–2930. (<a
href="https://doi.org/10.24963/ijcai.2024/324">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We investigate fairness in the allocation of indivisible items among groups of agents using the notion of maximin share (MMS). While previous work has shown that no nontrivial multiplicative MMS approximation can be guaranteed in this setting for general group sizes, we demonstrate that ordinal relaxations are much more useful. For example, we show that if n agents are distributed equally across g groups, there exists a 1-out-of-k MMS allocation for k = O(g log(n/g)), while if all but a constant number of agents are in the same group, we obtain k = O(log n / log log n). We also establish the tightness of these bounds and provide non-asymptotic results for the case of two groups. Keywords: Game Theory and Economic Paradigms: GTEP: Fair division Game Theory and Economic Paradigms: GTEP: Computational social choice},
  archive   = {C_IJCAI},
  author    = {Pasin Manurangsi and Warut Suksompong},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/324},
  month     = {8},
  pages     = {2922-2930},
  title     = {Ordinal maximin guarantees for group fair division},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tackling stackelberg network interdiction against a
boundedly rational adversary. <em>IJCAI</em>, 2913–2921. (<a
href="https://doi.org/10.24963/ijcai.2024/323">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This work studies Stackelberg network interdiction games --- an important class of games in which a defender first allocates (randomized) defense resources to a set of critical nodes on a graph while an adversary chooses its path to attack these nodes accordingly. We consider a boundedly rational adversary in which the adversary&#39;s response model is based on a dynamic form of classic logit-based (quantal response) discrete choice models. The resulting optimization is non-convex and additionally, involves complex terms that sum over exponentially many paths. We tackle these computational challenges by presenting new efficient algorithms with solution guarantees. First, we present a near optimal solution method based on path sampling, piece-wise linear approximation and mixed-integer linear programming (MILP) reformulation. Second, we explore a dynamic programming based method, addressing the exponentially-many-path challenge. We then show that the gradient of the non-convex objective can also be computed in polynomial time, which allows us to use a gradient-based method to solve the problem efficiently. Experiments based on instances of different sizes demonstrate the efficiency of our approach in achieving near-optimal solutions. Keywords: Game Theory and Economic Paradigms: GTEP: Noncooperative games Constraint Satisfaction and Optimization: CSO: Mixed discrete and continuous optimization},
  archive   = {C_IJCAI},
  author    = {Tien Mai and Avinandan Bose and Arunesh Sinha and Thanh Nguyen and Ayushman Kumar singh},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/323},
  month     = {8},
  pages     = {2913-2921},
  title     = {Tackling stackelberg network interdiction against a boundedly rational adversary},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal auction design with user coupons in advertising
systems. <em>IJCAI</em>, 2904–2912. (<a
href="https://doi.org/10.24963/ijcai.2024/322">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Online advertising is a major revenue source for most Internet companies. The advertising opportunities are usually sold to advertisers through auctions that take into account the bids of the advertisers and the click-through rates (CTRs) and the conversion rates (CVRs) of the users. Standard auction design theory perceives both the CTRs and the CVRs as constants. We consider a new auction mechanism that offers coupons to users when displaying the ads. Such coupons allow the user to buy the advertisers&#39; products or services at a lower price, which increases both the CTRs and the CVRs of the ads. In this paper, we formulate the problem mathematically and perform a systematic analysis. We characterize the set of individually rational and incentive compatible mechanisms in our setting. Based on the characterization, we identify the optimal strategy of offering coupons that maximizes the platform&#39;s expected revenue. We also conduct extensive experiments on both synthetic data and industrial data. Our experiment results show that our mechanism significantly improves both the revenue and welfare of the platform, thereby creating a win-win situation for all parties including the platform, the advertisers, and the user. Keywords: Game Theory and Economic Paradigms: GTEP: Auctions and market-based systems Game Theory and Economic Paradigms: GTEP: Mechanism design Game Theory and Economic Paradigms: GTEP: Noncooperative games},
  archive   = {C_IJCAI},
  author    = {Xiaodong Liu and Zhikang Fan and Yiming Ding and Yuan Guo and Lihua Zhang and Changcheng Li and Dongying Kong and Han Li and Weiran Shen},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/322},
  month     = {8},
  pages     = {2904-2912},
  title     = {Optimal auction design with user coupons in advertising systems},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Combinatorial games with incomplete information.
<em>IJCAI</em>, 2895–2903. (<a
href="https://doi.org/10.24963/ijcai.2024/321">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Games with incomplete information model multi-agent interaction in which players do not have common knowledge of the game they play. We propose a minimal generalisation of combinatorial games to incorporate incomplete information, called combinatorial game with incomplete information (CGII). The most important feature of CGIIs is that all actions are public, which allows better visualisation of each player&#39;s knowledge and incomplete information. To further motivate the study of this new formalism, we show that computing optimal strategies for CGIIs has the same computational complexity as for general extensive-form games. Keywords: Game Theory and Economic Paradigms: GTEP: Noncooperative games Uncertainty in AI: UAI: Sequential decision making},
  archive   = {C_IJCAI},
  author    = {Junkang Li and Bruno Zanuttini and Véronique Ventos},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/321},
  month     = {8},
  pages     = {2895-2903},
  title     = {Combinatorial games with incomplete information},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Vulnerabilities of single-round incentive compatibility in
auto-bidding: Theory and evidence from ROI-constrained online
advertising markets. <em>IJCAI</em>, 2886–2894. (<a
href="https://doi.org/10.24963/ijcai.2024/320">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Most of the work in the auction design literature assumes that bidders behave rationally based on the information available for every individual auction, and the revelation principle enables designers to restrict their efforts to incentive compatible (IC) mechanisms. However, in today’s online advertising markets, one of the most important real-life applications of auction design, the data and computational power required to bid optimally are only available to the platform, and an advertiser can only participate by setting performance objectives and constraints for its proxy auto-bidder provided by the platform. The prevalence of auto-bidding necessitates a review of auction theory. In this paper, we examine the markets through the lens of ROI-constrained value-maximizing campaigns. We show that second price auction exhibits many undesirable properties (computational hardness, non-monotonicity, instability of bidders’ utilities, and interference in A/B testing) and loses its dominant theoretical advantages in single-item scenarios. In addition, we make it clear how IC and its runner-up-winner interdependence contribute to each property. We hope that our work could bring new perspectives to the community and benefit practitioners to attain a better grasp of real-world markets. Keywords: Game Theory and Economic Paradigms: GTEP: Auctions and market-based systems Multidisciplinary Topics and Applications: MTA: Economics},
  archive   = {C_IJCAI},
  author    = {Juncheng Li and Pingzhong Tang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/320},
  month     = {8},
  pages     = {2886-2894},
  title     = {Vulnerabilities of single-round incentive compatibility in auto-bidding: Theory and evidence from ROI-constrained online advertising markets},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Public event scheduling with busy agents. <em>IJCAI</em>,
2877–2885. (<a href="https://doi.org/10.24963/ijcai.2024/319">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study a public event scheduling problem, where multiple public events are scheduled to coordinate the availability of multiple agents. The availability of each agent is determined by solving a separate flexible interval job scheduling problem, where the jobs are required to be preemptively processed. The agents want to attend as many events as possible, and their agreements are considered to be the total length of time during which they can attend these events. The goal is to find a schedule for events as well as the job schedule for each agent such that the total agreement is maximized. We first show that the problem is NP-hard, and then prove that a simple greedy algorithm achieves 1/2-approximation when the whole timeline is polynomially bounded. Our method also implies a (1-1/e)-approximate algorithm for this case. Subsequently, for the general timeline case, we present an algorithmic framework that extends a 1/alpha-approximate algorithm for the one-event instance to the general case that achieves 1/(alpha+1)-approximation. Finally, we give a polynomial time algorithm that solves the one-event instance, and this implies a 1/2-approximate algorithm for the general case. Keywords: Game Theory and Economic Paradigms: GTEP: Computational social choice Agent-based and Multi-agent Systems: MAS: Resource allocation Planning and Scheduling: PS: Scheduling},
  archive   = {C_IJCAI},
  author    = {Bo Li and Lijun Li and Minming Li and Ruilong Zhang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/319},
  month     = {8},
  pages     = {2877-2885},
  title     = {Public event scheduling with busy agents},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Allocating mixed goods with customized fairness and
indivisibility ratio. <em>IJCAI</em>, 2868–2876. (<a
href="https://doi.org/10.24963/ijcai.2024/318">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider the problem of fairly allocating a combination of divisible and indivisible goods. While fairness criteria like envy-freeness (EF) and proportionality (PROP) can always be achieved for divisible goods, only their relaxed versions, such as the “up to one” relaxations EF1 and PROP1, can be satisfied when the goods are indivisible. The “up to one” relaxations require the fairness conditions to be satisfied provided that one good can be completely eliminated or added in the comparison. In this work, we bridge the gap between the two extremes and propose “up to a fraction” relaxations for the allocation of mixed divisible and indivisible goods. The fraction is determined based on the proportion of indivisible goods, which we call the indivisibility ratio. The new concepts also introduce asymmetric conditions that are customized for individuals with varying indivisibility ratios. We provide both upper and lower bounds on the fractions of the modified item in order to satisfy the fairness criterion. Our results are tight up to a constant for EF and asymptotically tight for PROP. Keywords: Game Theory and Economic Paradigms: GTEP: Fair division},
  archive   = {C_IJCAI},
  author    = {Bo Li and Zihao Li and Shengxin Liu and Zekai Wu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/318},
  month     = {8},
  pages     = {2868-2876},
  title     = {Allocating mixed goods with customized fairness and indivisibility ratio},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Polynomial time presolve algorithms for rotation-based
models solving the robust stable matching problem. <em>IJCAI</em>,
2860–2867. (<a href="https://doi.org/10.24963/ijcai.2024/317">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Robust Stable Matching (RSM) problem involves finding a stable matching that allows getting another stable matching within a minimum number of changes when a pair becomes forbidden. It has been shown that such a problem is NP-Hard. In this paper, we enrich the mathematical model for the RSM problem based on new theoretical properties. We derive from these properties new polynomial time pre-solving algorithms which both reduce the search space and speed up the exploration. We also extend our results to the instances of the Many-to-Many problem and give its corresponding constraint programming (CP) model. We show how the use of our algorithms improve the state-of-the-art results and make it possible to obtain proofs of optimality on large instances via the CP model. Keywords: Game Theory and Economic Paradigms: GTEP: Computational social choice Knowledge Representation and Reasoning: KRR: Preference modelling and preference-based reasoning AI Ethics, Trust, Fairness: ETF: Safety and robustness Constraint Satisfaction and Optimization: CSO: Modeling},
  archive   = {C_IJCAI},
  author    = {Sulian Le Bozec-Chiffoleau and Charles Prud&#39;homme and Gilles Simonin},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/317},
  month     = {8},
  pages     = {2860-2867},
  title     = {Polynomial time presolve algorithms for rotation-based models solving the robust stable matching problem},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The distortion of threshold approval matching.
<em>IJCAI</em>, 2851–2859. (<a
href="https://doi.org/10.24963/ijcai.2024/316">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study matching settings in which a set of agents have private utilities over a set of items. Each agent reports a partition of the items into approval sets of different threshold utility levels. Given this limited information on input, the goal is to compute an assignment of the items to the agents (subject to cardinality constraints depending on the application) that (approximately) maximizes the social welfare (the total utility of the agents for their assigned items). We first consider the well-known, simple one-sided matching problem in which each of a set of agents is to be assigned exactly one item. We show tight bounds on distortion of deterministic and randomized matching algorithms that are functions of the number of threshold utility levels. We further show that our distortion bounds extend to a more general setting in which there are multiple copies of the items, each agent can be assigned a number of items (even copies of the same one) up to a capacity, and the utility of an agent for an item depends on the number of its copies that the agent is given. Keywords: Game Theory and Economic Paradigms: GTEP: Computational social choice Game Theory and Economic Paradigms: GTEP: Mechanism design},
  archive   = {C_IJCAI},
  author    = {Mohamad Latifian and Alexandros A. Voudouris},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/316},
  month     = {8},
  pages     = {2851-2859},
  title     = {The distortion of threshold approval matching},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Equilibria in two-stage facility location with atomic
clients. <em>IJCAI</em>, 2842–2850. (<a
href="https://doi.org/10.24963/ijcai.2024/315">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider competitive facility location as a two-stage multi-agent system with two types of clients. For a given host graph with weighted clients on the vertices, first facility agents strategically select vertices for opening their facilities. Then, the clients strategically select which of the opened facilities in their neighborhood to patronize. Facilities want to attract as much client weight as possible, clients want to minimize congestion on the chosen facility. All recently studied versions of this model assume that clients can split their weight strategically. We consider clients with unsplittable weights, but allow mixed strategies. So clients may randomize over which facility to patronize. Besides modeling a natural client behavior, this subtle change yields drastic changes, e.g., for a given facility placement, qualitatively different client equilibria are possible. As our main result, we show that pure subgame perfect equilibria always exist if all client weights are identical. For this, we use a novel potential function argument, employing a hierarchical classification of the clients and sophisticated rounding in each step. In contrast, for non-identical clients, we show that deciding the existence of even approximately stable states is computationally intractable. On the positive side, we give a tight bound of 2 on the price of anarchy which implies high social welfare of equilibria, if they exist. Keywords: Game Theory and Economic Paradigms: GTEP: Noncooperative games},
  archive   = {C_IJCAI},
  author    = {Simon Krogmann and Pascal Lenzner and Alexander Skopalik and Marc Uetz and Marnix C. Vos},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/315},
  month     = {8},
  pages     = {2842-2850},
  title     = {Equilibria in two-stage facility location with atomic clients},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sampling winners in ranked choice voting. <em>IJCAI</em>,
2834–2841. (<a href="https://doi.org/10.24963/ijcai.2024/314">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Ranked choice voting (RCV) is a voting rule that iteratively eliminates least-popular candidates until there is a single winner with a majority of all remaining votes. In this work, we explore three central questions about predicting the outcome of RCV on an election given a uniform sample of votes. First, in theory, how poorly can RCV sampling predict RCV outcomes? Second, can we use insights from the recently-proposed map of elections to better predict RCV outcomes? Third, is RCV the best rule to use on a sample to predict the outcome of RCV in real-world elections? We find that although RCV can do quite poorly in the worst case and it may be better to use other rules to predict RCV winners on synthetic data from the map of elections, RCV generally predicts itself well on real-world data, further contributing to its appeal as a theoretically-flawed but practicable voting process. We further supplement our work by exploring the effect of margin of victory (MoV) on sampling accuracy. Keywords: Game Theory and Economic Paradigms: GTEP: Computational social choice},
  archive   = {C_IJCAI},
  author    = {Matthew Iceland and Anson Kahng and Joseph Saber},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/314},
  month     = {8},
  pages     = {2834-2841},
  title     = {Sampling winners in ranked choice voting},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fair distribution of delivery orders. <em>IJCAI</em>,
2825–2833. (<a href="https://doi.org/10.24963/ijcai.2024/313">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We initiate the study of fair distribution of delivery tasks among a set of agents wherein delivery jobs are placed along the vertices of a graph. Our goal is to fairly distribute delivery costs (modeled as a submodular function) among a fixed set of agents while satisfying some desirable notions of economic efficiency. We adopt well-established fairness concepts—such as envy-freeness up to one item (EF1) and minimax share (MMS)—to our setting and show that fairness is often incompatible with the efficiency notion of social optimality. Yet, we characterize instances that admit fair and socially optimal solutions by exploiting graph structures. We further show that achieving fairness along with Pareto optimality is computationally intractable. Nonetheless, we design an XP algorithm (parameterized by the number of agents) for finding MMS and Pareto optimal solutions on every tree instance, and show that the same algorithm can be modified to find efficient solutions along with EF1, when such solutions exist. We complement these results by theoretically and experimentally analyzing the price of fairness. Keywords: Game Theory and Economic Paradigms: GTEP: Fair division Game Theory and Economic Paradigms: GTEP: Computational social choice},
  archive   = {C_IJCAI},
  author    = {Hadi Hosseini and Shivika Narang and Tomasz Wąs},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/313},
  month     = {8},
  pages     = {2825-2833},
  title     = {Fair distribution of delivery orders},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Determining winners in elections with absent votes.
<em>IJCAI</em>, 2816–2824. (<a
href="https://doi.org/10.24963/ijcai.2024/312">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {An important question in elections is determining whether a candidate can be a winner when some votes are absent. We study this determining winner with absent votes (WAV) problem with elections that take top-truncated ballots. We show that the WAV problem is NP-complete for single transferable vote, Maximin, and Copeland, and propose a special case of positional scoring rule such that the problem can be computed in polynomial time. Our results for top-truncated rankings differ from the results in full rankings as their hardness results still hold when the number of candidates or the number of missing votes are bounded, while we show that the problem can be solved in polynomial time in either case. Keywords: Game Theory and Economic Paradigms: GTEP: Computational social choice},
  archive   = {C_IJCAI},
  author    = {Qishen Han and Amelie Marian and Lirong Xia},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/312},
  month     = {8},
  pages     = {2816-2824},
  title     = {Determining winners in elections with absent votes},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Getting more by knowing less: Bayesian incentive compatible
mechanisms for fair division. <em>IJCAI</em>, 2807–2815. (<a
href="https://doi.org/10.24963/ijcai.2024/311">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study fair resource allocation with strategic agents. It is well-known that, across multiple fundamental problems in this domain, truthfulness and fairness are incompatible. For example, when allocating indivisible goods, no truthful and deterministic mechanism can guarantee envy-freeness up to one item (EF1), even for two agents with additive valuations. Or, in cake-cutting, no truthful and deterministic mechanism always outputs a proportional allocation, even for two agents with piecewise constant valuations. Our work stems from the observation that, in the context of fair division, truthfulness is used as a synonym for Dominant Strategy Incentive Compatibility (DSIC), requiring that an agent prefers reporting the truth, no matter what other agents report. In this paper, we instead focus on Bayesian Incentive Compatible (BIC) mechanisms, requiring that agents are better off reporting the truth in expectation over other agents&#39; reports. We prove that, when agents know a bit less about each other, a lot more is possible: using BIC mechanisms we can achieve fairness notions that are unattainable by DSIC mechanisms in both the fundamental problems of allocation of indivisible goods and cake-cutting. We prove that this is the case even for an arbitrary number of agents, as long as the agents&#39; priors about each others&#39; types satisfy a neutrality condition. Notably, for the case of indivisible goods, we significantly strengthen the state-of-the-art negative result for efficient DSIC mechanisms, while also highlighting the limitations of BIC mechanisms, by showing that a very general class of welfare objectives is incompatible with Bayesian Incentive Compatibility. Combined, these results give a near-complete picture of the power and limitations of BIC and DSIC mechanisms for the problem of allocating indivisible goods. Keywords: Game Theory and Economic Paradigms: GTEP: Fair division Game Theory and Economic Paradigms: GTEP: Mechanism design},
  archive   = {C_IJCAI},
  author    = {Vasilis Gkatzelis and Alexandros Psomas and Xizhi Tan and Paritosh Verma},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/311},
  month     = {8},
  pages     = {2807-2815},
  title     = {Getting more by knowing less: Bayesian incentive compatible mechanisms for fair division},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Weighted EF1 and PO allocations with few types of agents or
chores. <em>IJCAI</em>, 2799–2806. (<a
href="https://doi.org/10.24963/ijcai.2024/310">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We investigate the existence of fair and efficient allocations of indivisible chores to asymmetric agents who have unequal entitlements or weights. We consider the fairness notion of weighted envy-freeness up to one chore (wEF1) and the efficiency notion of Pareto-optimality (PO). The existence of EF1 and PO allocations of chores to symmetric agents is a major open problem in discrete fair division, and positive results are known only for certain structured instances. In this paper, we study this problem for a more general setting of asymmetric agents and show that an allocation that is wEF1 and PO exists and can be computed in polynomial time for instances with: - Three types of agents where agents with the same type have identical preferences but can have different weights. - Two types of chores For symmetric agents, our results establish that EF1 and PO allocations exist for three types of agents and also generalize known results for three agents, two types of agents, and two types of chores. Our algorithms use a weighted picking sequence algorithm as a subroutine; we expect this idea and our analysis to be of independent interest. Keywords: Game Theory and Economic Paradigms: GTEP: Fair division Agent-based and Multi-agent Systems: MAS: Resource allocation},
  archive   = {C_IJCAI},
  author    = {Jugal Garg and Aniket Murhekar and John Qin},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/310},
  month     = {8},
  pages     = {2799-2806},
  title     = {Weighted EF1 and PO allocations with few types of agents or chores},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Metric distortion with elicited pairwise comparisons.
<em>IJCAI</em>, 2791–2798. (<a
href="https://doi.org/10.24963/ijcai.2024/309">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In many social choice applications, information about individuals&#39; preferences can only be elicited using a limited number of pairwise comparisons. In these cases, the task is twofold: we must first choose the queries, and then second, we must aggregate the responses to choose an outcome. We study the problem of designing algorithms for this setting. To compare the effectiveness of different outcomes, we use the metric distortion framework. In addition, we consider various constraints on the query algorithms, namely, placing restrictions on how the choice of the next query may depend on previous answers. Our main contributions are nearly optimal algorithms for all settings considered. Keywords: Game Theory and Economic Paradigms: GTEP: Computational social choice},
  archive   = {C_IJCAI},
  author    = {Soroush Ebadian and Daniel Halpern and Evi Micha},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/309},
  month     = {8},
  pages     = {2791-2798},
  title     = {Metric distortion with elicited pairwise comparisons},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Individual rationality in topological distance games is
surprisingly hard. <em>IJCAI</em>, 2782–2790. (<a
href="https://doi.org/10.24963/ijcai.2024/308">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the recently introduced topological distance games, strategic agents need to be assigned to a subset of vertices of a topology. In the assignment, the utility of an agent depends on both the agent&#39;s inherent utilities for other agents and its distance from them on the topology. We study the computational complexity of finding individually-rational outcomes; this notion is widely assumed to be the very minimal stability requirement and requires that the utility of every agent in a solution is non-negative. We perform a comprehensive study of the problem&#39;s complexity, and we prove that even in very basic cases, deciding whether an individually-rational solution exists is intractable. To reach at least some tractability, one needs to combine multiple restrictions of the input instance, including the number of agents and the topology and the influence of distant agents on the utility. Keywords: Game Theory and Economic Paradigms: GTEP: Computational social choice},
  archive   = {C_IJCAI},
  author    = {Argyrios Deligkas and Eduard Eiben and Dušan Knop and Šimon Schierreich},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/308},
  month     = {8},
  pages     = {2782-2790},
  title     = {Individual rationality in topological distance games is surprisingly hard},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Truthful interval covering. <em>IJCAI</em>, 2774–2781. (<a
href="https://doi.org/10.24963/ijcai.2024/307">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We initiate the study of a novel problem in mechanism design without money, which we term Truthful Interval Covering (TIC). An instance of TIC consists of a set of agents each associated with an individual interval on a line, and the objective is to decide where to place a covering interval to minimize the total social or egalitarian cost of the agents, which is determined by the intersection of this interval with their individual ones. This fundamental problem can model situations of provisioning a public good, such as the use of power generators to prevent or mitigate load shedding in developing countries. In the strategic version of the problem, the agents wish to minimize their individual costs, and might misreport the position and/or length of their intervals to achieve that. Our goal is to design truthful mechanisms to prevent such strategic misreports and achieve good approximations to the best possible social or egalitarian cost. We consider the fundamental setting of known intervals with equal lengths and provide tight bounds on the approximation ratios achieved by truthful deterministic mechanisms. For the social cost, we also design a randomized truthful mechanism that outperforms all possible deterministic ones. Finally, we highlight a plethora of natural extensions of our model for future work, as well as some natural limitations of those settings. Keywords: Game Theory and Economic Paradigms: GTEP: Mechanism design Game Theory and Economic Paradigms: GTEP: Computational social choice},
  archive   = {C_IJCAI},
  author    = {Argyrios Deligkas and Aris Filos-Ratsikas and Alexandros A. Voudouris},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/307},
  month     = {8},
  pages     = {2774-2781},
  title     = {Truthful interval covering},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Selecting the most conflicting pair of candidates.
<em>IJCAI</em>, 2766–2773. (<a
href="https://doi.org/10.24963/ijcai.2024/306">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study committee elections from a perspective of finding the most conflicting candidates, that is, candidates that imply the largest amount of conflict, as per voter preferences. By proposing basic axioms to capture this objective, we show that none of the prominent multiwinner voting rules meet them. Consequently, we design committee voting rules compliant with our desiderata, introducing conflictual voting rules. A subsequent deepened analysis sheds more light on how they operate. Our investigation identifies various aspects of conflict, for which we come up with relevant axioms and quantitative measures, which may be of independent interest. We support our theoretical study with experiments on both real-life and synthetic data. Keywords: Game Theory and Economic Paradigms: GTEP: Computational social choice},
  archive   = {C_IJCAI},
  author    = {Théo Delemazure and Łukasz Janeczko and Andrzej Kaczmarczyk and Stanisław Szufa},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/306},
  month     = {8},
  pages     = {2766-2773},
  title     = {Selecting the most conflicting pair of candidates},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Comparing ways of obtaining candidate orderings from
approval ballots. <em>IJCAI</em>, 2757–2765. (<a
href="https://doi.org/10.24963/ijcai.2024/305">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {To understand and summarize approval preferences and other binary evaluation data, it is useful to order the items on an axis which explains the data. In a political election using approval voting, this could be an ideological left-right axis such that each voter approves adjacent candidates, an analogue of single-peakedness. In a perfect axis, every approval set would be an interval, which is usually not possible, and so we need to choose an axis that gets closest to this ideal. The literature has developed algorithms for optimizing several objective functions (e.g., minimize the number of added approvals needed to get a perfect axis), but provides little help with choosing among different objectives. In this paper, we take a social choice approach and compare 5 different axis selection rules axiomatically, by studying the properties they satisfy. We establish some impossibility theorems, and characterize (within the class of scoring rules) the rule that chooses the axes that maximize the number of votes that form intervals, using the axioms of ballot monotonicity and resistance to cloning. Finally, we study the behavior of the rules on data from French election surveys, on the votes of justices of the US Supreme Court, and on synthetic data. Keywords: Game Theory and Economic Paradigms: GTEP: Computational social choice},
  archive   = {C_IJCAI},
  author    = {Théo Delemazure and Chris Dong and Dominik Peters and Magdalena Tydrichova},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/305},
  month     = {8},
  pages     = {2757-2765},
  title     = {Comparing ways of obtaining candidate orderings from approval ballots},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Aggregation of continuous preferences in one dimension.
<em>IJCAI</em>, 2748–2756. (<a
href="https://doi.org/10.24963/ijcai.2024/304">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We develop a general, formal model of social choice in which voters have continuous preferences over a one-dimensional space. Our model is parameterized by different restrictions that we introduce regarding the way voter preferences change in time as well as the optimization criteria (that correspond to a normative continuum of fairness definitions) desired from an aggregation method---that outputs a continuous, one-dimensional curve---given such inputs. We discuss the applicability of the model to different real-world situations and, as a first step towards an analysis of the different model realizations, we concentrate on identifying those cases that are computationally feasible to compute. Keywords: Game Theory and Economic Paradigms: GTEP: Computational social choice},
  archive   = {C_IJCAI},
  author    = {Alberto Del Pia and Dušan Knop and Alexandra Lassota and Krzysztof Sornat and Nimrod Talmon},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/304},
  month     = {8},
  pages     = {2748-2756},
  title     = {Aggregation of continuous preferences in one dimension},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Popular and dominant matchings with uncertain and multimodal
preferences. <em>IJCAI</em>, 2740–2747. (<a
href="https://doi.org/10.24963/ijcai.2024/303">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the Popular Matching (PM) problem in multiple models, where the preferences of the agents in the instance may change or may be unknown or uncertain. In particular, we study an Uncertainty model, where each agent has a possible set of preference lists, a Multilayer model, where there are layers of preference profiles, and a Robust popularity model, where any agent may move some other agents up or down some places in his preference list. Our goal is always to find a matching that is popular in any possible preference profile. We study both one-sided (only one class of the agents have preferences) and two-sided bipartite markets. In the one-sided model, we show that all our problems can be solved in polynomial time by utilizing the structure of popular matchings. We also obtain nice structural results. With two-sided preferences, we show that all three above models lead to NP-hard questions for popular matchings. By using the connection between dominant matchings and stable matchings, we show that in the robust and uncertainty models, a certainly dominant matching in all possible preference profiles can be found in polynomial time, whereas in the multilayer model, the problem remains NP-hard for dominant matchings too. We also answer an open question about d-robust stable matchings. Keywords: Game Theory and Economic Paradigms: GTEP: Mechanism design Game Theory and Economic Paradigms: GTEP: Computational social choice},
  archive   = {C_IJCAI},
  author    = {Gergely Csáji},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/303},
  month     = {8},
  pages     = {2740-2747},
  title     = {Popular and dominant matchings with uncertain and multimodal preferences},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Couples can be tractable: New algorithms and hardness
results for the hospitals/residents problem with couples.
<em>IJCAI</em>, 2731–2739. (<a
href="https://doi.org/10.24963/ijcai.2024/302">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper we study the Hospitals/Residents problem with Couples (HRC), where a solution is a stable matching or a report that none exists. We present a novel polynomial-time algorithm that can find a near-feasible stable matching (adjusting the hospitals&#39; capacities by at most 1) in an HRC instance where the couples&#39; preferences are sub-responsive (i.e., if one member switches to a better hospital, than the couple also improves if the new pair is also acceptable) and sub-complete (i.e., each pair of hospitals that are individually acceptable to both members are jointly acceptable for the couple) by reducing it to an instance of the Stable Fixtures problem. We also present a polynomial-time algorithm for HRC in a sub-responsive, sub-complete instance that is a Dual Market, or where all couples are one of several possible types. Our polynomial-time solvability results greatly expand the class of known tractable instances of HRC. We complement our algorithms with several hardness results. We show that HRC with sub-responsive and sub-complete couples is NP-hard, even with other strong restrictions. We also show that HRC with a Dual Market is NP-hard under several simultaneous restrictions. Keywords: Game Theory and Economic Paradigms: GTEP: Mechanism design Game Theory and Economic Paradigms: GTEP: Computational social choice},
  archive   = {C_IJCAI},
  author    = {Gergely Csáji and David Manlove and Iain McBride and James Trimble},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/302},
  month     = {8},
  pages     = {2731-2739},
  title     = {Couples can be tractable: New algorithms and hardness results for the Hospitals/Residents problem with couples},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Online learning of partitions in additively separable
hedonic games. <em>IJCAI</em>, 2722–2730. (<a
href="https://doi.org/10.24963/ijcai.2024/301">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Coalition formation involves partitioning agents into disjoint coalitions based on their preferences over other agents. In reality, agents may lack enough information to assess their preferences before interacting with others. This motivates us to initiate the research on coalition formation from the viewpoint of online learning. At each round, a possibly different subset of a given set of agents arrives, that a learner then partitions into coalitions. Only afterwards, the agents&#39; preferences, which possibly change over time, are revealed. The learner&#39;s goal is optimizing social cost by minimizing his (static or dynamic) regret. We show that even no-static regret is hard to approximate, and constant approximation in polynomial time is unattainable. Yet, for a fractional relaxation of our problem, we devise an algorithm that simultaneously gives the optimal static and dynamic regret. We then present a rounding scheme with an optimal dynamic regret, which converts our algorithm&#39;s output into a solution for our original problem. Keywords: Game Theory and Economic Paradigms: GTEP: Cooperative games Game Theory and Economic Paradigms: GTEP: Computational social choice Machine Learning: ML: Online learning Machine Learning: ML: Optimization},
  archive   = {C_IJCAI},
  author    = {Saar Cohen and Noa Agmon},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/301},
  month     = {8},
  pages     = {2722-2730},
  title     = {Online learning of partitions in additively separable hedonic games},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the pursuit of EFX for chores: Non-existence and
approximations. <em>IJCAI</em>, 2713–2721. (<a
href="https://doi.org/10.24963/ijcai.2024/300">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the problem of fairly allocating a set of chores to a group of agents. The existence of envy-free up to any item (EFX) allocations is a long-standing open question for both goods and chores. We resolve this question by providing a negative answer for the latter, presenting a simple construction that admits no EFX solutions for allocating six items to three agents equipped with superadditive cost functions, thus proving a separation result between goods and bads. In fact, we uncover a deeper insight, showing that the instance has unbounded approximation ratio. Moreover, we show that deciding whether an EFX allocation exists is NP-complete. On the positive side, we establish the existence of EFX allocations under general monotone cost functions when the number of items is at most n + 2. We then shift our attention to additive cost functions. We employ a general framework in order to improve the approximation guarantees in the well-studied case of three additive agents, and provide several conditional approximation bounds that leverage ordinal information. Keywords: Game Theory and Economic Paradigms: GTEP: Fair division},
  archive   = {C_IJCAI},
  author    = {Vasilis Christoforidis and Christodoulos Santorinaios},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/300},
  month     = {8},
  pages     = {2713-2721},
  title     = {On the pursuit of EFX for chores: Non-existence and approximations},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Parameterized analysis of bribery in challenge the champ
tournaments. <em>IJCAI</em>, 2704–2712. (<a
href="https://doi.org/10.24963/ijcai.2024/299">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Challenge the champ tournaments are one of the simplest forms of competition, where a (initially selected) champ is repeatedly challenged by other players. If a player beats the champ, then that player is considered the new (current) champ. Each player in the competition challenges the current champ once in a fixed order. The champ of the last round is considered the winner of the tournament. We investigate a setting where players can be bribed to lower their winning probability against the initial champ. The goal is to maximize the probability of the initial champ winning the tournament by bribing the other players, while not exceeding a given budget for the bribes. In previous work is was shown that the problem can be solved in pseudo-polynomial time, and that it is in XP when parameterized by the number of players. We show that the problem is weakly NP-hard and W[1]-hard when parameterized by the number of players. On the algorithmic side, we show that the problem is fixed-parameter tractable when parameterized either by the number of different bribe values or the number of different probability values. To this end, we establish several results that are of independent interest. In particular, we show that the product knapsack problem is W[1]-hard when parameterized by the number of items in the knapsack, and that constructive bribery for cup tournaments is W[1]-hard when parameterized by the number of players. Furthermore, we present a novel way of designing mixed integer linear programs, ensuring optimal solutions where all variables are integers. Keywords: Game Theory and Economic Paradigms: GTEP: Computational social choice},
  archive   = {C_IJCAI},
  author    = {Juhi Chaudhary and Hendrik Molter and Meirav Zehavi},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/299},
  month     = {8},
  pages     = {2704-2712},
  title     = {Parameterized analysis of bribery in challenge the champ tournaments},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Layered graph security games. <em>IJCAI</em>, 2695–2703. (<a
href="https://doi.org/10.24963/ijcai.2024/298">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Security games model strategic interactions in adversarial real-world applications. Such applications often involve extremely large but highly structured strategy sets (e.g., selecting a distribution over all patrol routes in a given graph). In this paper, we represent each player&#39;s strategy space using a layered graph whose paths represent an exponentially large strategy space. Our formulation entails not only classic pursuit-evasion games, but also other security games, such as those modeling anti-terrorism and logistical interdiction. We study two-player zero-sum games under two distinct utility models: linear and binary utilities. We show that under linear utilities, Nash equilibrium can be computed in polynomial time, while binary utilities may lead to situations where even computing a best-response is computationally intractable. To this end, we propose a practical algorithm based on incremental strategy generation and mixed integer linear programs. We show through extensive experiments that our algorithm efficiently computes epsilon-equilibrium for many games of interest. We find that target values and graph structure often have a larger influence on running times as compared to the size of the graph per se. Keywords: Game Theory and Economic Paradigms: GTEP: Noncooperative games},
  archive   = {C_IJCAI},
  author    = {Jakub Cerny and Chun Kai Ling and Christian Kroer and Garud Iyengar},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/298},
  month     = {8},
  pages     = {2695-2703},
  title     = {Layered graph security games},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Randomized learning-augmented auctions with revenue
guarantees. <em>IJCAI</em>, 2687–2694. (<a
href="https://doi.org/10.24963/ijcai.2024/297">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider the fundamental problem of designing a truthful single-item auction with the challenging objective of extracting a large fraction of the highest agent valuation as revenue. Following a recent trend in algorithm design, we assume that the agent valuations belong to a known interval, and a prediction for the highest valuation is available. Then, auction design aims for high consistency and robustness, meaning that, for appropriate pairs of values γ and ρ, the extracted revenue should be at least a γ- or ρ-fraction of the highest valuation when the prediction is correct for the input instance or not. We characterize all pairs of parameters γ and ρ so that a randomized γ-consistent and ρ-robust auction exists. Furthermore, for the setting in which robustness can be a function of the prediction error, we give sufficient and necessary conditions for the existence of robust auctions and present randomized auctions that extract a revenue that is only a polylogarithmic (in terms of the prediction error) factor away from the highest agent valuation. Keywords: Game Theory and Economic Paradigms: GTEP: Mechanism design Game Theory and Economic Paradigms: GTEP: Auctions and market-based systems Game Theory and Economic Paradigms: GTEP: Noncooperative games},
  archive   = {C_IJCAI},
  author    = {Ioannis Caragiannis and Georgios Kalantzis},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/297},
  month     = {8},
  pages     = {2687-2694},
  title     = {Randomized learning-augmented auctions with revenue guarantees},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evaluation of project performance in participatory
budgeting. <em>IJCAI</em>, 2678–2686. (<a
href="https://doi.org/10.24963/ijcai.2024/296">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study ways of evaluating the performance of losing projects in participatory budgeting (PB) elections by seeking actions that would make them win. We focus on lowering their costs, obtaining additional approvals, and removing approvals for competing projects: The larger a change is needed, the less successful is the given project. We seek efficient algorithms for computing our measures and we analyze them experimentally, focusing on GreedyAV, Phragmen, and Equal-Shares PB rules. Keywords: Game Theory and Economic Paradigms: GTEP: Computational social choice},
  archive   = {C_IJCAI},
  author    = {Niclas Boehmer and Piotr Faliszewski and Łukasz Janeczko and Dominik Peters and Grzegorz Pierczyński and Šimon Schierreich and Piotr Skowron and Stanisław Szufa},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/296},
  month     = {8},
  pages     = {2678-2686},
  title     = {Evaluation of project performance in participatory budgeting},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Computing optimal equilibria in repeated games with
restarts. <em>IJCAI</em>, 2669–2677. (<a
href="https://doi.org/10.24963/ijcai.2024/295">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Infinitely repeated games can support cooperative outcomes that are not equilibria in the one-shot game. The idea is to make sure that any gains from deviating will be offset by retaliation in future rounds. However, this model of cooperation fails in anonymous settings with many strategic agents that interact in pairs. Here, a player can defect and then avoid penalization by immediately switching partners. In this paper, we focus on a specific set of equilibria that avoids this pitfall. In them, agents follow a designated sequence of actions, and restart if their opponent ever deviates. We show that the socially-optimal sequence of actions consists of an infinitely repeating goal value, preceded by a hazing period. We introduce an equivalence relation on sequences and prove that the computational problem of finding a representative from the optimal equivalence class is (weakly) NP-hard. Nevertheless, we present a pseudo-polynomial time dynamic program for this problem, as well as an integer linear program, and show they are efficient in practice. Lastly, we introduce a fully polynomial-time approximation scheme that outputs a hazing sequence with arbitrarily small approximation ratio. Keywords: Game Theory and Economic Paradigms: GTEP: Noncooperative games},
  archive   = {C_IJCAI},
  author    = {Ratip Emin Berker and Vincent Conitzer},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/295},
  month     = {8},
  pages     = {2669-2677},
  title     = {Computing optimal equilibria in repeated games with restarts},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Welfare loss in connected resource allocation.
<em>IJCAI</em>, 2660–2668. (<a
href="https://doi.org/10.24963/ijcai.2024/294">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the allocation of indivisible goods that form an undirected graph and investigate the worst-case welfare loss when requiring that each agent must receive a connected subgraph. Our focus is on both egalitarian and utilitarian welfare. Specifically, we introduce the concept of egalitarian (resp., utilitarian) price of connectivity, which captures the worst-case ratio between the optimal egalitarian (resp., utilitarian) welfare among all allocations and that among the connected allocations. We provide tight or asymptotically tight bounds on the price of connectivity for various large classes of graphs when there are two agents, and for paths, stars and cycles in the general case. Many of our results are supplemented with algorithms which find connected allocations with a welfare guarantee corresponding to the price of connectivity. Keywords: Game Theory and Economic Paradigms: GTEP: Fair division Agent-based and Multi-agent Systems: MAS: Resource allocation},
  archive   = {C_IJCAI},
  author    = {Xiaohui Bei and Alexander Lam and Xinhang Lu and Warut Suksompong},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/294},
  month     = {8},
  pages     = {2660-2668},
  title     = {Welfare loss in connected resource allocation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Facility location problems with capacity constraints: Two
facilities and beyond. <em>IJCAI</em>, 2651–2659. (<a
href="https://doi.org/10.24963/ijcai.2024/293">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we investigate the Mechanism Design aspects of the m-Capacitated Facility Location Problem (m-CFLP) on a line. We focus on two frameworks. In the first framework, the number of facilities is arbitrary, all facilities have the same capacity, and the number of agents is equal to the total capacity of all facilities. In the second framework, we aim to place two facilities, each with a capacity of at least half of the total agents. For both of these frameworks, we propose truthful mechanisms with bounded approximation ratios with respect to the Social Cost (SC) and the Maximum Cost (MC). When m&gt;2, the result sharply contrasts with the impossibility results known for the classic m-Facility Location Problem, where capacity constraints are not considered. Furthermore, all our mechanisms are optimal with respect to the MC and optimal or nearly optimal with respect to the SC among anonymous mechanisms. For both frameworks, we provide a lower bound on the approximation ratio that any truthful and deterministic mechanism can achieve with respect to the SC and MC. Keywords: Game Theory and Economic Paradigms: GTEP: Mechanism design Agent-based and Multi-agent Systems: MAS: Agent theories and models Agent-based and Multi-agent Systems: MAS: Coordination and cooperation Agent-based and Multi-agent Systems: MAS: Resource allocation},
  archive   = {C_IJCAI},
  author    = {Gennaro Auricchio and Zihe Wang and Jie Zhang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/293},
  month     = {8},
  pages     = {2651-2659},
  title     = {Facility location problems with capacity constraints: Two facilities and beyond},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimizing viscous democracy. <em>IJCAI</em>, 2643–2650. (<a
href="https://doi.org/10.24963/ijcai.2024/292">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Viscous democracy is a generalization of liquid democracy, a social choice framework in which voters may transitively delegate their votes. In viscous democracy, a &quot;viscosity&quot; factor decreases the weight of a delegation the further it travels, reducing the chance of excessive weight flowing between ideologically misaligned voters. We demonstrate that viscous democracy often significantly improves the quality of group decision-making over liquid democracy. We first show that finding optimal delegations within a viscous setting is NP-hard. However, simulations allow us to explore the practical effects of viscosity. Across social network structures, competence distributions, and delegation mechanisms we find high viscosity reduces the chance of ``super-voters&#39;&#39; attaining large amounts of weight and increases the number of voters that are able to affect the outcome of elections. This, in turn, improves group accuracy as a whole. As a result, we argue that viscosity should be considered a core component of liquid democracy. Keywords: Game Theory and Economic Paradigms: GTEP: Computational social choice Agent-based and Multi-agent Systems: MAS: Agent-based simulation and emergence Multidisciplinary Topics and Applications: MTA: Web and social networks},
  archive   = {C_IJCAI},
  author    = {Ben Armstrong and Shiri Alouf-Heffetz and Nimrod Talmon},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/292},
  month     = {8},
  pages     = {2643-2650},
  title     = {Optimizing viscous democracy},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). R2V-MIF: Rule-to-vector contrastive learning and
multi-channel information fusion for therapy recommendation.
<em>IJCAI</em>, 2634–2641. (<a
href="https://doi.org/10.24963/ijcai.2024/291">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Integrating data-driven and rule-based approaches is crucial for therapy recommendations since they can collaborate to achieve better performance. Medical rules, which are chains of reasoning that can infer therapies, widely exist. However, their symbolic and logical forms make integrating them with data-driven modeling technologies hard. Although rare attempts have indirectly modeled rules using data that supports them, the poor generalization of medical rules leads to inadequate supporting data and thus impairs the benefit of medical rules. To this end, we propose R2V-MIF, which fills the gap by rule-to-vector contrastive learning (R2V) and multi-channel information fusion (MIF). R2V is a data-free module and utilizes a hypergraph, including condition and result nodes, to instantiate the logic of medical rules. Each rule is reflected in the relations between nodes, and their representations are determined through contrastive learning. By taking rule representations as a bridge, MIF integrates the knowledge from medical rules, similar neighbors, and patient contents, and then recommends therapies. Extensive experiments show that R2V-MIF outperforms the baselines in several metrics using real-world medical data. Our code is available at https://github.com/vgeek-z/r2vmif. Keywords: Data Mining: DM: Recommender systems Data Mining: DM: Mining heterogenous data Multidisciplinary Topics and Applications: MTA: Health and medicine},
  archive   = {C_IJCAI},
  author    = {Nengjun Zhu and Jieyun Huang and Jian Cao and Liang Hu and Zixuan Yuan and Huanjing Gao},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/291},
  month     = {8},
  pages     = {2634-2641},
  title     = {R2V-MIF: Rule-to-vector contrastive learning and multi-channel information fusion for therapy recommendation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Estimating before debiasing: A bayesian approach to
detaching prior bias in federated semi-supervised learning.
<em>IJCAI</em>, 2625–2633. (<a
href="https://doi.org/10.24963/ijcai.2024/290">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Federated Semi-Supervised Learning (FSSL) leverages both labeled and unlabeled data on clients to collaboratively train a model. In FSSL, the heterogeneous data can introduce prediction bias into the model, causing the model&#39;s prediction to skew towards some certain classes. Existing FSSL methods primarily tackle this issue by enhancing consistency in model parameters or outputs. However, as the models themselves are biased, merely constraining their consistency is not sufficient to alleviate prediction bias. In this paper, we explore this bias from a Bayesian perspective and demonstrate that it principally originates from label prior bias within the training data. Building upon this insight, we propose a debiasing method for FSSL named FedDB. FedDB utilizes the Average Prediction Probability of Unlabeled Data (APP-U) to approximate the biased prior. During local training, FedDB employs APP-U to refine pseudo-labeling through Bayes&#39; theorem, thereby significantly reducing the label prior bias. Concurrently, during the model aggregation, FedDB uses APP-U from participating clients to formulate unbiased aggregate weights, thereby effectively diminishing bias in the global model. Experimental results show that FedDB can surpass existing FSSL methods. The code is available at https://github.com/GuogangZhu/FedDB. Keywords: Data Mining: DM: Parallel, distributed and cloud-based high performance mining Data Mining: DM: Privacy-preserving data mining Machine Learning: ML: Semi-supervised learning},
  archive   = {C_IJCAI},
  author    = {Guogang Zhu and Xuefeng Liu and Xinghao Wu and Shaojie Tang and Chao Tang and Jianwei Niu and Hao Su},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/290},
  month     = {8},
  pages     = {2625-2633},
  title     = {Estimating before debiasing: A bayesian approach to detaching prior bias in federated semi-supervised learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generalized taxonomy-guided graph neural networks.
<em>IJCAI</em>, 2616–2624. (<a
href="https://doi.org/10.24963/ijcai.2024/289">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph neural networks have been demonstrated to be effective analytic apparatus for mining network data. Most real-world networks are inherently hierarchical, offering unique opportunities to acquire latent, intrinsic network organizational properties by utilizing network taxonomies. The existing approaches for learning implicit hierarchical network structures focus on introducing taxonomy to graph neural networks but often run short of exploiting the rich network semantics and structural properties in the taxonomy, resulting in poor generalizability and reusability. To address these issues, we propose generalized Taxonomy-Guided Graph Neural Networks (TG-GNN) to integrate taxonomy into network representation learning. We first construct a taxonomy representation learning module that introduces the concept of ego network to propagate and aggregate rich semantic and structural information in the taxonomy. We then design a taxonomy-guided Markov mechanism, which encapsulates taxonomy knowledge in pairwise potential functions, to refine network embeddings. Extensive experiments on various real-world networks illustrate the effectiveness of TG-GNN over the state-of-the-art methods on scenarios involving incomplete taxonomies and inductive settings. Keywords: Data Mining: DM: Mining graphs Machine Learning: ML: Sequence and graph learning},
  archive   = {C_IJCAI},
  author    = {Yu Zhou and Di Jin and Jianguo Wei and Dongxiao He and Zhizhi Yu and Weixiong Zhang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/289},
  month     = {8},
  pages     = {2616-2624},
  title     = {Generalized taxonomy-guided graph neural networks},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Make graph neural networks great again: A generic
integration paradigm of topology-free patterns for traffic speed
prediction. <em>IJCAI</em>, 2607–2615. (<a
href="https://doi.org/10.24963/ijcai.2024/288">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Urban traffic speed prediction aims to estimate the future traffic speed for improving urban transportation services. Enormous efforts have been made to exploit Graph Neural Networks (GNNs) for modeling spatial correlations and temporal dependencies of traffic speed evolving patterns, regularized by graph topology. While achieving promising results, current traffic speed prediction methods still suffer from ignoring topology-free patterns, which cannot be captured by GNNs. To tackle this challenge, we propose a generic model for enabling the current GNN-based methods to preserve topology-free patterns. Specifically, we first develop a Dual Cross-Scale Transformer (DCST) architecture, including a Spatial Transformer and a Temporal Transformer, to preserve the cross-scale topology-free patterns and associated dynamics, respectively. Then, to further integrate both topology-regularized/-free patterns, we propose a distillation-style learning framework, in which the existing GNN-based methods are considered as the teacher model, and the proposed DCST architecture is considered as the student model. The teacher model would inject the learned topology-regularized patterns into the student model for integrating topology-free patterns. The extensive experimental results demonstrated the effectiveness of our methods. Keywords: Data Mining: DM: Mining spatial and/or temporal data},
  archive   = {C_IJCAI},
  author    = {Yicheng Zhou and Pengfei Wang and Hao Dong and Denghui Zhang and Dingqi Yang and Yanjie Fu and Pengyang Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/288},
  month     = {8},
  pages     = {2607-2615},
  title     = {Make graph neural networks great again: A generic integration paradigm of topology-free patterns for traffic speed prediction},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Modeling personalized retweeting behaviors for multi-stage
cascade popularity prediction. <em>IJCAI</em>, 2598–2606. (<a
href="https://doi.org/10.24963/ijcai.2024/287">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Predicting the size of message cascades is critical in various applications, such as online advertising and early detection of rumors. However, most existing deep learning approaches rely on cascade observation, which hinders accurate cascade prediction before message posting. Besides, these approaches overlook personalized retweeting behaviors that reflect users&#39; inclination to retweeting specific types of information. In this study, we propose a universal cascade prediction framework, namely Cascade prediction regarding Multiple Stage (CasMS), that effectively predicts cascade popularity across message generation stage as well as short-term and long-term stages. Unlike previous methods, our approach not only captures users&#39; personalized retweeting behaviors but also incorporates temporal cascade features. We perform the experiments in datasets collected ourselves as well as public datasets. The results show that our method significantly surpasses existing approaches in predicting the cascade during the message generation stage and different time periods in the cascade dynamics. Keywords: Data Mining: DM: Mining text, web, social media Data Mining: DM: Recommender systems Machine Learning: ML: Applications},
  archive   = {C_IJCAI},
  author    = {Mingyang Zhou and Yanjie Lin and Gang Liu and Zuwen Li and Hao Liao and Rui Mao},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/287},
  month     = {8},
  pages     = {2598-2606},
  title     = {Modeling personalized retweeting behaviors for multi-stage cascade popularity prediction},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A graph-based representation framework for trajectory
recovery via spatiotemporal interval-informed Seq2Seq. <em>IJCAI</em>,
2588–2597. (<a href="https://doi.org/10.24963/ijcai.2024/286">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The prevalent issue in urban trajectory data usage, notably in low-sample rate datasets, revolves around the accuracy of travel time estimations, traffic flow predictions, and trajectory similarity measurements. Conventional methods, often relying on simplistic mixes of static road networks and raw GPS data, fail to adequately integrate both network and trajectory dimensions. Addressing this, the innovative GRFTrajRec framework offers a graph-based solution for trajectory recovery. Its key feature is a trajectory-aware graph representation, enhancing the understanding of trajectory-road network interactions and facilitating the extraction of detailed embedding features for road segments. Additionally, GRFTrajRec&#39;s trajectory representation acutely captures spatiotemporal attributes of trajectory points. Central to this framework is a novel spatiotemporal interval-informed seq2seq model, integrating an attention-enhanced transformer and a feature differences-aware decoder. This model specifically excels in handling spatiotemporal intervals, crucial for restoring missing GPS points in low-sample datasets. Validated through extensive experiments on two large real-life trajectory datasets, GRFTrajRec has proven its efficacy in significantly boosting prediction accuracy and spatial consistency. Keywords: Data Mining: DM: Mining spatial and/or temporal data Data Mining: DM: Applications Data Mining: DM: Exploratory data mining},
  archive   = {C_IJCAI},
  author    = {Yaya Zhao and Kaiqi Zhao and Zhiqian Chen and Yuanyuan Zhang and Yalei Du and Xiaoling Lu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/286},
  month     = {8},
  pages     = {2588-2597},
  title     = {A graph-based representation framework for trajectory recovery via spatiotemporal interval-informed Seq2Seq},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). G2LTraj: A global-to-local generation approach for
trajectory prediction. <em>IJCAI</em>, 2579–2587. (<a
href="https://doi.org/10.24963/ijcai.2024/285">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Predicting future trajectories of traffic agents accurately holds substantial importance in various applications such as autonomous driving. Previous methods commonly infer all future steps of an agent either recursively or simultaneously. However, the recursive strategy suffers from the accumulated error, while the simultaneous strategy overlooks the constraints among future steps, resulting in kinematically infeasible predictions. To address these issues, in this paper, we propose G2LTraj, a plug-and-play global-to-local generation approach for trajectory prediction. Specifically, we generate a series of global key steps that uniformly cover the entire future time range. Subsequently, the local intermediate steps between the adjacent key steps are recursively filled in. In this way, we prevent the accumulated error from propagating beyond the adjacent key steps. Moreover, to boost the kinematical feasibility, we not only introduce the spatial constraints among key steps but also strengthen the temporal constraints among the intermediate steps. Finally, to ensure the optimal granularity of key steps, we design a selectable granularity strategy that caters to each predicted trajectory. Our G2LTraj significantly improves the performance of seven existing trajectory predictors across the ETH, UCY and nuScenes datasets. Experimental results demonstrate its effectiveness. Code will be available at https://github.com/Zhanwei-Z/G2LTraj. Keywords: Data Mining: DM: Mining spatial and/or temporal data Computer Vision: CV: Motion and tracking Machine Learning: ML: Time series and data streams},
  archive   = {C_IJCAI},
  author    = {Zhanwei Zhang and Zishuo Hua and Minghao Chen and Wei Lu and Binbin Lin and Deng Cai and Wenxiao Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/285},
  month     = {8},
  pages     = {2579-2587},
  title     = {G2LTraj: A global-to-local generation approach for trajectory prediction},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TFWT: Tabular feature weighting with transformer.
<em>IJCAI</em>, 2570–2578. (<a
href="https://doi.org/10.24963/ijcai.2024/284">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we propose a novel feature weighting method to address the limitation of existing feature processing methods for tabular data. Typically the existing methods assume equal importance across all samples and features in one dataset. This simplified processing methods overlook the unique contributions of each feature, and thus may miss important feature information. As a result, it leads to suboptimal performance in complex datasets with rich features. To address this problem, we introduce Tabular Feature Weighting with Transformer, a novel feature weighting approach for tabular data. Our method adopts Transformer to capture complex feature dependencies and contextually assign appropriate weights to discrete and continuous features. Besides, we employ a reinforcement learning strategy to further fine-tune the weighting process. Our extensive experimental results across various real-world datasets and diverse downstream tasks show the effectiveness of TFWT and highlight the potential for enhancing feature weighting in tabular data analysis. Keywords: Data Mining: DM: Applications Machine Learning: ML: Feature extraction, selection and dimensionality reduction},
  archive   = {C_IJCAI},
  author    = {Xinhao Zhang and Zaitian Wang and Lu Jiang and Wanfu Gao and Pengfei Wang and Kunpeng Liu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/284},
  month     = {8},
  pages     = {2570-2578},
  title     = {TFWT: Tabular feature weighting with transformer},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SaSDim: Self-adaptive noise scaling diffusion model for
spatial time series imputation. <em>IJCAI</em>, 2561–2569. (<a
href="https://doi.org/10.24963/ijcai.2024/283">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Spatial time series imputation is of great importance to various real-world applications. As the state-of-the-art generative models, diffusion models (e.g. CSDI) have outperformed statistical and autoregressive based models in time series imputation. However, diffusion models may introduce unstable noise owing to the inherent uncertainty in sampling, leading to the generated noise deviating from the intended Gaussian distribution. Consequently, the imputed data may deviate from the real data. To this end, we propose a Self-adaptive noise Scaling Diffusion Model named SaSDim for spatial time series imputation. Specifically, we introduce a novel Probabilistic High-Order SDE Solver Module to scale the noise following the standard Gaussian distribution. The noise scaling operation helps the noise prediction module of the diffusion model to more accurately estimate the variance of noise. To effectively learn the spatial and temporal features, a Spatial guided Global Convolution Module (SgGConv) for multi-periodic temporal dependencies learning with the Fast Fourier Transformation and dynamic spatial dependencies learning with dynamic graph convolution is also proposed. Extensive experiments conducted on three real-world spatial time series datasets verify the effectiveness of SaSDim. Keywords: Data Mining: DM: Mining spatial and/or temporal data},
  archive   = {C_IJCAI},
  author    = {Shunyang Zhang and Senzhang Wang and Xianzhen Tan and Renzhi Wang and Ruochen Liu and Jian Zhang and Jianxin Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/283},
  month     = {8},
  pages     = {2561-2569},
  title     = {SaSDim: Self-adaptive noise scaling diffusion model for spatial time series imputation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Score-CDM: Score-weighted convolutional diffusion model for
multivariate time series imputation. <em>IJCAI</em>, 2551–2560. (<a
href="https://doi.org/10.24963/ijcai.2024/282">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multivariant time series (MTS) data are usually incomplete in real scenarios, and imputing the incomplete MTS is practically important to facilitate various time series mining tasks. Recently, diffusion model-based MTS imputation methods have achieved promising results by utilizing CNN or attention mechanisms for temporal features learning. However, it is hard to adaptively trade off the diverse effects of local and global temporal features by simply combining CNN and attention. To address this issue, we propose a Score-weighted Convolutional Diffusion Model (Score-CDM for short), whose backbone consists of a Score-weighted Convolution Module (SCM) and an Adaptive Reception Module (ARM). SCM adopts a score map to capture the global temporal features in the time domain, while ARM uses a Spectral2Time Window Block (S2TWB) to convolve the local time series data in the spectral domain. Benefiting from the time convolution properties of Fast Fourier Transformation, ARM can adaptively change the receptive field of the score map, and thus effectively balance the local and global temporal features. We conduct extensive evaluations on three real MTS datasets of different domains, and the result verifies the effectiveness of the proposed Score-CDM. Keywords: Data Mining: DM: Mining spatial and/or temporal data},
  archive   = {C_IJCAI},
  author    = {Shunyang Zhang and Senzhang Wang and Hao Miao and Hao Chen and Changjun Fan and Jian Zhang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/282},
  month     = {8},
  pages     = {2551-2560},
  title     = {Score-CDM: Score-weighted convolutional diffusion model for multivariate time series imputation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Natural language-centered inference network for multi-modal
fake news detection. <em>IJCAI</em>, 2542–2550. (<a
href="https://doi.org/10.24963/ijcai.2024/281">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The proliferation of fake news with image and text in the internet has triggered widespread concern. Existing research has made important contributions in cross-modal information interaction and fusion, but fails to fundamentally address the modality gap among news image, text, and news-related external knowledge representations. In this paper, we propose a novel Natural Language-centered Inference Network (NLIN) for multi-modal fake news detection by aligning multi-modal news content with the natural language space and introducing an encoder-decoder architecture to fully comprehend the news in-context. Specifically, we first unify multi-modal news content into textual modality by converting news images and news-related external knowledge into plain textual content. Then, we design a multi-modal feature reasoning module, which consists of a multi-modal encoder, a unified-modal context encoder and an inference decoder with prompt phrase. This framework not only fully extracts the latent representation of cross-modal news content, but also utilizes the prompt phrase to stimulate the powerful in-context learning ability of the pre-trained large language model to reason about the truthfulness of the news content. In addition, to support the research in the field of multi-modal fake news detection, we produce a challenging large scale, multi-platform, multi-domain multi-modal Chinese Fake News Detection (CFND) dataset. Extensive experiments show that our CFND dataset is challenging and the proposed NLIN outperforms state-of-the-art methods. Keywords: Data Mining: DM: Mining text, web, social media Multidisciplinary Topics and Applications: MTA: News and media},
  archive   = {C_IJCAI},
  author    = {Qiang Zhang and Jiawei Liu and Fanrui Zhang and Jingyi Xie and Zheng-Jun Zha},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/281},
  month     = {8},
  pages     = {2542-2550},
  title     = {Natural language-centered inference network for multi-modal fake news detection},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploring urban semantics: A multimodal model for POI
semantic annotation with street view images and place names.
<em>IJCAI</em>, 2533–2541. (<a
href="https://doi.org/10.24963/ijcai.2024/280">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Semantic annotation for points of interest (POIs) is the process of annotating a POI with a category label, which facilitates many services related to POIs, such as POI search and recommendation. Most of the existing solutions extract features related to POIs from abundant user-generated content data (e.g., check-ins and user comments). However, such data are often difficult to obtain, especially for newly created POIs. In this paper, we aim to explore semantic annotation for POIs with limited information such as POI (place) names and geographic locations. Additionally, we have found that the street view images provide extensive visual clues about POI attributes and could be an essential supplement to limited information of POIs that enables semantic annotation. To this end, we propose a novel multimodal model for POI semantic annotation, namely M3PA, which achieves enhanced semantic annotation through fusing a POI’s textual and visual representations. Specifically, M3PA extracts visual features from street view images using a pre-trained image encoder and integrates these features to generate the visual representation of a targeted POI based on a geographic attention mechanism. Furthermore, M3PA utilizes the contextual information of neighboring POIs to extract textual features and captures their spatial relationships through geographical encoding to generate the textual representation of a targeted POI. Finally, the visual and textual representations of a POI are fused for semantic annotation. Extensive experiments with POI data from Amap validate the effectiveness of M3PA for POI semantic annotation, compared with several competitive baselines. Keywords: Data Mining: DM: Mining spatial and/or temporal data},
  archive   = {C_IJCAI},
  author    = {Dabin Zhang and Meng Chen and Weiming Huang and Yongshun Gong and Kai Zhao},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/280},
  month     = {8},
  pages     = {2533-2541},
  title     = {Exploring urban semantics: A multimodal model for POI semantic annotation with street view images and place names},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sub-adjacent transformer: Improving time series anomaly
detection with reconstruction error from sub-adjacent neighborhoods.
<em>IJCAI</em>, 2524–2532. (<a
href="https://doi.org/10.24963/ijcai.2024/279">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we present the Sub-Adjacent Transformer with a novel attention mechanism for unsupervised time series anomaly detection. Unlike previous approaches that rely on all the points within some neighborhood for time point reconstruction, our method restricts the attention to regions not immediately adjacent to the target points, termed sub-adjacent neighborhoods. Our key observation is that owing to the rarity of anomalies, they typically exhibit more pronounced differences from their sub-adjacent neighborhoods than from their immediate vicinities. By focusing the attention on the sub-adjacent areas, we make the reconstruction of anomalies more challenging, thereby enhancing their detectability. Technically, our approach concentrates attention on the non-diagonal areas of the attention matrix by enlarging the corresponding elements in the training stage. To facilitate the implementation of the desired attention matrix pattern, we adopt linear attention because of its flexibility and adaptability. Moreover, a learnable mapping function is proposed to improve the performance of linear attention. Empirically, the Sub-Adjacent Transformer achieves state-of-the-art performance across six real-world anomaly detection benchmarks, covering diverse fields such as server monitoring, space exploration, and water treatment. Keywords: Data Mining: DM: Anomaly/outlier detection Machine Learning: ML: Time series and data streams},
  archive   = {C_IJCAI},
  author    = {Wenzhen Yue and Xianghua Ying and Ruohao Guo and DongDong Chen and Ji Shi and Bowei Xing and Yuqing Zhu and Taiyan Chen},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/279},
  month     = {8},
  pages     = {2524-2532},
  title     = {Sub-adjacent transformer: Improving time series anomaly detection with reconstruction error from sub-adjacent neighborhoods},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LG-GNN: Local-global adaptive graph neural network for
modeling both homophily and heterophily. <em>IJCAI</em>, 2515–2523. (<a
href="https://doi.org/10.24963/ijcai.2024/278">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Most Graph Neural Networks (GNNs) are based on the homophily assumption, where nodes with the same labels or similar features tend to be connected to each other. However, real-world graphs often do not adhere to this homophily assumption. Currently, most researches aggregate multi-hop neighbor information to discover more potentially relevant nodes. However, in the aggregation process of GNNs, the difference in modeling global and local information is not considered, inevitably leading to information loss. Motivated by this limitation, we propose LG-GNN, a local-global adaptive graph neural network for modeling both homophily and heterophily. Specifically, we model the long-range structural similarity and local feature similarity between nodes from global and local perspectives, in order to capture distant dependencies in highly heterophilic networks while reducing the mixing of locally dissimilar feature nodes, thereby increasing the effectiveness of information aggregation in highly heterophilic graphs. Extensive experiments on a wide range of real-world datasets demonstrate that our proposed approach performs well in both heterophilic and homophilic graphs. Keywords: Data Mining: DM: Mining graphs Machine Learning: ML: Sequence and graph learning},
  archive   = {C_IJCAI},
  author    = {Zhizhi Yu and Bin Feng and Dongxiao He and Zizhen Wang and Yuxiao Huang and Zhiyong Feng},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/278},
  month     = {8},
  pages     = {2515-2523},
  title     = {LG-GNN: Local-global adaptive graph neural network for modeling both homophily and heterophily},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Kernel readout for graph neural networks. <em>IJCAI</em>,
2505–2514. (<a href="https://doi.org/10.24963/ijcai.2024/277">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph neural networks (GNNs) for graph classification or representation learning require a pooling operation to convert the nodes&#39; embeddings of each graph to a vector as the graph-level representation and the operation has a significant impact on model accuracy. The paper presents a novel graph pooling method called Kernel Readout (KerRead). KerRead maps the node embeddings from the sample space with limited nodes to an augmented sample space with infinite nodes, and then calculates the inner product between some learnable adaptive centers and the augmented node embeddings, which forms a final graph-level feature vector. We apply the proposed strategy to six supervised and two unsupervised graph neural networks such as GCN, GIN, GUNet, InfoGraph, and GraphCL, and the experiments on eight benchmark datasets show that the proposed readout outperforms classical pooling methods such as Sum and seven state-of-the-art pooling methods such as SRead and Janossy GRU. Code and Appendix are both available at https://github.com/jiajunCAU/KerRead. Keywords: Data Mining: DM: Mining graphs Machine Learning: ML: Representation learning},
  archive   = {C_IJCAI},
  author    = {Jiajun Yu and Zhihao Wu and Jinyu Cai and Adele Lu Jia and Jicong Fan},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/277},
  month     = {8},
  pages     = {2505-2514},
  title     = {Kernel readout for graph neural networks},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Joint domain adaptive graph convolutional network.
<em>IJCAI</em>, 2496–2504. (<a
href="https://doi.org/10.24963/ijcai.2024/276">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the realm of cross-network tasks, graph domain adaptation is an effective tool due to its ability to transfer abundant labels from nodes in the source domain to those in the target domain. Existing adversarial domain adaptation methods mainly focus on domain-wise alignment. These approaches, while effective in mitigating the marginal distribution shift between the two domains, often ignore the integral aspect of structural alignment, potentially leading to negative transfer. To address this issue, we propose a joint adversarial domain adaptive graph convolutional network (JDA-GCN) that is uniquely augmented with structural graph alignment, so as to enhance the efficacy of knowledge transfer. Specifically, we construct a structural graph to delineate the interconnections among nodes within identical categories across the source and target domains. To further refine node representation, we integrate the local consistency matrix with the global consistency matrix, thereby leveraging the learning of the sub-structure similarity of nodes to enable more robust and effective representation of nodes. Empirical evaluation on diverse real-world datasets substantiates the superiority of our proposed method, marking a significant advancement over existing state-of-the-art graph domain adaptation algorithms. Keywords: Data Mining: DM: Mining graphs Machine Learning: ML: Classification Machine Learning: ML: Sequence and graph learning},
  archive   = {C_IJCAI},
  author    = {Niya Yang and Ye Wang and Zhizhi Yu and Dongxiao He and Xin Huang and Di Jin},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/276},
  month     = {8},
  pages     = {2496-2504},
  title     = {Joint domain adaptive graph convolutional network},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Decoupled invariant attention network for multivariate
time-series forecasting. <em>IJCAI</em>, 2487–2495. (<a
href="https://doi.org/10.24963/ijcai.2024/275">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {To achieve more accurate prediction results in Time Series Forecasting (TSF), it is essential to distinguish between the valuable patterns (invariant patterns) of the spatial-temporal relationship and the patterns that are prone to generate distribution shift (variant patterns), then combine them for forecasting.The existing works, such as transformer-based models and GNN-based models, focus on capturing main forecasting dependencies whether it is stable or not, and they tend to overlook patterns that carry both useful information and distribution shift. In this paper, we propose a model for better forecasting time series: Decoupled Invariant Attention Network (DIAN), which contains two modules to learn spatial and temporal relationships respectively: 1) Spatial Decoupled Invariant-Variant Learning (SDIVL) to decouple the spatial invariant and variant attention scores, and then leverage convolutional networks to effectively integrate them for subsequent layers; 2) Temporal Augmented Invariant-Variant Learning (TAIVL) to decouple temporal invariant and variant patterns and combine them for further forecasting.In this module, we also design Temporal Intervention Mechanism to create multiple intervened samples by reassembling variant patterns across time stamps to eliminate the spurious impacts of variant patterns.In addition, we propose Joint Optimization to minimize the loss function considering all invariant patterns, variant patterns and intervened patterns so that our model can gain a more stable predictive ability.Extensive experiments on five datasets have demonstrated our superior performance with higher efficiency compared with state-of-the-art methods. Keywords: Data Mining: DM: Mining spatial and/or temporal data},
  archive   = {C_IJCAI},
  author    = {Haihua Xu and Wei Fan and Kun Yi and Pengyang Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/275},
  month     = {8},
  pages     = {2487-2495},
  title     = {Decoupled invariant attention network for multivariate time-series forecasting},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Graph attention network with high-order neighbor information
propagation for social recommendation. <em>IJCAI</em>, 2478–2486. (<a
href="https://doi.org/10.24963/ijcai.2024/274">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In recommender systems, graph neural networks (GNN) can integrate interactions between users and items with their attributes, which makes GNN-based methods more powerful. However, directly stacking multiple layers in a graph neural network can easily lead to over-smoothing, hence recommendation systems based on graph neural networks typically underutilize higher-order neighborhoods in their learning. Although some heterogeneous graph random walk methods based on meta-paths can achieve higher-order aggregation, the focus is predominantly on the nodes at the ends of the paths. Moreover, these methods require manually defined meta-paths, which limits the model’s expressiveness and flexibility. Furthermore, path encoding in graph neural networks usually focuses only on the sequence leading to the target node. However, real-world interactions often do not follow this strict sequence, limiting the predictive performance of sequence-based network models. These problems prevent GNN-based methods from being fully effective. We propose a Graph Attention network with Information Propagation path aggregation for Social Recommendation (GAIPSRec). Firstly, we propose a universal heterogeneous graph sampling framework that does not require manually defining meta-paths for path sampling, thereby offering greater flexibility. Moreover, our method takes into account all nodes on the aggregation path and is capable of learning information from higher-order neighbors without succumbing to over-smoothing. Finally, our method utilizes a gate mechanism to fuse sequential and non-sequential dependence in encoding path instances, allowing a more holistic view of the data. Extensive experiments on real-world datasets show that our proposed GAIPSRec improves the performance significantly and outperforms state-of-the-art methods. Keywords: Data Mining: DM: Mining graphs Data Mining: DM: Recommender systems},
  archive   = {C_IJCAI},
  author    = {Fei Xiong and Haoran Sun and Guixun Luo and Shirui Pan and Meikang Qiu and Liang Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/274},
  month     = {8},
  pages     = {2478-2486},
  title     = {Graph attention network with high-order neighbor information propagation for social recommendation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning fair representations for recommendation via
information bottleneck principle. <em>IJCAI</em>, 2469–2477. (<a
href="https://doi.org/10.24963/ijcai.2024/273">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {User-oriented recommender systems (RS) characterize users&#39; preferences based on observed behaviors and are widely deployed in personalized services. However, RS may unintentionally capture biases related to sensitive attributes (e.g., gender) from behavioral data, leading to unfair issues and discrimination against particular groups (e.g., females). Adversarial training is a popular technique for fairness-aware RS, when filtering sensitive information in user modeling. Despite advancements in fairness, achieving a good accuracy-fairness trade-off remains a challenge in adversarial training. In this paper, we investigate fair representation learning from a novel information theory perspective. Specifically, we propose a model-agnostic Fair recommendation method via the Information Bottleneck principle FairIB. The learning objective of FairIB is to maximize the mutual information between user representations and observed interactions, while simultaneously minimizing it between user representations and sensitive attributes. This approach facilitates the capturing of essential collaborative signals in user representations while mitigating the inclusion of unnecessary sensitive information. Empirical studies on two real-world datasets demonstrate the effectiveness of the proposed FairIB, which significantly improves fairness while maintaining competitive recommendation accuracy, either in single or multiple sensitive scenarios. The code is available at https://github.com/jsxie9/IJCAI_FairIB. Keywords: Data Mining: DM: Recommender systems AI Ethics, Trust, Fairness: ETF: Fairness and diversity Data Mining: DM: Collaborative filtering Machine Learning: ML: Representation learning},
  archive   = {C_IJCAI},
  author    = {Junsong Xie and Yonghui Yang and Zihan Wang and Le Wu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/273},
  month     = {8},
  pages     = {2469-2477},
  title     = {Learning fair representations for recommendation via information bottleneck principle},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hierarchical reinforcement learning for point of interest
recommendation. <em>IJCAI</em>, 2460–2468. (<a
href="https://doi.org/10.24963/ijcai.2024/272">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With the increasing popularity of location-based services, accurately recommending points of interest (POIs) has become a critical task. Although existing technologies are proficient in processing time-series data, they fall short when it comes to accommodating the diversity and dynamism in users&#39; POI selections, particularly in extracting key signals from complex historical behaviors. To address this challenge, we introduced the Hierarchical Reinforcement Learning Preprocessing Framework (HRL-PRP), a framework that can be integrated into existing recommendation models to effectively optimize user profiles. The HRL-PRP framework employs a two-tiered decision-making process, where the high-level process determines the necessity of modifying profiles, and the low-level process focuses on selecting POIs within the profiles. Through evaluations on multiple real-world datasets, we have demonstrated that HRL-PRP surpasses existing state-of-the-art methods in various recommendation performance metrics. Keywords: Data Mining: DM: Recommender systems},
  archive   = {C_IJCAI},
  author    = {Yanan Xiao and Lu Jiang and Kunpeng Liu and Yuanbo Xu and Pengyang Wang and Minghao Yin},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/272},
  month     = {8},
  pages     = {2460-2468},
  title     = {Hierarchical reinforcement learning for point of interest recommendation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Robust heterophilic graph learning against label noise for
anomaly detection. <em>IJCAI</em>, 2451–2459. (<a
href="https://doi.org/10.24963/ijcai.2024/271">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Given clean labels, Graph Neural Networks (GNNs) have shown promising abilities for graph anomaly detection. However, real-world graphs are inevitably noisy labeled, which drastically degrades the performance of GNNs. To alleviate it, some studies follow the local consistency (a.k.a homophily) assumption to conduct neighborhood-based label noise correction, and to dense raw graphs using raw features or representations learned by poisoned labels. But for the anomaly detection task, the graph is not always homophilic but more likely to be heterophilic, which would corrupt the above assumption due to complicating connection patterns and impairing the effects of message passing. To this end, we propose a novel label noise-resistant graph learning (NRGL) framework, which facilitates robust graph learning from the perspectives of structure augmentation and fine-grained label governance. Specifically, we first present an investigation to verify that increasing graph homophily could help resist label noise. Based on the observation, an unsupervised contrastive learning paradigm is then introduced so well that it cannot only adaptively extract the dual views from the raw graph as structure augmentation, but also enhance the robustness of node representations. Next, given robust node representations, the noisy labels are divided into three candidate sets based on the small-loss criterion for fine-grained noise governance. Furthermore, a node sampler is designed to take structure importance, class frequency, and confidence score into consideration, which helps select reliable and important nodes for training. Extensive experiments on real-world datasets demonstrate the effectiveness of our method. Keywords: Data Mining: DM: Applications Data Mining: DM: Exploratory data mining Data Mining: DM: Mining graphs},
  archive   = {C_IJCAI},
  author    = {Junhang Wu and Ruimin Hu and Dengshi Li and Zijun Huang and Lingfei Ren and Yilong Zang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/271},
  month     = {8},
  pages     = {2451-2459},
  title     = {Robust heterophilic graph learning against label noise for anomaly detection},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unsupervised anomaly detection via masked diffusion
posterior sampling. <em>IJCAI</em>, 2442–2450. (<a
href="https://doi.org/10.24963/ijcai.2024/270">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Reconstruction-based methods have been commonly used for unsupervised anomaly detection, in which a normal image is reconstructed and compared with the given test image to detect and locate anomalies. Recently, diffusion models have shown promising applications for anomaly detection due to their powerful generative ability. However, these models lack strict mathematical support for normal image reconstruction and unexpectedly suffer from low reconstruction quality. To address these issues, this paper proposes a novel and highly-interpretable method named Masked Diffusion Posterior Sampling (MDPS). In MDPS, the problem of normal image reconstruction is mathematically modeled as multiple diffusion posterior sampling for normal images based on the devised masked noisy observation model and the diffusion-based normal image prior under Bayesian framework. Using a metric designed from pixel-level and perceptual-level perspectives, MDPS can effectively compute the difference map between each normal posterior sample and the given test image. Anomaly scores are obtained by averaging all difference maps for multiple posterior samples. Exhaustive experiments on MVTec and BTAD datasets demonstrate that MDPS can achieve state-of-the-art performance in normal image reconstruction quality as well as anomaly detection and localization. Keywords: Data Mining: DM: Anomaly/outlier detection Computer Vision: CV: Applications Computer Vision: CV: Image and video synthesis and generation},
  archive   = {C_IJCAI},
  author    = {Di Wu and Shicai Fan and Xue Zhou and Li Yu and Yuzhong Deng and Jianxiao Zou and Baihong Lin},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/270},
  month     = {8},
  pages     = {2442-2450},
  title     = {Unsupervised anomaly detection via masked diffusion posterior sampling},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). WeatherGNN: Exploiting meteo- and spatial-dependencies for
local numerical weather prediction bias-correction. <em>IJCAI</em>,
2433–2441. (<a href="https://doi.org/10.24963/ijcai.2024/269">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Due to insufficient local area information, numerical weather prediction (NWP) may yield biases for specific areas. Previous studies correct biases mainly by employing handcrafted features or applying data-driven methods intuitively, overlooking the complicated dependencies between weather factors and between areas. To address this issue, we propose WeatherGNN, a local NWP bias-correction method that utilizes Graph Neural Networks (GNNs) to exploit meteorological dependencies and spatial dependencies under the guidance of domain knowledge. Specifically, we introduce a factor GNN to capture area-specific meteorological dependencies adaptively based on spatial heterogeneity and a fast hierarchical GNN to capture dynamic spatial dependencies efficiently guided by Tobler&#39;s first and second laws of geography. Our experimental results on two real-world datasets demonstrate that WeatherGNN achieves the state-of-the-art performance, outperforming the best baseline with an average of 4.75 % on RMSE. Keywords: Data Mining: DM: Applications Data Mining: DM: Mining spatial and/or temporal data},
  archive   = {C_IJCAI},
  author    = {Binqing Wu and Weiqi Chen and Wengwei Wang and Bingqing Peng and Liang Sun and Ling Chen},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/269},
  month     = {8},
  pages     = {2433-2441},
  title     = {WeatherGNN: Exploiting meteo- and spatial-dependencies for local numerical weather prediction bias-correction},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Joint source localization in different platforms via
implicit propagation characteristics of similar topics. <em>IJCAI</em>,
2424–2432. (<a href="https://doi.org/10.24963/ijcai.2024/268">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Different social media are widely used in our daily lives. Inspired by the fact that similar topics have similar propagation characteristics, we mine the implicit knowledge of cascades with similar topics from different platforms to enhance the localization performance for scenarios where limited propagation data leads to the weak learning ability of existing localization models. In this work, we first construct a multiple platform propagation cascade dataset, aligning similar topics from both Twitter and Weibo, and enriching it with user profiles. Leveraging this dataset, we propose a Dual-channel Source Localization Framework (DSLF) for the joint cascades with similar topics. Specifically, a self-loop attention based graph convolutional network is designed to adaptively adjust the neighborhood aggregation scheme of different users with heterogeneous features in the message-passing process. Additionally, a dual-structure based Kullback-Leibler (KL) regularization module is proposed to constrain the latent distribution space of the source probabilities of similar characteristic-level users for a similar topic, enhancing the robustness of the model. Extensive experiments across Twitter and Weibo platforms demonstrate the superiority of the proposed DSLF over the SOTA methods. The code is available at https://github.com/cgao-comp/DSLF. Keywords: Data Mining: DM: Networks Data Mining: DM: Mining graphs Data Mining: DM: Mining text, web, social media},
  archive   = {C_IJCAI},
  author    = {Zhen Wang and Dongpeng Hou and Shu Yin and Chao Gao and Xianghua Li},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/268},
  month     = {8},
  pages     = {2424-2432},
  title     = {Joint source localization in different platforms via implicit propagation characteristics of similar topics},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Spatial-temporal perceiving: Deciphering user hierarchical
intent in session-based recommendation. <em>IJCAI</em>, 2415–2423. (<a
href="https://doi.org/10.24963/ijcai.2024/267">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Session-based recommendation (SBR) aims to predict the next-interacted item based on anonymous users&#39; behavior sequences. The main challenge is how to recognize the user intent with limited interactions to achieve a more accurate inference of user behavior. Existing works usually regard several consecutive items in the current session as intent. However, we argue such intent generation based on temporal transition ignores the fact that each item also has its semantically connected items in the feature space, which can be regarded as spatial intent. The limited consideration of intent fails to capture complex behavioral patterns in real-world scenarios, leading to sub-optimal solutions. To address this issue, we propose the Hierarchical Intent Perceiving Contrastive Learning Framework (HearInt) for SBR, which proposes a hierarchical consideration of intents from both temporal and spatial perspective. Specifically, we first propose that the user&#39;s temporal intents are mutually exclusive while the spatial intents are mutually compatible. Following these analyses, we design a Temporal Intent Decoupling module to mitigate the mutual influence of long-term and short-term intents, and a Cross-scale Contrastive Learning task to enhance the consistency of intents across different spatial scales. Experimental results on three real-world datasets exhibit that HearInt achieves state-of-the-art performance. Keywords: Data Mining: DM: Recommender systems},
  archive   = {C_IJCAI},
  author    = {Xiao Wang and Tingting Dai and Qiao Liu and Shuang Liang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/267},
  month     = {8},
  pages     = {2415-2423},
  title     = {Spatial-temporal perceiving: Deciphering user hierarchical intent in session-based recommendation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FlagVNE: A flexible and generalizable reinforcement learning
framework for network resource allocation. <em>IJCAI</em>, 2406–2414.
(<a href="https://doi.org/10.24963/ijcai.2024/266">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Virtual network embedding (VNE) is an essential resource allocation task in network virtualization, aiming to map virtual network requests (VNRs) onto physical infrastructure. Reinforcement learning (RL) has recently emerged as a promising solution to this problem. However, existing RL-based VNE methods are limited by the unidirectional action design and one-size-fits-all training strategy, resulting in restricted searchability and generalizability. In this paper, we propose a flexible and generalizable RL framework for VNE, named FlagVNE. Specifically, we design a bidirectional action-based Markov decision process model that enables the joint selection of virtual and physical nodes, thus improving the exploration flexibility of solution space. To tackle the expansive and dynamic action space, we design a hierarchical decoder to generate adaptive action probability distributions and ensure high training efficiency. Furthermore, to overcome the generalization issue for varying VNR sizes, we propose a meta-RL-based training method with a curriculum scheduling strategy, facilitating specialized policy training for each VNR size. Finally, extensive experimental results show the effectiveness of FlagVNE across multiple key metrics. Our code is available at https://github.com/GeminiLight/flag-vne. Keywords: Data Mining: DM: Applications Data Mining: DM: Parallel, distributed and cloud-based high performance mining Machine Learning: ML: Applications},
  archive   = {C_IJCAI},
  author    = {Tianfu Wang and Qilin Fan and Chao Wang and Long Yang and Leilei Ding and Nicholas Jing Yuan and Hui Xiong},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/266},
  month     = {8},
  pages     = {2406-2414},
  title     = {FlagVNE: A flexible and generalizable reinforcement learning framework for network resource allocation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). HeterGCL: Graph contrastive learning framework on
heterophilic graph. <em>IJCAI</em>, 2397–2405. (<a
href="https://doi.org/10.24963/ijcai.2024/265">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph Contrastive Learning (GCL) has attracted significant research attention due to its self-supervised ability to learn robust node representations. Unfortunately, most methods primarily focus on homophilic graphs, rendering them less effective for heterophilic graphs. In addition, the complexity of node interactions in heterophilic graphs poses considerable challenges to augmentation schemes, coding architectures, and contrastive designs for traditional GCL. In this work, we propose HeterGCL, a novel graph contrastive learning framework with structural and semantic learning to explore the true potential of GCL on heterophilic graphs. Specifically, We abandon the random augmentation scheme that leads to the destruction of the graph structure, instead introduce an adaptive neighbor aggregation strategy (ANA) to extract topology-supervised signals from neighboring nodes at different distances and explore the structural information with an adaptive local-to-global contrastive loss. In the semantic learning module, we jointly consider the original nodes&#39; features and the similarity between nodes in the latent feature space to explore hidden associations between nodes. Experimental results on homophilic and heterophilic graphs demonstrate that HeterGCL outperforms existing self-supervised and semi-supervised baselines across various downstream tasks. Keywords: Data Mining: DM: Mining graphs Machine Learning: ML: Self-supervised Learning},
  archive   = {C_IJCAI},
  author    = {Chenhao Wang and Yong Liu and Yan Yang and Wei Li},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/265},
  month     = {8},
  pages     = {2397-2405},
  title     = {HeterGCL: Graph contrastive learning framework on heterophilic graph},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Make bricks with a little straw: Large-scale
spatio-temporal graph learning with restricted GPU-memory capacity.
<em>IJCAI</em>, 2388–2396. (<a
href="https://doi.org/10.24963/ijcai.2024/264">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Traffic prediction plays a key role in various smart city applications, which can help traffic managers make traffic plans in advance, assist online ride-hailing companies in deploying vehicles reasonably, and provide early warning of congestion for safety authorities. While increasingly complex models achieve impressive prediction performance, there are concerns about the effectiveness of these models in handling large-scale road networks. Especially for researchers who don&#39;t have access to powerful GPU devices, the expensive memory burden limits the usefulness of these models. In this paper, we take the first step of learning on the large-scale spatio-temporal graph and propose a divide-and-conquer training strategy for Large Spatio-Temporal Graph Learning, namely LarSTL. The core idea behind this strategy is to divide the large graph into multiple subgraphs, which are treated as task streams to sequentially train the model to conquer each subgraph one by one. We introduce a novel perspective based on the continuous learning paradigm to achieve this goal. In order to overcome forgetting the knowledge learned from previous subgraphs, an experience-replay strategy consolidates the learned knowledge by replaying nodes sampled from previous subgraphs. Moreover, we configure specific feature adaptors for each subgraph to extract personalized features, and it is also beneficial to consolidate the learned knowledge from the perspective of parameters. We conduct experiments using multiple large-scale traffic network datasets on a V100 GPU with only 16GB memory, and the results demonstrate that our LarSTL can achieve competitive performance and high efficiency. Keywords: Data Mining: DM: Mining spatial and/or temporal data Data Mining: DM: Big data and scalability Data Mining: DM: Mining graphs},
  archive   = {C_IJCAI},
  author    = {Binwu Wang and Pengkun Wang and Zhengyang Zhou and Zhe Zhao and Wei Xu and Yang Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/264},
  month     = {8},
  pages     = {2388-2396},
  title     = {Make bricks with a little straw: Large-scale spatio-temporal graph learning with restricted GPU-memory capacity},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Instance-level metalearning for outlier detection.
<em>IJCAI</em>, 2379–2387. (<a
href="https://doi.org/10.24963/ijcai.2024/263">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A machine learning task can be viewed as a sequential pipeline of different algorithmic choices, including data preprocessing, model selection, and hyper-parameter tuning. Automated machine learning selects this sequence in an automated manner. While such approaches are natural in supervised settings, they remain challenging for unsupervised tasks such as outlier detection because of the lack of availability of label-centric feedback. In this paper, we present an instance-level metalearning approach for outlier detection. This approach learns how outlier instances are related to normal points in many labeled data sets to create a supervised meta-model. This meta-model is then used on a new (unlabeled) data set to predict outliers. We show the robustness of our approach on several benchmarks from the OpenML repository. Keywords: Data Mining: DM: Anomaly/outlier detection Machine Learning: ML: Automated machine learning Machine Learning: ML: Meta-learning},
  archive   = {C_IJCAI},
  author    = {Long Vu and Peter Kirchner and Charu C. Aggarwal and Horst Samulowitz},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/263},
  month     = {8},
  pages     = {2379-2387},
  title     = {Instance-level metalearning for outlier detection},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SemanticMask: A contrastive view design for anomaly
detection in tabular data. <em>IJCAI</em>, 2370–2378. (<a
href="https://doi.org/10.24963/ijcai.2024/262">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Contrastive learning based on data augmentation techniques has recently achieved substantial advancement in learning a representation well-suited for anomaly detection in image domain. However, due to the lack of spatial structure, designing effective data augmentation methods for tabular data remains challenging. Conventional techniques, such as random mask, disregard the inter-feature correlations and fail to accurately represent the data. To address this issue, we propose a novel augmentation technique called SemanticMask which leverages the semantic information from column names to generate better augmented views. SemanticMask aims to ensure that the shared information between views contains sufficient information for anomaly detection without redundancy. We analyze the relationship between shared information and anomaly detection performance and empirically demonstrate that good views for tabular anomaly detection tasks are feature-dependent. Our experiment results validate the superiority of SemanticMask over the state-of-the-art anomaly detection methods and existing augmentation techniques for tabular data. In further evaluations of the multi-class novelty detection task, SemanticMask also significantly outperforms the baseline. Keywords: Data Mining: DM: Anomaly/outlier detection Machine Learning: ML: Unsupervised learning},
  archive   = {C_IJCAI},
  author    = {Shuting Tao and Tongtian Zhu and Hongwei Wang and Xiangming Meng},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/262},
  month     = {8},
  pages     = {2370-2378},
  title     = {SemanticMask: A contrastive view design for anomaly detection in tabular data},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Anomaly subgraph detection through high-order sampling
contrastive learning. <em>IJCAI</em>, 2362–2369. (<a
href="https://doi.org/10.24963/ijcai.2024/261">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Anomaly subgraph detection is a crucial task in various real-world applications, including identifying high-risk areas, detecting river pollution, and monitoring disease outbreaks. Early traditional graph-based methods can obtain high-precision detection results in scenes with small-scale graphs and obvious anomaly features. Most existing anomaly detection methods based on deep learning primarily concentrate on identifying anomalies at the node level, while neglecting to detect anomaly groups in the internal structure. In this paper, we propose a novel end-to-end Graph Neural Network (GNN) based anomaly subgraph detection approach(ASD-HC) in graph-structured data. 1)We propose a high-order neighborhood sampling strategy to construct our node and k-order neighbor-subgraph instance pairs. 2)Anomaly features of nodes are captured through a self-supervised contrastive learning model. 3) Detecting the maximum connected anomaly subgraph is performed by integrating the Non-parameter Graph Scan statistics and a Random Walk module. We evaluate ASD-HC against five state-of-the-art baselines using five benchmark datasets. ASD-HC outperforms the baselines by over 13.01% in AUC score. Various experiments demonstrate that our approach effectively detects anomaly subgraphs within large-scale graphs. Keywords: Data Mining: DM: Anomaly/outlier detection Data Mining: DM: Mining graphs Machine Learning: ML: Feature extraction, selection and dimensionality reduction Machine Learning: ML: Self-supervised Learning},
  archive   = {C_IJCAI},
  author    = {Ying Sun and Wenjun Wang and Nannan Wu and Chunlong Bao},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/261},
  month     = {8},
  pages     = {2362-2369},
  title     = {Anomaly subgraph detection through high-order sampling contrastive learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient correlated subgraph searches for AI-powered drug
discovery. <em>IJCAI</em>, 2351–2361. (<a
href="https://doi.org/10.24963/ijcai.2024/260">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Correlated subgraph searches (CSSs) are essential building blocks for AI-powered drug discovery. Given a query molecule modeled as a graph, CSS finds top-k molecules correlated to the query in a database. However, the cost increases exponentially with the molecule size. Herein we present Corgi, a framework to accelerate CSS methods while ensuring top-k search accuracy. Corgi dynamically excludes unnecessary subgraphs to overcome the expensive cost without sacrificing search accuracy. Our experimental analysis confirms that Corgi has a shorter running time and improved accuracy compared to existing state-of-the-art methods, while a case study demonstrates that Corgi is suitable for practical AI-powered drug discovery. Keywords: Data Mining: DM: Mining graphs Data Mining: DM: Big data and scalability Data Mining: DM: Applications Multidisciplinary Topics and Applications: MTA: Other},
  archive   = {C_IJCAI},
  author    = {Hiroaki Shiokawa and Yuma Naoi and Shohei Matsugu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/260},
  month     = {8},
  pages     = {2351-2361},
  title     = {Efficient correlated subgraph searches for AI-powered drug discovery},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unsupervised deep graph structure and embedding learning.
<em>IJCAI</em>, 2342–2350. (<a
href="https://doi.org/10.24963/ijcai.2024/259">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph Neural Network (GNN) is powerful in graph embedding learning, but its performance has been shown to be heavily degraded under adversarial attacks. Deep graph structure learning (GSL) is proposed to defend attack by jointly learning graph structure and graph embedding, typically in node classification task. Label supervision is expensive in real-world applications, and thus unsupervised GSL is more challenging and still remains less studied. To fulfill this gap, this paper proposes a new unsupervised GSL method, i.e., unsupervised property GNN (UPGNN). UPGNN first refines graph structure by exploring properties of low rank, sparsity, feature smoothness. UPGNN employs graph mutual information loss to learn graph embedding by maximizing its correlation with refined graph. The proposed UPGNN learns graph structure and embedding without label supervision, and thus can be applied various downstream tasks. We further propose Accelerated UPGNN (AUPGNN) to reduce computational complexity, providing a efficient alternative to UPGNN. Our extensive experiments on node classification and clustering demonstrate the effectiveness of the proposed method over the state-of-the-arts especially under heavy perturbation. Keywords: Data Mining: DM: Mining graphs Machine Learning: ML: Sequence and graph learning Machine Learning: ML: Unsupervised learning},
  archive   = {C_IJCAI},
  author    = {Xiaobo Shen and Lei Shi and Xiuwen Gong and Shirui Pan},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/259},
  month     = {8},
  pages     = {2342-2350},
  title     = {Unsupervised deep graph structure and embedding learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning multi-granularity and adaptive representation for
knowledge graph reasoning. <em>IJCAI</em>, 2333–2341. (<a
href="https://doi.org/10.24963/ijcai.2024/258">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Knowledge graph reasoning (KGR) aims to infer new factual triples from existing knowledge graphs (KGs). Recently, a new category of methods, possessing both transductive and inductive reasoning capabilities, has been proposed to tackle this task via learning entity-independent representations from local neighboring structures. However, these methods are plagued by inefficiency issues and they exclusively capture evidence from well-designed local structures, ignoring the correlation between the query and different structures within KGs. In this work, we first propose a novel multi-granularity and adaptive representation framework, MulGA, exploiting the connectivity subgraph to uniformly and hierarchically model query-related triples, relation paths, and subgraphs without explicitly extracting any graph structure, hence mitigating inefficiency issues. Second, we introduce a message-passing mechanism across connectivity subgraphs, facilitating all entities to attain query-related structural representations of diverse granularity levels, i.e., triple and relation paths of different lengths. Third, we design a self-attention-based merging mechanism that allocates weights to different granularities and then consolidates them into subgraph granularity representations for reasoning. The systematic experiments have been conducted on 15 benchmarks and MulGA achieves a significant improvement in MRR by an average of 1.5% on transductive and 2.7% on inductive tasks than existing state-of-the-art methods. Moreover, MulGA boasts faster convergence speed, competitive inference time, and alleviates the over-smoothing prevalent in graph neural networks. Keywords: Data Mining: DM: Knowledge graphs and knowledge base completion},
  archive   = {C_IJCAI},
  author    = {Ziyu Shang and Peng Wang and Wenjun Ke and Jiajun Liu and Hailang Huang and Guozheng Li and Chenxiao Wu and Jianghan Liu and Xiye Chen and Yining Li},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/258},
  month     = {8},
  pages     = {2333-2341},
  title     = {Learning multi-granularity and adaptive representation for knowledge graph reasoning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards dynamic trend filtering through trend point
detection with reinforcement learning. <em>IJCAI</em>, 2324–2332. (<a
href="https://doi.org/10.24963/ijcai.2024/257">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Trend filtering simplifies complex time series data by applying smoothness to filter out noise while emphasizing proximity to the original data. However, existing trend filtering methods fail to reflect abrupt changes in the trend due to `approximateness,&#39; resulting in constant smoothness. This approximateness uniformly filters out the tail distribution of time series data, characterized by extreme values, including both abrupt changes and noise. In this paper, we propose Trend Point Detection formulated as a Markov Decision Process (MDP), a novel approach to identifying essential points that should be reflected in the trend, departing from approximations. We term these essential points as Dynamic Trend Points (DTPs) and extract trends by interpolating them. To identify DTPs, we utilize Reinforcement Learning (RL) within a discrete action space and a forecasting sum-of-squares loss function as a reward, referred to as the Dynamic Trend Filtering network (DTF-net). DTF-net integrates flexible noise filtering, preserving critical original subsequences while removing noise as required for other subsequences. We demonstrate that DTF-net excels at capturing abrupt changes compared to other trend filtering algorithms and enhances forecasting performance, as abrupt changes are predicted rather than smoothed out. Keywords: Data Mining: DM: Mining spatial and/or temporal data Machine Learning: ML: Reinforcement learning},
  archive   = {C_IJCAI},
  author    = {Jihyeon Seong and Sekwang Oh and Jaesik Choi},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/257},
  month     = {8},
  pages     = {2324-2332},
  title     = {Towards dynamic trend filtering through trend point detection with reinforcement learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-relational graph attention network for social
relationship inference from human mobility data. <em>IJCAI</em>,
2315–2323. (<a href="https://doi.org/10.24963/ijcai.2024/256">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Inferring social relationships from human mobility data holds significant value in real-life spatio-temporal applications, which inspires the development of a series of graph-based methods for inferring social relationships. Despite their effectiveness, we argue that previous methods either rely solely on direct relations between users, neglecting valuable user mobility patterns, or have not fully harnessed the indirect interactions, thereby struggling to capture users&#39; mobility preferences. To address these issues, in this work, we propose the Multi-Relational Graph Attention Network (MRGAN), a novel graph attention network, which is able to explicitly model indirect relations and effectively capture their different impact. Specifically, we first extract a multi-relational graph from heterogeneous mobility graph to explicitly model the direct and indirect relations,and then utilize influence attention and cross-relation attention to further capture the different influence between users, and different importance of relations for each user. Comprehensive experiments on three real-world mobile datasets demonstrate that the proposed model significantly outperforms state-of-the-art models in predicting social relationships between users. The source code of our model is available at https://github.com/qinguangming1999/MRGAN_IJCAI. Keywords: Data Mining: DM: Mining spatial and/or temporal data Data Mining: DM: Mining graphs},
  archive   = {C_IJCAI},
  author    = {Guangming Qin and Jianpeng Qi and Bin Wang and Guiyuan Jiang and Yanwei Yu and Junyu Dong},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/256},
  month     = {8},
  pages     = {2315-2323},
  title     = {Multi-relational graph attention network for social relationship inference from human mobility data},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Counterfactual user sequence synthesis augmented with
continuous time dynamic preference modeling for sequential POI
recommendation. <em>IJCAI</em>, 2306–2314. (<a
href="https://doi.org/10.24963/ijcai.2024/255">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With the proliferation of Location-based Social Networks (LBSNs), user check-in data at Points-of-Interest (POIs) has surged, offering rich insights into user preferences. However, sequential POI recommendation systems always face two pivotal challenges. A challenge lies in the difficulty of modeling time in a discrete space, which fails to accurately capture the dynamic nature of user preferences. Another challenge is the inherent sparsity and noise in continuous POI recommendation, which hinder the recommendation process. To address these challenges, we propose counterfactual user sequence synthesis with continuous time dynamic preference modeling (CussCtpm). CussCtpm innovatively combines Gated Recurrent Unit (GRU) with neural Ordinary Differential Equations (ODEs) to model user preferences in a continuous time framework. CussCtpm captures user preferences at both the POI-level and interest-level, identifying deterministic and non-deterministic preference concepts. Particularly at the interest-level, we employ GRU and neural ODEs to model users&#39; dynamic preferences in continuous space, aiming to capture finer-grained shifts in user preferences over time. Furthermore, CussCtpm utilizes counterfactual data augmentation to generate counterfactual positive and negative user sequences. Our extensive experiments on two widely-used public datasets demonstrate that CussCtpm outperforms several advanced baseline models. Keywords: Data Mining: DM: Recommender systems},
  archive   = {C_IJCAI},
  author    = {Lianyong Qi and Yuwen Liu and Weiming Liu and Shichao Pei and Xiaolong Xu and Xuyun Zhang and Yingjie Wang and Wanchun Dou},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/255},
  month     = {8},
  pages     = {2306-2314},
  title     = {Counterfactual user sequence synthesis augmented with continuous time dynamic preference modeling for sequential POI recommendation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Seed selection in the heterogeneous moran process.
<em>IJCAI</em>, 2297–2305. (<a
href="https://doi.org/10.24963/ijcai.2024/254">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Moran process is a classic stochastic process that models the rise and takeover of novel traits in network-structured populations. In biological terms, a set of mutants, each with fitness m ∈ (0, ∞) invade a population of residents with fitness 1. Each agent reproduces at a rate proportional to its fitness and each offspring replaces a random network neighbor. The process ends when the mutants either fixate (take over the whole population) or go extinct. The fixation probability measures the success of the invasion. To account for environmental heterogeneity, we study a generalization of the Standard process, called the Heterogeneous Moran process. Here, the fitness of each agent is determined both by its type (resident/mutant) and the node it occupies. We study the natural optimization problem of seed selection: given a budget k, which k agents should initiate the mutant invasion to maximize the fixation probability? We show that the problem is strongly inapproximable: it is NP-hard to distinguish between maximum fixation probability 0 and 1. We then focus on mutant-biased networks, where each node exhibits at least as large mutant fitness as resident fitness. We show that the problem remains NP-hard, but the fixation probability becomes submodular, and thus the optimization problem admits a greedy (1 − 1/e)-approximation. An experimental evaluation of the greedy algorithm along with various heuristics on real-world data sets corroborates our results. Keywords: Data Mining: DM: Networks Agent-based and Multi-agent Systems: MAS: Resource allocation Constraint Satisfaction and Optimization: CSO: Constraint optimization problems Search: S: Evolutionary computation},
  archive   = {C_IJCAI},
  author    = {Petros Petsinis and Andreas Pavlogiannis and Josef Tkadlec and Panagiotis Karras},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/254},
  month     = {8},
  pages     = {2297-2305},
  title     = {Seed selection in the heterogeneous moran process},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Graph collaborative expert finding with contrastive
learning. <em>IJCAI</em>, 2288–2296. (<a
href="https://doi.org/10.24963/ijcai.2024/253">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In Community Question Answering (CQA) websites, most current expert finding methods often model expert embeddings from textual features and optimize them with expert-question first-order interactions, i.e., this expert has answered this question. In this paper, we try to address the limitation of current models that typically neglect the intrinsic high-order connectivity within expert-question interactions, which is pivotal for collaborative effects. We introduce an innovative and simple approach: by conceptualizing expert-question interactions as a bipartite graph, and then we propose a novel graph-based expert finding method based on contrastive learning to effectively capture both first-order and intricate high-order connectivity, named CGEF. Specifically, we employ a question encoder to model questions from titles and employ the graph attention network to recursively propagate embeddings. Besides, to alleviate the problem of sparse interactions, we devise two auxiliary tasks to enhance expert modeling. First, we generate multiple views of one expert, including: 1) behavior-level augmentation drops interaction edges randomly in the graph; 2) interest-level augmentation randomly replaces question titles with tags in the graph. Then we maximize the agreement between one expert and the corresponding augmented expert on a specific view. In this way, the model can effectively inject collaborative signals into expert modeling. Extensive experiments on six CQA datasets demonstrate significant improvements compared with recent methods. Keywords: Data Mining: DM: Mining graphs Data Mining: DM: Mining text, web, social media Data Mining: DM: Networks Data Mining: DM: Recommender systems},
  archive   = {C_IJCAI},
  author    = {Qiyao Peng and Wenjun Wang and Hongtao Liu and Cuiying Huo and Minglai Shao},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/253},
  month     = {8},
  pages     = {2288-2296},
  title     = {Graph collaborative expert finding with contrastive learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-modal sarcasm detection based on dual generative
processes. <em>IJCAI</em>, 2279–2287. (<a
href="https://doi.org/10.24963/ijcai.2024/252">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With the advancement of the internet, sarcastic sentiment expression on social media has grown increasingly diverse. Consequently, multimodal sarcasm detection has emerged as a valuable tool for users to comprehend and interpret sarcastic expressions. Previous research suggests that effectively integrating three modalities (namely image, text, and their inconsistencies) enhances sarcasm detection. However, in some instances, sarcasm detection can be achieved using a single modality, while others necessitate multiple modalities for accurate recognition. This variability suggests that each modality contributes differently to sarcasm detection, and employing a traditional fusion method may introduce bias in the information, unable to explicitly demonstrate the prediction ability of each modality. Therefore, we propose a multimodal sarcasm detection method based on dual generative processes. The dual generative processes map features into the same semantic space to deeply explore emotional inconsistencies between modalities. Concurrently, by incorporating the concept of strong and weak modalities, we explicitly model the modalities&#39; contributions based on prediction performance and autonomously adjust the weight distribution. Experimental results on publicly available multi-modal sarcasm detection datasets validate the superiority of our proposed model. Keywords: Data Mining: DM: Mining text, web, social media Natural Language Processing: NLP: Sentiment analysis, stylistic analysis, and argument mining},
  archive   = {C_IJCAI},
  author    = {Huiying Ma and Dongxiao He and Xiaobao Wang and Di Jin and Meng Ge and Longbiao Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/252},
  month     = {8},
  pages     = {2279-2287},
  title     = {Multi-modal sarcasm detection based on dual generative processes},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SeeDRec: Sememe-based diffusion for sequential
recommendation. <em>IJCAI</em>, 2270–2278. (<a
href="https://doi.org/10.24963/ijcai.2024/251">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Inspired by the power of Diffusion Models (DM) verified in various fields, some pioneering works have started to explore DM in recommendation. However, these prevailing endeavors commonly implement diffusion on item indices, leading to the increasing time complexity, the lack of transferability, and the inability to fully harness item semantic information. To tackle these challenges, we propose SeeDRec, a sememe-based diffusion framework for sequential recommendation (SR). Specifically, inspired by the notion of sememe in NLP, SeeDRec first defines a similar concept of recommendation sememe to represent the minimal interest unit and upgrades the specific diffusion objective from the item level to the sememe level. With the Sememe-to-Interest Diffusion Model (S2IDM), SeeDRec can accurately capture the user&#39;s diffused interest distribution learned from both local interest evolution and global interest generalization while maintaining low computational costs. Subsequently, an Interest-aware Prompt-enhanced (IPE) strategy is proposed to better guide each user&#39;s sequential behavior modeling via the learned user interest distribution. Extensive experiments on nine SR datasets and four cross-domain SR datasets verify its effectiveness and universality. The code is available in https://github.com/hulkima/SeeDRec. Keywords: Data Mining: DM: Recommender systems},
  archive   = {C_IJCAI},
  author    = {Haokai Ma and Ruobing Xie and Lei Meng and Yimeng Yang and Xingwu Sun and Zhanhui Kang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/251},
  month     = {8},
  pages     = {2270-2278},
  title     = {SeeDRec: Sememe-based diffusion for sequential recommendation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DGCD: An adaptive denoising GNN for group-level cognitive
diagnosis. <em>IJCAI</em>, 2261–2269. (<a
href="https://doi.org/10.24963/ijcai.2024/250">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Group-level cognitive diagnosis, pivotal in intelligent education, aims to effectively assess group-level knowledge proficiency by modeling the learning behaviors of individuals within the group. Existing methods typically conceptualize the group as an abstract entity or aggregate the knowledge levels of all members to represent the group’s overall ability. However, these methods neglect the high-order connectivity among groups, students, and exercises within the context of group learning activities, along with the noise present in their interactions, resulting in less robust and suboptimal diagnosis performance. To this end, in this paper, we propose DGCD, an adaptive Denoising graph neural network for realizing effective Group-level Cognitive Diagnosis. Specifically, we first construct a group-student-exercise (GSE) graph to explicitly model higher-order connectivity among groups, students, and exercises, contributing to the acquisition of informative representations. Then, we carefully design an adaptive denoising module, integrated into the graph neural network, to model the reliability distribution of student-exercise edges for mining purer interaction features. In particular, edges of lower reliability are more prone to exclusion, thereby reducing the impact of noisy interactions. Furthermore, recognizing the relational imbalance in the GSE graph, which could potentially introduce bias during message passing, we propose an entropy-weighted balance module to mitigate such bias. Finally, extensive experiments conducted on four real-world educational datasets clearly demonstrate the effectiveness of our proposed DGCD model. The code is available at https://github.com/BIMK/Intelligent-Education/tree/main/DGCD. Keywords: Data Mining: DM: Applications Multidisciplinary Topics and Applications: MTA: Education},
  archive   = {C_IJCAI},
  author    = {Haiping Ma and Siyu Song and Chuan Qin and Xiaoshan Yu and Limiao Zhang and Xingyi Zhang and Hengshu Zhu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/250},
  month     = {8},
  pages     = {2261-2269},
  title     = {DGCD: An adaptive denoising GNN for group-level cognitive diagnosis},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Massively parallel single-source SimRanks in o(log n)
rounds. <em>IJCAI</em>, 2252–2260. (<a
href="https://doi.org/10.24963/ijcai.2024/249">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {SimRank is one of the most fundamental measures that evaluate the structural similarity between two nodes in a graph and has been applied in a plethora of data mining and machine learning tasks. These tasks often involve single-source SimRank computation that evaluates the SimRank values between a source node u and all other nodes. Due to its high computation complexity, single-source SimRank computation for large graphs is notoriously challenging, and hence recent studies resort to distributed processing. To our surprise, although SimRank has been widely adopted for two decades, theoretical aspects of distributed SimRanks with provable results have rarely been studied. In this paper, we conduct a theoretical study on single-source SimRank computation in the Massive Parallel Computation (MPC) model, which is the standard theoretical framework modeling distributed systems. Existing distributed SimRank algorithms enforce either Ω(log n) communication round complexity or Ω(n) machine space for a graph of n nodes. We overcome this barrier. Particularly, given a graph of n nodes, for any query node v and constant error ϵ&gt;3/n, we show that using O(log² log n) rounds of communication among machines is enough to compute single-source SimRank values with at most ϵ absolute errors, while each machine only needs a space sub-linear to n. To the best of our knowledge, this is the first single-source SimRank algorithm in MPC that can overcome the Θ(log n) round complexity barrier with provable result accuracy. Keywords: Data Mining: DM: Parallel, distributed and cloud-based high performance mining Data Mining: DM: Theoretical foundations of data mining},
  archive   = {C_IJCAI},
  author    = {Siqiang Luo and Zulun Zhu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/249},
  month     = {8},
  pages     = {2252-2260},
  title     = {Massively parallel single-source SimRanks in o(log n) rounds},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards robust trajectory representations: Isolating
environmental confounders with causal learning. <em>IJCAI</em>,
2243–2251. (<a href="https://doi.org/10.24963/ijcai.2024/248">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Trajectory modeling refers to characterizing human movement behavior, serving as a pivotal step in understanding mobility patterns. Nevertheless, existing studies typically ignore the confounding effects of geospatial context, leading to the acquisition of spurious correlations and limited generalization capabilities. To bridge this gap, we initially formulate a Structural Causal Model (SCM) to decipher the trajectory representation learning process from a causal perspective. Building upon the SCM, we further present a Trajectory modeling framework (TrajCL) based on Causal Learning, which leverages the backdoor adjustment theory as an intervention tool to eliminate the spurious correlations between geospatial context and trajectories. Extensive experiments on two real-world datasets verify that TrajCL markedly enhances performance in trajectory classification tasks while showcasing superior generalization and interpretability. Keywords: Data Mining: DM: Mining spatial and/or temporal data Multidisciplinary Topics and Applications: MTA: Transportation},
  archive   = {C_IJCAI},
  author    = {Kang Luo and Yuanshao Zhu and Wei Chen and Kun Wang and Zhengyang Zhou and Sijie Ruan and Yuxuan Liang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/248},
  month     = {8},
  pages     = {2243-2251},
  title     = {Towards robust trajectory representations: Isolating environmental confounders with causal learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Heterogeneous graph transformer with poly-tokenization.
<em>IJCAI</em>, 2234–2242. (<a
href="https://doi.org/10.24963/ijcai.2024/247">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph neural networks have shown widespread success for learning on graphs, but they still face fundamental drawbacks, such as limited expressive power, over-smoothing, and over-squashing. Meanwhile, the transformer architecture offers a potential solution to these issues. However, existing graph transformers primarily cater to homogeneous graphs and are unable to model the intricate semantics of heterogeneous graphs. Moreover, unlike small molecular graphs where the entire graph can be considered as the receptive field in graph transformers, real-world heterogeneous graphs comprise a significantly larger number of nodes and cannot be entirely treated as such. Consequently, existing graph transformers struggle to capture the long-range dependencies in these complex heterogeneous graphs. To address these two limitations, we present Poly-tokenized Heterogeneous Graph Transformer (PHGT), a novel transformer-based heterogeneous graph model. In addition to traditional node tokens, PHGT introduces a novel poly-token design with two more token types: semantic tokens and global tokens. Semantic tokens encapsulate high-order heterogeneous semantic relationships, while global tokens capture semantic-aware long-range interactions. We validate the effectiveness of PHGT through extensive experiments on standardized heterogeneous graph benchmarks, demonstrating significant improvements over state-of-the-art heterogeneous graph representation learning models. Keywords: Data Mining: DM: Mining heterogenous data Data Mining: DM: Mining graphs},
  archive   = {C_IJCAI},
  author    = {Zhiyuan Lu and Yuan Fang and Cheng Yang and Chuan Shi},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/247},
  month     = {8},
  pages     = {2234-2242},
  title     = {Heterogeneous graph transformer with poly-tokenization},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Graph contrastive learning with reinforcement augmentation.
<em>IJCAI</em>, 2225–2233. (<a
href="https://doi.org/10.24963/ijcai.2024/246">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph contrastive learning (GCL), designing contrastive objectives to learn embeddings from augmented graphs, has become a prevailing method for extracting embeddings from graphs in an unsupervised manner. As an important procedure in GCL, graph data augmentation (GDA) directly affects the model performance on downstream tasks. Currently, the GCL methods typically treat GDA as independent events, neglecting its continuity. In this paper, we regard the GDA in GCL as a Markov decision process and propose a novel graph reinforcement augmentation framework for GCL. Based on this framework, we design a Graph Advantage Actor-Critic (GA2C) model. We conduct extensive experiments to evaluate GA2C on unsupervised learning, transfer learning, and semi-supervised learning. The experimental results demonstrate the performance superiority of GA2C over the state-of-the-art GCL models. Furthermore, we verify that GA2C is more efficient than the other GCL methods with learnable GDA and provide two examples of chemical molecular graphs from ZINC-2M to demonstrate that GA2C generates meaningful augmented views, where the edge weights reflect the importance of chemical bonds in the molecule. Keywords: Data Mining: DM: Mining graphs Machine Learning: ML: Representation learning Machine Learning: ML: Reinforcement learning Machine Learning: ML: Self-supervised Learning},
  archive   = {C_IJCAI},
  author    = {Ziyang Liu and Chaokun Wang and Cheng Wu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/246},
  month     = {8},
  pages     = {2225-2233},
  title     = {Graph contrastive learning with reinforcement augmentation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Full bayesian significance testing for neural networks in
traffic forecasting. <em>IJCAI</em>, 2216–2224. (<a
href="https://doi.org/10.24963/ijcai.2024/245">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Due to the complex and dynamic traffic contexts, the interpretability and uncertainty of traffic forecasting have gained increasing attention. Significance testing is a powerful tool in statistics used to determine whether a hypothesis is valid, facilitating the identification of pivotal features that predominantly contribute to the true relationship. However, existing works mainly regard traffic forecasting as a deterministic problem, making it challenging to perform effective significance testing. To fill this gap, we propose to conduct Full Bayesian Significance Testing for Neural Networks in Traffic Forecasting, namely ST-nFBST. A Bayesian neural network is utilized to capture the complicated traffic relationships through an optimization function resolved in the context of aleatoric uncertainty and epistemic uncertainty. Thereupon, ST-nFBST can achieve the significance testing by means of a delicate grad-based evidence value, further capturing the inherent traffic schema for better spatiotemporal modeling. Extensive experiments are conducted on METR-LA and PEMS-BAY to verify the advantages of our method in terms of uncertainty analysis and significance testing, helping the interpretability and promotion of traffic forecasting. Keywords: Data Mining: DM: Mining spatial and/or temporal data Knowledge Representation and Reasoning: KRR: Learning and reasoning Uncertainty in AI: UAI: Uncertainty representations Machine Learning: ML: Explainable/Interpretable machine learning},
  archive   = {C_IJCAI},
  author    = {Zehua Liu and Jingyuan Wang and Zimeng Li and Yue He},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/245},
  month     = {8},
  pages     = {2216-2224},
  title     = {Full bayesian significance testing for neural networks in traffic forecasting},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). KDDC: Knowledge-driven disentangled causal metric learning
for pre-travel out-of-town recommendation. <em>IJCAI</em>, 2207–2215.
(<a href="https://doi.org/10.24963/ijcai.2024/244">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Pre-travel recommendation is developed to provide a variety of out-of-town Point-of-Interests (POIs) for users planning to travel away from their hometowns but have not yet decided on their destination. Existing out-of-town recommender systems work on constructing users&#39; latent preferences and inferring travel intentions from their check-in sequences. However, there are still two challenges that hamper the performance of these approaches: i) Users&#39; interactive data (including hometown and out-of-town check-ins) tend to be rare, and while candidate POIs that come from different regions contain various semantic information; ii) The causes for user check-in include not only interest but also conformity, which are easily entangled and overlooked. To fill these gaps, we propose a Knowledge-Driven Disentangled Causal metric learning framework (KDDC) that mitigates interaction data sparsity by enhancing POI semantic representation and considers the distributions of two causes (i.e., conformity and interest) for pre-travel recommendation. Specifically, we pretrain a constructed POI attribute knowledge graph through a segmented interaction method and POI semantic information is aggregated via relational heterogeneity. In addition, we devise a disentangled causal metric learning to model and infer userrelated representations. Extensive experiments on two real-world nationwide datasets display the consistent superiority of our KDDC over state-of-theart baselines. Keywords: Data Mining: DM: Recommender systems Data Mining: DM: Mining spatial and/or temporal data},
  archive   = {C_IJCAI},
  author    = {Yinghui Liu and Guojiang Shen and Chengyong Cui and Zhenzhen Zhao and Xiao Han and Jiaxin Du and Xiangyu Zhao and Xiangjie Kong},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/244},
  month     = {8},
  pages     = {2207-2215},
  title     = {KDDC: Knowledge-driven disentangled causal metric learning for pre-travel out-of-town recommendation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fast and continual knowledge graph embedding via incremental
LoRA. <em>IJCAI</em>, 2198–2206. (<a
href="https://doi.org/10.24963/ijcai.2024/243">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Continual Knowledge Graph Embedding (CKGE) aims to efficiently learn new knowledge and simultaneously preserve old knowledge. Dominant approaches primarily focus on alleviating catastrophic forgetting of old knowledge but neglect efficient learning for the emergence of new knowledge. However, in real-world scenarios, knowledge graphs (KGs) are continuously growing, which brings a significant challenge to fine-tuning KGE models efficiently. To address this issue, we propose a fast CKGE framework (FastKGE), incorporating an incremental low-rank adapter (IncLoRA) mechanism to efficiently acquire new knowledge while preserving old knowledge. Specifically, to mitigate catastrophic forgetting, FastKGE isolates and allocates new knowledge to specific layers based on the fine-grained influence between old and new KGs. Subsequently, to accelerate fine-tuning, FastKGE devises an efficient IncLoRA mechanism, which embeds the specific layers into incremental low-rank adapters with fewer training parameters. Moreover, IncLoRA introduces adaptive rank allocation, which makes the LoRA aware of the importance of entities and adjusts its rank scale adaptively. We conduct experiments on four public datasets and two new datasets with a larger initial scale. Experimental results demonstrate that FastKGE can reduce training time by 34%-49% while still achieving competitive link prediction performance against state-of-the-art models on four public datasets (average MRR score of 21.0% vs. 21.1%). Meanwhile, on two newly constructed datasets, FastKGE saves 51%-68% training time and improves link prediction performance by 1.5%. Keywords: Data Mining: DM: Knowledge graphs and knowledge base completion},
  archive   = {C_IJCAI},
  author    = {Jiajun Liu and Wenjun Ke and Peng Wang and Jiahao Wang and Jinhua Gao and Ziyu Shang and Guozheng Li and Zijie Xu and Ke Ji and Yining Li},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/243},
  month     = {8},
  pages     = {2198-2206},
  title     = {Fast and continual knowledge graph embedding via incremental LoRA},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Encoding auxiliary information to restore compressed point
cloud geometry. <em>IJCAI</em>, 2189–2197. (<a
href="https://doi.org/10.24963/ijcai.2024/242">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The standardized Geometry-based Point Cloud Compression (G-PCC) suffers from limited coding performance and low-quality reconstruction. To address this, we propose AuxGR, a performance-complexity tradeoff solution for point cloud geometry restoration: leveraging auxiliary bitstream to enhance the quality of G-PCC compressed point cloud geometry. This auxiliary bitstream efficiently encapsulates spatio-temporal information. For static coding, we perform paired information embedding (PIE) on the G-PCC decoded frame by employing target convolutions from its original counterpart, producing an auxiliary bitstream containing abundant original information. For dynamic coding, in addition to PIE, we propose temporal information embedding (TIE) to capture motion information between the previously restored and the current G-PCC decoded frames. TIE applies target kNN attention between them, which ensures the temporal neighborhood construction for each point and implicitly represents motions. Due to the similarity across temporal frames, only the residuals between TIE and PIE outputs are compressed as auxiliary bitstream. Experimental results demonstrate that AuxGR notably outperforms existing methods in both static and dynamic coding scenarios. Moreover, our framework enables the flexible incorporation of auxiliary information under computation constraints, which is attractive to real applications. Keywords: Data Mining: DM: Mining spatial and/or temporal data},
  archive   = {C_IJCAI},
  author    = {Gexin Liu and Jiahao Zhu and Dandan Ding and Zhan Ma},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/242},
  month     = {8},
  pages     = {2189-2197},
  title     = {Encoding auxiliary information to restore compressed point cloud geometry},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Where to mask: Structure-guided masking for graph masked
autoencoders. <em>IJCAI</em>, 2180–2188. (<a
href="https://doi.org/10.24963/ijcai.2024/241">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph masked autoencoders (GMAE) have emerged as a significant advancement in self-supervised pre-training for graph-structured data. Previous GMAE models primarily utilize a straightforward random masking strategy for nodes or edges during training. However, this strategy fails to consider the varying significance of different nodes within the graph structure. In this paper, we investigate the potential of leveraging the graph&#39;s structural composition as a fundamental and unique prior in the masked pre-training process. To this end, we introduce a novel structure-guided masking strategy (i.e., StructMAE), designed to refine the existing GMAE models. StructMAE involves two steps: 1) Structure-based Scoring: Each node is evaluated and assigned a score reflecting its structural significance. Two distinct types of scoring manners are proposed: predefined and learnable scoring. 2) Structure-guided Masking: With the obtained assessment scores, we develop an easy-to-hard masking strategy that gradually increases the structural awareness of the self-supervised reconstruction task. Specifically, the strategy begins with random masking and progresses to masking structure-informative nodes based on the assessment scores. This design gradually and effectively guides the model in learning graph structural information. Furthermore, extensive experiments consistently demonstrate that our StructMAE method outperforms existing state-of-the-art GMAE models in both unsupervised and transfer learning tasks. Codes are available at https: //github.com/LiuChuang0059/StructMAE. Keywords: Data Mining: DM: Mining graphs Machine Learning: ML: Self-supervised Learning},
  archive   = {C_IJCAI},
  author    = {Chuang Liu and Yuyao Wang and Yibing Zhan and Xueqi Ma and Dapeng Tao and Jia Wu and Wenbin Hu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/241},
  month     = {8},
  pages     = {2180-2188},
  title     = {Where to mask: Structure-guided masking for graph masked autoencoders},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Gradformer: Graph transformer with exponential decay.
<em>IJCAI</em>, 2171–2179. (<a
href="https://doi.org/10.24963/ijcai.2024/240">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph Transformers (GTs) have demonstrated their advantages across a wide range of tasks. However, the self-attention mechanism in GTs overlooks the graph&#39;s inductive biases, particularly biases related to structure, which are crucial for the graph tasks. Although some methods utilize positional encoding and attention bias to model inductive biases, their effectiveness is still suboptimal analytically. Therefore, this paper presents Gradformer, a method innovatively integrating GT with the intrinsic inductive bias by applying an exponential decay mask to the attention matrix. Specifically, the values in the decay mask matrix diminish exponentially, correlating with the decreasing node proximities within the graph structure. This design enables Gradformer to retain its ability to capture information from distant nodes while focusing on the graph&#39;s local details. Furthermore, Gradformer introduces a learnable constraint into the decay mask, allowing different attention heads to learn distinct decay masks. Such an design diversifies the attention heads, enabling a more effective assimilation of diverse structural information within the graph. Extensive experiments on various benchmarks demonstrate that Gradformer consistently outperforms the Graph Neural Network and GT baseline models in various graph classification and regression tasks. Additionally, Gradformer has proven to be an effective method for training deep GT models, maintaining or even enhancing accuracy compared to shallow models as the network deepens, in contrast to the significant accuracy drop observed in other GT models. Codes are available at https://github.com/LiuChuang0059/Gradformer. Keywords: Data Mining: DM: Mining graphs Machine Learning: ML: Classification},
  archive   = {C_IJCAI},
  author    = {Chuang Liu and Zelin Yao and Yibing Zhan and Xueqi Ma and Shirui Pan and Wenbin Hu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/240},
  month     = {8},
  pages     = {2171-2179},
  title     = {Gradformer: Graph transformer with exponential decay},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Large language model guided knowledge distillation for time
series anomaly detection. <em>IJCAI</em>, 2162–2170. (<a
href="https://doi.org/10.24963/ijcai.2024/239">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Self-supervised methods have gained prominence in time series anomaly detection due to the scarcity of available annotations. Nevertheless, they typically demand extensive training data to acquire a generalizable representation map, which conflicts with scenarios of a few available samples, thereby limiting their performance. To overcome the limitation, we propose AnomalyLLM, a knowledge distillation-based time series anomaly detection approach where the student network is trained to mimic the features of the large language model (LLM)-based teacher network that is pretrained on large-scale datasets. During the testing phase, anomalies are detected when the discrepancy between the features of the teacher and student networks is large. To circumvent the student network from learning the teacher network’s feature of anomalous samples, we devise two key strategies. 1) Prototypical signals are incorporated into the student network to consolidate the normal feature extraction. 2) We use synthetic anomalies to enlarge the representation gap between the two networks. AnomalyLLM demonstrates state-of-the-art performance on 15 datasets, improving accuracy by at least 14.5% in the UCR dataset. Keywords: Data Mining: DM: Anomaly/outlier detection Data Mining: DM: Mining spatial and/or temporal data Machine Learning: ML: Unsupervised learning},
  archive   = {C_IJCAI},
  author    = {Chen Liu and Shibo He and Qihang Zhou and Shizhong Li and Wenchao Meng},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/239},
  month     = {8},
  pages     = {2162-2170},
  title     = {Large language model guided knowledge distillation for time series anomaly detection},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing dual-target cross-domain recommendation with
federated privacy-preserving learning. <em>IJCAI</em>, 2153–2161. (<a
href="https://doi.org/10.24963/ijcai.2024/238">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, dual-target cross-domain recommendation (DTCDR) has been proposed to alleviate the data sparsity problem by sharing the common knowledge across domains simultaneously. However, existing methods often assume that personal data containing abundant identifiable information can be directly accessed, which results in a controversial privacy leakage problem of DTCDR. To this end, we introduce the P2DTR framework, a novel approach in DTCDR while protecting private user information. Specifically, we first design a novel inter-client knowledge extraction mechanism, which exploits the private set intersection algorithm and prototype-based federated learning to enable collaboratively modeling among multiple users and a server. Furthermore, to improve the recommendation performance based on the extracted common knowledge across domains, we proposed an intra-client enhanced recommendation, consisting of a constrained dominant set (CDS) propagation mechanism and dual-recommendation module. Extensive experiments on real-world datasets validate that our proposed P2DTR framework achieves superior utility under a privacy-preserving guarantee on both domains. Keywords: Data Mining: DM: Recommender systems Data Mining: DM: Applications Data Mining: DM: Privacy-preserving data mining},
  archive   = {C_IJCAI},
  author    = {Zhenghong Lin and Wei Huang and Hengyu Zhang and Jiayu Xu and Weiming Liu and Xinting Liao and Fan Wang and Shiping Wang and Yanchao Tan},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/238},
  month     = {8},
  pages     = {2153-2161},
  title     = {Enhancing dual-target cross-domain recommendation with federated privacy-preserving learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Rethinking the effectiveness of graph classification
datasets in benchmarks for assessing GNNs. <em>IJCAI</em>, 2144–2152.
(<a href="https://doi.org/10.24963/ijcai.2024/237">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph classification benchmarks, vital for assessing and developing graph neural network (GNN) models, have recently been scrutinized, as simple methods like MLPs have demonstrated comparable performance. This leads to an important question: Do these benchmarks effectively distinguish the advancements of GNNs over other methodologies? If so, how do we quantitatively measure this effectiveness? In response, we first propose an empirical protocol based on a fair benchmarking framework to investigate the performance discrepancy between simple methods and GNNs. We further propose a novel metric to quantify the dataset effectiveness by considering both dataset complexity and model performance. To the best of our knowledge, our work is the first to thoroughly study and provide an explicit definition for dataset effectiveness in the graph learning area. Through testing across 16 real-world datasets, we found our metric to align with existing studies and intuitive assumptions. Finally, we explore the causes behind the low effectiveness of certain datasets by investigating the correlation between intrinsic graph properties and class labels, and we developed a novel technique supporting the correlation-controllable synthetic dataset generation. Our findings shed light on the current understanding of benchmark datasets, and our new platform could fuel the future evolution of graph classification benchmarks. Keywords: Data Mining: DM: Mining graphs Machine Learning: ML: Classification Machine Learning: ML: Representation learning Machine Learning: ML: Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Zhengdao Li and Yong Cao and Kefan Shuai and Yiming Miao and Kai Hwang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/237},
  month     = {8},
  pages     = {2144-2152},
  title     = {Rethinking the effectiveness of graph classification datasets in benchmarks for assessing GNNs},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). LLM-based multi-level knowledge generation for few-shot
knowledge graph completion. <em>IJCAI</em>, 2135–2143. (<a
href="https://doi.org/10.24963/ijcai.2024/236">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Knowledge Graphs (KGs) are pivotal in various NLP applications but often grapple with incompleteness, especially due to the long-tail problem where infrequent, unpopular relationships drastically reduce the KG completion performance. In this paper, we focus on Few-shot Knowledge Graph Completion (FKGC), a task addressing these gaps in long-tail scenarios. Amidst the rapid evolution of Large Language Models, we propose a generation-based FKGC paradigm facilitated by LLM distillation. Our MuKDC framework employs multi-level knowledge distillation for few-shot KG completion, generating supplementary knowledge to mitigate data scarcity in few-shot environments. MuKDC comprises two primary components: Multi-level Knowledge Generation, which enriches the KG at various levels, and Consistency Assessment, to ensure the coherence and reliability of the generated knowledge. Most notably, our method achieves SOTA results in both FKGC and multi-modal FKGC benchmarks, significantly advancing KG completion and enhancing the understanding and application of LLMs in structured knowledge generation and assessment. Keywords: Data Mining: DM: Knowledge graphs and knowledge base completion Natural Language Processing: NLP: Applications},
  archive   = {C_IJCAI},
  author    = {Qian Li and Zhuo Chen and Cheng Ji and Shiqi Jiang and Jianxin Li},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/236},
  month     = {8},
  pages     = {2135-2143},
  title     = {LLM-based multi-level knowledge generation for few-shot knowledge graph completion},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Contrastive learning drug response models from natural
language supervision. <em>IJCAI</em>, 2126–2134. (<a
href="https://doi.org/10.24963/ijcai.2024/235">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep learning-based drug response prediction (DRP) methods can accelerate the drug discovery process and reduce research and development costs. Despite their high accuracy, generating regression-aware representations remains challenging for mainstream approaches. For instance, the representations are often disordered, aggregated, and overlapping, and they fail to characterize distinct samples effectively. This results in poor representation during the DRP task, diminishing generalizability and potentially leading to substantial costs during the drug discovery. In this paper, we propose CLDR, a contrastive learning framework with natural language supervision for the DRP. The CLDR converts regression labels into text, which is merged with the drug response caption as a second sample modality instead of the traditional modes, i.e., graphs and sequences. Simultaneously, a common-sense numerical knowledge graph is introduced to improve the continuous text representation. Our framework is validated using the genomics of drug sensitivity in cancer dataset with average performance increases ranging from 7.8% to 31.4%. Furthermore, experiments demonstrate that the proposed CLDR effectively maps samples with distinct label values into a high-dimensional space. In this space, the sample representations are scattered, significantly alleviating feature overlap. The code is available at: https://github.com/DrugD/CLDR. Keywords: Data Mining: DM: Mining graphs Data Mining: DM: Knowledge graphs and knowledge base completion Multidisciplinary Topics and Applications: MTA: Bioinformatics},
  archive   = {C_IJCAI},
  author    = {Kun Li and Xiuwen Gong and Jia Wu and Wenbin Hu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/235},
  month     = {8},
  pages     = {2126-2134},
  title     = {Contrastive learning drug response models from natural language supervision},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Zero-shot learning for preclinical drug screening.
<em>IJCAI</em>, 2117–2125. (<a
href="https://doi.org/10.24963/ijcai.2024/234">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Conventional deep learning methods typically employ supervised learning for drug response prediction (DRP). This entails dependence on labeled response data from drugs for model training. However, practical applications in the preclinical drug screening phase demand that DRP models predict responses for novel compounds, often with unknown drug responses. This presents a challenge, rendering supervised deep learning methods unsuitable for such scenarios. In this paper, we propose a zero-shot learning solution for the DRP task in preclinical drug screening. Specifically, we propose a Multi-branch Multi-Source Domain Adaptation Test Enhancement Plug-in, called MSDA. MSDA can be seamlessly integrated with conventional DRP methods, learning invariant features from the prior response data of similar drugs to enhance real-time predictions of unlabeled compounds. The results of experiments on two large drug response datasets showed that MSDA efficiently predicts drug responses for novel compounds, leading to a general performance improvement of 5-10% in the preclinical drug screening phase. The significance of this solution resides in its potential to accelerate the drug discovery process, improve drug candidate assessment, and facilitate the success of drug discovery. The code is available at https://github.com/DrugD/MSDA. Keywords: Data Mining: DM: Mining graphs Data Mining: DM: Knowledge graphs and knowledge base completion Multidisciplinary Topics and Applications: MTA: Bioinformatics},
  archive   = {C_IJCAI},
  author    = {Kun Li and Weiwei Liu and Yong Luo and Xiantao Cai and Jia Wu and Wenbin Hu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/234},
  month     = {8},
  pages     = {2117-2125},
  title     = {Zero-shot learning for preclinical drug screening},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PHSIC against random consistency and its application in
causal inference. <em>IJCAI</em>, 2108–2116. (<a
href="https://doi.org/10.24963/ijcai.2024/233">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Hilbert-Schmidt Independence Criterion (HSIC) based on kernel functions is capable of detecting nonlinear dependencies between variables, making it a common method for association relationship mining. However, in situations with small samples, high dimensions, or noisy data, it may generate spurious associations, causing two unrelated variables to have certain scores. To address this issue, we propose a novel criterion, named as Pure Hilbert-Schmidt Independence Criterion (PHSIC). PHSIC is achieved by subtracting the mean HSIC obtained under random conditions from the original HSIC value. We demonstrate three significant advantages of PHSIC through theoretical and simulation experiments: (1) PHSIC has a baseline of zero, enhancing the interpretability of HSIC. (2) Compared to HSIC, PHSIC exhibits lower bias. (3) PHSIC enables a fairer comparison across different samples and dimensions. To validate the effectiveness of PHSIC, we apply it to multiple causal inference tasks to measure the independence between cause and residual. Experimental results demonstrate that the causal model based on PHSIC performs well compared to other methods in scenarios involving small sample sizes and noisy data, both in real and simulated datasets. Keywords: Data Mining: DM: Exploratory data mining AI Ethics, Trust, Fairness: ETF: Trustworthy AI Machine Learning: ML: Causality},
  archive   = {C_IJCAI},
  author    = {Jue Li and Yuhua Qian and Jieting Wang and Saixiong Liu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/233},
  month     = {8},
  pages     = {2108-2116},
  title     = {PHSIC against random consistency and its application in causal inference},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hierarchical reinforcement learning on multi-channel
hypergraph neural network for course recommendation. <em>IJCAI</em>,
2099–2107. (<a href="https://doi.org/10.24963/ijcai.2024/232">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With the widespread popularity of massive open online courses, personalized course recommendation has become increasingly important due to enhancing users&#39; learning efficiency. While achieving promising performances, current works suffering from the vary across the users and other MOOC entities. To address this problem, we propose hierarchical reinforcement learning with a multi-channel hypergraphs neural network for course recommendation(called HHCoR). Specifically, we first construct an online course hypergraph as the environment to capture the complex relationships and historical information by considering all entities. Then, we design a multi-channel propagation mechanism to aggregate embeddings in the online course hypergraph and extract user interest through an attention layer. Besides, we employ two-level decision-making: the low-level focuses on the rating courses, while the high-level integrates these considerations to finalize the decision. Furthermore, in co-optimization, we design a joint reward function to improve the policy of two-layer agents. Finally, we conducted extensive experiments on two real-world datasets and the quantitative results have demonstrated the effectiveness of the proposed method. Keywords: Data Mining: DM: Applications Data Mining: DM: Mining graphs Data Mining: DM: Mining heterogenous data Data Mining: DM: Mining spatial and/or temporal data},
  archive   = {C_IJCAI},
  author    = {Lu Jiang and Yanan Xiao and Xinxin Zhao and Yuanbo Xu and Shuli Hu and Pengyang Wang and Minghao Yin},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/232},
  month     = {8},
  pages     = {2099-2107},
  title     = {Hierarchical reinforcement learning on multi-channel hypergraph neural network for course recommendation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning hierarchy-enhanced POI category representations
using disentangled mobility sequences. <em>IJCAI</em>, 2090–2098. (<a
href="https://doi.org/10.24963/ijcai.2024/231">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Points of interest (POIs) carry a wealth of semantic information of varying locations in cities and thus have been widely used to enable various location-based services. To understand POI semantics, existing methods usually model contextual correlations of POI categories in users&#39; check-in sequences and embed categories into a latent space based on the word2vec framework. However, such an approach does not fully capture the underlying hierarchical relationship between POI categories and can hardly integrate the category hierarchy into various deep sequential models. To overcome this shortcoming, we propose a Semantically Disentangled POI Category Embedding Model (SD-CEM) to generate hierarchy-enhanced category representations using disentangled mobility sequences. Specifically, first, we construct disentangled mobility sequences using human mobility data based on the semantics of POIs. Then we utilize the POI category hierarchy to initialize a hierarchy-enhanced representation for each category in the disentangled sequences, employing an attention mechanism. Finally, we optimize these category representations by incorporating both the masked category prediction task and the next category prediction task. To evaluate the effectiveness of SD-CEM, we conduct comprehensive experiments using two check-in datasets covering three tasks. Experimental results demonstrate that SD-CEM outperforms several competitive baselines, highlighting its substantial improvement in performance as well as the understanding of learned category representations. Keywords: Data Mining: DM: Mining spatial and/or temporal data},
  archive   = {C_IJCAI},
  author    = {Hongwei Jia and Meng Chen and Weiming Huang and Kai Zhao and Yongshun Gong},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/231},
  month     = {8},
  pages     = {2090-2098},
  title     = {Learning hierarchy-enhanced POI category representations using disentangled mobility sequences},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multiplex graph representation learning via bi-level
optimization. <em>IJCAI</em>, 2081–2089. (<a
href="https://doi.org/10.24963/ijcai.2024/230">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Many multiplex graph representation learning (MGRL) methods have been demonstrated to 1) ignore the globally positive and negative relationships among node features; and 2) usually utilize the node classification task to train both graph structure learning and representation learning parameters, and thus resulting in the problem of edge starvation. To address these issues, in this paper, we propose a new MGRL method based on the bi-level optimization. Specifically, in the inner level, we optimize the self-expression matrix to capture the globally positive and negative relationships among nodes, as well as complement them with the local relationships in graph structures. In the outer level, we optimize the parameters of the graph convolutional layer to obtain discriminative node representations. As a result, the graph structure optimization does not depend on the node classification task, which solves the edge starvation problem. Extensive experiments show that our model achieves the superior performance on node classification tasks on all datasets. Keywords: Data Mining: DM: Mining graphs Data Mining: DM: Mining heterogenous data},
  archive   = {C_IJCAI},
  author    = {Yudi Huang and Yujie Mo and Yujing Liu and Ci Nie and Guoqiu Wen and Xiaofeng Zhu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/230},
  month     = {8},
  pages     = {2081-2089},
  title     = {Multiplex graph representation learning via bi-level optimization},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploring the role of node diversity in directed graph
representation learning. <em>IJCAI</em>, 2072–2080. (<a
href="https://doi.org/10.24963/ijcai.2024/229">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Many methods of Directed Graph Neural Networks (DGNNs) are designed to equally treat nodes in the same neighbor set (i.e., out-neighbor set and in-neighbor set) for every node, without considering the node diversity in directed graphs, so they are often unavailable to adaptively acquire suitable information from neighbors of different directions. To alleviate this issue, in this paper, we investigate a new way to first consider node diversity for representation learning on directed graphs, i.e., neighbor diversity and degree diversity, and then propose a new NDDGNN framework to adaptively assign weights to both outgoing information and incoming information at the node level. Extensive experiments on seven real-world datasets validate the superior performance of our method compared to state-of-the-art methods in terms of both node classification and link prediction tasks. Keywords: Data Mining: DM: Mining graphs Machine Learning: ML: Representation learning Machine Learning: ML: Semi-supervised learning},
  archive   = {C_IJCAI},
  author    = {Jincheng Huang and Yujie Mo and Ping Hu and Xiaoshuang Shi and Shangbo Yuan and Zeyu Zhang and Xiaofeng Zhu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/229},
  month     = {8},
  pages     = {2072-2080},
  title     = {Exploring the role of node diversity in directed graph representation learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reconstructing missing variables for multivariate time
series forecasting via conditional generative flows. <em>IJCAI</em>,
2063–2071. (<a href="https://doi.org/10.24963/ijcai.2024/228">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Variable Subset Forecasting (VSF) problem, where the majority of variables are unavailable in the inference stage of multivariate forecasting, has been an important but under-explored task with broad impacts in many real-world applications. Missing values, absent inter-correlation, and the impracticality of retraining largely hinder the ability of multivariate forecasting models to capture inherent relationships among variables, impacting their performance. However, existing approaches towards these issues either heavily rely on local temporal correlation or face limitations in fully recovering missing information from the unavailable subset, accompanied by notable computational expenses. To address these problems, we propose a novel density estimation solution to recover the information of missing variables via flows-based generative framework. In particular, a novel generative network for time series, namely Time-series Reconstruction Flows (TRF), is proposed to estimate and reconstruct the missing variable subset. In addition, a novel meta-training framework, Variable-Agnostic Meta Learning, has been developed to enhance the generalization ability of TRF, enabling it to adapt to diverse missing variables situations. Finally, extensive experiments are conducted to demonstrate the superiority of our proposed method compared with baseline methods. Keywords: Data Mining: DM: Mining spatial and/or temporal data},
  archive   = {C_IJCAI},
  author    = {Xuanming Hu and Wei Fan and Haifeng Chen and Pengyang Wang and Yanjie Fu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/228},
  month     = {8},
  pages     = {2063-2071},
  title     = {Reconstructing missing variables for multivariate time series forecasting via conditional generative flows},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SVD-AE: Simple autoencoders for collaborative filtering.
<em>IJCAI</em>, 2054–2062. (<a
href="https://doi.org/10.24963/ijcai.2024/227">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Collaborative filtering (CF) methods for recommendation systems have been extensively researched, ranging from matrix factorization and autoencoder-based to graph filtering-based methods. Recently, lightweight methods that require almost no training have been recently proposed to reduce overall computation. However, existing methods still have room to improve the trade-offs among accuracy, efficiency, and robustness. In particular, there are no well-designed closed-form studies for balanced CF in terms of the aforementioned trade-offs. In this paper, we design SVD-AE, a simple yet effective singular vector decomposition (SVD)-based linear autoencoder, whose closed-form solution can be defined based on SVD for CF. SVD-AE does not require iterative training processes as its closed-form solution can be calculated at once. Furthermore, given the noisy nature of the rating matrix, we explore the robustness against such noisy interactions of existing CF methods and our SVD-AE. As a result, we demonstrate that our simple design choice based on truncated SVD can be used to strengthen the noise robustness of the recommendation while improving efficiency. Code is available at https://github.com/seoyoungh/svd-ae. Keywords: Data Mining: DM: Collaborative filtering Multidisciplinary Topics and Applications: MTA: Web and social networks Data Mining: DM: Information retrieval},
  archive   = {C_IJCAI},
  author    = {Seoyoung Hong and Jeongwhan Choi and Yeon-Chang Lee and Srijan Kumar and Noseong Park},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/227},
  month     = {8},
  pages     = {2054-2062},
  title     = {SVD-AE: Simple autoencoders for collaborative filtering},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Class-specific semantic generation and reconstruction
learning for open set recognition. <em>IJCAI</em>, 2045–2053. (<a
href="https://doi.org/10.24963/ijcai.2024/226">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Open set recognition is a crucial research theme for open-environment machine learning. For this problem, a common solution is to learn compact representations of known classes and identify unknown samples by measuring deviations from these known classes. However, the aforementioned methods (1) lack open training consideration, which is detrimental to the fitting of known classes, and (2) recognize unknown classes on an inadequate basis, which limits the accuracy of recognition. In this study, we propose an open reconstruction learning framework that learns a union boundary region of known classes to characterize unknown space. This facilitates the isolation of known space from unknown space to represent known classes compactly and provides a more reliable recognition basis from the perspective of both known and unknown space. Specifically, an adversarial constraint is used to generate class-specific boundary samples. Then, the known classes and approximate unknown space are fitted with manifolds represented by class-specific auto-encoders. Finally, the auto-encoders output the reconstruction error in terms of known and unknown spaces to recognize samples. Extensive experimental results show that the proposed method outperforms existing advanced methods and achieves new stateof-the-art performance. The code is available at https://github.com/Ashowman98/CSGRL. Keywords: Data Mining: DM: Other Data Mining: DM: Anomaly/outlier detection},
  archive   = {C_IJCAI},
  author    = {Liu Haoyang and Yaojin Lin and Peipei Li and Jun Hu and Xuegang Hu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/226},
  month     = {8},
  pages     = {2045-2053},
  title     = {Class-specific semantic generation and reconstruction learning for open set recognition},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Real-world networks are low-dimensional: Theoretical and
practical assessment. <em>IJCAI</em>, 2036–2044. (<a
href="https://doi.org/10.24963/ijcai.2024/225">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent empirical evidence suggests that real-world networks have very low underlying dimensionality. We provide a theoretical explanation for this phenomenon as well as develop a linear-time algorithm for detecting the underlying dimensionality of such networks. Our theoretical analysis considers geometric inhomogeneous random graphs (GIRGs), a geometric random graph model, which captures a variety of properties observed in real-world networks. These properties include a heterogeneous degree distribution and non-vanishing clustering coefficient, which is the probability that two random neighbors of a vertex are adjacent. Our first result shows that the clustering coefficient of GIRGs scales inverse exponentially with respect to the number of dimensions d, when the latter is at most logarithmic in n, the number of vertices. Hence, for a GIRG to behave like many real-world networks and have a non-vanishing clustering coefficient, it must come from a geometric space of o(log n) dimensions. Our analysis on GIRGs allows us to obtain a linear-time algorithm for determining the dimensionality of a network. Our algorithm bridges the gap between theory and practice, as it comes with a rigorous proof of correctness and yields results comparable to prior empirical approaches, as indicated by our experiments on real-world instances. The efficiency of our algorithm makes it applicable to very large data-sets. We conclude that very low dimensionalities (from 1 to 10) are needed to explain properties of real-world networks. Keywords: Data Mining: DM: Networks Data Mining: DM: Theoretical foundations of data mining},
  archive   = {C_IJCAI},
  author    = {Tobias Friedrich and Andreas Göbel and Maximilian Katzmann and Leon Schiller},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/225},
  month     = {8},
  pages     = {2036-2044},
  title     = {Real-world networks are low-dimensional: Theoretical and practical assessment},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DGR: A general graph desmoothing framework for
recommendation via global and local perspectives. <em>IJCAI</em>,
2027–2035. (<a href="https://doi.org/10.24963/ijcai.2024/224">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph Convolutional Networks (GCNs) have become pivotal in recommendation systems for learning user and item embeddings by leveraging the user-item interaction graph&#39;s node information and topology. However, these models often face the famous over-smoothing issue, leading to indistinct user and item embeddings and reduced personalization. Traditional desmoothing methods in GCN-based systems are model-specific, lacking a universal solution. This paper introduces a novel, model-agnostic approach named Desmoothing Framework for GCN-based Recommendation Systems (DGR). It effectively addresses over-smoothing on general GCN-based recommendation models by considering both global and local perspectives. Specifically, we first introduce vector perturbations during each message passing layer to penalize the tendency of node embeddings approximating overly to be similar with the guidance of the global topological structure. Meanwhile, we further develop a tailored-design loss term for the readout embeddings to preserve the local collaborative relations between users and their neighboring items. In particular, items that exhibit a high correlation with neighboring items are also incorporated to enhance the local topological information. To validate our approach, we conduct extensive experiments on 5 benchmark datasets based on 5 well-known GCN-based recommendation models, demonstrating the effectiveness and generalization of our proposed framework. Our code is available at https://github.com/me-sonandme/DGR. Keywords: Data Mining: DM: Collaborative filtering Data Mining: DM: Recommender systems},
  archive   = {C_IJCAI},
  author    = {Leilei Ding and Dazhong Shen and Chao Wang and Tianfu Wang and Le Zhang and Yanyong Zhang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/224},
  month     = {8},
  pages     = {2027-2035},
  title     = {DGR: A general graph desmoothing framework for recommendation via global and local perspectives},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-modality spatio-temporal forecasting via
self-supervised learning. <em>IJCAI</em>, 2018–2026. (<a
href="https://doi.org/10.24963/ijcai.2024/223">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-modality spatio-temporal (MoST) data extends spatio-temporal (ST) data by incorporating multiple modalities, which is prevalent in monitoring systems, encompassing diverse traffic demands and air quality assessments. Despite significant strides in ST modeling in recent years, there remains a need to emphasize harnessing the potential of information from different modalities. Robust MoST forecasting is more challenging because it possesses (i) high-dimensional and complex internal structures and (ii) dynamic heterogeneity caused by temporal, spatial, and modality variations. In this study, we propose a novel MoST learning framework via Self-Supervised Learning, namely MoSSL, which aims to uncover latent patterns from temporal, spatial, and modality perspectives while quantifying dynamic heterogeneity. Experiment results on two real-world MoST datasets verify the superiority of our approach compared with the state-of-the-art baselines. Model implementation is available at https://github.com/beginner-sketch/MoSSL. Keywords: Data Mining: DM: Mining spatial and/or temporal data Knowledge Representation and Reasoning: KRR: Qualitative, geometric, spatial, and temporal reasoning Machine Learning: ML: Time series and data streams},
  archive   = {C_IJCAI},
  author    = {Jiewen Deng and Renhe Jiang and Jiaqi Zhang and Xuan Song},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/223},
  month     = {8},
  pages     = {2018-2026},
  title     = {Multi-modality spatio-temporal forecasting via self-supervised learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pre-DyGAE: Pre-training enhanced dynamic graph autoencoder
for occupational skill demand forecasting. <em>IJCAI</em>, 2009–2017.
(<a href="https://doi.org/10.24963/ijcai.2024/222">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Occupational skill demand (OSD) forecasting seeks to predict dynamic skill demand specific to occupations, beneficial for employees and employers to grasp occupational nature and maintain a competitive edge in the rapidly evolving labor market. Although recent research has proposed data-driven techniques for forecasting skill demand, the focus has remained predominantly on overall trends rather than occupational granularity. In this paper, we propose a novel Pre-training Enhanced Dynamic Graph Autoencoder (Pre-DyGAE), forecasting skill demand from an occupational perspective. Specifically, we aggregate job descriptions (JDs) by occupation and segment them into several timestamps. Subsequently, in the initial timestamps, we pre-train a graph autoencoder (GAE), consisting of a semantically-aware cross-attention enhanced uncertainty-aware encoder and decoders for link prediction and edge regression to achieve graph reconstruction. In particular, we utilize contrastive learning on skill cooccurrence clusters to solve the data sparsity and a unified Tweedie and ranking loss for predicting the imbalanced distribution. Afterward, we incorporate an adaptive temporal encoding unit and a temporal shift module into GAE to achieve a dynamic GAE (DyGAE). Furthermore, we fine-tune the DyGAE with a two-stage optimization strategy and infer future representations. Extensive experiments on four real-world datasets validate the effectiveness of Pre-DyGAE compared with state-of-the-art baselines. Keywords: Data Mining: DM: Applications Data Mining: DM: Mining spatial and/or temporal data},
  archive   = {C_IJCAI},
  author    = {Xi Chen and Chuan Qin and Zhigaoyuan Wang and Yihang Cheng and Chao Wang and Hengshu Zhu and Hui Xiong},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/222},
  month     = {8},
  pages     = {2009-2017},
  title     = {Pre-DyGAE: Pre-training enhanced dynamic graph autoencoder for occupational skill demand forecasting},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Automatic de-biased temporal-relational modeling for stock
investment recommendation. <em>IJCAI</em>, 1999–2008. (<a
href="https://doi.org/10.24963/ijcai.2024/221">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Stock investment recommendation is crucial for guiding investment decisions and managing portfolios. Recent studies have demonstrated the potential of temporal-relational models (TRM) to yield excess investment returns. However, in the complicated finance ecosystem, the current TRM suffer from both the intrinsic temporal bias from the low signal-to-noise ratio (SNR) and the relational bias caused by utilizing inappropriate relational topologies and propagation mechanisms. Moreover, the distribution shifts behind macro-market scenarios invalidate the underlying i.i.d. assumption and limit the generalization ability of TRM. In this paper, we pioneer the impact of the above issues on the effective learning of temporal-relational patterns and propose an Automatic De-Biased Temporal-Relational Model (ADB-TRM) for stock recommendation. Specifically, ADB-TRM consists of three main components, i.e., (i) a meta-learned architecture forms a dual-stage training process, with the inner part ameliorating temporal-relational bias and the outer meta-learner counteracting distribution shifts, (ii) automatic adversarial sample generation guides the model adaptively to alleviate bias and enhance its profiling ability through adversarial training, and (iii) global-local interaction helps seek relative invariant stock embeddings from local and global distribution perspectives to mitigate distribution shifts. Experiments on three datasets from distinct stock markets show that ADB-TRM excels state-of-the-arts over 28.41% and 9.53% in terms of cumulative and risk-adjusted returns. Keywords: Data Mining: DM: Applications Data Mining: DM: Mining spatial and/or temporal data Machine Learning: ML: Time series and data streams Multidisciplinary Topics and Applications: MTA: Finance},
  archive   = {C_IJCAI},
  author    = {Weijun Chen and Shun Li and Xipu Yu and Heyuan Wang and Wei Chen and Tengjiao Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/221},
  month     = {8},
  pages     = {1999-2008},
  title     = {Automatic de-biased temporal-relational modeling for stock investment recommendation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Rethinking the soft conflict pseudo boolean constraint on
MaxSAT local search solvers. <em>IJCAI</em>, 1989–1997. (<a
href="https://doi.org/10.24963/ijcai.2024/220">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {MaxSAT is an optimization version of the famous NP-complete Satisfiability problem (SAT). Algorithms for MaxSAT mainly include complete solvers and local search incomplete solvers. In many complete solvers, once a better solution is found, a Soft conflict Pseudo Boolean (SPB) constraint will be generated to enforce the algorithm to find better solutions. In many local search algorithms, clause weighting is a key technique for effectively guiding the search directions. In this paper, we propose to transfer the SPB constraint into the clause weighting system of the local search method, leading the algorithm to better solutions. We further propose an adaptive clause weighting strategy that breaks the tradition of using constant values to adjust clause weights. Based on the above methods, we propose a new local search algorithm called SPB-MaxSAT that provides new perspectives for clause weighting on MaxSAT local search solvers. Extensive experiments demonstrate the excellent performance of the proposed methods. Keywords: Constraint Satisfaction and Optimization: CSO: Satisfiabilty Constraint Satisfaction and Optimization: CSO: Solvers and tools Search: S: Local search},
  archive   = {C_IJCAI},
  author    = {Jiongzhi Zheng and Zhuo Chen and Chu-Min Li and Kun He},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/220},
  month     = {8},
  pages     = {1989-1997},
  title     = {Rethinking the soft conflict pseudo boolean constraint on MaxSAT local search solvers},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). A multi-valued decision diagram-based approach to
constrained optimal path problems over directed acyclic graphs.
<em>IJCAI</em>, 1979–1988. (<a
href="https://doi.org/10.24963/ijcai.2024/219">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Numerous combinatorial optimization problems can be reduced to the optimal path problem over directed acyclic graphs (DAGs). The constrained version of the optimal path problem requires the solution to satisfy a given logical constraint. BDD-constrained search (BCS) is an efficient algorithm for the constrained optimal path problem over DAGs. This algorithm considers edges as variables and constraints as Boolean functions and maintains constraints via binary decision diagrams (BDDs), a compact form of Boolean functions. However, BCS involves redundant operations during the search process. To reduce these redundant operations, we use vertices instead of edges as variables and hence represent constraints as multi-valued functions. Due to the multi-valued representation of constraints, we propose a novel algorithm, namely MDD-constrained search (MCS), by using multi-valued decision diagrams (MDDs) instead of BDDs, an efficient representation of multi-valued functions. In addition, we improve MCS via domain reduction in multi-valued functions. Experimental results prove that our proposed algorithm outperforms BCS. Keywords: Constraint Satisfaction and Optimization: CSO: Constraint optimization problems Constraint Satisfaction and Optimization: CSO: Applications Constraint Satisfaction and Optimization: CSO: Solvers and tools Knowledge Representation and Reasoning: KRR: Knowledge compilation},
  archive   = {C_IJCAI},
  author    = {Mingwei Zhang and Liangda Fang and Zhenhao Gu and Quanlong Guan and Yong Lai},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/219},
  month     = {8},
  pages     = {1979-1988},
  title     = {A multi-valued decision diagram-based approach to constrained optimal path problems over directed acyclic graphs},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A neural column generation approach to the vehicle routing
problem with two-dimensional loading and last-in-first-out constraints.
<em>IJCAI</em>, 1970–1978. (<a
href="https://doi.org/10.24963/ijcai.2024/218">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The vehicle routing problem with two-dimensional loading constraints (2L-CVRP) and the last-in-first-out (LIFO) rule presents significant practical and algorithmic challenges. While numerous heuristic approaches have been proposed to address its complexity, stemming from two NP-hard problems: the vehicle routing problem (VRP) and the two-dimensional bin packing problem (2D-BPP), less attention has been paid to developing exact algorithms. Bridging this gap, this article presents an exact algorithm that integrates advanced machine learning techniques, specifically a novel combination of attention and recurrence mechanisms. This integration accelerates the state-of-the-art exact algorithm by a median of 29.79% across various problem instances. Moreover, the proposed algorithm successfully resolves an open instance in the standard test-bed, demonstrating significant improvements brought about by the incorporation of machine learning models. Code is available at https://github.com/xyfffff/NCG-for-2L-CVRP. Keywords: Constraint Satisfaction and Optimization: CSO: Constraint optimization problems Constraint Satisfaction and Optimization: CSO: Modeling Machine Learning: ML: Applications Multidisciplinary Topics and Applications: MTA: Transportation},
  archive   = {C_IJCAI},
  author    = {Yifan Xia and Xiangyi Zhang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/218},
  month     = {8},
  pages     = {1970-1978},
  title     = {A neural column generation approach to the vehicle routing problem with two-dimensional loading and last-in-first-out constraints},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improved parallel algorithm for non-monotone submodular
maximization under knapsack constraint. <em>IJCAI</em>, 1961–1969. (<a
href="https://doi.org/10.24963/ijcai.2024/217">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This work proposes an efficient parallel algorithm for non-monotone submodular maximization under a knapsack constraint problem over the ground set of size n. Our algorithm improves the best approximation factor of the existing parallel one from 8 to 7 with O(log n) adaptive complexity. The key idea of our approach is to create an alternate threshold algorithmic framework. This new strategy alternately constructs two disjoint candidate solutions within a constant number of sequence rounds. Then, the algorithm boosts solution quality without sacrificing the adaptive complexity. Extensive experimental studies on three applications, Revenue Maximization, Image Summarization, and Maximum Weighted Cut, show that our algorithm not only significantly increases solution quality but also requires comparative adaptivity to state-of-the-art algorithms. Keywords: Constraint Satisfaction and Optimization: CSO: Constraint optimization problems Constraint Satisfaction and Optimization: CSO: Applications Constraint Satisfaction and Optimization: CSO: Constraint learning and acquisition Data Mining: DM: Big data and scalability},
  archive   = {C_IJCAI},
  author    = {Tan D. Tran and Canh V. Pham and Dung T. K. Ha and Phuong N. H. Pham},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/217},
  month     = {8},
  pages     = {1961-1969},
  title     = {Improved parallel algorithm for non-monotone submodular maximization under knapsack constraint},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Convexity certificates for symbolic tensor expressions.
<em>IJCAI</em>, 1953–1960. (<a
href="https://doi.org/10.24963/ijcai.2024/216">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Knowing that a function is convex ensures that any local minimum is also a global minimum. Here, we implement an approach to certify the convexity of twice-differentiable functions by certifying that their second-order derivative is positive semidefinite. Both the computation of the second-order derivative and the certification of positive semidefiniteness are done symbolically. Previous implementations of this approach assume that the function to be minimized takes scalar or vector inputs, meaning that the second-order derivative is at most a matrix. However, the input of many machine learning problems is naturally given in the form of matrices or higher order tensors, in which case the second-order derivative becomes a tensor of at least fourth order. The familiar linear algebra notations and known rules for determining whether a matrix is positive semidefinite are not sufficient to deal with these higher order expressions. Here, we present a formal language for tensor expressions that allows us to generalize semidefiniteness to higher-order tensors and thereby certify the convexity of a broader set of functions. Keywords: Constraint Satisfaction and Optimization: CSO: Solvers and tools Machine Learning: ML: Optimization Machine Learning: ML: Symbolic methods},
  archive   = {C_IJCAI},
  author    = {Paul G. Rump and Niklas Merk and Julien Klaus and Maurice Wenig and Joachim Giesen},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/216},
  month     = {8},
  pages     = {1953-1960},
  title     = {Convexity certificates for symbolic tensor expressions},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing scalability of metric differential privacy via
secret dataset partitioning and benders decomposition. <em>IJCAI</em>,
1944–1952. (<a href="https://doi.org/10.24963/ijcai.2024/215">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Metric Differential Privacy (mDP) extends the concept of Differential Privacy (DP) to serve as a new paradigm of data perturbation. It is designed to protect secret data represented in general metric space, such as text data encoded as word embeddings or geo-location data on the road network or grid maps. To derive an optimal data perturbation mechanism under mDP, a widely used method is linear programming (LP), which, however, might suffer from a polynomial explosion of decision variables, rendering it impractical in large-scale mDP. In this paper, our objective is to develop a new computation framework to enhance the scalability of the LP-based mDP. Considering the connections established by the mDP constraints among the secret records, we partition the original secret dataset into various subsets. Building upon the partition, we reformulate the LP problem for mDP and solve it via Benders Decomposition, which is composed of two stages: (1) a master program to manage the perturbation calculation across subsets, and (2) a set of subproblems, each managing the perturbation derivation within a subset. Our experimental results on multiple datasets, including geo-location data in the road network/grid maps, text data, and synthetic data, underscore our proposed mechanism’s superior scalability and efficiency. Keywords: Constraint Satisfaction and Optimization: CSO: Constraint optimization problems Constraint Satisfaction and Optimization: CSO: Constraint programming Multidisciplinary Topics and Applications: MTA: Security and privacy},
  archive   = {C_IJCAI},
  author    = {Chenxi Qiu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/215},
  month     = {8},
  pages     = {1944-1952},
  title     = {Enhancing scalability of metric differential privacy via secret dataset partitioning and benders decomposition},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A fast algorithm for MaxSAT above half number of clauses.
<em>IJCAI</em>, 1935–1943. (<a
href="https://doi.org/10.24963/ijcai.2024/214">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the following parameterization of the MaxSAT problem: Given a CNF formula F with m clauses, decide whether at least m/2 + μ clauses in F could be satisfied, where μ is the excess of the number of satisfied clauses over the trivial lower bound m/2 and is taken as the parameter. This perspective is known as the &quot;above guarantee&quot; parameterization. Since its introduction by Mahajan and Raman [1999], the analysis of parameterization above guarantee has become a highly active and fruitful line of research. In this paper, we develop a new algorithm with runtime O*(2.1479^μ), significantly improving the previous best upper bound O*(5.4064^μ) for this important problem. Here, the O* notation omits polynomial factors. Keywords: Constraint Satisfaction and Optimization: CSO: Satisfiabilty Constraint Satisfaction and Optimization: CSO: Constraint optimization problems Constraint Satisfaction and Optimization: CSO: Constraint satisfaction Search: S: Combinatorial search and optimisation},
  archive   = {C_IJCAI},
  author    = {Junqiang Peng and Mingyu Xiao},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/214},
  month     = {8},
  pages     = {1935-1943},
  title     = {A fast algorithm for MaxSAT above half number of clauses},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bridging the gap between general and down-closed convex sets
in submodular maximization. <em>IJCAI</em>, 1926–1934. (<a
href="https://doi.org/10.24963/ijcai.2024/213">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Optimization of DR-submodular functions has experienced a notable surge in significance in recent times, marking a pivotal development within the domain of non-convex optimization. Motivated by real-world scenarios, some recent works have delved into the maximization of non-monotone DR-submodular functions over general (not necessarily down-closed) convex set constraints. Up to this point, these works have all used the minimum L-infinity norm of any feasible solution as a parameter. Unfortunately, a recent hardness result due to Mualem and Feldman shows that this approach cannot yield a smooth interpolation between down-closed and non-down-closed constraints. In this work, we suggest novel offline and online algorithms that provably provide such an interpolation based on a natural decomposition of the convex body constraint into two distinct convex bodies: a down-closed convex body and a general convex body. We also empirically demonstrate the superiority of our proposed algorithms across three offline and two online applications. Keywords: Constraint Satisfaction and Optimization: CSO: Constraint optimization problems Machine Learning: ML: Online learning Search: S: Combinatorial search and optimisation},
  archive   = {C_IJCAI},
  author    = {Loay Mualem and Murad Tukan and Moran Feldman},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/213},
  month     = {8},
  pages     = {1926-1934},
  title     = {Bridging the gap between general and down-closed convex sets in submodular maximization},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Using large language models to improve query-based
constraint acquisition. <em>IJCAI</em>, 1916–1925. (<a
href="https://doi.org/10.24963/ijcai.2024/212">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Most active constraint acquisition systems suffer from two weaknesses. They require the explicit generation of the set of potential constraints (the bias), whose size can be prohibitive for practical use of these systems, and the answers to queries contain little information. In this paper, we introduce ACQNOGOODS, an active learning schema that does not require the construction of a bias. We then propose LLMACQ, an active learning system that incorporates a Large Language Model component in the ACQNOGOODS schema. LLMACQ interprets the user’s answers given in natural language, leading to more informative communication. As our experiments show, the non requirement of a bias in extension combined to the higher level communication with the user allow LLMACQ to learn constraints of any arity and to dramatically decrease the number of queries. Keywords: Constraint Satisfaction and Optimization: CSO: Constraint learning and acquisition},
  archive   = {C_IJCAI},
  author    = {Younes Mechqrane and Christian Bessiere and Ismail Elabbassi},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/212},
  month     = {8},
  pages     = {1916-1925},
  title     = {Using large language models to improve query-based constraint acquisition},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Layered and staged monte carlo tree search for SMT strategy
synthesis. <em>IJCAI</em>, 1907–1915. (<a
href="https://doi.org/10.24963/ijcai.2024/211">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Modern SMT solvers, such as Z3, offer user-controllable strategies that allow solver users the ability to tailor solving strategies for their unique set of instances, thus dramatically enhancing the solver performance for their specific use cases. However, this approach of strategy customization presents a significant challenge: handcrafting an optimized strategy for a class of SMT instances remains a complex and demanding task for both solver developers and users alike. In this paper, we address this problem of automated SMT strategy synthesis via a novel Monte Carlo Tree Search (MCTS) based method. Our method treats strategy synthesis as a sequential decision-making process, whose search tree corresponds to the strategy space, and employs MCTS to navigate this vast search space. The key innovations that enable our method to identify effective strategies, while keeping costs low, are the ideas of layered and staged MCTS search. These novel heuristics allow for a deeper and more efficient exploration of the strategy space, enabling us to synthesize more effective strategies than the default ones in state-of-the-art (SOTA) SMT solvers. We implement our method, dubbed Z3alpha, as part of the Z3 SMT solver. Through extensive evaluations across six important SMT logics, Z3alpha demonstrates superior performance compared to the SOTA synthesis tool FastSMT, the default Z3 solver, and the CVC5 solver on most benchmarks. Remarkably, on a challenging QF_BV benchmark set, Z3alpha solves 42.7% more instances than the default strategy in Z3. Keywords: Constraint Satisfaction and Optimization: CSO: Solvers and tools Knowledge Representation and Reasoning: KRR: Automated reasoning and theorem proving Search: S: Algorithm portfolios and configuration Search: S: Heuristic search},
  archive   = {C_IJCAI},
  author    = {Zhengyang Lu and Stefan Siemer and Piyush Jha and Joel Day and Florin Manea and Vijay Ganesh},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/211},
  month     = {8},
  pages     = {1907-1915},
  title     = {Layered and staged monte carlo tree search for SMT strategy synthesis},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A SAT solver + computer algebra attack on the minimum
kochen–specker problem. <em>IJCAI</em>, 1898–1906. (<a
href="https://doi.org/10.24963/ijcai.2024/210">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {One of the fundamental results in quantum foundations is the Kochen–Specker (KS) theorem, which states that any theory whose predictions agree with quantum mechanics must be contextual, i.e., a quantum observation cannot be understood as revealing a pre-existing value. The theorem hinges on the existence of a mathematical object called a KS vector system. While many KS vector systems are known, the problem of finding the minimum KS vector system in three dimensions (3D) has remained stubbornly open for over 55 years. To address the minimum KS problem, we present a new verifiable proof-producing method based on a combination of a Boolean satisfiability (SAT) solver and a computer algebra system (CAS) that uses an isomorph-free orderly generation technique that is very effective in pruning away large parts of the search space. Our method shows that a KS system in 3D must contain at least 24 vectors. We show that our sequential and parallel Cube-and-Conquer (CnC) SAT+CAS methods are significantly faster than SAT-only, CAS-only, and a prior CAS-based method of Uijlen and Westerbaan. Further, while our parallel pipeline is somewhat slower than the parallel CnC version of the recently introduced Satisfiability Modulo Theories (SMS) method, this is in part due to the overhead of proof generation. Finally, we provide the first computer-verifiable proof certificate of a lower bound to the KS problem with a size of 40.3 TiB in order 23. Keywords: Constraint Satisfaction and Optimization: CSO: Satisfiabilty Constraint Satisfaction and Optimization: CSO: Applications Constraint Satisfaction and Optimization: CSO: Solvers and tools},
  archive   = {C_IJCAI},
  author    = {Zhengyu Li and Curtis Bright and Vijay Ganesh},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/210},
  month     = {8},
  pages     = {1898-1906},
  title     = {A SAT solver + computer algebra attack on the minimum Kochen–Specker problem},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Solving quantified boolean formulas with few existential
variables. <em>IJCAI</em>, 1889–1897. (<a
href="https://doi.org/10.24963/ijcai.2024/209">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The quantified Boolean formula (QBF) problem is an important decision problem generally viewed as the archetype for PSPACE-completeness. Many problems of central interest in AI are in general not included in NP, e.g., planning, model checking, and non-monotonic reasoning, and for such problems QBF has successfully been used as a modelling tool. However, solvers for QBF are not as advanced as state of the art SAT solvers, which has prevented QBF from becoming a universal modelling language for PSPACE-complete problems. A theoretical explanation is that QBF (as well as many other PSPACE-complete problems) lacks natural parameters guaranteeing fixed-parameter tractability (FPT). In this paper we tackle this problem and consider a simple but overlooked parameter: the number of existentially quantified variables. This natural parameter is virtually unexplored in the literature which one might find surprising given the general scarcity of FPT algorithms for QBF. Via this parameterization we then develop a novel FPT algorithm applicable to QBF instances in conjunctive normal form (CNF) of bounded clause length. We complement this by a W[1]-hardness result for QBF in CNF of unbounded clause length as well as sharper lower bounds for the bounded arity case under the (strong) exponential-time hypothesis. Keywords: Constraint Satisfaction and Optimization: CSO: Satisfiabilty Constraint Satisfaction and Optimization: CSO: Constraint satisfaction Knowledge Representation and Reasoning: KRR: Computational complexity of reasoning},
  archive   = {C_IJCAI},
  author    = {Leif Eriksson and Victor Lagerkvist and Sebastian Ordyniak and George Osipov and Fahad Panolan and Mateusz Rychlicki},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/209},
  month     = {8},
  pages     = {1889-1897},
  title     = {Solving quantified boolean formulas with few existential variables},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal extended formulations from optimal dynamic
programming algorithms. <em>IJCAI</em>, 1881–1888. (<a
href="https://doi.org/10.24963/ijcai.2024/208">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Vertex Subset Problems (VSPs) are a class of combinatorial optimization problems on graphs where the goal is to find a subset of vertices satisfying a predefined condition. Two prominent approaches for solving VSPs are dynamic programming over tree-like structures, such as tree-decompositions or clique-decompositions, and linear programming. In this work, we establish a sharp connection between both approaches by showing that if a vertex-subset problem Pi admits a solution-preserving dynamic programming algorithm that produces tables of size at most alpha(k,n) when processing a tree decomposition of width at most k of an n-vertex graph G, then the polytope defined as the convex-hull of solutions of Pi in G has extension complexity at most O(alpha(k,n)*n). Additionally, this upper bound is optimal under the exponential time hypothesis (ETH). At the one hand, our results imply that ETH-optimal solution-preserving dynamic programming algorithms for combinatorial problems yield optimal-size parameterized extended formulations for the solution polytopes associated with instances of these problems. At the other hand, unconditional lower bounds obtained in the realm of the theory of extended formulations yield unconditional lower bounds on the table complexity of solution-preserving dynamic programming algorithms. Keywords: Constraint Satisfaction and Optimization: General Constraint Satisfaction and Optimization: CSO: Constraint optimization problems Constraint Satisfaction and Optimization: CSO: Mixed discrete and continuous optimization},
  archive   = {C_IJCAI},
  author    = {Mateus de Oliveira Oliveira and Wim Van den Broeck},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/208},
  month     = {8},
  pages     = {1881-1888},
  title     = {Optimal extended formulations from optimal dynamic programming algorithms},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient cost-minimization schemes for electrical energy
demand satisfaction by prosumers in microgrids with battery storage
capabilities. <em>IJCAI</em>, 1873–1880. (<a
href="https://doi.org/10.24963/ijcai.2024/207">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We introduce and study various models for satisfying electrical energy demands of prosumers in a microgrid, while optimizing their costs. Each prosumer has individual demands of electrical energy, which can vary day-by-day, and which they can satisfy by either generating electrical energy through a self-operated mini power plant like a solar panel, through buying from an external energy provider, such as the main grid or by trading with other prosumers. Our models take into account two key aspects motivated by real-life scenarios: first, we consider a daily volatility of prices for buying and selling the energy, and second, the possibility to store the self-generated energy in a battery of finite capacity to be either self-consumed or sold to other prosumers in the future. We provide a thorough complexity analysis, as well as efficient algorithms, so that prosumers can minimize their overall cost over the entire time horizon. As a byproduct, we also solve a new, generalized version of the KNAPSACK problem which may be of independent interest. We complement our theoretical findings by extensive experimental evaluations on realistic data sets. Keywords: Constraint Satisfaction and Optimization: CSO: Constraint optimization problems Planning and Scheduling: PS: Planning algorithms Planning and Scheduling: PS: Planning under uncertainty Planning and Scheduling: PS: Theoretical foundations of planning},
  archive   = {C_IJCAI},
  author    = {Laura Codazzi and Gergely Csáji and Matthias Mnich},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/207},
  month     = {8},
  pages     = {1873-1880},
  title     = {Efficient cost-minimization schemes for electrical energy demand satisfaction by prosumers in microgrids with battery storage capabilities},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Knowledge compilation for incremental and checkable
stochastic boolean satisfiability. <em>IJCAI</em>, 1862–1872. (<a
href="https://doi.org/10.24963/ijcai.2024/206">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Knowledge compilation has proven effective in (weighted) model counting, uniquely supporting incrementality and checkability. For incrementality, compiling an input formula once suffices to answer multiple queries, thus reducing the total solving effort. For checkability, the compiled formula is amenable to producing machine-checkable proofs for verification, thus strengthening the solver’s reliability. In this work, we extend knowledge compilation from model counting to stochastic Boolean satisfiability (SSAT) solving by generalizing the dec-DNNF representation to accommodate the SSAT quantifier structure and integrate it into SharpSSAT, a state-of-the-art SSAT solver. We further study proof generation from the compiled representation and extend CPOG, a certified model-counting toolchain, to generate proofs for certifying the results of SharpSSAT. Experimental results show the benefits of the proposed knowledge compilation approach for SSAT in sharing computation efforts for multiple queries and producing checkable dec-DNNF logs with negligible overhead. Keywords: Constraint Satisfaction and Optimization: CSO: Satisfiabilty Constraint Satisfaction and Optimization: CSO: Constraint satisfaction Constraint Satisfaction and Optimization: CSO: Solvers and tools Knowledge Representation and Reasoning: KRR: Knowledge compilation},
  archive   = {C_IJCAI},
  author    = {Che Cheng and Yun-Rong Luo and Jie-Hong R. Jiang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/206},
  month     = {8},
  pages     = {1862-1872},
  title     = {Knowledge compilation for incremental and checkable stochastic boolean satisfiability},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A top-down tree model counter for quantified boolean
formulas. <em>IJCAI</em>, 1853–1861. (<a
href="https://doi.org/10.24963/ijcai.2024/205">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper addresses the challenge of solution counting for Quantified Boolean Formulas (QBFs), a task distinct from the well-established model counting problem for SAT (\#SAT). Unlike SAT, where models are straightforward assignments to Boolean variables, QBF solution counting involves tree models that capture dependencies among variables within different quantifier blocks. We present a comprehensive top-down tree model counter capable of handling diverse satisfiable QBF formulas. Emphasizing the critical role of the branching heuristic, which must consider variables in the correct order according to quantification blocks, we further demonstrate the importance of addressing connected components, free variables, and caching. Experimental results indicate that our proposed approach for counting tree models of QBF formulas is highly efficient in practice, surpassing existing state-of-the-art methods designed for this specific purpose. Keywords: Constraint Satisfaction and Optimization: CSO: Satisfiabilty Constraint Satisfaction and Optimization: CSO: Solvers and tools},
  archive   = {C_IJCAI},
  author    = {Florent Capelli and Jean-Marie Lagniez and Andreas Plank and Martina Seidl},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/205},
  month     = {8},
  pages     = {1853-1861},
  title     = {A top-down tree model counter for quantified boolean formulas},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Markov constraint as large language model surrogate.
<em>IJCAI</em>, 1844–1852. (<a
href="https://doi.org/10.24963/ijcai.2024/204">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper presents NgramMarkov, a variant of the Markov constraints. It is dedicated to text generation in constraint programming (CP). It involves a set of n-grams (i.e., sequence of n words) associated with probabilities given by a large language model (LLM). It limits the product of the probabilities of the n-gram of a sentence. The propagator of this constraint can be seen as an extension of the ElementaryMarkov constraint propagator, incorporating the LLM distribution instead of the maximum likelihood estimation of n-grams. It uses a gliding threshold, i.e., it rejects n-grams whose local probabilities are too low, to guarantee balanced solutions. It can also be combined with a &quot;look-ahead&quot; approach to remove n-grams that are very unlikely to lead to acceptable sentences for a fixed-length horizon. This idea is based on the MDDMarkovProcess constraint propagator, but without explicitly using an MDD (Multi-Valued Decision Diagram). The experimental results show that the generated text is valued in a similar way to the LLM perplexity function. Using this new constraint dramatically reduces the number of candidate sentences produced, improves computation times, and allows larger corpora or smaller n-grams to be used. A real-world problem has been solved for the first time using 4-grams instead of 5-grams. Keywords: Constraint Satisfaction and Optimization: CSO: Constraint programming Constraint Satisfaction and Optimization: CSO: Applications Constraint Satisfaction and Optimization: CSO: Modeling Natural Language Processing: NLP: Language generation},
  archive   = {C_IJCAI},
  author    = {Alexandre Bonlarron and Jean-Charles Régin},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/204},
  month     = {8},
  pages     = {1844-1852},
  title     = {Markov constraint as large language model surrogate},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CLIP-FSAC: Boosting CLIP for few-shot anomaly classification
with synthetic anomalies. <em>IJCAI</em>, 1834–1842. (<a
href="https://doi.org/10.24963/ijcai.2024/203">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Few-shot anomaly classification (FSAC) is a vital task in manufacturing industry. Recent methods focus on utilizing CLIP in zero/few normal shot anomaly detection instead of custom models. However, there is a lack of specific text prompts in anomaly classification and most of them ignore the modality gap between image and text. Meanwhile, there is distribution discrepancy between the pre-trained and the target data. To provide a remedy, in this paper, we propose a method to boost CLIP for few-normal-shot anomaly classification, dubbed CLIP-FSAC, which contains two-stage of training and alternating fine-tuning with two modality-specific adapters. Specifically, in the first stage, we train image adapter with text representation output from text encoder and introduce an image-to-text tuning to enhance multi-modal interaction and facilitate a better language-compatible visual representation. In the second stage, we freeze the image adapter to train the text adapter. Both of them are constrained by fusion-text contrastive loss. Comprehensive experiment results are provided for evaluating our method in few-normal-shot anomaly classification, which outperforms the state-of-the-art method by 12.2%, 10.9%, 10.4% AUROC on VisA for 1, 2, and 4-shot settings. Keywords: Computer Vision: CV: Transfer, low-shot, semi- and un- supervised learning Computer Vision: CV: Multimodal learning Computer Vision: CV: Recognition (object detection, categorization)},
  archive   = {C_IJCAI},
  author    = {Zuo Zuo and Yao Wu and Baoqiang Li and Jiahao Dong and You Zhou and Lei Zhou and Yanyun Qu and Zongze Wu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/203},
  month     = {8},
  pages     = {1834-1842},
  title     = {CLIP-FSAC: Boosting CLIP for few-shot anomaly classification with synthetic anomalies},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SceneDiff: Generative scene-level image retrieval with text
and sketch using diffusion models. <em>IJCAI</em>, 1825–1833. (<a
href="https://doi.org/10.24963/ijcai.2024/202">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Jointly using text and sketch for scene-level image retrieval utilizes the complementary between text and sketch to describe the fine-grained scene content and retrieve the target image, which plays a pivotal role in accurate image retrieval. Existing methods directly fuse the features of sketch and text and thus suffer from the bottleneck of limited utilization for crucial semantic and structural information, leading to inaccurate matching with images. In this paper, we propose SceneDiff, a novel retrieval network that leverages a pre-trained diffusion model to establish a shared generative latent space, enabling a joint latent representation learning for both sketch and text features and precise alignment with the corresponding image. Specifically, we encode text, sketch and image features, and project them into the diffusion-based share space, conditioning the denoising process on sketch and text features to generate latent fusion features, while employing the pre-trained autoencoder for latent image features. Within this space, we introduce the content-aware feature transformation module to reconcile encoded sketch and image features with the diffusion latent space&#39;s dimensional requirements and preserve their visual content information. Then we augment the representation capability of the generated latent fusion features by integrating multiple samplings with partition attention, and utilize contrastive learning to align both direct fusion features and generated latent fusion features with corresponding image representations. Our method outperforms the state-of-the-art works through extensive experiments, providing a novel insight into the related retrieval field. Keywords: Computer Vision: CV: Image and video retrieval Computer Vision: CV: Multimodal learning},
  archive   = {C_IJCAI},
  author    = {Ran Zuo and Haoxiang Hu and Xiaoming Deng and Cangjun Gao and Zhengming Zhang and Yu-Kun Lai and Cuixia Ma and Yong-Jin Liu and Hongan Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/202},
  month     = {8},
  pages     = {1825-1833},
  title     = {SceneDiff: Generative scene-level image retrieval with text and sketch using diffusion models},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ABM: Attention before manipulation. <em>IJCAI</em>,
1816–1824. (<a href="https://doi.org/10.24963/ijcai.2024/201">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Vision-language models (VLMs) show promising generalization and zero-shot capabilities, offering a potential solution to the impracticality and cost of enabling robots to comprehend diverse human instructions and scene semantics in the real world. Existing approaches most directly integrate the semantic representations from pre-trained VLMs with policy learning. However, these methods are limited to the labeled data learned, resulting in poor generalization ability to unseen instructions and objects. To address the above limitation, we propose a simple method called &quot;Attention before Manipulation&quot; (ABM), which fully leverages the object knowledge encoded in CLIP to extract information about the target object in the image. It constructs an Object Mask Field, serving as a better representation of the target object for the model to separate visual grounding from action prediction and acquire specific manipulation skills effectively. We train ABM for 8 RLBench tasks and 2 real-world tasks via behavior cloning. Extensive experiments show that our method significantly outperforms the baselines in the zero-shot and compositional generalization experiment settings. Keywords: Computer Vision: CV: Embodied vision: Active agents, simulation Robotics: ROB: Applications Robotics: ROB: Manipulation Robotics: ROB: Robotics and vision},
  archive   = {C_IJCAI},
  author    = {Fan Zhuo and Ying He and Fei Yu and Pengteng Li and Zheyi Zhao and Xilong Sun},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/201},
  month     = {8},
  pages     = {1816-1824},
  title     = {ABM: Attention before manipulation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Class-consistent contrastive learning driven
cross-dimensional transformer for 3D medical image classification.
<em>IJCAI</em>, 1807–1815. (<a
href="https://doi.org/10.24963/ijcai.2024/200">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Transformer emerges as an active research topic in medical image analysis. Yet, three substantial challenges limit the effectiveness of both 2D and 3D Transformers in 3D medical image classification: 1) Challenge in capturing spatial structure correlation due to the unreasonable flattening operation; 2) Challenge in burdening the high computational complexity and memory consumption due to the quadratic growth of computational complexity and memory consumption for 3D medical data; 3) Challenge in discriminative representation learning, due to data-sensitivity. To address the above challenges, a novel Cross-dimensional Transformer (CdTransformer) and a creative Class-consistent Contrastive Learning (CcCL) are proposed. Specifically, CdTransformer consists of two novel modules: 1) Cross-dimensional Attention Module (CAM), which breaks the limitation that Transformer cannot reasonably establish spatial structure correlation when meeting 3D medical data, meanwhile, reduces the computational complexity and memory consumption. 2) Inter-dimensional Feed-forward Network (IdFN), which addresses the challenge of traditional feed-forward networks not being able to learn depth dimension information that is unique to 3D medical data. CcCL innovatively takes full advantage of the inter-class and intra-class features from the slice-distorted samples to boost Transformer in learning feature representation. CdTransformer and CcCL are validated on six 3D medical image classification tasks. Extensive experimental results demonstrate that CdTransformer outperforms state-of-the-art CNNs and Transformers on 3D medical image classification, and CcCL enables significantly improving Transformer in discriminative representation learning. Keywords: Computer Vision: CV: Biomedical image analysis Computer Vision: CV: Applications Machine Learning: ML: Adversarial machine learning Machine Learning: ML: Classification},
  archive   = {C_IJCAI},
  author    = {Qikui Zhu and Chuan Fu and Shuo Li},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/200},
  month     = {8},
  pages     = {1807-1815},
  title     = {Class-consistent contrastive learning driven cross-dimensional transformer for 3D medical image classification},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MISA: MIning saliency-aware semantic prior for box
supervised instance segmentation. <em>IJCAI</em>, 1798–1806. (<a
href="https://doi.org/10.24963/ijcai.2024/199">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Box supervised instance segmentation (BSIS) aims to achieve an effective trade-off between annotation costs and model performance by solely relying on bounding box annotations during training process. However, we observe that BSIS model is bottlenecked by the intricate objective under limited guidance, and tends to sacrifice segmentation capability in order to effectively recognize multiple instances. To boost the BSIS model&#39;s perceptual ability for object shape and contour, we introduce MISA, that is, MIning Saliency-Aware semantic prior from a well-optimized box supervised semantic segmentation (BSSS) network, and incorporating cross-model guidance into the learning process of BSIS. Specifically, we first design a Frequency-Space Distillation (FSD) module to extract assorted salient prior knowledge from BSSS model, and perform cross-model alignment for transfering the prior to BSIS model. Furthermore, we introduce Semantic-Enhanced Pairwise Affinity (SEPA), which borrows the object perceptual ability of BSSS model to emphasize the contribution of salient objects for pairwise affinity, providing more accurate guidance for the BSIS network. Extensive experiments show that our proposed MISA consistently surpasses the existing state-of-the-art methods by a large margin in the BSIS scenario. Keywords: Computer Vision: CV: Segmentation Computer Vision: CV: Transfer, low-shot, semi- and un- supervised learning},
  archive   = {C_IJCAI},
  author    = {Hao Zhu and Yan Zhu and Jiayu Xiao and Yike Ma and Yucheng Zhang and Jintao Li and Feng Dai},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/199},
  month     = {8},
  pages     = {1798-1806},
  title     = {MISA: MIning saliency-aware semantic prior for box supervised instance segmentation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Zero-shot high-fidelity and pose-controllable character
animation. <em>IJCAI</em>, 1788–1797. (<a
href="https://doi.org/10.24963/ijcai.2024/198">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Image-to-video (I2V) generation aims to create a video sequence from a single image, which requires high temporal coherence and visual fidelity. However, existing approaches suffer from inconsistency of character appearances and poor preservation of fine details. Moreover, they require a large amount of video data for training, which can be computationally demanding. To address these limitations, we propose PoseAnimate, a novel zero-shot I2V framework for character animation. PoseAnimate contains three key components: 1) a Pose-Aware Control Module (PACM) that incorporates diverse pose signals into text embeddings, to preserve character-independent content and maintain precise alignment of actions. 2) a Dual Consistency Attention Module (DCAM) that enhances temporal consistency and retains character identity and intricate background details. 3) a Mask-Guided Decoupling Module (MGDM) that refines distinct feature perception abilities, improving animation fidelity by decoupling the character and background. We also propose a Pose Alignment Transition Algorithm (PATA) to ensure smooth action transition. Extensive experiment results demonstrate that our approach outperforms the state-of-the-art training-based methods in terms of character consistency and detail fidelity. Moreover, it maintains a high level of temporal coherence throughout the generated animations. Keywords: Computer Vision: CV: Image and video synthesis and generation Machine Learning: ML: Multi-modal learning},
  archive   = {C_IJCAI},
  author    = {Bingwen Zhu and Fanyi Wang and Tianyi Lu and Peng Liu and Jingwen Su and Jinxiu Liu and Yanhao Zhang and Zuxuan Wu and Guo-Jun Qi and Yu-Gang Jiang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/198},
  month     = {8},
  pages     = {1788-1797},
  title     = {Zero-shot high-fidelity and pose-controllable character animation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Zero-shot sketch based image retrieval via modality capacity
guidance. <em>IJCAI</em>, 1780–1787. (<a
href="https://doi.org/10.24963/ijcai.2024/197">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Zero-shot sketch-based image retrieval (ZS-SBIR), aiming to recognize and retrieve relevant photos based on freehand sketch queries that belong to unseen categories in the search set, has sparked considerable interest, benefiting from the rapid advancements in multimodal learning and feature representation research. Despite the recent improvements in performance, there are still rooms for refining feature representation and thus enhancing the generalization capabilities of the models. Most of the existing research efforts have primarily focused on learning the feature distribution of modalities within specific datasets, without considering the broader dataset-agnostic `population distribution&#39; of relevant modalities. In this paper, we investigate the modality population distribution and apply such knowledge to guide feature learning. Specifically, we propose a modality capacity constraint loss to control the learning of population distribution for sketches and photos. This loss can be effectively combined with retrieval loss (e.g., triplet loss) or classification loss (e.g., InfoNCE loss) to enhance the performance of ZS-SBIR, through the fine-tuning process of pre-trained models like CLIP and DINO. Extensive experiment results have demonstrated our significant performance improvements, achieving an increase of 7.3%/3.2% and 19.9%/10.3% in terms of mAP@200/P@200 compared to the state-of-the-art models on CLIP and DINO, respectively, on the Sketchy-ext dataset (split 2). Data, code, and supplementary information are available at https://github.com/YHdian0716/ZS-SBIR-MCC.git. Keywords: Computer Vision: CV: Image and video retrieval Computer Vision: CV: Multimodal learning Computer Vision: CV: Recognition (object detection, categorization) Computer Vision: CV: Representation learning},
  archive   = {C_IJCAI},
  author    = {Yanghong Zhou and Dawei Liu and P. Y. Mok},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/197},
  month     = {8},
  pages     = {1780-1787},
  title     = {Zero-shot sketch based image retrieval via modality capacity guidance},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CoFInAl: Enhancing action quality assessment with
coarse-to-fine instruction alignment. <em>IJCAI</em>, 1771–1779. (<a
href="https://doi.org/10.24963/ijcai.2024/196">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Action Quality Assessment (AQA) is pivotal for quantifying actions across domains like sports and medical care. Existing methods often rely on pre-trained backbones from large-scale action recognition datasets to boost performance on smaller AQA datasets. However, this common strategy yields suboptimal results due to the inherent struggle of these backbones to capture the subtle cues essential for AQA. Moreover, fine-tuning on smaller datasets risks overfitting. To address these issues, we propose Coarse-to-Fine Instruction Alignment (CoFInAl). Inspired by recent advances in large language model tuning, CoFInAl aligns AQA with broader pre-trained tasks by reformulating it as a coarse-to-fine classification task. Initially, it learns grade prototypes for coarse assessment and then utilizes fixed sub-grade prototypes for fine-grained assessment. This hierarchical approach mirrors the judging process, enhancing interpretability within the AQA framework. Experimental results on two long-term AQA datasets demonstrate CoFInAl achieves state-of-the-art performance with significant correlation gains of 5.49% and 3.55% on Rhythmic Gymnastics and Fis-V, respectively. Our Code is available at https://github.com/ZhouKanglei/CoFInAl_AQA. Keywords: Computer Vision: CV: Action and behavior recognition Computer Vision: CV: Video analysis and understanding},
  archive   = {C_IJCAI},
  author    = {Kanglei Zhou and Junlin Li and Ruizhi Cai and Liyuan Wang and Xingxing Zhang and Xiaohui Liang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/196},
  month     = {8},
  pages     = {1771-1779},
  title     = {CoFInAl: Enhancing action quality assessment with coarse-to-fine instruction alignment},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Focus on the whole character: Discriminative character
modeling for scene text recognition. <em>IJCAI</em>, 1762–1770. (<a
href="https://doi.org/10.24963/ijcai.2024/195">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, scene text recognition (STR) models have shown significant performance improvements. However, existing models still encounter difficulties in recognizing challenging texts that involve factors such as severely distorted and perspective characters. These challenging texts mainly cause two problems: (1) Large Intra-Class Variance. (2) Small Inter-Class Variance. An extremely distorted character may prominently differ visually from other characters within the same category, while the variance between characters from different classes is relatively small. To address the above issues, we propose a novel method that enriches the character features to enhance the discriminability of characters. Firstly, we propose the Character-Aware Constraint Encoder (CACE) with multiple blocks stacked. CACE introduces a decay matrix in each block to explicitly guide the attention region for each token. By continuously employing the decay matrix, CACE enables tokens to perceive morphological information at the character level. Secondly, an Intra-Inter Consistency Loss (I^2CL) is introduced to consider intra-class compactness and inter-class separability at feature space. I^2CL improves the discriminative capability of features by learning a long-term memory unit for each character category. Trained with synthetic data, our model achieves state-of-the-art performance on common benchmarks (94.1% accuracy) and Union14M-Benchmark (61.6% accuracy). Code is available at https://github.com/bang123-box/CFE. Keywords: Computer Vision: CV: Recognition (object detection, categorization) Computer Vision: CV: Multimodal learning},
  archive   = {C_IJCAI},
  author    = {Bangbang Zhou and Yadong Qu and Zixiao Wang and Zicheng Li and Boqiang Zhang and Hongtao Xie},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/195},
  month     = {8},
  pages     = {1762-1770},
  title     = {Focus on the whole character: Discriminative character modeling for scene text recognition},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-attention based visual-semantic interaction for
few-shot learning. <em>IJCAI</em>, 1753–1761. (<a
href="https://doi.org/10.24963/ijcai.2024/194">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Few-Shot Learning (FSL) aims to train a model that can generalize to recognize new classes, with each new class having only very limited training samples. Since extracting discriminative features for new classes with few samples is challenging, existing FSL methods leverage visual and semantic prior knowledge to guide discriminative feature learning. However, for meta-learning purposes, the semantic knowledge of the query set is unavailable, so their features lack discriminability. To address this problem, we propose a novel Multi-Attention based Visual-Semantic Interaction (MAVSI) approach for FSL. Specifically, we utilize spatial and channel attention mechanisms to effectively select discriminative visual features for the support set based on its ground-truth semantics while using all the support set semantics for each query set sample. Then, a relation module with class prototypes of the support set is employed to supervise and select discriminative visual features for the query set. To further enhance the discriminability of the support set, we introduce a visual-semantic contrastive learning module to promote the similarity between visual features and their corresponding semantic features. Extensive experiments on four benchmark datasets demonstrate that our proposed MAVSI could outperform existing state-of-the-art FSL methods. Keywords: Computer Vision: CV: Transfer, low-shot, semi- and un- supervised learning Machine Learning: ML: Meta-learning},
  archive   = {C_IJCAI},
  author    = {Peng Zhao and Yin Wang and Wei Wang and Jie Mu and Huiting Liu and Cong Wang and Xiaochun Cao},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/194},
  month     = {8},
  pages     = {1753-1761},
  title     = {Multi-attention based visual-semantic interaction for few-shot learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ChatSpot: Bootstrapping multimodal LLMs via precise
referring instruction tuning. <em>IJCAI</em>, 1743–1752. (<a
href="https://doi.org/10.24963/ijcai.2024/193">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Human-AI interactivity is a critical aspect that reflects the usability of Multimodal Large Language Models (MLLMs). However, existing end-to-end MLLMs only allow users to interact with them through language instructions, leading to the limitation of the interactive accuracy and efficiency. In this study, we present precise referring instructions that utilize diverse reference representations such as points and boxes as referring prompts to refer to the special region. This enables MLLMs to focus on the region of interest and achieve finer-grained interaction. Based on precise referring instruction, we propose ChatSpot, a unified end-to-end MLLM that supports diverse forms of interactivity including mouse clicks, drag-and-drop, and drawing boxes, which provides a more flexible and seamless interactive experience. We also construct a multi-grained vision-language instruction-following dataset based on existing datasets and GPT-4 generating. Furthermore, we design a series of evaluation tasks to assess the effectiveness of region recognition and interaction. Experimental results showcase ChatSpot&#39;s promising performance. Project page: https://github.com/Ahnsun/ChatSpot. Keywords: Computer Vision: CV: Multimodal learning Computer Vision: CV: Embodied vision: Active agents, simulation Natural Language Processing: NLP: Dialogue and interactive systems Natural Language Processing: NLP: Question answering},
  archive   = {C_IJCAI},
  author    = {Liang Zhao and En Yu and Zheng Ge and Jinrong Yang and Haoran Wei and Hongyu Zhou and Jianjian Sun and Yuang Peng and Runpei Dong and Chunrui Han and Xiangyu Zhang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/193},
  month     = {8},
  pages     = {1743-1752},
  title     = {ChatSpot: Bootstrapping multimodal LLMs via precise referring instruction tuning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GenSeg: On generating unified adversary for segmentation.
<em>IJCAI</em>, 1733–1742. (<a
href="https://doi.org/10.24963/ijcai.2024/192">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Great advancements in semantic, instance, and panoptic segmentation have been made in recent years, yet the top-performing models remain vulnerable to imperceptible adversarial perturbation. Current attacks on segmentation primarily focus on a single task, and these methods typically rely on iterative instance-specific strategies, resulting in limited attack transferability and low efficiency. In this paper, we propose GenSeg, a Generative paradigm that creates unified adversaries for Segmentation tasks. In particular, we propose an intermediate-level objective to enhance attack transferability, including a mutual agreement loss for feature deviation, and a prototype obfuscating loss to disrupt intra-class and inter-class relationships. Moreover, GenSeg crafts an adversary in a single forward pass, significantly boosting the attack efficiency. Besides, we unify multiple segmentation tasks to GenSeg in a novel category-and-mask view, which makes it possible to attack these segmentation tasks within this unified framework, and conduct cross-domain and cross-task attacks as well. Extensive experiments demonstrate the superiority of GenSeg in black-box attacks compared with state-of-the-art attacks. To our best knowledge, GenSeg is the first approach capable of conducting cross-domain and cross-task attacks on segmentation tasks, which are closer to real-world scenarios. Keywords: Computer Vision: CV: Segmentation Computer Vision: CV: Adversarial learning, adversarial attack and defense methods},
  archive   = {C_IJCAI},
  author    = {Yuxuan Zhang and Zhenbo Shi and Wei Yang and Shuchang Wang and Shaowei Wang and Yinxing Xue},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/192},
  month     = {8},
  pages     = {1733-1742},
  title     = {GenSeg: On generating unified adversary for segmentation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Continual compositional zero-shot learning. <em>IJCAI</em>,
1724–1732. (<a href="https://doi.org/10.24963/ijcai.2024/191">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Compositional Zero-Shot Learning (CZSL) aims to recognize unseen compositions with the knowledge learned from seen compositions, where each composition is composed of two primitives (attribute and object). However, existing CZSL methods are designed to learn compositions from fixed primitive set, which cannot handle the continually expanding primitive set in real-world applications. In this paper, we propose a new CZSL setting, named Continual Compositional Zero-Shot Learning (CCZSL), which requires the model to recognize unseen compositions composed of learned primitive set while continually increasing the size of learned primitive set. Contextuality and catastrophic forgetting are the main issues to be addressed in this setting. Specifically, we capture similar contextuality in compositions through several learnable Super-Primitives that can modify the invariant primitive embedding to better adapt the contextuality in the corresponding composition. Then we introduce a dual knowledge distillation loss which aims at maintaining old knowledge learned from previous sessions and avoiding overfitting of new session. We design the CCZSL evaluation protocol and conduct extensive experiments on widely used benchmarks, demonstrating the superiority of our method compared to the state-of-the-art CZSL methods. Keywords: Computer Vision: CV: Transfer, low-shot, semi- and un- supervised learning Machine Learning: ML: Incremental learning},
  archive   = {C_IJCAI},
  author    = {Yang Zhang and Songhe Feng and Jiazheng Yuan},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/191},
  month     = {8},
  pages     = {1724-1732},
  title     = {Continual compositional zero-shot learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A fourier perspective of feature extraction and adversarial
robustness. <em>IJCAI</em>, 1715–1723. (<a
href="https://doi.org/10.24963/ijcai.2024/190">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Adversarial robustness and interpretability are longstanding challenges of computer vision. Deep neural networks are vulnerable to adversarial perturbations that are incomprehensible and imperceptible to humans. However, the opaqueness of networks prevents one from theoretically addressing adversarial robustness. As a human-comprehensible approach, the frequency perspective has been adopted in recent works to investigate the properties of neural networks and adversarial examples. In this paper, we investigate the frequency properties of feature extraction and analyze the stability of different frequency features when attacking different frequencies. Therefore, we propose an attack method, F-PGD, based on the projected gradient descent to attack the specified frequency bands. Utilizing this method, we find many intriguing properties of neural networks and adversarial perturbations. We experimentally show that contrary to the low-frequency bias of neural networks, the effective features of the same class are distributed across all frequency bands. Meanwhile, the high-frequency features often dominate when the neural networks make conflicting decisions on different frequency features. Furthermore, the attack experiments show that the low-frequency features are more robust to the attacks on different frequencies, but the interference to the high frequencies makes the network unable to make the right decision. These properties indicate that the decision-making process of neural networks tends to use as few low-frequency features as possible and cannot integrate features of different frequencies. Keywords: Computer Vision: CV: Interpretability and transparency Computer Vision: CV: Adversarial learning, adversarial attack and defense methods Computer Vision: CV: Recognition (object detection, categorization)},
  archive   = {C_IJCAI},
  author    = {Liangqi Zhang and Yihao Luo and Haibo Shen and Tianjiang Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/190},
  month     = {8},
  pages     = {1715-1723},
  title     = {A fourier perspective of feature extraction and adversarial robustness},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). 3DBench: A scalable 3D benchmark and instruction-tuning
dataset. <em>IJCAI</em>, 1706–1714. (<a
href="https://doi.org/10.24963/ijcai.2024/189">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Evaluating the performance of Multi-modal Large Language Models (MLLMs), integrating both point cloud and language, presents significant challenges. The lack of a comprehensive assessment hampers determining whether these models truly represent advancements, thereby impeding further progress in the field. Current evaluations heavily rely on classification and caption tasks, falling short in providing a thorough assessment of MLLMs. A pressing need exists for a more sophisticated evaluation method capable of thoroughly analyzing the spatial understanding and expressive capabilities of these models. To address these issues, we introduce a scalable 3D benchmark, accompanied by a large-scale instruction-tuning dataset known as 3DBench, providing an extensible platform for a comprehensive evaluation of MLLMs. Specifically, we establish the benchmark that spans a wide range of spatial and semantic scales, from object-level to scene-level, addressing both perception and planning tasks. Furthermore, we present a rigorous pipeline for automatically constructing scalable 3D instruction-tuning datasets, covering 10 diverse multi-modal tasks with more than 0.23 million QA pairs generated in total. Thorough experiments evaluating trending MLLMs, comparisons against existing datasets, and variations of training protocols demonstrate the superiority of 3DBench, offering valuable insights into current limitations and potential research directions. Codes are available at https://github.com/Inshsang/3DBench. Keywords: Computer Vision: CV: 3D computer vision Computer Vision: CV: Multimodal learning Computer Vision: CV: Scene analysis and understanding},
  archive   = {C_IJCAI},
  author    = {Junjie Zhang and Tianci Hu and Xiaoshui Huang and Yongshun Gong and Dan Zeng},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/189},
  month     = {8},
  pages     = {1706-1714},
  title     = {3DBench: A scalable 3D benchmark and instruction-tuning dataset},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sparse multi-relational graph convolutional network for
multi-type object trajectory prediction. <em>IJCAI</em>, 1697–1705. (<a
href="https://doi.org/10.24963/ijcai.2024/188">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Object trajectory prediction is a hot research issue with wide applications in video surveillance and autonomous driving. The previous studies consider the interaction sparsity mainly among the pedestrians instead of multi-type of objects, which brings new types of interactions and consequently superfluous ones. This paper proposes a Multi-type Object Trajectory Prediction (MOTP) method with a Sparse Multi-relational Graph Convolutional Network (SMGCN) and a novel multi-round Global Temporal Aggregation (GTA). MOTP introduces a novel adaptive sparsification and multi-scale division method to model interactions among multitype of objects. It further incorporates a Sparse Multi-relational Temporal Graph to capture the temporal division of multi-type trajectories, along with a multi-round Global Temporal Aggregation (GTA) mechanism to mitigate error accumulation, and enhances the trajectory prediction accuracy. The extensive evaluation on the ETH, UCY and SDD datasets shows that our method outperforms the typical state-of-the-art works by significant margins. Codes will be available in https://github.com/ sounio/SMGCN. Keywords: Computer Vision: CV: Video analysis and understanding Computer Vision: CV: Action and behavior recognition},
  archive   = {C_IJCAI},
  author    = {Jianhui Zhang and Jun Yao and Liqi Yan and Yanhong Xu and Zheng Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/188},
  month     = {8},
  pages     = {1697-1705},
  title     = {Sparse multi-relational graph convolutional network for multi-type object trajectory prediction},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Shap-mix: Shapley value guided mixing for long-tailed
skeleton based action recognition. <em>IJCAI</em>, 1688–1696. (<a
href="https://doi.org/10.24963/ijcai.2024/187">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In real-world scenarios, human actions often fall into a long-tailed distribution. It makes the existing skeleton-based action recognition works, which are mostly designed based on balanced datasets, suffer from a sharp performance degradation. Recently, many efforts have been made to image/video long-tailed learning. However, directly applying them to skeleton data can be sub-optimal due to the lack of consideration of the crucial spatial-temporal motion patterns, especially for some modality-specific methodologies such as data augmentation. To this end, considering the crucial role of the body parts in the spatially concentrated human actions, we attend to the mixing augmentations and propose a novel method, Shap-Mix, which improves long-tailed learning by mining representative motion patterns for tail categories. Specifically, we first develop an effective spatial-temporal mixing strategy for the skeleton to boost representation quality. Then, the employed saliency guidance method is presented, consisting of the saliency estimation based on Shapley value and a tail-aware mixing policy. It preserves the salient motion parts of minority classes in mixed data, explicitly establishing the relationships between crucial body structure cues and high-level semantics. Extensive experiments on three large-scale skeleton datasets show our remarkable performance improvement under both long-tailed and balanced settings. Our project is publicly available at: https://jhang2020.github.io/Projects/Shap-Mix/Shap-Mix.html. Keywords: Computer Vision: CV: Action and behavior recognition},
  archive   = {C_IJCAI},
  author    = {Jiahang Zhang and Lilang Lin and Jiaying Liu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/187},
  month     = {8},
  pages     = {1688-1696},
  title     = {Shap-mix: Shapley value guided mixing for long-tailed skeleton based action recognition},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DANCE: Dual-view distribution alignment for dataset
condensation. <em>IJCAI</em>, 1679–1687. (<a
href="https://doi.org/10.24963/ijcai.2024/186">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Dataset condensation addresses the problem of data burden by learning a small synthetic training set that preserves essential knowledge from the larger real training set. To date, the state-of-the-art (SOTA) results are often yielded by optimization-oriented methods, but their inefficiency hinders their application to realistic datasets. On the other hand, the Distribution-Matching (DM) methods show remarkable efficiency but sub-optimal results compared to optimization-oriented methods. In this paper, we reveal the limitations of current DM-based methods from the inner-class and inter-class views, i.e., Persistent Training and Distribution Shift. To address these problems, we propose a new DM-based method named Dual-view distribution AligNment for dataset CondEnsation (DANCE), which exploits a few pre-trained models to improve DM from both inner-class and inter-class views. Specifically, from the inner-class view, we construct multiple ``mid encoders&#39;&#39; to perform pseudo long-term distribution alignment, making the condensed set a good proxy of the real one during the whole training process; while from the inter-class view, we use the expert models to perform distribution calibration, ensuring the synthetic data remains in the real class region during condensing. Experiments demonstrate the proposed method achieves a SOTA performance while maintaining comparable efficiency with the original DM across various scenarios. Source codes are available at https://github.com/Hansong-Zhang/DANCE. Keywords: Computer Vision: CV: Image and video synthesis and generation Computer Vision: CV: Machine learning for vision Machine Learning: ML: Optimization},
  archive   = {C_IJCAI},
  author    = {Hansong Zhang and Shikun Li and Fanzhao Lin and Weiping Wang and Zhenxing Qian and Shiming Ge},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/186},
  month     = {8},
  pages     = {1679-1687},
  title     = {DANCE: Dual-view distribution alignment for dataset condensation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Detector collapse: Backdooring object detection to
catastrophic overload or blindness in the physical world.
<em>IJCAI</em>, 1670–1678. (<a
href="https://doi.org/10.24963/ijcai.2024/185">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Object detection tasks, crucial in safety-critical systems like autonomous driving, focus on pinpointing object locations. These detectors are known to be susceptible to backdoor attacks. However, existing backdoor techniques have primarily been adapted from classification tasks, overlooking deeper vulnerabilities specific to object detection. This paper is dedicated to bridging this gap by introducing Detector Collapse (DC), a brand-new backdoor attack paradigm tailored for object detection. DC is designed to instantly incapacitate detectors (i.e., severely impairing detector&#39;s performance and culminating in a denial-of-service). To this end, we develop two innovative attack schemes: Sponge for triggering widespread misidentifications and Blinding for rendering objects invisible. Remarkably, we introduce a novel poisoning strategy exploiting natural objects, enabling DC to act as a practical backdoor in real-world environments. Our experiments on different detectors across several benchmarks show a significant improvement (~10%-60% absolute and ~2-7x relative) in attack efficacy over state-of-the-art attacks. Keywords: Computer Vision: CV: Recognition (object detection, categorization) AI Ethics, Trust, Fairness: ETF: Trustworthy AI AI Ethics, Trust, Fairness: ETF: Safety and robustness},
  archive   = {C_IJCAI},
  author    = {Hangtao Zhang and Shengshan Hu and Yichen Wang and Leo Yu Zhang and Ziqi Zhou and Xianlong Wang and Yanjun Zhang and Chao Chen},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/185},
  month     = {8},
  pages     = {1670-1678},
  title     = {Detector collapse: Backdooring object detection to catastrophic overload or blindness in the physical world},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). AK4Prompts: Aesthetics-driven automatically
keywords-ranking for prompts in text-to-image models. <em>IJCAI</em>,
1661–1669. (<a href="https://doi.org/10.24963/ijcai.2024/184">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Current text-to-image synthesis (TIS) models have demonstrated the ability to generate high-fidelity images based on textual prompts. However, the efficacy of these models heavily relies on the keywords present in the prompts, and there is a dearth of objective analysis regarding how different keywords impact the ultimate quality of generated results. Therefore, manual evaluation becomes necessary but limited and inefficient to ascertain the role played by keywords. In this paper, we propose automated keywords-ranking for prompts (AK4Prompts), a keyword evaluation model based on mainstream TIS models that explicitly quantifies the multidimensional impact of various keywords on image generation based on prompts. To enable personalized keyword evaluation based on prompt content, we propose decoupling the latent representations of keywords and prompts in TIS models, followed by integrating the semantic features of prompts into keywords. For quantitative and multidimensional evaluation, we align the fused features of keywords using HPSv2, aesthetic score, and CLIP score, each representing distinct factors contributing to keyword impact. Our AK4Prompts can flexibly and automatically select the keywords that best match the original prompt based on individual user preferences. Extensive experimental results show the superiority of AK4Prompts to improve the quality of generated images significantly over strong baselines. Our approach not only enhances usability and user experience but also addresses the current gap in automated analysis and evaluation of keyword effects. Our code is availableat https://github.com/mRobotit/AK4Prompts. Keywords: Computer Vision: CV: Image and video synthesis and generation Computer Vision: CV: Computational photography Computer Vision: CV: Machine learning for vision},
  archive   = {C_IJCAI},
  author    = {Haiyang Zhang and Mengchao Wang and Shuai He and Anlong Ming},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/184},
  month     = {8},
  pages     = {1661-1669},
  title     = {AK4Prompts: Aesthetics-driven automatically keywords-ranking for prompts in text-to-image models},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Diffusion mask-driven visual-language tracking.
<em>IJCAI</em>, 1652–1660. (<a
href="https://doi.org/10.24963/ijcai.2024/183">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Most existing visual-language trackers greatly rely on the initial language descriptions on a target object to extract their multi-modal features. However, the initial language descriptions are often inaccurate in a highly time-varying video sequence and thus greatly deteriorate their tracking performance due to the low quality of extracted multi-modal features. To address this challenge, we propose a Diffusion Mask-Driven Visual-language Tracker (DMTrack) based on a diffusion model. Confronting the issue of low-quality multi-modal features due to inaccurate language descriptions, we leverage the diffusion model to capture high-quality semantic information from multi-modal features and transform it into target mask features. During the training phase, we further enhance the diffusion model&#39;s perception of pixel-level features by calculating the loss between the target mask features and the ground truth masks. Additionally, we perform joint localization of the target using both target mask features and visual features, instead of relying solely on multi-modal features for localization. Through extensive experiments on four tracking benchmarks (i.e., LaSOT, TNL2K, LaSOText, and OTB-Lang), we validate that our proposed Diffusion Mask-Driven Visual-language Tracker can improve the robustness and effectiveness of the model. Keywords: Computer Vision: CV: Motion and tracking},
  archive   = {C_IJCAI},
  author    = {Guangtong Zhang and Bineng Zhong and Qihua Liang and Zhiyi Mo and Shuxiang Song},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/183},
  month     = {8},
  pages     = {1652-1660},
  title     = {Diffusion mask-driven visual-language tracking},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards dynamic-prompting collaboration for source-free
domain adaptation. <em>IJCAI</em>, 1643–1651. (<a
href="https://doi.org/10.24963/ijcai.2024/182">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In domain adaptation, challenges such as data privacy constraints can impede access to source data, catalyzing the development of source-free domain adaptation (SFDA) methods. However, current approaches heavily rely on models trained on source data, posing the risk of overfitting and suboptimal generalization.This paper introduces a dynamic prompt learning paradigm that harnesses the power of large-scale vision-language models to enhance the semantic transfer of source models. Specifically, our approach fosters robust and adaptive collaboration between the source-trained model and the vision-language model, facilitating the reliable extraction of domain-specific information from unlabeled target data, while consolidating domain-invariant knowledge. Without the need for accessing source data, our method amalgamates the strengths inherent in both traditional SFDA approaches and vision-language models, formulating a collaborative framework for addressing SFDA challenges. Extensive experiments conducted on three benchmark datasets showcase the superiority of our framework over previous SOTA methods. Keywords: Computer Vision: CV: Transfer, low-shot, semi- and un- supervised learning Computer Vision: CV: Multimodal learning Computer Vision: CV: Representation learning},
  archive   = {C_IJCAI},
  author    = {Mengmeng Zhan and Zongqian Wu and Rongyao Hu and Ping Hu and Heng Tao Shen and Xiaofeng Zhu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/182},
  month     = {8},
  pages     = {1643-1651},
  title     = {Towards dynamic-prompting collaboration for source-free domain adaptation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MARS: Multimodal active robotic sensing for articulated
characterization. <em>IJCAI</em>, 1634–1642. (<a
href="https://doi.org/10.24963/ijcai.2024/181">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Precise perception of articulated objects is vital for empowering service robots. Recent studies mainly focus on point cloud, a single-modal approach, often neglecting vital texture and lighting details and assuming ideal conditions like optimal viewpoints, unrepresentative of real-world scenarios. To address these limitations, we introduce MARS, a novel framework for articulated object characterization. It features a multi-modal fusion module utilizing multi-scale RGB features to enhance point cloud features, coupled with reinforcement learning-based active sensing for autonomous optimization of observation viewpoints. In experiments conducted with various articulated object instances from the PartNet-Mobility dataset, our method outperformed current state-of-the-art methods in joint parameter estimation accuracy. Additionally, through active sensing, MARS further reduces errors, demonstrating enhanced efficiency in handling suboptimal viewpoints. Furthermore, our method effectively generalizes to real-world articulated objects, enhancing robot interactions. Code is available at https://github.com/robhlzeng/MARS. Keywords: Computer Vision: CV: 3D computer vision Computer Vision: CV: Multimodal learning Robotics: ROB: Perception Robotics: ROB: Manipulation},
  archive   = {C_IJCAI},
  author    = {Hongliang Zeng and Ping Zhang and Chengjiong Wu and Jiahua Wang and Tingyu Ye and Fang Li},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/181},
  month     = {8},
  pages     = {1634-1642},
  title     = {MARS: Multimodal active robotic sensing for articulated characterization},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CIC: A framework for culturally-aware image captioning.
<em>IJCAI</em>, 1625–1633. (<a
href="https://doi.org/10.24963/ijcai.2024/180">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Image Captioning generates descriptive sentences from images using Vision-Language Pre-trained models (VLPs) such as BLIP, which has improved greatly. However, current methods lack the generation of detailed descriptive captions for the cultural elements depicted in the images, such as the traditional clothing worn by people from Asian cultural groups. In this paper, we propose a new framework, Culturally-aware Image Captioning (CIC), that generates captions and describes cultural elements extracted from cultural visual elements in images representing cultures. Inspired by methods combining visual modality and Large Language Models (LLMs) through appropriate prompts, our framework (1) generates questions based on cultural categories from images, (2) extracts cultural visual elements from Visual Question Answering (VQA) using generated questions, and (3) generates culturally-aware captions using LLMs with the prompts. Our human evaluation conducted on 45 participants from 4 different cultural groups with a high understanding of the corresponding culture shows that our proposed framework generates more culturally descriptive captions when compared to the image captioning baseline based on VLPs. Resources can be found at https://shane3606.github.io/cic. Keywords: Computer Vision: CV: Bias, fairness and privacy Computer Vision: CV: Scene analysis and understanding Computer Vision: CV: Vision, language and reasoning},
  archive   = {C_IJCAI},
  author    = {Youngsik Yun and Jihie Kim},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/180},
  month     = {8},
  pages     = {1625-1633},
  title     = {CIC: A framework for culturally-aware image captioning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unified unsupervised salient object detection via knowledge
transfer. <em>IJCAI</em>, 1616–1624. (<a
href="https://doi.org/10.24963/ijcai.2024/179">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, unsupervised salient object detection (USOD) has gained increasing attention due to its annotation-free nature. However, current methods mainly focus on specific tasks such as RGB and RGB-D, neglecting the potential for task migration. In this paper, we propose a unified USOD framework for generic USOD tasks. Firstly, we propose a Progressive Curriculum Learning-based Saliency Distilling (PCL-SD) mechanism to extract saliency cues from a pre-trained deep network. This mechanism starts with easy samples and progressively moves towards harder ones, to avoid initial interference caused by hard samples. Afterwards, the obtained saliency cues are utilized to train a saliency detector, and we employ a Self-rectify Pseudo-label Refinement (SPR) mechanism to improve the quality of pseudo-labels. Finally, an adapter-tuning method is devised to transfer the acquired saliency knowledge, leveraging shared knowledge to attain superior transferring performance on the target tasks. Extensive experiments on five representative SOD tasks confirm the effectiveness and feasibility of our proposed method. Code and supplement materials are available at https://github.com/I2-Multimedia-Lab/A2S-v3. Keywords: Computer Vision: CV: Recognition (object detection, categorization) Computer Vision: CV: Scene analysis and understanding Machine Learning: ML: Unsupervised learning},
  archive   = {C_IJCAI},
  author    = {Yao Yuan and Wutao Liu and Pan Gao and Qun Dai and Jie Qin},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/179},
  month     = {8},
  pages     = {1616-1624},
  title     = {Unified unsupervised salient object detection via knowledge transfer},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hundredfold accelerating for pathological images diagnosis
and prognosis through self-reform critical region focusing.
<em>IJCAI</em>, 1607–1615. (<a
href="https://doi.org/10.24963/ijcai.2024/178">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Pathological slides are commonly gigapixel images with abundant information and are therefore significant for clinical diagnosis. However, the ultra-large size makes both training and evaluation extremely time-consuming. Most existing methods need to crop the slide into patches, which also leads to large memory requirements. In this paper, we propose the Self-reform Multilayer Transformer (SMT) to accelerate the pathological image diagnosis and prognosis. Inspired by the pathologists&#39; diagnostic procedure, SMT is designed to achieve layer-by-layer focus on critical regions. In the forward process, the first layer takes thumbnails as inputs and measures the significance of each patch that deserves focusing. Images from focused regions are cropped with a higher magnification and used as the input of the next layer. By analogy, the third layer inputs are focused images of second layer, which contain abundant cellular features. In addition to the forward focusing, the backward reform strategy is proposed to improve the precision of former layers. This cyclic process achieves iterative interactions for better performance on both classification and focusing. In this way, only a small part of critical patches are required in SMT for diagnosis and prognosis. Sufficient experiments demonstrate that SMT achieves hundreds times faster speed, while achieving comparable accuracy and less storage compared with existing SOTA methods. Keywords: Computer Vision: CV: Biomedical image analysis Computer Vision: CV: Recognition (object detection, categorization) Machine Learning: ML: Classification},
  archive   = {C_IJCAI},
  author    = {Xiaotian Yu and Haoming Luo and Jiacong Hu and Xiuming Zhang and Yuexuan Wang and Wenjie Liang and Yijun Bei and Mingli Song and Zunlei Feng},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/178},
  month     = {8},
  pages     = {1607-1615},
  title     = {Hundredfold accelerating for pathological images diagnosis and prognosis through self-reform critical region focusing},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Spear: Evaluate the adversarial robustness of compressed
neural models. <em>IJCAI</em>, 1598–1606. (<a
href="https://doi.org/10.24963/ijcai.2024/177">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As Artificial Intelligence evolves, the neural models vulnerable to adversarial attacks may produce fatal results in critical applications. This paper mainly discusses the robustness of the compressed neural models facing adversarial attacks. A few studies discuss the interaction between model compression and adversarial attack. However, they focus on the robustness against the traditional attacks designed for the dense models, not the attacks intended explicitly for the compressed models, using sparsity and quantization techniques. Compressed models often have fewer parameters and smaller sizes that are more friendly to resource-limited devices than dense models, so they are widely deployed in various edge and mobile devices. However, introducing the sparsity and quantization into neural models further imposes higher attack risks. A specific adversarial attack method (Spear) is proposed to generate the particular adversarial attack samples for evaluating the robustness of the compressed models. The Spear attack finds minimal perturbations to create the attack samples to maximize the different behaviors between the compressed and dense reference models. We demonstrate the proposed Spear attack technique can generally be applied to various networks and tasks through quantitative and ablation experiments. Keywords: Computer Vision: CV: Adversarial learning, adversarial attack and defense methods Machine Learning: ML: Adversarial machine learning Machine Learning: ML: Robustness},
  archive   = {C_IJCAI},
  author    = {Chong Yu and Tao Chen and Zhongxue Gan and Jiayuan Fan},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/177},
  month     = {8},
  pages     = {1598-1606},
  title     = {Spear: Evaluate the adversarial robustness of compressed neural models},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). 1DFormer: A transformer architecture learning 1D landmark
representations for facial landmark tracking. <em>IJCAI</em>, 1588–1597.
(<a href="https://doi.org/10.24963/ijcai.2024/176">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, heatmap regression methods based on 1D landmark representations have shown prominent performance on locating facial landmarks. However, previous methods ignored to make deep explorations on the good potentials of 1D landmark representations for sequential and structural modeling of multiple landmarks to track facial landmarks. To address this limitation, we propose a Transformer architecture, namely 1DFormer, which learns informative 1D landmark representations by capturing the dynamic and the geometric patterns of landmarks via token communications in both temporal and spatial dimensions for facial landmark tracking. For temporal modeling, we propose a confidence-enhanced multi-head attention mechanism with a recurrently token mixing strategy to adaptively and robustly embed long-term landmark dynamics into their 1D representations; for structure modeling, we design intra-group and inter-group geometric encoding mechanisms to encode the component-level as well as global-level facial structure patterns as a refinement for the 1D representations of landmarks through token communications in the spatial dimension via 1D convolutional layers. Experimental results on the 300VW and the TF databases show that 1DFormer successfully models the long-range sequential patterns as well as the inherent facial structures to learn informative 1D representations of landmark sequences, and achieves state-of-the-art performance on facial landmark tracking. Codes of our model are available in the supplementary materials. Keywords: Computer Vision: CV: Biometrics, face, gesture and pose recognition Computer Vision: CV: Motion and tracking Computer Vision: CV: Representation learning},
  archive   = {C_IJCAI},
  author    = {Shi Yin and Shijie Huang and Shangfei Wang and Jinshui Hu and Tao Guo and Bing Yin and Baocai Yin and Cong Liu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/176},
  month     = {8},
  pages     = {1588-1597},
  title     = {1DFormer: A transformer architecture learning 1D landmark representations for facial landmark tracking},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DiffStega: Towards universal training-free coverless image
steganography with diffusion models. <em>IJCAI</em>, 1579–1587. (<a
href="https://doi.org/10.24963/ijcai.2024/175">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Traditional image steganography focuses on concealing one image within another, aiming to avoid steganalysis by unauthorized entities. Coverless image steganography (CIS) enhances imperceptibility by not using any cover image. Recent works have utilized text prompts as keys in CIS through diffusion models. However, this approach faces three challenges: invalidated when private prompt is guessed, crafting public prompts for semantic diversity, and the risk of prompt leakage during frequent transmission. To address these issues, we propose DiffStega, an innovative training-free diffusion-based CIS strategy for universal application. DiffStega uses a password-dependent reference image as an image prompt alongside the text, ensuring that only authorized parties can retrieve the hidden information. Furthermore, we develop Noise Flip technique to further secure the steganography against unauthorized decryption. To comprehensively assess our method across general CIS tasks, we create a dataset comprising various image steganography instances. Experiments indicate substantial improvements in our method over existing ones, particularly in aspects of versatility, password sensitivity, and recovery quality. Codes are available at https://github.com/evtricks/DiffStega. Keywords: Computer Vision: CV: Machine learning for vision Computer Vision: CV: Applications Computer Vision: CV: Structural and model-based approaches, knowledge representation and reasoning},
  archive   = {C_IJCAI},
  author    = {Yiwei Yang and Zheyuan Liu and Jun Jia and Zhongpai Gao and Yunhao Li and Wei Sun and Xiaohong Liu and Guangtao Zhai},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/175},
  month     = {8},
  pages     = {1579-1587},
  title     = {DiffStega: Towards universal training-free coverless image steganography with diffusion models},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fusion from a distributional perspective: A unified
symbiotic diffusion framework for any multisource remote sensing data
classification. <em>IJCAI</em>, 1570–1578. (<a
href="https://doi.org/10.24963/ijcai.2024/174">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The joint classification of multisource remote sensing data is a prominent research field. However, most of the existing works are tailored for two specific data sources, which fail to effectively address the diverse combinations of data sources in practical applications. The importance of designing a unified network with applicability has been disregarded. In this paper, we propose a unified and self-supervised Symbiotic Diffusion framework (named SymDiffuser), which achieves the joint classification of any pair of different remote sensing data sources in a single model. The SymDiffuser captures the inter-modal relationship through establishing reciprocal conditional distributions across diverse sources step by step. The fusion process of multisource data is consistently represented within the framework from a data distribution perspective. Subsequently, features under the current conditional distribution at each time step is integrated during the downstream phase to accomplish the classification task. Such joint classification methodology transcends source-specific considerations, rendering it applicable to remote sensing data from any diverse sources. The experimental results showcase the framework&#39;s potential in achieving state-of-the-art performance in multimodal fusion classification task. Keywords: Computer Vision: CV: Recognition (object detection, categorization) Machine Learning: ML: Classification},
  archive   = {C_IJCAI},
  author    = {Teng Yang and Song Xiao and Wenqian Dong and Jiahui Qu and Yueguang Yang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/174},
  month     = {8},
  pages     = {1570-1578},
  title     = {Fusion from a distributional perspective: A unified symbiotic diffusion framework for any multisource remote sensing data classification},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Self-supervised monocular depth estimation in the dark:
Towards data distribution compensation. <em>IJCAI</em>, 1561–1569. (<a
href="https://doi.org/10.24963/ijcai.2024/173">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Nighttime self-supervised monocular depth estimation has received increasing attention in recent years. However, using night images for self-supervision is unreliable because the photometric consistency assumption is usually violated in the videos taken under complex lighting conditions. Even with domain adaptation or photometric loss repair, performance is still limited by the poor supervision of night images on trainable networks. In this paper, we propose a self-supervised nighttime monocular depth estimation method that does not use any night images during training. Our framework utilizes day images as a stable source for self-supervision and applies physical priors (e.g., wave optics, reflection model and read-shot noise model) to compensate for some key day-night differences. With day-to-night data distribution compensation, our framework can be trained in an efficient one-stage self-supervised manner. Though no nighttime images are considered during training, qualitative and quantitative results demonstrate that our method achieves SoTA depth estimating results on the challenging nuScenes-Night and RobotCar-Night compared with existing methods. Keywords: Computer Vision: CV: 3D computer vision Computer Vision: CV: Other Computer Vision: CV: Scene analysis and understanding Computer Vision: CV: Transfer, low-shot, semi- and un- supervised learning},
  archive   = {C_IJCAI},
  author    = {Haolin Yang and Chaoqiang Zhao and Lu Sheng and Yang Tang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/173},
  month     = {8},
  pages     = {1561-1569},
  title     = {Self-supervised monocular depth estimation in the dark: Towards data distribution compensation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). 3D vision and language pretraining with large-scale
synthetic data. <em>IJCAI</em>, 1552–1560. (<a
href="https://doi.org/10.24963/ijcai.2024/172">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {3D Vision-Language Pre-training (3D-VLP) aims to provide a pre-train model which can bridge 3D scenes with natural language, which is an important technique for embodied intelligence. However, current 3D-VLP datasets are hindered by limited scene-level diversity and insufficient fine-grained annotations (only 1.2K scenes and 280K textual annotations in ScanScribe), primarily due to the labor-intensive of collecting and annotating 3D scenes. To overcome these obstacles, we construct SynVL3D, a comprehensive synthetic scene-text corpus with 10K indoor scenes and 1M descriptions at object, view, and room levels, which has the advantages of diverse scene data, rich textual descriptions, multi-grained 3D-text associations, and low collection cost. Utilizing the rich annotations in SynVL3D, we pre-train a simple and unified Transformer for aligning 3D and language with multi-grained pretraining tasks. Moreover, we propose a synthetic-to-real domain adaptation in downstream task fine-tuning process to address the domain shift. Through extensive experiments, we verify the effectiveness of our model design by achieving state-of-the-art performance on downstream tasks including visual grounding, dense captioning, and question answering. Codes are available at: https://github.com/idejie/3DSyn Keywords: Computer Vision: CV: 3D computer vision Computer Vision: CV: Multimodal learning Computer Vision: CV: Vision, language and reasoning},
  archive   = {C_IJCAI},
  author    = {Dejie Yang and Zhu Xu and Wentao Mo and Qingchao Chen and Siyuan Huang and Yang Liu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/172},
  month     = {8},
  pages     = {1552-1560},
  title     = {3D vision and language pretraining with large-scale synthetic data},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reschedule diffusion-based bokeh rendering. <em>IJCAI</em>,
1543–1551. (<a href="https://doi.org/10.24963/ijcai.2024/171">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Bokeh rendering for images shot with small apertures has drawn much attention in practice. Very recently people start to explore diffusion models for bokeh rendering, aiming to leverage the models&#39; surging power of image generation. However, we can clearly observe two big issues with the images rendered by diffusion models: large fluctuation and severe color deviation. To address these issues, we propose in this paper a prior-aware sampling approach, which can adaptively control the noise scale through learned priors, and a prior-aware noise scheduling strategy, which can greatly reduce the number of inference steps without sacrificing performance. Extensive experiments show that our method can effectively alleviate the fluctuation problem of sampling results while ensuring similar color styles to the input image. In addition, our method outperforms state-of-the-art methods, sometimes even with only two steps of sampling. Our code is available at https://github.com/Loeiii/Reschedule-Diffusion-based-Bokeh-Rendering. Keywords: Computer Vision: CV: Image and video synthesis and generation Humans and AI: HAI: Applications Machine Learning: ML: Applications},
  archive   = {C_IJCAI},
  author    = {Shiyue Yan and Xiaoshi Qiu and Qingmin Liao and Jing-Hao Xue and Shaojun Liu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/171},
  month     = {8},
  pages     = {1543-1551},
  title     = {Reschedule diffusion-based bokeh rendering},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DTS-TPT: Dual temporal-sync test-time prompt tuning for
zero-shot activity recognition. <em>IJCAI</em>, 1534–1542. (<a
href="https://doi.org/10.24963/ijcai.2024/170">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Finetuning the large vision-language models on video data with a set of learnable prompts has shown promising performance on zero-shot activity recognition but still requires extra video data and expensive training costs. Inspired by recent Test-time Prompt Tuning (TPT) on the image domain, this work attempts to extend TPT to video data for zero-shot activity recognition. However, monotonous spatial augmentation and short class names cannot meet the need to capture diverse and complicated semantics of human behavior during prompt tuning. To this end, this work proposes a Dual Temporal-Sync Test-time Prompt Tuning (DTS-TPT) framework for zero-shot activity recognition. DTS-TPT tunes the learnable prompts appended to text inputs on video feature sequences of different temporal scales in multiple steps during test time. In each tuning step, we minimize the semantic consistency among the predictions from video feature sequences randomly augmented via AugMix with both original class names and the corresponding description generated through LLM. Compared with the state-of-the-art methods, the proposed method improves the zero-shot top-1 accuracy by approximately 2% ~ 5% on popular benchmarks. The code is available at https://github.com/quhongyu/DTS-TPT. Keywords: Computer Vision: CV: Video analysis and understanding Computer Vision: CV: Transfer, low-shot, semi- and un- supervised learning},
  archive   = {C_IJCAI},
  author    = {Rui Yan and Hongyu Qu and Xiangbo Shu and Wenbin Li and Jinhui Tang and Tieniu Tan},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/170},
  month     = {8},
  pages     = {1534-1542},
  title     = {DTS-TPT: Dual temporal-sync test-time prompt tuning for zero-shot activity recognition},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DFMDA-net: Dense fusion and multi-dimension aggregation
network for image restoration. <em>IJCAI</em>, 1525–1533. (<a
href="https://doi.org/10.24963/ijcai.2024/169">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The U-shape (encoder-decoder) architecture, combined with effective blocks, has shown significant success in image restoration. In U-shape models, there is insufficient focus on the feature fusion problem between encoder and decoder features at the same level. Current methods often employ simplistic operations like summation or concatenation, which makes it difficult to strike a balance between performance and complexity. To address this issue, we propose a compression-in-the-middle mechanism, termed Integration-Compression-Integration (ICI), which effectively conducts dense fusion and avoids information loss. From the block design perspective, we design a multi-dimension aggregation (MDA) mechanism, capable of effectively aggregating features from both the channel and spatial dimension. Combining the IntegrationCompression-Integration feature fusion and the multi-dimension aggregation, our dense fusion and multi-dimension aggregation network (DFMDANet) achieves superior performance over state-ofthe-art algorithms on 16 benchmarking datasets for numerous image restoration tasks. Keywords: Computer Vision: CV: Machine learning for vision Computer Vision: CV: Representation learning Machine Learning: ML: Attention models Machine Learning: ML: Convolutional networks},
  archive   = {C_IJCAI},
  author    = {Huibin Yan and Shuoyao Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/169},
  month     = {8},
  pages     = {1525-1533},
  title     = {DFMDA-net: Dense fusion and multi-dimension aggregation network for image restoration},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ProtoPFormer: Concentrating on prototypical parts in vision
transformers for interpretable image recognition. <em>IJCAI</em>,
1516–1524. (<a href="https://doi.org/10.24963/ijcai.2024/168">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Prototypical part network (ProtoPNet) and its variants have drawn wide attention and been applied to various tasks due to their inherent self-explanatory property. Previous ProtoPNets are primarily built upon convolutional neural networks (CNNs). Therefore, it is natural to investigate whether these explainable methods can be advantageous for the recently emerged Vision Transformers (ViTs). However, directly utilizing ViT-backed models as backbones can lead to prototypes paying excessive attention to background positions rather than foreground objects (i.e., the “distraction” problem). To address the problem, this paper proposes prototypical part Transformer (ProtoPFormer) for interpretable image recognition. Based the architectural characteristics of ViTs, we modify the original ProtoPNet by creating separate global and local branches, each accompanied by corresponding prototypes that can capture and highlight representative holistic and partial features. Specifically, the global prototypes can guide local prototypes to concentrate on the foreground and effectively suppress the background influence. Subsequently, local prototypes are explicitly supervised to concentrate on different discriminative visual parts. Finally, the two branches mutually correct each other and jointly make the final decisions. Moreover, extensive experiments demonstrate that ProtoPFormer can consistently achieve superior performance on accuracy, visualization results, and quantitative interpretability evaluation over the state-of-the-art (SOTA) baselines. Our code has been released at https://github.com/zju-vipa/ProtoPFormer. Keywords: Computer Vision: CV: Interpretability and transparency Computer Vision: CV: Recognition (object detection, categorization) Computer Vision: CV: Representation learning},
  archive   = {C_IJCAI},
  author    = {Mengqi Xue and Qihan Huang and Haofei Zhang and Jingwen Hu and Jie Song and Mingli Song and Canghong Jin},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/168},
  month     = {8},
  pages     = {1516-1524},
  title     = {ProtoPFormer: Concentrating on prototypical parts in vision transformers for interpretable image recognition},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning spatial similarity distribution for few-shot object
counting. <em>IJCAI</em>, 1507–1515. (<a
href="https://doi.org/10.24963/ijcai.2024/167">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Few-shot object counting aims to count the number of objects in a query image that belong to the same class as the given exemplar images. Existing methods compute the similarity between the query image and exemplars in the 2D spatial domain and perform regression to obtain the counting number. However, these methods overlook the rich information about the spatial distribution of similarity on the exemplar images, leading to significant impact on matching accuracy. To address this issue, we propose a network learning Spatial Similarity Distribution (SSD) for few-shot object counting, which preserves the spatial structure of exemplar features and calculates a 4D similarity pyramid point-to-point between the query features and exemplar features, capturing the complete distribution information for each point in the 4D similarity space. We propose a Similarity Learning Module (SLM) which applies the efficient center-pivot 4D convolutions on the similarity pyramid to map different similarity distributions to distinct predicted density values, thereby obtaining accurate count. Furthermore, we also introduce a Feature Cross Enhancement (FCE) module that enhances query and exemplar features mutually to improve the accuracy of feature matching. Our approach outperforms state-of-the-art methods on multiple datasets, including FSC-147 and CARPK. Code is available at https://github.com/CBalance/SSD. Keywords: Computer Vision: CV: Transfer, low-shot, semi- and un- supervised learning Computer Vision: CV: Recognition (object detection, categorization)},
  archive   = {C_IJCAI},
  author    = {Yuanwu Xu and Feifan Song and Haofeng Zhang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/167},
  month     = {8},
  pages     = {1507-1515},
  title     = {Learning spatial similarity distribution for few-shot object counting},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Negative prompt driven complementary parallel representation
for open-world 3D object retrieval. <em>IJCAI</em>, 1498–1506. (<a
href="https://doi.org/10.24963/ijcai.2024/166">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The limited availability of supervised labels (positive information) poses a notable challenge for open-world retrieval. However, negative information is more easily obtained but remains underexploited in current methods. In this paper, we introduce the Negative Prompt Driven Complementary Parallel Representation (NPCP) framework, which navigates the complexities of open-world retrieval through the lens of Negative Prompts. Specifically, we employ the Parallel Exclusive Embedding (PEE) to effectively utilize the prompt information, bilaterally capturing both explicit negative and implicit positive signals. To address the challenges of embedding unification and generalization, our method leverages high-order correlations among objects through the Complementary Structure Tuning (CST), by constructing a complementary hypergraph based on bi-directional and cross-category correlations. We have developed four multimodal datasets for open-world 3D object retrieval with negative prompts: NPMN, NPAB, NPNT, and NPES. Extensive experiments and ablation studies on these four benchmarks demonstrate the superiority of our method over current state-of-the-art approaches. Keywords: Computer Vision: CV: 3D computer vision Computer Vision: CV: Image and video retrieval Computer Vision: CV: Representation learning},
  archive   = {C_IJCAI},
  author    = {Yang Xu and Yifan Feng and Yue Gao},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/166},
  month     = {8},
  pages     = {1498-1506},
  title     = {Negative prompt driven complementary parallel representation for open-world 3D object retrieval},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Beyond alignment: Blind video face restoration via
parsing-guided temporal-coherent transformer. <em>IJCAI</em>, 1489–1497.
(<a href="https://doi.org/10.24963/ijcai.2024/165">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multiple complex degradations are coupled in low-quality video faces in the real world. Therefore, blind video face restoration is a highly challenging ill-posed problem, requiring not only hallucinating high-fidelity details but also enhancing temporal coherence across diverse pose variations. Restoring each frame independently in a naive manner inevitably introduces temporal incoherence and artifacts from pose changes and keypoint localization errors. To address this, we propose the first blind video face restoration approach with a novel parsing-guided temporal-coherent transformer (PGTFormer) without pre-alignment. PGTFormer leverages semantic parsing guidance to select optimal face priors for generating temporally coherent artifact-free results. Specifically, we pre-train a temporal-spatial vector quantized auto-encoder on high-quality video face datasets to extract expressive context-rich priors. Then, the temporal parse-guided codebook predictor (TPCP) restores faces in different poses based on face parsing context cues without performing face pre-alignment. This strategy reduces artifacts and mitigates jitter caused by cumulative errors from face pre-alignment. Finally, the temporal fidelity regulator (TFR) enhances fidelity through temporal feature interaction and improves video temporal consistency. Extensive experiments on face videos show that our method outperforms previous face restoration baselines. The code will be released on https://github.com/kepengxu/PGTFormer. Keywords: Computer Vision: CV: Computational photography Computer Vision: CV: Image and video synthesis and generation Computer Vision: CV: Biometrics, face, gesture and pose recognition Computer Vision: CV: Applications},
  archive   = {C_IJCAI},
  author    = {Kepeng Xu and Li Xu and Gang He and Wenxin Yu and Yunsong Li},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/165},
  month     = {8},
  pages     = {1489-1497},
  title     = {Beyond alignment: Blind video face restoration via parsing-guided temporal-coherent transformer},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Aggregation and purification: Dual enhancement network for
point cloud few-shot segmentation. <em>IJCAI</em>, 1480–1488. (<a
href="https://doi.org/10.24963/ijcai.2024/164">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Point cloud few-shot semantic segmentation (PC-FSS) aims to segment objects within query samples of new categories given only a handful of annotated support samples. Although PC-FSS demonstrates enhanced category generalization capabilities compared to the fully supervised paradigm, the prevalent significant scene discrepancies, which can be systematically summarized into intra-semantic diversity and semantic inconsistency, have posed substantial challenges to the area. In this work, we design a novel Dual Enhancement Network (DENet) to comprehensively tackle different kinds of scene discrepancies in a coherent and synergistic framework. The proposed DENet enjoys several merits. First, we design a mutual aggregation module to reconcile the intrinsic tension between the support prototypes and query point features, and the intra-semantic diversity is diminished in a bidirectional manner. Second, the consistent purification strategy is introduced to eliminate ambiguous prototypes, thereby reducing the mismatches brought by semantic inconsistency. Extensive experiments on S3DIS and ScanNet under different settings demonstrate that DENet significantly outperforms previous SOTAs. Keywords: Computer Vision: CV: 3D computer vision Computer Vision: CV: Transfer, low-shot, semi- and un- supervised learning},
  archive   = {C_IJCAI},
  author    = {Guoxin Xiong and Yuan Wang and Zhaoyang Li and Wenfei Yang and Tianzhu Zhang and Xu Zhou and Shifeng Zhang and Yongdong Zhang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/164},
  month     = {8},
  pages     = {1480-1488},
  title     = {Aggregation and purification: Dual enhancement network for point cloud few-shot segmentation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unified single-stage transformer network for efficient RGB-t
tracking. <em>IJCAI</em>, 1471–1479. (<a
href="https://doi.org/10.24963/ijcai.2024/163">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Most existing RGB-T tracking networks extract modality features in a separate manner, which lacks interaction and mutual guidance between modalities. This limits the network&#39;s ability to adapt to the diverse dual-modality appearances of targets and the dynamic relationships between the modalities. Additionally, the three-stage fusion tracking paradigm followed by these networks significantly restricts the tracking speed. To overcome these problems, we propose a unified single-stage Transformer RGB-T tracking network, namely USTrack, which unifies the above three stages into a single ViT (Vision Transformer) backbone through joint feature extraction, fusion and relation modeling. With this structure, the network can not only extract the fusion features of templates and search regions under the interaction of modalities, but also significantly improve tracking speed through the single-stage fusion tracking paradigm. Furthermore, we introduce a novel feature selection mechanism based on modality reliability to mitigate the influence of invalid modalities for final prediction. Extensive experiments on three mainstream RGB-T tracking benchmarks show that our method achieves the new state-of-the-art while achieving the fastest tracking speed of 84.2FPS. Code is available at https://github.com/xiajianqiang/USTrack. Keywords: Computer Vision: CV: Motion and tracking Computer Vision: CV: Multimodal learning Computer Vision: CV: Video analysis and understanding},
  archive   = {C_IJCAI},
  author    = {Jianqiang Xia and Dianxi Shi and Ke Song and Linna Song and Xiaolei Wang and Songchang Jin and Chenran Zhao and Yu Cheng and Lei Jin and Zheng Zhu and Jianan Li and Gang Wang and Junliang Xing and Jian Zhao},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/163},
  month     = {8},
  pages     = {1471-1479},
  title     = {Unified single-stage transformer network for efficient RGB-T tracking},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). KTCN: Enhancing open-world object detection with knowledge
transfer and class-awareness neutralization. <em>IJCAI</em>, 1462–1470.
(<a href="https://doi.org/10.24963/ijcai.2024/162">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Open-World Object Detection (OWOD) has garnered widespread attention due to its ability to recall unannotated objects. Existing works generate pseudo-labels for the model using heuristic priors, which limits the model’s performance. In this paper, we leverage the knowledge of the large-scale visual model to provide supervision for unknown categories. Specifically, we use the Segment Anything Model (SAM) to generate raw pseudo-labels for potential objects and refine them through Intersection over Union (IOU) and the shortest bounding box side length. Nevertheless, the abundance of pseudo-labels still exacerbates the competition issue in the one-to-many label assignment. To address this, we propose the Dual Matching Label Assignment (DMLA) strategy. Furthermore, we propose the Class-Awareness Neutralizer (CAN) to reduce the model’s bias towards known categories. Evaluation results on open-world object detection benchmarks, including MS COCO and Pascal VOC, show that our method achieves nearly 200% the unknown recall rate of previous state-of-the-art (SOTA) methods, reaching 41.5 U-Recall. Additionally, our approach does not add any extra parameters, maintaining the inference speed advantage of Faster R-CNN, leading the SOTA methods based on deformable DETR at a speed of over 10 FPS. Our code is available at https://github.com/xxyzll/KTCN. Keywords: Computer Vision: CV: Recognition (object detection, categorization)},
  archive   = {C_IJCAI},
  author    = {Xing Xi and Yangyang Huang and Jinhao Lin and Ronghua Luo},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/162},
  month     = {8},
  pages     = {1462-1470},
  title     = {KTCN: Enhancing open-world object detection with knowledge transfer and class-awareness neutralization},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). ELF-UA: Efficient label-free user adaptation in gaze
estimation. <em>IJCAI</em>, 1452–1461. (<a
href="https://doi.org/10.24963/ijcai.2024/161">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider the problem of user-adaptive 3D gaze estimation. The performance of person-independent gaze estimation is limited due to interpersonal anatomical differences. Our goal is to provide a personalized gaze estimation model specifically adapted to a target user. Previous work on user-adaptive gaze estimation requires some labeled images of the target person data to fine-tune the model at test time. However, this can be unrealistic in real-world applications, since it is cumbersome for an end-user to provide labeled images. In addition, previous work requires the training data to have both gaze labels and person IDs. This data requirement makes it infeasible to use some of the available data. To tackle these challenges, this paper proposes a new problem called efficient label-free user adaptation in gaze estimation. Our model only needs a few unlabeled images of a target user for the model adaptation. During offline training, we have some labeled source data without person IDs and some unlabeled person-specific data. Our proposed method uses a meta-learning approach to learn how to adapt to a new user with only a few unlabeled images. Our key technical innovation is to use a generalization bound from domain adaptation to define the loss function in meta-learning, so that our method can effectively make use of both the labeled source data and the unlabeled person-specific data during training. Extensive experiments validate the effectiveness of our method on several challenging benchmarks. Keywords: Computer Vision: CV: Transfer, low-shot, semi- and un- supervised learning Humans and AI: HAI: Applications},
  archive   = {C_IJCAI},
  author    = {Yong Wu and Yang Wang and Sanqing Qu and Zhijun Li and Guang Chen},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/161},
  month     = {8},
  pages     = {1452-1461},
  title     = {ELF-UA: Efficient label-free user adaptation in gaze estimation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). OD-DETR: Online distillation for stabilizing training of
detection transformer. <em>IJCAI</em>, 1443–1451. (<a
href="https://doi.org/10.24963/ijcai.2024/160">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {DEtection TRansformer (DETR) becomes a dominant paradigm, mainly due to its common architecture with high accuracy and no post-processing. However, DETR suffers from unstable training dynamics. It consumes more data and epochs to converge compared with CNN-based detectors. This paper aims to stabilize DETR training through the online distillation. It utilizes a teacher model, accumulated by Exponential Moving Average (EMA), and distills its knowledge into the online model in following three aspects. First, the matching relation between object queries and ground truth (GT) boxes in the teacher is employed to guide the student, so queries within the student are not only assigned labels based on their own predictions, but also refer to the matching results from the teacher. Second, the teacher&#39;s initial query is given to the online student, and its prediction is directly constrained by the corresponding output from the teacher. Finally, the object queries from teacher&#39;s different decoding stages are used to build the auxiliary groups to accelerate the convergence. For each GT, two queries with the least matching costs are selected into this extra group, and they predict the GT box and participate the optimization. Extensive experiments show that the proposed OD-DETR successfully stabilizes the training, and significantly increases the performance without bringing in more parameters. Keywords: Computer Vision: CV: Recognition (object detection, categorization)},
  archive   = {C_IJCAI},
  author    = {Shengjian Wu and Li Sun and Qingli Li},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/160},
  month     = {8},
  pages     = {1443-1451},
  title     = {OD-DETR: Online distillation for stabilizing training of detection transformer},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PointTFA: Training-free clustering adaption for large 3D
point cloud models. <em>IJCAI</em>, 1434–1442. (<a
href="https://doi.org/10.24963/ijcai.2024/159">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The success of contrastive learning models like CLIP, known for aligning 2D image-text pairs, has inspired the development of triplet alignment for Large 3D Point Cloud Models (3D-PCM). Examples like ULIP integrate images, text, and point clouds into a unified semantic space. However, despite showing impressive zero-shot capabilities, frozen 3D-PCM still falls short compared to fine-tuned methods, especially when downstream 3D datasets are significantly different from upstream data. Addressing this, we propose a Data-Efficient, Training-Free 3D Adaptation method named PointTFA that adjusts ULIP outputs with representative samples. PointTFA comprises the Representative Memory Cache (RMC) for selecting a representative support set, Cloud Query Refactor (CQR) for reconstructing a query cloud using the support set, and Training-Free 3D Adapter (3D-TFA) for inferring query categories from the support set. A key advantage of PointTFA is that it introduces no extra training parameters, yet outperforms vanilla frozen ULIP, closely approaching few-shot fine-tuning training methods in downstream cloud classification tasks like ModelNet10 &amp; 40 and ScanObjectNN. The code is available at: https://github.com/CaoChong-git/PointTFA. Keywords: Computer Vision: CV: 3D computer vision Computer Vision: CV: Recognition (object detection, categorization)},
  archive   = {C_IJCAI},
  author    = {Jinmeng Wu and Chong Cao and Hao Zhang and Basura Fernando and Yanbin Hao and Hanyu Hong},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/159},
  month     = {8},
  pages     = {1434-1442},
  title     = {PointTFA: Training-free clustering adaption for large 3D point cloud models},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Structure-aware spatial-temporal interaction network for
video shadow detection. <em>IJCAI</em>, 1425–1433. (<a
href="https://doi.org/10.24963/ijcai.2024/158">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Video shadow detection faces significant challenges due to ambiguous semantics and variable shapes. Existing video shadow detection algorithms typically overlook the fine shadow details, resulting in inconsistent detection between consecutive frames in complex real-world video scenarios. To address this issue, we propose a spatial-temporal feature interaction strategy, which refines and enhances global shadow semantics with local prior features in the modeling of shadow relations between frames. Moreover, a structure-aware shadow prediction module is proposed, which focuses on modeling the distance relation between local shadow edges and regions. Quantitative experimental results demonstrate that our approach significantly outperforms the state-of-the-art methods, providing stable and consistent shadow detection results in complex video shadow scenarios. Keywords: Computer Vision: CV: Recognition (object detection, categorization) Computer Vision: CV: Scene analysis and understanding Computer Vision: CV: Segmentation Computer Vision: CV: Video analysis and understanding},
  archive   = {C_IJCAI},
  author    = {Housheng Wei and Guanyu Xing and Jingwei Liao and Yanci Zhang and Yanli Liu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/158},
  month     = {8},
  pages     = {1425-1433},
  title     = {Structure-aware spatial-temporal interaction network for video shadow detection},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Boosting diffusion models with an adaptive momentum sampler.
<em>IJCAI</em>, 1416–1424. (<a
href="https://doi.org/10.24963/ijcai.2024/157">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Diffusion probabilistic models (DPMs) have been shown to generate high-quality images without the need for delicate adversarial training. The sampling process of DPMs is mathematically similar to Stochastic Gradient Descent (SGD), with both being iteratively updated with a function increment. Building on this, we present a novel reverse sampler for DPMs in this paper, drawing inspiration from the widely-used Adam optimizer. Our proposed sampler can be readily applied to a pre-trained diffusion model, utilizing momentum mechanisms and adaptive updating to enhance the generated image&#39;s quality. By effectively reusing update directions from early steps, our proposed sampler achieves a better balance between high-level semantics and low-level details. Additionally, this sampler is flexible and can be easily integrated into pre-trained DPMs regardless of the sampler used during training. Our experimental results on multiple benchmarks demonstrate that our proposed reverse sampler yields remarkable improvements over different baselines. Keywords: Computer Vision: CV: Image and video synthesis and generation},
  archive   = {C_IJCAI},
  author    = {Xiyu Wang and Anh-Dung Dinh and Daochang Liu and Chang Xu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/157},
  month     = {8},
  pages     = {1416-1424},
  title     = {Boosting diffusion models with an adaptive momentum sampler},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal graph learning and nuclear norm maximization for
deep cross-domain robust label propagation. <em>IJCAI</em>, 1407–1415.
(<a href="https://doi.org/10.24963/ijcai.2024/156">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Domain adaptation aims to achieve label transfer from a labeled source domain to an unlabeled target domain, where the two domains exhibit different distributions. Existing methods primarily concentrate on designing a feature extractor to learn better domain-invariant features, along with developing an effective classifier for reliable predictions. In this paper, we introduce optimal graph learning to generate a cross-domain graph that effectively connects the two domains, and two domain-specific graphs to capture domain-specific structures. On the one hand, we incorporate the three graphs into the label propagation (LP) classifier to enhance its robustness to distribution difference. On the other hand, we leverage the three graphs to introduce graph embedding losses, promoting the learning of locally discriminative and domain-invariant features. Furthermore, we maximize the nuclear norm of predictions in LP to enhance class diversity, thereby improving its robustness to class imbalance problem. Correspondingly, we develop an efficient algorithm to solve the associated optimization problem. Finally, we integrate the proposed LP and graph embedding losses into a deep neural network, resulting in our proposed deep cross-domain robust LP. Extensive experiments conducted on three cross-domain benchmark datasets demonstrate that our proposed approach could outperform existing state-of-the-art domain adaptation methods. Keywords: Computer Vision: CV: Transfer, low-shot, semi- and un- supervised learning Machine Learning: ML: Classification Machine Learning: ML: Feature extraction, selection and dimensionality reduction},
  archive   = {C_IJCAI},
  author    = {Wei Wang and Hanyang Li and Ke Shi and Chao Huang and Yang Cao and Cong Wang and Xiaochun Cao},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/156},
  month     = {8},
  pages     = {1407-1415},
  title     = {Optimal graph learning and nuclear norm maximization for deep cross-domain robust label propagation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Label-efficient semantic scene completion with scribble
annotations. <em>IJCAI</em>, 1398–1406. (<a
href="https://doi.org/10.24963/ijcai.2024/155">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Semantic scene completion aims to infer the 3D geometric structures with semantic classes from camera or LiDAR, which provide essential occupancy information in autonomous driving. Prior endeavors concentrate on constructing the network or benchmark in a fully supervised manner. While the dense occupancy grids need point-wise semantic annotations, which incur expensive and tedious labeling costs. In this paper, we build a new label-efficient benchmark, named ScribbleSC, where the sparse scribble-based semantic labels are combined with dense geometric labels for semantic scene completion. In particular, we propose a simple yet effective approach called Scribble2Scene, which bridges the gap between the sparse scribble annotations and fully-supervision. Our method consists of geometric-aware auto-labelers construction and online model training with an offline-to-online distillation module to enhance the performance. Experiments on SemanticKITTI demonstrate that Scribble2Scene achieves competitive performance against the fully-supervised counterparts, showing 99% performance of the fully-supervised models with only 13.5% voxels labeled. Both annotations of ScribbleSC and our full implementation are available at https://github.com/songw-zju/Scribble2Scene. Keywords: Computer Vision: CV: Scene analysis and understanding Computer Vision: CV: Applications},
  archive   = {C_IJCAI},
  author    = {Song Wang and Jiawei Yu and Wentong Li and Hao Shi and Kailun Yang and Junbo Chen and Jianke Zhu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/155},
  month     = {8},
  pages     = {1398-1406},
  title     = {Label-efficient semantic scene completion with scribble annotations},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). How to learn domain-invariant representations for visual
reinforcement learning: An information-theoretical perspective.
<em>IJCAI</em>, 1389–1397. (<a
href="https://doi.org/10.24963/ijcai.2024/154">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Despite the impressive success in visual control challenges, Visual Reinforcement Learning (VRL) policies have struggled to generalize to other scenarios. Existing works attempt to empirically improve the generalization capability, lacking theoretical support. In this work, we explore how to learn domain-invariant representations for VRL from an information-theoretical perspective. Specifically, we identify three Mutual Information (MI) terms. These terms highlight that a robust representation should preserve domain invariant information (return and dynamic transition) under significant observation perturbation. Furthermore, we relax the MI terms to derive three components for implementing a practical Mutual Information-based Invariant Representation (MIIR) algorithm for VRL. Extensive experiments demonstrate that MIIR achieves state-of-the-art generalization performance and the best sample efficiency in the DeepMind Control suite, Robotic Manipulation, and Carla. Keywords: Computer Vision: CV: Embodied vision: Active agents, simulation},
  archive   = {C_IJCAI},
  author    = {Shuo Wang and Zhihao Wu and Jinwen Wang and Xiaobo Hu and Youfang Lin and Kai Lv},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/154},
  month     = {8},
  pages     = {1389-1397},
  title     = {How to learn domain-invariant representations for visual reinforcement learning: An information-theoretical perspective},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Error-aware sampling in adaptive shells for neural surface
reconstruction. <em>IJCAI</em>, 1380–1388. (<a
href="https://doi.org/10.24963/ijcai.2024/153">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Neural implicit surfaces with signed distance functions (SDFs) achieve superior quality in 3D geometry reconstruction. However, training SDFs is time-consuming because it requires a great number of samples to calculate accurate weight distributions and a considerable amount of samples sampled from the distribution for integrating the rendering results. Some existing sampling strategies focus on this problem. During the training, they assume a spatially-consistent convergence speed of kernel size, thus still suffering from low convergence or errors. Instead, we introduce an error-aware sampling method based on thin intervals of valid weight distributions, dubbed adaptive shells, to reduce the number of samples while still maintaining the reconstruction accuracy. To this end, we first extend Laplace-based neural implicit surfaces with learned spatially-varying kernel sizes which indicates the range of valid weight distributions. Then, the adaptive shell for each ray is determined by an efficient double-clipping strategy with spatially-varying SDF values and kernel sizes, fitting larger kernel sizes to wider shells. Finally, we calculate the error-bounded cumulative distribution functions (CDFs) of shells to conduct efficient importance sampling, achieving low-variance rendering with fewer calculations. Extensive results in various scenes demonstrate the superiority of our sampling technique, including significantly reducing sample counts and training time, even improving the reconstruction quality. The code is available at https://github.com/erernan/ESampling. Keywords: Computer Vision: CV: 3D computer vision Computer Vision: CV: Applications},
  archive   = {C_IJCAI},
  author    = {Qi Wang and Yuchi Huo and Qi Ye and Rui Wang and Hujun Bao},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/153},
  month     = {8},
  pages     = {1380-1388},
  title     = {Error-aware sampling in adaptive shells for neural surface reconstruction},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Explore internal and external similarity for single image
deraining with graph neural networks. <em>IJCAI</em>, 1371–1379. (<a
href="https://doi.org/10.24963/ijcai.2024/152">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Patch-level non-local self-similarity is an important property of natural images. However, most existing methods do not consider this property into neural networks for image deraining, thus affecting recovery performance. Motivated by this property, we find that there exists significant patch recurrence property of a rainy image, that is, similar patches tend to recur many times in one image and its multi-scale images and external images. To better model this property for image detaining, we develop a multi-scale graph network with exemplars, called MSGNN, that contains two branches: 1) internal data-based supervised branch is used to model the internal relations of similar patches from the rainy image itself and its multi-scale images and 2) external data-participated unsupervised branch is used to model the external relations of the similar patches in the rainy image and exemplar. Specifically, we construct a graph model by searching the k-nearest neighboring patches from both the rainy images in a multi-scale framework and the exemplar. After obtaining the corresponding k neighboring patches from the multi-scale images and exemplar, we build a graph and aggregate them in an attentional manner so that the graph can provide more information from similar patches for image deraining. We embed the proposed graph in a deep neural network and train it in an end-to-end manner. Extensive experiments demonstrate that the proposed algorithm performs favorably against eight state-of-the-art methods on five public synthetic datasets and one real-world dataset. The source codes will be available at https://github.com/supersupercong/MSGNN. Keywords: Computer Vision: CV: Applications Computer Vision: CV: Computational photography},
  archive   = {C_IJCAI},
  author    = {Cong Wang and Wei Wang and Chengjin Yu and Jie Mu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/152},
  month     = {8},
  pages     = {1371-1379},
  title     = {Explore internal and external similarity for single image deraining with graph neural networks},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FLDM-VTON: Faithful latent diffusion model for virtual
try-on. <em>IJCAI</em>, 1362–1370. (<a
href="https://doi.org/10.24963/ijcai.2024/151">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Despite their impressive generative performance, latent diffusion model-based virtual try-on (VTON) methods lack faithfulness to crucial details of the clothes, such as style, pattern, and text. To alleviate these issues caused by the diffusion stochastic nature and latent supervision, we propose a novel Faithful Latent Diffusion Model for VTON, termed FLDM-VTON. FLDM-VTON improves the conventional latent diffusion process in three major aspects. First, we propose incorporating warped clothes as both the starting point and local condition, supplying the model with faithful clothes priors. Second, we introduce a novel clothes flattening network to constrain generated try-on images, providing clothes-consistent faithful supervision. Third, we devise a clothes-posterior sampling for faithful inference, further enhancing the model performance over conventional clothes-agnostic Gaussian sampling. Extensive experimental results on the benchmark VITON-HD and Dress Code datasets demonstrate that our FLDM-VTON outperforms state-of-the-art baselines and is able to generate photo-realistic try-on images with faithful clothing details. Keywords: Computer Vision: CV: Applications Computer Vision: CV: Image and video synthesis and generation},
  archive   = {C_IJCAI},
  author    = {Chenhui Wang and Tao Chen and Zhihao Chen and Zhizhong Huang and Taoran Jiang and Qi Wang and Hongming Shan},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/151},
  month     = {8},
  pages     = {1362-1370},
  title     = {FLDM-VTON: Faithful latent diffusion model for virtual try-on},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). OSIC: A new one-stage image captioner coined.
<em>IJCAI</em>, 1353–1361. (<a
href="https://doi.org/10.24963/ijcai.2024/150">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Mainstream image captioning models are usually two-stage captioners, i.e., encoding the region features by a pre-trained detector and then feeding them into a language model to generate the captions. However, such a two-stage procedure will lead to a task-based information gap that decreases the performance, because the region features in the detection task are suboptimal representations and cannot provide all the necessary information for subsequent captions generation. Besides, the region features are usually represented from the last layer of the detectors that lose the local details of images. In this paper, we propose a novel One-Stage Image Captioner (OSIC) with dynamic multi-sight learning, which directly transforms the images into descriptive sentences in one stage for eliminating the information gap. Specifically, to obtain rich features, multi-level features are captured by Swin Transformer, and then fed into a novel dynamic multi-sight embedding module to exploit both the global structure and local texture of input images. To enhance the global modeling capacity of the visual encoder, we propose a new dual-dimensional refining to non-locally model the features interaction. As a result, OSIC can directly obtain rich semantic information to improve the captioner. Extensive comparisons on the benchmark MS-COCO, Flickr8K and Flickr30K datasets verified the superior performance of our method. Keywords: Computer Vision: CV: Machine learning for vision Computer Vision: CV: Scene analysis and understanding Computer Vision: CV: Vision, language and reasoning Natural Language Processing: NLP: Language generation},
  archive   = {C_IJCAI},
  author    = {Bo Wang and Zhao Zhang and Mingbo Zhao and Xiaojie Jin and Mingliang Xu and Meng Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/150},
  month     = {8},
  pages     = {1353-1361},
  title     = {OSIC: A new one-stage image captioner coined},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Image retrieval with self-supervised divergence minimization
and cross-attention classification. <em>IJCAI</em>, 1344–1352. (<a
href="https://doi.org/10.24963/ijcai.2024/149">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Common approaches to image retrieval include contrastive methods and specialized loss functions such as ranking losses and entropy regularizers. We present DMCAC (Divergence Minimization with Cross-Attention Classification), a novel image retrieval method that offers a new perspective on this training paradigm. We use self-supervision with a novel divergence loss framework alongside a simple data flow adjustment that minimizes a distribution over a database directly during training. We show that jointly learning a query representation over a database is a competitive and often improved alternative to traditional contrastive methods for image retrieval. We evaluate our method across several model configurations and four datasets, achieving state-of-the-art performance in multiple settings. We also conduct a thorough set of ablations that show the robustness of our method across full vs. approximate retrieval and different hyperparameter configurations. Keywords: Computer Vision: CV: Image and video retrieval Computer Vision: CV: Representation learning},
  archive   = {C_IJCAI},
  author    = {Vivek Trivedy and Longin Jan Latecki},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/149},
  month     = {8},
  pages     = {1344-1352},
  title     = {Image retrieval with self-supervised divergence minimization and cross-attention classification},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Expressiveness is effectiveness: Self-supervised
fashion-aware CLIP for video-to-shop retrieval. <em>IJCAI</em>,
1335–1343. (<a href="https://doi.org/10.24963/ijcai.2024/148">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The rise of online shopping and social media has spurred the Video-to-Shop Retrieval (VSR) task, which involves identifying fashion items (e.g., clothing) in videos and matching them with identical products provided by stores. In real-world scenarios, human movement in dynamic video scenes can cause substantial morphological alterations of fashion items with aspects of occlusion, shifting viewpoints (parallax), and partial visibility (truncation). This results in those high-quality frames being overwhelmed by a vast of redundant ones, which makes the retrieval less effectiveness. To this end, this paper introduces a framework, named Self-supervised Fashion-aware CLIP (SF-CLIP), for effective VSR. The SF-CLIP enables the discovery of salient frames with high fashion expressiveness via generating pseudo-labels from three key aspects of fashion expressiveness to assess occlusion, parallax, and truncation. With such pseudo-labels, the ability of CLIP is expanded to facilitate the discovery of salient frames. Furthermore, to encompass the comprehensive representations among salient frames, a dual-branch graph-based fusion module is proposed to extract and integrate inter-frame features. Extensive experiments demonstrate the superiority of SF-CLIP over the state-of-the-arts. Keywords: Computer Vision: CV: Image and video retrieval Computer Vision: CV: Interpretability and transparency},
  archive   = {C_IJCAI},
  author    = {Likai Tian and Zhengwei Yang and Zechao Hu and Hao Li and Yifang Yin and Zheng Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/148},
  month     = {8},
  pages     = {1335-1343},
  title     = {Expressiveness is effectiveness: Self-supervised fashion-aware CLIP for video-to-shop retrieval},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-granularity graph-convolution-based method for weakly
supervised person search. <em>IJCAI</em>, 1326–1334. (<a
href="https://doi.org/10.24963/ijcai.2024/147">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {One-step Weakly Supervised Person Search (WSPS) jointly performs pedestrian detection and person Re-IDentification (ReID) only with bounding box annotations, which makes the traditional person ReID problem more suitable and efficient for real-world applications. However, this task is very challenging due to the following reasons: 1) large feature gap between person ReID and general object detection tasks when learning shared representations; 2) difficult pseudo identity estimation for each person image with unrefined raw detection and dramatic scale changes. To address above issues, we propose a multi-granularity graph convolution framework to jointly optimize the aligned task features, as well as to assist the pseudo label estimation. Specifically, the multi-granularity feature alignment module (MFA) in the designed two-branch framework, employs cluster-level bi-directional interaction of various granularity information to narrow down the large feature gap. Further, upon the MFA module, we introduce the multi-granularity graph-convolution-based pseudo-label estimation module, to enhance feature representations for distinguishing diverse identities. Extensive experimental results demonstrate the effectiveness of the proposed method, and show superior performances to state-of-the art methods by a large margin on CUHK-SYSU and PRW datasets. Keywords: Computer Vision: CV: Representation learning Computer Vision: CV: Image and video retrieval Computer Vision: CV: Recognition (object detection, categorization)},
  archive   = {C_IJCAI},
  author    = {Haichun Tai and De Cheng and Jie Li and Nannan Wang and Xinbo Gao},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/147},
  month     = {8},
  pages     = {1326-1334},
  title     = {Multi-granularity graph-convolution-based method for weakly supervised person search},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic brightness adaptation for robust multi-modal image
fusion. <em>IJCAI</em>, 1317–1325. (<a
href="https://doi.org/10.24963/ijcai.2024/146">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Infrared and visible image fusion aim to integrate modality strengths for visually enhanced, informative images. Visible imaging in real-world scenarios is susceptible to dynamic environmental brightness fluctuations, leading to texture degradation. Existing fusion methods lack robustness against such brightness perturbations, significantly compromising the visual fidelity of the fused imagery. To address this challenge, we propose the Brightness Adaptive multimodal dynamic fusion framework (BA-Fusion), which achieves robust image fusion despite dynamic brightness fluctuations. Specifically, we introduce a Brightness Adaptive Gate (BAG) module, which is designed to dynamically select features from brightness-related channels for normalization, while preserving brightness-independent structural information within the source images. Furthermore, we propose a brightness consistency loss function to optimize the BAG module. The entire framework is tuned via alternating training strategies. Extensive experiments validate that our method surpasses state-of-the-art methods in preserving multi-modal image information and visual fidelity, while exhibiting remarkable robustness across varying brightness levels. Our code is available: https://github.com/SunYM2020/BA-Fusion. Keywords: Computer Vision: CV: Applications Computer Vision: CV: Multimodal learning},
  archive   = {C_IJCAI},
  author    = {Yiming Sun and Bing Cao and Pengfei Zhu and Qinghua Hu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/146},
  month     = {8},
  pages     = {1317-1325},
  title     = {Dynamic brightness adaptation for robust multi-modal image fusion},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Who looks like me: Semantic routed image harmonization.
<em>IJCAI</em>, 1308–1316. (<a
href="https://doi.org/10.24963/ijcai.2024/145">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Image harmonization, aiming to seamlessly blend extraneous foreground objects with background images, is a promising and challenging task.Ensuring a synthetic image appears realistic requires maintaining consistency in visual characteristics, such as texture and style, across global and semantic regions.In this paper, We approach image harmonization as a semantic routed style transfer problem, and propose an imageharmonization model by routing semantic similarity explicitly to enhance the consistency of appearance characteristics.To refine calculate the similarity between the composed foreground and background instance, we propose an InstanceSimilarity Evaluation Module(ISEM).To harness analogous semantic information effectively, we further introduceStyle Transfer Block(STB) to establish fine-grained foreground-background semantic correlation.Our method has achieved excellent experimental results on existing datasets and our model outperforms the state-of-the-art by a margin of 0.45 dB on iHarmony4 dataset. Keywords: Computer Vision: CV: Image and video synthesis and generation Computer Vision: CV: Computational photography},
  archive   = {C_IJCAI},
  author    = {Jinsheng Sun and Chao Yao and Xiaokun Wang and Yu Guo and Yalan Zhang and Xiaojuan Ban},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/145},
  month     = {8},
  pages     = {1308-1316},
  title     = {Who looks like me: Semantic routed image harmonization},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FineFMPL: Fine-grained feature mining prompt learning for
few-shot class incremental learning. <em>IJCAI</em>, 1299–1307. (<a
href="https://doi.org/10.24963/ijcai.2024/144">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Few-Shot Class Incremental Learning (FSCIL) aims to continually learn new classes with few training samples without forgetting already learned old classes. Existing FSCIL methods generally fix the backbone network in incremental sessions to achieve a balance between suppressing forgetting old classes and learning new classes. However, the fixed backbone network causes insufficient learning of new classes from a few samples. Benefiting from the powerful visual and textual understanding ability of Vision-Language (VL) pre-training models, we propose a Fine-grained Feature Mining Prompt Learning (FineFMPL) approach to adapt the VL model to FSCIL, which comprehensively learns and memorizes fine-grained discriminative information of emerging classes. Concretely, the visual probe prompt is firstly proposed to guide the image encoder of VL model to extract global-level coarse-grained features and object-level fine-grained features, and visual prototypes are preserved based on image patch significance, which contains the discriminative characteristics exclusive to the class. Secondly, the textual context prompt is constructed by cross-modal mapping of visual prototypes, feeding into the text encoder of VL model to memorize the class information as textual prototypes. Finally, integrating visual and textual prototypes based on fine-grained feature mining into the model improves the recognition performance of all classes in FSCIL. Extensive experiments on three benchmark datasets demonstrate that our FineFMPL achieves new state-of-the-art. The code is available at https://github.com/PKU-ICST-MIPL/FineFMPL_IJCAI2024. Keywords: Computer Vision: CV: Recognition (object detection, categorization)},
  archive   = {C_IJCAI},
  author    = {Hongbo Sun and Jiahuan Zhou and Xiangteng He and Jinglin Xu and Yuxin Peng},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/144},
  month     = {8},
  pages     = {1299-1307},
  title     = {FineFMPL: Fine-grained feature mining prompt learning for few-shot class incremental learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CLR-face: Conditional latent refinement for blind face
restoration using score-based diffusion models. <em>IJCAI</em>,
1290–1298. (<a href="https://doi.org/10.24963/ijcai.2024/143">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent generative methods have shown promising blind face restoration performance. They usually project the degraded images to the latent space and then decode high-quality faces either by single-stage latent optimization or directly from the encoding. Generating fine-grained facial details faithful to inputs remains challenging. Most existing methods produce either overly smooth outputs or alter the identity. This could be attributed to the typical trade-off between quality and resolution in the latent space. If the latent is highly compressed, the decoded output is more robust to degradations but shows worse fidelity. On the other hand, a more flexible latent space can capture intricate details better, but is extremely difficult to optimize for highly degraded faces. We introduce a diffusion-based-prior inside a VQGAN architecture that focuses on learning the distribution over uncorrupted latent embeddings. We iteratively recover the clean embedding conditioning on the degraded counterpart. Furthermore, to ensure the reverse diffusion trajectory does not deviate from the underlying identity, we train a separate Identity Recovery Network and use its output to constrain the reverse diffusion. Specifically, using a learnable latent mask, we add gradients from a face-recognition network to a subset of latent features that correlates with the finer identity-related details in the pixel space, leaving the other features untouched. Disentanglement between perception and fidelity in the latent space allows us to achieve the best of both worlds. We perform extensive evaluations on multiple real and synthetic datasets to validate our approach. Keywords: Computer Vision: CV: Biometrics, face, gesture and pose recognition Computer Vision: CV: Image and video synthesis and generation Machine Learning: ML: Generative models},
  archive   = {C_IJCAI},
  author    = {Maitreya Suin and Rama Chellappa},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/143},
  month     = {8},
  pages     = {1290-1298},
  title     = {CLR-face: Conditional latent refinement for blind face restoration using score-based diffusion models},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A consistency and integration model with adaptive thresholds
for weakly supervised object localization. <em>IJCAI</em>, 1281–1289.
(<a href="https://doi.org/10.24963/ijcai.2024/142">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Weakly Supervised Object Localization (WSOL) is a challenging task, which aims to learn object localization with less costly image-level labels. Existing convolution neural network (CNN) based methods tend to focus on discriminative regions of objects, while transformer-based methods overemphasize deep global features powerful for classification and lack the capability to perceive object details, leading to prediction results far from the object boundary. In this paper, we propose a novel Consistency and Integration Model with Adaptive Thresholds (CIAT) that exploits the spatial-semantic consistency between shallow and deep features to activate more object regions and detects the object regions adaptively in different images. First, we introduce a simple plug-and-play consistency and integration module of shallow-deep features (CISD), which utilizes shallow features efficiently to enhance the entire object perception. Then, we design an online adaptive threshold (OAT) based on Bayesian decision theory, which computes a reasonable segmentation threshold adaptive for the localization map of each image, making the predicted bounding box closer to the ground truth. Extensive experiments on two widely used CUB-200-2011 and ILSVRC datasets verify the effectiveness of our methods. Keywords: Computer Vision: CV: Recognition (object detection, categorization) Computer Vision: CV: Interpretability and transparency Computer Vision: CV: Transfer, low-shot, semi- and un- supervised learning Computer Vision: CV: Segmentation},
  archive   = {C_IJCAI},
  author    = {Hao Su and Meng Yang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/142},
  month     = {8},
  pages     = {1281-1289},
  title     = {A consistency and integration model with adaptive thresholds for weakly supervised object localization},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RoboFusion: Towards robust multi-modal 3D object detection
via SAM. <em>IJCAI</em>, 1272–1280. (<a
href="https://doi.org/10.24963/ijcai.2024/141">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-modal 3D object detectors are dedicated to exploring secure and reliable perception systems for autonomous driving (AD). Although achieving state-of-the-art (SOTA) performance on clean benchmark datasets, they tend to overlook the complexity and harsh conditions of real-world environments. With the emergence of visual foundation models (VFMs), opportunities and challenges are presented for improving the robustness and generalization of multi-modal 3D object detection in AD. Therefore, we propose RoboFusion, a robust framework that leverages VFMs like SAM to tackle out-of-distribution (OOD) noise scenarios. We first adapt the original SAM for AD scenarios named SAM-AD. To align SAM or SAM-AD with multi-modal methods, we then introduce AD-FPN for upsampling the image features extracted by SAM. We employ wavelet decomposition to denoise the depth-guided images for further noise reduction and weather interference. At last, we employ self-attention mechanisms to adaptively reweight the fused features, enhancing informative features while suppressing excess noise. In summary, RoboFusion significantly reduces noise by leveraging the generalization and robustness of VFMs, thereby enhancing the resilience of multi-modal 3D object detection. Consequently, RoboFusion achieves SOTA performance in noisy scenarios, as demonstrated by the KITTI-C and nuScenes-C benchmarks. Code is available at https://github.com/adept-thu/RoboFusion. Keywords: Computer Vision: CV: 3D computer vision Computer Vision: CV: Recognition (object detection, categorization) Robotics: ROB: Perception},
  archive   = {C_IJCAI},
  author    = {Ziying Song and Guoxing Zhang and Lin Liu and Lei Yang and Shaoqing Xu and Caiyan Jia and Feiyang Jia and Li Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/141},
  month     = {8},
  pages     = {1272-1280},
  title     = {RoboFusion: Towards robust multi-modal 3D object detection via SAM},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SPGNet: A shape-prior guided network for medical image
segmentation. <em>IJCAI</em>, 1263–1271. (<a
href="https://doi.org/10.24963/ijcai.2024/140">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Given the intricacy and variability of anatomical structures in medical images, some methods employ shape priors to constrain segmentation. However, limited by the representational capability of these priors, existing approaches often struggle to capture diverse target structure morphologies. To address this, we propose SPGNet to guide segmentation by fully exploiting category-specific shape knowledge. The key idea is to enable the network to perceive data shape distributions by learning from statistical shape models. We uncover shape relationships via clustering and obtain statistical prior knowledge using principal component analysis. Our dual-path network comprises a segmentation path and a shape-prior path that collaboratively discern and harness shape prior distribution to improve segmentation robustness. The shape-prior path further serves to refine shapes iteratively by cropping features from the segmentation path, guiding the segmentation path and directing attention specifically to the edges of shapes which could be most significantly susceptible to segmentation error. We demonstrate superior performance on chest X-ray and breast ultrasound benchmarks. Keywords: Computer Vision: CV: Biomedical image analysis Computer Vision: CV: Segmentation},
  archive   = {C_IJCAI},
  author    = {Zhengxuan Song and Xun Liu and Wenhao Zhang and Yongyi Gong and Tianyong Hao and Kun Zeng},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/140},
  month     = {8},
  pages     = {1263-1271},
  title     = {SPGNet: A shape-prior guided network for medical image segmentation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning a spiking neural network for efficient image
deraining. <em>IJCAI</em>, 1254–1262. (<a
href="https://doi.org/10.24963/ijcai.2024/139">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, spiking neural networks (SNNs) have demonstrated substantial potential in computer vision tasks. In this paper, we present an Efficient Spiking Deraining Network, called ESDNet. Our work is motivated by the observation that rain pixel values will lead to a more pronounced intensity of spike signals in SNNs. However, directly applying deep SNNs to image deraining task still remains a significant challenge. This is attributed to the information loss and training difficulties that arise from discrete binary activation and complex spatiotemporal dynamics. To this end, we develop a spiking residual block to convert the input into spike signals, then adaptively optimize the membrane potential by introducing attention weights to adjust spike responses in a data-driven manner, alleviating information loss caused by discrete binary activation. By this way, our ESDNet can effectively detect and analyze the characteristics of rain streaks by learning their fluctuations. This also enables better guidance for the deraining process and facilitates high-quality image reconstruction. Instead of relying on the ANN-SNN conversion strategy, we introduce a gradient proxy strategy to directly train the model for overcoming the challenge of training. Experimental results show that our approach gains comparable performance against ANN-based methods while reducing energy consumption by 54%. The code source is available at https://github.com/MingTian99/ESDNet. Keywords: Computer Vision: CV: Image and video synthesis and generation Computer Vision: CV: Applications Computer Vision: CV: Computational photography},
  archive   = {C_IJCAI},
  author    = {Tianyu Song and Guiyue Jin and Pengpeng Li and Kui Jiang and Xiang Chen and Jiyu Jin},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/139},
  month     = {8},
  pages     = {1254-1262},
  title     = {Learning a spiking neural network for efficient image deraining},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Motion-aware heatmap regression for human pose estimation in
videos. <em>IJCAI</em>, 1245–1253. (<a
href="https://doi.org/10.24963/ijcai.2024/138">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present an approach to solving 2D human pose estimation in videos. The problem of human pose estimation in videos differs from estimating human poses in static images since videos contain a lot of motion related information. Thus, we investigate how to utilize by the information of the human body movements across in a sequence of video frames for estimating human poses in videos. To do this, we introduce a novel heatmap regression method what we call motion-aware heatmap regression. Our approach computes motion vectors in joint keypoints from adjacent frames. We then design a new style of heatmap that we call Motion-Aware Heatmaps to reflect the motion uncertainty of each joint point. Unlike traditional heatmaps, our motion-aware heatmaps not only consider the current joint locations but also account how joints move over time. Furthermore, we introduce a simple yet effective framework designed to incorporate motion information into heatmap regression. We evaluate our motion-aware heatmap regression on PoseTrack(2018, 21) and Sub-JHMDB datasets. Our results validate that the proposed motion-aware heatmaps significantly improve the precision of human pose estimation in videos, particularly in challenging scenarios such as videos like sports game footage with substantial human motions. (Code and related materials are available at https://github.com/Songinpyo/MTPose.) Keywords: Computer Vision: CV: Biometrics, face, gesture and pose recognition Computer Vision: CV: Action and behavior recognition Computer Vision: CV: Video analysis and understanding},
  archive   = {C_IJCAI},
  author    = {Inpyo Song and Jongmin Lee and Moonwook Ryu and Jangwon Lee},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/138},
  month     = {8},
  pages     = {1245-1253},
  title     = {Motion-aware heatmap regression for human pose estimation in videos},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Conflict-alleviated gradient descent for adaptive object
detection. <em>IJCAI</em>, 1236–1244. (<a
href="https://doi.org/10.24963/ijcai.2024/137">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Unsupervised domain adaptive object detection (DAOD) aims to adapt detectors from a labeled source domain to an unlabelled target domain. Existing DAOD works learn feature representations with both class discriminative and domain invariant by jointly minimizing the loss across domain alignment and detection tasks. However, joint resolution of different tasks may lead to conflicts, with one contributing factor being gradient conflicts during optimization. If left untouched, such disagreement may degrade adaptation performance. In this work, we propose an efficient optimization strategy named Conflict-Alleviated Gradient descent (CAGrad) which aims to alleviate the conflict between two tasks (i.e., alignment and classification). Particularly, we alter the gradients by projecting each onto the normal plane of the other. The projection operation changes conflicting gradients from obtuse angles to acute angles, thus alleviating the conflict and achieving gradient harmonization. We further validate our theoretical analysis and methods on several domain adaptive object detection tasks, including cross-camera, weather, scene, and synthetic to real-world adaptation. Extensive experiments on multiple DAOD benchmarks demonstrate the effectiveness and superiority of our CAGrad. Keywords: Computer Vision: CV: Recognition (object detection, categorization) Machine Learning: ML: Optimization Machine Learning: ML: Unsupervised learning},
  archive   = {C_IJCAI},
  author    = {Wenxu Shi and Bochuan Zheng},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/137},
  month     = {8},
  pages     = {1236-1244},
  title     = {Conflict-alleviated gradient descent for adaptive object detection},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Contrastive transformer cross-modal hashing for video-text
retrieval. <em>IJCAI</em>, 1227–1235. (<a
href="https://doi.org/10.24963/ijcai.2024/136">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As video-based social networks continue to grow exponentially, there is a rising interest in video retrieval using natural language. Cross-modal hashing, which learns compact hash code for encoding multi-modal data, has proven to be widely effective in large-scale cross-modal retrieval, e.g., image-text retrieval, primarily due to its computation and storage efficiency. However, when applied to video-text retrieval, existing cross-modal hashing methods generally extract features at the frame- or word-level for videos and texts individually, thereby ignoring their long-term dependencies. To address this issue, we propose Contrastive Transformer Cross-Modal Hashing (CTCH), a novel approach designed for video-text retrieval task. CTCH employs bidirectional transformer encoder to encode video and text and leverages their long-term dependencies. CTCH further introduces supervised multi-modality contrastive loss that effectively exploits inter-modality and intra-modality similarities among videos and texts. The experimental results on three video benchmark datasets demonstrate that CTCH outperforms the state-of-the-arts in video-text retrieval tasks. Keywords: Computer Vision: CV: Image and video retrieval Machine Learning: ML: Multi-modal learning Machine Learning: ML: Multi-view learning},
  archive   = {C_IJCAI},
  author    = {Xiaobo Shen and Qianxin Huang and Long Lan and Yuhui Zheng},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/136},
  month     = {8},
  pages     = {1227-1235},
  title     = {Contrastive transformer cross-modal hashing for video-text retrieval},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Contrastive transformer masked image hashing for degraded
image retrieval. <em>IJCAI</em>, 1218–1226. (<a
href="https://doi.org/10.24963/ijcai.2024/135">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Hashing utilizes hash code as a compact image representation, offering excellent performance in large-scale image retrieval due to its computational and storage advantages. However, the prevalence of degraded images on social media platforms, resulting from imperfections in the image capture process, poses new challenges for conventional image retrieval methods. To address this issue, we propose Contrastive Transformer Masked Image Hashing (CTMIH), a novel deep unsupervised hashing method specifically designed for degraded image retrieval, which is challenging yet relatively less studied. CTMIH addresses the problem by training on transformed and masked images, aiming to learn transform-invariant hash code in an unsupervised manner to mitigate performance degradation caused by image deterioration. CTMIH utilizes Vision Transformer (ViT) architecture applied to image patches to capture distant semantic relevance. CTMIH introduces cross-view debiased contrastive loss to align hash tokens from augmented views of the same image and presents semantic mask reconstruction loss at the patch level to recover masked patch tokens. Extensive empirical studies conducted on three benchmark datasets demonstrate the superiority of the proposed CTMIH over the state-of-the-art in both degraded and normal image retrieval. Keywords: Computer Vision: CV: Image and video retrieval Machine Learning: ML: Unsupervised learning},
  archive   = {C_IJCAI},
  author    = {Xiaobo Shen and Haoyu Cai and Xiuwen Gong and Yuhui Zheng},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/135},
  month     = {8},
  pages     = {1218-1226},
  title     = {Contrastive transformer masked image hashing for degraded image retrieval},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient screen content image compression via
superpixel-based content aggregation and dynamic feature fusion.
<em>IJCAI</em>, 1209–1217. (<a
href="https://doi.org/10.24963/ijcai.2024/134">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper addresses the challenge of efficiently compressing screen content images (SCIs) – computer generated images with unique attributes such as large uniform regions, sharp edges, and limited color palettes, which pose difficulties for conventional compression algorithms. We propose a Superpixel-based Content Aggregation Block (SCAB) to aggregate local pixels into one super-pixel and aggregate non-local information via super-pixel transformer. Such aggregation enables the dynamic assimilation of non-local information while maintaining manageable complexity. Furthermore, we enhance our channel-wise context entropy model with a Dynamic Feature Fusion (DFF) mechanism. This mechanism integrates decoded slices and side information dynamically based on their global correlation, allowing the network to dynamically learn the optimal weights for global information usage. Extensive experiments on three SCI datasets (SCID, CCT, and SIQAD) show our method’s superior RD performance and inference time, making it the first network comparable with the advanced VVC-SCC standard. Keywords: Computer Vision: CV: Image and video synthesis and generation Computer Vision: CV: Computational photography Computer Vision: CV: Other},
  archive   = {C_IJCAI},
  author    = {Sheng Shen and Huanjing Yue and Jingyu Yang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/134},
  month     = {8},
  pages     = {1209-1217},
  title     = {Efficient screen content image compression via superpixel-based content aggregation and dynamic feature fusion},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). EvaNet: Elevation-guided flood extent mapping on earth
imagery. <em>IJCAI</em>, 1200–1208. (<a
href="https://doi.org/10.24963/ijcai.2024/133">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Accurate and timely mapping of flood extent from high resolution satellite imagery plays a crucial role in disaster management such as damage assessment and relief activities. However, current state-of-the-art solutions are based on U-Net, which cannot segment the flood pixels accurately due to the ambiguous pixels (e.g., tree canopies, clouds) that prevent a direct judgement from only the spectral features. Thanks to the digital elevation model (DEM) data readily available from sources such as United States Geological Survey (USGS), this work explores the use of an elevation map to improve flood extent mapping. We propose, EvaNet, an elevation-guided segmentation model based on the encoder-decoder architecture with two novel techniques: (1) a loss function encoding the physical law of gravity that if a location is flooded (resp. dry), then its adjacent locations with a lower (resp. higher) elevation must also be flooded (resp. dry); (2) a new (de)convolution operation that integrates the elevation map by a location-sensitive gating mechanism to regulate how much spectral features flow through adjacent layers. Extensive experiments show that EvaNet significantly outperforms the U-Net baselines, and works as a perfect drop-in replacement for U-Net in existing solutions to flood extent mapping. EvaNet is open-sourced at https://github.com/MTSami/EvaNet. Keywords: Computer Vision: CV: 3D computer vision Computer Vision: CV: Applications Computer Vision: CV: Segmentation Data Mining: DM: Mining spatial and/or temporal data},
  archive   = {C_IJCAI},
  author    = {Mirza Tanzim Sami and Da Yan and Saugat Adhikari and Lyuheng Yuan and Jiao Han and Zhe Jiang and Jalal Khalil and Yang Zhou},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/133},
  month     = {8},
  pages     = {1200-1208},
  title     = {EvaNet: Elevation-guided flood extent mapping on earth imagery},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SEMv3: A fast and robust approach to table separation line
detection. <em>IJCAI</em>, 1191–1199. (<a
href="https://doi.org/10.24963/ijcai.2024/132">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Table structure recognition (TSR) aims to parse the inherent structure of a table from its input image. The &quot;split-and-merge&quot; paradigm is a pivotal approach to parse table structure, where the table separation line detection is crucial. However, challenges such as wireless and deformed tables make it demanding. In this paper, we adhere to the &quot;split-and-merge&quot; paradigm and propose SEMv3 (SEM: Split, Embed and Merge), a method that is both fast and robust for detecting table separation lines. During the split stage, we introduce a Keypoint Offset Regression (KOR) module, which effectively detects table separation lines by directly regressing the offset of each line relative to its keypoint proposals. Moreover, in the merge stage, we define a series of merge actions to efficiently describe the table structure based on table grids. Extensive ablation studies demonstrate that our proposed KOR module can detect table separation lines quickly and accurately. Furthermore, on public datasets (e.g. WTW, ICDAR-2019 cTDaR Historical and iFLYTAB), SEMv3 achieves state-of-the-art (SOTA) performance. The code is available at https://github.com/Chunchunwumu/SEMv3. Keywords: Computer Vision: CV: Recognition (object detection, categorization) Computer Vision: CV: Applications},
  archive   = {C_IJCAI},
  author    = {Chunxia Qin and Zhenrong Zhang and Pengfei Hu and Chenyu Liu and Jiefeng Ma and Jun Du},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/132},
  month     = {8},
  pages     = {1191-1199},
  title     = {SEMv3: A fast and robust approach to table separation line detection},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ESP-PCT: Enhanced VR semantic performance through efficient
compression of temporal and spatial redundancies in point cloud
transformers. <em>IJCAI</em>, 1182–1190. (<a
href="https://doi.org/10.24963/ijcai.2024/131">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Semantic recognition is pivotal in virtual reality (VR) applications, enabling immersive and interactive experiences. A promising approach is utilizing millimeter-wave (mmWave) signals to generate point clouds. However, the high computational and memory demands of current mmWave point cloud models hinder their efficiency and reliability. To address this limitation, our paper introduces ESP-PCT, a novel Enhanced Semantic Performance Point Cloud Transformer with a two-stage semantic recognition framework tailored for VR applications. ESP-PCT takes advantage of the accuracy of sensory point cloud data and optimizes the semantic recognition process, where the localization and focus stages are trained jointly in an end-to-end manner. We evaluate ESP-PCT on various VR semantic recognition conditions, demonstrating substantial enhancements in recognition efficiency. Notably, ESP-PCT achieves a remarkable accuracy of 93.2% while reducing the computational requirements (FLOPs) by 76.9% and memory usage by 78.2% compared to the existing Point Transformer model simultaneously. These underscore ESP-PCT&#39;s potential in VR semantic recognition by achieving high accuracy and reducing redundancy. The code and data of this project are available at \url{https://github.com/lymei-SEU/ESP-PCT}. Keywords: Computer Vision: CV: Applications Computer Vision: CV: Motion and tracking Machine Learning: ML: Optimization Multidisciplinary Topics and Applications: MTA: Security and privacy},
  archive   = {C_IJCAI},
  author    = {Luoyu Mei and Shuai Wang and Yun Cheng and Ruofeng Liu and Zhimeng Yin and Wenchao Jiang and Wei Gong},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/131},
  month     = {8},
  pages     = {1182-1190},
  title     = {ESP-PCT: Enhanced VR semantic performance through efficient compression of temporal and spatial redundancies in point cloud transformers},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FastScene: Text-driven fast indoor 3D scene generation via
panoramic gaussian splatting. <em>IJCAI</em>, 1173–1181. (<a
href="https://doi.org/10.24963/ijcai.2024/130">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Text-driven 3D indoor scene generation holds broad applications, ranging from gaming and smart homes to AR/VR applications. Fast and high-fidelity scene generation is paramount for ensuring user-friendly experiences. However, existing methods are characterized by lengthy generation processes or necessitate the intricate manual specification of motion parameters, which introduces inconvenience for users. Furthermore, these methods often rely on narrow-field viewpoint iterative generations, compromising global consistency and overall scene quality. To address these issues, we propose FastScene, a framework for fast and higher-quality 3D scene generation, while maintaining the scene consistency. Specifically, given a text prompt, we generate a panorama and estimate its depth, since the panorama encompasses information about the entire scene and exhibits explicit geometric constraints. To obtain high-quality novel views, we introduce the Coarse View Synthesis (CVS) and Progressive Novel View Inpainting (PNVI) strategies, ensuring both scene consistency and view quality. Subsequently, we utilize Multi-View Projection (MVP) to form perspective views, and apply 3D Gaussian Splatting (3DGS) for scene reconstruction. Comprehensive experiments demonstrate FastScene surpasses other methods in both generation speed and quality with better scene consistency. Notably, guided only by a text prompt, FastScene can generate a 3D scene within a mere 15 minutes, which is at least one hour faster than state-of-the-art methods, making it a paradigm for user-friendly scene generation. Keywords: Computer Vision: CV: 3D computer vision Computer Vision: CV: Image and video synthesis and generation Computer Vision: CV: Multimodal learning Computer Vision: CV: Scene analysis and understanding},
  archive   = {C_IJCAI},
  author    = {Yikun Ma and Dandan Zhan and Zhi Jin},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/130},
  month     = {8},
  pages     = {1173-1181},
  title     = {FastScene: Text-driven fast indoor 3D scene generation via panoramic gaussian splatting},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Self-promoted clustering-based contrastive learning for
brain networks pretraining. <em>IJCAI</em>, 1164–1172. (<a
href="https://doi.org/10.24963/ijcai.2024/129">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Rapid advancements in neuroimaging techniques, such as magnetic resonance imaging (MRI), have facilitated the acquisition of the structural and functional characteristics of the brain. Brain network analysis is one of the essential tools for exploring brain mechanisms from MRI, providing valuable insights into the brain&#39;s organization, and stimulating the understanding of brain cognition and pathology of neurodegenerative diseases. Graph Neural Networks (GNNs) are commonly used for brain network analysis, but they are limited by the scarcity of medical data. Although Graph Contrastive Learning methods have been developed to address this, they often involve graph augmentations that distort the anatomical brain structures. To address these challenges, an augmentation-free contrastive learning method, named Self-Promoted Clustering-based Contrastive Learning(SPCCL), is proposed in this paper. Specifically, by introducing a clustering-based contrastive Learning loss and a self-promoted contrastive pairs creation scheme, the proposed SPCCL can be pre-trained from additional healthy subjects&#39; data that are relatively easier to acquire than disorder ones. The proposed SPCCL leverages these additional data with respect to the integrity of the original brain structure, making it a promising approach for effective brain network analysis. Comprehensive experiments are conducted on an open-access schizophrenic dataset, demonstrating the effectiveness of the proposed method. Keywords: Computer Vision: CV: Biomedical image analysis Humans and AI: HAI: Brain sciences Machine Learning: ML: Deep learning architectures Machine Learning: ML: Multi-modal learning},
  archive   = {C_IJCAI},
  author    = {Junbo Ma and Caixuan Luo and Jia Hou and Kai Zhao},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/129},
  month     = {8},
  pages     = {1164-1172},
  title     = {Self-promoted clustering-based contrastive learning for brain networks pretraining},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). C3L: Content correlated vision-language instruction tuning
data generation via contrastive learning. <em>IJCAI</em>, 1155–1163. (<a
href="https://doi.org/10.24963/ijcai.2024/128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Vision-Language Instruction Tuning (VLIT) is a critical training phase for Large Vision-Language Models (LVLMs). With the improving capabilities of open-source LVLMs, researchers have increasingly turned to generate VLIT data by using open-source LVLMs and achieved significant progress. However, such data generation approaches are bottlenecked by the following challenges: 1) Since multi-modal models tend to be influenced by prior language knowledge, directly using LVLMs to generate VLIT data would inevitably lead to low content relevance between generated data and images. 2) To improve the ability of the models to generate VLIT data, previous methods have incorporated an additional training phase to boost the generative capacity. This process hurts the generalization of the models to unseen inputs (i.e., “exposure bias” problem). In this paper, we propose a new Content Correlated VLIT data generation via Contrastive Learning (C3L). Specifically, we design a new content relevance module which enhances the content relevance between VLIT data and images by computing Image Instruction Correspondence Scores S(I2C). Moreover, a contrastive learning module is introduced to further boost the VLIT data generation capability of the LVLMs. A large number of automatic measures on four benchmarks show the effectiveness of our method. Keywords: Computer Vision: CV: Vision, language and reasoning Computer Vision: CV: Multimodal learning Natural Language Processing: NLP: Language models},
  archive   = {C_IJCAI},
  author    = {Ji Ma and Wei Suo and Peng Wang and Yanning Zhang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/128},
  month     = {8},
  pages     = {1155-1163},
  title     = {C3L: Content correlated vision-language instruction tuning data generation via contrastive learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cross-domain feature augmentation for domain generalization.
<em>IJCAI</em>, 1146–1154. (<a
href="https://doi.org/10.24963/ijcai.2024/127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Domain generalization aims to develop models that are robust to distribution shifts. Existing methods focus on learning invariance across domains to enhance model robustness, and data augmentation has been widely used to learn invariant predictors, with most methods performing augmentation in the input space. However, augmentation in the input space has limited diversity whereas in the feature space is more versatile and has shown promising results. Nonetheless, feature semantics is seldom considered and existing feature augmentation methods suffer from a limited variety of augmented features. We decompose features into class-generic, class-specific, domain-generic, and domain-specific components. We propose a cross-domain feature augmentation method named XDomainMix that enables us to increase sample diversity while emphasizing the learning of invariant representations to achieve domain generalization. Experiments on widely used benchmark datasets demonstrate that our proposed method is able to achieve state-of-the-art performance. Quantitative analysis indicates that our feature augmentation approach facilitates the learning of effective models that are invariant across different domains. Keywords: Computer Vision: CV: Transfer, low-shot, semi- and un- supervised learning Computer Vision: CV: Machine learning for vision},
  archive   = {C_IJCAI},
  author    = {Yingnan Liu and Yingtian Zou and Rui Qiao and Fusheng Liu and Mong Li Lee and Wynne Hsu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/127},
  month     = {8},
  pages     = {1146-1154},
  title     = {Cross-domain feature augmentation for domain generalization},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Advancing generalized transfer attack with initialization
derived bilevel optimization and dynamic sequence truncation.
<em>IJCAI</em>, 1137–1145. (<a
href="https://doi.org/10.24963/ijcai.2024/126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Transfer attacks generate significant interest for real-world black-box applications by crafting transferable adversarial examples through surrogate models. Whereas, existing works essentially directly optimize the single-level objective w.r.t. the surrogate model, which always leads to poor interpretability of attack mechanism and limited generalization performance over unknown victim models. In this work, we propose the BilEvel Transfer AttacK (BETAK) framework by establishing an initialization derived bilevel optimization paradigm, which explicitly reformulates the nested constraint relationship between the Upper-Level (UL) pseudo-victim attacker and the Lower-Level (LL) surrogate attacker. Algorithmically, we introduce the Hyper Gradient Response (HGR) estimation as an effective feedback for the transferability over pseudo-victim attackers, and propose the Dynamic Sequence Truncation (DST) technique to dynamically adjust the back-propagation path for HGR and reduce computational overhead simultaneously. Meanwhile, we conduct detailed algorithmic analysis and provide convergence guarantee to support non-convexity of the LL surrogate attacker. Extensive evaluations demonstrate substantial improvement of BETAK (e.g., 53.41% increase of attack success rates against IncRes-v2_ens victim) against different victims and defense methods in targeted and untargeted attack scenarios. Keywords: Computer Vision: CV: Adversarial learning, adversarial attack and defense methods Computer Vision: CV: Machine learning for vision},
  archive   = {C_IJCAI},
  author    = {Yaohua Liu and Jiaxin Gao and Xuan Liu and Xianghao Jiao and Xin Fan and Risheng Liu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/126},
  month     = {8},
  pages     = {1137-1145},
  title     = {Advancing generalized transfer attack with initialization derived bilevel optimization and dynamic sequence truncation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DifTraj: Diffusion inspired by intrinsic intention and
extrinsic interaction for multi-modal trajectory prediction.
<em>IJCAI</em>, 1128–1136. (<a
href="https://doi.org/10.24963/ijcai.2024/125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent years have witnessed the success of generative adversarial networks and diffusion models in multi-model trajectory prediction. However, prevailing algorithms only explicitly consider human interaction, but ignore the modeling of human intention, yielding that the generated results deviate largely from real trajectories in some complex scenes. In this paper, we analyze the conditions of multi-modal trajectory prediction from two objective perspectives and propose a novel end-to-end framework based on the diffusion model to predict more precise and socially-acceptable trajectories for humans. Firstly, a spatial-temporal aggregation module is built to extract the extrinsic interaction features for capturing socially-acceptable behaviors. Secondly, we explicitly construct the intrinsic intention module to obtain intention features for precise prediction. Finally, we estimate a noise trajectory distribution with these two features as the initiation of diffusion model and leverage denoising process to obtain the final trajectories. Furthermore, to reduce the noise of the initiative trajectory estimation, we present a novel sample consistency loss to constrain multiple predictions. Extensive experiments demonstrate that our method outperforms the state-of-the-art methods on ETH-UCY and SDD benchmarks, specifically achieving 19.0%/24.2% ADE/FDE improvement on ETH-UCY. Keywords: Computer Vision: CV: Motion and tracking Agent-based and Multi-agent Systems: MAS: Multi-agent learning Machine Learning: ML: Time series and data streams},
  archive   = {C_IJCAI},
  author    = {Yanghong Liu and Xingping Dong and Yutian Lin and Mang Ye},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/125},
  month     = {8},
  pages     = {1128-1136},
  title     = {DifTraj: Diffusion inspired by intrinsic intention and extrinsic interaction for multi-modal trajectory prediction},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). DCDet: Dynamic cross-based 3D object detector.
<em>IJCAI</em>, 1119–1127. (<a
href="https://doi.org/10.24963/ijcai.2024/124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, significant progress has been made in the research of 3D object detection. However, most prior studies have focused on the utilization of center-based or anchor-based label assignment schemes. Alternative label assignment strategies remain unexplored in 3D object detection. We find that the center-based label assignment often fails to generate sufficient positive samples for training, while the anchor-based label assignment tends to encounter an imbalanced issue when handling objects with different scales. To solve these issues, we introduce a dynamic cross label assignment (DCLA) scheme, which dynamically assigns positive samples for each object from a cross-shaped region, thus providing sufficient and balanced positive samples for training. Furthermore, to address the challenge of accurately regressing objects with varying scales, we put forth a rotation-weighted Intersection over Union (RWIoU) metric to replace the widely used L1 metric in regression loss. Extensive experiments demonstrate the generality and effectiveness of our DCLA and RWIoU-based regression loss. The Code is available at https://github.com/Say2L/DCDet.git. Keywords: Computer Vision: CV: 3D computer vision Computer Vision: CV: Recognition (object detection, categorization)},
  archive   = {C_IJCAI},
  author    = {Shuai Liu and Boyang Li and Zhiyu Fang and Kai Huang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/124},
  month     = {8},
  pages     = {1119-1127},
  title     = {DCDet: Dynamic cross-based 3D object detector},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Where elegance meets precision: Towards a compact,
automatic, and flexible framework for multi-modality image fusion and
applications. <em>IJCAI</em>, 1110–1118. (<a
href="https://doi.org/10.24963/ijcai.2024/123">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-modality image fusion aims to integrate images from multiple sensors, producing an image that is visually appealing and offers more comprehensive information than any single one. To ensure high visual quality and facilitate accurate subsequent perception tasks, previous methods have often cascaded networks using weighted loss functions. However, such simplistic strategies struggle to truly achieve the &quot;Best of Both Worlds&quot;, and the adjustment of numerous hand-crafted parameters becomes burdensome. To address these challenges, this paper introduces a Compact, Automatic and Flexible framework, dubbed CAF, designed for infrared and visible image fusion, along with subsequent tasks. Concretely, we recast the combined problem of fusion and perception into a single objective, allowing mutual optimization of information from both tasks. Then we also utilize the perception task to inform the design of fusion loss functions, facilitating the automatic identification of optimal fusion objectives tailored to the task. Furthermore, CAF can support seamless integration with existing approaches easily, offering flexibility in adapting to various tasks and network structures. Extensive experiments demonstrate the superiority of CAF, which not only produces visually admirable fused results but also realizes 1.7 higher detection mAP@.5 and 2.0 higher segmentation mIoU than the state-of-the-art methods. The code is available at https://github.com/RollingPlain/CAF_IVIF. Keywords: Computer Vision: CV: Applications Computer Vision: CV: Multimodal learning},
  archive   = {C_IJCAI},
  author    = {Jinyuan Liu and Guanyao Wu and Zhu Liu and Long Ma and Risheng Liu and Xin Fan},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/123},
  month     = {8},
  pages     = {1110-1118},
  title     = {Where elegance meets precision: Towards a compact, automatic, and flexible framework for multi-modality image fusion and applications},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Accelerating diffusion models for inverse problems through
shortcut sampling. <em>IJCAI</em>, 1101–1109. (<a
href="https://doi.org/10.24963/ijcai.2024/122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Diffusion models have recently demonstrated an impressive ability to address inverse problems in an unsupervised manner. While existing methods primarily focus on modifying the posterior sampling process, the potential of the forward process remains largely unexplored. In this work, we propose Shortcut Sampling for Diffusion(SSD), a novel approach for solving inverse problems in a zero-shot manner. Instead of initiating from random noise, the core concept of SSD is to find a specific transitional state that bridges the measurement image y and the restored image x. By utilizing the shortcut path of &quot;input - transitional state - output&quot;, SSD can achieve precise restoration with fewer steps. To derive the transitional state during the forward process, we introduce Distortion Adaptive Inversion. Moreover, we apply back projection as additional consistency constraints during the generation process. Experimentally, we demonstrate SSD&#39;s effectiveness on multiple representative IR tasks. Our method achieves competitive results with only 30 NFEs compared to state-of-the-art zero-shot methods(100 NFEs) and outperforms them with 100 NFEs in certain tasks. Code is available at https://github.com/GongyeLiu/SSD. Keywords: Computer Vision: CV: Image and video synthesis and generation Computer Vision: CV: Applications},
  archive   = {C_IJCAI},
  author    = {Gongye Liu and Haoze Sun and Jiayi Li and Fei Yin and Yujiu Yang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/122},
  month     = {8},
  pages     = {1101-1109},
  title     = {Accelerating diffusion models for inverse problems through shortcut sampling},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing boundary segmentation for topological accuracy
with skeleton-based methods. <em>IJCAI</em>, 1092–1100. (<a
href="https://doi.org/10.24963/ijcai.2024/121">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Topological consistency plays a crucial role in the task of boundary segmentation for reticular images, such as cell membrane segmentation in neuron electron microscopic images, grain boundary segmentation in material microscopic images and road segmentation in aerial images. In these fields, topological changes in segmentation results have a serious impact on the downstream tasks, which can even exceed the misalignment of the boundary itself. To enhance the topology accuracy in segmentation results, we propose the Skea-Topo Aware loss, which is a novel loss function that takes into account the shape of each object and topological significance of the pixels. It consists of two components. First, a skeleton-aware weighted loss improves the segmentation accuracy by better modeling the object geometry with skeletons. Second, a boundary rectified term effectively identifies and emphasizes topological critical pixels in the prediction errors using both foreground and background skeletons in the ground truth and predictions. Experiments prove that our method improves topological consistency by up to 7 points in VI compared to 13 state-of-art methods, based on objective and subjective assessments across three different boundary segmentation datasets. The code is available at https://github.com/clovermini/Skea_topo. Keywords: Computer Vision: CV: Segmentation Computer Vision: CV: Biomedical image analysis},
  archive   = {C_IJCAI},
  author    = {Chuni Liu and Boyuan Ma and Xiaojuan Ban and Yujie Xie and Hao Wang and Weihua Xue and Jingchao Ma and Ke Xu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/121},
  month     = {8},
  pages     = {1092-1100},
  title     = {Enhancing boundary segmentation for topological accuracy with skeleton-based methods},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MCM: Multi-condition motion synthesis framework.
<em>IJCAI</em>, 1083–1091. (<a
href="https://doi.org/10.24963/ijcai.2024/120">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Conditional human motion synthesis (HMS) aims to generate human motion sequences that conform to specific conditions. Text and audio represent the two predominant modalities employed as HMS control conditions. While existing research has primarily focused on single conditions, the multi-condition human motion synthesis remains underexplored. In this study, we propose a multi-condition HMS framework, termed MCM, based on a dual-branch structure composed of a main branch and a control branch. This framework effectively extends the applicability of the diffusion model, which is initially predicated solely on textual conditions, to auditory conditions. This extension encompasses both music-to-dance and co-speech HMS while preserving the intrinsic quality of motion and the capabilities for semantic association inherent in the original model. Furthermore, we propose the implementation of a Transformer-based diffusion model, designated as MWNet, as the main branch. This model adeptly apprehends the spatial intricacies and inter-joint correlations inherent in motion sequences, facilitated by the integration of multi-wise self-attention modules. Extensive experiments show that our method achieves competitive results in single-condition and multi-condition HMS tasks. Keywords: Computer Vision: CV: 3D computer vision Computer Vision: CV: Applications},
  archive   = {C_IJCAI},
  author    = {Zeyu Ling and Bo Han and Yongkang Wong and Han Lin and Mohan Kankanhalli and Weidong Geng},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/120},
  month     = {8},
  pages     = {1083-1091},
  title     = {MCM: Multi-condition motion synthesis framework},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient event stream super-resolution with recursive
multi-branch fusion. <em>IJCAI</em>, 1074–1082. (<a
href="https://doi.org/10.24963/ijcai.2024/119">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Current Event Stream Super-Resolution (ESR) methods overlook the redundant and complementary information present in positive and negative events within the event stream, employing a direct mixing approach for super-resolution, which may lead to detail loss and inefficiency. To address these issues, we propose an efficient Recursive Multi-Branch Information Fusion Network (RMFNet) that separates positive and negative events for complementary information extraction, followed by mutual supplementation and refinement. Particularly, we introduce Feature Fusion Modules (FFM) and Feature Exchange Modules (FEM). FFM is designed for the fusion of contextual information within neighboring event streams, leveraging the coupling relationship between positive and negative events to alleviate the misleading of noises in the respective branches. FEM efficiently promotes the fusion and exchange of information between positive and negative branches, enabling superior local information enhancement and global information complementation. Experimental results demonstrate that our approach achieves over 17% and 31% improvement on synthetic and real datasets, accompanied by a 2.3x acceleration. Furthermore, we evaluate our method on two downstream event-driven applications, i.e., object recognition and video reconstruction, achieving remarkable results that outperform existing methods. Our code and Supplementary Material are available at https://github.com/Lqm26/RMFNet. Keywords: Computer Vision: CV: Image and video synthesis and generation Computer Vision: CV: Other},
  archive   = {C_IJCAI},
  author    = {Quanmin Liang and Zhilin Huang and Xiawu Zheng and Feidiao Yang and Jun Peng and Kai Huang and Yonghong Tian},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/119},
  month     = {8},
  pages     = {1074-1082},
  title     = {Efficient event stream super-resolution with recursive multi-branch fusion},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GUIDE: A guideline-guided dataset for instructional video
comprehension. <em>IJCAI</em>, 1065–1073. (<a
href="https://doi.org/10.24963/ijcai.2024/118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {There are substantial instructional videos on the Internet, which provide us tutorials for completing various tasks. Existing instructional video datasets only focus on specific steps at the video level, lacking experiential guidelines at the task level, which can lead to beginners struggling to learn new tasks due to the lack of relevant experience. Moreover, the specific steps without guidelines are trivial and unsystematic, making it difficult to provide a clear tutorial. To address these problems, we present the Guide (Guideline-Guided) dataset, which contains 3.5K videos of 560 instructional tasks in 8 domains related to our daily life. Specifically, we annotate each instructional task with a guideline, representing a common pattern shared by all task-related videos. On this basis, we annotate systematic specific steps, including their associated guideline steps, specific step descriptions and timestamps. Our proposed benchmark consists of three sub-tasks to evaluate comprehension ability of models: (1) Step Captioning: models have to generate captions for specific steps from videos. (2) Guideline Summarization: models have to mine the common pattern in task-related videos and summarize a guideline from them. (3) Guideline-Guided Captioning: models have to generate captions for specific steps under the guide of guideline. We evaluate plenty of foundation models with Guide and perform in-depth analysis. Given the diversity and practicality of Guide, we believe that it can be used as a better benchmark for instructional video comprehension. Keywords: Computer Vision: CV: Video analysis and understanding Natural Language Processing: NLP: Resources and evaluation},
  archive   = {C_IJCAI},
  author    = {Jiafeng Liang and Shixin Jiang and Zekun Wang and Haojie Pan and Zerui Chen and Zheng Chu and Ming Liu and Ruiji Fu and Zhongyuan Wang and Bing Qin},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/118},
  month     = {8},
  pages     = {1065-1073},
  title     = {GUIDE: A guideline-guided dataset for instructional video comprehension},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Advancing medical image segmentation via self-supervised
instance-adaptive prototype learning. <em>IJCAI</em>, 1056–1064. (<a
href="https://doi.org/10.24963/ijcai.2024/117">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Medical Image Segmentation (MIS) plays a crucial role in medical therapy planning and robot navigation. Prototype learning methods in MIS focus on generating segmentation masks through pixel-to-prototype comparison. However, current approaches often overlook sample diversity by using a fixed prototype per semantic class and neglect intra-class variation within each input. In this paper, we propose to generate instance-adaptive prototypes for MIS, which integrates a common prototype proposal (CPP) capturing common visual patterns and an instance-specific prototype proposal (IPP) tailored to each input. To further account for the intra-class variation, we propose to guide the IPP generation by re-weighting the intermediate feature map according to their confidence scores. These confidence scores are hierarchically generated using a transformer decoder. Additionally we introduce a novel self-supervised filtering strategy to prioritize the foreground pixels during the training of the transformer decoder. Extensive experiments demonstrate favorable performance of our method. Keywords: Computer Vision: CV: Biomedical image analysis Computer Vision: CV: Representation learning Computer Vision: CV: Segmentation Machine Learning: ML: Self-supervised Learning},
  archive   = {C_IJCAI},
  author    = {Guoyan Liang and Qin Zhou and Jingyuan Chen and Zhe Wang and Chang Yao},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/117},
  month     = {8},
  pages     = {1056-1064},
  title     = {Advancing medical image segmentation via self-supervised instance-adaptive prototype learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). Cross-modal generation and alignment via attribute-guided
prompt for unsupervised text-based person retrieval. <em>IJCAI</em>,
1047–1055. (<a href="https://doi.org/10.24963/ijcai.2024/116">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Text-based Person Search aims to retrieve a specified person using a given text query. Current methods predominantly rely on paired labeled image-text data to train the cross-modality retrieval model, necessitating laborious and time-consuming labeling. In response to this challenge, we present the Cross-modal Generation and Alignment via Attribute-guided Prompt framework (GAAP) for fully unsupervised text-based person search, utilizing only unlabeled images. Our proposed GAAP framework consists of two key parts: Attribute-guided Prompt Caption Generation and Attribute-guided Cross-modal Alignment module. The Attribute-guided Prompt Caption Generation module generates pseudo text labels by feeding the attribute prompts into a large-scale pre-trained vision-language model. These synthetic texts are then meticulously selected through a sample selection, ensuring the reliability for subsequent fine-tuning. The Attribute-guided Cross-modal Alignment module encompasses three sub-modules for feature alignment across modalities. Firstly, Cross-Modal Center Alignment (CMCA) aligns the samples with different modality centroids. Subsequently, to address ambiguity arising from local attribute similarities, an Attribute-guided Image-Text Contrastive Learning module (AITC) is proposed to facilitate the alignment of relationships among different pairs by considering local attribute similarities. Lastly, the Attribute-guided Image-Text Matching (AITM) module is introduced to mitigate noise in pseudo captions by using the image-attribute matching score to soften the hard matching labels. Empirical results showcase the effectiveness of our method across various text-based person search datasets under the fully unsupervised setting. Keywords: Computer Vision: CV: Multimodal learning Computer Vision: CV: Vision, language and reasoning Machine Learning: ML: Multi-modal learning Machine Learning: ML: Unsupervised learning},
  archive   = {C_IJCAI},
  author    = {Zongyi Li and Jianbo Li and Yuxuan Shi and Hefei Ling and Jiazhong Chen and Runsheng Wang and Shijuan Huang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/116},
  month     = {8},
  pages     = {1047-1055},
  title     = {Cross-modal generation and alignment via attribute-guided prompt for unsupervised text-based person retrieval},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). WSRFNet: Wavelet-based scale-specific recurrent feedback
network for diabetic retinopathy lesion segmentation. <em>IJCAI</em>,
1038–1046. (<a href="https://doi.org/10.24963/ijcai.2024/115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Diabetic retinopathy lesion segmentation (DRLS) faces a challenge of significant variation in the size of different lesions. An effective method to address this challenge is to fuse multi-scale features. To boost the performance of this kind of method, most existing DRLS methods work on devising sophisticated multi-scale feature fusion modules. Differently, we focus on improving the quality of the multi-scale features to enhance the fused multi-scale feature representation. To this end, we design a Wavelet-based Scale-specific Recurrent Feedback Network (WSRFNet), which refines multi-scale features using recurrent feedback mechanism. Specifically, to avoid information loss when introducing feedback to multi-scale features, we propose a wavelet-based feedback pyramid module (WFPM), which is based on a reversible downsampling operation, i.e., Haar wavelet transform. Unlike scale-agnostic feedback used in previous feedback methods, we develop a scale-specific refinement module (SRM), which utilizes scale-specific feedback to pointedly refine features of different scales. Experimental results on IDRiD and DDR datasets show that our approach outperforms state-of-the-art models. The code is available at https://github.com/xuanli01/WSRFNet. Keywords: Computer Vision: CV: Biomedical image analysis Computer Vision: CV: Segmentation},
  archive   = {C_IJCAI},
  author    = {Xuan Li and Xiangqian Wu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/115},
  month     = {8},
  pages     = {1038-1046},
  title     = {WSRFNet: Wavelet-based scale-specific recurrent feedback network for diabetic retinopathy lesion segmentation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Revitalizing real image deraining via a generic paradigm
towards multiple rainy patterns. <em>IJCAI</em>, 1029–1037. (<a
href="https://doi.org/10.24963/ijcai.2024/114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Synthetic data-driven methods perform well on image rain removal task, but they still face many challenges in real rainfall scenarios due to the complexity and diversity of rainy patterns. In this paper, we propose a new generic paradigm for real image deraining from the perspective of synthesizing data covering more rainy patterns and constructing image rain removal networks with strong generalization performance. Firstly, instead of simply superimposing rain layers, we integrate various rainy patterns and design a phenomenal pipeline that incorporates multiple degradation types. Secondly, we construct a Patterns-aware Rain Removal Network (PRRN), which learns from both synthetic and real data simultaneously. In addition, to eliminate the inevitable distribution differences between synthetic and real data, we design a new Multi-representation Inter-domain Alignment Module (MIAM) in PRRN. By using multiple parallel submodules, MIAM achieves alignment of data domains in multiple feature subspaces. Based on several authoritative objective evaluation metrics, we successfully validate the effectiveness and robustness of the proposed method in real scenarios through extensive experiments carried out on five challenging real datasets. Keywords: Computer Vision: CV: Computational photography Computer Vision: CV: Machine learning for vision Computer Vision: CV: Transfer, low-shot, semi- and un- supervised learning},
  archive   = {C_IJCAI},
  author    = {Xin Li and Yuxin Feng and Fan Zhou and Yun Liang and Zhuo Su},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/114},
  month     = {8},
  pages     = {1029-1037},
  title     = {Revitalizing real image deraining via a generic paradigm towards multiple rainy patterns},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DenseKoopman: A plug-and-play framework for dense pedestrian
trajectory prediction. <em>IJCAI</em>, 1020–1028. (<a
href="https://doi.org/10.24963/ijcai.2024/113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Pedestrian trajectory prediction has emerged as a core component of human-robot interaction and autonomous driving. Fast and accurate prediction of surrounding pedestrians contributes to making decisions and improves safety and efficiency. However, pedestrians’ future trajectories will interact with their surrounding traffic participants. As the density of pedestrians increases, the complexity of such interactions also increases significantly, leading to an inevitable decrease in the accuracy of pedestrian trajectory prediction. To address this issue, we propose DenseKoopman, a plug-and-play framework for dense pedestrian trajectory prediction. Specifically, we introduce the Koopman operator theory to find an embedding space for a global linear approximation of a nonlinear pedestrian motion system. By encoding historical trajectories as linear state embeddings in the Koopman space, we transforms nonlinear trajectory data for pedestrians in dense scenes. This linearized representation greatly reduces the complexity of dense pedestrian trajectory prediction. Extensive experiments on pedestrian trajectory prediction benchmarks demonstrate the superiority of the proposed framework. We also conducted an analysis of the data transformation to explore how our DenseKoopman framework works with each validation method and uncovers motion patterns that may be hidden within the trajectory data. Code is available at https://github.com/lixianbang/DenseKoopman. Keywords: Computer Vision: CV: Motion and tracking Computer Vision: CV: Machine learning for vision Computer Vision: CV: Other},
  archive   = {C_IJCAI},
  author    = {Xianbang Li and Yilong Ren and Han Jiang and Haiyang Yu and Yanlei Cui and Liang Xu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/113},
  month     = {8},
  pages     = {1020-1028},
  title     = {DenseKoopman: A plug-and-play framework for dense pedestrian trajectory prediction},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). OTOcc: Optimal transport for occupancy prediction.
<em>IJCAI</em>, 1010–1019. (<a
href="https://doi.org/10.24963/ijcai.2024/112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The autonomous driving community is highly interested in 3D occupancy prediction due to its outstanding geometric perception and object recognition capabilities. However, previous methods are limited to existing semantic conversion mechanisms for solving sparse ground truths problem, causing excessive computational demands and sub-optimal voxels representation. To tackle the above limitations, we propose OTOcc, a novel 3D occupancy prediction framework that models semantic conversion from 2D pixels to 3D voxels as Optimal Transport (OT) problem, offering accurate semantic mapping to adapt to sparse scenarios without attention or depth estimation. Specifically, the unit transportation cost between each demander (voxel) and supplier (pixel) pair is defined as the weighted occupancy prediction loss. Then, we utilize the Sinkhorn-Knopp Iteration to find the best mapping matrices with minimal transportation costs. To reduce the computational cost, we propose a block reading technique with multi-perspective feature representation, which also brings fine-grained scene understanding. Extensive experiments show that OTOcc not only has the competitive prediction performance but also has about more than 4.58% reduction in computational overhead compared to state-of-the-art methods. Keywords: Computer Vision: CV: 3D computer vision Computer Vision: CV: Applications Computer Vision: CV: Machine learning for vision},
  archive   = {C_IJCAI},
  author    = {Pengteng Li and Ying He and F. Richard Yu and Pinhao Song and Xingchen Zhou and Guang Zhou},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/112},
  month     = {8},
  pages     = {1010-1019},
  title     = {OTOcc: Optimal transport for occupancy prediction},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Probabilistic contrastive learning for domain adaptation.
<em>IJCAI</em>, 1001–1009. (<a
href="https://doi.org/10.24963/ijcai.2024/111">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Contrastive learning has shown impressive success in enhancing feature discriminability for various visual tasks in a self-supervised manner, but the standard contrastive paradigm (features+l2 normalization) has limited benefits when applied in domain adaptation. We find that this is mainly because the class weights (weights of the final fully connected layer) are ignored in the domain adaptation optimization process, which makes it difficult for features to cluster around the corresponding class weights. To solve this problem, we propose the simple but powerful Probabilistic Contrastive Learning (PCL), which moves beyond the standard paradigm by removing l2 normalization and replacing the features with probabilities. PCL can guide the probability distribution towards a one-hot configuration, thus minimizing the discrepancy between features and class weights. We conduct extensive experiments to validate the effectiveness of PCL and observe consistent performance gains on five tasks, i.e., Unsupervised/Semi-Supervised Domain Adaptation (UDA/SSDA), Semi-Supervised Learning (SSL), UDA Detection and Semantic Segmentation. Notably, for UDA Semantic Segmentation on SYNTHIA, PCL surpasses the sophisticated CPSL-D by 2% in terms of mean IoU with a much lower training cost (PCL: 1*3090, 5 days v.s. CPSL-D: 4*V100, 11 days). Code is available at https://github.com/ljjcoder/Probabilistic-Contrastive-Learning. Keywords: Computer Vision: CV: Transfer, low-shot, semi- and un- supervised learning Computer Vision: CV: Recognition (object detection, categorization)},
  archive   = {C_IJCAI},
  author    = {Junjie Li and Yixin Zhang and Zilei Wang and Saihui Hou and Keyu Tu and Man Zhang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/111},
  month     = {8},
  pages     = {1001-1009},
  title     = {Probabilistic contrastive learning for domain adaptation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Boundary-aware decoupled flow networks for realistic extreme
rescaling. <em>IJCAI</em>, 992–1000. (<a
href="https://doi.org/10.24963/ijcai.2024/110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently developed generative methods, including invertible rescaling network (IRN) based and generative adversarial network (GAN) based methods, have demonstrated exceptional performance in image rescaling. However, IRN-based methods tend to produce over-smoothed results, while GAN-based methods easily generate fake details, which thus hinders their real applications. To address this issue, we propose Boundary-aware Decoupled Flow Networks (BDFlow) to generate realistic and visually pleasing results. Unlike previous methods that model high-frequency information as standard Gaussian distribution directly, our BDFlow first decouples the high-frequency information into semantic high-frequency that adheres to a Boundary distribution and non-semantic high-frequency counterpart that adheres to a Gaussian distribution. Specifically, to capture semantic high-frequency parts accurately, we use Boundary-aware Mask (BAM) to constrain the model to produce rich textures, while non-semantic high-frequency part is randomly sampled from a Gaussian distribution. Comprehensive experiments demonstrate that our BDFlow significantly outperforms other state-of-the-art methods while maintaining lower complexity. Notably, our BDFlow improves the PSNR by 4.4 dB and the SSIM by 0.1 on average over GRAIN, utilizing only 74% of the parameters and 20% of the computation. The code will be available at https://github.com/THU-Kingmin/BAFlow. Keywords: Computer Vision: CV: Image and video synthesis and generation Computer Vision: CV: Applications},
  archive   = {C_IJCAI},
  author    = {Jinmin Li and Tao Dai and Jingyun Zhang and Kang Liu and Jun Wang and Shaoming Wang and Shu-Tao Xia and Rizen Guo},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/110},
  month     = {8},
  pages     = {992-1000},
  title     = {Boundary-aware decoupled flow networks for realistic extreme rescaling},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Invertible residual rescaling models. <em>IJCAI</em>,
983–991. (<a href="https://doi.org/10.24963/ijcai.2024/109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Invertible Rescaling Networks (IRNs) and their variants have witnessed remarkable achievements in various image processing tasks like image rescaling. However, we observe that IRNs with deeper networks are difficult to train, thus hindering the representational ability of IRNs. To address this issue, we propose Invertible Residual Rescaling Models (IRRM) for image rescaling by learning a bijection between a high-resolution image and its low-resolution counterpart with a specific distribution. Specifically, we propose IRRM to build a deep network, which contains several Residual Downscaling Modules (RDMs) with long skip connections. Each RDM consists of several Invertible Residual Blocks (IRBs) with short connections. In this way, RDM allows rich low-frequency information to be bypassed by skip connections and forces models to focus on extracting high-frequency information from the image. Extensive experiments show that our IRRM performs significantly better than other state-of-the-art methods with much fewer parameters and complexity. Particularly, our IRRM has respectively PSNR gains of at least 0.3 dB over HCFlow and IRN in the x4 rescaling while only using 60% parameters and 50% FLOPs. The code will be available at https://github.com/THU-Kingmin/IRRM. Keywords: Computer Vision: CV: Image and video synthesis and generation Computer Vision: CV: Applications},
  archive   = {C_IJCAI},
  author    = {Jinmin Li and Tao Dai and Yaohua Zha and Yilu Luo and Longfei Lu and Bin Chen and Zhi Wang and Shu-Tao Xia and Jingyun Zhang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/109},
  month     = {8},
  pages     = {983-991},
  title     = {Invertible residual rescaling models},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A coarse-to-fine fusion network for event-based image
deblurring. <em>IJCAI</em>, 974–982. (<a
href="https://doi.org/10.24963/ijcai.2024/108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Event-driven image deblurring is an innovative approach involving the input of events obtained from the event camera alongside blurred frames to facilitate the deblurring process. Unlike conventional cameras, event cameras in event-driven imaging exhibit low-latency characteristics and are immune to motion blur, resulting in significant advancements in image deblurring. In this paper, we propose a pioneering event-based coarse-to-fine image deblurring network named CFFNet. In contrast to existing deblurring methods, our approach incorporates event data, generating multiple coarse frames from a single frame before further refining them into a sharp image. We introduce an Event Image Fusion Block (EIFB) for the coarse fusion of events and images, producing coarse frames at different time points. Additionally, we propose a Bidirectional Frame Fusion Block (BFFB) for the fine fusion of coarse frames. CFFNet effectively harnesses the spatiotemporal information of event data through a comprehensive fusion process from coarse to fine. Experimental results on the GoPro and REBlur datasets demonstrate that our method achieves state-of-the-art performance for image deblurring task. Keywords: Computer Vision: CV: Applications},
  archive   = {C_IJCAI},
  author    = {Huan Li and Hailong Shi and Xingyu Gao},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/108},
  month     = {8},
  pages     = {974-982},
  title     = {A coarse-to-fine fusion network for event-based image deblurring},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Bridging stereo geometry and BEV representation with
reliable mutual interaction for semantic scene completion.
<em>IJCAI</em>, 965–973. (<a
href="https://doi.org/10.24963/ijcai.2024/107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {3D semantic scene completion (SSC) is an ill-posed perception task that requires inferring a dense 3D scene from limited observations. Previous camera-based methods struggle to predict accurate semantic scenes due to inherent geometric ambiguity and incomplete observations. In this paper, we resort to stereo matching technique and bird’s-eye-view (BEV) representation learning to address such issues in SSC. Complementary to each other, stereo matching mitigates geometric ambiguity with epipolar constraint while BEV representation enhances the hallucination ability for invisible regions with global semantic context. However, due to the inherent representation gap between stereo geometry and BEV features, it is non-trivial to bridge them for dense prediction task of SSC. Therefore, we further develop a unified occupancy-based framework dubbed BRGScene, which effectively bridges these two representations with dense 3D volumes for reliable semantic scene completion. Specifically, we design a novel Mutual Interactive Ensemble (MIE) block for pixel-level reliable aggregation of stereo geometry and BEV features. Within the MIE block, a Bi-directional Reliable Interaction (BRI) module, enhanced with confidence re-weighting, is employed to encourage fine-grained interaction through mutual guidance. Besides, a Dual Volume Ensemble (DVE) module is introduced to facilitate complementary aggregation through channel-wise recalibration and multi-group voting. Our method outperforms all published camera-based methods on SemanticKITTI for semantic scene completion. Our code is available on https://github.com/Arlo0o/StereoScene. Keywords: Computer Vision: CV: 3D computer vision Computer Vision: CV: Recognition (object detection, categorization) Computer Vision: CV: Scene analysis and understanding},
  archive   = {C_IJCAI},
  author    = {Bohan Li and Yasheng Sun and Zhujin Liang and Dalong Du and Zhuanghui Zhang and Xiaofeng Wang and Yunnan Wang and Xin Jin and Wenjun Zeng},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/107},
  month     = {8},
  pages     = {965-973},
  title     = {Bridging stereo geometry and BEV representation with reliable mutual interaction for semantic scene completion},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). IntensPure: Attack intensity-aware secondary domain adaptive
diffusion for adversarial purification. <em>IJCAI</em>, 956–964. (<a
href="https://doi.org/10.24963/ijcai.2024/106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Adversarial attacks pose a severe threat to the accuracy of person re-identification (re-ID) systems, a critical security technology. Adversarial purification methods are promising approaches for defending against comprehensive attacks, including unseen ones. However, re-ID testing identities (IDs) are unseen, requiring more sophisticated purification than other classification tasks for adversarial defense. We propose IntensPure, an adversarial purification method in person re-ID that quantifies attack intensity via ID stability and attribute inconsistency to customize purification strength. Based on the estimated attack intensity, IntensPure employs secondary domain adaptive diffusion focused on purifying the low- and mid-frequency coefficients vulnerable to re-ID attacks. This method significantly reduces computational costs compared to the conventional diffusion method. For elaborate purification, IntensPure performs a directional diffusion process and refinements, leveraging the directional characteristics of secondary images. The experimental results on diverse attacks demonstrate that IntensPure outperforms the existing methods in terms of rank-1 accuracy. Keywords: Computer Vision: CV: Adversarial learning, adversarial attack and defense methods Computer Vision: CV: Machine learning for vision Computer Vision: CV: Recognition (object detection, categorization)},
  archive   = {C_IJCAI},
  author    = {Eun-Gi Lee and Moon Seok Lee and Jae Hyun Yoon and Seok Bong Yoo},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/106},
  month     = {8},
  pages     = {956-964},
  title     = {IntensPure: Attack intensity-aware secondary domain adaptive diffusion for adversarial purification},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TFLOP: Table structure recognition framework with layout
pointer mechanism. <em>IJCAI</em>, 947–955. (<a
href="https://doi.org/10.24963/ijcai.2024/105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Table Structure Recognition (TSR) is a task aimed at converting table images into a machine-readable format (e.g. HTML), to facilitate other applications such as information retrieval. Recent works tackle this problem by identifying the HTML tags and text regions, where the latter is used for text extraction from the table document. These works however, suffer from misalignment issues when mapping text into the identified text regions. In this paper, we introduce a new TSR framework, called TFLOP (TSR Framework with LayOut Pointer mechanism), which reformulates the conventional text region prediction and matching into a direct text region pointing problem. Specifically, TFLOP utilizes text region information to identify both the table&#39;s structure tags and its aligned text regions, simultaneously. Without the need for region prediction and alignment, TFLOP circumvents the additional text region matching stage, which requires finely-calibrated post-processing. TFLOP also employs span-aware contrastive supervision to enhance the pointing mechanism in tables with complex structure. As a result, TFLOP achieves the state-of-the-art performance across multiple benchmarks such as PubTabNet, FinTabNet, and SynthTabNet. In our extensive experiments, TFLOP not only exhibits competitive performance but also shows promising results on industrial document TSR scenarios such as documents with watermarks or in non-English domain. Source code of our work is publicly available at: https://github.com/UpstageAI/TFLOP. Keywords: Computer Vision: CV: Recognition (object detection, categorization) Computer Vision: CV: Applications Natural Language Processing: NLP: Applications},
  archive   = {C_IJCAI},
  author    = {Minsoo Khang and Teakgyu Hong},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/105},
  month     = {8},
  pages     = {947-955},
  title     = {TFLOP: Table structure recognition framework with layout pointer mechanism},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Scene-adaptive person search via bilateral modulations.
<em>IJCAI</em>, 938–946. (<a
href="https://doi.org/10.24963/ijcai.2024/104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Person search aims to localize specific a target person from a gallery set of images with various scenes. As the scene of moving pedestrian changes, the captured person image inevitably bring in lots of background noise and foreground noise on the person feature, which are completely unrelated to the person identity, leading to severe performance degeneration. To address this issue, we present a Scene-Adaptive Person Search (SEAS) model by introducing bilateral modulations to simultaneously eliminate scene noise and maintain a consistent person representation to adapt to various scenes. In SEAS, a Background Modulation Network (BMN) is designed to encode the feature extracted from the detected bounding box into a multi-granularity embedding, which reduces the input of background noise from multiple levels with norm-aware. Additionally, to mitigate the effect of foreground noise on the person feature, SEAS introduces a Foreground Modulation Network (FMN) to compute the clutter reduction offset for the person embedding based on the feature map of the scene image. By bilateral modulations on both background and foreground within an end-to-end manner, SEAS obtains consistent feature representations without scene noise. SEAS can achieve state-of-the-art (SOTA) performance on two benchmark datasets, CUHK-SYSU with 97.1% mAP and PRW with 60.5% mAP. The code is available at https://github.com/whbdmu/SEAS. Keywords: Computer Vision: CV: Image and video retrieval Computer Vision: CV: Representation learning},
  archive   = {C_IJCAI},
  author    = {Yimin Jiang and Huibing Wang and Jinjia Peng and Xianping Fu and Yang Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/104},
  month     = {8},
  pages     = {938-946},
  title     = {Scene-adaptive person search via bilateral modulations},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LeMeViT: Efficient vision transformer with learnable meta
tokens for remote sensing image interpretation. <em>IJCAI</em>, 929–937.
(<a href="https://doi.org/10.24963/ijcai.2024/103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Due to spatial redundancy in remote sensing images, sparse tokens containing rich information are usually involved in self-attention (SA) to reduce the overall token numbers within the calculation, avoiding the high computational cost issue in Vision Transformers. However, such methods usually obtain sparse tokens by hand-crafted or parallel-unfriendly designs, posing a challenge to reach a better balance between efficiency and performance. Different from them, this paper proposes to use learnable meta tokens to formulate sparse tokens, which effectively learn key information meanwhile improving the inference speed. Technically, the meta tokens are first initialized from image tokens via cross-attention. Then, we propose Dual Cross-Attention (DCA) to promote information exchange between image tokens and meta tokens, where they serve as query and key (value) tokens alternatively in a dual-branch structure, significantly reducing the computational complexity compared to self-attention. By employing DCA in the early stages with dense visual tokens, we obtain the hierarchical architecture LeMeViT with various sizes. Experimental results in classification and dense prediction tasks show that LeMeViT has a significant 1.7 × speedup, fewer parameters, and competitive performance compared to the baseline models, and achieves a better trade-off between efficiency and performance. The code is released at https://github.com/ViTAE-Transformer/LeMeViT. Keywords: Computer Vision: CV: Representation learning Computer Vision: CV: Recognition (object detection, categorization) Computer Vision: CV: Segmentation},
  archive   = {C_IJCAI},
  author    = {Wentao Jiang and Jing Zhang and Di Wang and Qiming Zhang and Zengmao Wang and Bo Du},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/103},
  month     = {8},
  pages     = {929-937},
  title     = {LeMeViT: Efficient vision transformer with learnable meta tokens for remote sensing image interpretation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). M2Beats: When motion meets beats in short-form videos.
<em>IJCAI</em>, 920–928. (<a
href="https://doi.org/10.24963/ijcai.2024/102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In recent years, short-form videos have gained popularity and the editing of these videos, particularly when motion is synchronized with music, is highly favored due to its beat-matching effect. However, detecting motion rhythm poses a significant challenge as it is influenced by multiple factors that make it difficult to define using explicit rules. While traditional methods attempt to define motion rhythm, they often yield unsatisfactory results. On the other hand, learning-based methods can extract motion rhythm without relying on explicit rules but require high-quality datasets. Unfortunately, existing datasets simply substitute music rhythm for motion rhythm which are not equivalent. To address these challenges, we present the motion rhythm dataset AIST-M2B, which is annotated with meticulously curated motion rhythm labels derived from the profound correlation between motion and music in professional dance. We propose a novel network architecture called M2BNet that is specifically trained on AIST-M2B to effectively extract intricate motion rhythms by incorporating both human body structure and temporal information. Additionally, we introduce a pioneering algorithm for enhancing motion rhythm synchronization with beats. Experimental results substan- tiate the superior performance of our method compared to other existing algorithms in the domain of motion rhythm analysis. Our code is available at https://github.com/mRobotit/M2Beats. Keywords: Computer Vision: CV: Image and video synthesis and generation Computer Vision: CV: Image and video retrieval Computer Vision: CV: Motion and tracking},
  archive   = {C_IJCAI},
  author    = {Dongxiang Jiang and Yongchang Zhang and Shuai He and Anlong Ming},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/102},
  month     = {8},
  pages     = {920-928},
  title     = {M2Beats: When motion meets beats in short-form videos},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Revealing the two sides of data augmentation: An asymmetric
distillation-based win-win solution for open-set recognition.
<em>IJCAI</em>, 911–919. (<a
href="https://doi.org/10.24963/ijcai.2024/101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we reveal the two sides of data augmentation: enhancements in closed-set recognition correlate with a significant decrease in open-set recognition. Through empirical investigation, we find that multi-sample-based augmentations would contribute to reducing feature discrimination, thereby diminishing the open-set criteria. Although knowledge distillation could impair the feature via imitation, the mixed feature with ambiguous semantics hinders the distillation. To this end, we propose an asymmetric distillation framework by feeding teacher model extra raw data to enlarge the benefit of teacher. Moreover, a joint mutual information loss and a selective relabel strategy are utilized to alleviate the influence of hard mixed samples. Our method successfully mitigates the decline in open-set and outperforms SOTAs by 2%~3% AUROC on the Tiny-ImageNet dataset and experiments on large-scale dataset ImageNet-21K demonstrate the generalization of our method. Keywords: Computer Vision: CV: Representation learning Computer Vision: CV: Structural and model-based approaches, knowledge representation and reasoning},
  archive   = {C_IJCAI},
  author    = {Yunbing Jia and Xiaoyu Kong and Fan Tang and Yixing Gao and Weiming Dong and Yi Yang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/101},
  month     = {8},
  pages     = {911-919},
  title     = {Revealing the two sides of data augmentation: An asymmetric distillation-based win-win solution for open-set recognition},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dual enhancement in ODI super-resolution: Adapting
convolution and upsampling to projection distortion. <em>IJCAI</em>,
902–910. (<a href="https://doi.org/10.24963/ijcai.2024/100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Omnidirectional images (ODIs) demand considerably higher resolution to ensure high quality across all viewports. Traditional convolutional neural networks (CNN)-based single-image super-resolution (SISR) networks, however, are not effective for spherical ODIs. This is due to the uneven pixel density distribution and varying texture complexity in different regions that arise when projecting from a sphere to a plane. Additionally, the computational and memory costs associated with large-sized ODIs present a challenge for real-world application. To address these issues, we propose an efficient distortion-adaptive super-resolution network (ODA-SRN). Specifically, ODA-SRN employs a series of specially designed Distortion Attention Block Groups (DABG) as its backbone. Our Distortion Attention Blocks (DABs) utilize multi-segment parameterized convolution to generate dynamic filters, which compensate for distortion and texture fading during feature extraction. Moreover, we introduce an upsampling scheme that accounts for the dependence of pixel position and distortion degree to achieve pixel-level distortion offset. A comprehensive set of results demonstrates that our ODA-SRN significantly improves the super-resolution performance for ODIs, both quantitatively and qualitatively, when compared to other state-of-the-art methods. Keywords: Computer Vision: CV: 3D computer vision Agent-based and Multi-agent Systems: MAS: Human-agent interaction Computer Vision: CV: Applications Computer Vision: CV: Structural and model-based approaches, knowledge representation and reasoning},
  archive   = {C_IJCAI},
  author    = {Xiang Ji and Changqiao Xu and Lujie Zhong and Shujie Yang and Han Xiao and Gabriel-Miro Muntean},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/100},
  month     = {8},
  pages     = {902-910},
  title     = {Dual enhancement in ODI super-resolution: Adapting convolution and upsampling to projection distortion},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PPTFormer: Pseudo multi-perspective transformer for UAV
segmentation. <em>IJCAI</em>, 893–901. (<a
href="https://doi.org/10.24963/ijcai.2024/99">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The ascension of Unmanned Aerial Vehicles (UAVs) in various fields necessitates effective UAV image segmentation, which faces challenges due to the dynamic perspectives of UAV-captured images. Traditional segmentation algorithms falter as they cannot accurately mimic the complexity of UAV perspectives, and the cost of obtaining multi-perspective labeled datasets is prohibitive. To address these issues, we introduce the PPTFormer, a novel Pseudo Multi-Perspective Transformer network that revolutionizes UAV image segmentation. Our approach circumvents the need for actual multi-perspective data by creating pseudo perspectives for enhanced multi-perspective learning. The PPTFormer network boasts Perspective Decomposition, novel Perspective Prototypes, and a specialized encoder and decoder that together achieve superior segmentation results through Pseudo Multi-Perspective Attention (PMP Attention) and fusion. Our experiments demonstrate that PPTFormer achieves state-of-the-art performance across five UAV segmentation datasets, confirming its capability to effectively simulate UAV flight perspectives and significantly advance segmentation precision. This work presents a pioneering leap in UAV scene understanding and sets a new benchmark for future developments in semantic segmentation. Keywords: Computer Vision: CV: Scene analysis and understanding Computer Vision: CV: Segmentation},
  archive   = {C_IJCAI},
  author    = {Deyi Ji and Wenwei Jin and Hongtao Lu and Feng Zhao},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/99},
  month     = {8},
  pages     = {893-901},
  title     = {PPTFormer: Pseudo multi-perspective transformer for UAV segmentation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Rethinking correlation learning via label prior for open set
domain adaptation. <em>IJCAI</em>, 884–892. (<a
href="https://doi.org/10.24963/ijcai.2024/98">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Open Set Domain Adaptation (OSDA) aims to transfer knowledge from a labeled source domain to an unlabeled target domain, where known classes exist across domains while unknown classes are present only in the target domain. Existing methods rely on the clustering structure to identify the unknown classes, which empirically induces a large identification error if the unknown classes are a mixture of multiple components. To break through this barrier, we formulate OSDA from the view of correlation and propose a correlation metric-based framework called Balanced Correlation Learning (BCL). BCL employs Hilbert-Schmidt Independence Criterion (HSIC) to characterize the separation between unknown and known classes, where HSIC is reformulated as the nodes’ relation on graph. By considering the label prior as variable, theoretical results are derived to analytically show a sufficient condition for desired learning direction for OSDA. Methodologically, the class-balanced HSIC is proposed to preserve domain-invariant and class-discriminative features. With the guarantee of correlation learning, the entropy-based principle can effectively identify the unknown classes via uncertainty. Empirically, extensive evaluations are conducted, where BCL achieves significant performance improvements. Keywords: Computer Vision: CV: Machine learning for vision Computer Vision: CV: Transfer, low-shot, semi- and un- supervised learning},
  archive   = {C_IJCAI},
  author    = {Zi-Xian Huang and Chuan-Xian Ren},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/98},
  month     = {8},
  pages     = {884-892},
  title     = {Rethinking correlation learning via label prior for open set domain adaptation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Eliminating the cross-domain misalignment in text-guided
image inpainting. <em>IJCAI</em>, 875–883. (<a
href="https://doi.org/10.24963/ijcai.2024/97">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Text-guided image inpainting has rapidly garnered prominence as a task in user-directed image synthesis, aiming to complete the occluded image regions following the textual prompt provided. However, current methods usually grapple with issues arising from the disparity between low-level pixel data and high-level semantic descriptions, which results in inpainted sections not harmonizing with the original image (either structurally or texturally). In this study, we introduce a Structure-Aware Inpainting Learning scheme and an Asymmetric Cross Domain Attention to address these cross-domain misalignment challenges. The proposed structure-aware learning scheme employs features of an intermediate modality as structure guidance to bridge the gap between text information and low-level pixels. Meanwhile, asymmetric cross-domain attention enhances the texture consistency between inpainted and unmasked regions. Our experiments show exceptional performance on leading datasets such as MS-COCO and Open Images, surpassing state-of-the-art text-guided image inpainting methods. Code is released at: https://github.com/MucciH/ECDM-inpainting Keywords: Computer Vision: CV: Image and video synthesis and generation Computer Vision: CV: Vision, language and reasoning},
  archive   = {C_IJCAI},
  author    = {Muqi Huang and Chaoyue Wang and Yong Luo and Lefei Zhang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/97},
  month     = {8},
  pages     = {875-883},
  title     = {Eliminating the cross-domain misalignment in text-guided image inpainting},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Long short-term dynamic prototype alignment learning for
video anomaly detection. <em>IJCAI</em>, 866–874. (<a
href="https://doi.org/10.24963/ijcai.2024/96">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Video anomaly detection (VAD) is the core problem of intelligent video surveillance. Previous methods commonly adopt the unsupervised paradigm of frame reconstruction or prediction. However, the lack of mining of temporal dependent relationships and diversified event patterns within videos limit the performance of existing methods. To tackle these problems, we propose a novel prototype-guided and dynamic-aware long-distance frame prediction paradigm for VAD. Specifically, we develop a prototype-guided dynamics matching network (PDM-Net) to enhance the discriminant and robustness of anomaly detector. To explore the temporal contexts, we equip PDM-Net with a long short-term dynamic prototype alignment learning mechanism, which stores long-term dynamic prototypes into memory bank and learns how to recall long-term dynamic prototypes with short-term dynamics. As a result, the short input sequences can recall long-term dynamic prototypes stored in the memory bank to achieve the task of long-distance frame prediction. Besides, a feature discrimination module is adopted to extract the representative dynamic features of various normal events meanwhile preserving the diversity of normal patterns. Experimental results on four public datasets demonstrate the superiority of our method. Keywords: Computer Vision: CV: Video analysis and understanding Computer Vision: CV: Multimodal learning Machine Learning: ML: Unsupervised learning},
  archive   = {C_IJCAI},
  author    = {Chao Huang and Jie Wen and Chengliang Liu and Yabo Liu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/96},
  month     = {8},
  pages     = {866-874},
  title     = {Long short-term dynamic prototype alignment learning for video anomaly detection},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hundred-kilobyte lookup tables for efficient single-image
super-resolution. <em>IJCAI</em>, 857–865. (<a
href="https://doi.org/10.24963/ijcai.2024/95">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Conventional super-resolution (SR) schemes make heavy use of convolutional neural networks (CNNs), which involve intensive multiply-accumulate (MAC) operations, and require specialized hardware such as graphics processing units. This contradicts the regime of edge AI that often runs on devices strained by power, computing, and storage resources. Such a challenge has motivated a series of lookup table (LUT)-based SR schemes that employ simple LUT readout and largely elude CNN computation. Nonetheless, the multi-megabyte LUTs in existing methods still prohibit on-chip storage and necessitate off-chip memory transport. This work tackles this storage hurdle and innovates hundred-kilobyte LUT (HKLUT) models amenable to on-chip cache. Utilizing an asymmetric two-branch multistage network coupled with a suite of specialized kernel patterns, HKLUT demonstrates an uncompromising performance and superior hardware efficiency over existing LUT schemes. Our implementation is publicly available at: https://github.com/jasonli0707/hklut. Keywords: Computer Vision: CV: Image and video synthesis and generation Computer Vision: CV: Applications},
  archive   = {C_IJCAI},
  author    = {Binxiao Huang and Jason Chun Lok Li and Jie Ran and Boyu Li and Jiajun Zhou and Dahai Yu and Ngai Wong},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/95},
  month     = {8},
  pages     = {857-865},
  title     = {Hundred-kilobyte lookup tables for efficient single-image super-resolution},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving adversarial robustness via feature pattern
consistency constraint. <em>IJCAI</em>, 848–856. (<a
href="https://doi.org/10.24963/ijcai.2024/94">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Convolutional Neural Networks (CNNs) are well-known for their vulnerability to adversarial attacks, posing significant security concerns. In response to these threats, various defense methods have emerged to bolster the model&#39;s robustness. However, most existing methods either focus on learning from adversarial perturbations, leading to overfitting to the adversarial examples, or aim to eliminate such perturbations during inference, inevitably increasing computational burdens. Conversely, clean training, which strengthens the model&#39;s robustness by relying solely on clean examples, can address the aforementioned issues. In this paper, we align with this methodological stream and enhance its generalizability to unknown adversarial examples. This enhancement is achieved by scrutinizing the behavior of latent features within the network. Recognizing that a correct prediction relies on the correctness of the latent feature&#39;s pattern, we introduce a novel and effective Feature Pattern Consistency Constraint (FPCC) method to reinforce the latent feature&#39;s capacity to maintain the correct feature pattern. Specifically, we propose Spatial-wise Feature Modification and Channel-wise Feature Selection to enhance latent features. Subsequently, we employ the Pattern Consistency Loss to constrain the similarity between the feature pattern of the latent features and the correct feature pattern. Our experiments demonstrate that the FPCC method empowers latent features to uphold correct feature patterns even in the face of adversarial examples, resulting in inherent adversarial robustness surpassing state-of-the-art models. Keywords: Computer Vision: CV: Adversarial learning, adversarial attack and defense methods Computer Vision: CV: Recognition (object detection, categorization) Machine Learning: ML: Classification},
  archive   = {C_IJCAI},
  author    = {Jiacong Hu and Jingwen Ye and Zunlei Feng and Jiazhen Yang and Shunyu Liu and Xiaotian Yu and Lingxiang Jia and Mingli Song},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/94},
  month     = {8},
  pages     = {848-856},
  title     = {Improving adversarial robustness via feature pattern consistency constraint},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Why only text: Empowering vision-and-language navigation
with multi-modal prompts. <em>IJCAI</em>, 839–847. (<a
href="https://doi.org/10.24963/ijcai.2024/93">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Current Vision-and-Language Navigation (VLN) tasks mainly employ textual instructions to guide agents. However, being inherently abstract, the same textual instruction can be associated with different visual signals, causing severe ambiguity and limiting the transfer of prior knowledge in the vision domain from the user to the agent. To fill this gap, we propose Vision-and-Language Navigation with Multi-modal Prompts (VLN-MP), a novel task augmenting traditional VLN by integrating both natural language and images in instructions. VLN-MP not only maintains backward compatibility by effectively handling text-only prompts but also consistently shows advantages with different quantities and relevance of visual prompts. Possible forms of visual prompts include both exact and similar object images, providing adaptability and versatility in diverse navigation scenarios. To evaluate VLN-MP under a unified framework, we implement a new benchmark that offers: (1) a training-free pipeline to transform textual instructions into multi-modal forms with landmark images; (2) diverse datasets with multi-modal instructions for different downstream tasks; (3) a novel module designed to process various image prompts for seamless integration with state-of-the-art VLN models. Extensive experiments on four VLN benchmarks (R2R, RxR, REVERIE, CVDN) show that incorporating visual prompts would significantly boost navigation performance. While maintaining efficiency with text-only prompts, VLN-MP enables agents to navigate in the pre-explore setting and outperform text-based models, showing its broader applicability. Code is available at https://github.com/honghd16/VLN-MP. Keywords: Computer Vision: CV: Vision, language and reasoning Computer Vision: CV: Multimodal learning Machine Learning: ML: Multi-modal learning},
  archive   = {C_IJCAI},
  author    = {Haodong Hong and Sen Wang and Zi Huang and Qi Wu and Jiajun Liu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/93},
  month     = {8},
  pages     = {839-847},
  title     = {Why only text: Empowering vision-and-language navigation with multi-modal prompts},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CMMU: A benchmark for chinese multi-modal multi-type
question understanding and reasoning. <em>IJCAI</em>, 830–838. (<a
href="https://doi.org/10.24963/ijcai.2024/92">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-modal large language models(MLLMs) have achieved remarkable progress and demonstrated powerful knowledge comprehension and reasoning abilities. However, the mastery of domain-specific knowledge, which is essential for evaluating the intelligence of MLLMs, continues to be a challenge. Current multi-modal benchmarks for domain-specific knowledge concentrate on multiple-choice questions and are predominantly available in English, which imposes limitations on the comprehensiveness of the evaluation. To this end, we introduce CMMU, a novel benchmark for multi-modal and multi-type question understanding and reasoning in Chinese. CMMU consists of 3,603 questions in 7 subjects, covering knowledge from primary to high school. The questions can be categorized into 3 types: multiple-choice, multiple-response, and fill-in-the-blank, bringing greater challenges to MLLMs. In addition, we propose an evaluation strategy called Positional Error Variance for assessing multiple-choice questions. The strategy aims to perform a quantitative analysis of position bias. We evaluate seven open-source MLLMs along with GPT4-V, Gemini-Pro, and Qwen-VL-Plus. The results demonstrate that CMMU poses a significant challenge to the recent MLLMs. The data and code are available at https://github.com/FlagOpen/CMMU. Keywords: Computer Vision: CV: Multimodal learning Multidisciplinary Topics and Applications: MTA: Education},
  archive   = {C_IJCAI},
  author    = {Zheqi He and Xinya Wu and Pengfei Zhou and Richeng Xuan and Guang Liu and Xi Yang and Qiannan Zhu and Hua Huang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/92},
  month     = {8},
  pages     = {830-838},
  title     = {CMMU: A benchmark for chinese multi-modal multi-type question understanding and reasoning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A lightweight u-like network utilizing neural memory
ordinary differential equations for slimming the decoder.
<em>IJCAI</em>, 821–829. (<a
href="https://doi.org/10.24963/ijcai.2024/91">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In recent years, advanced U-like networks have demonstrated remarkable performance in medical image segmentation tasks. However, their drawbacks, including excessive parameters, high computational complexity, and slow inference speed, pose challenges for practical implementation in scenarios with limited computational resources. Existing lightweight U-like networks have alleviated some problems, but they often have pre-designed structures and consist of non-detachable modules, limiting their application scenarios. In this paper, we propose three plug-and-play decoders by employing different discretization methods of the neural memory Ordinary Differential Equation (nmODE). These decoders integrate features at various levels of abstraction by processing information from skip connections and performing numerical operations on upward paths. Through experiments on the PH2, ISIC2017, and ISIC2018 datasets, we embed these decoders into different U-like networks, demonstrating their effectiveness in significantly reducing the number of parameters and computation while maintaining performance. In summary, the proposed discretized nmODE decoder is capable of reducing the number of parameters by about 20% ~ 50% and computation by up to 74%, while being adaptive to all U-like networks. Our code is available at https://github.com/nayutayuki/Lightweight-nmODE-Decoders-For-U-like-networks. Keywords: Computer Vision: CV: Segmentation Computer Vision: CV: Biomedical image analysis Computer Vision: CV: Machine learning for vision Machine Learning: ML: Convolutional networks},
  archive   = {C_IJCAI},
  author    = {Quansong He and Xiaojun Yao and Jun Wu and Zhang Yi and Tao He},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/91},
  month     = {8},
  pages     = {821-829},
  title     = {A lightweight U-like network utilizing neural memory ordinary differential equations for slimming the decoder},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). UniM-OV3D: Uni-modality open-vocabulary 3D scene
understanding with fine-grained feature representation. <em>IJCAI</em>,
812–820. (<a href="https://doi.org/10.24963/ijcai.2024/90">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {3D open-vocabulary scene understanding aims to recognize arbitrary novel categories beyond the base label space. However, existing works not only fail to fully utilize all the available modal information in the 3D domain but also lack sufficient granularity in representing the features of each modality. In this paper, we propose a unified multimodal 3D open-vocabulary scene understanding network, namely UniM-OV3D, aligning point clouds with image, language and depth. To better integrate global and local features of the point clouds, we design a hierarchical point cloud feature extraction module that learns fine-grained feature representations. Further, to facilitate the learning of coarse-to-fine point-semantic representations from captions, we propose the utilization of hierarchical 3D caption pairs, capitalizing on geometric constraints across various viewpoints of 3D scenes. Extensive experimental results have demonstrated the effectiveness and superiority of our method in open-vocabulary semantic and instance segmentation, which achieves state-of-the-art performance on both indoor and outdoor benchmarks such as ScanNet, ScanNet200, S3IDS and nuScenes. Code is available at https://github.com/hithqd/UniM-OV3D. Keywords: Computer Vision: CV: 3D computer vision Computer Vision: CV: Applications Computer Vision: CV: Scene analysis and understanding},
  archive   = {C_IJCAI},
  author    = {Qingdong He and Jinlong Peng and Zhengkai Jiang and Kai Wu and Xiaozhong Ji and Jiangning Zhang and Yabiao Wang and Chengjie Wang and Mingang Chen and Yunsheng Wu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/90},
  month     = {8},
  pages     = {812-820},
  title     = {UniM-OV3D: Uni-modality open-vocabulary 3D scene understanding with fine-grained feature representation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TSESNet: Temporal-spatial enhanced breast tumor segmentation
in DCE-MRI using feature perception and separability. <em>IJCAI</em>,
803–811. (<a href="https://doi.org/10.24963/ijcai.2024/89">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Accurate segmentation of breast tumors in dynamic contrast-enhanced magnetic resonance images (DCE-MRI) is critical for early diagnosis of breast cancer. However, this task remains challenging due to the wide range of tumor sizes, shapes, and appearances. Additionally, the complexity is further compounded by the high dimensionality and ill-posed artifacts present in DCE-MRI data. Furthermore, accurately modeling features in DCE-MRI sequences presents a challenge that hinders the effective representation of essential tumor characteristics. Therefore, this paper introduces a novel Temporal-Spatial Enhanced Network (TSESNet) for breast tumor segmentation in DCE-MRI. TSESNet leverages the spatial and temporal dependencies of DCE-MRI to provide a comprehensive representation of tumor features. To address sequence modeling challenges, we propose a Temporal-Spatial Contrastive Loss (TSCLoss) that maximizes the distance between different classes and minimizes the distance within the same class, thereby improving the separation between tumors and the background. Moreover, we design a novel Temporal Series Feature Fusion (TSFF) module that effectively integrates temporal MRI features from multiple time points, enhancing the model&#39;s ability to handle temporal sequences and improving overall performance. Finally, we introduce a simple and effective Tumor-Aware (TA) module that enriches feature representation to accommodate tumors of various sizes. We conducted comprehensive experiments to validate the proposed method and demonstrate its superior performance compared to recent state-of-the-art segmentation methods on two breast cancer DCE-MRI datasets. Keywords: Computer Vision: CV: Segmentation Computer Vision: CV: 3D computer vision Computer Vision: CV: Biomedical image analysis},
  archive   = {C_IJCAI},
  author    = {Jiezhou He and Xue Zhao and Zhiming Luo and Songzhi Su and Shaozi Li and Guojun Zhang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/89},
  month     = {8},
  pages     = {803-811},
  title     = {TSESNet: Temporal-spatial enhanced breast tumor segmentation in DCE-MRI using feature perception and separability},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing cross-modal completion and alignment for
unsupervised incomplete text-to-image person retrieval. <em>IJCAI</em>,
794–802. (<a href="https://doi.org/10.24963/ijcai.2024/88">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Traditional text-image person retrieval methods heavily rely on fully matched and identity-annotated multimodal data, representing an ideal yet limited scenario. The issues of handling incomplete multimodal data and the complexities of labeling multimodal data are common challenges encountered in real-world applications. In response to these challenges encountered, we consider a more robust and pragmatic setting termed unsupervised incomplete text-image person retrieval, where person images and text descriptions are not fully matched and lack the supervision of identity labels. To tackle these two problems, we propose the Enhancing Cross-modal Completion and Alignment (ECCA) method. Specifically, we propose a feature-level cross-modal completion strategy for incomplete data. This approach leverages the available cross-modal high semantic similarity features to construct relational graphs for missing modal data, which can generate more reliable completion features. Additionally, to address the cross-modal matching ambiguity, we propose weighted inter-instance granularity alignment as well as enhanced prototype-wise granularity alignment modules that can map semantically similar image-text pairs more compact in the common embedding space. Extensive experiments on public datasets, fully demonstrate the consistent superiority of our method over SOTA text-image person retrieval methods. Keywords: Computer Vision: CV: Multimodal learning},
  archive   = {C_IJCAI},
  author    = {Tiantian Gong and Junsheng Wang and Liyan Zhang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/88},
  month     = {8},
  pages     = {794-802},
  title     = {Enhancing cross-modal completion and alignment for unsupervised incomplete text-to-image person retrieval},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cross-scale domain adaptation with comprehensive information
for pansharpening. <em>IJCAI</em>, 785–793. (<a
href="https://doi.org/10.24963/ijcai.2024/87">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep learning-based pansharpening methods typically use simulated data at the reduced-resolution scale for training. It limits their performance when generalizing the trained model to the full-resolution scale due to incomprehensive information utilization of panchromatic (PAN) images at the full-resolution scale and low generalization ability. In this paper, we adopt two targeted strategies to address the above two problems. On the one hand, we introduce a cross-scale comprehensive information capture module, which improves the information utilization of the original PAN image through fully-supervised reconstruction. On the other hand, we pioneer a domain adaptation strategy to tackle the problem of low generalization across different scales. Considering the instinct domain gap between different scales, we leverage the maximum mean discrepancy loss and the inherent pixel-level correlations between features at different scales to reduce the scale variance, thus boosting the generalization ability of our model. Experiments on various satellites demonstrate the superiority of our method over the state-of-the-arts in terms of information retention. Our code is publicly available at https://github.com/Meiqi-Gong/SDIPS. Keywords: Computer Vision: CV: Multimodal learning Computer Vision: CV: Computational photography},
  archive   = {C_IJCAI},
  author    = {Meiqi Gong and Hao Zhang and Hebaixu Wang and Jun Chen and Jun Huang and Xin Tian and Jiayi Ma},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/87},
  month     = {8},
  pages     = {785-793},
  title     = {Cross-scale domain adaptation with comprehensive information for pansharpening},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A dataset and model for realistic license plate deblurring.
<em>IJCAI</em>, 776–784. (<a
href="https://doi.org/10.24963/ijcai.2024/86">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Vehicle license plate recognition is a crucial task in intelligent traffic management systems. However, the challenge of achieving accurate recognition persists due to motion blur from fast-moving vehicles. Despite the widespread use of image synthesis approaches in existing deblurring and recognition algorithms, their effectiveness in real-world scenarios remains unproven. To address this, we introduce the first large-scale license plate deblurring dataset named License Plate Blur (LPBlur), captured by a dual-camera system and processed through a post-processing pipeline to avoid misalignment issues. Then, we propose a License Plate Deblurring Generative Adversarial Network (LPDGAN) to tackle the license plate deblurring: 1) a Feature Fusion Module to integrate multi-scale latent codes; 2) a Text Reconstruction Module to restore structure through textual modality; 3) a Partition Discriminator Module to enhance the model&#39;s perception of details in each letter. Extensive experiments validate the reliability of the LPBlur dataset for both model training and testing, showcasing that our proposed model outperforms other state-of-the-art motion deblurring methods in realistic license plate deblurring scenarios. The dataset and code are available at https://github.com/haoyGONG/LPDGAN. Keywords: Computer Vision: CV: Adversarial learning, adversarial attack and defense methods Computer Vision: CV: Applications Computer Vision: CV: Image and video synthesis and generation},
  archive   = {C_IJCAI},
  author    = {Haoyan Gong and Yuzheng Feng and Zhenrong Zhang and Xianxu Hou and Jingxin Liu and Siqi Huang and Hongbin Liu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/86},
  month     = {8},
  pages     = {776-784},
  title     = {A dataset and model for realistic license plate deblurring},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Self-supervised pre-training with symmetric superimposition
modeling for scene text recognition. <em>IJCAI</em>, 767–775. (<a
href="https://doi.org/10.24963/ijcai.2024/85">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In text recognition, self-supervised pre-training emerges as a good solution to reduce dependence on expansive annotated real data. Previous studies primarily focus on local visual representation by leveraging mask image modeling or sequence contrastive learning. However, they omit modeling the linguistic information in text images, which is crucial for recognizing text. To simultaneously capture local character features and linguistic information in visual space, we propose Symmetric Superimposition Modeling (SSM). The objective of SSM is to reconstruct the direction-specific pixel and feature signals from the symmetrically superimposed input. Specifically, we add the original image with its inverted views to create the symmetrically superimposed inputs. At the pixel level, we reconstruct the original and inverted images to capture character shapes and texture-level linguistic context. At the feature level, we reconstruct the feature of the same original image and inverted image with different augmentations to model the semantic-level linguistic context and the local character discrimination. In our design, we disrupt the character shape and linguistic rules. Consequently, the dual-level reconstruction facilitates understanding character shapes and linguistic information from the perspective of visual texture and feature semantics. Experiments on various text recognition benchmarks demonstrate the effectiveness and generality of SSM, with 4.1\% average performance gains and 86.6% new state-of-the-art average word accuracy on Union14M benchmarks. The code is available at https://github.com/FaltingsA/SSM. Keywords: Computer Vision: CV: Recognition (object detection, categorization) Computer Vision: CV: Multimodal learning Computer Vision: CV: Representation learning Computer Vision: CV: Transfer, low-shot, semi- and un- supervised learning},
  archive   = {C_IJCAI},
  author    = {Zuan Gao and Yuxin Wang and Yadong Qu and Boqiang Zhang and Zixiao Wang and Jianjun Xu and Hongtao Xie},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/85},
  month     = {8},
  pages     = {767-775},
  title     = {Self-supervised pre-training with symmetric superimposition modeling for scene text recognition},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CF-deformable DETR: An end-to-end alignment-free model for
weakly aligned visible-infrared object detection. <em>IJCAI</em>,
758–766. (<a href="https://doi.org/10.24963/ijcai.2024/84">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Weakly aligned visible-infrared object detection poses significant challenges due to the imprecise alignment between visible and infrared images. Most existing methods explore the alignment strategies between visible and infrared images, yielding unbearable computation costs. This paper first proposes an end-to-end alignment-free architecture Cross-modal Fusion Deformable DEtection TRansformer (``CF-Deformable DETR&#39;&#39;) for weakly aligned visible-infrared object detection. Abandoning the traditional image alignment, CF-Deformable DETR introduces a simple yet effective cross-modal deformable attention mechanism to directly implement automatic cross-modal point mapping, generating well-aligned bimodal features with high efficiency. Moreover, we design a Point-level Feature Consistency Loss to guide the cross-modal point mapping, ensuring the consistency of paired features to support the following fusion. Extensive experiments are conducted on three benchmark datasets. The experimental results demonstrate that CF-Deformable DETR achieves close accuracy on weakly aligned and strictly aligned data as well as maintains stable performance to a certain extent against various offset degrees of weakly aligned data. Code is available at https://github.com/116508/CF-Deformable-DETR. Keywords: Computer Vision: CV: Recognition (object detection, categorization) Computer Vision: CV: Multimodal learning},
  archive   = {C_IJCAI},
  author    = {Haolong Fu and Jin Yuan and Guojin Zhong and Xuan He and Jiacheng Lin and Zhiyong Li},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/84},
  month     = {8},
  pages     = {758-766},
  title     = {CF-deformable DETR: An end-to-end alignment-free model for weakly aligned visible-infrared object detection},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unified physical-digital face attack detection.
<em>IJCAI</em>, 749–757. (<a
href="https://doi.org/10.24963/ijcai.2024/83">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Face Recognition (FR) systems can suffer from physical (i.e., print photo) and digital (i.e., DeepFake) attacks. However, previous related work rarely considers both situations at the same time. This implies the deployment of multiple models and thus more computational burden. The main reasons for this lack of an integrated model are caused by two factors: (1) The lack of a dataset including both physical and digital attacks which the same ID covers the real face and all attack types; (2) Given the large intra-class variance between these two attacks, it is difficult to learn a compact feature space to detect both attacks simultaneously. To address these issues, we collect a Unified physical-digital Attack dataset, called UniAttackData. The dataset consists of 1,800 participations of 2 and 12 physical and digital attacks, respectively, resulting in a total of 28,706 videos. Then, we propose a Unified Attack Detection framework based on Vision-Language Models (VLMs), namely UniAttackDetection, which includes three main modules: the Teacher-Student Prompts (TSP) module, focused on acquiring unified and specific knowledge respectively; the Unified Knowledge Mining (UKM) module, designed to capture a comprehensive feature space; and the Sample-Level Prompt Interaction (SLPI) module, aimed at grasping sample-level semantics. These three modules seamlessly form a robust unified attack detection framework. Extensive experiments on UniAttackData and three other datasets demonstrate the superiority of our approach for unified face attack detection. Dataset link: https://sites.google.com/view/face-anti-spoofing-challenge/dataset-download/uniattackdatacvpr2024 Keywords: Computer Vision: CV: Biometrics, face, gesture and pose recognition Machine Learning: ML: Multi-modal learning},
  archive   = {C_IJCAI},
  author    = {Hao Fang and Ajian Liu and Haocheng Yuan and Junze Zheng and Dingheng Zeng and Yanhong Liu and Jiankang Deng and Sergio Escalera and Xiaoming Liu and Jun Wan and Zhen Lei},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/83},
  month     = {8},
  pages     = {749-757},
  title     = {Unified physical-digital face attack detection},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bridging generative and discriminative models for unified
visual perception with diffusion priors. <em>IJCAI</em>, 740–748. (<a
href="https://doi.org/10.24963/ijcai.2024/82">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The remarkable prowess of diffusion models in image generation has spurred efforts to extend their application beyond generative tasks. However, a persistent challenge exists in lacking a unified approach to apply diffusion models to visual perception tasks with diverse semantic granularity requirements. Our purpose is to establish a unified visual perception framework, capitalizing on the potential synergies between generative and discriminative models. In this paper, we propose Vermouth, a simple yet effective framework comprising a pre-trained Stable Diffusion (SD) model containing rich generative priors, a unified head (U-head) capable of integrating hierarchical representations, and an Adapted-Expert providing discriminative priors. Comprehensive investigations unveil potential characteristics of Vermouth, such as varying granularity of perception concealed in latent variables at distinct time steps and various U-net stages. We emphasize that there is no necessity for incorporating a heavyweight or intricate decoder to transform diffusion models into potent representation learners. Extensive comparative evaluations against tailored discriminative models showcase the efficacy of our approach on zero-shot sketch-based image retrieval (ZS-SBIR), few-shot classification, and open-vocabulary (OV) semantic segmentation tasks. The promising results demonstrate the potential of diffusion models as formidable learners, establishing their significance in furnishing informative and robust visual representations. Keywords: Computer Vision: CV: Representation learning Computer Vision: CV: Recognition (object detection, categorization) Computer Vision: CV: Segmentation Computer Vision: CV: Transfer, low-shot, semi- and un- supervised learning},
  archive   = {C_IJCAI},
  author    = {Shiyin Dong and Mingrui Zhu and Kun Cheng and Nannan Wang and Xinbo Gao},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/82},
  month     = {8},
  pages     = {740-748},
  title     = {Bridging generative and discriminative models for unified visual perception with diffusion priors},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FreqFormer: Frequency-aware transformer for lightweight
image super-resolution. <em>IJCAI</em>, 731–739. (<a
href="https://doi.org/10.24963/ijcai.2024/81">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Transformer-based models have been widely and successfully used in various low-vision visual tasks, and have achieved remarkable performance in single image super-resolution (SR). Despite the significant progress in SR, Transformer-based SR methods (e.g., SwinIR) still suffer from the problems of heavy computation cost and low-frequency preference, while ignoring the reconstruction of rich high-frequency information, hence hindering the representational power of Transformers. To address these issues, in this paper, we propose a novel Frequency-aware Transformer (FreqFormer) for lightweight image SR. Specifically, a Frequency Division Module (FDM) is first introduced to separately handle high- and low-frequency information in a divide-and-conquer manner. Moreover, we present Frequency-aware Transformer Block (FTB) to extracting both spatial frequency attention and channel transposed attention to recover high-frequency details. Extensive experimental results on public datasets demonstrate the superiority of our FreqFormer over state-of-the-art SR methods in terms of both quantitative metrics and visual quality. Code and models are available at https://github.com/JPWang-CS/FreqFormer. Keywords: Computer Vision: CV: Applications Computer Vision: CV: Image and video synthesis and generation Computer Vision: CV: Interpretability and transparency Computer Vision: CV: Machine learning for vision},
  archive   = {C_IJCAI},
  author    = {Tao Dai and Jianping Wang and Hang Guo and Jinmin Li and Jinbao Wang and Zexuan Zhu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/81},
  month     = {8},
  pages     = {731-739},
  title     = {FreqFormer: Frequency-aware transformer for lightweight image super-resolution},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hybrid frequency modulation network for image restoration.
<em>IJCAI</em>, 722–730. (<a
href="https://doi.org/10.24963/ijcai.2024/80">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Image restoration involves recovering a high-quality image from its corrupted counterpart. This paper presents an effective and efficient framework for image restoration, termed CSNet, based on ``channel + spatial&quot; hybrid frequency modulation. Different feature channels include different degradation patterns and degrees, however, most current networks ignore the importance of channel interactions. To alleviate this issue, we propose a frequency-based channel feature modulation module to facilitate channel interactions through the channel-dimension Fourier transform. Furthermore, based on our observations, we develop a multi-scale frequency-based spatial feature modulation module to refine the direct-current component of features using extremely lightweight learnable parameters. This module contains a densely connected coarse-to-fine learning paradigm for enhancing multi-scale representation learning. In addition, we introduce a frequency-inspired loss function to achieve omni-frequency learning. Extensive experiments on nine datasets demonstrate that the proposed network achieves state-of-the-art performance for three image restoration tasks, including image dehazing, image defocus deblurring, and image desnowing. The code and models are available at https://github.com/c-yn/CSNet. Keywords: Computer Vision: CV: Applications Computer Vision: CV: Computational photography Computer Vision: CV: Representation learning},
  archive   = {C_IJCAI},
  author    = {Yuning Cui and Mingyu Liu and Wenqi Ren and Alois Knoll},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/80},
  month     = {8},
  pages     = {722-730},
  title     = {Hybrid frequency modulation network for image restoration},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fast one-stage unsupervised domain adaptive person search.
<em>IJCAI</em>, 713–721. (<a
href="https://doi.org/10.24963/ijcai.2024/79">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Unsupervised person search aims to localize a particular target person from a gallery set of scene images without annotations, which is extremely challenging due to the unexpected variations of the unlabeled domains. However, most existing methods dedicate to developing multi-stage models to adapt domain variations while using clustering for iterative model training, which inevitably increase model complexity. To address this issue, we propose a Fast One-stage Unsupervised person Search (FOUS) which complementaryly integrates domain adaption with label adaption within an end-to-end manner without iterative clustering. To minimize the domain discrepancy, FOUS introduced an Attention-based Domain Alignment Module (ADAM) which can not only align various domains for both detection and ReID tasks but also construct an attention mechanism to reduce the adverse impacts of low-quality candidates resulting from unsupervised detection. Moreover, to avoid the redundant iterative clustering mode, FOUS adopts a prototype-guided labeling method which minimizes redundant correlation computations for partial samples and assigns noisy coarse label groups efficiently. The coarse label groups will be continuously refined via label-flexible training network with an adaptive selection strategy. With the adapted domains and labels, FOUS can achieve the state-of-the-art (SOTA) performance on two benchmark datasets, CUHK-SYSU and PRW. The code is available at https://github.com/whbdmu/FOUS. Keywords: Computer Vision: CV: Recognition (object detection, categorization) Computer Vision: CV: Image and video retrieval},
  archive   = {C_IJCAI},
  author    = {Tianxiang Cui and Huibing Wang and Jinjia Peng and Ruoxi Deng and Xianping Fu and Yang Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/79},
  month     = {8},
  pages     = {713-721},
  title     = {Fast one-stage unsupervised domain adaptive person search},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Imperio: Language-guided backdoor attacks for arbitrary
model control. <em>IJCAI</em>, 704–712. (<a
href="https://doi.org/10.24963/ijcai.2024/78">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Natural language processing (NLP) has received unprecedented attention. While advancements in NLP models have led to extensive research into their backdoor vulnerabilities, the potential for these advancements to introduce new backdoor threats remains unexplored. This paper proposes Imperio, which harnesses the language understanding capabilities of NLP models to enrich backdoor attacks. Imperio provides a new model control experience. Demonstrated through controlling image classifiers, it empowers the adversary to manipulate the victim model with arbitrary output through language-guided instructions. This is achieved using a language model to fuel a conditional trigger generator, with optimizations designed to extend its language understanding capabilities to backdoor instruction interpretation and execution. Our experiments across three datasets, five attacks, and nine defenses confirm Imperio&#39;s effectiveness. It can produce contextually adaptive triggers from text descriptions and control the victim model with desired outputs, even in scenarios not encountered during training. The attack reaches a high success rate without compromising the accuracy of clean inputs and exhibits resilience against representative defenses. Supplementary materials are available at https://khchow.com/Imperio. Keywords: Computer Vision: CV: Adversarial learning, adversarial attack and defense methods AI Ethics, Trust, Fairness: ETF: Safety and robustness AI Ethics, Trust, Fairness: ETF: Trustworthy AI},
  archive   = {C_IJCAI},
  author    = {Ka-Ho Chow and Wenqi Wei and Lei Yu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/78},
  month     = {8},
  pages     = {704-712},
  title     = {Imperio: Language-guided backdoor attacks for arbitrary model control},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Denoising diffusion-augmented hybrid video anomaly detection
via reconstructing noised frames. <em>IJCAI</em>, 695–703. (<a
href="https://doi.org/10.24963/ijcai.2024/77">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Video Anomaly Detection (VAD) is crucial for enhancing security and surveillance systems through automatic identification of irregular events, thereby enabling timely responses and augmenting overall situational awareness. Although existing methods have achieved decent detection performances on benchmarks, their predicted objects still remain ambiguous in terms of the semantic aspect. To overcome this limitation, we propose the Denoising diffusion-augmented Hybrid Video Anomaly Detection (DHVAD) framework. The proposed Denoising diffusion-based Reconstruction Unit (DRU) enhances the understanding of semantically accurate normality as a crucial component in DHVAD. Meanwhile, we propose a detection strategy that integrates the advantages of a prediction-based Frame Prediction Unit (FPU) with DRU by exploring the spatial-temporal consistency seamlessly. The competitive performance of DHVAD compared with state-of-the-art methods on three benchmark datasets proves the effectiveness of our framework. The extended experimental analysis demonstrates that our framework can gain a better understanding of the normality in terms of semantic accuracy for VAD and efficiently leverage the strengths of both components. Keywords: Computer Vision: CV: Video analysis and understanding Computer Vision: CV: Representation learning Computer Vision: CV: Scene analysis and understanding},
  archive   = {C_IJCAI},
  author    = {Kai Cheng and Yaning Pan and Yang Liu and Xinhua Zeng and Rui Feng},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/77},
  month     = {8},
  pages     = {695-703},
  title     = {Denoising diffusion-augmented hybrid video anomaly detection via reconstructing noised frames},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MetaISP: Efficient RAW-to-sRGB mappings with merely 1M
parameters. <em>IJCAI</em>, 686–694. (<a
href="https://doi.org/10.24963/ijcai.2024/76">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {State-of-the-art deep ISP models alleviate the dilemma of limited generalization capabilities across heterogeneous inputs by increasing the size and complexity of the network, which inevitably leads to considerable growth in parameter counts and FLOPs. To address this challenge, this paper presents MetaISP - a streamlined model that achieves superior reconstruction quality by adaptively modulating its parameters and architecture in response to diverse inputs. Our rationale revolves around obtaining corresponding spatial and channel-wise correction matrices for various inputs within distinct feature spaces, which assists in assigning optimal attention. This is achieved by predicting dynamic weights for each input image and combining these weights with multiple learnable basis matrices to construct the correction matrices. The proposed MetaISP makes it possible to obtain best performance while being computationally efficient. SOTA results are achieved on two large-scale datasets, e.g. 23.80dB PSNR on ZRR, exceeding the previous SOTA 0.19dB with only 9.2% of its parameter count and 10.6% of its FLOPs; 25.06dB PSNR on MAI21, exceeding the previous SOTA 0.17dB with only 0.9% of its parameter count and 2.7% of its FLOPs. Keywords: Computer Vision: CV: Computational photography Computer Vision: CV: Applications},
  archive   = {C_IJCAI},
  author    = {Zigeng Chen and Chaowei Liu and Yuan Yuan and Michael Bi Mi and Xinchao Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/76},
  month     = {8},
  pages     = {686-694},
  title     = {MetaISP: Efficient RAW-to-sRGB mappings with merely 1M parameters},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). EVE: Efficient zero-shot text-based video editing with depth
map guidance and temporal consistency constraints. <em>IJCAI</em>,
677–685. (<a href="https://doi.org/10.24963/ijcai.2024/75">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Motivated by the superior performance of image diffusion models, more and more researchers strive to extend these models to the text-based video editing task. Nevertheless, current video editing tasks mainly suffer from the dilemma between the high fine-tuning cost and the limited generation capacity. Compared with images, we conjecture that videos necessitate more constraints to preserve the temporal consistency during editing. Towards this end, we propose EVE, a robust and Efficient zero-shot Video Editing method. Under the guidance of depth maps and temporal consistency constraints, EVE derives satisfactory video editing results with an affordable computational and time cost. Moreover, recognizing the absence of a publicly available video editing dataset for fair comparisons, we construct a new benchmark named ZVE-50 dataset. Through comprehensive experimentation, we validate that EVE achieves a satisfactory trade-off between performance and efficiency. Codebase, datasets, and video editing demos are available at https://github.com/alipay/Ant-Multi-Modal-Framework/blob/main/prj/EVE. Keywords: Computer Vision: CV: Image and video synthesis and generation Computer Vision: CV: Applications},
  archive   = {C_IJCAI},
  author    = {Yutao Chen and Xingning Dong and Tian Gan and Chunluan Zhou and Ming Yang and Qingpei Guo},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/75},
  month     = {8},
  pages     = {677-685},
  title     = {EVE: Efficient zero-shot text-based video editing with depth map guidance and temporal consistency constraints},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). D3ETR: Decoder distillation for detection transformer.
<em>IJCAI</em>, 668–676. (<a
href="https://doi.org/10.24963/ijcai.2024/74">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Although various knowledge distillation (KD) methods for CNN-based detectors have been proven effective in improving small students, build- ing baselines and recipes for DETR-based detec- tors remains a challenge. This paper concentrates on the transformer decoder of DETR-based detec- tors and explores KD methods suitable for them. However, the random order of the decoder outputs poses a challenge for knowledge distillation as it provides no direct correspondence between the pre- dictions of the teacher and the student. To this end, we propose MixMatcher that aligns the de- coder outputs of DETR-based teacher and student, by mixing two teacher-student matching strategies for combined advantages. The first strategy, Adap- tive Matching, applies bipartite matching to adap- tively match the outputs of the teacher and the stu- dent in each decoder layer. The second strategy, Fixed Matching, fixes the correspondence between the outputs of the teacher and the student with the same object queries as input, which alleviates in- stability of bipartite matching in Adaptive Match- ing. Using both strategies together produces bet- ter results than using either strategy alone. Based on MixMatcher, we devise Decoder Distillation for DEtection TRansformer (D3ETR), which dis- tills knowledge in decoder predictions and attention maps from the teacher to student. D3ETR shows superior performance on various DETR-based de- tectors with different backbones. For instance, D3ETR improves Conditional DETR-R50-C5 by 8.3 mAP under 12 epochs training setting with Conditional DETR-R101-C5 serving as the teacher. The code will be released. Keywords: Computer Vision: CV: Applications Computer Vision: CV: Recognition (object detection, categorization)},
  archive   = {C_IJCAI},
  author    = {Xiaokang Chen and Jiahui Chen and Yan Liu and Jiaxiang Tang and Gang Zeng},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/74},
  month     = {8},
  pages     = {668-676},
  title     = {D3ETR: Decoder distillation for detection transformer},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). A transformer-based adaptive prototype matching network for
few-shot semantic segmentation. <em>IJCAI</em>, 659–667. (<a
href="https://doi.org/10.24963/ijcai.2024/73">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Few-shot semantic segmentation (FSS) aims to generate a model for segmenting novel classes using a limited number of annotated samples. Previous FSS methods have shown sensitivity to background noise due to inherent bias, attention bias, and spatial-aware bias. In this study, we propose a Transformer-Based Adaptive Prototype Matching Network to establish robust matching relationships by improving the semantic and spatial perception of query features. The model includes three modules: target enhancement module (TEM), dual constraint aggregation module (DCAM), and dual classification module (DCM). In particular, TEM mitigates inherent bias by exploring the relevance of multi-scale local context to enhance foreground features. Then, DCAM addresses attention bias through the dual semantic-aware attention mechanism to strengthen constraints. Finally, the DCM module decouples the segmentation task into semantic alignment and spatial alignment to alleviate spatial-aware bias. Extensive experiments on PASCAL-5i and COCO-20i confirm the effectiveness of our approach. Keywords: Computer Vision: CV: Segmentation Computer Vision: CV: Representation learning Computer Vision: CV: Scene analysis and understanding Computer Vision: CV: Transfer, low-shot, semi- and un- supervised learning},
  archive   = {C_IJCAI},
  author    = {Sihan Chen and Yadang Chen and Yuhui Zheng and Zhi-Xin Yang and Enhua Wu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/73},
  month     = {8},
  pages     = {659-667},
  title     = {A transformer-based adaptive prototype matching network for few-shot semantic segmentation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bridging LiDAR gaps: A multi-LiDARs domain adaptation
dataset for 3D semantic segmentation. <em>IJCAI</em>, 650–658. (<a
href="https://doi.org/10.24963/ijcai.2024/72">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We focus on the domain adaptation problem for 3D semantic segmentation, addressing the challenge of data variability in point clouds collected by different LiDARs. Existing benchmarks often mix different types of datasets, which blurs and complicates segmentation evaluations. Here, we introduce a Multi-LiDARs Domain Adaptation Segmentation (MLDAS) dataset, which contains point-wise semantic annotated point clouds captured simultaneously by a 128-beam LiDAR, a 64-beam LiDAR, a 32-beam LiDAR. We select 31,875 scans from 2 representative scenarios: campus and urban street. Furthermore, we evaluate the current 3D segmentation unsupervised domain adaptation methods on the proposed dataset and propose Hierarchical Segmentation Network with Spatial Consistency (HSSC) as a novel knowledge transfer method to mitigate the domain gap significantly using spatial-temporal consistency constraints. Extensive experiments show that HSSC greatly improves the state-of-the-art cross-domain semantic segmentation methods. Our project is available at https://sychen320.github.io/projects/MLDAS. Keywords: Computer Vision: CV: 3D computer vision},
  archive   = {C_IJCAI},
  author    = {Shaoyang Chen and Bochun Yang and Yan Xia and Ming Cheng and Siqi Shen and Cheng Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/72},
  month     = {8},
  pages     = {650-658},
  title     = {Bridging LiDAR gaps: A multi-LiDARs domain adaptation dataset for 3D semantic segmentation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cross-domain few-shot semantic segmentation via doubly
matching transformation. <em>IJCAI</em>, 641–649. (<a
href="https://doi.org/10.24963/ijcai.2024/71">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Cross-Domain Few-shot Semantic Segmentation (CD-FSS) aims to train generalized models that can segment classes from different domains with a few labeled images. Previous works have proven the effectiveness of feature transformation in addressing CD-FSS. However, they completely rely on support images for feature transformation, and repeatedly utilizing a few support images for each class may easily lead to overfitting and overlooking intra-class appearance differences. In this paper, we propose a Doubly Matching Transformation-based Network (DMTNet) to solve the above issue. Instead of completely relying on support images, we propose Self-Matching Transformation (SMT) to construct query-specific transformation matrices based on query images themselves to transform domain-specific query features into domain-agnostic ones. Calculating query-specific transformation matrices can prevent overfitting, especially for the meta-testing stage where only one or several images are used as support images to segment hundreds or thousands of images. After obtaining domain-agnostic features, we exploit a Dual Hypercorrelation Construction (DHC) module to explore the hypercorrelations between the query image with the foreground and background of the support image, based on which foreground and background prediction maps are generated and supervised, respectively, to enhance the segmentation result. In addition, we propose a Test-time Self-Finetuning (TSF) strategy to more accurately self-tune the query prediction in unseen domains. Extensive experiments on four popular datasets show that DMTNet achieves superior performance over state-of-the-art approaches. Code is available at https://github.com/ChenJiayi68/DMTNet. Keywords: Computer Vision: CV: Segmentation Computer Vision: CV: Transfer, low-shot, semi- and un- supervised learning},
  archive   = {C_IJCAI},
  author    = {Jiayi Chen and Rong Quan and Jie Qin},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/71},
  month     = {8},
  pages     = {641-649},
  title     = {Cross-domain few-shot semantic segmentation via doubly matching transformation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evolutionary generalized zero-shot learning. <em>IJCAI</em>,
632–640. (<a href="https://doi.org/10.24963/ijcai.2024/70">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Attribute-based Zero-Shot Learning (ZSL) has revolutionized the ability of models to recognize new classes not seen during training. However, with the advancement of large-scale models, the expectations have risen. Beyond merely achieving zero-shot generalization, there is a growing demand for universal models that can continually evolve in expert domains using unlabeled data. To address this, we introduce a scaled-down instantiation of this challenge: Evolutionary Generalized Zero-Shot Learning (EGZSL). This setting allows a low-performing zero-shot model to adapt to the test data stream and evolve online. We elaborate on three challenges of this special task, \ie, catastrophic forgetting, initial prediction bias, and evolutionary data class bias. Moreover, we propose targeted solutions for each challenge, resulting in a generic method capable of continuous evolution from a given initial IGZSL model. Experiments on three popular GZSL benchmark datasets demonstrate that our model can learn from the test data stream while other baselines fail. The codes are available at https://github.com/cdb342/EGZSL. Keywords: Computer Vision: CV: Transfer, low-shot, semi- and un- supervised learning Computer Vision: CV: Vision, language and reasoning},
  archive   = {C_IJCAI},
  author    = {Dubing Chen and Chenyi Jiang and Haofeng Zhang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/70},
  month     = {8},
  pages     = {632-640},
  title     = {Evolutionary generalized zero-shot learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing cross-modal retrieval via visual-textual prompt
hashing. <em>IJCAI</em>, 623–631. (<a
href="https://doi.org/10.24963/ijcai.2024/69">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Cross-modal hashing has garnered considerable research interest due to its rapid retrieval and low storage costs. However, the majority of existing methods suffer from the limitations of context loss and information redundancy, particularly in simulated textual environments enriched with manually annotated tags or virtual descriptions. To mitigate these issues, we propose a novel Visual-Textual Prompt Hashing (VTPH) that aims to bridge the gap between simulated textual and visual modalities within a unified prompt optimization paradigm for cross-modal retrieval. By seamlessly integrating robust reasoning capabilities inherent in large-scale models, we design the visual and textual alignment prompt mechanisms to collaboratively enhance the contextual awareness and semantic capabilities embedded within simulated textual features. Furthermore, an affinity-adaptive contrastive learning strategy is dedicated to dynamically recalibrating the semantic interaction between visual and textual modalities by modeling the nuanced heterogeneity and semantic gaps between simulated and real-world textual environments. To the best of our knowledge, this is the first attempt to integrate both visual and textual prompt learning into cross-modal hashing, facilitating the efficacy of semantic coherence between diverse modalities. Extensive experiments on multiple benchmark datasets consistently demonstrate the superiority and robustness of our VTPH method over state-of-the-art competitors. Keywords: Computer Vision: CV: Image and video retrieval Computer Vision: CV: Multimodal learning Computer Vision: CV: Scene analysis and understanding Computer Vision: CV: Vision, language and reasoning},
  archive   = {C_IJCAI},
  author    = {Bingzhi Chen and Zhongqi Wu and Yishu Liu and Biqing Zeng and Guangming Lu and Zheng Zhang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/69},
  month     = {8},
  pages     = {623-631},
  title     = {Enhancing cross-modal retrieval via visual-textual prompt hashing},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CoAtFormer: Vision transformer with composite attention.
<em>IJCAI</em>, 614–622. (<a
href="https://doi.org/10.24963/ijcai.2024/68">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Transformer has recently gained significant attention and achieved state-of-the-art performance in various computer vision applications, including image classification, instance segmentation, and object detection. However, the self-attention mechanism underlying the transformer leads to quadratic computational cost with respect to image size,limiting its widespread adoption in state-of-the-art vision backbones. In this paper we introduce an efficient and effective attention module we call Composite Attention. It features parallel branches, enabling the modeling of various global dependencies. In each composite attention module, one branch employs a dynamic channel attention module to capture global channel dependencies, while the other branch utilizes an efficient spatial attention module to extract long-range spatial interactions. In addition, we effectively blending composite attention module with convolutions, and accordingly develop a simple hierarchical vision backbone, dubbed CoAtFormer, by simply repeating the basic building block over multiple stages. Extensive experiments show our CoAtFormer achieves state-of-the-art results on various different tasks. Without any pre-training and extra data, CoAtFormer-Tiny, CoAtFormer-Small, and CoAtFormer-Base achieve 84.4%, 85.3%, and 85.9% top-1 accuracy on ImageNet-1K with 24M, 37M, and 73M parameters, respectively. Furthermore, CoAtFormer also consistently outperform prior work in other vision tasks such as object detection, instance segmentation, and semantic segmentation. When further pretraining on the larger dataset ImageNet-22k, we achieve 88.7% Top-1 accuracy on ImageNet-1K Keywords: Computer Vision: CV: Representation learning Machine Learning: ML: Deep learning architectures},
  archive   = {C_IJCAI},
  author    = {Zhiyong Chang and Mingjun Yin and Yan Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/68},
  month     = {8},
  pages     = {614-622},
  title     = {CoAtFormer: Vision transformer with composite attention},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MLP-DINO: Category modeling and query graphing with deep MLP
for object detection. <em>IJCAI</em>, 605–613. (<a
href="https://doi.org/10.24963/ijcai.2024/67">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Popular transformer-based detectors detect objects in a one-to-one manner, where both the bounding box and category of each object are predicted only by the single query, leading to the box-sensitive category predictions. Additionally, the initialization of positional queries solely based on the predicted confidence scores or learnable embeddings neglects the significant spatial interrelation between different queries. This oversight leads to an imbalanced spatial distribution of queries (SDQ). In this paper, we propose a new MLP-DINO model to address these issues. Firstly, we present a new Query-Independent Category Supervision (QICS) approach for modeling categories information, decoupling the sensitive bounding box prediction process to improve the detection performance. Additionally, to further improve the category predictions, we introduce a deep MLP model into transformer-based detection framework to capture the long-range and short-range information simultaneously. Thirdly, to balance the SDQ, we design a novel Graph-based Query Selection (GQS) method that distributes each query point in a discrete manner by graphing the spatial information of queries to cover a broader range of potential objects, significantly enhancing the hit-rate of queries. Experimental results on COCO indicate that our MLP-DINO achieves 54.6% AP with only 44M parame    ters under 36-epoch setting, greatly outperforming the original DINO by +3.7% AP with fewer parameters and FLOPs. The source codes will be available at https://github.com/Med-Process/MLP-DINO. Keywords: Computer Vision: CV: Recognition (object detection, categorization) Computer Vision: CV: Scene analysis and understanding Machine Learning: ML: Multi-label learning},
  archive   = {C_IJCAI},
  author    = {Guiping Cao and Wenjian Huang and Xiangyuan Lan and Jianguo Zhang and Dongmei Jiang and Yaowei Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/67},
  month     = {8},
  pages     = {605-613},
  title     = {MLP-DINO: Category modeling and query graphing with deep MLP for object detection},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SGDCL: Semantic-guided dynamic correlation learning for
explainable autonomous driving. <em>IJCAI</em>, 596–604. (<a
href="https://doi.org/10.24963/ijcai.2024/66">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {By learning expressive representations, deep learning (DL) has revolutionized autonomous driving (AD). Despite significant advancements, the inherent opacity of DL models engenders public distrust, impeding their widespread adoption. For explainable autonomous driving, current studies primarily concentrate on extracting features from input scenes to predict driving actions and their corresponding explanations. However, these methods underutilize semantics and correlation information within actions and explanations (collectively called categories in this work), leading to suboptimal performance. To address this issue, we propose Semantic-Guided Dynamic Correlation Learning (SGDCL), a novel approach that effectively exploits semantic richness and dynamic interactions intrinsic to categories. SGDCL employs a semantic-guided learning module to obtain category-specific representations and a dynamic correlation learning module to adaptively capture intricate correlations among categories. Additionally, we introduce an innovative loss term to leverage fine-grained co-occurrence statistics of categories for refined regularization. We extensively evaluate SGDCL on two well-established benchmarks, demonstrating its superiority over seven state-of-the-art baselines and a large vision-language model. SGDCL significantly promotes explainable autonomous driving with up to 15.3% performance improvement and interpretable attention scores, bolstering public trust in AD. Keywords: Computer Vision: CV: Interpretability and transparency Machine Learning: ML: Explainable/Interpretable machine learning Machine Learning: ML: Classification Computer Vision: CV: Machine learning for vision},
  archive   = {C_IJCAI},
  author    = {Chengtai Cao and Xinhong Chen and Jianping Wang and Qun Song and Rui Tan and Yung-Hui Li},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/66},
  month     = {8},
  pages     = {596-604},
  title     = {SGDCL: Semantic-guided dynamic correlation learning for explainable autonomous driving},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Attention shifting to pursue optimal representation for
adapting multi-granularity tasks. <em>IJCAI</em>, 587–595. (<a
href="https://doi.org/10.24963/ijcai.2024/65">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Object recognition in open environments, e.g., video surveillance, poses significant challenges due to the inclusion of unknown and multi-granularity tasks (MGT). However, recent methods exhibit limitations as they struggle to capture subtle differences between different parts within an object and adaptively handle MGT. To address this limitation, this paper proposes a Class-semantic Guided Attention Shift (SegAS) method. SegAS transforms adaptive MGT into dynamic combinations of invariant discriminant representations across different levels to effectively enhance adaptability to multi-granularity downstream tasks. Specifically, SegAS incorporates a hardness-based Attention Part Filtering Strategy (ApFS) to dynamically decompose objects into complementary parts based on the object structure and relevance to the instance. Then, SegAS shifts attention to the optimal discriminant region of each part under the guidance of hierarchical class semantics. Finally, a diversity loss is employed to emphasize the importance and distinction of different partial features. Extensive experiments validate SegAS&#39; effectiveness in multi-granularity recognition of three tasks. Keywords: Computer Vision: CV: Representation learning Computer Vision: CV: Recognition (object detection, categorization)},
  archive   = {C_IJCAI},
  author    = {Gairui Bai and Wei Xi and Yihan Zhao and Xinhui Liu and Jizhong Zhao},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/65},
  month     = {8},
  pages     = {587-595},
  title     = {Attention shifting to pursue optimal representation for adapting multi-granularity tasks},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bring metric functions into diffusion models.
<em>IJCAI</em>, 578–586. (<a
href="https://doi.org/10.24963/ijcai.2024/64">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We introduce a Cascaded Diffusion Model (Cas-DM) that improves a Denoising Diffusion Probabilistic Model (DDPM) by effectively incorporating additional metric functions in training. Metric functions such as the LPIPS loss have been proven highly effective in consistency models derived from the score matching. However, for the diffusion counterparts, the methodology and efficacy of adding extra metric functions remain unclear. One major challenge is the mismatch between the noise predicted by a DDPM at each step and the desired clean image that the metric function works well on. To address this problem, we propose Cas-DM, a network architecture that cascades two network modules to effectively apply metric functions to the diffusion model training. The first module, similar to a standard DDPM, learns to predict the added noise and is unaffected by the metric function. The second cascaded module learns to predict the clean image, thereby facilitating the metric function computation. Experiment results show that the proposed diffusion model backbone enables the effective use of the LPIPS loss, improving the image quality (FID, sFID) of diffusion models on various established benchmarks. Keywords: Computer Vision: CV: Image and video synthesis and generation},
  archive   = {C_IJCAI},
  author    = {Jie An and Zhengyuan Yang and Jianfeng Wang and Linjie Li and Zicheng Liu and Lijuan Wang and Jiebo Luo},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/64},
  month     = {8},
  pages     = {578-586},
  title     = {Bring metric functions into diffusion models},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A general black-box adversarial attack on graph-based fake
news detectors. <em>IJCAI</em>, 568–576. (<a
href="https://doi.org/10.24963/ijcai.2024/63">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph Neural Network (GNN)-based fake news detectors apply various methods to construct graphs, aiming to learn distinctive news embeddings for classification. Since the construction details are unknown for attackers in a black-box scenario, it is unrealistic to conduct the classical adversarial attacks that require a specific adjacency matrix. In this paper, we propose the first general black-box adversarial attack framework, i.e., General Attack via Fake Social Interaction (GAFSI), against detectors based on different graph structures. Specifically, as sharing is an important social interaction for GNN-based fake news detectors to construct the graph, we simulate sharing behaviors to fool the detectors. Firstly, we propose a fraudster selection module to select engaged users leveraging local and global information. In addition, a post injection module guides the selected users to create shared relations by sending posts. The sharing records will be added to the social context, leading to a general attack against different detectors. Experimental results on empirical datasets demonstrate the effectiveness of GAFSI. Keywords: AI Ethics, Trust, Fairness: ETF: Safety and robustness Data Mining: DM: Mining graphs Machine Learning: ML: Robustness Machine Learning: ML: Sequence and graph learning},
  archive   = {C_IJCAI},
  author    = {Peican Zhu and Zechen Pan and Yang Liu and Jiwei Tian and Keke Tang and Zhen Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/63},
  month     = {8},
  pages     = {568-576},
  title     = {A general black-box adversarial attack on graph-based fake news detectors},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). PRASS: Probabilistic risk-averse robust learning with
stochastic search. <em>IJCAI</em>, 559–567. (<a
href="https://doi.org/10.24963/ijcai.2024/62">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep learning models, despite their remarkable success in various tasks, have been shown to be vulnerable to adversarial perturbations. Although robust learning techniques that consider adversarial risks against worst-case perturbations can effectively increase a model&#39;s robustness, they may not always be the most suitable approach. This is due to the fact that in certain scenarios, perturbations are more likely to occur probabilistically rather than being intentionally crafted by attackers. To address this challenge, we propose a novel risk-averse robust learning method based on entropic value-at-risk, called PRASS (Probabilistical Risk-Averse Robust Learning with Stochastic Search). Our approach leverages principles of stochastic optimisation and considers perturbing distributions rather than solely worst-case adversaries. By applying adaptive stochastic search to parameterised distributions, we further enhance the scalability of PRASS to handle distributional robustness. Empirical experiments demonstrate that PRASS outperforms existing state-of-the-art baselines. Keywords: AI Ethics, Trust, Fairness: ETF: Trustworthy AI AI Ethics, Trust, Fairness: ETF: Safety and robustness Machine Learning: ML: Adversarial machine learning Machine Learning: ML: Robustness},
  archive   = {C_IJCAI},
  author    = {Tianle Zhang and Yanghao Zhang and Ronghui Mu and Jiaxu Liu and Jonathan Fieldsend and Wenjie Ruan},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/62},
  month     = {8},
  pages     = {559-567},
  title     = {PRASS: Probabilistic risk-averse robust learning with stochastic search},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). BADFSS: Backdoor attacks on federated self-supervised
learning. <em>IJCAI</em>, 548–558. (<a
href="https://doi.org/10.24963/ijcai.2024/61">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Self-supervised learning (SSL) is capable of learning remarkable representations from centrally available data. Recent works further implement federated learning with SSL to learn from rapidly growing decentralized unlabeled images (e.g., from cameras and phones), often resulting from privacy constraints. Extensive attention has been paid to designing new frameworks or methods that achieve better performance for the SSL-based FL. However, such an effort has not yet taken the security of SSL-based FL into consideration. We aim to explore backdoor attacks in the context of SSL-based FL via an in-depth empirical study. In this paper, we propose a novel backdoor attack BADFSS against SSL-based FL. First, BADFSS learns a backdoored encoder via supervised contrastive learning on poison datasets constructed based on local datasets. Then, BADFSS employs attention alignment to enhance the backdoor effect and maintain the consistency between backdoored and global encoders. Moreover, we perform empirical evaluations of the proposed backdoor attacks on four datasets and compared BADFSS with three existing backdoor attacks that are transferred into federated self-supervised learning. The experiments demonstrate that BADFSS outperforms baseline methods and is effective under various settings. Keywords: AI Ethics, Trust, Fairness: ETF: Trustworthy AI AI Ethics, Trust, Fairness: ETF: Safety and robustness Multidisciplinary Topics and Applications: MTA: Security and privacy},
  archive   = {C_IJCAI},
  author    = {Jiale Zhang and Chengcheng Zhu and Di Wu and Xiaobing Sun and Jianming Yong and Guodong Long},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/61},
  month     = {8},
  pages     = {548-558},
  title     = {BADFSS: Backdoor attacks on federated self-supervised learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CMACE: CMAES-based counterfactual explanations for black-box
models. <em>IJCAI</em>, 539–547. (<a
href="https://doi.org/10.24963/ijcai.2024/60">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Explanatory Artificial Intelligence plays a vital role in machine learning, due to its widespread application in decision-making scenarios, e.g., credit lending. Counterfactual Explanation (CFE) is a new kind of explanatory method that involves asking “what if ”, i.e. what would have happened if model inputs slightly change. To answer the question, Counterfactual Explanation aims at finding a minimum perturbation in model inputs leading to a different model decision. Compared with model-agnostic approaches, model-specific CFE approaches designed only for specific type of models usually have better performance in finding optimal counterfactual perturbations, owing to access to the inner workings of models. To deal with this dilemma, this work first proposes CMAES-based Counterfactual Explanations (CMACE): an effective model-agnostic counterfactual generating approach based on Covariance Matrix Adaptation Evolution Strategy (CMA-ES) and a warm starting scheme that provides good initialization of the counterfactual&#39;s mean and covariance parameters for CMA-ES taking advantage of prior information of training samples. CMACE significantly outperforms another state-of-art (SOTA) model-agnostic approach (Bayesian Counterfactual Generator, BayCon) with various experimental settings. Extensive experiments also demonstrate that CMACE is superior to a SOTA model-specific approach (Flexible Optimizable Counterfactual Explanations for Tree Ensembles, FOCUS) that is designed for tree-based models using gradient-based optimization. Keywords: AI Ethics, Trust, Fairness: ETF: Explainability and interpretability AI Ethics, Trust, Fairness: ETF: Trustworthy AI Machine Learning: ML: Optimization Machine Learning: ML: Trustworthy machine learning},
  archive   = {C_IJCAI},
  author    = {Xudong Yin and Yao Yang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/60},
  month     = {8},
  pages     = {539-547},
  title     = {CMACE: CMAES-based counterfactual explanations for black-box models},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Attribution quality metrics with magnitude alignment.
<em>IJCAI</em>, 530–538. (<a
href="https://doi.org/10.24963/ijcai.2024/59">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Attribution algorithms play an instrumental role in human interpretation of AI models. The methods measure the importance of the input features to the model output decision, which can be displayed as an attribution map for image classifiers. Perturbation tests are the state-of-the-art approach to evaluate the quality of an attribution map. Unfortunately, we observe that perturbation tests fail to consider attribution magnitude, which translates into inconsistent quality scores. In this paper, we propose Magnitude Aligned Scoring (MAS), a new attribution quality metric that measures the alignment between the magnitude of the attributions and the model response. In particular, the metric accounts for both the relative ordering and the magnitude of the pixels within an attribution. In the experimental evaluation, we compare the MAS metric with existing metrics across a wide range of models, datasets, attributions, and evaluations. The results demonstrate that the MAS metric is 4x more sensitive to attribution changes, 2x more consistent, and 1.6x more invariant to baseline modifications. Our code and the referenced appendix are publicly available via https://github.com/chasewalker26/Magnitude-Aligned-Scoring. Keywords: AI Ethics, Trust, Fairness: ETF: Explainability and interpretability AI Ethics, Trust, Fairness: ETF: Trustworthy AI Computer Vision: CV: Interpretability and transparency Machine Learning: ML: Explainable/Interpretable machine learning},
  archive   = {C_IJCAI},
  author    = {Chase Walker and Dominic Simon and Kenny Chen and Rickard Ewetz},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/59},
  month     = {8},
  pages     = {530-538},
  title     = {Attribution quality metrics with magnitude alignment},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the effects of fairness to adversarial vulnerability.
<em>IJCAI</em>, 521–529. (<a
href="https://doi.org/10.24963/ijcai.2024/58">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Fairness and robustness are two important notions of learning models. Fairness ensures that models do not disproportionately harm (or benefit) some groups over others, while robustness measures the models&#39; resilience against small input perturbations. While equally important properties, this paper illustrates a dichotomy between fairness and robustness, and analyzes when striving for fairness decreases the model robustness to adversarial samples. The reported analysis sheds light on the factors causing such contrasting behavior, suggesting that distance to the decision boundary across groups as a key factor. Experiments on non-linear models and different architectures validate the theoretical findings. In addition to the theoretical analysis, the paper also proposes a simple, yet effective, solution to construct models achieving good tradeoffs between fairness and robustness. Keywords: AI Ethics, Trust, Fairness: ETF: Fairness and diversity AI Ethics, Trust, Fairness: ETF: Safety and robustness AI Ethics, Trust, Fairness: ETF: Trustworthy AI Constraint Satisfaction and Optimization: CSO: Constraint optimization problems},
  archive   = {C_IJCAI},
  author    = {Cuong Tran and Keyu Zhu and Pascal Van Hentenryck and Ferdinando Fioretto},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/58},
  month     = {8},
  pages     = {521-529},
  title     = {On the effects of fairness to adversarial vulnerability},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). When fairness meets privacy: Exploring privacy threats in
fair binary classifiers via membership inference attacks.
<em>IJCAI</em>, 512–520. (<a
href="https://doi.org/10.24963/ijcai.2024/57">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {While in-processing fairness approaches show promise in mitigating bias predictions, their potential impact on privacy leakage remains under-explored. We aim to address this gap by assessing the privacy risks of fairness-enhanced binary classifiers with membership inference attacks (MIAs). Surprisingly, our results reveal that these fairness interventions exhibit increased resilience against existing attacks, indicating that enhancing fairness does not necessarily lead to privacy compromises. However, we find current attack methods are ineffective as they typically degrade into simple threshold models with limited attack effectiveness. Following this observation, we discover a novel threat dubbed Fairness Discrepancy Membership Inference Attacks (FD-MIA) that exploits prediction discrepancies between fair and biased models. This attack reveals more potent vulnerabilities and poses significant privacy risks to model privacy. Extensive experiments across multiple datasets, attack methods, and representative fairness approaches confirm our findings and demonstrate the efficacy of the proposed attack method. Our study exposes the overlooked privacy threats in fairness studies, advocating for thorough evaluations of potential security vulnerabilities before model deployments. Keywords: AI Ethics, Trust, Fairness: ETF: Trustworthy AI AI Ethics, Trust, Fairness: ETF: Fairness and diversity AI Ethics, Trust, Fairness: ETF: Safety and robustness},
  archive   = {C_IJCAI},
  author    = {Huan Tian and Guangsheng Zhang and Bo Liu and Tianqing Zhu and Ming Ding and Wanlei Zhou},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/57},
  month     = {8},
  pages     = {512-520},
  title     = {When fairness meets privacy: Exploring privacy threats in fair binary classifiers via membership inference attacks},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A self-explaining neural architecture for generalizable
concept learning. <em>IJCAI</em>, 503–511. (<a
href="https://doi.org/10.24963/ijcai.2024/56">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With the wide proliferation of Deep Neural Networks in high-stake applications, there is a growing demand for explainability behind their decision-making process. Concept learning models attempt to learn high-level &#39;concepts&#39; - abstract entities that align with human understanding, and thus provide interpretability to DNN architectures. However, in this paper, we demonstrate that present SOTA concept learning approaches suffer from two major problems - lack of concept fidelity wherein the models fail to learn consistent concepts among similar classes and limited concept interoperability wherein the models fail to generalize learned concepts to new domains for the same task. Keeping these in mind, we propose a novel self-explaining architecture for concept learning across domains which - i) incorporates a new concept saliency network for representative concept selection, ii) utilizes contrastive learning to capture representative domain invariant concepts, and iii) uses a novel prototype-based concept grounding regularization to improve concept alignment across domains. We demonstrate the efficacy of our proposed approach over current SOTA concept learning approaches on four widely used real-world datasets. Empirical results show that our method improves both concept fidelity measured through concept overlap and concept interoperability measured through domain adaptation performance. An appendix of the paper with more comprehensive results can also be viewed at https://arxiv.org/abs/2405.00349. Keywords: AI Ethics, Trust, Fairness: ETF: Explainability and interpretability AI Ethics, Trust, Fairness: ETF: Trustworthy AI Computer Vision: CV: Transfer, low-shot, semi- and un- supervised learning Machine Learning: ML: Explainable/Interpretable machine learning},
  archive   = {C_IJCAI},
  author    = {Sanchit Sinha and Guangzhi Xiong and Aidong Zhang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/56},
  month     = {8},
  pages     = {503-511},
  title     = {A self-explaining neural architecture for generalizable concept learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Ten words only still help: Improving black-box AI-generated
text detection via proxy-guided efficient re-sampling. <em>IJCAI</em>,
494–502. (<a href="https://doi.org/10.24963/ijcai.2024/55">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With the rapidly increasing application of large language models (LLMs), their abuse has caused many undesirable societal problems such as fake news, academic dishonesty, and information pollution. This makes AI-generated text (AIGT) detection of great importance. Among existing methods, white-box methods are generally superior to black-box methods in terms of performance and generalizability, but they require access to LLMs&#39; internal states and are not applicable to black-box settings. In this paper, we propose to estimate word generation probabilities as pseudo white-box features via multiple re-sampling to help improve AIGT detection under the black-box setting. Specifically, we design POGER, a proxy-guided efficient re-sampling method, which selects a small subset of representative words (e.g., 10 words) for performing multiple re-sampling in black-box AIGT detection. Experiments on datasets containing texts from humans and seven LLMs show that POGER outperforms all baselines in macro F1 under black-box, partial white-box, and out-of-distribution settings and maintains lower re-sampling costs than its existing counterparts. Keywords: AI Ethics, Trust, Fairness: ETF: Trustworthy AI Natural Language Processing: NLP: Applications},
  archive   = {C_IJCAI},
  author    = {Yuhui Shi and Qiang Sheng and Juan Cao and Hao Mi and Beizhe Hu and Danding Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/55},
  month     = {8},
  pages     = {494-502},
  title     = {Ten words only still help: Improving black-box AI-generated text detection via proxy-guided efficient re-sampling},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). By fair means or foul: Quantifying collusion in a market
simulation with deep reinforcement learning. <em>IJCAI</em>, 485–493.
(<a href="https://doi.org/10.24963/ijcai.2024/54">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the rapidly evolving landscape of eCommerce, Artificial Intelligence (AI) based pricing algorithms, particularly those utilizing Reinforcement Learning (RL), are becoming increasingly prevalent. This rise has led to an inextricable pricing situation with the potential for market collusion. Our research employs an experimental oligopoly model of repeated price competition, systematically varying the environment to cover scenarios from basic economic theory to subjective consumer demand preferences. We also introduce a novel demand framework that enables the implementation of various demand models, allowing for a weighted blending of different models. In contrast to existing research in this domain, we aim to investigate the strategies and emerging pricing patterns developed by the agents, which may lead to a collusive outcome. Furthermore, we investigate a scenario where agents cannot observe their competitors’ prices. Finally, we provide a comprehensive legal analysis across all scenarios. Our findings indicate that RL-based AI agents converge to a collusive state characterized by the charging of supracompetitive prices, without necessarily requiring inter-agent communication. Implementing alternative RL algorithms, altering the number of agents or simulation settings, and restricting the scope of the agents’ observation space does not significantly impact the collusive market outcome behavior. Keywords: AI Ethics, Trust, Fairness: ETF: AI and law, governance, regulation Agent-based and Multi-agent Systems: MAS: Agent-based simulation and emergence Machine Learning: ML: Reinforcement learning Multidisciplinary Topics and Applications: MTA: Economics},
  archive   = {C_IJCAI},
  author    = {Michael Schlechtinger and Damaris Kosack and Franz Krause and Heiko Paulheim},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/54},
  month     = {8},
  pages     = {485-493},
  title     = {By fair means or foul: Quantifying collusion in a market simulation with deep reinforcement learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Normative testimony and belief functions: A formal theory of
norm learning. <em>IJCAI</em>, 476–484. (<a
href="https://doi.org/10.24963/ijcai.2024/53">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The ability to learn another’s moral beliefs is necessary for all social agents. It allows us to predict their behavior and is a prerequisite to correcting their beliefs if they are incorrect. To make AI systems more socially competent, a formal theory for learning internal normative beliefs is thus needed. However, to the best of our knowledge, a philosophically justified formal theory for this process does not yet exist. This paper begins the development of such a theory, focusing on learning from testimony. We make four main contributions. First, we provide a set of axioms that any such theory must satisfy. Second, we provide justification for belief functions, as opposed to traditional probability theory, for modeling norm learning. Third, we construct a novel learning function that satisfies these axioms. Fourth, we provide a complexity analysis of this formalism and proof that deontic rules are sound under its semantics. This paper thus serves as a theoretical contribution towards modeling learning norms from testimony, paving the road towards more social AI systems. Keywords: AI Ethics, Trust, Fairness: ETF: Values Agent-based and Multi-agent Systems: MAS: Normative systems Knowledge Representation and Reasoning: KRR: Learning and reasoning Uncertainty in AI: UAI: Uncertainty representations},
  archive   = {C_IJCAI},
  author    = {Taylor Olson and Kenneth D. Forbus},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/53},
  month     = {8},
  pages     = {476-484},
  title     = {Normative testimony and belief functions: A formal theory of norm learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Relevant irrelevance: Generating alterfactual explanations
for image classifiers. <em>IJCAI</em>, 467–475. (<a
href="https://doi.org/10.24963/ijcai.2024/52">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we demonstrate the feasibility of alterfactual explanations for black box image classifiers. Traditional explanation mechanisms from the field of Counterfactual Thinking are a widely-used paradigm for Explainable Artificial Intelligence (XAI), as they follow a natural way of reasoning that humans are familiar with. However, most common approaches from this field are based on communicating information about features or characteristics that are especially important for an AI&#39;s decision. However, to fully understand a decision, not only knowledge about relevant features is needed, but the awareness of irrelevant information also highly contributes to the creation of a user&#39;s mental model of an AI system. To this end, a novel approach for explaining AI systems called alterfactual explanations was recently proposed on a conceptual level. It is based on showing an alternative reality where irrelevant features of an AI&#39;s input are altered. By doing so, the user directly sees which input data characteristics can change arbitrarily without influencing the AI&#39;s decision. In this paper, we show for the first time that it is possible to apply this idea to black box models based on neural networks. To this end, we present a GAN-based approach to generate these alterfactual explanations for binary image classifiers. Further, we present a user study that gives interesting insights on how alterfactual explanations can complement counterfactual explanations. Keywords: AI Ethics, Trust, Fairness: ETF: Explainability and interpretability AI Ethics, Trust, Fairness: ETF: Bias AI Ethics, Trust, Fairness: ETF: Trustworthy AI Machine Learning: ML: Classification},
  archive   = {C_IJCAI},
  author    = {Silvan Mertes and Tobias Huber and Christina Karle and Katharina Weitz and Ruben Schlagowski and Cristina Conati and Elisabeth André},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/52},
  month     = {8},
  pages     = {467-475},
  title     = {Relevant irrelevance: Generating alterfactual explanations for image classifiers},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). EAB-FL: Exacerbating algorithmic bias through model
poisoning attacks in federated learning. <em>IJCAI</em>, 458–466. (<a
href="https://doi.org/10.24963/ijcai.2024/51">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Federated Learning (FL) is a technique that allows multiple parties to train a shared model collaboratively without disclosing their private data. It has become increasingly popular due to its distinct privacy advantages. However, FL models can suffer from biases against certain demographic groups (e.g., racial and gender groups) due to the heterogeneity of data and party selection. Researchers have proposed various strategies for characterizing the group fairness of FL algorithms to address this issue. However, the effectiveness of these strategies in the face of deliberate adversarial attacks has not been fully explored. Although existing studies have revealed various threats (e.g., model poisoning attacks) against FL systems caused by malicious participants, their primary aim is to decrease model accuracy, while the potential of leveraging poisonous model updates to exacerbate model unfairness remains unexplored. In this paper, we propose a new type of model poisoning attack, EAB-FL, with a focus on exacerbating group unfairness while maintaining a good level of model utility. Extensive experiments on three datasets demonstrate the effectiveness and efficiency of our attack, even with state-of-the-art fairness optimization algorithms and secure aggregation rules employed. We hope this work will help the community fully understand the attack surfaces of current FL systems and facilitate corresponding mitigation to improve their resilience. Keywords: AI Ethics, Trust, Fairness: ETF: Fairness and diversity AI Ethics, Trust, Fairness: ETF: Bias Machine Learning: ML: Adversarial machine learning},
  archive   = {C_IJCAI},
  author    = {Syed Irfan Ali Meerza and Jian Liu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/51},
  month     = {8},
  pages     = {458-466},
  title     = {EAB-FL: Exacerbating algorithmic bias through model poisoning attacks in federated learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FairGT: A fairness-aware graph transformer. <em>IJCAI</em>,
449–457. (<a href="https://doi.org/10.24963/ijcai.2024/50">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The design of Graph Transformers (GTs) often neglects considerations for fairness, resulting in biased outcomes against certain sensitive subgroups. Since GTs encode graph information without relying on message-passing mechanisms, conventional fairness-aware graph learning methods are not directly applicable to address these issues. To tackle this challenge, we propose FairGT, a Fairness-aware Graph Transformer explicitly crafted to mitigate fairness concerns inherent in GTs. FairGT incorporates a meticulous structural feature selection strategy and a multi-hop node feature integration method, ensuring independence of sensitive features and bolstering fairness considerations. These fairness-aware graph information encodings seamlessly integrate into the Transformer framework for downstream tasks. We also prove that the proposed fair structural topology encoding with adjacency matrix eigenvector selection and multi-hop integration are theoretically effective. Empirical evaluations conducted across five real-world datasets demonstrate FairGT&#39;s superiority in fairness metrics over existing graph transformers, graph neural networks, and state-of-the-art fairness-aware graph learning approaches. Keywords: AI Ethics, Trust, Fairness: ETF: Fairness and diversity Data Mining: DM: Mining graphs Machine Learning: ML: Trustworthy machine learning},
  archive   = {C_IJCAI},
  author    = {Renqiang Luo and Huafei Huang and Shuo Yu and Xiuzhen Zhang and Feng Xia},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/50},
  month     = {8},
  pages     = {449-457},
  title     = {FairGT: A fairness-aware graph transformer},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Formalisation and evaluation of properties for
consequentialist machine ethics. <em>IJCAI</em>, 440–448. (<a
href="https://doi.org/10.24963/ijcai.2024/49">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As artificial intelligence (AI) technologies continue to influence our daily lives, there has been a growing need to ensure that AI enabled decision making systems adhere to principles expected of human decision makers. This need has given rise to the area of Machine Ethics. We formalise several ethical principles from the philosophical literature in the situation calculus framework to verify the ethical permissibility of a plan. Moreover, we propose several important properties, including some of our own that are intuitively appealing, and a number derived from the social choice literature that would appear to be relevant in evaluating the various approaches. Finally we provide an assessment of how our various situation calculus models of Machine Ethics that we examine satisfy the important properties we have identified. Keywords: AI Ethics, Trust, Fairness: ETF: Moral decision making Knowledge Representation and Reasoning: KRR: Reasoning about actions Knowledge Representation and Reasoning: KRR: Common-sense reasoning Knowledge Representation and Reasoning: KRR: Other},
  archive   = {C_IJCAI},
  author    = {Raynaldio Limarga and Yang Song and Abhaya Nayak and David Rajaratnam and Maurice Pagnucco},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/49},
  month     = {8},
  pages     = {440-448},
  title     = {Formalisation and evaluation of properties for consequentialist machine ethics},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Protecting object detection models from model extraction
attack via feature space coverage. <em>IJCAI</em>, 431–439. (<a
href="https://doi.org/10.24963/ijcai.2024/48">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The model extraction attack is an attack pattern aimed at stealing well-trained machine learning models&#39; functionality or privacy information. With the gradual popularization of AI-related technologies in daily life, various well-trained models are being deployed. As a result, these models are considered valuable assets and attractive to model extraction attackers. Currently, the academic community primarily focuses on defense for model extraction attacks in the context of classification, with little attention to the more commonly used task scenario of object detection. Therefore, we propose a detection framework targeting model extraction attacks against object detection models in this paper. The framework first locates suspicious users based on feature coverage in query traffic and uses an active verification module to confirm whether the identified suspicious users are attackers. Through experiments conducted in multiple task scenarios, we validate the effectiveness and detection efficiency of the proposed method. Keywords: AI Ethics, Trust, Fairness: ETF: Safety and robustness Computer Vision: CV: Recognition (object detection, categorization)},
  archive   = {C_IJCAI},
  author    = {Zeyu Li and Yuwen Pu and Xuhong Zhang and Yu Li and Jinbao Li and Shouling Ji},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/48},
  month     = {8},
  pages     = {431-439},
  title     = {Protecting object detection models from model extraction attack via feature space coverage},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SwiftThief: Enhancing query efficiency of model stealing by
contrastive learning. <em>IJCAI</em>, 422–430. (<a
href="https://doi.org/10.24963/ijcai.2024/47">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Model-stealing attacks are emerging as a severe threat to AI-based services because an adversary can create models that duplicate the functionality of the black-box AI models inside the services with regular query-based access. To avoid detection or query costs, the model-stealing adversary must consider minimizing the number of queries to obtain an accurate clone model. To achieve this goal, we propose SwiftThief, a novel model-stealing framework that utilizes both queried and unqueried data to reduce query complexity. In particular, SwiftThief uses contrastive learning, a recent technique for representation learning. We formulate a new objective function for model stealing consisting of self-supervised (for abundant unqueried inputs from public datasets) and soft-supervised (for queried inputs) contrastive losses, jointly optimized with an output matching loss (for queried inputs). In addition, we suggest a new sampling strategy to prioritize rarely queried classes to improve attack performance. Our experiments proved that SwiftThief could significantly enhance the efficiency of model-stealing attacks compared to the existing methods, achieving similar attack performance using only half of the query budgets of the competing approaches. Also, SwiftThief showed high competence even when a defense was activated for the victims. Keywords: AI Ethics, Trust, Fairness: ETF: Safety and robustness Multidisciplinary Topics and Applications: MTA: Security and privacy},
  archive   = {C_IJCAI},
  author    = {Jeonghyun Lee and Sungmin Han and Sangkyun Lee},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/47},
  month     = {8},
  pages     = {422-430},
  title     = {SwiftThief: Enhancing query efficiency of model stealing by contrastive learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Speech-forensics: Towards comprehensive synthetic speech
dataset establishment and analysis. <em>IJCAI</em>, 413–421. (<a
href="https://doi.org/10.24963/ijcai.2024/46">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Detecting synthetic from real speech is increasingly crucial due to the risks of misinformation and identity impersonation. While various datasets for synthetic speech analysis have been developed, they often focus on specific areas, limiting their utility for comprehensive research. To fill this gap, we propose the Speech-Forensics dataset by extensively covering authentic, synthetic, and partially forged speech samples that include multiple segments synthesized by different high-quality algorithms. Moreover, we propose a TEmporal Speech LocalizaTion network, called TEST, aiming at simultaneously performing authenticity detection, multiple fake segments localization, and synthesis algorithms recognition, without any complex post-processing. TEST effectively integrates LSTM and Transformer to extract more powerful temporal speech representations and utilizes dense prediction on multi-scale pyramid features to estimate the synthetic spans. Our model achieves an average mAP of 83.55% and an EER of 5.25% at the utterance level. At the segment level, it attains an EER of 1.07% and a 92.19% F1 score. These results highlight the model&#39;s robust capability for a comprehensive analysis of synthetic speech, offering a promising avenue for future research and practical applications in this field. Keywords: AI Ethics, Trust, Fairness: ETF: Safety and robustness Machine Learning: ML: Deep learning architectures Machine Learning: ML: Structured prediction Natural Language Processing: NLP: Speech},
  archive   = {C_IJCAI},
  author    = {Zhoulin Ji and Chenhao Lin and Hang Wang and Chao Shen},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/46},
  month     = {8},
  pages     = {413-421},
  title     = {Speech-forensics: Towards comprehensive synthetic speech dataset establishment and analysis},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Updates on the complexity of SHAP scores. <em>IJCAI</em>,
403–412. (<a href="https://doi.org/10.24963/ijcai.2024/45">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {SHAP scores represent one of the most widely used methods of explainability by feature attribution, as illustrated by the explainable AI tool SHAP. A number of recent works studied the computational complexity of the exact computation of SHAP scores, covering a comprehensive range of families of classifiers. This paper refines some of the existing complexity claims, including families of classifiers for which the computation of SHAP scores is computationally hard and those for which there exist polynomial-time algorithms. Keywords: AI Ethics, Trust, Fairness: ETF: Explainability and interpretability AI Ethics, Trust, Fairness: ETF: Trustworthy AI Knowledge Representation and Reasoning: KRR: Computational complexity of reasoning Machine Learning: ML: Explainable/Interpretable machine learning},
  archive   = {C_IJCAI},
  author    = {Xuanxiang Huang and Joao Marques-Silva},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/45},
  month     = {8},
  pages     = {403-412},
  title     = {Updates on the complexity of SHAP scores},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Online combinatorial optimization with group fairness
constraints. <em>IJCAI</em>, 394–402. (<a
href="https://doi.org/10.24963/ijcai.2024/44">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As digital marketplaces and services continue to expand, it is crucial to maintain a safe and fair environment for all users. This requires implementing fairness constraints into the sequential decision-making processes of these platforms to ensure equal treatment. However, this can be challenging as these processes often need to solve NP-complete problems with exponentially large decision spaces at each time step. To overcome this, we propose a general framework incorporating robustness and fairness into NP-complete problems, such as optimizing product ranking and maximizing sub-modular functions. Our framework casts the problem as a max-min game between a primal player aiming to maximize the platform&#39;s objective and a dual player in charge of group fairness constraints. We show that one can trace the entire Pareto fairness curve by changing the thresholds on the fairness constraints. We provide theoretical guarantees for our method and empirically evaluate it, demonstrating its effectiveness. Keywords: AI Ethics, Trust, Fairness: ETF: Fairness and diversity Constraint Satisfaction and Optimization: CSO: Mixed discrete and continuous optimization Machine Learning: ML: Online learning Machine Learning: ML: Optimization},
  archive   = {C_IJCAI},
  author    = {Negin Golrezaei and Rad Niazadeh and Kumar Kshitij Patel and Fransisca Susan},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/44},
  month     = {8},
  pages     = {394-402},
  title     = {Online combinatorial optimization with group fairness constraints},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Detecting and understanding vulnerabilities in language
models via mechanistic interpretability. <em>IJCAI</em>, 385–393. (<a
href="https://doi.org/10.24963/ijcai.2024/43">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Large Language Models (LLMs), characterized by being trained on broad amounts of data in a self-supervised manner, have shown impressive performance across a wide range of tasks. Indeed, their generative abilities have aroused interest on the application of LLMs across a wide range of contexts. However, neural networks in general, and LLMs in particular, are known to be vulnerable to adversarial attacks, where an imperceptible change to the input can mislead the output of the model. This is a serious concern that impedes the use of LLMs on high-stakes applications, such as healthcare, where a wrong prediction can imply serious consequences. Even though there are many efforts on making LLMs more robust to adversarial attacks, there are almost no works that study how and where these vulnerabilities that make LLMs prone to adversarial attacks happen. Motivated by these facts, we explore how to localize and understand vulnerabilities, and propose a method, based on Mechanistic Interpretability (MI) techniques, to guide this process. Specifically, this method enables us to detect vulnerabilities related to a concrete task by (i) obtaining the subset of the model that is responsible for that task, (ii) generating adversarial samples for that task, and (iii) using MI techniques together with the previous samples to discover and understand the possible vulnerabilities. We showcase our method on a pretrained GPT-2 Small model carrying out the task of predicting 3-letter acronyms to demonstrate its effectiveness on locating and understanding concrete vulnerabilities of the model. Keywords: AI Ethics, Trust, Fairness: ETF: Explainability and interpretability AI Ethics, Trust, Fairness: ETF: Trustworthy AI Machine Learning: ML: Explainable/Interpretable machine learning},
  archive   = {C_IJCAI},
  author    = {Jorge García-Carrasco and Alejandro Maté and Juan Trujillo},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/43},
  month     = {8},
  pages     = {385-393},
  title     = {Detecting and understanding vulnerabilities in language models via mechanistic interpretability},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The impact of features used by algorithms on perceptions of
fairness. <em>IJCAI</em>, 376–384. (<a
href="https://doi.org/10.24963/ijcai.2024/42">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We investigate perceptions of fairness in the choice of features that algorithms use about individuals in a simulated gigwork employment experiment. First, a collection of experimental participants (the selectors) were asked to recommend an algorithm for making employment decisions. Second, a different collection of participants (the workers) were told about the setup, and a subset were ostensibly selected by the algorithm to perform an image labeling task. For both selector and worker participants, algorithmic choices differed principally in the inclusion of features that were non-volitional, and either directly relevant to the task, or for which relevance is not evident except for these features resulting in higher accuracy. We find that the selectors had a clear predilection for the more accurate algorithms, which they also judged as more fair. Worker sentiments were considerably more nuanced. Workers who were hired were largely indifferent among the algorithms. In contrast, workers who were not hired exhibited considerably more positive sentiments for algorithms that included non-volitional but relevant features. However, workers with disadvantaged values of non-volitional features exhibited more negative sentiment towards their use than the average, although the extent of this appears to depend considerably on the nature of such features. Keywords: AI Ethics, Trust, Fairness: ETF: Fairness and diversity AI Ethics, Trust, Fairness: ETF: Moral decision making AI Ethics, Trust, Fairness: ETF: Societal impact of AI AI Ethics, Trust, Fairness: ETF: Values},
  archive   = {C_IJCAI},
  author    = {Andrew Estornell and Tina Zhang and Sanmay Das and Chien-Ju Ho and Brendan Juba and Yevgeniy Vorobeychik},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/42},
  month     = {8},
  pages     = {376-384},
  title     = {The impact of features used by algorithms on perceptions of fairness},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Are logistic models really interpretable? <em>IJCAI</em>,
367–375. (<a href="https://doi.org/10.24963/ijcai.2024/41">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The demand for open and trustworthy AI models points towards widespread publishing of model weights. Consumers of these model weights must be able to act accordingly with the information provided. That said, one of the simplest AI classification models, Logistic Regression (LR), has an unwieldy interpretation of its model weights, with greater difficulties when extending LR to generalised additive models. In this work, we show via a User Study that skilled participants are unable to reliably reproduce the action of small LR models given the trained parameters. As an antidote to this, we define Linearised Additive Models (LAMs), an optimal piecewise linear approximation that augments any trained additive model equipped with a sigmoid link function, requiring no retraining. We argue that LAMs are more interpretable than logistic models -- survey participants are shown to solve model reasoning tasks with LAMs much more accurately than with LR given the same information. Furthermore, we show that LAMs do not suffer from large performance penalties in terms of ROC-AUC and calibration with respect to their logistic counterparts on a broad suite of public financial modelling data. Keywords: AI Ethics, Trust, Fairness: ETF: Explainability and interpretability Machine Learning: ML: Classification},
  archive   = {C_IJCAI},
  author    = {Danial Dervovic and Freddy Lecue and Nicolas Marchesotti and Daniele Magazzeni},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/41},
  month     = {8},
  pages     = {367-375},
  title     = {Are logistic models really interpretable?},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Machine unlearning via null space calibration.
<em>IJCAI</em>, 358–366. (<a
href="https://doi.org/10.24963/ijcai.2024/40">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Machine unlearning aims to enable models to forget specific data instances when receiving deletion requests. Current research centers on efficient unlearning to erase the influence of data from the model and neglects the subsequent impacts on the remaining data. Consequently, existing unlearning algorithms degrade the model&#39;s performance after unlearning, known as over-unlearning. This paper addresses this critical yet under-explored issue by introducing machine Unlearning via Null Space Calibration (UNSC), which can accurately unlearn target samples without over-unlearning. On the contrary, by calibrating the decision space during unlearning, UNSC can significantly improve the model&#39;s performance on the remaining samples. In particular, our approach hinges on confining the unlearning process to a specified null space tailored to the remaining samples, which is augmented by strategically pseudo-labeling the unlearning samples. Comparison against several established baselines affirms the superiority of our approach. Keywords: AI Ethics, Trust, Fairness: ETF: Trustworthy AI AI Ethics, Trust, Fairness: ETF: Accountability AI Ethics, Trust, Fairness: ETF: Ethical, legal and societal issues AI Ethics, Trust, Fairness: ETF: Other},
  archive   = {C_IJCAI},
  author    = {Huiqiang Chen and Tianqing Zhu and Xin Yu and Wanlei Zhou},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/40},
  month     = {8},
  pages     = {358-366},
  title     = {Machine unlearning via null space calibration},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). BadFusion: 2D-oriented backdoor attacks against 3D object
detection. <em>IJCAI</em>, 349–357. (<a
href="https://doi.org/10.24963/ijcai.2024/39">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {3D object detection plays an important role in autonomous driving; however, its vulnerability to backdoor attacks has become evident. By injecting “triggers” to poison the training dataset, backdoor attacks manipulate the detector&#39;s prediction for inputs containing these triggers. Existing backdoor attacks against 3D object detection primarily poison 3D LiDAR signals, where large-sized 3D triggers are injected to ensure their visibility within the sparse 3D space, rendering them easy to detect and impractical in real-world scenarios. In this paper, we delve into the robustness of 3D object detection, exploring a new backdoor attack surface through 2D cameras. Given the prevalent adoption of camera and LiDAR signal fusion for high-fidelity 3D perception, we investigate the latent potential of camera signals to disrupt the process. Although the dense nature of camera signals enables the use of nearly imperceptible small-sized triggers to mislead 2D object detection, realizing 2D-oriented backdoor attacks against 3D object detection is non-trivial. The primary challenge emerges from the fusion process that transforms camera signals into a 3D space, compromising the association with the 2D trigger to the target output. To tackle this issue, we propose an innovative 2D-oriented backdoor attack against LiDAR-camera fusion methods for 3D object detection, named BadFusion, for preserving trigger effectiveness throughout the entire fusion process. The evaluation demonstrates the effectiveness of BadFusion, achieving a significantly higher attack success rate compared to existing 2D-oriented attacks. Keywords: AI Ethics, Trust, Fairness: ETF: Safety and robustness AI Ethics, Trust, Fairness: ETF: Trustworthy AI Computer Vision: CV: Adversarial learning, adversarial attack and defense methods Computer Vision: CV: 3D computer vision},
  archive   = {C_IJCAI},
  author    = {Saket S. Chaturvedi and Lan Zhang and Wenbin Zhang and Pan He and Xiaoyong Yuan},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/39},
  month     = {8},
  pages     = {349-357},
  title     = {BadFusion: 2D-oriented backdoor attacks against 3D object detection},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Discriminative feature decoupling enhancement for speech
forgery detection. <em>IJCAI</em>, 340–348. (<a
href="https://doi.org/10.24963/ijcai.2024/38">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The emergence of AIGC has brought attention to the issue of generating realistic deceptive content. While AIGC has the potential to revolutionize content creation, it also facilitates criminal activities. Specifically, the manipulation of speech has been exploited in tele-fraud and financial fraud schemes, posing a significant threat to societal security. Current deep learning-based methods for detecting forged speech extract mixed features from the original speech, which often contain redundant information. Moreover, these methods fail to consider the distinct characteristics of human voice-specific features and the diversity of background environmental sounds. This paper introduces a framework called Discriminative fEature dEcoupling enhanceMent (DEEM) for detecting speech forgery. Initially, the framework decouples the original speech into human voice features and background sound features. Subsequently, DEEM enhances voice-specific features through temporal dimension aggregation and improves continuity-related features in the background sound map via spectral-dimension aggregation. By employing the decoupling enhancement features, extensive experiments demonstrate that DEEM achieves an accuracy improvement of over 5% on FoR dataset compared to the state-of-the-art methods. Keywords: AI Ethics, Trust, Fairness: ETF: Safety and robustness AI Ethics, Trust, Fairness: ETF: AI and law, governance, regulation AI Ethics, Trust, Fairness: ETF: Fairness and diversity AI Ethics, Trust, Fairness: ETF: Societal impact of AI},
  archive   = {C_IJCAI},
  author    = {Yijun Bei and Xing Zhou and Erteng Liu and Yang Gao and Sen Lin and Kewei Gao and Zunlei Feng},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/38},
  month     = {8},
  pages     = {340-348},
  title     = {Discriminative feature decoupling enhancement for speech forgery detection},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pluggable watermarking of deepfake models for deepfake
detection. <em>IJCAI</em>, 331–339. (<a
href="https://doi.org/10.24963/ijcai.2024/37">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deepfake model misuse poses major security concerns. Existing passive and active Deepfake detection methods both suffer from a lack of generalizability and robustness. In this study, we propose a pluggable and efficient active model watermarking framework for Deepfake detection. This approach facilitates the embedding of identification watermarks across a variety of Deepfake generation models, enabling easy extraction by authorities for detection purposes. Specifically, our method leverages the universal convolutional structure in generative model decoders. It employs convolutional kernel sparsification for adaptive watermark embedding positioning and introduces convolutional kernel normalization to seamlessly integrate watermark parameters with those of the generative model. For watermark extraction, we jointly train a watermark extractor based on a Deepfake detection model and use BCH encoding to identify watermark images effectively. Finally, we apply our approach to eight major types of Deepfake generation models. Experiments show our method successfully detects Deepfakes with an average accuracy exceeding 94% even in heavy lossy channels. This approach operates independently of the generation model&#39;s training without affecting the original model&#39;s performance. Furthermore, our model requires training a very limited number of parameters, and it is resilient against three major adaptive attacks. The source code can be found at https://github.com/GuaiZao/Pluggable-Watermarking Keywords: AI Ethics, Trust, Fairness: ETF: Trustworthy AI AI Ethics, Trust, Fairness: ETF: Safety and robustness},
  archive   = {C_IJCAI},
  author    = {Han Bao and Xuhong Zhang and Qinying Wang and Kangming Liang and Zonghui Wang and Shouling Ji and Wenzhi Chen},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/37},
  month     = {8},
  pages     = {331-339},
  title     = {Pluggable watermarking of deepfake models for deepfake detection},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards a pretrained model for restless bandits via
multi-arm generalization. <em>IJCAI</em>, 321–329. (<a
href="https://doi.org/10.24963/ijcai.2024/36">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Restless multi-arm bandits (RMABs) is a class of resource allocation problems with broad application in areas such as healthcare, online advertising, and anti-poaching. We explore several important question such as how to handle arms opting-in and opting-out over time without frequent retraining from scratch, how to deal with continuous state settings with nonlinear reward functions, which appear naturally in practical contexts. We address these questions by developing a pre-trained model (PreFeRMAB) based on a novel combination of three key ideas: (i) to enable fast generalization, we use train agents to learn from each other&#39;s experience; (ii) to accommodate streaming RMABs, we derive a new update rule for a crucial $\lambda$-network; (iii) to handle more complex continuous state settings, we design the algorithm to automatically define an abstract state based on raw observation and reward data. PreFeRMAB allows general zero-shot ability on previously unseen RMABs, and can be fine-tuned on specific instances in a more sample-efficient way than retraining from scratch. We theoretically prove the benefits of multi-arm generalization and empirically demonstrate the advantages of our approach on several challenging, real-world inspired problems. Keywords: Agent-based and Multi-agent Systems: MAS: Multi-agent learning Agent-based and Multi-agent Systems: MAS: Resource allocation Machine Learning: ML: Few-shot learning Agent-based and Multi-agent Systems: MAS: Multi-agent planning},
  archive   = {C_IJCAI},
  author    = {Yunfan Zhao and Nikhil Behari and Edward Hughes and Edwin Zhang and Dheeraj Nagaraj and Karl Tuyls and Aparna Taneja and Milind Tambe},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/36},
  month     = {8},
  pages     = {321-329},
  title     = {Towards a pretrained model for restless bandits via multi-arm generalization},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Guidance graph optimization for lifelong multi-agent path
finding. <em>IJCAI</em>, 311–320. (<a
href="https://doi.org/10.24963/ijcai.2024/35">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study how to use guidance to improve the throughput of lifelong Multi-Agent Path Finding (MAPF). Previous studies have demonstrated that, while incorporating guidance, such as highways, can accelerate MAPF algorithms, this often results in a trade-off with solution quality. In addition, how to generate good guidance automatically remains largely unexplored, with current methods falling short of surpassing manually designed ones. In this work, we introduce the guidance graph as a versatile representation of guidance for lifelong MAPF, framing Guidance Graph Optimization as the task of optimizing its edge weights. We present two GGO algorithms to automatically generate guidance for arbitrary lifelong MAPF algorithms and maps. The first method directly optimizes edge weights, while the second method optimizes an update model capable of generating edge weights. Empirically, we show that (1) our guidance graphs improve the throughput of three representative lifelong MAPF algorithms in eight benchmark maps, and (2) our update model can generate guidance graphs for as large as 93 x 91 maps and as many as 3,000 agents. We include the source code at: https://github.com/lunjohnzhang/ggo_public. All optimized guidance graphs are available online at: https://yulunzhang.net/publication/zhang2024ggo. Keywords: Agent-based and Multi-agent Systems: MAS: Multi-agent planning Planning and Scheduling: PS: Applications Robotics: ROB: Multi-robot systems Search: S: Evolutionary computation},
  archive   = {C_IJCAI},
  author    = {Yulun Zhang and He Jiang and Varun Bhatt and Stefanos Nikolaidis and Jiaoyang Li},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/35},
  month     = {8},
  pages     = {311-320},
  title     = {Guidance graph optimization for lifelong multi-agent path finding},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ADMN: Agent-driven modular network for dynamic parameter
sharing in cooperative multi-agent reinforcement learning.
<em>IJCAI</em>, 302–310. (<a
href="https://doi.org/10.24963/ijcai.2024/34">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Parameter sharing is a common strategy in multi-agent reinforcement learning (MARL) to make the training more efficient and scalable. However, applying parameter sharing among agents indiscriminately hinders the emergence of agents diversity and degrades the final cooperative performance. To better balance parameter sharing and agents diversity, we propose a novel Agent-Driven Modular Network (ADMN), where agents share a base network consisting of multiple specialized modules, and each agent has its own routing to connect these modules. In ADMN, modules are shared among agents to improve the training efficiency, while the combination of different modules brings rich diversity. The agent routing at different time steps is learned end-to-end to achieve a dynamic and adaptive balance. Specifically, we also propose an information-theoretical regularization between the routing of agents and their behavior to further guarantee the identifiability of different routing. We evaluated ADMN in challenging StarCraft micromanagement games and Google Research Football games, and results demonstrate the superior performance of ADMN, particularly in larger or heterogeneous cooperative tasks. Keywords: Agent-based and Multi-agent Systems: MAS: Multi-agent learning Machine Learning: ML: Reinforcement learning},
  archive   = {C_IJCAI},
  author    = {Yang Yu and Qiyue Yin and Junge Zhang and Pei Xu and Kaiqi Huang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/34},
  month     = {8},
  pages     = {302-310},
  title     = {ADMN: Agent-driven modular network for dynamic parameter sharing in cooperative multi-agent reinforcement learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Intention progression with temporally extended goals.
<em>IJCAI</em>, 292–301. (<a
href="https://doi.org/10.24963/ijcai.2024/33">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Belief-Desire-Intention (BDI) approach to agent development has formed the basis for much of the research on architectures for autonomous agents. A key advantage of the BDI approach is that agents may pursue multiple intentions in parallel. However, previous approaches to managing possible interactions between concurrently executing intentions are limited to interactions between simple achievement goals (and in some cases maintenance goals). In this paper we present a new approach to intention progression for agents with temporally extended goals which allow mixing reachability and invariant properties, e.g., ``travel to location A while not exceeding a gradient of 5%&#39;&#39;. Temporally extended goals may be specified at run-time (top-level goals), and as subgoals in plans. In addition, our approach allows human-authored plans and plans implemented as RL policies to be freely mixed in an agent program, allowing the development of agents with `neuro-symbolic&#39; architectures. Keywords: Agent-based and Multi-agent Systems: MAS: Agent theories and models Agent-based and Multi-agent Systems: MAS: Engineering methods, platforms, languages and tools},
  archive   = {C_IJCAI},
  author    = {Yuan Yao and Natasha Alechina and Brian Logan},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/33},
  month     = {8},
  pages     = {292-301},
  title     = {Intention progression with temporally extended goals},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Population-based diverse exploration for sparse-reward
multi-agent tasks. <em>IJCAI</em>, 283–291. (<a
href="https://doi.org/10.24963/ijcai.2024/32">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Exploration under sparse rewards is a key challenge for multi-agent reinforcement learning problems. Although population-based learning shows its potential in producing diverse behaviors, most previous works still focus on improving the exploration of a single joint policy. In this paper, we show that with a suitable exploration method, maintaining a population of joint policies rather than one joint policy can significantly improve exploration. Our key idea is to guide each member of the population to explore different regions of the environment. To this end, we propose a member-aware exploration objective which explicitly guides each member to maximize deviation from the explored regions of other members, thus forcing them to explore different regions. In addition, we further propose an exploration-enhanced policy constraint to guide each member to learn a joint policy that is both different from other members and promotes exploration, thus increasing the probability of exploring different regions. Under reward-free setting, our method achieves 72% average improvement in the number of explored states compared to classical exploration methods in the multiple-particle environment. Moreover, under sparse-reward setting, we show that the proposed method significantly outperforms the state-of-the-art methods in the multiple-particle environment, the Google Research Football, and StarCraft II micromanagement tasks. Keywords: Agent-based and Multi-agent Systems: MAS: Multi-agent learning Machine Learning: ML: Reinforcement learning},
  archive   = {C_IJCAI},
  author    = {Pei Xu and Junge Zhang and Kaiqi Huang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/32},
  month     = {8},
  pages     = {283-291},
  title     = {Population-based diverse exploration for sparse-reward multi-agent tasks},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A successful strategy for multichannel iterated prisoner’s
dilemma. <em>IJCAI</em>, 274–282. (<a
href="https://doi.org/10.24963/ijcai.2024/31">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Iterated prisoner’s dilemma (IPD) and its variants are fundamental models for understanding the evolution of cooperation in human society as well as AI systems. In this paper, we focus on multichannel IPD, and examine how an agent should behave to obtain generally high payoffs under this setting. We propose a novel strategy that chooses to cooperate or defect by considering the difference in the cumulative number of defections between two agents. We show that our proposed strategy is nice, retaliatory, and forgiving. Moreover, we analyze the performance of our proposed strategy across different scenarios, including the self-play settings with and without errors, as well as when facing various opponent strategies. In particular, we show that our proposed strategy is invincible and never loses to any opponent strategy in terms of the expected payoff. Last but not least, we empirically validate the evolutionary advantage of our strategy, and demonstrate its potential to serve as a catalyst for cooperation emergence. Keywords: Agent-based and Multi-agent Systems: MAS: Coordination and cooperation Agent-based and Multi-agent Systems: MAS: Agent-based simulation and emergence Game Theory and Economic Paradigms: GTEP: Noncooperative games},
  archive   = {C_IJCAI},
  author    = {Zhen Wang and Zhaoheng Cao and Juan Shi and Peican Zhu and Shuyue Hu and Chen Chu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/31},
  month     = {8},
  pages     = {274-282},
  title     = {A successful strategy for multichannel iterated prisoner’s dilemma},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reinforcement nash equilibrium solver. <em>IJCAI</em>,
265–273. (<a href="https://doi.org/10.24963/ijcai.2024/30">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Nash Equilibrium (NE) is the canonical solution concept of game theory, which provides an elegant tool to understand the rationalities. Though mixed strategy NE exists in any game with finite players and actions, computing NE in two- or multi-player general-sum games is PPAD-Complete. Various alternative solutions, e.g., Correlated Equilibrium (CE), and learning methods, e.g., fictitious play (FP), are proposed to approximate NE. For convenience, we call these methods as ``inexact solvers&#39;&#39;, or ``solvers&#39;&#39; for short. However, the alternative solutions differ from NE and the learning methods generally fail to converge to NE. Therefore, in this work, we propose REinforcement Nash Equilibrium Solver (RENES), which trains a single policy to modify the games with different sizes and applies the solvers on the modified games where the obtained solution is evaluated on the original games. Specifically, our contributions are threefold. i) We represent the games as alpha-rank response graphs and leverage graph neural network (GNN) to handle the games with different sizes as inputs; ii) We use tensor decomposition, e.g., canonical polyadic (CP), to make the dimension of modifying actions fixed for games with different sizes; iii) We train the modifying strategy for games with the widely-used proximal policy optimization (PPO) and apply the solvers to solve the modified games, where the obtained solution is evaluated on original games. Extensive experiments on large-scale normal-form games show that our method can further improve the approximation of NE of different solvers, i.e., alpha-rank, CE, FP and PRD, and can be generalized to unseen games. Keywords: Agent-based and Multi-agent Systems: MAS: Multi-agent learning Game Theory and Economic Paradigms: GTEP: Noncooperative games Machine Learning: ML: Game Theory Machine Learning: ML: Reinforcement learning},
  archive   = {C_IJCAI},
  author    = {Xinrun Wang and Chang Yang and Shuxin Li and Pengdeng Li and Xiao Huang and Hau Chan and Bo An},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/30},
  month     = {8},
  pages     = {265-273},
  title     = {Reinforcement nash equilibrium solver},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Design a win-win strategy that is fair to both service
providers and tasks when rejection is not an option. <em>IJCAI</em>,
257–264. (<a href="https://doi.org/10.24963/ijcai.2024/29">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Assigning tasks to service providers is a frequent procedure across various applications. Often the tasks arrive dynamically while the service providers remain static. Preventing task rejection caused by service provider overload is of utmost significance. To ensure a positive experience in relevant applications for both service providers and tasks, fairness must be considered. To address the issue, we model the problem as an online matching within a bipartite graph and tackle two minimax problems: one focuses on minimizing the highest waiting time of a task, while the other aims to minimize the highest workload of a service provider. We show that the second problem can be expressed as a linear program and thus solved efficiently while maintaining a reasonable approximation to the objective of the first problem. We developed novel methods that utilize the two minimax problems. We conducted extensive simulation experiments using real data and demonstrated that our novel heuristics, based on the linear program, performed remarkably well. Keywords: Agent-based and Multi-agent Systems: MAS: Resource allocation},
  archive   = {C_IJCAI},
  author    = {Yohai Trabelsi and Pan Xu and Sarit Kraus},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/29},
  month     = {8},
  pages     = {257-264},
  title     = {Design a win-win strategy that is fair to both service providers and tasks when rejection is not an option},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MGCBS: An optimal and efficient algorithm for solving
multi-goal multi-agent path finding problem. <em>IJCAI</em>, 249–256.
(<a href="https://doi.org/10.24963/ijcai.2024/28">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With the expansion of the scale of robotics applications, the multi-goal multi-agent pathfinding (MG-MAPF) problem began to gain widespread attention. This problem requires each agent to visit pre-assigned multiple goal points at least once without conflict. Some previous methods have been proposed to solve the MG-MAPF problem based on Decoupling the goal Vertex visiting order search and the Single-agent pathfinding (DVS). However, this paper demonstrates that the methods based on DVS cannot always obtain the optimal solution. To obtain the optimal result, we propose the Multi-Goal Conflict-Based Search (MGCBS), which is based on Decoupling the goal Safe interval visiting order search and the Single-agent pathfinding (DSS). Additionally, we present the Time-Interval-Space Forest (TIS Forest) to enhance the efficiency of MGCBS by maintaining the shortest paths from any start point at any start time step to each safe interval at the goal points. The experiment demonstrates that our method can consistently obtain optimal results and execute up to 7 times faster than the state-of-the-art method in our evaluation. Keywords: Agent-based and Multi-agent Systems: MAS: Multi-agent planning Planning and Scheduling: PS: Robot planning Robotics: ROB: Multi-robot systems Search: S: Combinatorial search and optimisation},
  archive   = {C_IJCAI},
  author    = {Mingkai Tang and Yuanhang Li and Hongji Liu and Yingbing Chen and Ming Liu and Lujia Wang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/28},
  month     = {8},
  pages     = {249-256},
  title     = {MGCBS: An optimal and efficient algorithm for solving multi-goal multi-agent path finding problem},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Faster optimal coalition structure generation via offline
coalition selection and graph-based search. <em>IJCAI</em>, 238–248. (<a
href="https://doi.org/10.24963/ijcai.2024/27">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Coalition formation is a key capability in multi-agent systems. An important problem in coalition formation is coalition structure generation: partitioning agents into coalitions to optimize the social welfare. This is a challenging problem that has been the subject of active research for the past three decades. In this paper, we present a novel algorithm, SMART, for the problem based on a hybridization of three innovative techniques. Two of these techniques are based on dynamic programming, where we show a powerful connection between the coalitions selected for evaluation and the performance of the algorithms. These algorithms use offline phases to optimize the choice of coalitions to evaluate. The third one uses branch-and-bound and integer partition graph search to explore the solution space. Our techniques bring a new way of approaching the problem and a new level of precision to the field. In experiments over several common value distributions, we show that the hybridization of these techniques in SMART is faster than the fastest prior algorithms (ODP-IP, BOSS) in generating optimal solutions across all the value distributions. Keywords: Agent-based and Multi-agent Systems: MAS: Coordination and cooperation Game Theory and Economic Paradigms: GTEP: Cooperative games Machine Learning: ML: Optimization},
  archive   = {C_IJCAI},
  author    = {Redha Taguelmimt and Samir Aknine and Djamila Boukredera and Narayan Changder and Tuomas Sandholm},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/27},
  month     = {8},
  pages     = {238-248},
  title     = {Faster optimal coalition structure generation via offline coalition selection and graph-based search},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cooperation and control in delegation games. <em>IJCAI</em>,
229–237. (<a href="https://doi.org/10.24963/ijcai.2024/26">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Many settings of interest involving humans and machines – from virtual personal assistants to autonomous vehicles – can naturally be modelled as principals (humans) delegating to agents (machines), which then interact with each other on their principals’ behalf. We refer to these multi-principal, multi-agent scenarios as delegation games. In such games, there are two important failure modes: problems of control (where an agent fails to act in line their principal’s preferences) and problems of cooperation (where the agents fail to work well together). In this paper we formalise and analyse these problems, further breaking them down into issues of alignment (do the players have similar preferences?) and capabilities (how competent are the players at satisfying those preferences?). We show – theoretically and empirically – how these measures determine the principals’ welfare, how they can be estimated using limited observations, and thus how they might be used to help us design more aligned and cooperative AI systems. Keywords: Agent-based and Multi-agent Systems: MAS: Coordination and cooperation AI Ethics, Trust, Fairness: ETF: Safety and robustness Game Theory and Economic Paradigms: GTEP: Other Humans and AI: HAI: Human-AI collaboration},
  archive   = {C_IJCAI},
  author    = {Oliver Sourbut and Lewis Hammond and Harriet Wood},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/26},
  month     = {8},
  pages     = {229-237},
  title     = {Cooperation and control in delegation games},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning fair cooperation in mixed-motive games with
indirect reciprocity. <em>IJCAI</em>, 220–228. (<a
href="https://doi.org/10.24963/ijcai.2024/25">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Altruistic cooperation is costly yet socially desirable. As a result, agents struggle to learn cooperative policies through independent reinforcement learning (RL). Indirect reciprocity, where agents consider their interaction partner’s reputation, has been shown to stabilise cooperation in homogeneous, idealised populations. However, more realistic settings are comprised of heterogeneous agents with different characteristics and group-based social identities. We study cooperation when agents are stratified into two such groups, and allow reputation updates and actions to depend on group information. We consider two modelling approaches: evolutionary game theory, where we comprehensively search for social norms (i.e., rules to assign reputations) leading to cooperation and fairness; and RL, where we consider how the stochastic dynamics of policy learning affects the analytically identified equilibria. We observe that a defecting majority leads the minority group to defect, but not the inverse. Moreover, changing the norms that judge inand out-group interactions can steer a system towards either fair or unfair cooperation. This is made clearer when moving beyond equilibrium analysis to independent RL agents, where convergence to fair cooperation occurs with a narrower set of norms. Our results highlight that, in heterogeneous populations with reputations, carefully defining interaction norms is fundamental to tackle both dilemmas of cooperation and of fairness. Keywords: Agent-based and Multi-agent Systems: MAS: Coordination and cooperation Agent-based and Multi-agent Systems: MAS: Agent-based simulation and emergence Agent-based and Multi-agent Systems: MAS: Multi-agent learning},
  archive   = {C_IJCAI},
  author    = {Martin Smit and Fernando P. Santos},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/25},
  month     = {8},
  pages     = {220-228},
  title     = {Learning fair cooperation in mixed-motive games with indirect reciprocity},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fostering collective action in complex societies using
community-based agents. <em>IJCAI</em>, 211–219. (<a
href="https://doi.org/10.24963/ijcai.2024/24">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As AI integrates into human societies, its ability to engage in collective action is increasingly important. Human social systems have large and flexible strategy spaces, conflicting interests, power asymmetry, and interdependence among members, which together make it challenging for agents to learn collective action. In this paper, we explore the ability of community-based agents to learn collective action within a novel model of complex social systems. We first present this social model, called the Junior High Game (JHG). The JHG embodies key elements of human social systems that require players to act collectively. We then describe an agent, called CAB, which is based on community detection and formation algorithms. Via simulations and user studies, we evaluate the ability of CAB agents to interact in JHG societies consisting of humans and AI agents. These evaluations both identify requirements for successful collective behaviors in the JHG and identify important unsolved problems for developing AI agents capable of collective action in complex social systems. Keywords: Agent-based and Multi-agent Systems: MAS: Coordination and cooperation Agent-based and Multi-agent Systems: MAS: Agent societies Agent-based and Multi-agent Systems: MAS: Human-agent interaction Agent-based and Multi-agent Systems: MAS: Trust and reputation},
  archive   = {C_IJCAI},
  author    = {Jonathan Skaggs and Michael Richards and Melissa Morris and Michael A. Goodrich and Jacob W. Crandall},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/24},
  month     = {8},
  pages     = {211-219},
  title     = {Fostering collective action in complex societies using community-based agents},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Langshaw: Declarative interaction protocols based on sayso
and conflict. <em>IJCAI</em>, 202–210. (<a
href="https://doi.org/10.24963/ijcai.2024/23">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Current languages for specifying multiagent protocols either over-constrain protocol enactments or complicate capturing their meanings. We propose Langshaw, a declarative protocol language based on (1) sayso, a new construct that captures who has priority over setting each attribute, and (2) nono and nogo, two constructs to capture conflicts between actions. Langshaw combines flexibility with an information model to express meaning. We give a formal semantics for Langshaw, procedures for determining the safety and liveness of a protocol, and a method to generate a message-oriented protocol (embedding needed coordination) suitable for flexible asynchronous enactment. Keywords: Agent-based and Multi-agent Systems: MAS: Agent communication Agent-based and Multi-agent Systems: MAS: Engineering methods, platforms, languages and tools Agent-based and Multi-agent Systems: MAS: Formal verification, validation and synthesis Agent-based and Multi-agent Systems: General},
  archive   = {C_IJCAI},
  author    = {Munindar P. Singh and Samuel H. Christie V. and Amit K. Chopra},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/23},
  month     = {8},
  pages     = {202-210},
  title     = {Langshaw: Declarative interaction protocols based on sayso and conflict},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing cooperation through selective interaction and
long-term experiences in multi-agent reinforcement learning.
<em>IJCAI</em>, 193–201. (<a
href="https://doi.org/10.24963/ijcai.2024/22">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The significance of network structures in promoting group cooperation within social dilemmas has been widely recognized. Prior studies attribute this facilitation to the assortment of strategies driven by spatial interactions. Although reinforcement learning has been employed to investigate the impact of dynamic interaction on the evolution of cooperation, there remains a lack of understanding about how agents develop neighbour selection behaviours and the formation of strategic assortment within an explicit interaction structure. To address this, our study introduces a computational framework based on multi-agent reinforcement learning in the spatial Prisoner&#39;s Dilemma game. This framework allows agents to select dilemma strategies and interacting neighbours based on their long-term experiences, differing from existing research that relies on preset social norms or external incentives. By modelling each agent using two distinct Q-networks, we disentangle the coevolutionary dynamics between cooperation and interaction. The results indicate that long-term experience enables agents to develop the ability to identify non-cooperative neighbours and exhibit a preference for interaction with cooperative ones. This emergent self-organizing behaviour leads to the clustering of agents with similar strategies, thereby increasing network reciprocity and enhancing group cooperation. Keywords: Agent-based and Multi-agent Systems: MAS: Coordination and cooperation Game Theory and Economic Paradigms: GTEP: Cooperative games Machine Learning: ML: Multiagent Reinforcement Learning Multidisciplinary Topics and Applications: MTA: Social sciences},
  archive   = {C_IJCAI},
  author    = {Tianyu Ren and Xiao-Jun Zeng},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/22},
  month     = {8},
  pages     = {193-201},
  title     = {Enhancing cooperation through selective interaction and long-term experiences in multi-agent reinforcement learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Safety constrained multi-agent reinforcement learning for
active voltage control. <em>IJCAI</em>, 184–192. (<a
href="https://doi.org/10.24963/ijcai.2024/21">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Active voltage control presents a promising avenue for relieving power congestion and enhancing voltage quality, taking advantage of the distributed controllable generators in the power network, such as roof-top photovoltaics. While Multi-Agent Reinforcement Learning (MARL) has emerged as a compelling approach to address this challenge, existing MARL approaches tend to overlook the constrained optimization nature of this problem, failing in guaranteeing safety constraints. In this paper, we formalize the active voltage control problem as a constrained Markov game and propose a safety-constrained MARL algorithm. We expand the primal-dual optimization RL method to multi-agent settings, and augment it with a novel approach of double safety estimation to learn the policy and to update the Lagrange-multiplier. In addition, we proposed different cost functions and investigated their influences on the behavior of our constrained MARL method. We evaluate our approach in the power distribution network simulation environment with real-world scale scenarios. Experimental results demonstrate the effectiveness of the proposed method compared with the state-of-the-art MARL methods. Keywords: Agent-based and Multi-agent Systems: MAS: Applications Machine Learning: ML: Multiagent Reinforcement Learning Agent-based and Multi-agent Systems: MAS: Coordination and cooperation Agent-based and Multi-agent Systems: MAS: Multi-agent learning},
  archive   = {C_IJCAI},
  author    = {Yang Qu and Jinming Ma and Feng Wu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/21},
  month     = {8},
  pages     = {184-192},
  title     = {Safety constrained multi-agent reinforcement learning for active voltage control},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Individual fairness under group fairness constraints in
bipartite matching - one framework to approximate them all.
<em>IJCAI</em>, 175–183. (<a
href="https://doi.org/10.24963/ijcai.2024/20">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the probabilistic assignment of items to platforms that satisfies both group and individual fairness constraints. Each item belongs to specific groups and has a preference ordering over platforms. Each platform enforces group fairness by limiting the number of items per group that can be assigned to it. There could be multiple optimal solutions that satisfy the group fairness constraints, but this alone ignores item preferences. Our approach explores a `best of both worlds fairness&#39; solution to get a randomized matching, which is ex-ante individually fair and ex-post group-fair. Thus, we seek a `probabilistic individually fair&#39; distribution over `group-fair&#39; matchings where each item has a `high&#39; probability of matching to one of its top choices. This distribution is also ex-ante group-fair. Users can customize fairness constraints to suit their requirements. Our first result is a polynomial-time algorithm that computes a distribution over `group-fair&#39; matchings such that the individual fairness constraints are approximately satisfied and the expected size of a matching is close to OPT. We empirically test this on real-world datasets. We present two additional polynomial-time bi-criteria approximation algorithms that users can choose from to balance group fairness and individual fairness trade-offs. For disjoint groups, we provide an exact polynomial-time algorithm adaptable to additional lower `group fairness&#39; bounds. Extending our model, we encompass `maxmin group fairness,&#39; amplifying underrepresented groups, and `mindom group fairness,&#39; reducing the representation of dominant groups.&#39; Keywords: Agent-based and Multi-agent Systems: MAS: Resource allocation AI Ethics, Trust, Fairness: ETF: Fairness and diversity},
  archive   = {C_IJCAI},
  author    = {Atasi Panda and Anand Louis and Prajakta Nimbhorkar},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/20},
  month     = {8},
  pages     = {175-183},
  title     = {Individual fairness under group fairness constraints in bipartite matching - one framework to approximate them all},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Diversifying training pool predictability for zero-shot
coordination: A theory of mind approach. <em>IJCAI</em>, 166–174. (<a
href="https://doi.org/10.24963/ijcai.2024/19">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The challenge in constructing artificial social agents is to enable adaptation ability to novel agents, and is called zero-shot coordination (ZSC). A promising approach is to train the adaptive agents by interacting with a diverse pool of collaborators, assuming that the greater the diversity in other agents seen during training, the better the generalisation. In this paper, we explore an alternative procedure by considering the behavioural predictability of collaborators, i.e. whether their actions and intentions are predictable, and use it to select a diverse set of agents for the training pool. More specifically, we develop a pool of agents through self-play training during which agents&#39; behaviour evolves and has diversity in levels of behavioural predictability (LoBP) through its evolution. We construct an observer to compute the level of behavioural predictability for each version of the collaborators. To do so, the observer is equipped with the theory of mind (ToM) capability to learn to infer the actions and intentions of others. We then use an episodic memory based on the LoBP metric to maintain agents with different levels of behavioural predictability in the pool of agents. Since behaviours that emerge at the later training phase are more complex and meaningful, the memory is updated with the latest versions of training agents. Our extensive experiments demonstrate that LoBP-based diversity training leads to better ZSC than other diversity training methods. Keywords: Agent-based and Multi-agent Systems: MAS: Coordination and cooperation Machine Learning: ML: Multiagent Reinforcement Learning Machine Learning: ML: Reinforcement learning},
  archive   = {C_IJCAI},
  author    = {Dung Nguyen and Hung Le and Kien Do and Sunil Gupta and Svetha Venkatesh and Truyen Tran},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/19},
  month     = {8},
  pages     = {166-174},
  title     = {Diversifying training pool predictability for zero-shot coordination: A theory of mind approach},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fraud risk mitigation in real-time payments: A strategic
agent-based analysis. <em>IJCAI</em>, 157–165. (<a
href="https://doi.org/10.24963/ijcai.2024/18">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Whereas standard financial mechanisms for payment may take days to finalize, real-time payments (RTPs) provide immediate processing and final receipt of funds. The speed of settlement benefits customers, but raises vulnerability to fraud. We seek to understand how bank nodes may strategically mitigate fraud risk in RTPs, through investment in fraud detection and restricting payments eligible for real-time processing. To study this, we introduce an agent-based model of the payment network supporting both real-time and standard payments, and define a game among banks and fraudsters. Using empirical game-theoretic analysis, we identify Nash equilibria in nine game configurations defined by network attributes. Our analysis finds that as banks become more liable for fraud, they continue to allow RTPs but are more likely to employ both restrictions and a high level of fraud detection. Fraudsters, in response, switch from targeting only RTPs to attempting fraud with any type of payment and tend to exploit banks where they have historically been most successful. We also conduct a strategic feature gains assessment to further understand the benefit offered by each of the bank&#39;s risk mitigation measures, which confirms the importance of selective RTP restrictions. Finally, we find that in equilibrium bank strategic decisions negatively affect fraudsters while minimally impacting customers. Keywords: Agent-based and Multi-agent Systems: MAS: Applications Multidisciplinary Topics and Applications: MTA: Economics Multidisciplinary Topics and Applications: MTA: Finance},
  archive   = {C_IJCAI},
  author    = {Katherine Mayo and Nicholas Grabill and Michael P. Wellman},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/18},
  month     = {8},
  pages     = {157-165},
  title     = {Fraud risk mitigation in real-time payments: A strategic agent-based analysis},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A meta-game evaluation framework for deep multiagent
reinforcement learning. <em>IJCAI</em>, 148–156. (<a
href="https://doi.org/10.24963/ijcai.2024/17">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Evaluating deep multiagent reinforcement learning (MARL) algorithms is complicated by stochasticity in training and sensitivity of agent performance to the behavior of other agents. We propose a meta-game evaluation framework for deep MARL, by framing each MARL algorithm as a meta-strategy, and repeatedly sampling normal-form empirical games over combinations of meta-strategies resulting from different random seeds. Each empirical game captures both self-play and cross-play factors across seeds. These empirical games provide the basis for constructing a sampling distribution, using bootstrapping, over a variety of game analysis statistics. We use this approach to evaluate state-of-the-art deep MARL algorithms on a class of negotiation games. From statistics on individual payoffs, social welfare, and empirical best-response graphs, we uncover strategic relationships among self-play, population-based, model-free, and model-based MARL methods. We also investigate the effect of run-time search as a meta-strategy operator, and find via meta-game analysis that the search version of a meta-strategy generally leads to improved performance. Keywords: Agent-based and Multi-agent Systems: MAS: Multi-agent learning Game Theory and Economic Paradigms: GTEP: Noncooperative games},
  archive   = {C_IJCAI},
  author    = {Zun Li and Michael P. Wellman},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/17},
  month     = {8},
  pages     = {148-156},
  title     = {A meta-game evaluation framework for deep multiagent reinforcement learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Self-adaptive PSRO: Towards an automatic population-based
game solver. <em>IJCAI</em>, 139–147. (<a
href="https://doi.org/10.24963/ijcai.2024/16">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Policy-Space Response Oracles (PSRO) as a general algorithmic framework has achieved state-of-the-art performance in learning equilibrium policies of two-player zero-sum games. However, the hand-crafted hyperparameter value selection in most of the existing works requires extensive domain knowledge, forming the main barrier to applying PSRO to different games. In this work, we make the first attempt to investigate the possibility of self-adaptively determining the optimal hyperparameter values in the PSRO framework. Our contributions are three-fold: (1) Using several hyperparameters, we propose a parametric PSRO that unifies the gradient descent ascent (GDA) and different PSRO variants. (2) We propose the self-adaptive PSRO (SPSRO) by casting the hyperparameter value selection of the parametric PSRO as a hyperparameter optimization (HPO) problem where our objective is to learn an HPO policy that can self-adaptively determine the optimal hyperparameter values during the running of the parametric PSRO. (3) To overcome the poor performance of online HPO methods, we propose a novel offline HPO approach to optimize the HPO policy based on the Transformer architecture. Experiments on various two-player zero-sum games demonstrate the superiority of SPSRO over different baselines. Keywords: Agent-based and Multi-agent Systems: MAS: Multi-agent learning Game Theory and Economic Paradigms: GTEP: Noncooperative games Machine Learning: ML: Game Theory Machine Learning: ML: Hyperparameter optimization},
  archive   = {C_IJCAI},
  author    = {Pengdeng Li and Shuxin Li and Chang Yang and Xinrun Wang and Xiao Huang and Hau Chan and Bo An},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/16},
  month     = {8},
  pages     = {139-147},
  title     = {Self-adaptive PSRO: Towards an automatic population-based game solver},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MuEP: A multimodal benchmark for embodied planning with
foundation models. <em>IJCAI</em>, 129–138. (<a
href="https://doi.org/10.24963/ijcai.2024/15">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Foundation models have demonstrated significant emergent abilities, holding great promise for enhancing embodied agents&#39; reasoning and planning capacities. However, the absence of a comprehensive benchmark for evaluating embodied agents with multimodal observations in complex environments remains a notable gap. In this paper, we present MuEP, a comprehensive Multimodal benchmark for Embodied Planning. MuEP facilitates the evaluation of multimodal and multi-turn interactions of embodied agents in complex scenes, incorporating fine-grained evaluation metrics that provide insights into the performance of embodied agents throughout each task. Furthermore, we evaluate embodied agents with recent state-of-the-art foundation models, including large language models (LLMs) and large multimodal models (LMMs), on the proposed benchmark. Experimental results show that foundation models based on textual representations of environments usually outperform their visual counterparts, suggesting a gap in embodied planning abilities with multimodal observations. We also find that control language generation is an indispensable ability beyond common-sense knowledge for accurate embodied task completion. We hope the proposed MuEP benchmark can contribute to the advancement of embodied AI with foundation models. Keywords: Agent-based and Multi-agent Systems: MAS: Agent-based simulation and emergence Computer Vision: CV: Embodied vision: Active agents, simulation Multidisciplinary Topics and Applications: MTA: Databases},
  archive   = {C_IJCAI},
  author    = {Kanxue Li and Baosheng Yu and Qi Zheng and Yibing Zhan and Yuhui Zhang and Tianle Zhang and Yijun Yang and Yue Chen and Lei Sun and Qiong Cao and Li Shen and Lusong Li and Dapeng Tao and Xiaodong He},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/15},
  month     = {8},
  pages     = {129-138},
  title     = {MuEP: A multimodal benchmark for embodied planning with foundation models},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). STAR: Spatio-temporal state compression for multi-agent
tasks with rich observations. <em>IJCAI</em>, 120–128. (<a
href="https://doi.org/10.24963/ijcai.2024/14">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper focuses on the problem of learning compressed state representations for multi-agent tasks. Under the assumption of rich observation, we pinpoint that the state representations should be compressed both spatially and temporally to enable efficient prioritization of task-relevant features, while existing works typically fail. To overcome this limitation, we propose a novel method named Spatio-Temporal stAte compRession (STAR) that explicitly defines both spatial and temporal compression operations on the learned state representations to encode per-agent task-relevant features. Specifically, we first formalize this problem by introducing Task Informed Partially Observable Stochastic Game (TI-POSG). Then, we identify the spatial representation compression in it as encoding the latent states from the joint observations of all agents, and achieve this by learning representations that approximate the latent states based on the information theoretical principle. After that, we further extract the task-relevant features of each agent from these representations by aligning them based on their reward similarities, which is regarded as the temporal representation compression. Structurally, we implement these two compression by learning a set of agent-specific decoding functions and incorporate them into a critic shared by agents for scalable learning. We evaluate our method by developing decentralized policies on 12 maps of the StarCraft Multi-Agent Challenge benchmark, and the superior performance demonstrates its effectiveness. Keywords: Agent-based and Multi-agent Systems: MAS: Multi-agent learning Machine Learning: ML: Reinforcement learning},
  archive   = {C_IJCAI},
  author    = {Chao Li and Yujing Hu and Shangdong Yang and Tangjie Lv and Changjie Fan and Wenbin Li and Chongjie Zhang and Yang Gao},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/14},
  month     = {8},
  pages     = {120-128},
  title     = {STAR: Spatio-temporal state compression for multi-agent tasks with rich observations},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). To promote full cooperation in social dilemmas, agents need
to unlearn loyalty. <em>IJCAI</em>, 111–119. (<a
href="https://doi.org/10.24963/ijcai.2024/13">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {If given the choice, what strategy should agents use to switch partners in strategic social interactions? While many analyses have been performed on specific switching heuristics, showing how and when these lead to more cooperation, no insights have been provided into which rule will actually be learnt by agents when given the freedom to do so. Starting from a baseline model that has demonstrated the potential of rewiring for cooperation, we provide answers to this question over the full spectrum of social dilemmas. Multi-agent Q-learning with Boltzmann exploration is used to learn when to sever or maintain an association. In both the Prisoner&#39;s Dilemma and the Stag Hunt games we observe that the Out-for-Tat rewiring rule, breaking ties with other agents choosing socially undesirable actions, becomes dominant, confirming at the same time that cooperation flourishes when rewiring is fast enough relative to imitation. Nonetheless, in the transitory region before full cooperation, a Stay strategy, keeping a connection at all costs, remains present, which shows that loyalty needs to be overcome for full cooperation to emerge. In conclusion, individuals learn cooperation-promoting rewiring rules but need to overcome a kind of loyalty to achieve full cooperation in the full spectrum of social dilemmas. Keywords: Agent-based and Multi-agent Systems: MAS: Agent-based simulation and emergence Agent-based and Multi-agent Systems: MAS: Agent societies Agent-based and Multi-agent Systems: MAS: Coordination and cooperation Agent-based and Multi-agent Systems: MAS: Multi-agent learning},
  archive   = {C_IJCAI},
  author    = {Chin-wing Leung and Tom Lenaerts and Paolo Turrini},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/13},
  month     = {8},
  pages     = {111-119},
  title     = {To promote full cooperation in social dilemmas, agents need to unlearn loyalty},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Formal verification of parameterised neural-symbolic
multi-agent systems. <em>IJCAI</em>, 103–110. (<a
href="https://doi.org/10.24963/ijcai.2024/12">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the problem of verifying multi-agent systems composed of arbitrarily many neural-symbolic agents. We introduce a novel parameterised model, where the parameter denotes the number of agents in the system, each homogeneously constructed from an agent template equipped with a neural network-based perception unit and a traditionally programmed action selection mechanism. We define the verification and emergence identification problems for these models against a bounded fragment of CTL. We put forward an abstraction methodology that enables us to recast both problems to the problem of checking Neural Interpreted Systems with a bounded number of agents. We present an implementation and discuss experimental results obtained on a social dilemma game based on guarding. Keywords: Agent-based and Multi-agent Systems: MAS: Formal verification, validation and synthesis},
  archive   = {C_IJCAI},
  author    = {Panagiotis Kouvaros and Elena Botoeva and Cosmo De Bonis-Campbell},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/12},
  month     = {8},
  pages     = {103-110},
  title     = {Formal verification of parameterised neural-symbolic multi-agent systems},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). X-light: Cross-city traffic signal control using transformer
on transformer as meta multi-agent reinforcement learner.
<em>IJCAI</em>, 94–102. (<a
href="https://doi.org/10.24963/ijcai.2024/11">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The effectiveness of traffic light control has been significantly improved by current reinforcement learning-based approaches via better cooperation among multiple traffic lights. However, a persisting issue remains: how to obtain a multi-agent traffic signal control algorithm with remarkable transferability across diverse cities? In this paper, we propose a Transformer on Transformer (TonT) model for cross-city meta multi-agent traffic signal control, named as X-Light: We input the full Markov Decision Process trajectories, and the Lower Transformer aggregates the states, actions, rewards among the target intersection and its neighbors within a city, and the Upper Transformer learns the general decision trajectories across different cities. This dual-level approach bolsters the model&#39;s robust generalization and transferability. Notably, when directly transferring to unseen scenarios, ours surpasses all baseline methods with +7.91% on average, and even +16.3% in some cases, yielding the best results. Keywords: Agent-based and Multi-agent Systems: MAS: Applications Machine Learning: ML: Meta-learning Machine Learning: ML: Multi-task and transfer learning Multidisciplinary Topics and Applications: MTA: Transportation},
  archive   = {C_IJCAI},
  author    = {Haoyuan Jiang and Ziyue Li and Hua Wei and Xuantang Xiong and Jingqing Ruan and Jiaming Lu and Hangyu Mao and Rui Zhao},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/11},
  month     = {8},
  pages     = {94-102},
  title     = {X-light: Cross-city traffic signal control using transformer on transformer as meta multi-agent reinforcement learner},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CompetEvo: Towards morphological evolution from competition.
<em>IJCAI</em>, 85–93. (<a
href="https://doi.org/10.24963/ijcai.2024/10">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Training an agent to adapt to specific tasks through co-optimization of morphology and control has widely attracted attention. However, whether there exists an optimal configuration and tactics for agents in a multiagent competition scenario is still an issue that is challenging to definitively conclude. In this context, we propose competitive evolution (CompetEvo), which co-evolves agents&#39; designs and tactics in confrontation. We build arenas consisting of three animals and their evolved derivatives, placing agents with different morphologies in direct competition with each other. The results reveal that our method enables agents to evolve a more suitable design and strategy for fighting compared to fixed-morph agents, allowing them to obtain advantages in combat scenarios. Moreover, we demonstrate the amazing and impressive behaviors that emerge when confrontations are conducted under asymmetrical morphs. Keywords: Agent-based and Multi-agent Systems: MAS: Agent-based simulation and emergence Robotics: ROB: Learning in robotics Search: S: Evolutionary computation},
  archive   = {C_IJCAI},
  author    = {Kangyao Huang and Di Guo and Xinyu Zhang and Xiangyang Ji and Huaping Liu},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/10},
  month     = {8},
  pages     = {85-93},
  title     = {CompetEvo: Towards morphological evolution from competition},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Parameterized complexity of kidney exchange revisited.
<em>IJCAI</em>, 76–84. (<a
href="https://doi.org/10.24963/ijcai.2024/9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As of January 2023, there are more than 90,000 people on the national transplant waiting list in need of a kidney in the United States. These patients often have a friend or family member who is willing to donate, but whose kidney type might not be compatible. To help match these patients to suitable donors, patient-donor compatibility can be modeled as a directed graph. Specifically, in the Kidney Exchange problem, the input is a directed graph G, a subset B of vertices (altruistic donors), and two integers l_p and l_c. An altruistic donor is a donor who is not paired with a patient, and the remaining vertices are patient-donor pairs. Whenever a donor is compatible with a patient from a patient-donor pair, we place a directed edge from the donor vertex to the patient-donor pair. Here the donor vertex can be either altruistic or non-altruistic. The goal is to find a collection of vertex-disjoint cycles and paths covering the maximum number of patients such that each cycle has length at most l_c, and such that each path has length at most l_p and begins at a vertex in B. The path and cycle lengths are bounded so that the surgeries for a given path or cycle can be performed simultaneously. Kidney Exchange has received a great deal of attention in recent years. We contribute to this line of work by closing two open problems from IJCAI &#39;18 and IJCAI &#39;22: &quot;Is Kidney Exchange FPT when parameterized by (i) the treewidth (omega) of G and (ii) the number of vertex types in G?&#39;&#39; Two vertices have the same vertex type if they have the same in- and out-neighborhoods. We show that Kidney Exchange is FPT parameterized by the number of vertex types. On the other hand, we show W[1]-hardness with respect to omega. We also design a randomized 4^t * n^O(1)-time algorithm parameterized by t, the number of patients helped, significantly improving upon the previous state of the art, which was 161^t * n^O(1). Keywords: Agent-based and Multi-agent Systems: MAS: Resource allocation Constraint Satisfaction and Optimization: CSO: Constraint optimization problems Game Theory and Economic Paradigms: GTEP: Auctions and market-based systems Game Theory and Economic Paradigms: GTEP: Computational social choice},
  archive   = {C_IJCAI},
  author    = {Úrsula Hébert-Johnson and Daniel Lokshtanov and Chinmay Sonar and Vaishali Surianarayanan},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/9},
  month     = {8},
  pages     = {76-84},
  title     = {Parameterized complexity of kidney exchange revisited},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Endogenous energy reactive modules games: Modelling side
payments among resource-bounded agents. <em>IJCAI</em>, 67–75. (<a
href="https://doi.org/10.24963/ijcai.2024/8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We introduce Energy Reactive Modules Games (ERMGs), an extension of Reactive Modules Games (RMGs) in which actions incur an energy cost (which may be positive or negative), and the choices that players make are restricted by the energy available to them. In ERMGs, each action is associated with an energy level update, which determines how their energy level is affected by the performance of the action. In addition, agents are provided with an initial energy allowance. This allowance plays a crucial role in shaping an agent’s behaviour, as it must be taken into consideration when one is determining their strategy: agents may only perform actions if they have the requisite energy. We begin by studying rational verification for ERMGs and then introduce Endogenous ERMGs, where agents can choose to transfer their energy to other agents. This exchange may enable equilibria that are impossible to achieve without such transfers. We study the decision problem of whether a stable outcome exists under both the Nash equilibrium and Core solution concepts. Keywords: Agent-based and Multi-agent Systems: MAS: Formal verification, validation and synthesis},
  archive   = {C_IJCAI},
  author    = {Julian Gutierrez and David Hyland and Muhammad Najib and Giuseppe Perelli and Michael Wooldridge},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/8},
  month     = {8},
  pages     = {67-75},
  title     = {Endogenous energy reactive modules games: Modelling side payments among resource-bounded agents},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Scalable mechanism design for multi-agent path finding.
<em>IJCAI</em>, 58–66. (<a
href="https://doi.org/10.24963/ijcai.2024/7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-Agent Path Finding (MAPF) involves determining paths for multiple agents to travel simultaneously and collision-free through a shared area toward given goal locations. This problem is computationally complex, especially when dealing with large numbers of agents, as is common in realistic applications like autonomous vehicle coordination. Finding an optimal solution is often computationally infeasible, making the use of approximate, suboptimal algorithms essential. Adding to the complexity, agents might act in a self-interested and strategic way, possibly misrepresenting their goals to the MAPF algorithm if it benefits them. Although the field of mechanism design offers tools to align incentives, using these tools without careful consideration can fail when only having access to approximately optimal outcomes. In this work, we introduce the problem of scalable mechanism design for MAPF and propose three strategyproof mechanisms, two of which even use approximate MAPF algorithms. We test our mechanisms on realistic MAPF domains with problem sizes ranging from dozens to hundreds of agents. We find that they improve welfare beyond a simple baseline. Keywords: Agent-based and Multi-agent Systems: MAS: Multi-agent planning Game Theory and Economic Paradigms: GTEP: Mechanism design Planning and Scheduling: PS: Planning algorithms},
  archive   = {C_IJCAI},
  author    = {Paul Friedrich and Yulun Zhang and Michael Curry and Ludwig Dierks and Stephen McAleer and Jiaoyang Li and Tuomas Sandholm and Sven Seuken},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/7},
  month     = {8},
  pages     = {58-66},
  title     = {Scalable mechanism design for multi-agent path finding},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving multi-agent reinforcement learning with stable
prefix policy. <em>IJCAI</em>, 49–57. (<a
href="https://doi.org/10.24963/ijcai.2024/6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In multi-agent reinforcement learning (MARL), the epsilon-greedy method plays an important role in balancing exploration and exploitation during the decision-making process in value-based algorithms. However, the epsilon-greedy exploration process will introduce conservativeness when calculating the expected state value when the agents are more in need of exploitation during the approximate policy convergence, which may result in a suboptimal policy convergence. Besides, eliminating the epsilon-greedy algorithm leaves no exploration and may lead to unacceptable local optimal policies. To address this dilemma, we use the previously collected trajectories to construct a Monte-Carlo Trajectory Tree, so that an existing optimal template, a sequence of state prototypes, can be planned out. The agents start by following the planned template and act according to the policy without exploration, Stable Prefix Policy. The agents will adaptively dropout and begin to explore by following the epsilon-greedy method when the policy still needs exploration. We scale our approach to various value-based MARL methods and empirically verify our method in a cooperative MARL task, SMAC benchmarks. Experimental results demonstrate that our method achieves not only better performance but also faster convergence speed than baseline algorithms within early time steps. Keywords: Agent-based and Multi-agent Systems: MAS: Multi-agent learning Agent-based and Multi-agent Systems: MAS: Coordination and cooperation},
  archive   = {C_IJCAI},
  author    = {Yue Deng and Zirui Wang and Yin Zhang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/6},
  month     = {8},
  pages     = {49-57},
  title     = {Improving multi-agent reinforcement learning with stable prefix policy},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning translations: Emergent communication pretraining
for cooperative language acquisition. <em>IJCAI</em>, 40–48. (<a
href="https://doi.org/10.24963/ijcai.2024/5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In Emergent Communication (EC) agents learn to communicate with one another, but the protocols that they develop are specialised to their training community. This observation led to research into Zero-Shot Coordination (ZSC) for learning communication strategies that are robust to agents not encountered during training. However, ZSC typically assumes that no prior data is available about the agents that will be encountered in the zero-shot setting. In many cases, this presents an unnecessarily hard problem and rules out communication via preestablished conventions. We propose a novel AI challenge called a Cooperative Language Acquisition Problem (CLAP) in which the ZSC assumptions are relaxed by allowing a &#39;joiner&#39; agent to learn from a dataset of interactions between agents in a target community. We propose and compare two methods for solving CLAPs: Behaviour Cloning (BC), and Emergent Communication pretraining and Translation Learning (ECTL), in which an agent is trained in self-play with EC and then learns to translate between an emergent protocol and the target community&#39;s protocol. Keywords: Agent-based and Multi-agent Systems: MAS: Agent communication Agent-based and Multi-agent Systems: MAS: Agent-based simulation and emergence Agent-based and Multi-agent Systems: MAS: Coordination and cooperation Machine Learning: ML: Multiagent Reinforcement Learning},
  archive   = {C_IJCAI},
  author    = {Dylan Cope and Peter McBurney},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/5},
  month     = {8},
  pages     = {40-48},
  title     = {Learning translations: Emergent communication pretraining for cooperative language acquisition},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PTDE: Personalized training with distilled execution for
multi-agent reinforcement learning. <em>IJCAI</em>, 31–39. (<a
href="https://doi.org/10.24963/ijcai.2024/4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Centralized Training with Decentralized Execution (CTDE) has emerged as a widely adopted paradigm in multi-agent reinforcement learning, emphasizing the utilization of global information for learning an enhanced joint Q-function or centralized critic. In contrast, our investigation delves into harnessing global information to directly enhance individual Q-functions or individual actors. Notably, we discover that applying identical global information universally across all agents proves insufficient for optimal performance. Consequently, we advocate for the customization of global information tailored to each agent, creating agent-personalized global information to bolster overall performance. Furthermore, we introduce a novel paradigm named Personalized Training with Distilled Execution (PTDE), wherein agent-personalized global information is distilled into the agent&#39;s local information. This distilled information is then utilized during decentralized execution, resulting in minimal performance degradation. PTDE can be seamless integrated with state-of-the-art algorithms, leading to notable performance enhancements across diverse benchmarks, including the SMAC benchmark, Google Research Football (GRF) benchmark, and Learning to Rank (LTR) task. Keywords: Agent-based and Multi-agent Systems: MAS: Multi-agent learning Agent-based and Multi-agent Systems: MAS: Coordination and cooperation},
  archive   = {C_IJCAI},
  author    = {Yiqun Chen and Hangyu Mao and Jiaxin Mao and Shiguang Wu and Tianle Zhang and Bin Zhang and Wei Yang and Hongxing Chang},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/4},
  month     = {8},
  pages     = {31-39},
  title     = {PTDE: Personalized training with distilled execution for multi-agent reinforcement learning},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AutoAgents: A framework for automatic agent generation.
<em>IJCAI</em>, 22–30. (<a
href="https://doi.org/10.24963/ijcai.2024/3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Large language models (LLMs) have enabled remarkable advances in automated task-solving with multi-agent systems. However, most existing LLM-based multi-agent approaches rely on predefined agents to handle simple tasks, limiting the adaptability of multi-agent collaboration to different scenarios. Therefore, we introduce AutoAgents, an innovative framework that adaptively generates and coordinates multiple specialized agents to build an AI team according to different tasks. Specifically, AutoAgents couples the relationship between tasks and roles by dynamically generating multiple required agents based on task content and planning solutions for the current task based on the generated expert agents. Multiple specialized agents collaborate with each other to efficiently accomplish tasks. Concurrently, an observer role is incorporated into the framework to reflect on the designated plans and agents&#39; responses and improve upon them. Our experiments on various benchmarks demonstrate that AutoAgents generates more coherent and accurate solutions than the existing multi-agent methods. This underscores the significance of assigning different roles to different tasks and of team cooperation, offering new perspectives for tackling complex tasks. The repository of this project is available at https://github.com/Link-AGI/AutoAgents. Keywords: Agent-based and Multi-agent Systems: MAS: Applications Natural Language Processing: NLP: Applications},
  archive   = {C_IJCAI},
  author    = {Guangyao Chen and Siwei Dong and Yu Shu and Ge Zhang and Jaward Sesay and Börje Karlsson and Jie Fu and Yemin Shi},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/3},
  month     = {8},
  pages     = {22-30},
  title     = {AutoAgents: A framework for automatic agent generation},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Truth table net: Scalable, compact &amp; verifiable neural
networks with a dual convolutional small boolean circuit networks form.
<em>IJCAI</em>, 13–21. (<a
href="https://doi.org/10.24963/ijcai.2024/2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We introduce &quot;Truth Table net&quot;&#39; (TTnet), a novel Deep Neural Network (DNN) architecture designed to provide excellent scalability/compactness trade-offs among DNNs, allowing in turn to tackle the DNN challenge of fast formal verification. TTnet is constructed using Learning Truth Table (LTT) filters, analogous to how a Deep Convolutional Neural Network (DCNN) is built upon convolutional filters. The differentiable LTT filters are unique by their dual form: they are both a neural network-based function and a small-sized truth table that can be computed within a practical time frame. This characteristic guarantees, by design and independently of the overall architecture, the ability to practically extract an efficient (in terms of the number of logical gates) and functionally equivalent Conjunctive Normal Form (CNF) Boolean logic gate implementation. This CNF circuit is even optimal when the LTT truth table&#39;s input bit size n &lt; 12. In particular, TTnet architecture is the first differentiable DNN with as dual form a compact logic gate representation that can scale to datasets larger than CIFAR-10: we achieve an accuracy of 41% on the ImageNet dataset while ensuring that each LTT filter truth table is fully computable within 2^{16} operations. We further compare the compactness and scalability performances of TTnet Boolean logic circuit representation to state-of-the-art differentiable logic DNNs across tabular, MNIST, and CIFAR-10 datasets. We emphasize that TTnet is the first solution to the open problem of designing differentiable convolutional neural networks with an exact dual logic gate circuit representation, bridging the gap between symbolic AI and trainable DCNNs. Finally, as improving DNNs compactness in Boolean logic circuit form reduces the complexity of their formal verification, we demonstrate TTnet effectiveness in exact sound and complete formal verification. Notably, our model achieves robustness verification in 10ms vs 100s for traditional state-of-the-art DNNs solvers. Keywords: Agent-based and Multi-agent Systems: MAS: Formal verification, validation and synthesis AI Ethics, Trust, Fairness: ETF: Trustworthy AI Constraint Satisfaction and Optimization: CSO: Satisfiabilty Machine Learning: ML: Convolutional networks},
  archive   = {C_IJCAI},
  author    = {Adrien Benamira and Thomas Peyrin and Trevor Yap and Tristan Guérand and Bryan Hooi},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/2},
  month     = {8},
  pages     = {13-21},
  title     = {Truth table net: Scalable, compact &amp;amp; verifiable neural networks with a dual convolutional small boolean circuit networks form},
  year      = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Certified policy verification and synthesis for MDPs under
distributional reach-avoidance properties. <em>IJCAI</em>, 3–12. (<a
href="https://doi.org/10.24963/ijcai.2024/1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Markov Decision Processes (MDPs) are a classical model for decision making in the presence of uncertainty. Often they are viewed as state transformers with planning objectives defined with respect to paths over MDP states. An increasingly popular alternative is to view them as distribution transformers, giving rise to a sequence of probability distributions over MDP states. For instance, reachability and safety properties in modeling robot swarms or chemical reaction networks are naturally defined in terms of probability distributions over states. Verifying such distributional properties is known to be hard and often beyond the reach of classical state-based verification techniques. In this work, we consider the problems of certified policy (i.e. controller) verification and synthesis in MDPs under distributional reach-avoidance specifications. By certified we mean that, along with a policy, we also aim to synthesize a (checkable) certificate ensuring that the MDP indeed satisfies the property. Thus, given the target set of distributions and an unsafe set of distributions over MDP states, our goal is to either synthesize a certificate for a given policy or synthesize a policy along with a certificate, proving that the target distribution can be reached while avoiding unsafe distributions. To solve this problem, we introduce the novel notion of distributional reach-avoid certificates and present automated procedures for (1) synthesizing a certificate for a given policy, and (2) synthesizing a policy together with the certificate, both providing formal guarantees on certificate correctness. Our experimental evaluation demonstrates the ability of our method to solve several non-trivial examples, including a multi-agent robot-swarm model, to synthesize certified policies and to certify existing policies. Keywords: Agent-based and Multi-agent Systems: MAS: Formal verification, validation and synthesis Agent-based and Multi-agent Systems: MAS: Trust and reputation Planning and Scheduling: PS: Markov decisions processes Planning and Scheduling: PS: Planning under uncertainty},
  archive   = {C_IJCAI},
  author    = {S. Akshay and Krishnendu Chatterjee and Tobias Meggendorfer and Đorđe Žikelić},
  booktitle = {Thirty-Third International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2024/1},
  month     = {8},
  pages     = {3-12},
  title     = {Certified policy verification and synthesis for MDPs under distributional reach-avoidance properties},
  year      = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
